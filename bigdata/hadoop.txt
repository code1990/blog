1	{"count":100,"start":0,"total":244,"books":[{"rating":{"max":10,"numRaters":81,"average":"8.4","min":0},"subtitle":"","author":["Tom White"],"pubdate":"2017-7","tags":[{"count":99,"name":"大数据","title":"大数据"},{"count":56,"name":"Hadoop","title":"Hadoop"},{"count":34,"name":"计算机","title":"计算机"},{"count":25,"name":"hadoop","title":"hadoop"},{"count":14,"name":"编程","title":"编程"},{"count":11,"name":"Java","title":"Java"},{"count":8,"name":"数据分析","title":"数据分析"},{"count":5,"name":"软件开发","title":"软件开发"}],"origin_title":"Hadoop:the Definitive Guide Storage and Analysis At Internet Scale","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29544746.jpg","binding":"平装","translator":["王海","华东","刘喻","吕粤海"],"catalog":"第Ⅰ部分 Hadoop基础知识\n第1章 初识Hadoop 3\n1.1 数据！数据！ 3\n1.2 数据的存储与分析 5\n1.3 查询所有数据 6\n1.4 不仅仅是批处理 7\n1.5 相较于其他系统的优势 8\n1.5.1 关系型数据库管理系统 8\n1.5.2 网格计算 10\n1.5.3 志愿计算 11\n1.6 Apache Hadoop发展简史 12\n1.7 本书包含的内容 16\n第2章 关于MapReduce 19\n2.1 气象数据集 19\n2.2 使用Unix工具来分析数据 21\n2.3 使用Hadoop来分析数据 22\n2.3.1 map和reduce 23\n2.3.2 Java MapReduce 24\n2.4 横向扩展 31\n2.4.1 数据流 31\n2.4.2 biner函数 35\n2.4.3 运行分布式的MapReduce作业 37\n2.5 Hadoop Streaming 37\n2.5.1 Ruby版本 38\n2.5.2 Python版本 40\n第3章 Hadoop分布式文件系统 42\n3.1 HDFS的设计 42\n3.2 HDFS的概念 44\n3.2.1 数据块 44\n3.2.2 namenode和datanode 45\n3.2.3 块缓存 46\n3.2.4 联邦HDFS 47\n3.2.5 HDFS的高可用性 47\n3.3 命令行接口 50\n3.4 Hadoop文件系统 52\n3.5 Java接口 56\n3.5.1 从Hadoop URL读取数据 56\n3.5.2 通过FileSystem API读取数据 58\n3.5.3 写入数据 61\n3.5.4 目录 63\n3.5.5 查询文件系统 63\n3.5.6 删除数据 68\n3.6 数据流 68\n3.6.1 剖析文件读取 68\n3.6.2 剖析文件写入 71\n3.6.3 一致模型 74\n3.7 通过distcp并行复制 76\n第4章 关于YARN 78\n4.1 剖析YARN应用运行机制 79\n4.1.1 资源请求 80\n4.1.2 应用生命期 81\n4.1.3 构建YARN应用 81\n4.2 YARN与MapReduce 1相比 82\n4.3 YARN中的调度 85\n4.3.1 调度选项 85\n4.3.2 容量调度器配置 87\n4.3.3 公平调度器配置 89\n4.3.5 延迟调度 93\n4.3.5 主导资源公平性 94\n4.4 延伸阅读 95\n第5章 Hadoop的I／O操作 96\n5.1 数据完整性 96\n5.1.1 HDFS的数据完整性 97\n5.1.2 LocalFileSystem 98\n5.1.3 ChecksumFileSystem 98\n5.2 压缩 99\n5.2.1 codec 100\n5.2.2 压缩和输入分片 105\n5.2.3 在MapReduce中使用压缩 106\n5.3 序列化 109\n5.3.1 Writable接口 110\n5.3.2 Writable类 112\n5.3.3 实现定制的Writable集合 121\n5.3.4 序列化框架 125\n5.4 基于文件的数据结构 127\n5.4.1 关于SequenceFile 127\n5.4.2 关于MapFile 135\n5.4.3 其他文件格式和面向列的格式 136\n第Ⅱ部分 关于MapReduce\n第6章 MapReduce应用开发 141\n6.1 用于配置的API 142\n6.1.1 资源合并 143\n6.1.2 变量扩展 144\n6.2 配置开发环境 144\n6.2.1 管理配置 146\n6.2.2 辅助类GenericOptionsParser，Tool和ToolRunner 149\n6.3 用MRUnit来写单元测试 152\n6.3.1 关于Mapper 152\n6.3.2 关于Reducer 156\n6.4 本地运行测试数据 156\n6.4.1 在本地作业运行器上运行作业 156\n6.4.2 测试驱动程序 158\n6.5 在集群上运行 160\n6.5.1 打包作业 160\n6.5.2 启动作业 162\n6.5.3 MapReduce的Web界面 165\n6.5.4 获取结果 167\n6.5.5 作业调试 168\n6.5.6 Hadoop日志 171\n6.5.7 远程调试 173\n6.6 作业调优 174\n6.7 MapReduce的工作流 176\n6.7.1 将问题分解成MapReduce作业 177\n6.7.2 关于JobControl 178\n6.7.3 关于Apache Oozie 179\n第7章 MapReduce的工作机制 184\n7.1 剖析MapReduce作业运行机制 184\n7.1.1 作业的提交 185\n7.1.2 作业的初始化 186\n7.1.3 任务的分配 187\n7.1.4 任务的执行 188\n7.1.5 进度和状态的更新 189\n7.1.6 作业的完成 191\n7.2 失败 191\n7.2.1 任务运行失败 191\n7.2.2 application master运行失败 193\n7.2.3 节点管理器运行失败 193\n7.2.4 资源管理器运行失败 194\n7.3 shuffle和排序 195\n7.3.1 map端 195\n7.3.2 reduce端 197\n7.3.3 配置调优 199\n7.4 任务的执行 201\n7.4.1 任务执行环境 201\n7.4.2 推测执行 202\n7.4.3 关于OutputCommitters 204\n第8章 MapReduce的类型与格式 207\n8.1 MapReduce的类型 207\n8.1.1 默认的MapReduce作业 212\n8.1.2 默认的Streaming作业 216\n8.2 输入格式 218\n8.2.1 输入分片与记录 218\n8.2.2 文本输入 229\n8.2.3 二进制输入 233\n8.2.4 多个输入 234\n8.2.5 数据库输入（和输出） 235\n8.3 输出格式 236\n8.3.1 文本输出 236\n8.3.2 二进制输出 237\n8.3.3 多个输出 237\n8.3.4 延迟输出 242\n8.3.5 数据库输出 242\n第9章 MapReduce的特性 243\n9.1 计数器 243\n9.1.1 内置计数器 243\n9.1.2 用户定义的Java计数器 248\n9.1.3 用户定义的Streaming计数器 251\n9.2 排序 252\n9.2.1 准备 252\n9.2.2 部分排序 253\n9.2.3 全排序 255\n9.2.4 辅助排序 259\n9.3 连接 264\n9.3.1 map端连接 266\n9.3.2 reduce端连接 266\n9.4 边数据分布 270\n9.4.1 利用JobConf来配置作业 270\n9.4.2 分布式缓存 270\n9.5 MapReduce库类 276\n第Ⅲ部分 Hadoop的操作\n第10章 构建Hadoop集群 279\n10.1 集群规范 280\n10.1.1 集群规模 281\n10.1.2 网络拓扑 282\n10.2 集群的构建和安装 284\n10.2.1 安装Java 284\n10.2.2 创建Unix 用户账号 284\n10.2.3 安装Hadoop 284\n10.2.4 SSH配置 285\n10.2.5 配置Hadoop 286\n10.2.6 格式化HDFS 文件系统 286\n10.2.7 启动和停止守护进程 286\n10.2.8 创建用户目录 288\n10.3 Hadoop配置 288\n10.3.1 配置管理 289\n10.3.2 环境设置 290\n10.3.3 Hadoop守护进程的关键属性 293\n10.3.4 Hadoop守护进程的地址和端口 300\n10.3.5 Hadoop的其他属性 303\n10.4 安全性 305\n10.4.1 Kerberos和Hadoop 306\n10.4.2 委托令牌 308\n10.4.3 其他安全性改进 309\n10.5 利用基准评测程序测试Hadoop集群 311\n10.5.1 Hadoop基准评测程序 311\n10.5.2 用户作业 313\n第11章 管理Hadoop 314\n11.1 HDFS 314\n11.1.1 永久性数据结构 314\n11.1.2 安全模式 320\n11.1.3 日志审计 322\n11.1.4 工具 322\n11.2 监控 327\n11.2.1 日志 327\n11.2.2 度量和JMX（Java管理扩展） 328\n11.3 维护 329\n11.3.1 日常管理过程 329\n11.3.2 委任和解除节点 331\n11.3.3 升级 334\n第Ⅳ部分 Hadoop相关开源项目\n第12章 关于Avro 341\n12.1 Avro数据类型和模式 342\n12.2 内存中的序列化和反序列化特定API 347\n12.3 Avro数据文件 349\n12.4 互操作性 351\n12.4.1 Python API 351\n12.4.2 Avro工具集 352\n12.5 模式解析 352\n12.6 排列顺序 354\n12.7 关于Avro MapReduce 356\n12.8 使用Avro MapReduce进行排序 359\n12.9 其他语言的Avro 362\n第13章 关于Parquet 363\n13.1 数据模型 364\n13.2 Parquet文件格式 367\n13.3 Parquet的配置 368\n13.4 Parquet文件的读／写 369\n13.4.1 Avro、Protocol Buffers和Thrift 371\n13.4.2 投影模式和读取模式 373\n13.5 Parquet MapReduce 374\n第14章 关于Flume 377\n14.1 安装Flume 378\n14.2 示例 378\n14.3 事务和可靠性 380\n14.4 HDFS Sink 382\n14.5 扇出 385\n14.5.1 交付保证 386\n14.5.2 复制和复用选择器 387\n14.6 通过代理层分发 387\n14.7 Sink组 391\n14.8 Flume与应用程序的集成 395\n14.9 组件编目 395\n14.10 延伸阅读 397\n第15章 关于Sqoop 398\n15.1 获取Sqoop 398\n15.2 Sqoop连接器 400\n15.3 一个导入的例子 401\n15.4 生成代码 404\n15.5 深入了解数据库导入 405\n15.5.1 导入控制 407\n15.5.2 导入和一致性 408\n15.5.3 增量导入 408\n15.5.4 直接模式导入 408\n15.6 使用导入的数据 409\n15.7 导入大对象 412\n15.8 执行导出 414\n15.9 深入了解导出功能 416\n15.9.1 导出与事务 417\n15.9.2 导出和SequenceFile 418\n15.10 延伸阅读 419\n第16章 关于Pig 420\n16.1 安装与运行Pig 421\n16.1.1 执行类型 422\n16.1.2 运行Pig程序 423\n16.1.3 Grunt 424\n16.1.4 Pig Latin编辑器 424\n16.2 示例 425\n16.3 与数据库进行比较 428\n16.4 PigLatin 429\n16.4.1 结构 430\n16.4.2 语句 431\n16.4.3 表达式 436\n16.4.4 类型 437\n16.4.5 模式 438\n16.4.6 函数 443\n16.4.7 宏 445\n16.5 用户自定义函数 446\n16.5.1 过滤UDF 447\n16.5.2 计算UDF 450\n16.5.3 加载UDF 452\n16.6 数据处理操作 455\n16.6.1 数据的加载和存储 455\n16.6.2 数据的过滤 455\n16.6.3 数据的分组与连接 458\n16.6.4 数据的排序 463\n16.6.5 数据的组合和切分 465\n16.7 Pig实战 465\n16.7.1 并行处理 465\n16.7.2 匿名关系 466\n16.7.3 参数代换 467\n16.8 延伸阅读 468\n第17章 关于Hive 469\n17.1 安装Hive 470\nHive的shell环境 471\n17.2 示例 472\n17.3 运行Hive 473\n17.3.1 配置Hive 473\n17.3.2 Hive服务 476\n17.3.3 Metastore 478\n17.4 Hive与传统数据库相比 480\n17.4.1 读时模式vs.写时模式 480\n17.4.2 更新、事务和索引 481\n17.4.3 其他SQL—on—Hadoop技术 482\n17.5 HiveQL 483\n17.5.1 数据类型 484\n17.5.2 操作与函数 487\n17.6 表 488\n17.6.1 托管表和外部表 488\n17.6.2 分区和桶 490\n17.6.3 存储格式 494\n17.6.4 导入数据 498\n17.6.5 表的修改 500\n17.6.6 表的丢弃 501\n17.7 查询数据 501\n17.7.1 排序和聚集 501\n17.7.2 MapReduce脚本 502\n17.7.3 连接 503\n17.7.4 子查询 506\n17.7.5 视图 507\n17.8 用户定义函数 508\n17.8.1 写UDF 510\n17.8.2 写UDAF 512\n17.9 延伸阅读 516\n第18章 关于Crunch 517\n18.1 示例 518\n18.2 Crunch核心API 521\n18.2.1 基本操作 522\n18.2.2 类型 527\n18.2.3 源和目标 530\n18.2.4 函数 532\n18.2.5 物化 535\n18.3 管线执行 537\n18.3.1 运行管线 538\n18.3.2 停止管线 539\n18.3.3 查看Crunch计划 540\n18.3.4 迭代算法 543\n18.3.5 给管线设置检查点 544\n18.4 Crunch库 545\n18.5 延伸阅读 547\n第19章 关于Spark 548\n19.1 安装Spark 549\n19.2 示例 549\n19.2.1 Spark应用、作业、阶段和任务 551\n19.2.2 Scala独立应用 552\n19.2.3 Java示例 553\n19.2.4 Python示例 554\n19.3 弹性分布式数据集 555\n19.3.1 创建 555\n19.3.2 转换和动作 557\n19.3.3 持久化 561\n19.3.4 序列化 563\n19.4 共享变量 564\n19.4.1 广播变量 564\n19.4.2 累加器 565\n19.5 剖析Spark作业运行机制 565\n19.5.1 作业提交 566\n19.5.2 DAG的构建 566\n19.5.3 任务调度 569\n19.5.4 任务执行 570\n19.6 执行器和集群管理器 570\n19.7 延伸阅读 574\n第20章 关于HBase 575\n20.1 HBase基础 575\n20.2 概念 576\n20.2.1 数据模型的“旋风之旅” 576\n20.2.2 实现 578\n20.3 安装 581\n20.4 客户端 584\n20.4.1 Java 584\n20.4.2 MapReduce 588\n20.4.3 REST和Thrift 589\n20.5 创建在线查询应用 589\n20.5.1 模式设计 590\n20.5.2 加载数据 591\n20.5.3 在线查询 595\n20.6 HBase和RDBMS的比较 598\n20.6.1 成功的服务 599\n20.6.2 HBase 600\n20.7 Praxis 601\n20.7.1 HDFS 601\n20.7.2 用户界面 602\n20.7.3 度量 602\n20.7.4 计数器 602\n20.8 延伸阅读 602\n第21章 关于ZooKeeper 604\n21.1 安装和运行ZooKeeper 605\n21.2 示例 607\n21.2.1 ZooKeeper中的组成员关系 608\n21.2.2 创建组 608\n21.2.3 加入组 611\n21.2.4 列出组成员 612\n21.2.5 删除组 614\n21.3 ZooKeeper服务 615\n21.3.1 数据模型 615\n21.3.2 操作 618\n21.3.3 实现 622\n21.3.4 一致性 624\n21.3.5 会话 626\n21.3.6 状态 628\n21.4 使用ZooKeeper来构建应用 629\n21.4.1 配置服务 629\n21.4.2 可复原的ZooKeeper应用 633\n21.4.3 锁服务 637\n21.4.4 更多分布式数据结构和协议 639\n21.5 生产环境中的ZooKeeper 640\n21.5.1 可恢复性和性能 641\n21.5.2 配置 642\n21.6 延伸阅读 643\n第Ⅴ部分 案例学习\n第22章 医疗公司塞纳（Cerner）的可聚合数据 647\n22.1 从多CPU到语义集成 647\n22.2 进入Apache Crunch 648\n22.3 建立全貌 649\n22.4 集成健康医疗数据 651\n22.5 框架之上的可组合性 654\n22.6 下一步 655\n第23章 生物数据科学：用软件拯救生命 657\n23.1 DNA的结构 659\n23.2 遗传密码：将DNA字符转译为蛋白质 660\n22.3 将DNA想象成源代码 661\n23.4 人类基因组计划和参考基因组 663\n22.5 DNA测序和比对 664\n23.6 ADAM，一个可扩展的基因组分析平台 666\n23.7 使用Avro接口描述语言进行自然语言编程 666\n23.8 使用Parquet进行面向列的存取 668\n23.9 一个简单例子：用Spark和ADAM做k—mer计数 669\n23.10 从个性化广告到个性化医疗 672\n23.11 联系我们 673\n第24章 开源项目Cascading 674\n24.1 字段、元组和管道 675\n24.2 操作 678\n24.3 Taps，Schemes和Flows 680\n24.4 Cascading实践应用 681\n24.5 灵活性 684\n24.6 ShareThis中的Hadoop和Cascading 685\n24.7 总结 689\n附录A 安装Apache Hadoop 691\n附录B 关于CDH 697\n附录C 准备NCDC气象数据 699\n附录D 新版和旧版JavaMapReduce API 702","pages":"705","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29544746.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29544746.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29544746.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27115351\/","id":"27115351","publisher":"清华大学出版社","isbn10":"7302465134","isbn13":"9787302465133","title":"Hadoop权威指南:大数据的存储与分析(第4版)(修订版)(升级版)","url":"https:\/\/api.douban.com\/v2\/book\/27115351","alt_title":"Hadoop:the Definitive Guide Storage and Analysis At Internet Scale","author_intro":"Tom White是最杰出的Hadoop专家之一。自2007年2月以来，Tom White一直是Apache Hadoop的提交者(committer)，也是Apache软件基金会的成员。Tom是Cloudera的软件工程师，他是Cloudera的首批员工，对Apache和Cloudera做出了举足轻重的贡献。在此之前，他是一名独立的Hadoop顾问，帮助公司搭建、使用和扩展Hadoop。他是很多行业大会的专题演讲人，比如ApacheCon、OSCON和Strata。Tom在英国剑桥大学获得数学学士学位，在利兹大学获得科学哲学硕士学位。他目前与家人居住在威尔士。\n译者简介\n王海博士，解放军理工大学通信工程学院教授，博导，教研中心主任，长期从事无线自组网网络的设计与研发工作，主持国家自然科学基金、国家863计划课题等多项国 家级课题，近5年获军队科技进步二等奖1项，三等奖6项，作为第1发明人申请国家发明专利十余项，发表学术论文50余篇。\n华东博士，现任南京医科大学计算机教研室教师，一直致力于计算机辅助教学的相关技术研究，陆续开发了人体解剖学网络自主学习考试平台、诊断学自主学习平台和面向执业医师考试的预约化考试平台等系统，并在各个学科得到广泛的使用，获得全国高等学校计算机课件评比一等奖和三等奖各一项。主编、副主编教材两部，获发明专利一项、软件著作权多项。\n刘喻博士，长期从事软件开发、软件测试和软件工程化管理工作，目前任教于清华大学软件所。\n吕粤海，长期从事军事通信网络技术研究与软件开发工作，先后通过华为光网络高级工程师认证、思科网络工程师认证。","summary":"本书结合理论和实践，由浅入深，全方位介绍了Hadoop 这一高性能的海量数据处理和分析平台。全书5部分24 章，第Ⅰ部分介绍Hadoop 基础知识，第Ⅱ部分介绍MapReduce,第Ⅲ部分介绍Hadoop 的运维，第Ⅳ部分介绍Hadoop 相关开源项目，第Ⅴ部分提供了三个案例，分别来自医疗卫生信息技术服务商塞纳(Cerner)、微软的人工智能项目ADAM(一种大规模分布式深度学习框架)和开源项目Cascading(一个新的针对MapReduce 的数据处理API)。本书是一本专业、全面的Hadoop 参考书和工具书，阐述了Hadoop 生态圈的新发展和应用，程序员可以从中探索海量数据集的存储和分析，管理员可以从中了解Hadoop 集群的安装和运维。","price":"148.00元"},{"rating":{"max":10,"numRaters":178,"average":"7.7","min":0},"subtitle":"","author":["Chuck Lam"],"pubdate":"2011-10","tags":[{"count":271,"name":"hadoop","title":"hadoop"},{"count":144,"name":"分布式","title":"分布式"},{"count":95,"name":"云计算","title":"云计算"},{"count":69,"name":"大数据","title":"大数据"},{"count":49,"name":"Hadoop","title":"Hadoop"},{"count":43,"name":"计算机","title":"计算机"},{"count":31,"name":"编程","title":"编程"},{"count":25,"name":"并行计算","title":"并行计算"}],"origin_title":"Hadoop in Action","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8480468.jpg","binding":"平装","translator":["韩冀中"],"catalog":"第一部分  Hadoop——一种分布式编程框架\n第1 章  Hadoop简介　　2\n1.1  为什么写《Hadoop 实战》　　3\n1.2  什么是Hadoop 　　3\n1.3  了解分布式系统和Hadoop 　　4\n1.4  比较SQL 数据库和Hadoop　　5\n1.5  理解MapReduce　　6\n1.5.1  动手扩展一个简单程序　　7\n1.5.2  相同程序在MapReduce中的扩展　　9\n1.6  用Hadoop统计单词——运行第一个程序　　11\n1.7  Hadoop历史　　15\n1.8  小结　　16\n1.9  资源　　16\n第2 章  初识Hadoop 　　17\n2.1  Hadoop 的构造模块　　17\n2.1.1  NameNode 　　17\n2.1.2  DataNode 　　18\n2.1.3  Secondary NameNode 　　19\n2.1.4  JobTracker　　19\n2.1.5  TaskTracker　　19\n2.2  为Hadoop 集群安装SSH　　21\n2.2.1  定义一个公共账号　　21\n2.2.2  验证SSH安装　　21\n2.2.3  生成SSH密钥对　　21\n2.2.4  将公钥分布并登录验证　　22\n2.3  运行Hadoop 　　22\n2.3.1  本地（单机）模式　　23\n2.3.2   伪分布模式　　24\n2.3.3  全分布模式　　25\n2.4  基于Web 的集群用户界面　　28\n2.5  小结　　30\n第3 章  Hadoop组件　　31\n3.1  HDFS 文件操作　　31\n3.1.1  基本文件命令　　32\n3.1.2  编程读写HDFS　　35\n3.2  剖析MapReduce 程序　　37\n3.2.1  Hadoop数据类型　　39\n3.2.2  Mapper　　40\n3.2.3  Reducer　　41\n3.2.4  Partitioner：重定向Mapper输出　　41\n3.2.5  Combiner：本地reduce 　　43\n3.2.6  预定义mapper和Reducer类的单词计数　　43\n3.3  读和写　　43\n3.3.1  InputFormat 　　44\n3.3.2  OutputFormat　　49\n3.4  小结　　50\n第二部分  实战\n第4 章  编写MapReduce基础程序　　52\n4.1  获得专利数据集　　52\n4.1.1  专利引用数据　　53\n4.1.2  专利描述数据　　54\n4.2  构建MapReduce 程序的基础模板　　55\n4.3  计数　　60\n4.4  适应Hadoop API 的改变　　64\n4.5  Hadoop 的Streaming 　　 67\n4.5.1  通过Unix命令使用Streaming 　　 68\n4.5.2  通过脚本使用Streaming　　 69\n4.5.3  用Streaming处理键\/值对　　 72\n4.5.4  通过Aggregate包使用Streaming　　75\n4.6  使用combiner 提升性能　　 80\n4.7  温故知新　　83\n4.8  小结　　84\n4.9  更多资源　　84\n第5 章  高阶MapReduce 　　 85\n5.1  链接MapReduce 作业　　 85\n5.1.1  顺序链接MapReduce作业　　 85\n5.1.2  具有复杂依赖的MapReduce链接　　86\n5.1.3  预处理和后处理阶段的链接　　86\n5.2  联结不同来源的数据　　 89\n5.2.1  Reduce侧的联结　　 90\n5.2.2  基于DistributedCache的复制联结　　 98\n5.2.3  半联结：map侧过滤后在reduce侧联结　　101\n5.3  创建一个Bloom filter 　　102\n5.3.1  Bloom filter做了什么　　102\n5.3.2  实现一个Bloom filter 　　104\n5.3.3  Hadoop 0.20 以上版本的Bloom filter 　　 110\n5.4  温故知新　　　110\n5.5  小结　　 111\n5.6  更多资源　　 112\n第6 章  编程实践　　 113\n6.1  开发MapReduce 程序　　 113\n6.1.1  本地模式　　 114\n6.1.2  伪分布模式　　 118\n6.2  生产集群上的监视和调试　　123\n6.2.1  计数器　　123\n6.2.2  跳过坏记录　　125\n6.2.3  用IsolationRunner重新运行出错的任务　　128\n6.3  性能调优　　 129\n6.3.1  通过combiner来减少网络流量　　129\n6.3.2  减少输入数据量　　129\n6.3.3  使用压缩　　129\n6.3.4  重用JVM 　　132\n6.3.5  根据猜测执行来运行　　132\n6.3.6  代码重构与算法重写　　133\n6.4  小结　　134\n第7 章  细则手册　　135\n7.1  向任务传递作业定制的参数　　 135\n7.2  探查任务特定信息　　137\n7.3  划分为多个输出文件　　138\n7.4  以数据库作为输入输出　　143\n7.5  保持输出的顺序　　145\n7.6  小结　　 146\n第8 章  管理Hadoop　　147\n8.1  为实际应用设置特定参数值　　 147\n8.2  系统体检　　149\n8.3  权限设置　　151\n8.4  配额管理　　151\n8.5  启用回收站　　152\n8.6  删减DataNode 　　152\n8.7  增加DataNode 　　153\n8.8  管理NameNode 和SNN　　 153\n8.9  恢复失效的NameNode 　　155\n8.10  感知网络布局和机架的设计　　156\n8.11  多用户作业的调度　　157\n8.11.1  多个JobTracker 　　 158\n8.11.2  公平调度器　　158\n8.12  小结　　 160\n第三部分  Hadoop也疯狂\n第9 章  在云上运行Hadoop 　　 162\n9.1  Amazon Web Services 简介　　162\n9.2  安装AWS　　163\n9.2.1  获得AWS身份认证凭据　　164\n9.2.2  获得命令行工具　　166\n9.2.3  准备SSH密钥对　　168\n9.3  在EC2 上安装Hadoop　　169\n9.3.1  配置安全参数　　169\n9.3.2  配置集群类型　　169\n9.4  在EC2 上运行MapReduce 程序　　171\n9.4.1  将代码转移到Hadoop集群上　　171\n9.4.2  访问Hadoop集群上的数据　　172\n9.5  清空和关闭EC2 实例　　175\n9.6  Amazon Elastic MapReduce 和其他AWS 服务　　176\n9.6.1  Amazon Elastic MapReduce 　　176\n9.6.2  AWS导入\/导出　　177\n9.7  小结　　177\n第10 章  用Pig编程　　178\n10.1  像Pig 一样思考　　178\n10.1.1  数据流语言　　179\n10.1.2  数据类型　　179\n10.1.3  用户定义函数　　179\n10.2  安装Pig 　　179\n10.3  运行Pig 　　180\n10.4  通过Grunt 学习Pig Latin　　182\n10.5  谈谈Pig Latin 　　186\n10.5.1  数据类型和schema　　186\n10.5.2  表达式和函数　　187\n10.5.3  关系型运算符　　189\n10.5.4  执行优化　　196\n10.6  用户定义函数　　196\n10.6.1  使用UDF 　　196\n10.6.2  编写UDF 　　197\n10.7  脚本　　199\n10.7.1  注释　　199\n10.7.2  参数替换　　200\n10.7.3  多查询执行　　201\n10.8  Pig 实战——计算相似专利的例子　　201\n10.9  小结　　206\n第11 章  Hive及Hadoop群　　207\n11.1  Hive 　　207\n11.1.1  安装与配置Hive 　　208\n11.1.2  查询的示例　　210\n11.1.3  深入HiveQL 　　213\n11.1.4  Hive小结　　221\n11.2  其他Hadoop 相关的部分　　221\n11.2.1  HBase 　　221\n11.2.2  ZooKeeper 　　221\n11.2.3  Cascading 　　221\n11.2.4  Cloudera 　　222\n11.2.5  Katta 　　222\n11.2.6  CloudBase 　　222\n11.2.7  Aster Data和Greenplum 　　222\n11.2.8  Hama和Mahout 　　223\n11.2.9  search-hadoop.com 　　223\n11.3  小结　　223\n第12 章  案例研究　　224\n12.1  转换《纽约时报》1100 万个库存图片文档　　224\n12.2  挖掘中国移动的数据　　225\n12.3  在StumbleUpon 推荐最佳网站　　229\n12.3.1  分布式StumbleUpon 的开端　　230\n12.3.2  HBase 和StumbleUpon 　　230\n12.3.3  StumbleUpon 上的更多Hadoop 应用　　236\n12.4  搭建面向企业查询的分析系统——IBM的ES2 项目　　238\n12.4.1  ES2 系统结构　　240\n12.4.2  ES2 爬虫　　241\n12.4.3  ES2 分析　　242\n12.4.4  小结　　249\n12.4.5  参考文献　　250\n附录A  HDFS文件命令　　251","pages":"253","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s8480468.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s8480468.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8480468.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6859710\/","id":"6859710","publisher":"人民邮电出版社","isbn10":"7115264481","isbn13":"9787115264480","title":"Hadoop实战","url":"https:\/\/api.douban.com\/v2\/book\/6859710","alt_title":"Hadoop in Action","author_intro":"Chuck Lam 目前建立了一个名为RollCall的移动社交网络公司，让活跃的个体用户拥有了一个社交助理。他以前曾是RockYou的高级技术组长，开发了社交应用 程序和数据处理基础架构，能够支撑上亿的用户。在斯坦福大学攻读博士的时候，Chuck就对大数据产生了兴趣。他的论文“Computational Data Acquisition”首创了可用于机器学习的数据采集方法，吸纳了来自开源软件和网络游戏等领域的思想。","summary":"《Hadoop实战》作为云计算所青睐的分布式架构，Hadoop是一个用Java语言实现的软件框架，在由大量计算机组成的集群中运行海量数据的分布式计算，是谷歌实现云计算的重要基石。《Hadoop实战》分为3个部分，深入浅出地介绍了Hadoop框架、编写和运行Hadoop数据处理程序所需的实践技能及Hadoop之外更大的生态系统。\n《Hadoop实战》适合需要处理大量离线数据的云计算程序员、架构师和项目经理阅读参考。","price":"59.00元"},{"rating":{"max":10,"numRaters":145,"average":"8.4","min":0},"subtitle":"深入解析MapReduce架构设计与实现原理","author":["董西成"],"pubdate":"2013-5","tags":[{"count":294,"name":"Hadoop","title":"Hadoop"},{"count":119,"name":"MapReduce","title":"MapReduce"},{"count":91,"name":"大数据","title":"大数据"},{"count":74,"name":"分布式","title":"分布式"},{"count":65,"name":"云计算","title":"云计算"},{"count":47,"name":"Hadoop技术内幕","title":"Hadoop技术内幕"},{"count":40,"name":"hadoop","title":"hadoop"},{"count":39,"name":"源码分析","title":"源码分析"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26559339.jpg","binding":"平装","translator":[],"catalog":"前　言\n第一部分　基础篇\n第1章　阅读源代码前的准备\/ 2\n1.1　准备源代码学习环境\/ 2\n1.1.1　基础软件下载\/ 2\n1.1.2　如何准备Windows环境\/ 3\n1.1.3　如何准备Linux环境\/ 6\n1.2　获取Hadoop源代码\/ 7\n1.3　搭建Hadoop源代码阅读环境\/ 8\n1.3.1　创建Hadoop工程\/ 8\n1.3.2　Hadoop源代码阅读技巧\/ 9\n1.4　Hadoop源代码组织结构\/ 10\n1.5　Hadoop初体验\/ 13\n1.5.1　启动Hadoop\/ 13\n1.5.2　Hadoop Shell介绍\/ 15\n1.5.3　Hadoop Eclipse插件介绍\/ 15\n1.6　编译及调试Hadoop源代码\/ 19\n1.6.1　编译Hadoop源代码\/ 19\n1.6.2　调试Hadoop源代码\/ 20\n1.7　小结\/ 23\n第2章　MapReduce设计理念与基本架构\/ 24\n2.1　Hadoop发展史\/ 24\n2.1.1　Hadoop产生背景\/ 24\n2.1.2　Apache Hadoop新版本的特性\/ 25\n2.1.3　Hadoop版本变迁\/ 26\n2.2　Hadoop MapReduce设计目标\/ 28\n2.3　MapReduce编程模型概述\/ 29\n2.3.1　MapReduce编程模型简介\/ 29\n2.3.2　MapReduce编程实例\/ 31\n2.4　Hadoop基本架构\/ 32\n2.4.1　HDFS架构\/ 33\n2.4.2　Hadoop MapReduce架构\/ 34\n2.5　Hadoop MapReduce作业的生命周期\/ 36\n2.6　小结\/ 38\n第二部分　MapReduce编程模型篇\n第3章　MapReduce编程模型\/ 40\n3.1　MapReduce编程模型概述\/ 40\n3.1.1　MapReduce编程接口体系结构\/ 40\n3.1.2　新旧MapReduce API比较\/ 41\n3.2　MapReduce API基本概念\/ 42\n3.2.1　序列化\/ 42\n3.2.2　Reporter参数\/ 43\n3.2.3　回调机制\/ 43\n3.3　Java API解析\/ 44\n3.3.1　作业配置与提交\/ 44\n3.3.2　InputFormat接口的设计与实现\/ 48\n3.3.3　OutputFormat接口的设计与实现\/ 53\n3.3.4　Mapper与Reducer解析\/ 55\n3.3.5　Partitioner接口的设计与实现\/ 59\n3.4　非Java API解析\/ 61\n3.4.1　Hadoop Streaming的实现原理\/ 61\n3.4.2　Hadoop Pipes的实现原理\/ 64\n3.5　Hadoop工作流\/ 67\n3.5.1　JobControl的实现原理\/ 67\n3.5.2　ChainMapper\/ChainReducer的实现原理\/ 69\n3.5.3　Hadoop工作流引擎\/ 71\n3.6　小结\/ 73\n第三部分　MapReduce核心设计篇\n第4章　Hadoop RPC框架解析\/ 76\n4.1　Hadoop RPC框架概述\/ 76\n4.2　Java基础知识\/ 77\n4.2.1　Java反射机制与动态代理\/ 78\n4.2.2　Java网络编程\/ 80\n4.2.3　Java NIO\/ 82\n4.3　Hadoop RPC基本框架分析\/ 89\n4.3.1　RPC基本概念\/ 89\n4.3.2　Hadoop RPC基本框架\/ 91\n4.3.3　集成其他开源RPC框架\/ 98\n4.4　MapReduce通信协议分析\/ 100\n4.4.1　MapReduce 通信协议概述\/ 100\n4.4.2　JobSubmissionProtocol通信协议\/ 102\n4.4.3　InterTrackerProtocol通信协议\/ 102\n4.4.4　TaskUmbilicalProtocol通信协议\/ 103\n4.4.5　其他通信协议\/ 104\n4.5　小结\/ 106\n第5章　作业提交与初始化过程分析\/ 107\n5.1　作业提交与初始化概述\/ 107\n5.2　作业提交过程详解\/ 108\n5.2.1　执行Shell命令\/ 108\n5.2.2　作业文件上传\/ 109\n5.2.3　产生InputSplit文件\/ 111\n5.2.4　作业提交到JobTracker\/ 113\n5.3　作业初始化过程详解\/ 115\n5.4　Hadoop DistributedCache原理分析\/ 117\n5.4.1　使用方法介绍\/ 118\n5.4.2　工作原理分析\/ 120\n5.5　小结\/ 122\n第6章　JobTracker内部实现剖析\/ 123\n6.1　JobTracker概述\/ 123\n6.2　JobTracker启动过程分析\/ 125\n6.2.1　JobTracker启动过程概述\/ 125\n6.2.2　重要对象初始化\/ 125\n6.2.3　各种线程功能\/ 128\n6.2.4　作业恢复\/ 129\n6.3　心跳接收与应答\/ 129\n6.3.1　更新状态\/ 131\n6.3.2　下达命令\/ 131\n6.4　Job和Task运行时信息维护\/ 134\n6.4.1　作业描述模型\/ 134\n6.4.2　JobInProgress\/ 136\n6.4.3　TaskInProgress\/ 137\n6.4.4　作业和任务状态转换图\/ 139\n6.5　容错机制\/ 141\n6.5.1　JobTracker容错\/ 141\n6.5.2　TaskTracker容错\/ 142\n6.5.3　Job\/Task容错\/ 145\n6.5.4　Record容错\/ 147\n6.5.5　磁盘容错\/ 151\n6.6　任务推测执行原理\/ 152\n6.6.1　计算模型假设\/ 153\n6.6.2　1.0.0版本的算法\/ 153\n6.6.3　0.21.0版本的算法\/ 154\n6.6.4　2.0版本的算法\/ 156\n6.7　Hadoop资源管理\/ 157\n6.7.1　任务调度框架分析\/ 159\n6.7.2　任务选择策略分析\/ 162\n6.7.3　FIFO调度器分析\/ 164\n6.7.4　Hadoop资源管理优化\/ 165\n6.8　小结\/ 168\n第7章　TaskTracker内部实现剖析\/ 169\n7.1　TaskTracker概述\/ 169\n7.2　TaskTracker启动过程分析\/ 170\n7.2.1　重要变量初始化\/ 171\n7.2.2　重要对象初始化\/ 171\n7.2.3　连接JobTracker\/ 172\n7.3　心跳机制\/ 172\n7.3.1　单次心跳发送\/ 172\n7.3.2　状态发送\/ 175\n7.3.3　命令执行\/ 178\n7.4　TaskTracker行为分析\/ 179\n7.4.1　启动新任务\/ 179\n7.4.2　提交任务\/ 179\n7.4.3　杀死任务\/ 181\n7.4.4　杀死作业\/ 182\n7.4.5　重新初始化\/ 184\n7.5　作业目录管理\/ 184\n7.6　启动新任务\/ 186\n7.6.1　任务启动过程分析\/ 186\n7.6.2　资源隔离机制\/ 193\n7.7　小结\/ 195\n第8章　Task运行过程分析\/ 196\n8.1　Task运行过程概述\/ 196\n8.2　基本数据结构和算法\/ 197\n8.2.1　IFile存储格式\/ 197\n8.2.2　排序\/ 198\n8.2.3　Reporter\/ 201\n8.3　Map Task内部实现\/ 204\n8.3.1　Map Task整体流程\/ 204\n8.3.2　Collect过程分析\/ 205\n8.3.3　Spill过程分析\/ 213\n8.3.4　Combine过程分析\/ 214\n8.4　Reduce Task内部实现\/ 214\n8.4.1　Reduce Task整体流程\/ 215\n8.4.2　Shuffle和Merge阶段分析\/ 215\n8.4.3　Sort和Reduce阶段分析\/ 218\n8.5　Map\/Reduce Task优化\/ 219\n8.5.1　参数调优\/ 219\n8.5.2　系统优化\/ 220\n8.6　小结\/ 224\n第四部分　MapReduce高级篇\n第9章　Hadoop性能调优\/ 228\n9.1　概述\/ 228\n9.2　从管理员角度进行调优\/ 229\n9.2.1　硬件选择\/ 229\n9.2.2　操作系统参数调优\/ 229\n9.2.3　JVM参数调优\/ 230\n9.2.4　Hadoop参数调优\/ 230\n9.3　从用户角度进行调优\/ 235\n9.3.1　应用程序编写规范\/ 235\n9.3.2　作业级别参数调优\/ 235\n9.3.3　任务级别参数调优\/ 239\n9.4　小结\/ 240\n第10章　Hadoop多用户作业调度器\/ 241\n10.1　多用户调度器产生背景\/ 241\n10.2　HOD\/ 242\n10.2.1　Torque资源管理器\/ 242\n10.2.2　HOD作业调度\/ 243\n10.3　Hadoop队列管理机制\/ 245\n10.4　Capacity Scheduler实现\/ 246\n10.4.1　Capacity Scheduler功能介绍\/ 247\n10.4.2　Capacity Scheduler实现\/ 249\n10.4.3　多层队列调度\/ 254\n10.5　Fair Scheduler实现\/ 255\n10.5.1　Fair Scheduler功能介绍\/ 255\n10.5.2　Fair Scheduler实现\/ 258\n10.5.3　Fair Scheduler与Capacity Scheduler对比\/ 263\n10.6　其他Hadoop调度器介绍\/ 264\n10.7　小结\/ 265\n第11章　Hadoop安全机制\/ 266\n11.1　Hadoop安全机制概述\/ 266\n11.1.1　Hadoop面临的安全问题\/ 266\n11.1.2　Hadoop对安全方面的需求\/ 267\n11.1.3　Hadoop安全设计基本原则\/ 267\n11.2　基础知识\/ 268\n11.2.1　安全认证机制\/ 268\n11.2.2　Kerberos介绍\/ 270\n11.3　Hadoop安全机制实现\/ 273\n11.3.1　RPC\/ 273\n11.3.2　HDFS\/ 276\n11.3.3　MapReduce\/ 278\n11.3.4　上层服务\/ 280\n11.4　应用场景总结\/ 281\n11.4.1　文件存取\/ 281\n11.4.2　作业提交与运行\/ 282\n11.4.3　上层中间件访问Hadoop\/ 282\n11.5　小结\/ 283\n第12章　下一代MapReduce框架\/ 284\n12.1　第一代MapReduce框架的局限性\/ 284\n12.2　下一代MapReduce框架概述\/ 284\n12.2.1　基本设计思想\/ 284\n12.2.2　资源统一管理平台\/ 286\n12.3　Apache YARN\/ 287\n12.3.1　Apache YARN基本框架\/ 287\n12.3.2　Apache YARN工作流程\/ 290\n12.3.3　Apache YARN设计细节\/ 291\n12.3.4　MapReduce与YARN结合\/ 294\n12.4　Facebook Corona \/ 298\n12.4.1　Facebook Corona基本框架\/ 298\n12.4.2　Facebook Corona工作流程\/ 300\n12.4.3　YARN与Corona对比\/ 303\n12.5　Apache Mesos\/ 304\n12.5.1　Apache Mesos基本框架\/ 304\n12.5.2　Apache Mesos资源分配\/ 305\n12.5.3　MapReduce与Mesos结合\/ 307\n12.6　小结\/ 309\n附录A　安装Hadoop过程中可能存在的问题及解决方案\/ 310\n附录B　Hadoop默认HTTP端口号以及HTTP地址\/ 312\n参考资料\/ 313","ebook_url":"https:\/\/read.douban.com\/ebook\/15232980\/","pages":"332","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s26559339.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s26559339.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26559339.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24375031\/","id":"24375031","publisher":"机械工业出版社","isbn10":"7111422260","isbn13":"9787111422266","title":"Hadoop技术内幕","url":"https:\/\/api.douban.com\/v2\/book\/24375031","alt_title":"","author_intro":"作者信息请参考他的技术博客：http:\/\/dongxicheng.org\/ 和该书的官方宣传网站：http:\/\/hadoop123.com\/","summary":"《Hadoop技术内幕:深入解析MapReduce架构设计与实现原理》内容简介：“Hadoop技术内幕”共两册，分别从源代码的角度对“Common+HDFS”和“MapReduce的架构设计和实现原理”进行了极为详细的分析。《Hadoop技术内幕:深入解析MapReduce架构设计与实现原理》由Hadoop领域资深的实践者亲自执笔，首先介绍了MapReduce的设计理念和编程模型，然后从源代码的角度深入分析了RPC框架、客户端、JobTracker、TaskTracker和Task等MapReduce运行时环境的架构设计与实现原理，最后从实际应用的角度深入讲解了Hadoop的性能优化、安全机制、多用户作业调度器和下一代MapReduce框架等高级主题和内容。《Hadoop技术内幕:深入解析MapReduce架构设计与实现原理》适合Hadoop的二次开发人员、应用开发工程师、运维工程师阅读。\n\n海报：","ebook_price":"25.00","series":{"id":"19432","title":"大数据技术丛书"},"price":"69.00元"},{"rating":{"max":10,"numRaters":107,"average":"8.8","min":0},"subtitle":"The Definitive Guide","author":["Tom White"],"pubdate":"2012-5-26","tags":[{"count":123,"name":"Hadoop","title":"Hadoop"},{"count":43,"name":"分布式","title":"分布式"},{"count":33,"name":"并行计算","title":"并行计算"},{"count":30,"name":"数据挖掘","title":"数据挖掘"},{"count":24,"name":"大数据","title":"大数据"},{"count":23,"name":"计算机","title":"计算机"},{"count":20,"name":"O'Reilly","title":"O'Reilly"},{"count":18,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27225339.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"688","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27225339.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27225339.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27225339.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10464777\/","id":"10464777","publisher":"O'Reilly Media","isbn10":"1449311520","isbn13":"9781449311520","title":"Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/10464777","alt_title":"","author_intro":"","summary":"Ready to unleash the power of your massive dataset? With the latest edition of this comprehensive resource, you'll learn how to use Apache Hadoop to build and maintain reliable, scalable, distributed systems. It's ideal for programmers looking to analyze datasets of any size, and for administrators who want to set up and run Hadoop clusters. This third edition covers recent changes to Hadoop, including new material on the new MapReduce API, as well as version 2 of the MapReduce runtime (YARN) and its more flexible execution model. You'll also find illuminating case studies that demonstrate how Hadoop is used to solve specific problems. * Store large datasets with the Hadoop Distributed File System (HDFS), then run distributed computations with MapReduce * Use Hadoop's data and I\/O building blocks for compression, data integrity, serialization (including Avro), and persistence * Discover common pitfalls and advanced features for writing real-world MapReduce programs * Design, build, and administer a dedicated Hadoop cluster, or run Hadoop in the cloud * Use Pig, a high-level query language for large-scale data processing * Analyze datasets with Hive, Hadoop's data warehousing system * Load data from relational databases into HDFS, using Sqoop * Take advantage of HBase, the database for structured and semi-structured data * Use ZooKeeper, the toolkit for building distributed systems","price":"USD 49.99"},{"rating":{"max":10,"numRaters":251,"average":"7.7","min":0},"subtitle":"Hadoop权威指南","author":["Tom White"],"pubdate":"2011-7","tags":[{"count":374,"name":"hadoop","title":"hadoop"},{"count":212,"name":"分布式","title":"分布式"},{"count":149,"name":"MapReduce","title":"MapReduce"},{"count":116,"name":"云计算","title":"云计算"},{"count":77,"name":"大数据","title":"大数据"},{"count":70,"name":"计算机","title":"计算机"},{"count":46,"name":"O'Reilly","title":"O'Reilly"},{"count":41,"name":"编程","title":"编程"}],"origin_title":"Hadoop: The Definitive Guide","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6641416.jpg","binding":"平装","translator":["周敏奇","王晓玲","金澈清","钱卫宁","周傲英"],"catalog":"第1章 初识Hadoop\n数据！数据！\n数据存储与分析\n与其他系统相比\n关系型数据库管理系统\n网格计算\n志愿计算\n1.3.4 Hadoop 发展简史\nApache Hadoop和Hadoop生态圈\n第2章 关于MapReduce\n一个气象数据集\n数据的格式\n使用Unix工具进行数据分析\n使用Hadoop分析数据\nmap阶段和reduce阶段\n横向扩展\n合并函数\n运行一个分布式的MapReduce作业\nHadoop的Streaming\nRuby版本\nPython版本\nHadoop Pipes\n编译运行\n第3章 Hadoop分布式文件系统\nHDFS的设计\nHDFS的概念\n数据块\nnamenode和datanode\n命令行接口\n基本文件系统操作\nHadoop文件系统\n接口\nJava接口\n从Hadoop URL中读取数据\n通过FileSystem API读取数据\n写入数据\n目录\n查询文件系统\n删除数据\n数据流\n文件读取剖析\n文件写入剖析\n一致模型\n通过 distcp并行拷贝\n保持 HDFS 集群的均衡\nHadoop的归档文件\n使用Hadoop归档文件\n不足\n第4章 Hadoop I\/O\n数据完整性\nHDFS的数据完整性\nLocalFileSystem\nChecksumFileSystem\n压缩\ncodec\n压缩和输入切分\n在MapReduce中使用压缩\n序列化\nWritable接口\nWritable类\n实现定制的Writable类型\n序列化框架\nAvro\n依据文件的数据结构\n写入SequenceFile\nMapFile\n第5章 MapReduce应用开发\n配置API\n合并多个源文件\n可变的扩展\n配置开发环境\n配置管理\n辅助类GenericOptionsParser，Tool和ToolRunner\n编写单元测试\nmapper\nreducer\n本地运行测试数据\n在本地作业运行器上运行作业\n测试驱动程序\n在集群上运行\n打包\n启动作业\nMapReduce的Web界面\n获取结果\n作业调试\n使用远程调试器\n作业调优\n分析任务\nMapReduce的工作流\n将问题分解成MapReduce作业\n运行独立的作业\n第6章 MapReduce的工作机制\n剖析MapReduce作业运行机制\n作业的提交\n作业的初始化\n任务的分配\n任务的执行\n进度和状态的更新\n作业的完成\n失败\n任务失败\ntasktracker失败\njobtracker失败\n作业的调度\nFair Scheduler\nCapacity Scheduler\nshuffle和排序\nmap端\nreduce端\n配置的调优\n任务的执行\n推测式执行\n重用JVM\n跳过坏记录\n任务执行环境\n第7章 MapReduce的类型与格式\nMapReduce的类型\n默认的MapReduce作业\n输入格式\n输入分片与记录\n文本输入\n二进制输入\n多种输入\n数据库输入（和输出）\n输出格式\n文本输出\n二进制输出\n多个输出\n延迟输出\n数据库输出\n第8章 MapReduce的特性\n计数器\n内置计数器\n用户定义的Java计数器\n用户定义的Streaming计数器\n排序\n准备\n部分排序\n总排序\n二次排序\n联接\nmap端联接\nreduce端联接\n边数据分布\n利用JobConf来配置作业\n分布式缓存\nMapReduce库类\n第9章 构建Hadoop集群\n集群规范\n网络拓扑\n集群的构建和安装\n安装Java\n创建Hadoop用户\n安装Hadoop\n测试安装\nSSH配置\nHadoop配置\n配置管理\n环境设置\nHadoop守护进程的关键属性\nHadoop守护进程的地址和端口\nHadoop的其他属性\n创建用户帐号\n安全性\nKerberos和Hadoop\n委托令牌\n其他安全性改进\n利用基准测试程序测试Hadoop集群\nHadoop基准测试程序\n用户的作业\n云上的Hadoop\nAmazon EC2上的Hadoop\n第10章 管理Hadoop\nHDFS\n永久性数据结构\n安全模式\n日志审计\n工具\n监控\n日志\n度量\nJava管理扩展（JMX）\n维护\n日常管理过程\n委任节点和解除节点\n升级\n第11章 Pig简介\n安装与运行Pig\n执行类型\n运行Pig程序\nGrunt\nPig Latin编辑器\n示例\n生成示例\n与数据库比较\nPigLatin\n结构\n语句\n表达式\n1.4.4 类型\n模式\n函数\n用户自定义函数\n过滤UDF\n计算UDF\n加载UDF\n数据处理操作\n加载和存储数据\n过滤数据\n分组与连接数据\n对数据进行排序\n组合和分割数据\nPig实战\n并行处理\n参数代换\n第12章 Hive\n1.1 安装Hive\n1.1.1 Hive外壳环境\n1.2 示例\n1.3 运行Hive\n1.3.1 配置Hive\n1.3.2 Hive服务\n1.3.3 Metastore\n1.4  和传统数据库进行比较\n1.4.1 读时模式（Schema on Read）vs.写时模式（Schema on Write）\n1.4.2 更新、事务和索引\n1.5 HiveQL\n1.5.1 数据类型\n1.5.2 操作和函数\n1.6 表\n1.6.1 托管表（Managed Tables）和外部表（External Tables）\n1.6.2 分区（Partitions）和桶（Buckets）\n1.6.3 存储格式\n1.6.4 导入数据\n1.6.5 表的修改\n1.6.6 表的丢弃\n1.7 查询数据\n1.7.1 排序（Sorting）和聚集（Aggregating）\n1.7.2 MapReduce脚本\n1.7.3 连接\n1.7.4 子查询\n1.7.5 视图（view）\n1.8 用户定义函数（User-Defined Functions）\n1.8.1 编写UDF\n1.8.2 编写UDAF\n第13章 HBase\n2.1 HBasics\n2.1.1 背景\n2.2 概念\n2.2.1 数据模型的“旋风之旅”\n2.2.2 实现\n2.3 安装\n2.3.1 测试驱动\n2.4 客户机\n2.4.1 Java\n2.4.2 Avro，REST，以及Thrift\n2.5 示例\n2.5.1 模式\n2.5.2 加载数据\n2.5.3 Web查询\n2.6 HBase和RDBMS的比较\n2.6.1 成功的服务\n2.6.2 HBase\n2.6.3 实例：HBase在Streamy.com的使用\n2.7 Praxis\n2.7.1 版本\n2.7.2 HDFS\n2.7.3 用户接口（UI）\n2.7.4 度量（metrics）\n2.7.5 模式设计\n2.7.6 计数器\n2.7.7 批量加载（bulkloading）\n第14章 ZooKeeper\n安装和运行ZooKeeper\n示例\nZooKeeper中的组成员关系\n创建组\n加入组\n列出组成员\nZooKeeper服务\n数据模型\n操作\n实现\n一致性\n会话\n状态\n使用ZooKeeper来构建应用\n配置服务\n具有可恢复性的ZooKeeper应用\n锁服务\n生产环境中的ZooKeeper\n可恢复性和性能\n配置\n第15章 开源工具Sqoop\n获取Sqoop\n一个导入的例子\n生成代码\n其他序列化系统\n深入了解数据库导入\n导入控制\n导入和一致性\n直接模式导入\n使用导入的数据\n导入的数据与Hive\n导入大对象\n执行导出\n深入了解导出\n导出与事务\n导出和SequenceFile\n第16章 实例分析\nHadoop 在Last.fm的应用\nLast.fm：社会音乐史上的革命\nHadoop a Last.fm\n用Hadoop产生图表\nTrack Statistics程序\n总结\nHadoop和Hive在Facebook的应用\n概要介绍\nHadoop a Facebook\n假想的使用情况案例\nHive\n问题与未来工作计划\nNutch 搜索引擎\n背景介绍\n数据结构\nNutch系统利用Hadoop进行数据处理的精选实例\n总结\nRackspace的日志处理\n简史\n选择Hadoop\n收集和存储\n日志的MapReduce模型\n关于Cascading\n字段、元组和管道\n操作\nTap类，Scheme对象和Flow对象\nCascading实战\n灵活性\nHadoop和Cascading在ShareThis的应用\n总结\n在Apache Hadoop上的TB字节数量级排序\n使用Pig和Wukong来探索10亿数量级边的 网络图\n测量社区\n每个人都在和我说话：Twitter回复关系图\n（度）degree\n对称链接\n社区提取\n附录A 安装Apache Hadoop\n附录B Cloudera’s Distribution for Hadoop\n附录C 准备NCDC天气数据\n索引","pages":"600","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s6641416.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s6641416.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6641416.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6523762\/","id":"6523762","publisher":"清华大学出版社","isbn10":"7302257582","isbn13":"9787302257585","title":"Hadoop权威指南（第2版）","url":"https:\/\/api.douban.com\/v2\/book\/6523762","alt_title":"Hadoop: The Definitive Guide","author_intro":"Tom White从2007年以来，一直担任Apache Hadoop项目负责人。他是Apache软件基金会的成员之一，同时也是Cloudera的一名工程师。Tom为oreully.com、java.net和IBM的developerWorks写过大量文章，并经常在很多行业大会上发表演讲。","summary":"《Hadoop权威指南(第2版)(修订•升级版)》从Hadoop的缘起开始，由浅入深，结合理论和实践，全方位地介绍Hadoop这一高性能处理海量数据集的理想工具。全书共16章，3个附录，涉及的主题包括：Haddoop简介；MapReduce简介；Hadoop分布式文件系统；Hadoop的I\/O、MapReduce应用程序开发；MapReduce的工作机制；MapReduce的类型和格式；MapReduce的特性；如何构建Hadoop集群，如何管理Hadoop；Pig简介；Hbase简介；Hive简介；ZooKeeper简介；开源工具Sqoop，最后还提供了丰富的案例分析。\n《Hadoop权威指南(第2版)(修订•升级版)》是Hadoop权威参考，程序员可从中探索如何分析海量数据集，管理员可以从中了解如何安装与运行Hadoop集群。","price":"89.00元"},{"rating":{"max":10,"numRaters":59,"average":"8.0","min":0},"subtitle":"深入解析YARN架构设计与实现原理","author":["董西成"],"pubdate":"2013-11-30","tags":[{"count":72,"name":"Hadoop","title":"Hadoop"},{"count":61,"name":"YARN","title":"YARN"},{"count":48,"name":"大数据","title":"大数据"},{"count":20,"name":"hadoop2.0","title":"hadoop2.0"},{"count":14,"name":"计算机","title":"计算机"},{"count":14,"name":"hadoop","title":"hadoop"},{"count":11,"name":"MapReduce","title":"MapReduce"},{"count":6,"name":"分布式","title":"分布式"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27145238.jpg","binding":"平装","translator":[],"catalog":"前　言\n第一部分　准备篇\n第1章　环境准备 2\n1.1　准备学习环境 2\n1.1.1　基础软件下载 2\n1.1.2　如何准备Linux环境 3\n1.2　获取Hadoop源代码 5\n1.3　搭建Hadoop源代码阅读环境 5\n1.3.1　创建Hadoop工程 5\n1.3.2　Hadoop源代码阅读技巧 8\n1.4　Hadoop源代码组织结构 10\n1.5　Hadoop初体验 12\n1.5.1　搭建Hadoop环境 12\n1.5.2　Hadoop Shell介绍 15\n1.6　编译及调试Hadoop源代码 16\n1.6.1　编译Hadoop源代码 17\n1.6.2　调试Hadoop源代码 18\n1.7　小结 20\n第2章　YARN设计理念与基本架构 21\n2.1　YARN产生背景 21\n2.1.1　MRv1的局限性 21\n2.1.2　轻量级弹性计算平台 22\n2.2　Hadoop基础知识 23\n2.2.1　术语解释 23\n2.2.2　Hadoop版本变迁 25\n2.3　YARN基本设计思想 29\n2.3.1　基本框架对比 29\n2.3.2　编程模型对比 30\n2.4　YARN 基本架构 31\n2.4.1　YARN基本组成结构 32\n2.4.2　YARN通信协议 34\n2.5　YARN工作流程 35\n2.6　多角度理解YARN 36\n2.6.1　并行编程 36\n2.6.2　资源管理系统 36\n2.6.3　云计算 37\n2.7　本书涉及内容 38\n2.8　小结 38\n第二部分　YARN核心设计篇\n第3章　YARN基础库 40\n3.1　概述 40\n3.2　第三方开源库 41\n3.2.1　Protocol Buffers 41\n3.2.2　Apache Avro 43\n3.3　底层通信库 46\n3.3.1　RPC通信模型 46\n3.3.2　Hadoop RPC的特点概述 48\n3.3.3　RPC总体架构 48\n3.3.4　Hadoop RPC使用方法 49\n3.3.5　Hadoop RPC类详解 51\n3.3.6　Hadoop RPC参数调优 57\n3.3.7　YARN RPC实现 57\n3.3.8　YARN RPC应用实例 61\n3.4　服务库与事件库 65\n3.4.1　服务库 66\n3.4.2　事件库 66\n3.4.3　YARN服务库和事件库的使用方法 68\n3.4.4　事件驱动带来的变化 70\n3.5　状态机库 72\n3.5.1　YARN状态转换方式 72\n3.5.2　状态机类 73\n3.5.3　状态机的使用方法 73\n3.5.4　状态机可视化 76\n3.6　源代码阅读引导 76\n3.7　小结 77\n3.8　问题讨论 77\n第4章　YARN应用程序设计方法 78\n4.1　概述 78\n4.2　客户端设计 79\n4.2.1　客户端编写流程 80\n4.2.2　客户端编程库 84\n4.3　ApplicationMaster设计 84\n4.3.1　ApplicationMaster编写流程 84\n4.3.2　ApplicationMaster编程库 92\n4.4　YARN 应用程序实例 95\n4.4.1　DistributedShell 95\n4.4.2　Unmanaged AM 99\n4.5　源代码阅读引导 100\n4.6　小结 100\n4.7　问题讨论 100\n第5章　ResourceManager剖析 102\n5.1　概述 102\n5.1.1　ResourceManager基本职能 102\n5.1.2　ResourceManager内部架构 103\n5.1.3　ResourceManager事件与事件处理器 106\n5.2　用户交互模块 108\n5.2.1　ClientRMService 108\n5.2.2　AdminService 109\n5.3　ApplicationMaster管理 109\n5.4　NodeManager管理 112\n5.5　Application管理 113\n5.6　状态机管理 114\n5.6.1　RMApp状态机 115\n5.6.2　RMAppAttempt状态机 119\n5.6.3　RMContainer状态机 123\n5.6.4　RMNode状态机 127\n5.7　几个常见行为分析 129\n5.7.1　启动ApplicationMaster  129\n5.7.2　申请与分配Container 132\n5.7.3　杀死Application 134\n5.7.4　Container超时 135\n5.7.5　ApplicationMaster超时 138\n5.7.6　NodeManager超时 138\n5.8　安全管理 139\n5.8.1　术语介绍 139\n5.8.2　Hadoop认证机制 139\n5.8.3　Hadoop授权机制 142\n5.9　容错机制 144\n5.9.1　Hadoop HA基本框架 145\n5.9.2　YARN HA实现  148\n5.10　源代码阅读引导 149\n5.11　小结 151\n5.12　问题讨论 152\n第6章　资源调度器 153\n6.1　资源调度器背景 153\n6.2　HOD调度器 154\n6.2.1　Torque资源管理器 154\n6.2.2　HOD作业调度 155\n6.3　YARN资源调度器的基本架构 157\n6.3.1　基本架构 157\n6.3.2　资源表示模型 160\n6.3.3　资源调度模型 161\n6.3.4　资源抢占模型 164\n6.4　YARN层级队列管理机制 169\n6.4.1　层级队列管理机制 169\n6.4.2　队列命名规则 171\n6.5　Capacity Scheduler 172\n6.5.1　Capacity Scheduler的功能 172\n6.5.2　Capacity Scheduler实现 176\n6.6　Fair Scheduler 179\n6.6.1　Fair Scheduler功能介绍 180\n6.6.2　Fair Scheduler实现 182\n6.6.3　Fair Scheduler与Capacity Scheduler对比 183\n6.7　其他资源调度器介绍 184\n6.8　源代码阅读引导 185\n6.9　小结 186\n6.10　问题讨论 187\n第7章　NodeManager剖析 188\n7.1　概述 188\n7.1.1　NodeManager基本职能 188\n7.1.2　NodeManager内部架构 190\n7.1.3　NodeManager事件与事件处理器 193\n7.2　节点健康状况检测 194\n7.2.1　自定义Shell脚本 194\n7.2.2　检测磁盘损坏数目 196\n7.3　分布式缓存机制 196\n7.3.1　资源可见性与分类 198\n7.3.2　分布式缓存实现 200\n7.4　目录结构管理 203\n7.4.1　数据目录管理 203\n7.4.2　日志目录管理 203\n7.5　状态机管理 206\n7.5.1　Application状态机 207\n7.5.2　Container状态机 210\n7.5.3　LocalizedResource状态机 213\n7.6　Container生命周期剖析 214\n7.6.1　Container资源本地化 214\n7.6.2　Container运行 218\n7.6.3　Container资源清理 222\n7.7　资源隔离 224\n7.7.1　Cgroups介绍 224\n7.7.2　内存资源隔离 228\n7.7.3　CPU资源隔离 230\n7.8　源代码阅读引导 234\n7.9　小结 235\n7.10　问题讨论 236\n第三部分　计算框架篇\n第8章　离线计算框架MapReduce 238\n8.1　概述 238\n8.1.1　基本构成 238\n8.1.2　事件与事件处理器 240\n8.2　MapReduce客户端 241\n8.2.1　ApplicationClientProtocol协议 242\n8.2.2　MRClientProtocol协议 243\n8.3　MRAppMaster工作流程 243\n8.4　MR作业生命周期及相关状态机 246\n8.4.1　MR作业生命周期 246\n8.4.2　Job状态机 249\n8.4.3　Task状态机 253\n8.4.4　TaskAttempt状态机 255\n8.5　资源申请与再分配 259\n8.5.1　资源申请 259\n8.5.2　资源再分配 262\n8.6　Container启动与释放 263\n8.7　推测执行机制 264\n8.7.1　算法介绍 265\n8.7.2　推测执行相关类 266\n8.8　作业恢复 267\n8.9　数据处理引擎 269\n8.10　历史作业管理器 271\n8.11　MRv1与MRv2对比 273\n8.11.1　MRv1 On YARN 273\n8.11.2　MRv1与MRv2架构比较 274\n8.11.3　MRv1与MRv2编程接口兼容性 274\n8.12　源代码阅读引导 275\n8.13　小结 277\n8.14　问题讨论 277\n第9章　DAG计算框架Tez 278\n9.1　背景 278\n9.2　Tez数据处理引擎 281\n9.2.1　Tez编程模型 281\n9.2.2　Tez数据处理引擎 282\n9.3　DAG Master实现 284\n9.3.1　DAG编程模型 284\n9.3.2　MR到DAG转换 286\n9.3.3　DAGAppMaster 288\n9.4　优化机制 291\n9.4.1　当前YARN框架存在的问题 291\n9.4.2　Tez引入的优化技术 292\n9.5　Tez应用场景 292\n9.6　与其他系统比较 294\n9.7　小结 295\n第10章　实时\/内存计算框架Storm\/Spark 296\n10.1　Hadoop MapReduce的短板 296\n10.2　实时计算框架Storm  296\n10.2.1　Storm编程模型 297\n10.2.2　Storm基本架构 302\n10.2.3　Storm On YARN 304\n10.3　内存计算框架Spark 307\n10.3.1　Spark编程模型 308\n10.3.2　Spark基本架构 312\n10.3.3　Spark On YARN 316\n10.3.4　Spark\/Storm On YARN比较 317\n10.4　小结 317\n第四部分　高级篇\n第11章　Facebook Corona剖析 320\n11.1　概述 320\n11.1.1　Corona的基本架构 320\n11.1.2　Corona的RPC协议与序列化框架 322\n11.2　Corona设计特点 323\n11.2.1　推式网络通信模型 323\n11.2.2　基于Hadoop 0.20版本 324\n11.2.3　使用Thrift 324\n11.2.4　深度集成Fair Scheduler 324\n11.3　工作流程介绍 324\n11.3.1　作业提交 325\n11.3.2　资源申请与任务启动 326\n11.4　主要模块介绍 327\n11.4.1　ClusterManager 327\n11.4.2　CoronaJobTracker 330\n11.4.3　CoronaTaskTracker 333\n11.5　小结 335\n第12章　Apache Mesos剖析 336\n12.1　概述 336\n12.2　底层网络通信库 337\n12.2.1　libprocess基本架构 338\n12.2.2　一个简单示例 338\n12.3　Mesos服务 340\n12.3.1　SchedulerProcess 341\n12.3.2　Mesos Master  342\n12.3.3　Mesos Slave  343\n12.3.4　ExecutorProcess 343\n12.4　Mesos工作流程 344\n12.4.1　框架注册过程 344\n12.4.2　Framework Executor注册过程 345\n12.4.3　资源分配到任务运行过程 345\n12.4.4　任务启动过程 347\n12.4.5　任务状态更新过程 347\n12.5　Mesos资源分配策略 348\n12.5.1　Mesos资源分配框架 349\n12.5.2　Mesos资源分配算法 349\n12.6　Mesos容错机制 350\n12.6.1　Mesos Master容错 350\n12.6.2　Mesos Slave容错 351\n12.7　Mesos应用实例 352\n12.7.1　Hadoop On Mesos 352\n12.7.2　Storm On Mesos 353\n12.8　Mesos与YARN对比 354\n12.9　小结 355\n第13章　YARN总结与发展趋势 356\n13.1　资源管理系统设计动机 356\n13.2　资源管理系统架构演化 357\n13.2.1　集中式架构 357\n13.2.2　双层调度架构 358\n13.2.3　共享状态架构 358\n13.3　YARN发展趋势  359\n13.3.1　YARN自身的完善 359\n13.3.2　以YARN为核心的生态系统 361\n13.3.3　YARN周边工具的完善 363\n13.4　小结 363\n附录A　YARN安装指南 364\n附录B　YARN配置参数介绍 367\n附录C　Hadoop Shell命令介绍 371\n附录D　参考资料 374","ebook_url":"https:\/\/read.douban.com\/ebook\/15354232\/","pages":"396","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27145238.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27145238.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27145238.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25774649\/","id":"25774649","publisher":"机械工业出版社","isbn10":"7111445341","isbn13":"9787111445340","title":"Hadoop技术内幕","url":"https:\/\/api.douban.com\/v2\/book\/25774649","alt_title":"","author_intro":"","summary":"本书从应用角度系统讲解了YARN的基本库和组件用法、应用程序设计方法、YARN上流行的各种计算框架（MapReduce、Tez、Storm、Spark），以及多个类YARN的开源资源管理系统（Corona和Mesos）；从源代码角度深入分析YARN的设计理念与基本架构、各个组件的实现原理，以及各种计算框架的实现细节。\n全书共四部分13章：第一部分（第1~2章）主要介绍了如何获取、阅读和调试Hadoop的源代码，以及YARN的设计思想、基本架构和工作流程；第二部分（第3~7章）结合源代码详细剖析和讲解了YARN的第三方开源库、底层通信库、服务库、事件库的基本使用和实现细节，详细讲解了YARN的应用程序设计方法，深入讲解和分析了ResourceManager、资源调度器、NodeManager等组件的实现细节；第三篇（第8~10章）则对离线计算框架MapReduce、DAG计算框架Tez、实时计算框架Storm和内存计算框架Spark进行了详细的讲解；第四部分（第11~13章）首先对Facebook Corona和Apache Mesos进行了深入讲解，然后对YARN的发展趋势进行了展望。附录部分收录了YARN安装指南、YARN配置参数以及Hadoop Shell命令等非常有用的资料。","ebook_price":"25.00","series":{"id":"19432","title":"大数据技术丛书"},"price":"69.00元"},{"rating":{"max":10,"numRaters":76,"average":"8.1","min":0},"subtitle":"深入解析Hadoop Common和HDFS架构设计与实现原理","author":["蔡斌","陈湘萍"],"pubdate":"2013-4","tags":[{"count":139,"name":"hadoop","title":"hadoop"},{"count":84,"name":"大数据","title":"大数据"},{"count":65,"name":"HDFS","title":"HDFS"},{"count":43,"name":"云计算","title":"云计算"},{"count":36,"name":"分布式","title":"分布式"},{"count":35,"name":"Hadoop","title":"Hadoop"},{"count":20,"name":"计算机","title":"计算机"},{"count":13,"name":"架构","title":"架构"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s26376893.jpg","binding":"平装","translator":[],"catalog":"前　言\n第一部分　环境准备\n第1章　源代码环境准备\/ 2\n1.1　什么是Hadoop \/ 2\n1.1.1　Hadoop简史\/ 2\n1.1.2　Hadoop的优势\/ 3\n1.1.3　Hadoop生态系统\/ 4\n1.2　准备源代码阅读环境\/ 8\n1.2.1　安装与配置JDK \/ 8\n1.2.2　安装Eclipse \/ 9\n1.2.3　安装辅助工具Ant\/ 12\n1.2.4　安装类UNIX Shell环境Cygwin \/ 13\n1.3　准备Hadoop源代码\/ 15\n1.3.1　下载Hadoop \/ 15\n1.3.2　创建Eclipse项目\/ 16\n1.3.3　Hadoop源代码组织\/ 18\n1.4　小结\/ 19\n第二部分　Common的实现\n第2章　Hadoop配置信息处理\/ 22\n2.1　配置文件简介\/ 22\n2.1.1　Windows操作系统的配置文件\/ 22\n2.1.2　Java配置文件\/ 23\n2.2　Hadoop Configuration详解\/ 24\n2.2.1　Hadoop配置文件的格式\/ 24\n2.2.2　Configuration的成员变量\/ 26\n2.2.3　资源加载\/ 27\n2.2.4　使用get*和set*访问\/设置配置项\/ 32\n2.3　Configurable接口\/ 34\n2.4　小结\/ 35\n第3章　序列化与压缩\/ 36\n3.1　序列化\/ 36\n3.1.1　Java内建序列化机制\/ 36\n3.1.2　Hadoop序列化机制\/ 38\n3.1.3　Hadoop序列化机制的特征\/ 39\n3.1.4　Hadoop Writable机制\/ 39\n3.1.5　典型的Writable类详解\/ 41\n3.1.6　Hadoop序列化框架\/ 48\n3.2　压缩\/ 49\n3.2.1　Hadoop压缩简介\/ 50\n3.2.2　Hadoop压缩API应用实例\/ 51\n3.2.3　Hadoop压缩框架\/ 52\n3.2.4　Java本地方法\/ 61\n3.2.5　支持Snappy压缩\/ 65\n3.3　小结\/ 69\n第4章　Hadoop远程过程调用\/ 70\n4.1　远程过程调用基础知识\/ 70\n4.1.1　RPC原理\/ 70\n4.1.2　RPC机制的实现\/ 72\n4.1.3　Java远程方法调用\/ 73\n4.2　Java动态代理\/ 78\n4.2.1　创建代理接口\/ 78\n4.2.2　调用转发\/ 80\n4.2.3　动态代理实例\/ 81\n4.3　Java NIO\/ 84\n4.3.1　Java基本套接字\/ 84\n4.3.2　Java NIO基础\/ 86\n4.3.3　Java NIO实例：回显服务器\/ 93\n4.4　Hadoop中的远程过程调用\/ 96\n4.4.1　利用Hadoop IPC构建简单的分布式系统\/ 96\n4.4.2　Hadoop IPC的代码结构\/ 100\n4.5　Hadoop IPC连接相关过程\/ 104\n4.5.1　IPC连接成员变量\/ 104\n4.5.2　建立IPC连接\/ 106\n4.5.3　数据分帧和读写\/ 111\n4.5.4　维护IPC连接\/ 114\n4.5.5　关闭IPC连接\/ 116\n4.6　Hadoop IPC方法调用相关过程\/ 118\n4.6.1　Java接口与接口体\/ 119\n4.6.2　IPC方法调用成员变量\/ 121\n4.6.3　客户端方法调用过程\/ 123\n4.6.4　服务器端方法调用过程\/ 126\n4.7　Hadoop IPC上的其他辅助过程\/ 135\n4.7.1　RPC.getProxy()和RPC.stopProxy() \/ 136\n4.7.2　RPC.getServer()和Server的启停\/ 138\n4.8　小结\/ 141\n第5章　Hadoop文件系统\/ 142\n5.1　文件系统\/ 142\n5.1.1　文件系统的用户界面\/ 142\n5.1.2　文件系统的实现\/ 145\n5.1.3　文件系统的保护控制\/ 147\n5.2　Linux文件系统\/ 150\n5.2.1　Linux本地文件系统\/ 150\n5.2.2　虚拟文件系统\/ 153\n5.2.3　Linux文件保护机制\/ 154\n5.2.4　Linux文件系统API\/ 155\n5.3　分布式文件系统\/ 159\n5.3.1　分布式文件系统的特性\/ 159\n5.3.2　基本NFS体系结构\/ 160\n5.3.3　NFS支持的文件操作\/ 160\n5.4　Java文件系统\/ 162\n5.4.1　Java文件系统API \/ 162\n5.4.2　URI和URL \/ 164\n5.4.3　Java输入\/输出流\/ 166\n5.4.4　随机存取文件\/ 169\n5.5　Hadoop抽象文件系统\/ 170\n5.5.1　Hadoop文件系统API \/ 170\n5.5.2　Hadoop输入\/输出流\/ 175\n5.5.3　Hadoop文件系统中的权限\/ 179\n5.5.4　抽象文件系统中的静态方法\/ 180\n5.5.5　Hadoop文件系统中的协议处理器\/ 184\n5.6　Hadoop具体文件系统\/ 188\n5.6.1　FileSystem层次结构\/ 189\n5.6.2　RawLocalFileSystem的实现\/ 191\n5.6.3　ChecksumFileSystem的实现\/ 196\n5.6.4　RawInMemoryFileSystem的实现\/ 210\n5.7　小结\/ 213\n第三部分　Hadoop分布式文件系统\n第6章　HDFS概述\/ 216\n6.1　初识HDFS \/ 216\n6.1.1　HDFS主要特性\/ 216\n6.1.2　HDFS体系结构\/ 217\n6.1.3　HDFS源代码结构\/ 221\n6.2　基于远程过程调用的接口\/ 223\n6.2.1　与客户端相关的接口\/ 224\n6.2.2　HDFS各服务器间的接口\/ 236\n6.3　非远程过程调用接口\/ 244\n6.3.1　数据节点上的非IPC接口\/ 245\n6.3.2　名字节点和第二名字节点上的非IPC接口\/ 252\n6.4　HDFS主要流程\/ 254\n6.4.1　客户端到名字节点的文件与目录操作\/ 254\n6.4.2　客户端读文件\/ 256\n6.4.3　客户端写文件\/ 257\n6.4.4　数据节点的启动和心跳\/ 258\n6.4.5　第二名字节点合并元数据\/ 259\n6.5　小结\/ 261\n第7章　数据节点实现\/ 263\n7.1　数据块存储\/ 263\n7.1.1　数据节点的磁盘目录文件结构\/ 263\n7.1.2　数据节点存储的实现\/ 266\n7.1.3　数据节点升级\/ 269\n7.1.4　文件系统数据集的工作机制\/ 276\n7.2　流式接口的实现\/ 285\n7.2.1　DataXceiverServer和DataXceiver \/ 286\n7.2.2　读数据\/ 289\n7.2.3　写数据\/ 298\n7.2.4　数据块替换、数据块拷贝和读数据块检验信息\/ 313\n7.3　作为整体的数据节点\/ 314\n7.3.1　数据节点和名字节点的交互\/ 314\n7.3.2　数据块扫描器\/ 319\n7.3.3　数据节点的启停\/ 321\n7.4　小结\/ 326\n第8章　名字节点实现\/ 327\n8.1　文件系统的目录树\/ 327\n8.1.1　从i-node到INode\/ 327\n8.1.2　命名空间镜像和编辑日志\/ 333\n8.1.3　第二名字节点\/ 351\n8.1.4　FSDirectory的实现\/ 361\n8.2　数据块和数据节点管理\/ 365\n8.2.1　数据结构\/ 366\n8.2.2　数据节点管理\/ 378\n8.2.3　数据块管理\/ 392\n8.3　远程接口ClientProtocol的实现\/ 412\n8.3.1　文件和目录相关事务\/ 412\n8.3.2　读数据使用的方法\/ 415\n8.3.3　写数据使用的方法\/ 419\n8.3.4　工具dfsadmin依赖的方法\/ 443\n8.4　名字节点的启动和停止\/ 444\n8.4.1　安全模式\/ 444\n8.4.2　名字节点的启动\/ 449\n8.4.3　名字节点的停止\/ 454\n8.5　小结\/ 454\n第9章　HDFS客户端\/ 455\n9.1　认识DFSClient \/ 455\n9.1.1　DFSClient的构造和关闭\/ 455\n9.1.2　文件和目录、系统管理相关事务\/ 457\n9.1.3　删除HDFS文件\/目录的流程\/ 459\n9.2　输入流\/ 461\n9.2.1　读数据前的准备：打开文件\/ 463\n9.2.2　读数据\/ 465\n9.2.3　关闭输入流\/ 475\n9.2.4　读取HDFS文件数据的流程\/ 475\n9.3　输出流\/ 478\n9.3.1　写数据前的准备：创建文件\/ 481\n9.3.2　写数据：数据流管道的建立\/ 482\n9.3.3　写数据：数据包的发送\/ 486\n9.3.4　写数据：数据流管道出错处理\/ 493\n9.3.5　写数据：租约更新\/ 496\n9.3.6　写数据：DFSOutputStream.sync()的作用\/ 497\n9.3.7　关闭输出流\/ 499\n9.3.8　向HDFS文件写入数据的流程\/ 500\n9.4　DistributedFileSystem的实现\/ 506\n9.5　HDFS常用工具\/ 508\n9.5.1　FsShell \/ 508\n9.5.2　DFSAdmin \/ 510\n9.6　小结\/ 511","ebook_url":"https:\/\/read.douban.com\/ebook\/15235711\/","pages":"512","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s26376893.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s26376893.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s26376893.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24294210\/","id":"24294210","publisher":"机械工业出版社","isbn10":"7111417666","isbn13":"9787111417668","title":"Hadoop技术内幕","url":"https:\/\/api.douban.com\/v2\/book\/24294210","alt_title":"","author_intro":"蔡斌，资深Hadoop技术专家，基于Hadoop的开源项目X-RIME的作者之一。国内Hadoop应用和源代码研究领域的先驱之一，有10余年开发经验，先后任职于朗讯科技、IBM中国研究院等国内外知名企业，目前担任腾讯数据平台部的高级工程师，从事Hadoop相关技术的研究、应用和实施，实战经验非常丰富。对分布式计算、电信增值业务、网络管理等领域有深刻的认识和理解，拥有近10项发明专利，其中两项为美国专利，大部分与海量数据处理相关。近期关注海量数据的流式处理、Hadoop上的大数据应用与挖掘等。\n陈湘萍，北京大学计算机系博士，目前就职于中山大学，专注于Hadoop、云计算、软件中间件、模型驱动的软件工程等技术的研究和实践。拥有发明专利5项，参与1项国家电子行业标准的制定，发表学术论文10余篇。","summary":"《Hadoop技术内幕:深入解析Hadoop Common和HDFS架构设计与实现原理》内容简介：“Hadoop技术内幕”共两册，分别从源代码的角度对“Common+HDFS”和MapReduce的架构设计与实现原理进行了极为详细的分析。《Hadoop技术内幕:深入解析Hadoop Common和HDFS架构设计与实现原理》由腾讯数据平台的资深Hadoop专家、X-RIME的作者亲自执笔，对Common和HDFS的源代码进行了分析，旨在为Hadoop的优化、定制和扩展提供原理性的指导。除此之外，《Hadoop技术内幕:深入解析Hadoop Common和HDFS架构设计与实现原理》还从源代码实现中对分布式技术的精髓、分布式系统设计的优秀思想和方法，以及Java语言的编码技巧、编程规范和对设计模式的精妙运用进行了总结和分析，对提高读者的分布式技术能力和Java编程能力都非常有帮助。《Hadoop技术内幕:深入解析Hadoop Common和HDFS架构设计与实现原理》适合Hadoop的二次开发人员、应用开发工程师、运维工程师阅读。\n全书共9章，分为三部分：第一部分（第1章）主要介绍了Hadoop源代码的获取和源代码阅读环境的搭建；第二部分（第2～5章）对Hadoop公共工具Common的架构设计和实现原理进行了深入分析，包含Hadoop的配置信息处理、面向海量数据处理的序列化和压缩机制、Hadoop的远程过程调用，以及满足Hadoop上各类应用访问数据的Hadoop抽象文件系统和部分具体文件系统等内容；第三部分（第6～9章）对Hadoop的分布式文件系统HDFS的架构设计和实现原理进行了详细的分析，这部分内容采用了总分总的结构，第6章对HDFS的各个实体和实体间接口进行了分析；第7章和第8章分别详细地研究了数据节点和名字节点的实现原理，并通过第9章对客户端的解析，回顾了HDFS各节点间的配合，完整地介绍了一个大规模数据存储系统的实现。\n\n海报：","ebook_price":"30.00","series":{"id":"19432","title":"大数据技术丛书"},"price":"89.00元"},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"","author":["Tom White"],"pubdate":"2010-10-12","tags":[{"count":8,"name":"hadoop","title":"hadoop"},{"count":2,"name":"计算机科学","title":"计算机科学"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"程序设计","title":"程序设计"},{"count":2,"name":"分布式计算","title":"分布式计算"},{"count":1,"name":"软件开发","title":"软件开发"},{"count":1,"name":"架构设计","title":"架构设计"},{"count":1,"name":"互联网","title":"互联网"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s6492719.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"628","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s6492719.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s6492719.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s6492719.jpg"},"alt":"https:\/\/book.douban.com\/subject\/5312116\/","id":"5312116","publisher":"Yahoo Press","isbn10":"1449389732","isbn13":"9781449389734","title":"Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/5312116","alt_title":"","author_intro":"","summary":"Discover how Apache Hadoop can unleash the power of your data. This comprehensive resource shows you how to build and maintain reliable, scalable, distributed systems with the Hadoop framework -- an open source implementation of MapReduce, the algorithm on which Google built its empire. Programmers will find details for analyzing datasets of any size, and administrators will learn how to set up and run Hadoop clusters.   This revised edition covers recent changes to Hadoop, including new features such as Hive, Sqoop, and Avro. It also provides illuminating case studies that illustrate how Hadoop is used to solve specific problems. Looking to get the most out of your data? This is your book.    Use the Hadoop Distributed File System (HDFS) for storing large datasets, then run distributed computations over those datasets with MapReduce   Become familiar with Hadoop’s data and I\/O building blocks for compression, data integrity, serialization, and persistence   Discover common pitfalls and advanced features for writing real-world MapReduce programs   Design, build, and administer a dedicated Hadoop cluster, or run Hadoop in the cloud   Use Pig, a high-level query language for large-scale data processing   Analyze datasets with Hive, Hadoop’s data warehousing system   Take advantage of HBase, Hadoop’s database for structured and semi-structured data   Learn ZooKeeper, a toolkit of coordination primitives for building distributed systems     \"Now you have the opportunity to learn about Hadoop from a master -- not only of the technology, but also of common sense and plain talk.\" \n\n --Doug Cutting, Cloudera","price":"USD 49.99"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"The Definitive Guide","author":["Tom White"],"pubdate":"2009-6-12","tags":[{"count":5,"name":"hadoop","title":"hadoop"},{"count":3,"name":"云计算","title":"云计算"},{"count":2,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"云一下","title":"云一下"},{"count":1,"name":"Programming","title":"Programming"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s10915536.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"528","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s10915536.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s10915536.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s10915536.jpg"},"alt":"https:\/\/book.douban.com\/subject\/3529888\/","id":"3529888","publisher":"O'Reilly Media","isbn10":"0596521979","isbn13":"9780596521974","title":"Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/3529888","alt_title":"","author_intro":"","summary":"Organizations large and small are adopting Apache Hadoop to deal with huge application datasets, and this comprehensive resource provides you with the key for unlocking the wealth this data holds. Hadoop is ideal for storing and processing massive amounts of data, but until now, information on this open-source project has been lacking - especially with regard to best practices. \"Hadoop: The Definitive Guide\" demonstrates how to use Hadoop to build reliable, scalable, distributed systems. Programmers will find details for analyzing large datasets with Hadoop, and administrators will learn how to set up and run Hadoop clusters. The book also provides case studies that illustrate how Hadoop solves specific problems.","price":"USD 44.99"},{"rating":{"max":10,"numRaters":268,"average":"8.3","min":0},"subtitle":"MapReduce for the Cloud","author":["Tom White"],"pubdate":"2009","tags":[{"count":316,"name":"hadoop","title":"hadoop"},{"count":178,"name":"MapReduce","title":"MapReduce"},{"count":150,"name":"分布式","title":"分布式"},{"count":59,"name":"Cloud","title":"Cloud"},{"count":42,"name":"计算机","title":"计算机"},{"count":39,"name":"架构","title":"架构"},{"count":34,"name":"Hadoop","title":"Hadoop"},{"count":26,"name":"技术","title":"技术"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s3810946.jpg","binding":"pap","translator":[],"catalog":"","pages":"250","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s3810946.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s3810946.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s3810946.jpg"},"alt":"https:\/\/book.douban.com\/subject\/3220004\/","id":"3220004","publisher":"O'Reilly Media, Inc.","isbn10":"0596521995","isbn13":"9780596521998","title":"Hadoop: The Definitive Guide","url":"https:\/\/api.douban.com\/v2\/book\/3220004","alt_title":"","author_intro":"","summary":"Apache Hadoop is ideal for organizations with a growing need to store and process massive application datasets. Hadoop: The Definitive Guide is a comprehensive resource for using Hadoop to build reliable, scalable, distributed systems. Programmers will find details for analyzing large datasets with Hadoop, and administrators will learn how to set up and run Hadoop clusters. The book includes case studies that illustrate how Hadoop solves specific problems.\nOrganizations large and small are adopting Apache Hadoop to deal with huge application datasets. Hadoop: The Definitive Guide provides you with the key for unlocking the wealth this data holds. Hadoop is ideal for storing and processing massive amounts of data, but until now, information on this open-source project has been lacking -- especially with regard to best practices. This comprehensive resource demonstrates how to use Hadoop to build reliable, scalable, distributed systems. Programmers will find details for analyzing large datasets with Hadoop, and administrators will learn how to set up and run Hadoop clusters.\nWith case studies that illustrate how Hadoop solves specific problems, this book helps you:\n* Learn the Hadoop Distributed File System (HDFS), including ways to use its many APIs to transfer data\n* Write distributed computations with MapReduce, Hadoop's most vital component\n* Become familiar with Hadoop's data and IO building blocks for compression, data integrity, serialization, and persistence\n* Learn the common pitfalls and advanced features for writing real-world MapReduce programs\n* Design, build, and administer a dedicated Hadoop cluster\n* Use HBase, Hadoop's database for structured and semi-structured data\nAnd more. Hadoop: The Definitive Guide is still in progress, but you can get started on this technology with the Rough Cuts edition, which lets you read the book online or download it in PDF format as the manuscript evolves.","price":"44.99"},{"rating":{"max":10,"numRaters":257,"average":"7.2","min":0},"subtitle":"","author":["(美) Tom White"],"pubdate":"2010-5","tags":[{"count":396,"name":"hadoop","title":"hadoop"},{"count":216,"name":"分布式","title":"分布式"},{"count":126,"name":"云计算","title":"云计算"},{"count":86,"name":"mapreduce","title":"mapreduce"},{"count":77,"name":"Hadoop权威指南","title":"Hadoop权威指南"},{"count":64,"name":"计算机","title":"计算机"},{"count":50,"name":"大数据","title":"大数据"},{"count":41,"name":"O'Reilly","title":"O'Reilly"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s4356809.jpg","binding":"","translator":["周傲英","曾大聃"],"catalog":"","pages":"504","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s4356809.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s4356809.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s4356809.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4817792\/","id":"4817792","publisher":"清华大学出版社","isbn10":"7302224242","isbn13":"9787302224242","title":"Hadoop权威指南(中文版)","url":"https:\/\/api.douban.com\/v2\/book\/4817792","alt_title":"","author_intro":"","summary":"本书是您纵情享用数据之美的得力助手。作为处理海量数据集的理想工具，Apache Hadoop架构是MapReduce算法的一种开源应用，是Google(谷歌)开创其帝国的重要基石。本书内容丰富，展示了如何使用Hadoop构建可靠、可伸缩的分布式系统，程序员可从中探索如何分析海量数据集，管理员可以了解如何建立与运行Hadoop集群。.\n本书完全通过案例学习来展示如何用Hadoop解决特殊问题，它将帮助您：\n使用Hadoop分布式文件系统（HDFS）来存储海量数据集，通过MapReduce对这些数据集运行分布式计算..\n熟悉Hadoop的数据和I\/O构件，用于压缩、数据集成、序列化和持久处理\n洞悉编写MapReduce实际应用程序时常见陷阱和高级特性\n设计、构建和管理专用的Hadoop集群或在云上运行Hadoop\n使用Pig这种高级的查询语言来处理大规模数据\n利用HBase这个Hadoop数据库来处理结构化和半结构化数据\n学习Zookeeper，这是一个用于构建分布式系统的协作原语工具箱\n如果您拥有海量数据，无论是GB级还是PB级，Hadoop都是完美的选择。本书是这方面最全面的参考。","price":"79.00元"},{"rating":{"max":10,"numRaters":116,"average":"8.2","min":0},"subtitle":"","author":["Chuck Lam"],"pubdate":"2010-12-22","tags":[{"count":158,"name":"Hadoop","title":"Hadoop"},{"count":58,"name":"分布式","title":"分布式"},{"count":58,"name":"云计算","title":"云计算"},{"count":33,"name":"map-reduce","title":"map-reduce"},{"count":26,"name":"MapReduce","title":"MapReduce"},{"count":23,"name":"hadoop","title":"hadoop"},{"count":18,"name":"programming","title":"programming"},{"count":9,"name":"大数据","title":"大数据"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s8512763.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"325","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s8512763.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s8512763.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s8512763.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4049942\/","id":"4049942","publisher":"Manning Publications","isbn10":"1935182196","isbn13":"9781935182191","title":"Hadoop in Action","url":"https:\/\/api.douban.com\/v2\/book\/4049942","alt_title":"","author_intro":"","summary":"HIGHLIGHT  Hadoop in Action is an example-rich tutorial that shows developers how to  implement data-intensive distributed computing using Hadoop and the Map-  Reduce framework.  DESCRIPTION  Hadoop is an open source implementation of Google's MapReduce framework  for scalable, distributed data processing. Hadoop in Action is for programmers,  architects, and project managers who have to process large amounts of data  offline.  The book begins with several simple examples that illustrate the basic idea  behind Hadoop. Later chapters explain the core framework components and  demonstrate Hadoop in a variety of data analysis tasks. Throughout the book,  readers will learn best practices and design patterns, and how to write meaningful  programs in a MapReduce framework.  KEY POINTS Explains distributed computing, MapReduce, and the Hadoop framework Focuses on most-used features and rapid development solutions Numerous hands-on examples to illustrate abstract ideas Concise, developer-centric,  In Action  style Multiple case studies demonstrate real-world Hadoop uses Covers popular Hadoop extensions that ease development and extend  functionality","price":"USD 44.99"},{"rating":{"max":10,"numRaters":23,"average":"6.4","min":0},"subtitle":"用Hadoop创建数据分析应用","author":["[美] Russell Jurne"],"pubdate":"2014-7","tags":[{"count":22,"name":"数据挖掘","title":"数据挖掘"},{"count":12,"name":"Hadoop","title":"Hadoop"},{"count":8,"name":"计算机","title":"计算机"},{"count":4,"name":"数据分析","title":"数据分析"},{"count":4,"name":"敏捷","title":"敏捷"},{"count":4,"name":"大数据","title":"大数据"},{"count":2,"name":"编程","title":"编程"},{"count":2,"name":"Python","title":"Python"}],"origin_title":"Agile Data Science","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27328296.jpg","binding":"平装","translator":["冯文中","朱洪波"],"catalog":"第1 部分 起步 ............................................................... 1\n第1 章 理论 .................................................................. 3\n敏捷大数据 ............................................................................................................3\nBig Words 定义 ......................................................................................................4\n敏捷大数据团队 .....................................................................................................5\n认识机遇和问题 ..............................................................................................6\n敏捷大数据流程 ................................................................................................... 11\n代码检查和结对编程 ...........................................................................................12\n敏捷的场所：开发的效率 ....................................................................................13\n协作空间 .......................................................................................................14\n私人空间 .......................................................................................................14\n个人空间 .......................................................................................................14\n用大幅打印件明确表达想法 ................................................................................15\n第2 章 数据 ............................................................... 17\n电子邮件 ..............................................................................................................17\n处理原始数据 ......................................................................................................18\n原始的电子邮件 ............................................................................................18\n结构化与半结构化数据 .................................................................................18\nSQL ......................................................................................................................20\nNoSQL .................................................................................................................24\n序列化 ...........................................................................................................24\n从演变的模式中抽取和展示特征 ..................................................................25\n数据流水线 ...................................................................................................26\n数据透视 ..............................................................................................................27\n社交网络 .......................................................................................................28\n时间序列 .......................................................................................................30\n自然语言 .......................................................................................................31\n概率 ...............................................................................................................33\n小结 .....................................................................................................................35\n第3 章 敏捷开发工具 ................................................... 37\n可扩展性= 简洁...................................................................................................37\n敏捷大数据处理 ...................................................................................................38\n设置运行Python 的虚拟环境 ...............................................................................39\n使用Avro 对事件进行序列化 ..............................................................................40\n在Python 中使用Avro ..................................................................................40\n收集数据 ..............................................................................................................42\n使用Pig 处理数据................................................................................................44\n安装Pig .........................................................................................................45\n使用MongoDB 发布数据 ....................................................................................49\n安装MongoDB ..............................................................................................49\n安装MongoDB 的Java 驱动程序 .................................................................50\n安装mongo-hadoop .......................................................................................50\n用Pig 向MongoDB 推送数据 .......................................................................50\n使用ElasticSearch 搜索数据 ................................................................................52\n安装 ...............................................................................................................52\n使用Wonderdog 整合ElasticSearch 和Pig ...................................................53\n对工作流程的反思 ...............................................................................................55\n轻量级的Web 应用 ..............................................................................................56\nPython 和 Flask .............................................................................................56\n展示数据 ..............................................................................................................58\n安装Bootstrap ...............................................................................................58\n启用Bootstrap ...............................................................................................59\n使用d3.js 和nvd3.js 可视化数据 ..................................................................63\n小结 .....................................................................................................................64\n第4 章 在云端 ............................................................. 65\n引言 .....................................................................................................................65\nGitHub .................................................................................................................67\ndotCloud ...............................................................................................................67\ndotCloud Echo 服务 .......................................................................................68\nPython 工作者服务 ........................................................................................71\nAmazon Web Services ..........................................................................................71\nSimple Storage Service ..................................................................................71\nElastic MapReduce ........................................................................................72\nMongoDB 即服务 ..........................................................................................79\n辅助工具（Instrumentation） ................................................................................81\nGoogle Analytics ...........................................................................................81\nMortar Data ...................................................................................................82\n第2 部分 登上金字塔 ................................................... 85\n第5 章 收集和展示数据 ............................................... 89\n整合软件栈 ..........................................................................................................90\n收集并序列化收件箱 ...........................................................................................90\n处理和发布邮件数据 ...........................................................................................91\n在浏览器中显示邮件 ...........................................................................................93\n用Flask 和pymongo 处理邮件数据 ..............................................................94\n使用Jinja2 渲染HTML5 页面 ......................................................................94\n敏捷检查点 ..........................................................................................................98\n生成电子邮件清单 ...............................................................................................99\n用MongoDB 显示邮件 .................................................................................99\n对数据展示的分析 ...................................................................................... 101\n搜索邮件 ............................................................................................................ 106\n使用Pig，ElasticSearch 和Wonderdog 构建索引 ....................................... 106\n在网页中搜索邮件数据 ............................................................................... 107\n结论 ................................................................................................................... 108\n第6 章 使用图表可视化数据 ....................................... 111\n优秀的图表 ........................................................................................................ 112\n抽取实体：邮件地址 ......................................................................................... 112\n抽取邮件 ..................................................................................................... 112\n对时间进行可视化 ............................................................................................. 116\n结论 ................................................................................................................... 122\n第7 章 利用报表探索数据 .......................................... 123\n为数据添加联系 ................................................................................................. 126\n用TF-IDF 从邮件中提取关键字 ........................................................................ 133\n小结 ................................................................................................................... 138\n第8 章 预测 .............................................................. 141\n预测电子邮件的回复率 ...................................................................................... 142\n个性化 ................................................................................................................ 147\n小结 ................................................................................................................... 148\n第9 章 驱动行动 ........................................................ 149\n好邮件的属性 .................................................................................................... 150\n使用朴素贝叶斯方法进行更好的预测 ............................................................... 150\nP(Reply | From ∩ To) ........................................................................................ 150\nP(Reply | Token) ................................................................................................. 151\n实时预测 ............................................................................................................ 153\n记录事件日志 .................................................................................................... 157\n小结 ................................................................................................................... 157\n索引 ........................................................................... 159","pages":"184","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27328296.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27328296.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27328296.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25929433\/","id":"25929433","publisher":"电子工业出版社","isbn10":"7121236192","isbn13":"9787121236198","title":"敏捷数据科学","url":"https:\/\/api.douban.com\/v2\/book\/25929433","alt_title":"Agile Data Science","author_intro":"作者介绍：Russsel Jurney 在美国和墨西哥的赌场开始他的数据分析生涯。他开发了一个 Web 应用来分析老虎机的性能。在经历了创业、交互式媒体和新闻业以后，他到了硅谷，在 Ning 和LinkedIn 开始构建可扩展的数据分析应用。\n译者介绍：朱洪波 阿里巴巴数据挖掘专家，机器学习团队负责人，司职于解决商业客户对数据的深层需求。纸质书爱好者，相信理性与逻辑的力量。","summary":"《敏捷数据科学：用Hadoop创建数据分析应用》面向大数据挖掘，以敏捷视角呈现高效构建数据模型的全程实践和思路。在一组以一个真实电子邮箱数据挖掘为例的数据-价值金字塔进阶模式中，你将学到：一整套实用工具及其方法论，可快速实现在Hadoop 上构建数据分析应用；用Python、Apache Pig 及D3.js等轻量级工具创建用于探索数据的敏捷环境；一种可根据数据中信息快速切换，进行不同类型数据分析的迭代式开发方法。\n《敏捷数据科学：用Hadoop创建数据分析应用》适合所有与数据工作相关的从业者，同时也适合有志成为数据科学工作者的广大读者作为入门读物。","price":"49.00元"},{"rating":{"max":10,"numRaters":92,"average":"7.2","min":0},"subtitle":"","author":["[美] Tom White"],"pubdate":"2015-1","tags":[{"count":71,"name":"大数据","title":"大数据"},{"count":50,"name":"hadoop","title":"hadoop"},{"count":27,"name":"计算机","title":"计算机"},{"count":25,"name":"Hadoop","title":"Hadoop"},{"count":14,"name":"数据挖掘","title":"数据挖掘"},{"count":13,"name":"云计算，大数据，数据挖掘","title":"云计算，大数据，数据挖掘"},{"count":10,"name":"云计算","title":"云计算"},{"count":9,"name":"软件开发","title":"软件开发"}],"origin_title":"Hadoop: The Definitive Guide，3rd Edition","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28735604.jpg","binding":"平装","translator":["华东师范大学数据科学与工程学院"],"catalog":"\" 目录\n第1章  初识Hadoop 1\n1.1  数据！数据！ 1\n1.2  数据的存储与分析 3\n1.3  相较于其他系统的优势 4\n1.3.1  关系型数据库管理系统 5\n1.3.2  网格计算 7\n1.3.3  志愿计算 9\n1.4  Hadoop发展简史 10\n1.5  Apache Hadoop和Hadoop生态系统 14\n1.6  Hadoop的发行版本 15\n1.6.1  本书包含的内容 16\n1.6.2  兼容性 17\n第2章  关于MapReduce 19\n2.1  气象数据集 19\n2.2  使用Unix工具来分析数据 21\n2.3  使用Hadoop来分析数据 23\n2.3.1  map和reduce 23\n2.3.2  Java MapReduce 24\n2.4  横向扩展 33\n2.4.1  数据流 34\n2.4.2  combiner函数 37\n2.4.3  运行分布式的MapReduce作业 39\n2.5  Hadoop Streaming 40\n2.5.1  Ruby版本 40\n2.5.2  Python版本 43\n2.6  Hadoop Pipes 44\n第3章  Hadoop分布式文件系统 49\n3.1  HDFS的设计 49\n3.2  HDFS的概念 51\n3.2.1  数据块 51\n3.2.2  namenode和datanode 52\n3.2.3  联邦HDFS 53\n3.2.4  HDFS的高可用性 54\n3.3  命令行接口 56\n3.4  Hadoop文件系统 58\n3.5  Java接口 62\n3.5.1  从Hadoop URL读取数据 63\n3.5.2  通过FileSystem API读取数据 64\n3.5.3  写入数据 68\n3.5.4  目录 70\n3.5.5  查询文件系统 70\n3.5.6  删除数据 75\n3.6  数据流 75\n3.6.1  剖析文件读取 75\n3.6.2  剖析文件写入 78\n3.6.3  一致模型 81\n3.7  通过Flume和Sqoop导入数据 83\n3.8  通过distcp并行复制 84\n3.9  Hadoop存档 86\n3.9.1  使用Hadoop存档工具 86\n3.9.2  不足 88\n第4章  Hadoop的I\/O操作 89\n4.1  数据完整性 89\n4.1.1  HDFS的数据完整性 89\n4.1.2  LocalFileSystem 91\n4.1.3  ChecksumFileSystem 91\n4.2  压缩 92\n4.2.1  codec 93\n4.2.2  压缩和输入分片 98\n4.2.3  在MapReduce中使用压缩 99\n4.3  序列化 102\n4.3.1  Writable接口 103\n4.3.2  Writable类 105\n4.3.3  实现定制的Writable集合 114\n4.3  序列化框架 118\n4.4  Avro 121\n4.4.1  Avro数据类型和模式 122\n4.4.2  内存中的序列化和反序列化 126\n4.4.3  Avro数据文件 129\n4.4.4  互操作性 130\n4.4.5  模式的解析 133\n4.4.6  排列顺序 135\n4.4.7  关于Avro MapReduce 137\n4.4.8  使用Avro MapReduce进行排序 141\n4.4.9  其他语言的Avro MapReduce 143\n4.5  基于文件的数据结构 143\n4.5.1  关于SequenceFile 143\n4.5.2  关于MapFile 151\n第5章  MapReduce应用开发 157\n5.1  用于配置的API 157\n5.1.1  资源合并 159\n5.1.2  可变的扩展 160\n5.2  配置开发环境 160\n5.2.1  管理配置 162\n5.2.2  辅助类GenericOptionsParser，Tool和ToolRunner 165\n5.3  用MRUnit来写单元测试 168\n5.3.1  关于Mapper 168\n5.3.2  关于Reducer 170\n5.4  本地运行测试数据 171\n5.4.1  在本地作业运行器上运行作业 171\n5.4.2  测试驱动程序 175\n5.5  在集群上运行 176\n5.5.1  打包作业 177\n5.5.2  启动作业 179\n5.5.3  MapReduce的Web界面 181\n5.5.4  获取结果 184\n5.5.5  作业调试 185\n5.5.6  Hadoop日志 190\n5.5.7  远程调试 192\n5.6  作业调优 193\n5.7  MapReduce的工作流 196\n5.7.1  将问题分解成MapReduce作业 197\n5.7.2  关于JobControl 198\n5.7.3  关于Apache Oozie 199\n第6章  MapReduce的工作机制 205\n6.1  剖析MapReduce作业运行机制 205\n6.1.1  经典的MapReduce (MapReduce 1) 206\n6.1.2  YARN (MapReduce 2) 213\n6.2  失败 219\n6.2.1  经典MapReduce中的失败 219\n6.2.2  YARN中的失败 222\n6.3  作业的调度 224\n6.3.1  公平调度器 225\n6.3.2  容量调度器 225\n6.4  shuffle和排序 226\n6.4.1  map端 226\n6.4.2  reduce端 228\n6.4.3  配置调优 230\n6.5  任务的执行 232\n6.5.1  任务执行环境 232\n6.5.2  推测执行 233\n6.5.3  关于OutputCommitters 235\n6.5.4  任务JVM重用 237\n6.5.5  跳过坏记录 238\n第7章  MapReduce的类型与格式 241\n7.1  MapReduce的类型 241\n7.1.1  默认的MapReduce作业 245\n7.1.2  默认的Streaming作业 249\n7.2  输入格式 252\n7.2.1  输入分片与记录 252\n7.2.2  文本输入 264\n7.2.3  二进制输入 268\n7.2.4  多个输入 269\n7.2.5  数据库输入(和输出) 270\n7.3  输出格式 271\n7.3.1  文本输出 271\n7.3.2  二进制输出 272\n7.3.3  多个输出 272\n7.3.4  延迟输出 277\n7.3.5  数据库输出 277\n第8章  MapReduce的特性 279\n8.1  计数器 279\n8.1.1  内置计数器 279\n8.1.2  用户定义的Java计数器 284\n8.1.3  用户定义的Streaming计数器 289\n8.2  排序 289\n8.2.1  准备 290\n8.2.2  部分排序 291\n8.2.3  全排序 295\n8.2.4  辅助排序 299\n8.3  连接 305\n8.3.1  map端连接 307\n8.3.2  reduce端连接 307\n8.4  边数据分布 311\n8.4.1  利用JobConf来配置作业 311\n8.4.2  分布式缓存 311\n8.5  MapReduce库类 318\n第9章  构建Hadoop集群 321\n9.1  集群规范 321\n9.2  集群的构建和安装 325\n9.2.1  安装Java 326\n9.2.2  创建Hadoop用户 326\n9.2.3  安装Hadoop 326\n9.2.4  测试安装 327\n9.3  SSH配置 327\n9.4  Hadoop配置 328\n9.4.1  配置管理 329\n9.4.2  环境设置 332\n9.4.3  Hadoop守护进程的关键属性 336\n9.4.4  Hadoop守护进程的地址和端口 341\n9.4.5  Hadoop的其他属性 343\n9.4.6  创建用户帐号 346\n9.5  YARN配置 346\n9.5.1  YARN守护进程的重要属性 347\n9.5.2  YARN守护进程的地址和端口 350\n9.6  安全性 352\n9.6.1  Kerberos和Hadoop 353\n9.6.2  委托令牌 355\n9.6.3  其他安全性改进 356\n9.7  利用基准评测程序测试Hadoop集群 358\n9.7.1  Hadoop基准评测程序 358\n9.7.2  用户作业 361\n9.8  云端的Hadoop 361\n第10章  管理Hadoop 367\n10.1  HDFS 367\n10.1.1  永久性数据结构 367\n10.1.2  安全模式 373\n10.1.3  日志审计 375\n10.1.4  工具 375\n10.2  监控 380\n10.2.1  日志 381\n10.2.2  度量 382\n10.2.3  Java管理扩展(JMX) 385\n10.3  维护 387\n10.3.1  日常管理过程 387\n10.3.2  委任和解除节点 389\n10.3.3  升级 392\n第11章  关于Pig 397\n11.1  安装与运行Pig 398\n11.1.1  执行类型 399\n11.1.2  运行Pig程序 400\n11.1.3  Grunt 401\n11.1.4  Pig Latin编辑器 401\n11.2  示例 402\n11.3  与数据库进行比较 405\n11.4  Pig Latin 406\n11.4.1  结构 407\n11.4.2  语句 408\n11.4.3  表达式 413\n11.4.4  类型 414\n11.4.5  模式 415\n11.4.6  函数 420\n11.4.7  宏 422\n11.5  用户自定义函数 423\n11.5.1  过滤UDF 423\n11.5.2  计算UDF 427\n11.5.3  加载UDF 429\n11.6  数据处理操作 432\n11.6.1  数据的加载和存储 432\n11.6.2  数据的过滤 433\n11.6.3  数据的分组与连接 436\n11.6.4  数据的排序 441\n11.6.5  数据的组合和切分 442\n11.7  Pig实战 443\n11.7.1  并行处理 443\n11.7.2  参数代换 444\n第12章  关于Hive 447\n12.1  安装Hive 448\n12.2  示例 450\n12.3  运行Hive 451\n12.3.1  配置Hive 452\n12.3.2  Hive服务 454\n12.3.3  Metastore 456\n12.4  Hive与传统数据库相比 458\n12.4.1  读时模式vs.写时模式 458\n12.4.2  更新、事务和索引 459\n12.5  HiveQL 460\n12.5.1  数据类型 461\n12.5.2  操作与函数 463\n12.6  表 464\n12.6.1  托管表和外部表 465\n12.6.2  分区和桶 466\n12.6.3  存储格式 471\n12.6.4  导入数据 477\n12.6.5  表的修改 479\n12.6.6  表的丢弃 480\n12.7  查询数据 480\n12.7.1  排序和聚集 480\n12.7.2  MapReduce脚本 481\n12.7.3  连接 482\n12.7.4  子查询 486\n12.7.5  视图 486\n12.8  用户定义函数 488\n12.8.1  写UDF 489\n12.8.2  写UDAF 491\n第13章  关于HBase 497\n13.1  HBase基础 497\n13.2  概念 498\n13.3.1  数据模型的“旋风之旅” 498\n13.3.2  实现 500\n13.3  安装 503\n13.4  客户端 506\n13.4.1  Java 506\n13.4.2  Avro、REST和Thrift 510\n13.5  示例 511\n13.5.1  模式 511\n13.5.2  加载数据 512\n13.5.3  Web查询 516\n13.6  HBase和RDBMS的比较 519\n13.6.1  成功的服务 520\n13.6.2  HBase 521\n13.6.3  实例：HBase在Streamy.com的使用 522\n13.7  Praxis 524\n13.7.1  版本 524\n13.7.2  HDFS 525\n13.7.3  用户界面 526\n13.7.4  度量 526\n13.7.5  模式的设计 526\n13.7.6  计数器 527\n13.7.7  批量加载 528\n第14章  关于ZooKeeper 529\n14.1  安装和运行ZooKeeper 530\n14.2  示例 532\n14.2.1  ZooKeeper中的组成员关系 533\n14.2.2  创建组 534\n14.2.3  加入组 536\n14.2.4  列出组成员 537\n14.2.5  删除组 539\n14.3  ZooKeeper服务 540\n14.3.1  数据模型 540\n14.3.2  操作 543\n14.3.3  实现 548\n14.3.4  一致性 549\n14.3.5  会话 552\n14.3.6  状态 554\n14.4  使用ZooKeeper来构建应用 555\n14.4.1  配置服务 555\n14.4.2  可复原的ZooKeeper应用 559\n14.4.3  锁服务 563\n14.4.4  更多分布式数据结构和协议 565\n14.5  生产环境中的ZooKeeper 567\n14.5.1  可恢复性和性能 567\n14.5.2  配置 568\n第15章  关于Sqoop 571\n15.1  获取Sqoop 571\n15.2  Sqoop连接器 573\n15.3  一个导入的例子 573\n15.4  生成代码 577\n15.5  深入了解数据库导入 578\n15.5.1  导入控制 580\n15.5.2  导入和一致性 581\n15.5.3  直接模式导入 581\n15.6  使用导入的数据 581\n15.7  导入大对象 585\n15.8  执行导出 587\n15.9  深入了解导出功能 589\n15.9.1  导出与事务 590\n15.9.2  导出和SequenceFile 591\n第16章  实例学习 593\n16.1  Hadoop 在Last.fm的应用 593\n16.1.1  Last.fm：社会音乐史上的革命 593\n16.1.2  Hadoop在Last.fm中的应用 593\n16.1.3  用Hadoop制作图表 594\n16.1.4  Track Statistics程序 595\n16.1.5  总结 602\n16.2  Hadoop和Hive在Facebook的应用 603\n16.2.1  Hadoop在Facebook的使用 603\n16.2.2  虚构的使用样例 606\n16.2.3  Hive 609\n16.2.4  存在的问题与未来工作计划 613\n16.3  Nutch搜索引擎 615\n16.3.1  背景介绍 615\n16.3.2  数据结构 616\n16.3.3  Nutch系统利用Hadoop进行数据处理的精选实例 619\n16.3.4  总结 630\n16.4  Rackspace的日志处理 631\n16.4.1  要求\/问题 631\n16.4.2  简史 632\n16.4.3  选择Hadoop 632\n16.4.4  收集和存储 632\n16.4.5  对日志的MapReduce处理 634\n16.5  关于Cascading 640\n16.5.1  字段、元组和管道 641\n16.5.2  操作 644\n16.5.3  Tap、Scheme和Flow 645\n16.5.4  Cascading实战 646\n16.5.5  灵活性 650\n16.5.6  Hadoop和Cascading在ShareThis的应用 650\n16.5.7  总结 655\n16.6  Apache Hadoop上万亿数量级排序 655\n16.7  用Pig和Wukong探索10亿数量级边的网络图 659\n16.7.1  社区判断 661\n16.7.2  每个人都在和我说话：Twitter回复关系图 661\n16.7.3  对称链接 664\n16.7.4  社区提取 666\n附录A  安装Apache Hadoop 669\n附录B  关于CDH 675\n附录C  准备NCDC气象数据 677\n\"","pages":"716","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28735604.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28735604.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28735604.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26206050\/","id":"26206050","publisher":"清华大学出版社","isbn10":"7302370850","isbn13":"9787302370857","title":"Hadoop权威指南(第3版)","url":"https:\/\/api.douban.com\/v2\/book\/26206050","alt_title":"Hadoop: The Definitive Guide，3rd Edition","author_intro":"Tom White，数学王子&Hadoop专家。身为Apache Hadoop提交者八年之久，Apache软件基金会成员之一。全球知名云计算公司Cloudera的软件工程师。Tom拥有英国剑桥大学数学学士学位和利兹大学科学哲学硕士学位。","summary":"准备好释放数据的强大潜能了吗？借助于这本《Hadoop权威指南》，你将学习如何使用ApacheHadoop构建和维护稳定性高、伸缩性强的分布式系统。本书是为程序员写的，可帮助他们分析任何大小的数据集。本书同时也是为管理员写的，帮助他们了解如何设置和运行Hadoop集群。\n《Hadoop权威指南（第3版 修订版）》通过丰富的案例学习来解释Hadoop的幕后机理，阐述了Hadoop如何解决现实生活中的具体问题。第3版覆盖Hadoop的最新动态，包括新增的MapReduceAPI，以及MapReduce2及其灵活性更强的执行模型（YARN）。","price":"99.00元"},{"rating":{"max":10,"numRaters":13,"average":"5.8","min":0},"subtitle":"Hadoop分布式文件系统深度实践","author":["文艾","王磊"],"pubdate":"2012-5","tags":[{"count":25,"name":"hadoop","title":"hadoop"},{"count":19,"name":"HDFS","title":"HDFS"},{"count":14,"name":"分布式","title":"分布式"},{"count":6,"name":"存储","title":"存储"},{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"数据库","title":"数据库"},{"count":1,"name":"放下","title":"放下"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s9112216.jpg","binding":"平装","translator":[],"catalog":"目录\n第1章 HDFS HA及解决方案 1\n1.1 HDFS系统架构 2\n1.2 HA定义 3\n1.3 HDFS HA原因分析及应对措施 4\n1.3.1 可靠性 4\n1.3.2 可维护性 5\n1.4 现有HDFS HA解决方案 5\n1.4.1 Hadoop的元数据备份方案 6\n1.4.2 Hadoop的SecondaryNameNode方案 7\n1.4.3 Hadoop的Checkpoint ode方案 7\n1.4.4 Hadoop的BackupNode方案 8\n1.4.5 DRDB方案 9\n1.4.6 FaceBook的AvatarNode方案 10\n1.5 方案优缺点比较 10\n第2章 HDFS元数据解析 13\n2.1 概述 14\n2.2 内存元数据结构 14\n2.2.1 INode 15\n2.2.2 Block 16\n2.2.3 BlockInfo和DatanodeDescriptor 17\n2.2.4 小结 17\n2.2.5 代码分析——元数据结构 18\n2.3 磁盘元数据文件 24\n2.4 Format情景分析 27\n2.5 元数据应用场景分析 45\n第3章 Hadoop的元数据备份方案 47\n3.1 运行机制分析 48\n3.1.1 NameNode启动加载元数据情景分析 50\n3.1.2 元数据更新及日志写入情景分析 64\n3.1.3 Checkpoint过程情景分析 73\n3.1.4 元数据可靠性机制 109\n3.1.5 元数据一致性机制 110\n3.2 使用说明 110\n第4章 Hadoop的Backup Node方案 113\n4.1 Backup Node概述 114\n4.1.1 系统架构 115\n4.1.2 使用原则 115\n4.1.3 优缺点 116\n4.2 运行机制分析 116\n4.2.1 启动流程 117\n4.2.2 元数据操作情景分析 141\n4.2.3 日志池（journal spool）机制 151\n4.2.4 故障切换机制 156\n4.3 实验方案说明 158\n4.4 构建实验环境 158\n4.4.1 网络拓扑 159\n4.4.2 系统安装及配置 160\n4.4.3 安装JDK 170\n4.4.4 虚拟机集群架设 171\n4.4.5 NameNode安装及配置 173\n4.4.6 Backup Node安装及配置 173\n4.4.7 Data Node安装及配置 174\n4.4.8 Clients安装及配置 175\n4.5 异常解决方案 175\n4.5.1 异常情况分析 175\n4.5.2 NameNode配置 175\n4.5.3 Backup Node配置 182\n4.5.4 Data Node配置 185\n4.5.5 NameNode宕机切换实验 189\n4.5.6 NameNode宕机读写测试 196\n第5章 AvatarNode运行机制 205\n5.1 方案说明 206\n5.1.1 系统架构 206\n5.1.2 思路分析 208\n5.1.3 性能数据 209\n5.2 元数据分析 209\n5.2.1 类FSNamesystem 210\n5.2.2 类FSDirectory 210\n5.2.3 AvatarNode的磁盘元数据文件 211\n5.3 AvatarNode Primary启动过程 211\n5.4 AvatarNode Standby启动过程 217\n5.4.1 AvatarNode的构造方法 217\n5.4.2 Standby线程的run()方法 218\n5.4.3 Ingest线程的run()方法 220\n5.4.4 Ingest线程的ingestFSEdits ()方法 220\n5.4.5 Standby线程的doCheckpoint()方法 221\n5.5 用户操作情景分析 223\n5.5.1 创建目录情景分析 223\n5.5.2 创建文件情景分析 231\n5.6 AvatarNode Standby故障切换过程 240\n5.7 元数据一致性保证机制 242\n5.7.1 元数据目录树信息 242\n5.7.2 Data Node与Block数据块映射信息 243\n5.8 Block更新同步问题 246\n5.8.1 问题描述 246\n5.8.2 结论 246\n5.8.3 源码分析 246\n第6章 AvatarNode使用 253\n6.1 方案说明 254\n6.1.1 网络拓扑 254\n6.1.2 操作系统安装及配置 255\n6.2 使用Avatar打补丁版本 255\n6.2.1 Hadoop源码联机Build 256\n6.2.2 Hadoop源码本地Build 262\n6.2.3 NFS服务器构建 264\n6.2.4 Avatar分发与部署 267\n6.2.5 Primary（namenode0）节点配置 269\n6.2.7 Data Node节点配置 276\n6.2.8 Client节点配置 278\n6.2.9 创建目录 279\n6.2.10 挂载NFS 280\n6.2.11 启动Ucarp 280\n6.2.12 格式化 281\n6.2.13 系统启动 281\n6.2.14 检查 282\n6.2.15 NameNode失效切换写文件实验 283\n6.2.16 NameNode失效切换读文件实验 291\n6.3 Avatar FaceBook版本的使用 294\n6.3.1 Hadoop FaceBook版本安装 294\n6.3.2 节点配置 295\n6.3.3 启动HDFS 300\n6.3.4 NameNode失效切换 302\n第7章 AvatarNode异常解决方案 305\n7.1 测试环境 306\n7.2 Primary失效 306\n7.2.1 解决方案 306\n7.2.2 写操作实验步骤 307\n7.2.3 改进写操作机制 313\n7.2.4 读操作实验步骤 313\n7.2.5 小结 317\n7.3 Standby失效 317\n7.4 NFS失效（数据未损坏） 317\n7.4.1 解决方案 317\n7.4.2 写操作实验步骤 318\n7.4.3 读操作实验步骤 320\n7.4.4 小结 322\n7.5 NFS失效（数据已损坏） 323\n7.5.1 解决方案 323\n7.5.2 写操作实验步骤 324\n7.5.3 读操作实验步骤 327\n7.5.4 小结 330\n7.6 Primary先失效，NFS后失效（数据未损坏） 331\n7.6.1 解决方案 331\n7.6.2 写操作实验步骤 331\n7.6.3 读操作实验步骤 333\n7.6.4 小结 334\n7.7 Primary先失效（数据未损坏），NFS后失效（数据损坏） 335\n7.7.1 解决方案 335\n7.7.2 写操作实验步骤 335\n7.7.3 读操作实验步骤 338\n7.7.4 小结 339\n7.8 NFS先失效（数据未损坏），Primary后失效 340\n7.8.1 解决方案 340\n7.8.2 写操作实验步骤 340\n7.8.3 读操作实验步骤 342\n7.8.4 小结 343\n7.9 NFS先失效（数据损坏），Primary后失效（数据损坏） 344\n7.9.1 解决方案 344\n7.9.2 写操作实验步骤 344\n7.9.3 读操作实验步骤 346\n7.9.4 小结 348\n7.10 实验结论 348\n第8章 Cloudera HA NameNode使用 349\n8.1 HA NameNode说明 350\n8.2 CDH4B1版本HDFS集群配置 351\n8.2.1 虚拟机安装 351\n8.2.2 nn1配置 351\n8.2.3 dn1~dn3配置 355\n8.2.4 HDFS集群构建 358\n8.3 HA NameNode配置 361\n8.3.1 nn1配置 361\n8.3.2 其他节点配置 365\n8.4 HA NameNode使用 367\n8.4.1 启动HA HDFS集群 367\n8.4.2 第1次failover 368\n8.4.3 模拟写操作 368\n8.4.4 模拟Active Name Node失效，第2次failover 369\n8.3.5 模拟新的Standby NameNode加入 370\n8.5 小结 371","pages":"371","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s9112216.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s9112216.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s9112216.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10742139\/","id":"10742139","publisher":"清华大学出版社","isbn10":"7302282587","isbn13":"9787302282587","title":"高可用性的HDFS","url":"https:\/\/api.douban.com\/v2\/book\/10742139","alt_title":"","author_intro":"","summary":"《高可用性的HDFS:Hadoop分布式文件系统深度实践》专注于Hadoop分布式文件系统（HDFS）的主流HA解决方案，内容包括：HDFS元数据解析、Hadoop元数据备份方案、Hadoop Backup Node方案、AvatarNode解决方案以及最新的HA解决方案Cloudrea HA Name Node等。其中有关Backup Node方案及AvatarNode方案的内容是该书重点，尤其是对AvatarNode方案从运行机制到异常处理方案的步骤进行了详尽介绍，同时还总结了各种异常情况下AvatarNode的各种处理方案。\n《高可用性的HDFS:Hadoop分布式文件系统深度实践》从代码入手并结合情景分析、案例解说对HDFS的元数据以及主流的HDFS HA解决方案的运行机制进行了深入剖析，力求使读者在解决问题时做到心中有数，不仅知其然还知其所以然。\n《高可用性的HDFS:Hadoop分布式文件系统深度实践》光盘包含本书部分操作的视频教程以及所有源代码、脚本等开发文件。\n《高可用性的HDFS:Hadoop分布式文件系统深度实践》读者主要为云计算相关领域的研发人员、云计算系统管理维护人员，也适合作为高校研究生和高年级本科生的专业课辅助教材。","price":"59.00元"},{"rating":{"max":10,"numRaters":12,"average":"6.2","min":0},"subtitle":"Analytics for Enterprise Class Hadoop and Streaming Data","author":["IBM, Paul Zikopoulos","Chris Eaton","Paul Zikopoulos"],"pubdate":"2011-10-19","tags":[{"count":12,"name":"数据挖掘","title":"数据挖掘"},{"count":8,"name":"IBM","title":"IBM"},{"count":8,"name":"BigData","title":"BigData"},{"count":5,"name":"大数据","title":"大数据"},{"count":5,"name":"hadoop","title":"hadoop"},{"count":4,"name":"data","title":"data"},{"count":4,"name":"Big_Data","title":"Big_Data"},{"count":3,"name":"big","title":"big"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s7057772.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"176","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s7057772.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s7057772.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s7057772.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10462720\/","id":"10462720","publisher":"McGraw-Hill Osborne Media","isbn10":"0071790535","isbn13":"9780071790536","title":"Understanding Big Data","url":"https:\/\/api.douban.com\/v2\/book\/10462720","alt_title":"","author_intro":"","summary":"Big Data represents a new era in data exploration and utilization, and IBM is uniquely positioned to help clients navigate this transformation. This book reveals how IBM is leveraging open source Big Data technology, infused with IBM technologies, to deliver a robust, secure, highly available, enterprise-class Big Data platform. The three defining characteristics of Big Data--volume, variety, and velocity--are discussed. You'll get a primer on Hadoop and how IBM is hardening it for the enterprise, and learn when to leverage IBM InfoSphere BigInsights (Big Data at rest) and IBM InfoSphere Streams (Big Data in motion) technologies. Industry use cases are also included in this practical guide. Learn how IBM hardens Hadoop for enterprise-class scalability and reliability Gain insight into IBM's unique in-motion and at-rest Big Data analytics platform Learn tips and tricks for Big Data use cases and solutions Get a quick Hadoop primer","price":"USD 20.00"},{"rating":{"max":10,"numRaters":96,"average":"6.7","min":0},"subtitle":"","author":["陆嘉恒"],"pubdate":"2012-11","tags":[{"count":77,"name":"hadoop","title":"hadoop"},{"count":56,"name":"大数据","title":"大数据"},{"count":26,"name":"Hadoop","title":"Hadoop"},{"count":17,"name":"计算机","title":"计算机"},{"count":12,"name":"编程","title":"编程"},{"count":10,"name":"Java","title":"Java"},{"count":9,"name":"hadoop实战","title":"hadoop实战"},{"count":5,"name":"分布式","title":"分布式"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24321021.jpg","binding":"","translator":[],"catalog":"目录\n前言\n第1章　Hadoop简介\/1\n1.1　什么是Hadoop\/2\n1.1.1　Hadoop概述\/2\n1.1.2　Hadoop的历史\/2\n1.1.3　Hadoop的功能与作用\/2\n1.1.4　Hadoop的优势\/3\n1.1.5　Hadoop应用现状和发展趋势\/3\n1.2　Hadoop项目及其结构\/3\n1.3　Hadoop体系结构\/6\n1.4　Hadoop与分布式开发\/7\n1.5　Hadoop计算模型—MapReduce\/10\n1.6　Hadoop数据管理\/10\n1.6.1　HDFS的数据管理\/10\n1.6.2　HBase的数据管理\/12\n1.6.3　Hive的数据管理\/13\n1.7　Hadoop集群安全策略\/15\n1.8　本章小结\/17\n第2章　Hadoop的安装与配置\/19\n2.1　在Linux上安装与配置Hadoop\/20\n2.1.1　安装JDK 1.6\/20\n2.1.2　配置SSH免密码登录\/21\n2.1.3　安装并运行Hadoop\/22\n2.2　在Mac OSX上安装与配置Hadoop\/24\n2.2.1　安装Homebrew\/24\n2.2.2　使用Homebrew安装Hadoop\/25\n2.2.3　配置SSH和使用Hadoop\/25\n2.3　在Windows上安装与配置Hadoop\/25\n2.3.1　安装JDK 1.6或更高版本\/25\n2.3.2　安装Cygwin\/25\n2.3.3　配置环境变量\/26\n2.3.4　安装sshd服务\/26\n2.3.5　启动sshd服务\/26\n2.3.6　配置SSH免密码登录\/26\n2.3.7　安装并运行Hadoop\/26\n2.4　安装和配置Hadoop集群\/27\n2.4.1　网络拓扑\/27\n2.4.2　定义集群拓扑\/27\n2.4.3　建立和安装Cluster \/28\n2.5　日志分析及几个小技巧\/34\n2.6　本章小结\/35\n第3章　MapReduce计算模型\/36\n3.1　为什么要用MapReduce\/37\n3.2　MapReduce计算模型\/38\n3.2.1　MapReduce Job\/38\n3.2.2　Hadoop中的Hello World程序\/38\n3.2.3　MapReduce的数据流和控制流\/46\n3.3　MapReduce任务的优化\/47\n3.4　Hadoop流\/49\n3.4.1　Hadoop流的工作原理\/50\n3.4.2　Hadoop流的命令\/51\n3.4.3　两个例子\/52\n3.5　Hadoop Pipes\/54\n3.6　本章小结\/56\n第4章　开发MapReduce应用程序\/57\n4.1　系统参数的配置\/58\n4.2　配置开发环境\/60\n4.3　编写MapReduce程序\/60\n4.3.1　Map处理\/60\n4.3.2　Reduce处理\/61\n4.4　本地测试\/62\n4.5　运行MapReduce程序\/62\n4.5.1　打包\/64\n4.5.2　在本地模式下运行\/64\n4.5.3　在集群上运行\/64\n4.6　网络用户界面\/65\n4.6.1　JobTracker页面\/65\n4.6.2　工作页面\/65\n4.6.3　返回结果\/66\n4.6.4　任务页面\/67\n4.6.5　任务细节页面\/67\n4.7　性能调优\/68\n4.7.1　输入采用大文件\/68\n4.7.2　压缩文件\/68\n4.7.3　过滤数据\/69\n4.7.4　修改作业属性\/71\n4.8　MapReduce工作流\/72\n4.8.1　复杂的Map和Reduce函数\/72\n4.8.2　MapReduce Job中全局共享数据\/74\n4.8.3　链接MapReduce Job\/75\n4.9　本章小结\/77\n第5章　MapReduce应用案例\/79\n5.1　单词计数\/80\n5.1.1　实例描述\/80\n5.1.2　设计思路\/80\n5.1.3　程序代码\/81\n5.1.4　代码解读\/82\n5.1.5　程序执行\/83\n5.1.6　代码结果\/83\n5.1.7　代码数据流\/84\n5.2　数据去重\/85\n5.2.1　实例描述\/85\n5.2.2　设计思路\/86\n5.2.3　程序代码\/86\n5.3　排序\/87\n5.3.1　实例描述\/87\n5.3.2　设计思路\/88\n5.3.3　程序代码\/89\n5.4　单表关联\/91\n5.4.1　实例描述\/91\n5.4.2　设计思路\/92\n5.4.3　程序代码\/92\n5.5　多表关联\/95\n5.5.1　实例描述\/95\n5.5.2　设计思路\/96\n5.5.3　程序代码\/96\n5.6　本章小结\/98\n第6章　MapReduce工作机制\/99\n6.1　MapReduce作业的执行流程\/100\n6.1.1　MapReduce任务执行总流程\/100\n6.1.2　提交作业\/101\n6.1.3　初始化作业\/103\n6.1.4　分配任务\/104\n6.1.5　执行任务\/106\n6.1.6　更新任务执行进度和状态\/107\n6.1.7　完成作业\/108\n6.2　错误处理机制 \/108\n6.2.1　硬件故障\/109\n6.2.2　任务失败\/109\n6.3　作业调度机制\/110\n6.4　Shuffle和排序\/111\n6.4.1　Map端\/111\n6.4.2　Reduce端\/113\n6.4.3　shuffle过程的优化\/114\n6.5　任务执行\/114\n6.5.1　推测式执行\/114\n6.5.2　任务JVM重用\/115\n6.5.3　跳过坏记录\/115\n6.5.4　任务执行环境\/116\n6.6　本章小结\/117\n第7章　Hadoop I\/O操作\/118\n7.1　I\/O操作中的数据检查\/119\n7.2　数据的压缩 \/126\n7.2.1　Hadoop对压缩工具的选择\/126\n7.2.2　压缩分割和输入分割\/127\n7.2.3　在MapReduce程序中使用压缩\/127\n7.3　数据的I\/O中序列化操作\/128\n7.3.1　Writable类\/128\n7.3.2　实现自己的Hadoop数据类型\/137\n7.4　针对Mapreduce的文件类\/139\n7.4.1　SequenceFile类\/139\n7.4.2　MapFile类\/144\n7.4.3　ArrayFile、SetFile和BloomMapFile\/146\n7.5　本章小结\/148\n第8章　下一代MapReduce：YARN\/149\n8.1　MapReduce V2设计需求\/150\n8.2　MapReduce V2主要思想和架构\/151\n8.3　MapReduce V2设计细节\/153\n8.4　MapReduce V2优势\/156\n8.5　本章小结\/156\n第9章　HDFS详解\/157\n9.1　Hadoop的文件系统\/158\n9.2　HDFS简介\/160\n9.3　HDFS体系结构\/161\n9.3.1　HDFS的相关概念\/161\n9.3.2　HDFS的体系结构\/162\n9.4　HDFS的基本操作\/164\n9.4.1　HDFS的命令行操作\/164\n9.4.2　HDFS的Web界面\/165\n9.5　HDFS常用Java API详解\/166\n9.5.1　使用Hadoop URL读取数据\/166\n9.5.2　使用FileSystem API读取数据\/167\n9.5.3　创建目录\/169\n9.5.4　写数据\/169\n9.5.5　删除数据\/171\n9.5.6　文件系统查询\/171\n9.6　HDFS中的读写数据流\/175\n9.6.1　文件的读取\/175\n9.6.2　文件的写入\/176\n9.6.3　一致性模型\/178\n9.7　HDFS命令详解\/179\n9.7.1　通过distcp进行并行复制\/179\n9.7.2　HDFS的平衡\/180\n9.7.3　使用Hadoop归档文件\/180\n9.7.4　其他命令\/183\n9.8　WebHDFS\/186\n9.8.1　WebHDFS的配置\/186\n9.8.2　WebHDFS命令\/186\n9.9　本章小结\/190\n第10章　Hadoop的管理\/191\n10.1　HDFS文件结构\/192\n10.2　Hadoop的状态监视和管理工具\/196\n10.2.1　审计日志\/196\n10.2.2　监控日志\/196\n10.2.3　Metrics\/197\n10.2.4　Java管理扩展 \/199\n10.2.5　Ganglia\/200\n10.2.6　Hadoop管理命令\/202\n10.3　Hadoop集群的维护\/206\n10.3.1　安全模式\/206\n10.3.2　Hadoop的备份\/207\n10.3.3　Hadoop的节点管理\/208\n10.3.4　系统升级\/210\n10.4　本章小结\/212\n第11章　Hive详解\/213\n11.1　Hive简介\/214\n11.1.1　Hive的数据存储\/214\n11.1.2　Hive的元数据存储\/216\n11.2　Hive的基本操作\/216\n11.2.1　在集群上安装Hive\/216\n11.2.2　配置MySQL存储Hive元数据\/218\n11.2.3　配置Hive\/220\n11.3　Hive QL详解\/221\n11.3.1　数据定义（DDL）操作\/221\n11.3.2　数据操作（DML）\/231\n11.3.3　SQL操作\/233\n11.3.4　Hive QL使用实例\/235\n11.4　Hive网络（Web UI）接口\/237\n11.4.1　Hive网络接口配置\/237\n11.4.2　Hive网络接口操作实例\/238\n11.5　Hive的JDBC接口\/\/241\n11.5.1　Eclipse环境配置\/241\n11.5.2　程序实例\/241\n11.6　Hive的优化\/244\n11.7　本章小结\/246\n第12章　HBase详解\/247\n12.1　HBase简介\/248\n12.2　HBase的基本操作\/249\n12.2.1　HBase的安装\/249\n12.2.2　运行HBase \/253\n12.2.3　HBase Shell\/255\n12.2.4　HBase配置\/258\n12.3　HBase体系结构\/260\n12.3.1　HRegion\/260\n12.3.2　HRegion服务器\/261\n12.3.3　HBase Master服务器\/262\n12.3.4　ROOT表和META表\/262\n12.3.5　ZooKeeper\/263\n12.4　HBase数据模型\/263\n12.4.1　数据模型\/263\n12.4.2　概念视图\/264\n12.4.3　物理视图\/264\n12.5　HBase与RDBMS\/265\n12.6　HBase与HDFS\/266\n12.7　HBase客户端\/266\n12.8　Java API \/267\n12.9　HBase编程 \/273\n12.9.1　使用Eclipse开发HBase应用程序\/273\n12.9.2　HBase编程\/275\n12.9.3　HBase与MapReduce\/278\n12.10　模式设计\/280\n12.10.1　模式设计应遵循的原则\/280\n12.10.2　学生表\/281\n12.10.3　事件表\/282\n12.11　本章小结\/283\n第13章　Mahout详解\/284\n13.1　Mahout简介\/285\n13.2　Mahout的安装和配置\/285\n13.3　Mahout API简介\/288\n13.4　Mahout中的频繁模式挖掘\/290\n13.4.1　什么是频繁模式挖掘\/290\n13.4.2　Mahout中的频繁模式挖掘\/290\n13.5　Mahout中的聚类和分类\/292\n13.5.1　什么是聚类和分类\/292\n13.5.2　Mahout中的数据表示\/293\n13.5.3　将文本转化成向量\/294\n13.5.4　Mahout中的聚类、分类算法\/295\n13.5.5　算法应用实例\/299\n13.6　Mahout应用：建立一个推荐引擎\/304\n13.6.1　推荐引擎简介\/304\n13.6.2　使用Taste构建一个简单的推荐引擎\/305\n13.6.3　简单分布式系统下基于产品的推荐系统简介\/307\n13.7　本章小结\/309\n第14章　Pig详解\/310\n14.1　Pig简介\/311\n14.2　Pig的安装和配置 \/311\n14.2.1　Pig的安装条件\/311\n14.2.2　Pig的下载、安装和配置\/312\n14.2.3　Pig运行模式\/313\n14.3　Pig Latin语言\/315\n14.3.1　Pig Latin语言简介\/315\n14.3.2　Pig Latin的使用\/316\n14.3.3　Pig Latin的数据类型\/318\n14.3.4　Pig Latin关键字\/319\n14.4　用户定义函数 \/323\n14.4.1　编写用户定义函数\/324\n14.4.2　使用用户定义函数\/325\n14.5　Zebra简介 \/326\n14.5.1　Zebra的安装\/326\n14.5.2　Zebra的使用简介\/327\n14.6　Pig实例 \/328\n14.6.1　Local模式\/328\n14.6.2　MapReduce模式\/330\n14.7　Pig进阶\/331\n14.7.1　数据实例\/331\n14.7.2　Pig数据分析\/332\n14.8　本章小结\/336\n第15章　ZooKeeper详解\/337\n15.1　ZooKeeper简介\/338\n15.1.1　ZooKeeper的设计目标\/338\n15.1.2　数据模型和层次命名空间\/339\n15.1.3　ZooKeeper中的节点和临时节点\/339\n15.1.4　ZooKeeper的应用\/340\n15.2　ZooKeeper的安装和配置\/340\n15.2.1　安装ZooKeeper \/340\n15.2.2　配置ZooKeeper\/346\n15.2.3　运行ZooKeeper\/348\n15.3　ZooKeeper的简单操作\/350\n15.3.1　使用ZooKeeper命令的简单操作步骤\/350\n15.3.2　ZooKeeper API的简单使用\/352\n15.4　ZooKeeper的特性\/355\n15.4.1　ZooKeeper的数据模型\/355\n15.4.2　ZooKeeper会话及状态\/356\n15.4.3　ZooKeeper watches\/357\n15.4.4　ZooKeeper ACL\/358\n15.4.5　ZooKeeper的一致性保证\/359\n15.5　使用ZooKeeper进行Leader选举\/359\n15.6　ZooKeeper锁服务\/360\n15.6.1　ZooKeeper中的锁机制\/360\n15.6.2　ZooKeeper提供的一个写锁的实现\/361\n15.7　使用ZooKeeper创建应用程序 \/363\n15.7.1　使用Eclipse开发ZooKeeper应用程序\/363\n15.7.2　应用程序实例\/365\n15.8　BooKeeper\/369\n15.9　本章小结\/371\n第16章　Avro详解\/372\n16.1　Avro介绍\/373\n16.1.1　模式声明\/374\n16.1.2　数据序列化\/378\n16.1.3　数据排列顺序\/380\n16.1.4　对象容器文件 \/381\n16.1.5　协议声明\/382\n16.1.6　协议传输格式\/383\n16.1.7　模式解析\/386\n16.2　Avro的C\/C++实现\/387\n16.3　Avro的Java实现\/398\n16.4　GenAvro（Avro IDL）语言\/402\n16.5　Avro SASL概述\/406\n16.6　本章小结\/407\n第17章　Chukwa详解\/409\n17.1　Chukwa简介\/410\n17.2　Chukwa架构\/411\n17.2.1　客户端及其数据模型\/412\n17.2.2　收集器\/413\n17.2.3　归档器和分离解析器\/414\n17.2.4　HICC\/415\n17.3　Chukwa的可靠性\/415\n17.4　Chukwa集群搭建\/416\n17.4.1　基本配置要求\/416\n17.4.2　Chukwa的安装\/416\n17.4.3　Chukwa的运行\/419\n17.5　Chukwa数据流的处理\/424\n17.6　Chukwa与其他监控系统比较\/425\n17.7　本章小结\/426\n本章参考资料\/426\n第18章　Hadoop的常用插件与开发\/428\n18.1　Hadoop Studio的介绍和使用\/429\n18.1.1　Hadoop Studio的介绍\/429\n18.1.2　Hadoop Studio的安装配置\/430\n18.1.3　Hadoop Studio的使用举例\/430\n18.2　Hadoop Eclipse的介绍和使用\/436\n18.2.1　Hadoop Eclipse的介绍\/436\n18.2.2　Hadoop Eclipse的安装配置\/437\n18.2.3　Hadoop Eclipse的使用举例\/438\n18.3　Hadoop Streaming的介绍和使用\/440\n18.3.1　Hadoop Streaming的介绍\/440\n18.3.2　Hadoop Streaming的使用举例\/444\n18.3.3　使用Hadoop Streaming常见的问题\/446\n18.4　Hadoop Libhdfs的介绍和使用\/448\n18.4.1　Hadoop Libhdfs的介绍\/448\n18.4.2　Hadoop Libhdfs的安装配置\/448\n18.4.3　Hadoop Libhdfs API简介\/448\n18.4.4　Hadoop Libhdfs的使用举例\/449\n18.5　本章小结\/450\n第19章　企业应用实例\/452\n19.1　Hadoop在Yahoo!的应用\/453\n19.2　Hadoop在eBay的应用\/455\n19.3　Hadoop在百度的应用\/457\n19.4　即刻搜索中的Hadoop\/460\n19.4.1　即刻搜索简介\/460\n19.4.2　即刻Hadoop应用架构\/460\n19.4.3　即刻Hadoop应用分析\/463\n19.5　Facebook中的Hadoop和HBase\/463\n19.5.1　Facebook中的任务特点\/464\n19.5.2　MySQL VS Hadoop+HBase\/466\n19.5.3　Hadoop和HBase的实现\/467\n19.6　本章小结\/472\n本章参考资料\/472\n附录A　云计算在线检测平台\/474\n附录B　Hadoop安装、运行与使用说明\/484\n附录C　使用DistributedCache的MapReduce程序\/491\n附录D　使用ChainMapper和ChainReducer的MapReduce程序\/495","pages":"498","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s24321021.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s24321021.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24321021.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20275953\/","id":"20275953","publisher":"机械工业出版社华章公司","isbn10":"7111395832","isbn13":"9787111395836","title":"Hadoop实战（第2版）","url":"https:\/\/api.douban.com\/v2\/book\/20275953","alt_title":"","author_intro":"陆嘉恒，资深数据库专家和云计算技术专家，对Hadoop及其相关技术有非常深入的研究，主持了多个分布式云计算项目的研究与实施，积累了丰富的实践经验。获得新加坡国立大学博士学位，美国加利福尼亚大学尔湾分校(University of California, Irvine) 博士后，现为中国人民大学教授，博士生导师。此外，他对数据挖掘和Web信息搜索等技术也有深刻的认识。","summary":"本书能满足读者全面学习最新的Hadoop技术及其相关技术（Hive、HBase等）的需求，是一本系统且极具实践指导意义的Hadoop工具书和参考书。第1版上市后广受好评，被誉为学习Hadoop技术的经典著作之一。与第1版相比，第2版技术更新颖，所有技术都针对最新版进行了更新；内容更全面，几乎每一个章节都增加了新内容，而且增加了新的章节；实战性更强，案例更丰富；细节更完美，对第1版中存在的缺陷和不足进行了修正。\n本书内容全面，对Hadoop整个技术体系进行了全面的讲解，不仅包括HDFS、MapReduce、YARN等核心内容，而且还包括Hive、HBase、Mahout、Pig、ZooKeeper、Avro、Chukwa等与Hadoop技术相关的重要内容。实战性强，不仅为各个知识点精心设计了大量经典的小案例，而且还包括Yahoo!等多个大公司的企业级案例，可操作系极强。\n全书一共19章：第1~2章首先对Hadoop进行了全方位的宏观介绍，然后介绍了Hadoop在三大主流操作系统平台上的安装与配置方法；第3~6章分别详细讲解了MapReduce计算模型、MapReduce的工作机制、MapReduce应用的开发方法，以及多个精巧的MapReduce应用案例；第7章全面讲解了Hadoop的I\/O操作；第8章对YARN进行了介绍；第9章对HDFS进行了详细讲解和分析；第10章细致地讲解了Hadoop的管理；第11~17章对Hadoop大生态系统中的Hive、HBase、Mahout、Pig、ZooKeeper、Avro、Chukwa等技术进行了详细的讲解；第18章讲解了Hadoop的各种常用插件，以及Hadoop插件的开发方法；第19章分析了Hadoop在Yahoo!、eBay、百度、Facebook等企业中的应用案例。","series":{"id":"19972","title":"实战系列"},"price":"79.00元"},{"rating":{"max":10,"numRaters":12,"average":"7.5","min":0},"subtitle":"基于Storm、Spark等Hadoop替代技术的实时应用","author":["Vijay Srinivas Agneeswaran"],"pubdate":"2015-4","tags":[{"count":13,"name":"大数据","title":"大数据"},{"count":7,"name":"数据挖掘","title":"数据挖掘"},{"count":3,"name":"数据平台","title":"数据平台"},{"count":2,"name":"spark","title":"spark"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"数据分析","title":"数据分析"},{"count":1,"name":"数学","title":"数学"},{"count":1,"name":"技术","title":"技术"}],"origin_title":"Big Data Analytics Beyond Hadoop","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28071590.jpg","binding":"平装","translator":["吴京润","黄经业"],"catalog":"目录\n前言\n致谢\n关于作者\n1 引言：为什么要超越 Hadoop Map-Reduce  1\nHadoop的适用范围  3\n大数据分析之机器学习实现的革命  10\n第一代机器学习工具 \/范式  11\n第二代机器学习工具 \/范式  11\n第三代机器学习工具 \/范式  14\n小结  18\n参考文献  19\n2 何为伯克利数据分析栈（BDAS）  23\n实现 BDAS的动机  24\nSpark：动机  25\nShark：动机  26\nMesos：动机  28\nBDAS的设计及架构  29\nSpark：高效的集群数据处理的范式  34\nSpark的弹性分布式数据集  36\nSpark的实现  40\nSpark VS. 分布式共享内存系统  42\nRDD的表达性  44\n类似 Spark的系统  45\nShark：分布式系统上的 SQL接口  46\nSpark为 Shark提供的扩展  47\n列内存存储  49\n分布式数据加载  50\n完全分区智能连接  50\n分区修剪  50\n机器学习的支持  51\nMesos：集群调度及管理系统  51\nMesos组件  52\n资源分配  54\n隔离  55\n容错性  57\n小结  58\n参考文献  59\n3 使用 Spark实现机器学习算法  66\n机器学习基础知识  66\n机器学习：随机森林示例  68\n逻辑回归：概述  72\n二元形式的逻辑回归  73\n逻辑回归估计  75\n多元逻辑回归  76\nSpark中的逻辑回归算法  77\n支持向量机  80\n复杂决策面  81\n支持向量机背后的数学原理  82\nSpark中的支持向量机  84\nSpark对 PMML的支持  85\nPMML结构  87\nPMML的生产者及消费者  92\nSpark对朴素贝叶斯的 PMML支持  94\nSpark对线性回归的 PMML支持  95\n在 Spark中使用 MLbase进行机器学习  97\n参考文献  99\n4 实现实时的机器学习算法 101\nStorm简介  101\n数据流  103\n拓扑  104\nStorm集群  105\n简单的实时计算例子  106\n数据流组  108\nStorm的消息处理担保  109\n基于 Storm的设计模式  111\n分布式远程过程调用  111\nTrident：基于 Storm的实时聚合  115\n实现基于 Storm的逻辑回归算法  116\n实现基于 Storm的支持向量机算法  120\nStorm对朴素贝叶斯 PMML的支持  122\n实时分析的应用  126\n工业日志分类  126\n互联网流量过滤器  130\nStorm的替代品  131\nSpark流  133\nD-Streams的动机  133\n参考文献  135\n5 图处理范式 138\nPregel：基于 BSP的图处理框架  139\n类似的做法  141\n开源的 Pregel实现  143\nGiraph  143\nGoldenORB  145\nPhoebus  145\nApache Hama  146\nStanford GPS  146\nGraphLab  147\nGraphLab：多核版本  148\n分布式的 GraphLab  150\nPowerGraph  152\n通过 GraphLab实现网页排名算法  156\n顶点程序  158\n基于 GraphLab实现随机梯度下降算法  163\n参考文献  167\n6 结论：超越Hadoop Map-Reduce的大数据分析  171\nHadoop YARN概览  172\nHadoop YARN的动机  172\n作为资源调度器的 YARN  174\nYARN上的其他框架  175\n大数据分析的未来是怎样的  177\n参考文献  180\n附录A 代码笔记  182","pages":"218","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28071590.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28071590.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28071590.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26389123\/","id":"26389123","publisher":"电子工业出版社","isbn10":"7121252244","isbn13":"9787121252242","title":"颠覆大数据分析","url":"https:\/\/api.douban.com\/v2\/book\/26389123","alt_title":"Big Data Analytics Beyond Hadoop","author_intro":"Vijay Srinivas Agneeswaran 博士，1998 年于SVCE 的马德拉斯分校获得计算机科学与工程专业的学士学位，2001 年获取了印度理工学院马德拉斯分校的硕士学位（研究性质），2008年又获取了该校的博士学位。他曾在瑞士洛桑的联邦理工学院的分布式信息系统实验室（LSIR）担任过一年的博士后研究员。之前7 年先后就职于Oracle、Cognizant 及Impetus，对大数据及云领域的工程研发贡献颇多。目前担任Impetus 的大数据实验室的执行总监。他的研发团队在专利、论文、受邀的会议发言以及下一代产品创新方面都处于领导地位。他主要研究的领域包括大数据管理、批处理及实时分析，以及大数据的机器学习算法的实现范式。最近8 年来，他一直是计算机协会（ACM）以及电气和电子工程师协会（IEEE）的专家成员，并于2012年12 月被推选为IEEE 的资深成员。他在美国、欧洲以及印度的专利局都申请过专利（并持有美国的两项专利）。他在前沿的期刊及会议，包括IEEE transaction 上都发表过论文。他还是国内外多个会议的特邀发言人，譬如O’Reilly 的Strata 大数据系列会议。最近一次公开发表论文是在Liebertpub 的大数据期刊上。他与妻子及儿女一起居住在班加罗尔，对印度、埃及、巴比伦以及希腊古代的文化与哲学的研究非常感兴趣。","summary":"Vijay Srinivas Agneeswaran 博士，1998 年于SVCE 的马德拉斯分校获得计算机科学与工程专业的学士学位，2001 年获取了印度理工学院马德拉斯分校的硕士学位（研究性质），2008年又获取了该校的博士学位。他曾在瑞士洛桑的联邦理工学院的分布式信息系统实验室（LSIR）担任过一年的博士后研究员。之前7 年先后就职于Oracle、Cognizant 及Impetus，对大数据及云领域的工程研发贡献颇多。目前担任Impetus 的大数据实验室的执行总监。他的研发团队在专利、论文、受邀的会议发言以及下一代产品创新方面都处于领导地位。他主要研究的领域包括大数据管理、批处理及实时分析，以及大数据的机器学习算法的实现范式。最近8 年来，他一直是计算机协会（ACM）以及电气和电子工程师协会（IEEE）的专家成员，并于2012年12 月被推选为IEEE 的资深成员。他在美国、欧洲以及印度的专利局都申请过专利（并持有美国的两项专利）。他在前沿的期刊及会议，包括IEEE transaction 上都发表过论文。他还是国内外多个会议的特邀发言人，譬如O’Reilly 的Strata 大数据系列会议。最近一次公开发表论文是在Liebertpub 的大数据期刊上。他与妻子及儿女一起居住在班加罗尔，对印度、埃及、巴比伦以及希腊古代的文化与哲学的研究非常感兴趣。","price":"49.00元"},{"rating":{"max":10,"numRaters":68,"average":"6.2","min":0},"subtitle":"","author":["陆嘉恒"],"pubdate":"2011-10","tags":[{"count":65,"name":"Hadoop","title":"Hadoop"},{"count":30,"name":"hadoop","title":"hadoop"},{"count":26,"name":"云计算","title":"云计算"},{"count":23,"name":"分布式","title":"分布式"},{"count":18,"name":"map\/reduce","title":"map\/reduce"},{"count":15,"name":"计算机","title":"计算机"},{"count":9,"name":"大数据","title":"大数据"},{"count":8,"name":"hbase","title":"hbase"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6950784.jpg","binding":"","translator":[],"catalog":"前言\n第1章 Hadoop简介\n第2章 Hadoop的安装与配置\n第3章 Hadoop应用案例分析\n第4章 MapReduce计算模型\n第5章 开发MapReduce应用程序\n第6章 MapReduce应用案例\n第7章 MapReduce工作机制\n第8章 HadoopI\/O\n第9章 HDFS详解\n第10章 Hadoop的管理\n第11章 Hive详解\n第12章 HBase详解\n第13章 Mahout详解\n第14章 Pig详解\n第15章 ZooKeepet详解\n第16章 Avro详解\n第17章 Chukwa详解\n第18章 Hadoop的常用插件与开发\n附录A 云计算在线检测平台","ebook_url":"https:\/\/read.douban.com\/ebook\/957990\/","pages":"441","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s6950784.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s6950784.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6950784.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6860889\/","id":"6860889","publisher":"机械工业出版社华章公司","isbn10":"7111359445","isbn13":"9787111359449","title":"Hadoop实战","url":"https:\/\/api.douban.com\/v2\/book\/6860889","alt_title":"","author_intro":"陆嘉恒，中国人民大学副教授，新加坡国立大学博士，美国加利福尼亚大学尔湾分校(University of California, Irvine) 博士后。专注于云计算及其相关技术的研究，对Hadoop有较深入的研究，积累了丰富的实践经验。对分布式计算和海量数据处理有深刻的认识，主持并完成了多个国家863和自然科学基金项目的研究与实施。2009年入选新世纪优秀人才，2010年入选北京科技新星。主持《云计算概论》课程获教育部-IBM精品课程称号。","summary":"本书是一本系统且极具实践指导意义的Hadoop工具书和参考书。内容全面，对Hadoop整个技术体系进行了全面的讲解，不仅包括HDFS和MapReduce这两大核心内容，而且还包括Hive、HBase、Mahout、Pig、ZooKeeper、Avro、Chukwa等与Hadoop相关的子项目的内容。实战性强，为各个知识点精心设计了大量经典的小案例，易于理解，可操作性强。\n全书一共18章：第1章全面介绍了Hadoop的概念、优势、项目结构、体系结构，以及它与分布式计算的关系；第2章详细讲解了Hadoop集群的安装和配置，以及常用的日志分析技巧；第3章分析了Hadoop在Yahoo！、eBay、Facebook和百度的应用案例，以及Hadoop平台上海量数据的排序；第4-7章深入地讲解了MapReduce计算模型、MapReduce应用的开发方法、MapReduce的工作机制，同时还列出了多个MapReduce的应用案例，涉及单词计数、数据去重、排序、单表关联和多表关联等内容；第8-11章全面地阐述了Hadoop的I\/O操作、HDFS的原理与基本操作，以及Hadoop的各种管理操作，如集群的维护等；第12-17章详细而系统地讲解了Hive、HBase、Mahout、Pig、ZooKeeper、Avro、Chukwa等所有与Hadoop相关的子项目的原理及使用，以及这些子项目与Hadoop的整合使用；第18章以实例的方式讲解了常用Hadoop插件的使用和Hadoop插件的开发。\n本书既适合没有Hadoop基础的初学者系统地学习，又适合有一定Hadoop基础但是缺乏实践经验的读者实践和参考。","ebook_price":"25.00","price":"69.00元"},{"rating":{"max":10,"numRaters":12,"average":"7.1","min":0},"subtitle":"Hadoop\/Spark大数据处理技巧","author":["Mahmoud Parsian"],"pubdate":"2016-10-1","tags":[{"count":20,"name":"大数据","title":"大数据"},{"count":18,"name":"机器学习","title":"机器学习"},{"count":14,"name":"数据科学","title":"数据科学"},{"count":13,"name":"spark","title":"spark"},{"count":10,"name":"Hadoop","title":"Hadoop"},{"count":8,"name":"数据算法","title":"数据算法"},{"count":6,"name":"大数据_开发","title":"大数据_开发"},{"count":4,"name":"java","title":"java"}],"origin_title":"Data Algorithms: Recipes for Scaling Up with Hadoop and Spark","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29216480.jpg","binding":"Paperback","translator":["苏金国","杨健康"],"catalog":"序 1\n前言 3\n第1章二次排序：简介 19\n二次排序问题解决方案 21\nMapReduce\/Hadoop的二次排序解决方案 25\nSpark的二次排序解决方案 29\n第2章二次排序：详细示例 42\n二次排序技术 43\n二次排序的完整示例 46\n运行示例——老版本Hadoop API 50\n运行示例——新版本Hadoop API 52\n第3章 Top 10 列表 54\nTop N 设计模式的形式化描述 55\nMapReduce\/Hadoop实现：唯一键 56\nSpark实现：唯一键 62\nSpark实现：非唯一键 73\n使用takeOrdered()的Spark Top 10 解决方案 84\nMapReduce\/Hadoop Top 10 解决方案：非唯一键 91\n第4章左外连接 96\n左外连接示例 96\nMapReduce左外连接实现 99\nSpark左外连接实现 105\n使用leftOuterJoin()的Spark实现 117\n第5章反转排序 127\n反转排序模式示例 128\n反转排序模式的MapReduce\/Hadoop实现 129\n运行示例 134\n第6章移动平均 137\n示例1：时间序列数据（股票价格） 137\n示例2：时间序列数据（URL访问数） 138\n形式定义 139\nPOJO移动平均解决方案 140\nMapReduce\/Hadoop移动平均解决方案 143\n第7章购物篮分析 155\nMBA目标 155\nMBA的应用领域 157\n使用MapReduce的购物篮分析 157\nSpark解决方案 166\n运行Spark实现的YARN 脚本 179\n第8章共同好友 182\n输入 183\nPOJO共同好友解决方案 183\nMapReduce算法 184\n解决方案1: 使用文本的Hadoop实现 187\n解决方案2: 使用ArrayListOfLongsWritable 的Hadoop实现 189\nSpark解决方案 191\n第9章使用MapReduce实现推荐引擎 201\n购买过该商品的顾客还购买了哪些商品 202\n经常一起购买的商品 206\n推荐连接 210\n第10章基于内容的电影推荐 225\n输入 226\nMapReduce阶段1 226\nMapReduce阶段2和阶段3 227\nSpark电影推荐实现 234\n第11章使用马尔可夫模型的智能邮件营销 .253\n马尔可夫链基本原理 254\n使用MapReduce的马尔可夫模型 256\nSpark解决方案 269\n第12章 K-均值聚类 282\n什么是K-均值聚类? 285\n聚类的应用领域 285\nK-均值聚类方法非形式化描述：分区方法 286\nK-均值距离函数 286\nK-均值聚类形式化描述 287\nK-均值聚类的MapReduce解决方案 288\nK-均值算法Spark实现 292\n第13章 k-近邻 296\nkNN分类 297\n距离函数 297\nkNN示例 298\nkNN算法非形式化描述 299\nkNN算法形式化描述 299\nkNN的类Java非MapReduce 解决方案 299\nSpark的kNN算法实现 301\n第14章朴素贝叶斯 315\n训练和学习示例 316\n条件概率 319\n深入分析朴素贝叶斯分类器 319\n朴素贝叶斯分类器：符号数据的MapReduce解决方案 322\n朴素贝叶斯分类器Spark实现 332\n使用Spark和Mahout 347\n第15章情感分析 349\n情感示例 350\n情感分数：正面或负面 350\n一个简单的MapReduce情感分析示例 351\n真实世界的情感分析 353\n第16章查找、统计和列出大图中的所有三角形 354\n基本的图概念 355\n三角形计数的重要性 356\nMapReduce\/Hadoop解决方案 357\nSpark解决方案 364\n第17章 K-mer计数 375\nK-mer计数的输入数据 376\nK-mer计数应用 376\nK-mer计数MapReduce\/Hadoop解决方案 377\nK-mer计数Spark解决方案 378\n第18章 DNA测序 390\nDNA测序的输入数据 392\n输入数据验证 393\nDNA序列比对 393\nDNA测试的MapReduce算法 394\n第19章 Cox回归 413\nCox模型剖析 414\n使用R的Cox回归 415\nCox回归应用 416\nCox回归 POJO解决方案 417\nMapReduce输入 418\n使用MapReduce的Cox回归 419\n第20章 Cochran-Armitage趋势检验 426\nCochran-Armitage算法 427\nCochran-Armitage应用 432\nMapReduce解决方案 435\n第21章等位基因频率 443\n基本定义 444\n形式化问题描述 448\n等位基因频率分析的MapReduce解决方案 449\nMapReduce解决方案, 阶段1 449\nMapReduce解决方案，阶段2 459\nMapReduce解决方案, 阶段3 463\n染色体X 和Y的特殊处理 466\n第22章 T检验 468\n对bioset完成T检验 469\nMapReduce问题描述 472\n输入 472\n期望输出 473\nMapReduce解决方案 473\nSpark实现 476\n第23章皮尔逊相关系数 488\n皮尔逊相关系数公式 489\n皮尔逊相关系数示例 491\n皮尔逊相关系数数据集 492\n皮尔逊相关系数POJO 解决方案 492\n皮尔逊相关系数MapReduce解决方案 493\n皮尔逊相关系数的Spark 解决方案 496\n运行Spark程序的YARN 脚本 516\n使用Spark计算斯皮尔曼相关系数 517\n第24章 DNA碱基计数 520\nFASTA 格式 521\nFASTQ 格式 522\nMapReduce解决方案：FASTA 格式 522\n运行示例 524\nMapReduce解决方案: FASTQ 格式 528\nSpark 解决方案: FASTA 格式 533\nSpark解决方案: FASTQ 格式 537\n第25章 RNA测序 543\n数据大小和格式 543\nMapReduce工作流 544\nRNA测序分析概述 544\nRNA测序MapReduce算法 548\n第26章基因聚合 553\n输入 554\n输出 554\nMapReduce解决方案（按单个值过滤和按平均值过滤） 555\n基因聚合的Spark解决方案 567\nSpark解决方案：按单个值过滤 567\nSpark解决方案：按平均值过滤 576\n第27章线性回归 586\n基本定义 587\n简单示例 587\n问题描述 588\n输入数据 589\n期望输出 590\n使用SimpleRegression的MapReduce解决方案 590\nHadoop实现类 593\n使用R线性模型的MapReduce解决方案 593\n第28章 MapReduce和幺半群 600\n概述 600\n幺半群的定义 602\n幺半群和非幺半群示例 603\nMapReduce示例：非幺半群 606\nMapReduce示例：幺半群 608\n使用幺半群的Spark示例 612\n使用幺半群的结论 618\n函子和幺半群 619\n第29章小文件问题 622\n解决方案1：在客户端合并小文件 623\n解决方案2：用CombineFileInputFormat解决小文件问题 629\n其他解决方案 634\n第30章 MapReduce的大容量缓存 635\n实现方案 636\n缓存问题形式化描述 637\n一个精巧、可伸缩的解决方案 637\n实现LRUMap缓存 640\n使用LRUMap的MapReduce解决方案 646\n第31章 Bloom过滤器 651Bloom\n过滤器性质 651\n一个简单的Bloom过滤器示例 653","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29216480.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29216480.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29216480.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26934459\/","id":"26934459","publisher":"中国电力出版社","isbn10":"7512395949","isbn13":"9787512395947","title":"数据算法","url":"https:\/\/api.douban.com\/v2\/book\/26934459","alt_title":"Data Algorithms: Recipes for Scaling Up with Hadoop and Spark","author_intro":"Mahmoud Parsian，计算机科学博士，是一位热衷于实践的软件专家，作为开发人员、设计人员、架构师和作者，他有30多年的软件开发经验。目前领导着Illumina的大数据团队，在过去15年间，他主要从事Java (服务器端)、数据库、MapReduce和分布式计算的有关工作。Mahmoud还著有《JDBC Recipes》和《JDBC Metadata， MySQL，and Oracle Recipes》等书（均由Apress出版）。","summary":"《数据算法：Hadoop\/Spark大数据处理技巧》介绍了很多基本设计模式、优化技术和数据挖掘及机器学习解决方案，以解决生物信息学、基因组学、统计和社交网络分析等领域的很多问题。这还概要介绍了MapReduce、Hadoop和Spark。\n主要内容包括：\n■ 完成超大量交易的购物篮分析。\n■ 数据挖掘算法（K-均值、KNN和朴素贝叶斯）。\n■ 使用超大基因组数据完成DNA和RNA测序。\n■ 朴素贝叶斯定理和马尔可夫链实现数据和市场预测。\n■ 推荐算法和成对文档相似性。\n■ 线性回归、Cox回归和皮尔逊（Pearson）相关分析。\n■ 等位基因频率和DNA挖掘。\n■ 社交网络分析（推荐系统、三角形计数和情感分析）。","price":"128元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Tom White"],"pubdate":"2010-1-25","tags":[{"count":1,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s4634425.jpg","binding":"大型本","translator":[],"catalog":"","pages":"568","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s4634425.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s4634425.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s4634425.jpg"},"alt":"https:\/\/book.douban.com\/subject\/5976949\/","id":"5976949","publisher":"オライリージャパン","isbn10":"487311439X","isbn13":"9784873114392","title":"Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/5976949","alt_title":"","author_intro":"","summary":"","price":"JPY 4830"},{"rating":{"max":10,"numRaters":28,"average":"7.0","min":0},"subtitle":"","author":["Jason Venner"],"pubdate":"2009-6-21","tags":[{"count":50,"name":"hadoop","title":"hadoop"},{"count":19,"name":"MapReduce","title":"MapReduce"},{"count":11,"name":"分布式","title":"分布式"},{"count":5,"name":"编程","title":"编程"},{"count":4,"name":"云计算","title":"云计算"},{"count":4,"name":"Hadoop","title":"Hadoop"},{"count":3,"name":"架构","title":"架构"},{"count":3,"name":"programming","title":"programming"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4250281.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"440","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s4250281.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s4250281.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4250281.jpg"},"alt":"https:\/\/book.douban.com\/subject\/3529886\/","id":"3529886","publisher":"Apress","isbn10":"1430219424","isbn13":"9781430219422","title":"Pro Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/3529886","alt_title":"","author_intro":"","summary":"You've heard the hype about Hadoop: it runs petabyte--scale data mining tasks insanely fast, it runs gigantic tasks on clouds for absurdly cheap, it's been heavily committed to by tech giants like IBM, Yahoo!, and the Apache Project, and it's completely open source (thus free). But what exactly is it, and more importantly, how do you even get a Hadoop cluster up and running? From Apress, the name you've come to trust for hands--on technical knowledge, Pro Hadoop brings you up to speed on Hadoop. You learn the ins and outs of MapReduce; how to structure a cluster, design, and implement the Hadoop file system; and how to build your first cloud--computing tasks using Hadoop. Learn how to let Hadoop take care of distributing and parallelizing your software--you just focus on the code, Hadoop takes care of the rest. Best of all, you'll learn from a tech professional who's been in the Hadoop scene since day one. Written from the perspective of a principal engineer with down--in--the--trenches knowledge of what to do wrong with Hadoop, you learn how to avoid the common, expensive first errors that everyone makes with creating their own Hadoop system or inheriting someone else's. Skip the novice stage and the expensive, hard--to--fix mistakes...go straight to seasoned pro on the hottest cloud--computing framework with Pro Hadoop. Your productivity will blow your managers away.  What you'll learn * Set up a stand--alone Hadoop cluster the smart way, laid out simply and step by step so you can get up and running quickly to build your next data center, collaborative, data--intensive Internet services application, Software as a Service (SaaS), and more. * Optimize your Hadoop production tasks like an experienced pro. * Work with time--proven, bulletproof standard patterns that have been tested and debugged in high--volume production. * Understand just enough theoretical knowledge to know why something works in Hadoop, without getting bogged down in abstruse walls of theory. * Get detailed explanations of not only how to do something with Hadoop, but also why, from a front--line coder with years in the Hadoop game. * Turn someone else's expensive cluster--wide \"wrong\" into an orderly, productive \"right\" with professional--level debugging and testing. Who this book is for IT professionals interested in investigating Hadoop and implementing it in their organizations, and existing Hadoop users who want to deepen their professional toolkits. Table of Contents * Getting Started with Hadoop Core * The Basics of a MapReduce Job * The Basics of Multimachine Clusters * HDFS Details for Multimachine Clusters * MapReduce Details for Multimachine Clusters * Tuning Your MapReduce Jobs * Unit Testing and Debugging * Advanced and Alternate MapReduce Techniques * Solving Problems with Hadoop * Projects Based On Hadoop and Future Directions","price":"USD 39.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Surhone, Lambert M.; Tennoe, Mariam T.; Henssonow, Susan F."],"pubdate":"","tags":[{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s22181881.jpg","binding":"","translator":[],"catalog":"","pages":"92","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s22181881.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s22181881.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s22181881.jpg"},"alt":"https:\/\/book.douban.com\/subject\/19370584\/","id":"19370584","publisher":"","isbn10":"6134560227","isbn13":"9786134560221","title":"Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/19370584","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":12,"average":"7.8","min":0},"subtitle":"Moving beyond MapReduce and Batch Processing with Apache Hadoop 2","author":["Arun Murthy","Vinod Kumar Vavilapalli","Doug Eadline (Author), Joseph Niemiec (Author), Jeff Markham (Author)"],"pubdate":"2014-3-31","tags":[{"count":9,"name":"hadoop","title":"hadoop"},{"count":4,"name":"yarn","title":"yarn"},{"count":3,"name":"大数据","title":"大数据"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"apache","title":"apache"},{"count":1,"name":"BigData","title":"BigData"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27202479.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"336","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27202479.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27202479.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27202479.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25812368\/","id":"25812368","publisher":"Addison-Wesley Professional","isbn10":"0321934504","isbn13":"9780321934505","title":"Apache Hadoop YARN","url":"https:\/\/api.douban.com\/v2\/book\/25812368","alt_title":"","author_intro":"About the Author\nArun Murthy (California) has contributed to Apache Hadoop full-time since the inception of the project in early 2006. He is a long-term Hadoop Committer and a member of the Apache Hadoop Project Management Committee. Previously, he was the architect and lead of the Yahoo Hadoop Map-Reduce development team and was ultimately responsible, technically, for providing Hadoop Map-Reduce as a service for all of Yahoo - currently running on nearly 50,000 machines! Arun is the Founder and Architect of the Hortonworks Inc., a software company that is helping to accelerate the development and adoption of Apache Hadoop. Hortonworks was formed by the key architects and core Hadoop committers from the Yahoo! Hadoop software engineering team in June 2011 in order to accelerate the development and adoption of Apache Hadoop. Funded by Yahoo! and Benchmark Capital, one of the preeminent technology investors, their goal is to ensure that Apache Hadoop becomes the standard platform for storing, processing, managing and analyzing big data. He lives in Silicon Valley in California.\nDouglas Eadline (Pennsylvania), PhD, began his career as a practitioner and a chronicler of the Linux Cluster HPC revolution and now documents big data analytics. Starting with the first Beowulf How To document, Dr. Eadline has written hundreds of articles, white papers, and instructional documents covering virtually all aspects of HPC computing. Prior to starting and editing the popular ClusterMonkey.net web site in 2005, he served as Editorinchief for ClusterWorld Magazine, and was Senior HPC Editor for Linux Magazine. Currently, he is a consultant to the HPC industry and writes a monthly column in HPC Admin Magazine. Both clients and readers have recognized Dr. Eadline's ability to present a \"technological value proposition\" in a clear and accurate style. He has practical hands on experience in many aspects of HPC including, hardware and software design, benchmarking, storage, GPU, cloud, and parallel computing.","summary":"Apache Hadoop is right at the heart of the Big Data revolution. In the brand-new Release 2, Hadoop’s data processing has been thoroughly overhauled. The result is Apache Hadoop YARN, a generic compute fabric providing resource management at datacenter scale, and a simple method to implement distributed applications such as MapReduce to process petabytes of data on Apache Hadoop HDFS. Apache Hadoop 2 and YARN truly deserve to be called breakthroughs.\n\nIn Apache Hadoop YARN , key YARN developer Arun Murthy shows how the key design changes in Apache  Hadoop lead to increased scalability and cluster utilization, new programming models and services, and the ability to move beyond Java and batch processing within the Hadoop ecosystem. Readers also learn to run existing applications like Pig and Hive under the Apache Hadoop 2 MapReduce framework, and develop new applications that take absolutely full advantage of Hadoop YARN resources. Drawing on insights from the entire Apache Hadoop 2 team, Murthy and Dr. Douglas Eadline:\nReview Apache Hadoop YARN’s goals, design, architecture, and components\nGuide you through installation and administration of the new YARN architecture,\nDemonstrate how to optimize existing MapReduce applications quickly\nIdentify the functional requirements for each element of an Apache Hadoop 2 application\nWalk you through a complete sample application project\nOffer multiple examples and case studies drawn from their cutting-edge experience","price":"USD 39.99"},{"rating":{"max":10,"numRaters":53,"average":"5.5","min":0},"subtitle":"开启通向云计算的捷径","author":["刘鹏"],"pubdate":"2011-8","tags":[{"count":55,"name":"hadoop","title":"hadoop"},{"count":34,"name":"云计算","title":"云计算"},{"count":15,"name":"计算机","title":"计算机"},{"count":9,"name":"编程","title":"编程"},{"count":5,"name":"Hadoop","title":"Hadoop"},{"count":4,"name":"计算机科学","title":"计算机科学"},{"count":4,"name":"大数据","title":"大数据"},{"count":3,"name":"易学","title":"易学"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s7640717.jpg","binding":"平装","translator":[],"catalog":"《实战hadoop》\n第1 章 神奇的大象——hadoop\n1.1 初识神象 2\n1.2 hadoop 初体验 4\n1.2.1 了解hadoop 的构架 4\n1.2.2 查看hadoop 活动 7\n1.3 hadoop 族群 10\n1.4 hadoop 安装 11\n1.4.1 在linux 系统中安装hadoop 11\n1.4.2 在windows 系统中安装hadoop 21\n1.4.3 站在象背上说“hello” 29\n1.4.4 eclipse 下的hadoop 应用开发 30\n参考文献 34\n第2 章 hdfs——不怕故障的海量存储\n2.1 开源的gfs——hdfs 36\n2.1.1 设计前提与目标 36\n2.1.2 hdfs 体系结构 37\n2.1.3 保障hdfs 可靠性措施 39\n2.2 hdfs 常用操作 42\n2.2.1 hdfs 下的文件操作 42\n.2.2.2 管理与更新 45\n2.3 hdfs api 之旅 48\n2.4 实战：用hdfs 存储海量视频数据 55\n2.4.1 应用场景 55\n2.4.2 设计实现 55\n参考文献 58\n第3 章 分久必合——mapreduce\n3.1 mapreduce 基础 60\n3.1.1 mapreduce 编程模型 60\n3.1.2 mapreduce 的集群行为 62\n3.2 样例分析：单词计数 64\n3.2.1 wordcount 源码分析 64\n3.2.2 wordcount 处理过程 67\n3.3 mapreduce，你够了解吗 69\n3.3.1 没有map、reduce 的mapreduce 69\n3.3.2 多少个reducers 最佳 72\n3.4 实战：倒排索引 74\n3.4.1 倒排索引简介 74\n3.4.2 分析与设计 76\n3.4.3 倒排索引完整源码 79\n参考文献 83\n第4 章 一张无限大的表——hbase\n4.1 hbase 简介 85\n4.1.1 逻辑模型 85\n4.1.2 物理模型 86\n4.1.3 region 服务器 87\n4.1.4 主服务器 89\n4.1.5 元数据表 89\n4.2 hbase 入门 91\n4.2.1 hbase 的安装配置 91\n4.2.2 hbase 用户界面 97\n实战hadoop —— 开启通向云计算的捷径\n4.3 hbase 操作演练 100\n4.3.1 基本shell 操作 100\n4.3.2 基本api 使用 103\n4.4 实战：使用mapreduce 构建hbase 索引 105\n4.4.1 索引表蓝图 105\n4.4.2 hbase 和mapreduce 107\n4.4.3 实现索引 108\n参考文献 112\n第5 章 更上一层楼——mapreduce 进阶\n5.1 简介 114\n5.2 复合键值对的使用 115\n5.2.1 把小的键值对合并成大的键值对 115\n5.2.2 巧用复合键让系统完成排序 117\n5.3 用户定制数据类型 123\n5.3.1 hadoop 内置的数据类型 123\n5.3.2 用户自定义数据类型的实现 124\n5.4 用户定制输入\/输出格式 126\n5.4.1 hadoop 内置的数据输入格式和recordreader 126\n5.4.2 用户定制数据输入格式与recordreader 127\n5.4.3 hadoop 内置的数据输出格式与recordwriter 133\n5.4.4 用户定制数据输出格式与recordwriter 134\n5.4.5 通过定制数据输出格式实现多集合文件输出 134\n5.5 用户定制partitioner 和combiner 137\n5.5.1 用户定制partitioner 137\n5.5.2 用户定制combiner 139\n5.6 组合式mapreduce 计算作业 141\n5.6.1 迭代mapreduce 计算任务 141\n5.6.2 顺序组合式mapreduce 作业的执行 142\n5.6.3 具有复杂依赖关系的组合式mapreduce 作业的执行 144\n5.6.4 mapreduce 前处理和后处理步骤的链式执行 145\n5.7 多数据源的连接 148\n5.7.1 基本问题数据示例 149\n5.7.2 用datajoin 类实现reduce 端连接 150\n5.7.3 用全局文件复制方法实现map 端连接 158\n5.7.4 带map 端过滤的reduce 端连接 162\n5.7.5 多数据源连接解决方法的限制 162\n5.8 全局参数\/数据文件的传递与使用 163\n5.8.1 全局作业参数的传递 163\n5.8.2 查询全局mapreduce 作业属性 166\n5.8.3 全局数据文件的传递 167\n5.9 关系数据库的连接与访问 169\n5.9.1 从数据库中输入数据 169\n5.9.2 向数据库中输出计算结果 170\n参考文献 172\n第6 章 hive——飞进数据仓库的小蜜蜂\n6.1 hive 的组成 174\n6.2 搭建蜂房——hive 安装 176\n6.3 hive 的服务 182\n6.3.1 hive shell 182\n6.3.2 jdbc\/odbc 支持 183\n6.3.3 thrift 服务 184\n6.3.4 web 接口 185\n6.3.5 元数据服务 186\n6.4 hiveql 的使用 187\n6.4.1 hiveql 的数据类型 187\n6.4.2 hiveql 常用操作 188\n6.5 hive 示例 196\n6.5.1 udf 编程示例 196\n实战hadoop —— 开启通向云计算的捷径\n6.5.2 udaf 编程示例 198\n6.6 实战：基于hive 的hadoop 日志分析 200\n参考文献 209\n第7 章 pig——一头什么都能吃的猪\n7.1 pig 的基本框架 211\n7.2 pig 的安装 212\n7.2.1 开始安装pig 212\n7.2.2 验证安装 213\n7.3 pig 的使用 214\n7.3.1 pig 的mapreduce 模式 214\n7.3.2 使用pig 216\n7.3.3 pig 的调试 219\n7.4 pig latin 编程语言 224\n7.4.1 数据模型 224\n7.4.2 数据类型 225\n7.4.3 运算符 226\n7.4.4 常用操作 228\n7.4.5 用户自定义函数 231\n7.5 实战：基于pig 的通话记录查询 231\n7.5.1 应用场景 231\n7.5.2 设计实现 232\n参考文献 238\n第8 章 facebook 的女神——cassandra\n8.1 洞察cassandra 的全貌 240\n8.1.1 目标及特点 240\n8.1.2 体系结构 241\n8.1.3 存储机制 243\n8.1.4 数据操作过程 244\n8.2 让cassandra 飞 247\n8.2.1 windows 7 下单机安装 247\n8.2.2 linux 下分布式安装 249\n8.3 cassandra 操作示例 253\n8.3.1 客户端命令代码跟踪 253\n8.3.2 增删cassandra 节点 262\n8.3.3 jconsole 监控cassandra 263\n8.4 cassandra 与mapreduce 结合 266\n8.4.1 需求分析 266\n8.4.2 编码流程分析 267\n8.4.3 mapreduce 的核心代码 268\n参考文献 269\n第9 章 chukwa——收集数据的大乌龟\n9.1 初识chukwa 271\n9.1.1 为什么需要chukwa 271\n9.1.2 什么是chukwa 272\n9.2 chukwa 架构与设计 274\n9.2.1 代理与适配器 276\n9.2.2 元数据 277\n9.2.3 收集器 278\n9.2.4 mapreduce 作业 279\n9.2.5 hicc 280\n9.2.6 数据接口与支持 280\n9.3 chukwa 安装与配置 281\n9.3.1 chukwa 安装 281\n9.3.2 源节点代理配置 284\n9.3.3 收集器 288\n9.3.4 demux 作业与hicc 配置 289\n9.4 chukwa 小试 291\n实战hadoop —— 开启通向云计算的捷径\n9.4.1 数据生成 291\n9.4.2 数据收集 292\n9.4.3 数据处理 292\n9.4.4 数据析取 293\n9.4.5 数据稀释 294\n9.4.6 数据显示 294\n参考文献 295\n第10 章 一统天下——zookeeper\n10.1 zookeeper 是个谜 297\n10.1.1 zookeeper 工作原理 298\n10.1.2 zookeeper 的特性 301\n10.2 zookeeper 安装和编程 303\n10.2.1 zookeeper 的安装和配置 303\n10.2.2 zookeeper 的编程实现 306\n10.3 zookeeper 演练：进程调度系统 308\n10.3.1 设计方案 308\n10.3.2 设计实现 309\n10.4 实战演练：zookeeper 实现namenode 自动切换 318\n10.4.1 设计思想 319\n10.4.2 详细设计 319\n10.4.3 编码 321\n10.4.4 实战总结 329\n参考文献 329\n第11 章 综合实战1——打造一个搜索引擎\n11.1 系统工作原理 331\n11.2 网页搜集与信息提取 333\n11.2.1 网页搜集 334\n11.2.2 网页信息的提取与存储 337\n11.3 基于mapreduce 的预处理 338\n11.3.1 元数据过滤 339\n11.3.2 生成倒排文件 341\n11.3.3 建立二级索引 353\n11.3.4 小节 357\n11.4 建立web 信息查询服务 358\n11.4.1 建立前台查询接口 358\n11.4.2 后台信息查询与合并 359\n11.4.3 返回显示结果 360\n11.5 系统优化 361\n11.5.1 存储方面的优化 361\n11.5.2 计算方面的优化 362\n11.6 本章总结 363\n参考文献 364\n第12 章 综合实战2——生物信息学应用\n12.1 背景 366\n12.2 总体框架 368\n12.3 系统实现 370\n12.3.1 序列数据库的切分和存储 370\n12.3.2 构造单词列表和扫描器 375\n12.3.3 map：扫描和扩展 376\n12.3.4 主控程序 378\n12.4 扩展性能测试 381\n12.5 本章总结 382\n参考文献 383\n第13 章 综合实战3——移动通信信令监测与查询\n13.1 分析与设计 385\n13.1.1 cdr 数据文件的检测与索引创建任务调度 388\n13.1.2 从hdfs 读取数据并创建索引 389\n实战hadoop —— 开启通向云计算的捷径\n13.1.3 查询cdr 信息 390\n13.2 实现代码 391\n13.2.1 cdr 文件检测和索引创建任务调度程序 392\n13.2.2 读取cdr 数据和索引创建处理 397\n13.2.3 cdr 查询 402\n13.3 本章总结 407\n参考文献 407\n第14 章 高枕无忧——hadoop 容错\n14.1 hadoop 的可靠性 409\n14.1.1 hdfs 中namenode 单点问题 409\n14.1.2 hdfs 数据块副本机制 410\n14.1.3 hdfs 心跳机制 411\n14.1.4 hdfs 负载均衡 412\n14.1.5 mapreduce 容错 413\n14.2 hadoop 的secondarynamenode 机制 414\n14.2.1 磁盘镜像与日志文件 414\n14.2.2 secondarynamenode 更新镜像的流程 414\n14.3 avatar 机制 418\n14.3.1 系统架构 419\n14.3.2 avatar 元数据同步机制 420\n14.3.3 故障切换过程 423\n14.3.4 avatar 运行流程 426\n14.3.5 avatar 故障切换流程 431\n14.4 avatar 实战 436\n14.4.1 实验环境 436\n14.4.2 编译avatar 437\n14.4.3 avatar 安装和配置 440\n14.4.4 avatar 启动运行与宕机切换 452\n参考文献 456","pages":"456","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s7640717.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s7640717.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s7640717.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6799549\/","id":"6799549","publisher":"电子工业出版社","isbn10":"7121144751","isbn13":"9787121144752","title":"实战Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/6799549","alt_title":"","author_intro":"清华大学博士，解放军理工大学教授、学科带头人，中国云计算专家委员会委员。主要研究方向为信息网格和云计算，完成科研课题18项，发表论文70余篇，获部级科技进步奖6项。曾夺得国际计算机排序比赛冠军，并两次夺得全国高校科技比赛最高奖，获“全军十大学习成才标兵”、“南京十大杰出青年”和“清华大学学术新秀”等称号。2002年首倡的“网格计算池”和2003年研发的“反垃圾邮件网格”分别为云计算和云安全的前身。创办了知名的中国网格(chinagrid．net)和中国云计算(chinacloud．cn)网站","summary":"《实战Hadoop:开启通向云计算的捷径》讲述了：作为谷歌云计算基础架构的模仿实现，Hadoop堪称业界最经典的开源云计算平台软件。《实战Hadoop:开启通向云计算的捷径》是原著的Hadoop编程技术书籍，是云计算专家刘鹏教授继《云计算》教材取得成功后，再次组织团队精心编写的又一力作，其作者均来自拥有丰富实践经验的云计算技术研发和教学团队。\n该书强调动手、强调实战，以风趣幽默的语言和一系列生动的实战应用案例，系统地讲授了Hadoop的核心技术和扩展技术，包括： HDFS、MapReduce、HBase、Hive、Pig、Cassandra、Chukwa和ZooKeeper等，并给出了3个完整的Hadoop云计算综合应用实例，最后介绍了保障Hadoop平台可靠性的方法。\n《实战Hadoop:开启通向云计算的捷径》读者对象为各类云计算相关企业、高校和科研机构的研发人员，亦适合作为高校研究生和本科生教材。","price":"59.00元"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"Hadoop源代码分析","author":["张鑫"],"pubdate":"2013-6","tags":[{"count":7,"name":"hadoop","title":"hadoop"},{"count":3,"name":"hadoop源码","title":"hadoop源码"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26722499.jpg","binding":"","translator":[],"catalog":"","pages":"644","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s26722499.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s26722499.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26722499.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24714270\/","id":"24714270","publisher":"中国铁道出版社","isbn10":"7113163661","isbn13":"9787113163662","title":"Hadoop源代码分析-深入云计算","url":"https:\/\/api.douban.com\/v2\/book\/24714270","alt_title":"","author_intro":"","summary":"本书是一本全面细致的介绍和分析Hadoop源码和内部工作机理的的一本技术书籍。本书通过对Hadoop内部源码详细细致的解析，使得读者能够快速高效的理解Hadoop的内部工作机制，了解Hadoop内部源码架构，快速高效的上手Hadoop，对Hadoop有深刻的认识。同时是国内第一本详细介绍Hadoop源码的书籍。","price":"89.00元"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"Recipes for Scaling Up with Hadoop and Spark","author":["Mahmoud Parsian"],"pubdate":"2015-5-23","tags":[{"count":8,"name":"Hadoop","title":"Hadoop"},{"count":7,"name":"Spark","title":"Spark"},{"count":4,"name":"计算机","title":"计算机"},{"count":4,"name":"Data","title":"Data"},{"count":3,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"英文版","title":"英文版"},{"count":1,"name":"spark","title":"spark"},{"count":1,"name":"Machine.Learning","title":"Machine.Learning"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28005883.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"778","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28005883.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28005883.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28005883.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25974637\/","id":"25974637","publisher":"O'Reilly Media","isbn10":"1491906189","isbn13":"9781491906187","title":"Data Algorithms","url":"https:\/\/api.douban.com\/v2\/book\/25974637","alt_title":"","author_intro":"","summary":"","price":"USD 69.99"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"Hadoop源代码情景分析","author":["毛德操"],"pubdate":"2017-4-30","tags":[{"count":6,"name":"Hadoop","title":"Hadoop"},{"count":4,"name":"毛德操","title":"毛德操"},{"count":3,"name":"hadoop","title":"hadoop"},{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"源码分析","title":"源码分析"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"#FDP#","title":"#FDP#"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29560437.jpg","binding":"平装","translator":[],"catalog":"第1章 大数据与Hadoop\n1.1 什么是大数据\n1.2 大数据的用途\n1.3 并行计算\n1.4 数据流\n1.5 函数式程序设计与Lambda演算\n1.6 MapReduce\n1.7 大数据处理平台\n1.8 Hadoop的由来和发展\n1.9 Hadoop的MapReduce计算框架\n1.10 Hadoop的分布式容错文件系统HDFS\n第2章 研究方法\n2.1 摘要卡片\n2.2 情景分析\n2.3 面向对象的程序设计\n2.4 怎样阅读分析Hadoop的代码\n第3章 Hadoop集群和YARN\n3.1 Hadoop集群\n3.2 Hadoop系统的结构\n3.3 Hadoop的YARN框架\n3.4 状态机\n3.5 资源管理器ResourceManager\n3.6 资源调度器ResourceScheduler\n第4章 Hadoop的RPC机制\n4.1 RPC与RMI\n4.2 ProtoBuf\n4.3 Java的Reflection机制\n4.4 RM节点上的RPC服务\n4.5 RPC客户端的创建\n第5章 Hadoop作业的提交\n5.1 从“地方”到“中央”\n5.2 示例一：采用老API的ValueAggregatorJob\n5.3 示例二：采用新API的WordCount\n5.4 示例三：采用ToolRunner的QuasiMonteCarlo\n5.5 从Job.submit()开始的第二段流程\n5.6 YARNRunner和ResourceMgrDelegate\n第6章 作业的调度与指派\n6.1 作业的受理\n6.2 NM节点的心跳和容器周转\n6.3 容器的分配\n第7章 NodeManager与任务投运\n7.1 AMLauncher与任务投运\n7.2 MRAppMaster或AM的创建\n7.3 资源本地化\n7.4 容器的投运\n第8章 MRAppMaster与作业投运\n8.1 MRAppMaster\n8.2 App资源与容器\n8.3 容器的跨节点投送和启动\n8.4 目标节点上的容器投运\n8.5 Uber模式下的本地容器分配与投运\n8.6 任务的启动\n8.7 MapTask的运行\n8.8 ReduceTask的投运\n第9章 YARN子系统的计算框架\n9.1 MapReduce框架\n9.2 Streaming框架\n9.3 Chain框架\n9.4 Client与ApplicationMaster\n第10章 MapReduce框架中的数据流\n10.1 数据流和工作流\n10.2 Mapper的输入\n10.3 Mapper的输出缓冲区MapOutputBuffer\n10.4 作为Collector的MapOutputBuffer\n10.5 环形缓冲区kvbuffer\n10.6 对MapoutputBuffer的输出\n10.7 Sort和Spill\n10.8 Map计算的终结与Spill文件的合并\n10.9 Reduce阶段\n10.10 Merge\n10.11 Reduce阶段的输入和输出\n第11章 Hadoop的文件系统HDFS\n11.1 文件的分布与容错\n11.2 目录节点NameNode\n11.3 FSNamesystem\n11.4 文件系统目录FSDirectory\n11.5 文件系统映像FsImage\n11.6 文件系统更改记录FSEditLog\n11.7 FSEditLog与Journal\n11.8 EditLog记录的重演\n11.9 版本升级与故障恢复\n第12章 HDFS的DataNode\n12.1 DataNode\n12.2 数据块的存储\n12.3 RamDisk复份的持久化存储\n12.4 目录扫描线程DirectoryScanner\n12.5 数据块扫描线程DataBlockScanner\n第13章 DataNode与NameNode的互动\n13.1 DataNode与NameNode的互动\n13.2 心跳HeartBeat\n13.3 BlockReport\n第14章 DataNode间的互动\n14.1 数据块的接收和存储\n14.2 命令DNA_TRANSFER的执行\n第15章 HDFS的文件访问\n15.1 DistributedFileSystem和DFSClient\n15.2 FsShell\n15.3 HDFS的打开文件流程\n15.4 HDFS的读文件流程\n15.5 HDFS的创建文件流程\n15.6 文件租约\n15.7 HDFS的写文件流程\n15.8 实例\n第16章 Hadoop的容错机制\n16.1 容错与高可用\n16.2 HDFS的HA机制\n16.3 NameNode的倒换\n16.4 Zookeeper与自动倒换\n16.5 YARN的HA机制\n第17章 Hadoop的安全机制\n17.1 大数据集群的安全问题\n17.2 UGI、Token和ACL\n17.3 UGI的来源和流转\n17.4 Token的使用\n第18章 Hadoop的人机界面\n18.1 Hadoop的命令行界面\n18.2 Hadoop的Web界面\n18.3 Dependency Inject和Annotation\n18.4 对网页的访问\n第19章 Hadoop的部署和启动\n19.1 Hadoop的运维脚本\n19.2 Hadoop的部署与启动\n19.3 Hadoop的日常使用\n19.4 Hadoop平台的关闭\n第20章 Spark的优化与改进\n20.1 Spark与Hadoop\n20.2 RDD与Stage——概念与思路\n20.3 RDD的存储和引用\n20.4 DStream\n20.5 拓扑的灵活性和多样性\n20.6 性能的提升\n20.7 使用的方便性\n20.8 几个重要的类及其作用\n参考资料","pages":"771","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29560437.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29560437.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29560437.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27155240\/","id":"27155240","publisher":"浙江大学出版社","isbn10":"7308166694","isbn13":"9787308166690","title":"大数据处理系统","url":"https:\/\/api.douban.com\/v2\/book\/27155240","alt_title":"","author_intro":"毛德操，著名计算机专家，浙江大学教授，浙大网新科技首席科学家，连连支付大数据与区块链特别顾问。曾留学美国Umas大学，获得计算机硕士学位。著有重磅著作《LINUX核心源代码情景分析》和《Windows内核情景分析：采用开源代码ReactOS（上、下册）》，影响了整整一代大学生和工程师。","summary":"Hadoop是目前重要的一种开源的大数据处理平台，读懂Hadoop的源代码，深入理解其各种机理，对于掌握大数据处理的技术有着显而易见的重要性。 本书从大数据处理的原理开始，讲到Hadoop的由来，进而讲述对于代码的研究方法，然后以Hadoop作为样本，较为详尽地逐一分析大数据处理平台各核心组成部分的代码，并从宏观上讲述这些部分的联系和作用。 本书沿用作者独特而广受欢迎的情景分析方法和风格，深入浅出直白易懂，可以作为大数据系统高级课程的教材，也可用作计算机软件专业和其他相关专业大学本科高年级学生和研究生深入学习大数据系统的参考书。同时，还可以作为各行业从事软件开发和数据挖掘的工程师、研究人员以及其他对大数据处理技术感兴趣者的自学教材。","price":"CNY 128.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Hadoop, Lustre, Google File System, Andrew File System, Offsystem, Distributed File System, Ceph","author":["Books, LLC"],"pubdate":"2010-05-03","tags":[{"count":10,"name":"Distributed.System","title":"Distributed.System"},{"count":8,"name":"分布式","title":"分布式"},{"count":6,"name":"文件系统","title":"文件系统"},{"count":2,"name":"并行","title":"并行"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":2,"name":"Distributed","title":"Distributed"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"DEV","title":"DEV"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s4436404.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"28","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s4436404.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s4436404.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s4436404.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4946995\/","id":"4946995","publisher":"Books LLC","isbn10":"115534653X","isbn13":"9781155346533","title":"Distributed File Systems","url":"https:\/\/api.douban.com\/v2\/book\/4946995","alt_title":"","author_intro":"","summary":"","price":"USD 19.99"},{"rating":{"max":10,"numRaters":20,"average":"7.4","min":0},"subtitle":"","author":["Arun C. Murthy","Vinod Kumar Vavilapalli","Doug Eadline","Joseph Niemiec","Jeff Markham"],"pubdate":"2015-4-13","tags":[{"count":25,"name":"Yarn","title":"Yarn"},{"count":20,"name":"大数据","title":"大数据"},{"count":20,"name":"Hadoop","title":"Hadoop"},{"count":12,"name":"hadoop","title":"hadoop"},{"count":3,"name":"计算机","title":"计算机"},{"count":2,"name":"数据平台","title":"数据平台"},{"count":1,"name":"HADOOP","title":"HADOOP"},{"count":1,"name":"2019","title":"2019"}],"origin_title":"Apache Hadoop Yarn: Moving Beyond Mapreduce and Batch Processing with Apache Hadoop 2","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28060254.jpg","binding":"平装","translator":["罗韩梅","洪志国","杨旭"],"catalog":"译者序\n推荐序一\n推荐序二\n前　言\n第1章　Apache Hadoop YARN：简明历史及基本原理 1\n1.1　引言 1\n1.2　Apache Hadoop 2\n1.3　阶段0：Ad Hoc集群时期 3\n1.4　阶段1：Hadoop on Demand 3\n1.4.1　HOD世界中的HDFS 5\n1.4.2　HOD的特色及优势 5\n1.4.3　HOD的缺点 6\n1.5　阶段2：共享计算集群的黎明 8\n1.5.1　共享集群的演进 8\n1.5.2　使用共享MapReduce集群的问题 13\n1.6　阶段3：YARN的出现 15\n1.7　小结 16\n第2章　Apache Hadoop YARN安装快速入门 17\n2.1　准备开始 18\n2.2　配置单节点YARN集群的步骤 18\n2.2.1　第1步：下载Apache Hadoop 18\n2.2.2　第2步：设置JAVA_HOME 19\n2.2.3　第3步：创建用户和用户组 19\n2.2.4　第4步：创建数据和日志目录 19\n2.2.5　第5步：配置core-site.xml 19\n2.2.6　第6步：配置hdfs-site.xml 20\n2.2.7　第7步：配置mapred-site.xml 21\n2.2.8　第8步：配置yarn-site.xml 21\n2.2.9　第9步：调整Java堆大小 21\n2.2.10　第10步：格式化HDFS 22\n2.2.11　第11步：启动HDFS服务 22\n2.2.12　第12步：启动YARN服务 23\n2.2.13　第13步：通过Web接口验证正在运行的服务 24\n2.3　运行MapReduce示例程序 25\n2.4　小结 26\n第3章　Apache Hadoop YARN的核心概念 27\n3.1　不只是MapReduce 27\n3.2　Apache Hadoop MapReduce 29\n3.2.1　支持非MapReduce应用的需求 30\n3.2.2　解决可扩展性 30\n3.2.3　提高资源使用率 30\n3.2.4　用户敏捷性 30\n3.3　Apache Hadoop YARN 31\n3.4　YARN组件 32\n3.4.1　ResourceManager 32\n3.4.2　ApplicationMaster 32\n3.4.3　资源模型 33\n3.4.4　ResourceRequest和Container 33\n3.4.5　Container规范 34\n3.5　小结 34\n第4章　YARN组件的功能概述 35\n4.1　体系架构概述 35\n4.2　ResourceManager 37\n4.3　YARN调度组件 38\n4.3.1　FIFO调度器 38\n4.3.2　Capacity调度器 38\n4.3.3　Fair调度器 39\n4.4　Container 40\n4.5　NodeManager 40\n4.6　ApplicationMaster 41\n4.7　YARN资源模型 41\n4.7.1　客户端资源请求 42\n4.7.2　ApplicationMaster Container的分配 42\n4.7.3　ApplicationMaster与Container管理器的通信 44\n4.8　管理应用程序的依赖文件 44\n4.8.1　LocalResource的定义 44\n4.8.2　LocalResource时间戳 45\n4.8.3　LocalResource类型 46\n4.8.4　LocalResource的可见性 46\n4.8.5　LocalResource的生命周期 47\n4.9　小结 47\n第5章　安装Apache Hadoop YARN 49\n5.1　基础知识 49\n5.2　系统准备 50\n5.2.1　第1步：安装EPEL和pdsh 50\n5.2.2　第2步：生成和分发ssh密钥 51\n5.3　基于脚本安装Hadoop 2 51\n5.3.1　JDK选项 52\n5.3.2　第1步：下载并解压脚本 52\n5.3.3　第2步：设置脚本里的变量 52\n5.3.4　第3步：提供节点名字 53\n5.3.5　第4步：运行脚本 54\n5.3.6　第5步：验证安装 54\n5.4　基于脚本的卸载 57\n5.5　配置文件处理 57\n5.6　配置文件设置 57\n5.6.1　core-site.xml 57\n5.6.2　hdfs-site.xml 58\n5.6.3　mapred-site.xml 58\n5.6.4　yarn-site.xml 59\n5.7　启动脚本 59\n5.8　用Apache Ambari安装Hadoop 60\n5.8.1　基于Ambari安装Hadoop 61\n5.8.2　第1步：检查要求 61\n5.8.3　第2步：安装Ambari服务器 62\n5.8.4　第3步：安装和启动Ambari代理 62\n5.8.5　第4步：启动Ambari服务器 62\n5.8.6　第5步：安装HDP2.X集群 63\n5.9　小结 70\n第6章　Apache Hadoop YARN的管理 71\n6.1　基于脚本的配置 71\n6.2　监控集群健康：Nagios 76\n6.2.1　监控基本的Hadoop服务 77\n6.2.2　监控JVM 80\n6.3　实时监控系统：Ganglia 82\n6.4　使用Ambari管理 83\n6.5　JVM分析 88\n6.6　基本的YARN管理 90\n6.6.1　YARN的管理工具 91\n6.6.2　增加或关闭YARN节点 92\n6.6.3　Capacity调度器的配置 92\n6.6.4　YARN的Web代理 92\n6.6.5　使用JobHistoryServer 93\n6.6.6　更新用户到用户组的映射 93\n6.6.7　更新超级用户代理群组映射 93\n6.6.8　更新ResourceManager管理的ACL 93\n6.6.9　重新加载服务级授权策略文件 94\n6.6.10　管理YARN作业 94\n6.6.11　设置Container的内存 94\n6.6.12　设置Container核数 94\n6.6.13　设置MapReduce配置项 95\n6.6.14　用户日志管理 95\n6.7　小结 97\n第7章　Apache Hadoop YARN的架构指南 98\n7.1　概述 98\n7.2　ResourceManager 99\n7.2.1　ResourceManager组件概述 100\n7.2.2　客户端和ResourceManager交互 100\n7.2.3　应用程序和ResourceManager的通信 102\n7.2.4　节点和ResourceManager的通信 103\n7.2.5　ResourceManager核心组件 104\n7.2.6　ResourceManager安全相关的组件 105\n7.3　NodeManager 109\n7.3.1　NodeManager各组件概述 109\n7.3.2　NodeManager组件 110\n7.3.3　NodeManager安全组件 116\n7.3.4　NodeManager的重要功能 116\n7.4　ApplicationMaster 117\n7.4.1　概述 117\n7.4.2　活跃 119\n7.4.3　资源需求 119\n7.4.4　调度 120\n7.4.5　调度协议和本地性 121\n7.4.6　启动Container 123\n7.4.7　完成的Container 124\n7.4.8　ApplicationMaster失败和恢复 124\n7.4.9　协调和输出提交 124\n7.4.10　为客户端提供信息 125\n7.4.11　安全 125\n7.4.12　ApplicationMaster退出时进行清理 125\n7.5　YARN Container 125\n7.5.1　Container运行环境 126\n7.5.2　与ApplicationMaster通信 127\n7.6　应用程序开发者的摘要 127\n7.7　小结 128\n第8章　YARN中的Capacity调度器 129\n8.1　Capacity调度器介绍 129\n8.1.1　多租户弹性 130\n8.1.2　安全 130\n8.1.3　资源感知 130\n8.1.4　细粒度调度 130\n8.1.5　本地化 131\n8.1.6　调度策略 131\n8.2　Capacity调度器配置 131\n8.3　队列 132\n8.4　层级队列 132\n8.4.1　关键特性 132\n8.4.2　队列间的调度 132\n8.4.3　定义层级队列 133\n8.5　队列访问控制 134\n8.6　层级队列Capacity管理 135\n8.7　用户级别限制 137\n8.8　预订 139\n8.9　队列的状态 140\n8.10　应用程序的限制 141\n8.11　用户接口 141\n8.12　小结 142\n第9章　Apache Hadoop YARN下的MapReduce 143\n9.1　运行Hadoop YARN MapReduce实例 143\n9.1.1　可利用的实例列表 143\n9.1.2　运行Pi实例 144\n9.1.3　使用Web GUI监控实例 146\n9.1.4　运行terasort测试 151\n9.1.5　运行TestDFSIO基准测试 151\n9.2　MapReduce兼容性 152\n9.3　MapReduce ApplicationMaster 153\n9.3.1　启用ApplicationMaster的重启 153\n9.3.2　启用已完成任务的恢复 153\n9.3.3　JobHistory服务 153\n9.4　计算一个节点的容量 154\n9.5　Shuffle服务的变动 155\n9.6　运行已有的第1版Hadoop的应用程序 155\n9.6.1　org.apache.hadoop.mapred API的二进制兼容性 155\n9.6.2　org.apache.hadoop.mapreduce API的源码兼容性 155\n9.6.3　命令行脚本的兼容性 156\n9.6.4　MRv1和早期MRv2（0.23.x）应用程序兼容性的权衡 156\n9.7　运行第1版MapReduce现有的代码 157\n9.7.1　在YARN上运行Apache Pig脚本 157\n9.7.2　在YARN上运行Apache Hive查询 157\n9.7.3　在YARN上运行Apache Oozie工作流 157\n9.8　高级特性 158\n9.8.1　Uber作业 158\n9.8.2　可插拔的Shuffle和Sort 158\n9.9　小结 159\n第10章　Apache Hadoop YARN应用程序范例 160\n10.1　YARN客户端 161\n10.2　ApplicationMaster 175\n10.3　小结 192\n第11章　使用Apache Hadoop YARN Distributed-Shell 193\n11.1　使用YARN Distributed-Shell 193\n11.1.1　简单例子 194\n11.1.2　使用更多Container 195\n11.1.3　带有shell命令参数的Distributed-Shell 195\n11.2　Distributed-Shell内部实现 197\n11.2.1　应用的常量定义 198\n11.2.2　Client 198\n11.2.3　ApplicationMaster 201\n11.2.4　普通Container 205\n11.3　小结 205\n第12章　Apache Hadoop YARN框架 206\n12.1　Distributed-Shell 206\n12.2　Hadoop MapReduce 206\n12.3　Apache Tez 207\n12.4　Apache Giraph 207\n12.5　Hoya：HBase on YARN 208\n12.6　Dryad on YARN 208\n12.7　Apache Spark 208\n12.8　Apache Storm 209\n12.9　REEF：Retainable Evaluator Execution Framework 209\n12.10　Hamster：Hadoop and MPI on the Same Cluster 210\n12.11　小结 210\n附录A　补充内容和代码下载 211\n附录B　YARN的安装脚本 212\n附录C　YARN的管理脚本 224\n附录D　Nagios模块 229\n附录E　资源及附加资料 235\n附录F　HDFS快速参考 237","pages":"242","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28060254.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28060254.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28060254.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26377893\/","id":"26377893","publisher":"机械工业出版社","isbn10":"7111491815","isbn13":"9787111491811","title":"Hadoop YARN权威指南","url":"https:\/\/api.douban.com\/v2\/book\/26377893","alt_title":"Apache Hadoop Yarn: Moving Beyond Mapreduce and Batch Processing with Apache Hadoop 2","author_intro":"Arun C. Murthy，自从Apache Hadoop启动以来就是一个全职的贡献者，并创立了Apache YARN项目。他作为雅虎Hadoop MapReduce开发团队的架构师和领导者，负责为整个雅虎公司提供MapReduce技术服务。他是Hortonworks公司的创始人和架构师，Hortonworks公司由雅虎Hadoop团队的核心成员组成，并加速了Hadoop的发展和普及。\nVinod Kumar Vavilapalli 是Hortonworks公司的首席开发者和Apache Hadoop YARN的项目负责人。他之前参与的项目有Hadoop On Deamand、Hadoop-0.20、Capacity调度器、Hadoop安全性和MapReduce。\nDoug Eadline博士作为Linux的HPC集群革命的实践者和见证者开始了他的职业生涯，目前在为大数据分析撰写文档。\nJoseph Niemiec是Hortonworks大数据解决方案工程师，致力于为许多财富1000强公司设计Hadoop解决方案。\nJeff Markham是Hortonworks解决方案工程师。此前，他为VMware、Red Hat和IBM开发过分布式数据应用。","summary":"《Hadoop YARN权威指南》由YARN的创建和开发团队亲笔撰写，Altiscale的CEO作序鼎力推荐，是使用Hadoop YARN建立分布式、大数据应用的权威指南。书中利用多个实例，详细介绍Hadoop YARN的安装和管理，以帮助用户使用YARN进行应用开发，并在YARN上运行除了MapReduce之外的新框架。\n《Hadoop YARN权威指南》共12章，第1章讲述Apache Hadoop YARN产生和发展的历史；第2章讲解在单台机器（工作站、服务器或笔记本电脑）上快速安装Hadoop 2.0；第3章介绍Apache Hadoop YARN资源管理器；第4章简要介绍YARN组件的功能，帮助读者开始深入了解YARN；第5章详细讲解YARN的安装方法，包括一个基于脚本的手动安装，以及使用Apache Ambari基于GUI的安装；第6章讲述对YARN集群的管理，涉及一些基本的YARN管理场景，介绍如何利用Nagios和Ganglia监控集群，论述对JVM的监视，并介绍Ambari的管理界面；第7章深入探究YARN的架构，向读者展示YARN的内部工作原因；第8章深入讨论Capacity调度器；第9章描述基于现有MapReduce的应用程序如何继续工作以及利用YARN的优势；第10章通过创建一个JBoss Application Server集群的过程，讲述如何构建一个YARN应用程序；第11章描述建立在YARN上的典型示例程序distributed shell的使用和内部情况；第12章总结运行在YARN上的新兴开源框架。最后提供6个附录，包括补充内容和代码下载、YARN的安装脚本、YARN管理脚本、Nagios模块、资源及其他信息、HDFS快速参考。","series":{"id":"19432","title":"大数据技术丛书"},"price":"59.00元"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"Real-Time Applications with Storm, Spark, and More Hadoop Alternatives","author":["Vijay Srinivas Agneeswaran"],"pubdate":"2014-5-17","tags":[{"count":5,"name":"大数据","title":"大数据"},{"count":5,"name":"Hadoop","title":"Hadoop"},{"count":3,"name":"Mining","title":"Mining"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":2,"name":"Spark","title":"Spark"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"数据","title":"数据"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27290304.jpg","binding":"Hardcover","translator":[],"catalog":"","pages":"240","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27290304.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27290304.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27290304.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25893854\/","id":"25893854","publisher":"Pearson FT Press","isbn10":"0133837947","isbn13":"9780133837940","title":"Big Data Analytics Beyond Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/25893854","alt_title":"","author_intro":"","summary":"","price":"USD 69.99"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"Assessing Azure, Amazon EC2, Google App Engine and Hadoop for IT Decision Making and Developer Career Growth","author":["Paul Fisher","Rajiv Pant","Jeremy Edberg"],"pubdate":"2010-02-01","tags":[{"count":2,"name":"hadoop","title":"hadoop"},{"count":2,"name":"cloud","title":"cloud"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4181642.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"400","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s4181642.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s4181642.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4181642.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4297306\/","id":"4297306","publisher":"Apress","isbn10":"1430227249","isbn13":"9781430227243","title":"Cloud Computing","url":"https:\/\/api.douban.com\/v2\/book\/4297306","alt_title":"","author_intro":"","summary":"This book is an industry-leading primer on cloud computing: its background, the purpose it serves, how the cloud can be best utilized, which platforms offer which features, and how to get started. Cloud computing is one of today's most interesting technologies, but remains a bit mercurial and mysterious. It can mean a lot of different things to different people. By tracing several real-world scenarios--from the requirement gathering through the design, coding, and deployment phases--this book will give you a clear understanding of what it takes to build and deploy a successful, scalable application that leverages cloud computing platforms and tools. Furthermore, this book emphasizes the critical differences between legacy IT approaches, and explains the methodologies and features available through a cloud-based model. Frameworks and tools such as Amazon EC2, Azure, Google App Engine, Hadoop, CouchDB, Memcache, and JavaSpaces are introduced, illustrating how each technology is best utilized within the context of cloud computing. In the end, this book clears the air and empowers you--whether you're an IT decision maker or a career progression-minded developer--with the information and knowledge necessary to fully consider the implications of migrating to, developing, and\/or using cloud-driven applications. What you'll learn How to take the vagueness out of cloud computing The core concepts and considerations of cloud computing When and when not to go to the cloud How to weigh the varying factors that go into ROI-based decisions of going into the cloud How to use various cloud computing platforms such as Amazon, Azure, and Google App Engine How to use cloud-based techniques and strategies Who is this book for? This book is intended for anyone interested in the shift currently occurring in the IT industry, in which IT resources and CPU utilization are becoming standard commodities. This book covers both general theoretical concepts and hands-on, real-world examples--targeting this book to both businesspeople and developers alike.","price":"USD 34.99"},{"rating":{"max":10,"numRaters":48,"average":"9.0","min":0},"subtitle":"4th Edition","author":["Tom White"],"pubdate":"2015-4-11","tags":[{"count":31,"name":"Hadoop","title":"Hadoop"},{"count":24,"name":"大数据","title":"大数据"},{"count":14,"name":"BigData","title":"BigData"},{"count":11,"name":"计算机","title":"计算机"},{"count":11,"name":"分布式","title":"分布式"},{"count":8,"name":"hadoop","title":"hadoop"},{"count":5,"name":"机器学习","title":"机器学习"},{"count":4,"name":"O'Reilly","title":"O'Reilly"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28267249.jpg","binding":"Paperback","translator":[],"catalog":"Hadoop Fundamentals\nChapter 1Meet Hadoop\nData!\nData Storage and Analysis\nQuerying All Your Data\nBeyond Batch\nComparison with Other Systems\nA Brief History of Apache Hadoop\nWhat’s in This Book?\nChapter 2MapReduce\nA Weather Dataset\nAnalyzing the Data with Unix Tools\nAnalyzing the Data with Hadoop\nScaling Out\nHadoop Streaming\nChapter 3The Hadoop Distributed Filesystem\nThe Design of HDFS\nHDFS Concepts\nThe Command-Line Interface\nHadoop Filesystems\nThe Java Interface\nData Flow\nParallel Copying with distcp\nChapter 4YARN\nAnatomy of a YARN Application Run\nYARN Compared to MapReduce 1\nScheduling in YARN\nFurther Reading\nChapter 5Hadoop I\/O\nData Integrity\nCompression\nSerialization\nFile-Based Data Structures\nMapReduce\nChapter 1Developing a MapReduce Application\nThe Configuration API\nSetting Up the Development Environment\nWriting a Unit Test with MRUnit\nRunning Locally on Test Data\nRunning on a Cluster\nTuning a Job\nMapReduce Workflows\nChapter 2How MapReduce Works\nAnatomy of a MapReduce Job Run\nFailures\nShuffle and Sort\nTask Execution\nChapter 3MapReduce Types and Formats\nMapReduce Types\nInput Formats\nOutput Formats\nChapter 4MapReduce Features\nCounters\nSorting\nJoins\nSide Data Distribution\nMapReduce Library Classes\nHadoop Operations\nChapter 1Setting Up a Hadoop Cluster\nCluster Specification\nCluster Setup and Installation\nHadoop Configuration\nSecurity\nBenchmarking a Hadoop Cluster\nChapter 2Administering Hadoop\nHDFS\nMonitoring\nMaintenance\nRelated Projects\nChapter 1Avro\nAvro Data Types and Schemas\nIn-Memory Serialization and Deserialization\nAvro Datafiles\nInteroperability\nSchema Resolution\nSort Order\nAvro MapReduce\nSorting Using Avro MapReduce\nAvro in Other Languages\nChapter 2Parquet\nData Model\nParquet File Format\nParquet Configuration\nWriting and Reading Parquet Files\nParquet MapReduce\nChapter 3Flume\nInstalling Flume\nAn Example\nTransactions and Reliability\nThe HDFS Sink\nFan Out\nDistribution: Agent Tiers\nSink Groups\nIntegrating Flume with Applications\nComponent Catalog\nFurther Reading\nChapter 4Sqoop\nGetting Sqoop\nSqoop Connectors\nA Sample Import\nGenerated Code\nImports: A Deeper Look\nWorking with Imported Data\nImporting Large Objects\nPerforming an Export\nExports: A Deeper Look\nFurther Reading\nChapter 5Pig\nInstalling and Running Pig\nAn Example\nComparison with Databases\nPig Latin\nUser-Defined Functions\nData Processing Operators\nPig in Practice\nFurther Reading\nChapter 6Hive\nInstalling Hive\nAn Example\nRunning Hive\nComparison with Traditional Databases\nHiveQL\nTables\nQuerying Data\nUser-Defined Functions\nFurther Reading\nChapter 7Crunch\nAn Example\nThe Core Crunch API\nPipeline Execution\nCrunch Libraries\nFurther Reading\nChapter 8Spark\nInstalling Spark\nAn Example\nResilient Distributed Datasets\nShared Variables\nAnatomy of a Spark Job Run\nExecutors and Cluster Managers\nFurther Reading\nChapter 9HBase\nHBasics\nConcepts\nInstallation\nClients\nBuilding an Online Query Application\nHBase Versus RDBMS\nPraxis\nFurther Reading\nChapter 10ZooKeeper\nInstalling and Running ZooKeeper\nAn Example\nThe ZooKeeper Service\nBuilding Applications with ZooKeeper\nZooKeeper in Production\nFurther Reading\nCase Studies\nChapter 1Composable Data at Cerner\nFrom CPUs to Semantic Integration\nEnter Apache Crunch\nBuilding a Complete Picture\nIntegrating Healthcare Data\nComposability over Frameworks\nMoving Forward\nChapter 2Biological Data Science: Saving Lives with Software\nThe Structure of DNA\nThe Genetic Code: Turning DNA Letters into Proteins\nThinking of DNA as Source Code\nThe Human Genome Project and Reference Genomes\nSequencing and Aligning DNA\nADAM, A Scalable Genome Analysis Platform\nFrom Personalized Ads to Personalized Medicine\nJoin In\nChapter 3Cascading\nFields, Tuples, and Pipes\nOperations\nTaps, Schemes, and Flows\nCascading in Practice\nFlexibility\nHadoop and Cascading at ShareThis\nSummary\nAppendix Installing Apache Hadoop\nPrerequisites\nInstallation\nConfiguration\nAppendix Cloudera’s Distribution Including Apache Hadoop\nAppendix Preparing the NCDC Weather Data\nAppendix The Old and New Java MapReduce APIs\nCase Studies\nChapter 1Composable Data at Cerner\nFrom CPUs to Semantic Integration\nEnter Apache Crunch\nBuilding a Complete Picture\nIntegrating Healthcare Data\nComposability over Frameworks\nMoving Forward\nChapter 2Biological Data Science: Saving Lives with Software\nThe Structure of DNA\nThe Genetic Code: Turning DNA Letters into Proteins\nThinking of DNA as Source Code\nThe Human Genome Project and Reference Genomes\nSequencing and Aligning DNA\nADAM, A Scalable Genome Analysis Platform\nFrom Personalized Ads to Personalized Medicine\nJoin In\nChapter 3Cascading\nFields, Tuples, and Pipes\nOperations\nTaps, Schemes, and Flows\nCascading in Practice\nFlexibility\nHadoop and Cascading at ShareThis\nSummary\nAppendix Installing Apache Hadoop\nPrerequisites\nInstallation\nConfiguration\nAppendix Cloudera’s Distribution Including Apache Hadoop\nAppendix Preparing the NCDC Weather Data\nAppendix The Old and New Java MapReduce APIs","pages":"756","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28267249.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28267249.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28267249.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26359169\/","id":"26359169","publisher":"O'Reilly Media","isbn10":"1491901632","isbn13":"9781491901632","title":"Hadoop: The Definitive Guide","url":"https:\/\/api.douban.com\/v2\/book\/26359169","alt_title":"","author_intro":"Tom White has been an Apache Hadoop committer since February 2007, and is a member of the Apache Software Foundation. He works for Cloudera, a company set up to offer Hadoop support and training. Previously he was as an independent Hadoop consultant, working with companies to set up, use, and extend Hadoop. He has written numerous articles for O'Reilly, java.net and IBM's developerWorks, and has spoken at several conferences, including at ApacheCon 2008 on Hadoop. Tom has a Bachelor's degree in Mathematics from the University of Cambridge and a Master's in Philosophy of Science from the University of Leeds, UK.","summary":"Get ready to unlock the power of your data. With the fourth edition of this comprehensive guide, you’ll learn how to build and maintain reliable, scalable, distributed systems with Apache Hadoop. This book is ideal for programmers looking to analyze datasets of any size, and for administrators who want to set up and run Hadoop clusters.\nUsing Hadoop 2 exclusively, author Tom White presents new chapters on YARN and several Hadoop-related projects such as Parquet, Flume, Crunch, and Spark. You’ll learn about recent changes to Hadoop, and explore new case studies on Hadoop’s role in healthcare systems and genomics data processing.\nLearn fundamental components such as MapReduce, HDFS, and YARN\nExplore MapReduce in depth, including steps for developing applications with it\nSet up and maintain a Hadoop cluster running HDFS and MapReduce on YARN\nLearn two data formats: Avro for data serialization and Parquet for nested data\nUse data ingestion tools such as Flume (for streaming data) and Sqoop (for bulk data transfer)\nUnderstand how high-level data processing tools like Pig, Hive, Crunch, and Spark work with Hadoop\nLearn the HBase distributed database and the ZooKeeper distributed configuration service","price":"USD 49.99"},{"rating":{"max":10,"numRaters":19,"average":"8.3","min":0},"subtitle":"Includes 85 Techniques","author":["Alex Holmes"],"pubdate":"2012-10-13","tags":[{"count":25,"name":"Hadoop","title":"Hadoop"},{"count":8,"name":"大数据","title":"大数据"},{"count":5,"name":"Programming","title":"Programming"},{"count":2,"name":"分布式","title":"分布式"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":2,"name":"bigdata","title":"bigdata"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s23110381.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"536","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s23110381.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s23110381.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s23110381.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10748575\/","id":"10748575","publisher":"Manning Publications","isbn10":"1617290238","isbn13":"9781617290237","title":"Hadoop in Practice","url":"https:\/\/api.douban.com\/v2\/book\/10748575","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":15,"average":"8.4","min":0},"subtitle":"","author":["[英] Garry Turkington"],"pubdate":"2014-1","tags":[{"count":28,"name":"Hadoop","title":"Hadoop"},{"count":12,"name":"大数据","title":"大数据"},{"count":8,"name":"数据挖掘","title":"数据挖掘"},{"count":8,"name":"hadoop","title":"hadoop"},{"count":6,"name":"计算机","title":"计算机"},{"count":6,"name":"入门","title":"入门"},{"count":3,"name":"技术","title":"技术"},{"count":2,"name":"计算机技术","title":"计算机技术"}],"origin_title":"Hadoop beginner’s guide","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27183972.jpg","binding":"平装","translator":["张治起"],"catalog":"第1章　绪论　　1\n1.1 　大数据处理　　1\n1.1.1 　数据的价值　　2\n1.1.2 　受众较少　　2\n1.1.3 　一种不同的方法　　4\n1.1.4 　Hadoop　　7\n1.2 　基于Amazon Web Services的云计算　　12\n1.2.1 　云太多了　　12\n1.2.2 　第三种方法　　12\n1.2.3 　不同类型的成本　　12\n1.2.4 　AWS：Amazon的弹性架构　　13\n1.2.5 　本书内容　　14\n1.3 　小结　　15\n第2章　安装并运行Hadoop　　16\n2.1 　基于本地Ubuntu主机的Hadoop系统　　16\n2.2 　实践环节：检查是否已安装JDK　　17\n2.3 　实践环节：下载Hadoop　　18\n2.4 　实践环节：安装SSH　　19\n2.5 　实践环节：使用Hadoop计算圆周率　　20\n2.6 　实践环节：配置伪分布式模式　　22\n2.7 　实践环节：修改HDFS的根目录　　24\n2.8 　实践环节：格式化NameNode　　25\n2.9 　实践环节：启动Hadoop　　26\n2.10 　实践环节：使用HDFS　　27\n2.11 　实践环节：MapReduce的经典入门程序——字数统计　　28\n2.12 　使用弹性MapReduce　　33\n2.13 　实践环节：使用管理控制台在EMR运行WordCount　　34\n2.13.1 　使用EMR的其他方式　　41\n2.13.2 　AWS生态系统　　42\n2.14 　本地Hadoop与EMR Hadoop的对比　　42\n2.15 　小结　　43\n第3章　理解MapReduce　　44\n3.1 　键值对　　44\n3.1.1 　具体含义　　44\n3.1.2 　为什么采用键\/值数据　　45\n3.1.3 　MapReduce作为一系列键\/值变换　　46\n3.2 　MapReduce的Hadoop Java API　　47\n3.3 　编写MapReduce程序　　50\n3.4 　实践环节：设置classpath　　50\n3.5 　实践环节：实现WordCount　　51\n3.6 　实践环节：构建JAR文件　　53\n3.7 　实践环节：在本地Hadoop集群运行WordCount　　54\n3.8 　实践环节：在EMR上运行WordCount　　54\n3.8.1 　0.20之前版本的Java MapReduce API　　56\n3.8.2 　Hadoop提供的mapper和reducer实现　　57\n3.9 　实践环节：WordCount的简易方法　　58\n3.10 　查看WordCount的运行全貌　　59\n3.10.1 　启动　　59\n3.10.2 　将输入分块　　59\n3.10.3 　任务分配　　60\n3.10.4 　任务启动　　60\n3.10.5 　不断监视JobTracker　　60\n3.10.6 　mapper的输入　　61\n3.10.7 　mapper的执行　　61\n3.10.8 　mapper的输出和reducer的输入　　61\n3.10.9 　分块　　62\n3.10.10　　可选分块函数　　62\n3.10.11　　reducer类的输入　　62\n3.10.12　　reducer类的执行　　63\n3.10.13　　reducer类的输出　　63\n3.10.14　　关机　　63\n3.10.15　　这就是MapReduce的全部　　64\n3.10.16　　也许缺了combiner　　64\n3.11 　实践环节：使用combiner编写WordCount　　64\n3.12 　实践环节：更正使用combiner的WordCount　　65\n3.13 　Hadoop专有数据类型　　67\n3.13.1　　Writable和Writable-Comparable接口　　67\n3.13.2 　wrapper类介绍　　68\n3.14 　实践环节：使用Writable包装类　　69\n3.15 　输入\/输出　　71\n3.15.1　　文件、split和记录　　71\n3.15.2　　InputFormat和RecordReader　　71\n3.15.3　　Hadoop提供的InputFormat　　72\n3.15.4　　Hadoop提供的RecordReader　　73\n3.15.5　　OutputFormat和Record-Writer　　73\n3.15.6　　Hadoop提供的OutputFormat　　73\n3.15.7　　别忘了Sequence files　　74\n3.16 　小结　　74\n第4章　开发MapReduce程序　　75\n4.1 　使用非Java语言操作Hadoop　　75\n4.1.1 　Hadoop Streaming工作原理　　76\n4.1.2　　使用Hadoop Streaming的原因　　76\n4.2 　实践环节：使用Streaming实现Word-Count　　76\n4.3 　分析大数据集　　79\n4.3.1 　获取UFO目击事件数据集　　79\n4.3.2 　了解数据集　　80\n4.4 　实践环节：统计汇总UFO数据　　80\n4.5 　实践环节：统计形状数据　　82\n4.6 　实践环节：找出目击事件的持续时间与UFO形状的关系　　84\n4.7 　实践环节：在命令行中执行形状\/时间分析　　87\n4.8 　实践环节：使用ChainMapper进行字段验证\/分析　　88\n4.9 　实践环节：使用Distributed Cache改进地点输出　　93\n4.10 　计数器、状态和其他输出　　96\n4.11 　实践环节：创建计数器、任务状态和写入日志　　96\n4.12 　小结　　102\n第5章　高级MapReduce技术　　103\n5.1 　初级、高级还是中级　　103\n5.2 　多数据源联结　　103\n5.2.1 　不适合执行联结操作的情况　　104\n5.2.2　　map端联结与reduce端联结的对比　　104\n5.2.3 　匹配账户与销售信息　　105\n5.3 　实践环节：使用MultipleInputs实现reduce端联结　　105\n5.3.1 　实现map端联结　　109\n5.3.2 　是否进行联结　　112\n5.4 　图算法　　112\n5.4.1 　Graph 101　　112\n5.4.2 　图和MapReduce　　112\n5.4.3 　图的表示方法　　113\n5.5 　实践环节：图的表示　　114\n5.6 　实践环节：创建源代码　　115\n5.7 　实践环节：第一次运行作业　　119\n5.8 　实践环节：第二次运行作业　　120\n5.9 　实践环节：第三次运行作业　　121\n5.10 　实践环节：第四次也是最后一次运行作业　　122\n5.10.1 　运行多个作业　　124\n5.10.2 　关于图的终极思考　　124\n5.11 　使用语言无关的数据结构　　124\n5.11.1 　候选技术　　124\n5.11.2 　Avro简介　　125\n5.12 　实践环节：获取并安装Avro　　125\n5.13 　实践环节：定义模式　　126\n5.14 　实践环节：使用Ruby创建Avro源数据　　127\n5.15 　实践环节：使用Java语言编程操作Avro数据　　128\n5.16 　实践环节：在MapReduce中统计UFO形状　　130\n5.17 　实践环节：使用Ruby检查输出数据　　134\n5.18 　实践环节：使用Java检查输出数据　　135\n5.19 　小结　　137\n第6章　故障处理　　138\n6.1 　故障　　138\n6.1.1 　拥抱故障　　138\n6.1.2 　至少不怕出现故障　　139\n6.1.3 　严禁模仿　　139\n6.1.4 　故障类型　　139\n6.1.5 　Hadoop节点故障　　139\n6.2 　实践环节：杀死DataNode进程　　141\n6.3 　实践环节：复制因子的作用　　144\n6.4 　实践环节：故意造成数据块丢失　　146\n6.5 　实践环节：杀死TaskTracker进程　　149\n6.6 　实践环节：杀死JobTracker　　153\n6.7 　实践环节：杀死NameNode进程　　154\n6.8 　实践环节：引发任务故障　　160\n6.9 　数据原因造成的任务故障　　163\n6.10 　实践环节：使用skip模式处理异常数据　　164\n6.11 　小结　　169\n第7章　系统运行与维护　　170\n7.1 　关于EMR的说明　　170\n7.2 　Hadoop配置属性　　171\n7.3 　实践环节：浏览默认属性　　171\n7.3.1 　附加的属性元素　　172\n7.3.2 　默认存储位置　　172\n7.3.3 　设置Hadoop属性的几种方式　　173\n7.4 　集群设置　　174\n7.4.1 　为集群配备多少台主机　　174\n7.4.2 　特殊节点的需求　　176\n7.4.3 　不同类型的存储系统　　177\n7.4.4 　Hadoop的网络配置　　178\n7.5 　实践环节：查看默认的机柜配置　　180\n7.6 　实践环节：报告每台主机所在机柜　　180\n7.7 　集群访问控制　　183\n7.8 　实践环节：展示Hadoop的默认安全机制　　183\n7.9 　管理NameNode　　187\n7.10 　实践环节：为fsimage文件新增一个存储路径　　188\n7.11 　实践环节：迁移到新的NameNode主机　　190\n7.12 　管理HDFS　　192\n7.12.1 　数据写入位置　　192\n7.12.2 　使用平衡器　　193\n7.13 　MapReduce管理　　193\n7.13.1 　通过命令行管理作业　　193\n7.13.2 　作业优先级和作业调度　　194\n7.14 　实践环节：修改作业优先级并结束作业运行　　194\n7.15 　扩展集群规模　　197\n7.15.1 　提升本地Hadoop集群的计算能力　　197\n7.15.2 　提升EMR作业流的计算能力　　198\n7.16 　小结　　198\n第8章　Hive：数据的关系视图　　200\n8.1 　Hive概述　　200\n8.1.1 　为什么使用Hive　　200\n8.1.2 　感谢Facebook　　201\n8.2 　设置Hive　　201\n8.2.1 　准备工作　　201\n8.2.2 　下载Hive　　202\n8.3 　实践环节：安装Hive　　202\n8.4 　使用Hive　　203\n8.5 　实践环节：创建UFO数据表　　204\n8.6 　实践环节：在表中插入数据　　206\n8.7 　实践环节：验证表　　208\n8.8 　实践环节：用正确的列分隔符重定义表　　210\n8.9 　实践环节：基于现有文件创建表　　212\n8.10 　实践环节：执行联结操作　　214\n8.11 　实践环节：使用视图　　216\n8.12 　实践环节：导出查询结果　　219\n8.13 　实践环节：制作UFO目击事件分区表　　221\n8.13.1 　分桶、归并和排序　　224\n8.13.2 　用户自定义函数　　225\n8.14 　实践环节：新增用户自定义函数　　225\n8.14.1 　是否进行预处理　　228\n8.14.2 　Hive和Pig的对比　　229\n8.14.3 　未提到的内容　　229\n8.15 　基于Amazon Web Services的Hive　　230\n8.16 　实践环节：在EMR上分析UFO数据　　230\n8.16.1 　在开发过程中使用交互式作业流　　235\n8.16.2 　与其他AWS产品的集成　　236\n8.17 　小结　　236\n第9章　与关系数据库协同工作　　238\n9.1 　常见数据路径　　238\n9.1.1 　Hadoop用于存储档案　　238\n9.1.2 　使用Hadoop进行数据预处理　　239\n9.1.3 　使用Hadoop作为数据输入工具　　239\n9.1.4 　数据循环　　240\n9.2 　配置MySQL　　240\n9.3 　实践环节：安装并设置MySQL　　240\n9.4 　实践环节：配置MySQL允许远程连接　　243\n9.5 　实践环节：建立员工数据库　　245\n9.6 　把数据导入Hadoop　　246\n9.6.1 　使用MySQL工具手工导入　　246\n9.6.2 　在mapper中访问数据库　　246\n9.6.3 　更好的方法：使用Sqoop　　247\n9.7 　实践环节：下载并配置Sqoop　　247\n9.8 　实践环节：把MySQL的数据导入HDFS　　249\n9.9 　实践环节：把MySQL数据导出到\nHive　　253\n9.10 　实践环节：有选择性的导入数据　　255\n9.11 　实践环节：使用数据类型映射　　257\n9.12 　实践环节：通过原始查询导入数据　　258\n9.13 　从Hadoop导出数据　　261\n9.13.1 　在reducer中把数据写入关系数据库　　261\n9.13.2 　利用reducer输出SQL数据文件　　262\n9.13.3 　仍是最好的方法　　262\n9.14 　实践环节：把Hadoop数据导入MySQL　　262\n9.15 　实践环节：把Hive数据导入MySQL　　265\n9.16 　实践环节：改进mapper并重新运行数据导出命令　　267\n9.17 　在AWS上使用Sqoop　　269\n9.18 　小结　　270\n第10章　使用Flume收集数据　　271\n10.1 　关于AWS的说明　　271\n10.2 　无处不在的数据　　271\n10.2.1 　数据类别　　272\n10.2.2 　把网络流量导入Hadoop　　272\n10.3 　实践环节：把网络服务器数据导入Hadoop　　272\n10.3.1 　把文件导入Hadoop　　273\n10.3.2 　潜在的问题　　273\n10.4 　Apache Flume简介　　274\n10.5 　实践环节：安装并配置Flume　　275\n10.6 　实践环节：把网络流量存入日志文件　　277\n10.7 　实践环节：把日志输出到控制台　　279\n10.8 　实践环节：把命令的执行结果写入平面文件　　281\n10.9 　实践环节：把远程文件数据写入本地平面文件　　283\n10.9.1 　信源、信宿和信道　　284\n10.9.2 　Flume配置文件　　286\n10.9.3 　一切都以事件为核心　　287\n10.10 　实践环节：把网络数据写入HDFS　　287\n10.11 　实践环节：加入时间戳　　289\n10.12 　实践环节：多层Flume网络　　292\n10.13 　实践环节：把事件写入多个信宿　　294\n10.13.1 　选择器的类型　　295\n10.13.2 　信宿故障处理　　295\n10.13.3 　使用简单元件搭建复杂系统　　296\n10.14 　更高的视角　　297\n10.14.1 　数据的生命周期　　297\n10.14.2 　集结数据　　297\n10.14.3 　调度　　297\n10.15 　小结　　298\n第11章　展望未来　　299\n11.1 　全书回顾　　299\n11.2 　即将到来的Hadoop变革　　300\n11.3 　其他版本的Hadoop软件包　　300\n11.4 　其他Apache项目　　303\n11.4.1 　HBase　　303\n11.4.2 　Oozie　　303\n11.4.3 　Whir　　304\n11.4.4 　Mahout　　304\n11.4.5 　MRUnit　　305\n11.5 　其他程序设计模式　　305\n11.5.1 　Pig　　305\n11.5.2 　Cascading　　305\n11.6 　AWS资源　　306\n11.6.1 　在EMR上使用HBase　　306\n11.6.2 　SimpleDB　　306\n11.6.3 　DynamoDB　　306\n11.7 　获取信息的渠道　　307\n11.7.1 　源代码　　307\n11.7.2 　邮件列表和论坛　　307\n11.7.3 　LinkedIn群组　　307\n11.7.4 　Hadoop用户群　　307\n11.7.5 　会议　　308\n11.8 　小结　　308\n随堂测验答案　　309","ebook_url":"https:\/\/read.douban.com\/ebook\/12187539\/","pages":"324","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27183972.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27183972.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27183972.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25794620\/","id":"25794620","publisher":"人民邮电出版社","isbn10":"7115341338","isbn13":"9787115341334","title":"Hadoop基础教程","url":"https:\/\/api.douban.com\/v2\/book\/25794620","alt_title":"Hadoop beginner’s guide","author_intro":"作者简介：\nGarry Turkington\n拥有14年行业经验，其大部分时间都专注于大型分布式系统的设计与实现。目前，他在Improve Digital公司担任数据工程部副总裁和公司的首席架构师。他主要负责实现可以存储、处理并从公司海量数据中挖掘潜在价值的系统。在加入 Improve Digital公司之前，他曾在Amazon 英国公司领导着几个软件开发团队，他们开发的系统用于处理Amazon为全世界所有对象创建的目录数据。在此之前，他还曾在英国和美国政府机关任职十年。\n他在北爱尔兰的贝尔法斯特女王大学获得了计算机学士和博士学位，并在美国斯蒂文斯理工学院获得系统工程的工程硕士学位。\n译者简介：\n张治起\nHadoop技术爱好者和研究者，对Hadoop技术有非常深刻的认识和理解，热切关注Hadoop和相关大数据处理技术。有着丰富的实践经验，热衷于技术分享，致力于不断探索揭开Hadoop的神秘面纱，帮助更多初学者接触和理解Hadoop。","summary":"Hadoop和云服务出现的历史背景，以及何时适用Hadoop的背景知识\n安装并配置Hadoop集群的最佳方式，根据手头的问题调整系统配置\n用Java和Ruby示例程序讲解如何编写运行在Hadoop上的程序\nAmazon网络服务提供的托管Hadoop集群的运行方式，以及它与用户直接管理的Hadoop集群有何区别\nHadoop与关系数据库的融合，使用Hive执行SQL查询，使用Sqoop迁移数据\n组成Hadoop生态系统的其他项目和工具，以及Hadoop的发展方向\n针对初学者的有效方法\n通过清晰操作步骤讲解最有用的任务\n边干边学——立刻动手实践\n摆脱枯燥的二进制\n有启发意义的理想的案例，能够带给读者灵感，从而解决面临的问题\n促进读者动手练习的作业和习题","ebook_price":"19.99","price":"65.00"},{"rating":{"max":10,"numRaters":34,"average":"8.8","min":0},"subtitle":"","author":["徐鹏"],"pubdate":"2016-3","tags":[{"count":31,"name":"HADOOP","title":"HADOOP"},{"count":26,"name":"大数据","title":"大数据"},{"count":20,"name":"源码分析","title":"源码分析"},{"count":20,"name":"hdfs","title":"hdfs"},{"count":16,"name":"Hadoop","title":"Hadoop"},{"count":15,"name":"hadoop","title":"hadoop"},{"count":6,"name":"JAVA","title":"JAVA"},{"count":5,"name":"HDFS","title":"HDFS"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28552110.jpg","binding":"平装","translator":[],"catalog":"第1章  HDFS\t1\n1.1  HDFS概述\t1\n1.1.1  HDFS体系结构\t1\n1.1.2  HDFS基本概念\t2\n1.2  HDFS通信协议\t4\n1.2.1  Hadoop RPC接口\t4\n1.2.2  流式接口\t20\n1.3  HDFS主要流程\t22\n1.3.1  HDFS客户端读流程\t22\n1.3.2  HDFS客户端写流程\t24\n1.3.3  HDFS客户端追加写流程\t25\n1.3.4  Datanode启动、心跳以及执行名字节点指令流程\t26\n1.3.5  HA切换流程\t27\n第2章  Hadoop RPC\t29\n2.1  概述\t29\n2.1.1  RPC框架概述\t29\n2.1.2  Hadoop RPC框架概述\t30\n2.2  Hadoop RPC的使用\t36\n2.2.1  Hadoop RPC使用概述\t36\n2.2.2  定义RPC协议\t40\n2.2.3  客户端获取Proxy对象\t45\n2.2.4  服务器获取Server对象\t54\n2.3  Hadoop RPC实现\t63\n2.3.1  RPC类实现\t63\n2.3.2  Client类实现\t64\n2.3.3  Server类实现\t76\n第3章  Namenode（名字节点）\t88\n3.1  文件系统目录树\t88\n3.1.1  INode相关类\t89\n3.1.2  Feature相关类\t102\n3.1.3  FSEditLog类\t117\n3.1.4  FSImage类\t138\n3.1.5  FSDirectory类\t158\n3.2  数据块管理\t162\n3.2.1  Block、Replica、BlocksMap\t162\n3.2.2  数据块副本状态\t167\n3.2.3  BlockManager类（done）\t177\n3.3  数据节点管理\t211\n3.3.1  DatanodeDescriptor\t212\n3.3.2  DatanodeStorageInfo\t214\n3.3.3  DatanodeManager\t217\n3.4  租约管理\t233\n3.4.1  LeaseManager.Lease\t233\n3.4.2  LeaseManager\t234\n3.5  缓存管理\t246\n3.5.1  缓存概念\t247\n3.5.2  缓存管理命令\t247\n3.5.3  HDFS集中式缓存架构\t247\n3.5.4  CacheManager类实现\t248\n3.5.5  CacheReplicationMonitor\t250\n3.6  ClientProtocol实现\t251\n3.6.1  创建文件\t251\n3.6.2  追加写文件\t254\n3.6.3  创建新的数据块\t257\n3.6.4  放弃数据块\t265\n3.6.5  关闭文件\t266\n3.7  Namenode的启动和停止\t268\n3.7.1  安全模式\t268\n3.7.2  HDFS High Availability\t276\n3.7.3  名字节点的启动\t301\n3.7.4  名字节点的停止\t306\n第4章  Datanode（数据节点）\t307\n4.1  Datanode逻辑结构\t307\n4.1.1  HDFS 1.X架构\t307\n4.1.2  HDFS Federation\t308\n4.1.3  Datanode逻辑结构\t310\n4.2  Datanode存储\t312\n4.2.1  Datanode升级机制\t312\n4.2.2  Datanode磁盘存储结构\t315\n4.2.3  DataStorage实现\t317\n4.3  文件系统数据集\t334\n4.3.1  Datanode上数据块副本的状态\t335\n4.3.2  BlockPoolSlice实现\t335\n4.3.3  FsVolumeImpl实现\t342\n4.3.4  FsVolumeList实现\t345\n4.3.5  FsDatasetImpl实现\t348\n4.4  BlockPoolManager\t375\n4.4.1  BPServiceActor实现\t376\n4.4.2  BPOfferService实现\t389\n4.4.3  BlockPoolManager实现\t396\n4.5  流式接口\t398\n4.5.1  DataTransferProtocol定义\t398\n4.5.2  Sender和Receiver\t399\n4.5.3  DataXceiverServer\t403\n4.5.4  DataXceiver\t406\n4.5.5  读数据\t408\n4.5.6  写数据（done）\t423\n4.5.7  数据块替换、数据块拷贝和读数据块校验\t437\n4.5.8  短路读操作\t437\n4.6  数据块扫描器\t437\n4.6.1  DataBlockScanner实现\t438\n4.6.2  BlockPoolSliceScanner实现\t439\n4.7  DirectoryScanner\t442\n4.8  DataNode类的实现\t443\n4.8.1  DataNode的启动\t444\n4.8.2  DataNode的关闭\t446\n第5章  HDFS客户端\t447\n5.1  DFSClient实现\t447\n5.1.1  构造方法\t448\n5.1.2  关闭方法\t449\n5.1.3  文件系统管理与配置方法\t450\n5.1.4  HDFS文件与目录操作方法\t451\n5.1.5  HDFS文件读写方法\t452\n5.2  文件读操作与输入流\t452\n5.2.1  打开文件\t452\n5.2.2  读操作——DFSInputStream实现\t461\n5.3  文件短路读操作\t481\n5.3.1  短路读共享内存\t482\n5.3.2  DataTransferProtocol\t484\n5.3.3  DFSClient短路读操作流程\t488\n5.3.4  Datanode短路读操作流程\t509\n5.4  文件写操作与输出流\t512\n5.4.1  创建文件\t512\n5.4.2  写操作——DFSOutputStream实现\t516\n5.4.3  追加写操作\t543\n5.4.4  租约相关\t546\n5.4.5  关闭输出流\t548\n5.5  HDFS常用工具\t549\n5.5.1  FsShell实现\t550\n5.5.2  DFSAdmin实现\t552","ebook_url":"https:\/\/read.douban.com\/ebook\/35728749\/","pages":"516","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28552110.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28552110.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28552110.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26755716\/","id":"26755716","publisher":"电子工业出版社","isbn10":"7121281554","isbn13":"9787121281556","title":"Hadoop 2.X HDFS源码剖析","url":"https:\/\/api.douban.com\/v2\/book\/26755716","alt_title":"","author_intro":"徐鹏 2005-2012年 在北京邮电大学完成本科以及硕士的学习，目前就职于今日头条担任基础架构研发工程师。长期关注大数据处理、分布式系统的研究以及Hadoop相关技术的应用与开发。","summary":"《Hadoop 2.X HDFS源码剖析》以Hadoop 2.6.0源码为基础，深入剖析了HDFS 2.X中各个模块的实现细节，包括RPC框架实现、Namenode实现、Datanode实现以及HDFS客户端实现等。《Hadoop 2.X HDFS源码剖析》一共有5章，其中第1章从总体上介绍了HDFS的组件、概念以及典型的流程，同时详细介绍了HDFS各个组件间RPC接口的定义。第2章介绍了Hadoop RPC框架的实现，Hadoop RPC是HDFS各个组件间通信所依赖的底层框架，可以理解为HDFS的神经系统。第3~5章分别介绍了Namenode、Datanode以及HDFS客户端这三个组件的实现细节，同时穿插介绍了HDFS 2.X的新特性，例如Namenode HA、Federation Namenode等。\n阅读《Hadoop 2.X HDFS源码剖析》可以帮助读者从架构设计与源码实现角度了解HDFS 2.X，同时还能学习HDFS 2.X框架中优秀的设计思想、设计模式、Java语言技巧以及编程规范等。这些对于读者全面提高自己的技术水平有很大的帮助。","ebook_price":"54.00","price":"108"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"Delivering on the Promise of Hadoop and Data Science in the Enterprise","author":["Alex Gorelik"],"pubdate":"2017-8-31","tags":[{"count":3,"name":"计算机","title":"计算机"},{"count":2,"name":"Data","title":"Data"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"bigdata","title":"bigdata"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29475998.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"200","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29475998.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29475998.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29475998.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27070002\/","id":"27070002","publisher":"O'Reilly Media","isbn10":"1491931558","isbn13":"9781491931554","title":"The Enterprise Big Data Lake","url":"https:\/\/api.douban.com\/v2\/book\/27070002","alt_title":"","author_intro":"Alex Gorelik is CTO and founder of Waterline Data and the founder of three startups. He also served as GM of Informatica’s Data Quality Business Unit and managed the company’s platform and data integration technology. Also for Informatica, Alex managed a team of 400 engineers and product managers as SVP of R&D for Core Technology, developing Informatica’s platform and Data Integration technology. Alex was an IBM Distinguished Engineer and co-founder, CTO and VP of engineering at Exeros and Acta Technology. Previously, Alex was co-founder, CTO and VP of Engineering at Acta Technology (acquired by Business Objects and now marketed as SAP Business Objects Data Services). Prior to founding Acta, Alex managed development of Replication Server at Sybase and worked on Sybase’s strategy for enterprise application integration (EAI). Earlier, he developed the database kernel for Amdahl’s Design Automation group. Alex holds a B.S. in Computer Science from Columbia University School of Engineering and a M.S. in Computer Science from Stanford University.","summary":"The data lake is a daring new approach for harnessing the power of big data technology and providing convenient self-service capabilities. But is it right for your company? This book is based on discussions with practitioners and executives from more than a hundred organizations, ranging from data-driven companies such as Google, LinkedIn, and Facebook, to governments and traditional corporate enterprises. You’ll learn what a data lake is, why enterprises need one, and how to build one successfully with the best practices in this book.\nAlex Gorelik, CTO and founder of Waterline Data, explains why old systems and processes can no longer support data needs in the enterprise. Then, in a collection of essays about data lake implementation, you’ll examine data lake initiatives, analytic projects, experiences, and best practices from data experts working in various industries.\nGet a succinct introduction to data warehousing, big data, and data science\nLearn various paths enterprises take to build a data lake\nExplore how to build a self-service model and best practices for providing analysts access to the data\nUse different methods for architecting your data lake\nDiscover ways to implement a data lake from experts in different industries","price":"GBP 31.99"},{"rating":{"max":10,"numRaters":13,"average":"7.7","min":0},"subtitle":"","author":["Eric Sammer"],"pubdate":"2012-10-16","tags":[{"count":32,"name":"Hadoop","title":"Hadoop"},{"count":7,"name":"O'Reilly","title":"O'Reilly"},{"count":4,"name":"大数据","title":"大数据"},{"count":2,"name":"Operations","title":"Operations"},{"count":1,"name":"运维","title":"运维"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"程序设计","title":"程序设计"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s22996944.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"298","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s22996944.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s22996944.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s22996944.jpg"},"alt":"https:\/\/book.douban.com\/subject\/17458570\/","id":"17458570","publisher":"O'Reilly Media","isbn10":"1449327052","isbn13":"9781449327057","title":"Hadoop Operations","url":"https:\/\/api.douban.com\/v2\/book\/17458570","alt_title":"","author_intro":"","summary":"If you've been tasked with the job of maintaining large and complex Hadoop clusters, or are about to be, this book is a must. You'll learn the particulars of Hadoop operations, from planning, installing, and configuring the system to providing ongoing maintenance. Hadoop is being adopted by more and more Fortune 500 companies, and the demand for operations-specific material has skyrocketed. This book - written by Eric Sammer, Principal Solution Architect at Cloudera - is the definitive operations guide for administrators. Developers who want to improve MapReduce jobs by learning how Hadoop works in large production environments will also benefit. Application administrators responsible for the health and operation of large distributed applications or systems will find this guide extremely useful.","price":"USD 39.99"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"Interactive SQL for Apache Hadoop","author":["John Russell"],"pubdate":"2014-10-5","tags":[{"count":2,"name":"大数据","title":"大数据"},{"count":2,"name":"impala","title":"impala"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"英文版","title":"英文版"},{"count":1,"name":"数据仓库，hive优化","title":"数据仓库，hive优化"},{"count":1,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"1","title":"1"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28061902.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"110","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28061902.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28061902.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28061902.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26379638\/","id":"26379638","publisher":"O'Reilly Media","isbn10":"1491905778","isbn13":"9781491905777","title":"Getting Started with Impala","url":"https:\/\/api.douban.com\/v2\/book\/26379638","alt_title":"","author_intro":"","summary":"","price":"USD 29.99"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"Hadoop应用开发实战详解","author":["万川梅"],"pubdate":"2013-6","tags":[{"count":5,"name":"hadoop","title":"hadoop"},{"count":2,"name":"云计算","title":"云计算"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"无PDF","title":"无PDF"},{"count":1,"name":"-IT","title":"-IT"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26706188.jpg","binding":"","translator":[],"catalog":"","pages":"397","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s26706188.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s26706188.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26706188.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24714272\/","id":"24714272","publisher":"","isbn10":"7113161936","isbn13":"9787113161934","title":"Hadoop应用开发实战详解-深入云计算","url":"https:\/\/api.douban.com\/v2\/book\/24714272","alt_title":"","author_intro":"","summary":"本书由浅入深，全面、系统地介绍了Hadoop这一高性能处理海量数据集的理想工具。本书的内容主要包括hdfs、mapreduce、hive、hbase、mahout、pig、zookeeper、avro、chukwa等与hadoop相关的子项目，各个知识点都精心设计了大量经典的小案例，实战型强，可操作性强。","price":"59.80元"},{"rating":{"max":10,"numRaters":28,"average":"7.0","min":0},"subtitle":"Building Effective Algorithms and Analytics for Hadoop and Other Systems","author":["Donald Miner","Adam Shook"],"pubdate":"2012-12-22","tags":[{"count":33,"name":"MapReduce","title":"MapReduce"},{"count":17,"name":"大数据","title":"大数据"},{"count":11,"name":"O'Reilly","title":"O'Reilly"},{"count":10,"name":"数据挖掘","title":"数据挖掘"},{"count":5,"name":"计算机科学","title":"计算机科学"},{"count":5,"name":"Patterns","title":"Patterns"},{"count":5,"name":"Design","title":"Design"},{"count":3,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s10659818.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"230","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s10659818.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s10659818.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s10659818.jpg"},"alt":"https:\/\/book.douban.com\/subject\/11229683\/","id":"11229683","publisher":"O'Reilly Media","isbn10":"1449327176","isbn13":"9781449327170","title":"MapReduce Design Patterns","url":"https:\/\/api.douban.com\/v2\/book\/11229683","alt_title":"","author_intro":"","summary":"Design patterns for the MapReduce framework, until now, have been scattered among various research papers, blogs, and books. This handy guide brings together a unique collection of valuable MapReduce patterns that will save you time and effort regardless of the domain, language, or development framework you're using. Each pattern is explained in context, with pitfalls and caveats clearly identified - so you can avoid some of the common design mistakes when modeling your Big Data architecture. This book also provides a complete overview of MapReduce that explains its origins and implementations, and why design patterns are so important. Hadoop MapReduce code is provided to help you learn how to apply the design patterns by example. Topics include: Basic patterns, including map-only filter, group by, aggregation, distinct, and limit  Joins: traditional reduce-side join, reduce-side join with Bloom filter, replicated join with distributed cache, merge join, Cartesian products, and intersections  Binning, sharding for other systems, sorting, sampling, unions, and other patterns for organizing data  Job optimization patterns, including multi-job map-only job folding, and overloading the key grouping to perform two jobs at once","price":"USD 44.99"},{"rating":{"max":10,"numRaters":15,"average":"9.4","min":0},"subtitle":"Designing Real World Big Data Applications","author":["Mark Grover","Ted Malaska","Jonathan Seidman","Gwen Shapira"],"pubdate":"2015-4","tags":[{"count":23,"name":"Hadoop","title":"Hadoop"},{"count":22,"name":"大数据","title":"大数据"},{"count":11,"name":"hadoop","title":"hadoop"},{"count":8,"name":"架构","title":"架构"},{"count":5,"name":"计算机","title":"计算机"},{"count":5,"name":"Architecture","title":"Architecture"},{"count":3,"name":"英文版","title":"英文版"},{"count":3,"name":"O'Reilly","title":"O'Reilly"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28123450.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"250","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28123450.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28123450.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28123450.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25940455\/","id":"25940455","publisher":"O'Reilly Media","isbn10":"1491900083","isbn13":"9781491900086","title":"Hadoop Application Architectures","url":"https:\/\/api.douban.com\/v2\/book\/25940455","alt_title":"","author_intro":"","summary":"With Early Release ebooks, you get books in their earliest form — the author's raw and unedited content as he or she writes — so you can take advantage of these technologies long before the official release of these titles. You'll also receive updates when significant changes are made, new chapters as they're written, and the final ebook bundle.\nGet expert guidance on architecting end-to-end data management solutions with Apache Hadoop. While many sources explain how to use various components in the Hadoop ecosystem, this practical book takes you through architectural considerations necessary to tie those components together into a complete tailored application, based on your particular use case.\nTo reinforce those lessons, the book’s second section provides detailed examples of architecture used in some of the most commonly found Hadoop applications. Whether you’re designing and implementing a new Hadoop application, or planning to integrate Hadoop into your existing data infrastructure, Hadoop Application Architectures will skillfully guide you through the process.\nThe Early Release edition begins with chapters that concentrate on design considerations for Data Modeling and Data Movement in Hadoop:\nExplore whether your application should store data on Hadoop Distributed File System (HDFS) or HBase\nGet best practices for designing an HDFS or HBase schema\nLearn how to design schemas for SQL-on-Hadoop (e.g. Hive, Impala, HCatalog) tables","price":"49.99"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"构建与实现大数据解决方案","author":["(美)卢博林斯凯(Lublinsky, B.)","(美)雅库伯维奇(Yakubovich, A.)","(美)史密斯(Smith, K. T.)"],"pubdate":"2014-8-1","tags":[{"count":13,"name":"Hadoop","title":"Hadoop"},{"count":6,"name":"大数据","title":"大数据"},{"count":3,"name":"计算机","title":"计算机"},{"count":3,"name":"云计算","title":"云计算"},{"count":2,"name":"我想读这本书","title":"我想读这本书"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"计算机技术","title":"计算机技术"},{"count":1,"name":"纸书","title":"纸书"}],"origin_title":"Professional Hadoop Solutions","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27359077.jpg","binding":"平装","translator":["穆玉伟"],"catalog":"目    录\n第1章  大数据和Hadoop生态系统\t1\n1.1  当大数据遇见Hadoop\t2\n1.1.1  Hadoop：直面大数据的挑战\t3\n1.1.2  商业世界中的数据科学\t4\n1.2  Hadoop生态系统\t6\n1.3  Hadoop核心组件\t7\n1.4  Hadoop发行版\t9\n1.5  使用Hadoop开发企业级应用\t10\n1.6  小结\t14\n第2章 Hadoop数据存储\t15\n2.1  HDFS\t15\n2.1.1  HDFS架构\t15\n2.1.2  使用HDFS文件\t19\n2.1.3  Hadoop特定的文件类型\t21\n2.1.4  HDFS联盟和高可用性\t26\n2.2  HBase\t28\n2.2.1  HBase架构\t28\n2.2.2  HBase结构设计\t34\n2.2.3  HBase编程\t35\n2.2.4  HBase新特性\t42\n2.3  将HDFS和HBase的组合用于高效数据存储\t45\n2.4  使用Apache Avro\t45\n2.5  利用HCatalog管理元数据\t49\n2.6  为应用程序选择合适的Hadoop数据组织形式\t51\n2.7  小结\t53\n第3章  使用MapReduce处理数据\t55\n3.1  了解MapReduce\t55\n3.1.1  MapReduce执行管道\t56\n3.1.2  MapReduce中的运行时协调和任务管理\t59\n3.2  第一个MapReduce应用程序\t61\n3.3  设计MapReduce实现\t69\n3.3.1  将MapReduce用作并行处理框架\t70\n3.3.2  使用MapReduce进行简单的数据处理\t71\n3.3.3  使用MapReduce构建连接\t72\n3.3.4  构建迭代式MapReduce应用程序\t77\n3.3.5  是否使用MapReduce\t82\n3.3.6  常见的MapReduce设计陷阱\t83\n3.4  小结\t84\n第4章  自定义MapReduce执行\t85\n4.1  使用InputFormat控制MapReduce执行\t85\n4.1.1  为计算密集型应用程序实现InputFormat\t87\n4.1.2  实现InputFormat以控制Map的数量\t93\n4.1.3  实现用于多个HBase表的InputFormat\t99\n4.2  使用自定义RecordReader以自己的方式读取数据\t102\n4.2.1  实现基于队列的RecordReader\t102\n4.2.2  为XML数据实现RecordReader\t105\n4.3  使用自定义输出格式组织输出数据\t109\n4.4  使用自定义记录写入器以自己的方式写入数据\t119\n4.5  使用组合器优化MapReduce执行\t121\n4.6  使用分区器控制Reducer执行\t124\n4.7  在Hadoop中使用非Java代码\t128\n4.7.1  Pipes\t128\n4.7.2  Hadoop Streaming\t128\n4.7.3  使用JNI\t129\n4.8  小结\t131\n第5章  构建可靠的MapReduce应用程序\t133\n5.1  单元测试MapReduce应用程序\t133\n5.1.1  测试Mapper\t136\n5.1.2  测试Reducer\t137\n5.1.3  集成测试\t138\n5.2  使用Eclipse进行本地应用程序测试\t139\n5.3  将日志用于Hadoop测试\t141\n5.4  使用作业计数器报告指标\t146\n5.5  MapReduce中的防御性编程\t149\n5.6  小结\t151\n第6章  使用Oozie自动化数据处理\t153\n6.1  认识Oozie\t154\n6.2  Oozie Workflow\t155\n6.2.1  在Oozie Workflow中执行异步操作\t159\n6.2.2  Oozie的恢复能力\t164\n6.2.3  Oozie Workflow作业的生命周期\t164\n6.3  Oozie Coordinator\t165\n6.4  Oozie Bundle\t170\n6.5  用表达式语言对Oozie进行参数化\t174\n6.5.1  Workflow函数\t175\n6.5.2  Coordinator函数\t175\n6.5.3  Bundle函数\t175\n6.5.4  其他EL函数\t175\n6.6  Oozie作业执行模型\t176\n6.7  访问Oozie\t179\n6.8  Oozie SLA\t180\n6.9  小结\t185\n第7章  使用Oozie\t187\n7.1  使用探测包验证位置相关信息的正确性\t187\n7.2  设计基于探测包的地点正确性验证\t188\n7.3  设计Oozie Workflow\t190\n7.4  实现Oozie Workflow应用程序\t193\n7.4.1  实现数据准备Workflow\t193\n7.4.2  实现考勤指数和聚类探测包串Workflow\t201\n7.5  实现 Workflow行为\t203\n7.5.1  发布来自java动作的执行上下文\t204\n7.5.2  在Oozie Workflow中使用MapReduce作业\t204\n7.6  实现Oozie Coordinator应用程序\t207\n7.7  实现Oozie Bundle应用程序\t212\n7.8  部署、测试和执行Oozie应用程序\t213\n7.8.1  部署Oozie应用程序\t213\n7.8.2  使用Oozie CLI执行Oozie应用程序\t215\n7.8.3  向Oozie作业传递参数\t218\n7.9  使用Oozie控制台获取Oozie应用程序信息\t221\n7.9.1  了解Oozie控制台界面\t221\n7.9.2  获取 Coordinator作业信息\t225\n7.10 小结\t227\n第8章  高级Oozie特性\t229\n8.1  构建自定义Oozie Workflow动作\t230\n8.1.1  实现自定义Oozie Workflow动作\t230\n8.1.2  部署Oozie自定义Workflow动作\t235\n8.2  向Oozie Workflow添加动态执行\t237\n8.2.1  总体实现方法\t237\n8.2.2  一个机器学习模型、参数和算法\t240\n8.2.3  为迭代过程定义Workflow\t241\n8.2.4  动态Workflow生成\t244\n8.3  使用Oozie Java API\t247\n8.4  在Oozie应用中使用uber jar包\t251\n8.5  数据吸收传送器\t256\n8.6  小结\t263\n第9章  实时Hadoop\t265\n9.1  现实世界中的实时应用\t266\n9.2  使用HBase来实现实时应用\t266\n9.2.1  将HBase用作图片管理系统\t268\n9.2.2  将HBase用作Lucene后端\t275\n9.3  使用专门的实时Hadoop查询系统\t295\n9.3.1  Apache Drill\t296\n9.3.2  Impala\t298\n9.3.3  实时查询和MapReduce的对比\t299\n9.4  使用基于Hadoop的事件处理系统\t300\n9.4.1  HFlame\t301\n9.4.2  Storm\t302\n9.4.3  事件处理和MapReduce的对比\t305\n9.5  小结\t305\n第10章  Hadoop安全\t307\n10.1  简要的历史：理解Hadoop安全的挑战\t308\n10.2  认证\t309\n10.2.1  Kerberos认证\t310\n10.2.2  委派安全凭据\t318\n10.3  授权\t323\n10.3.1  HDFS文件访问权限\t323\n10.3.2  服务级授权\t327\n10.3.3  作业授权\t329\n10.4  Oozie认证和授权\t329\n10.5  网络加密\t331\n10.6  使用Rhino项目增强安全性\t332\n10.6.1  HDFS磁盘级加密\t333\n10.6.2  基于令牌的认证和统一的授权框架\t333\n10.6.3  HBase单元格级安全\t334\n10.7  将所有内容整合起来——保证Hadoop安全的最佳实践\t334\n10.7.1  认证\t335\n10.7.2  授权\t335\n10.7.3  网络加密\t336\n10.7.4  敬请关注Hadoop的增强功能\t336\n10.8  小结\t336\n第11章  在AWS上运行Hadoop应用\t337\n11.1  初识AWS\t338\n11.2  在AWS上运行Hadoop的可选项\t339\n11.2.1  使用EC2实例的自定义安装\t339\n11.2.2  弹性MapReduce\t339\n11.2.3  做出选择前的额外考虑\t339\n11.3  理解EMR-Hadoop的关系\t340\n11.3.1  EMR架构\t341\n11.3.2  使用S3存储\t343\n11.3.3  最大化EMR的使用\t343\n11.3.4  利用CloudWatch和其他AWS组件\t345\n11.3.5  访问和使用EMR\t346\n11.4  使用AWS S3\t351\n11.4.1  理解桶的使用\t352\n11.4.2  使用控制台浏览内容\t354\n11.4.3  在S3中编程访问文件\t355\n11.4.4  使用MapReduce上传多个文件到S3\t365\n11.5  自动化EMR作业流创建和作业执行\t367\n11.6  管理EMR中的作业执行\t372\n11.6.1  在EMR集群上使用Oozie\t372\n11.6.2  AWS 简单工作流\t374\n11.6.3  AWS数据管道\t375\n11.7  小结\t376\n第12章  为Hadoop实现构建企业级安全解决方案\t377\n12.1  企业级应用的安全顾虑\t378\n12.1.1  认证\t380\n12.1.2  授权\t380\n12.1.3  保密性\t380\n12.1.4  完整性\t381\n12.1.5  审计\t381\n12.2  Hadoop安全没有为企业级应用原生地提供哪些机制\t381\n12.2.1  面向数据的访问控制\t382\n12.2.2  差分隐私\t382\n12.2.3  加密静止的数据\t383\n12.2.4  企业级安全集成\t384\n12.3  保证使用Hadoop的企业级应用安全的方法\t384\n12.3.1  使用Accumulo进行访问控制保护\t385\n12.3.2  加密静止数据\t394\n12.3.3  网络隔离和分隔方案\t395\n12.4  小结\t397\n第3章  Hadoop的未来\t399\n13.1  使用DSL简化MapReduce编程\t400\n13.1.1  什么是DSL\t400\n13.1.2  Hadoop的DSL\t401\n13.2  更快、更可扩展的数据处理\t412\n13.2.1  Apache YARN\t412\n13.2.2  Tez\t414\n13.3  安全性的改进\t415\n13.4  正在出现的趋势\t415\n13.5  小结\t416\n附录  有用的阅读\t417","pages":"448","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27359077.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27359077.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27359077.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25942338\/","id":"25942338","publisher":"清华大学出版社","isbn10":"7302369062","isbn13":"9787302369066","title":"Hadoop高级编程——构建与实现大数据解决方案","url":"https:\/\/api.douban.com\/v2\/book\/25942338","alt_title":"Professional Hadoop Solutions","author_intro":"Boris Lublinsky是诺基亚的首席架构师，出版了70多篇作品，包括Applied SOA: Service-Oriented Architecture and Design Strategies 。\nKevin T. Smith是Novetta Solutions公司AMS部门的技术解决方案总监，他为客户构建高度安全的、面向数据的解决方案。\nAlexey Yakubovich是Hortonworks的一名系统架构师，而且是对象管理组织(OMG)关于SOA治理和模型驱动架构的特别兴趣小组(SIG)的一名成员。","summary":"如果你已经准备好要充分实施大规模可扩展性数据分析工作，那么需要知道如何利用Hadoop技术。这本《Hadoop高级编程——构建与实现大数据解决方案》可以帮助你做到这一点！本书关注用于构建先进的、基于Hadoop的企业级应用的架构和方案，并为实现现实的解决方案提供深入的、代码级的讲解。本书还会带你领略数据设计以及数据设计如何影响实现。本书解释了MapReduce的工作原理，并展示了如何在MapReduce中重新定制特定的业务问题。在整本书中，你将会发现深入的Java代码示例，这些代码示例可以直接使用，它们均源自于已经成功地构建和部署的应用程序。","series":{"id":"9751","title":"wrox红皮书"},"price":"59.8"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["Vignesh Prajapati"],"pubdate":"2013-11-25","tags":[{"count":16,"name":"R","title":"R"},{"count":12,"name":"hadoop","title":"hadoop"},{"count":9,"name":"数据挖掘","title":"数据挖掘"},{"count":8,"name":"数据分析","title":"数据分析"},{"count":4,"name":"bigdata","title":"bigdata"},{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"英文版","title":"英文版"},{"count":1,"name":"ebook","title":"ebook"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27279440.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"238","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27279440.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27279440.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27279440.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25799722\/","id":"25799722","publisher":"Packt Publishing","isbn10":"178216328X","isbn13":"9781782163282","title":"Big Data Analytics with R and Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/25799722","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"An Introduction to Hadoop, Its Ecosystem, and Aligned Technologies","author":["Kevin Sitto","Marshall Presser"],"pubdate":"2015-3-23","tags":[{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"英文","title":"英文"},{"count":1,"name":"2017","title":"2017"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28041267.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"132","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28041267.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28041267.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28041267.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26359184\/","id":"26359184","publisher":"O'Reilly Media","isbn10":"1491947934","isbn13":"9781491947937","title":"Field Guide to Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26359184","alt_title":"","author_intro":"","summary":"","price":"USD 39.99"},{"rating":{"max":10,"numRaters":16,"average":"9.1","min":0},"subtitle":"","author":["[美]Alex Holmes（（亚历克斯.霍姆斯））"],"pubdate":"2015-1","tags":[{"count":15,"name":"hadoop","title":"hadoop"},{"count":8,"name":"Hadoop","title":"Hadoop"},{"count":5,"name":"MapReduce","title":"MapReduce"},{"count":4,"name":"计算机","title":"计算机"},{"count":2,"name":"DM&BI","title":"DM&BI"},{"count":1,"name":"数据平台","title":"数据平台"},{"count":1,"name":"想读的书","title":"想读的书"},{"count":1,"name":"图书馆","title":"图书馆"}],"origin_title":"Hadoop in Practice","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27983775.jpg","binding":"平装","translator":["梁李印","宁青","杨卓荦"],"catalog":"前言 ...............................................................................................................XV\n致谢 ............................................................................................................XVII\n关于本书 ..................................................................................................... XIX\n第1 部分　背景和基本原理...............................................1\n1　跳跃中的Hadoop....................................................................................... 3\n1.1　什么是Hadoop ................................................................................................. 4\n1.1.1　Hadoop 的核心组件 ............................................................................ 5\n1.1.2　Hadoop 生态圈 .................................................................................... 9\n1.1.3　物理架构 ............................................................................................ 10\n1.1.4　谁在使用Hadoop .............................................................................. 12\n1.1.5　Hadoop 的局限性 .............................................................................. 13\n1.2　运行Hadoop ................................................................................................... 14\n1.2.1　下载并安装Hadoop .......................................................................... 14\n1.2.2　Hadoop 的配置 .................................................................................. 15\n1.2.3　CLI 基本命令 ..................................................................................... 17\n1.2.4　运行MapReduce 作业 ....................................................................... 18\n1.3　本章小结 ........................................................................................................ 24\n第2 部分　数据逻辑....................................................... 25\n2　将数据导入导出Hadoop.........................................................27\n2.1　导入导出的关键要素 .................................................................................... 29\n2.2　将数据导入Hadoop ....................................................................................... 30\n2.2.1　将日志文件导入Hadoop .................................................................. 31\n技术点1　使用Flume 将系统日志文件导入HDFS ............................. 33\n2.2.2　导入导出半结构化和二进制文件 .................................................... 42\n技术点2　自动复制文件到HDFS 的机制 ............................................ 43\n技术点3　使用Oozie 定期执行数据导入活动 ..................................... 48\n2.2.3　从数据库中拉数据 ............................................................................ 52\n技术点4　使用MapReduce 将数据导入数据库 ................................... 53\n技术点5　使用Sqoop 从MySQL 导入数据 ......................................... 58\n2.2.4　HBase ................................................................................................. 68\n技术点6　HBase 导入HDFS ................................................................. 68\n技术点7　将HBase 作为MapReduce 的数据源 .................................. 70\n2.3　将数据导出Hadoop ....................................................................................... 73\n2.3.1　将数据导入本地文件系统 ................................................................ 73\n技术点8　自动复制HDFS 中的文件 .................................................... 73\n2.3.2　数据库 ................................................................................................ 74\n技术点9　使用Sqoop 将数据导入MySQL .......................................... 75\n2.3.3　Hbase .................................................................................................. 78\n技术点10　将数据从HDFS 导入HBase .............................................. 78\n技术点11　使用HBase 作为MapReduce 的数据接收器 .................... 79\n2.4　本章小结 ........................................................................................................ 81\n3　数据序列化——处理文本文件及其他格式的文件........................83\n3.1　了解MapReduce 中的输入和输出 ............................................................... 84\n3.1.1　数据输入 ............................................................................................ 85\n3.1.2　数据输出 ............................................................................................ 89\n3.2　处理常见的序列化格式 ................................................................................ 91\n3.2.1　XML ................................................................................................... 91\n技术点12　MapReduce 和XML ............................................................ 91\n3.2.2　JSON ................................................................................................... 95\n技术点13　MapReduce 和JSON ........................................................... 95\n3.3　大数据的序列化格式 .................................................................................... 99\n3.3.1　比较SequenceFiles、Protocol Buffers、Thrift 和 Avro .................. 99\n3.3.2　Sequence File .................................................................................... 101\n技术点14　处理SequenceFile .............................................................. 103\n3.3.3　Protocol Buffers ................................................................................ 109\n技术点15　整合Protocol Buffers 和MapReduce ............................... 110\n3.3.4　Thrift ................................................................................................. 117\n技术点16　使用Thrift .......................................................................... 117\n3.3.5　Avro .................................................................................................. 119\n技术点17　MapReduce 的下一代数据序列化技术 ............................ 120\n3.4　自定义文件格式 .......................................................................................... 127\n3.4.1　输入输出格式 .................................................................................. 127\n技术点18　输入和输出格式为CSV 的文件 ...................................... 128\n3.4.2　output committing 的重要性 ........................................................... 136\n3.5　本章小结 ...................................................................................................... 136\n第3 部分　大数据模式..................................................137\n4　处理大数据的MapReduce 模式............................................. 139\n4.1　Join ................................................................................................................ 140\n4.1.1　Repartition Join ................................................................................ 141\n技术点19　优化repartition join ........................................................... 142\n4.1.2　Replicated Join ................................................................................. 146\n4.1.3　Semi-join .......................................................................................... 147\n技术点20　实现semi-join .................................................................... 148\n4.1.4　为你的数据挑选最优的合并策略 .................................................. 154\n4.2　排序 .............................................................................................................. 155\n4.2.1　二次排序 .......................................................................................... 156\n技术点21　二次排序的实现 ................................................................ 157\n4.2.2　整体并行排序 .................................................................................. 162\n技术点22　通过多个reducer 对key 进行排序 .................................. 162\n4.3　抽样 .............................................................................................................. 165\n技术点23　蓄水池抽样（reservoir 抽样） ........................................... 165\n4.4　本章小结 ...................................................................................................... 168\n5　优化HDFS 处理大数据的技术............................................... 169\n5.1　处理小文件 .................................................................................................. 170\n技术点24　使用Avro 存储大量小文件 .............................................. 170\n5.2　通过压缩提高数据存储效率 ...................................................................... 178\n技术点25　选择合适的压缩解码器 .................................................... 178\n技术点26　在HDFS、MapReduce、Pig 和Hive 中使用数据压缩 .. 182\n技术点27　在MapReduce、Hive 和Pig 中处理可分割的LZOP ..... 187\n5.3　本章小结 ...................................................................................................... 193\n6　诊断和优化性能问题............................................................. 194\n6.1　衡量MapReduce 和你的环境 ..................................................................... 195\n6.1.1　提取作业统计信息的工具 .............................................................. 195\n6.1.2　监控 .................................................................................................. 196\n6.2　确定性能问题的原因 .................................................................................. 198\n6.2.1　了解哪些因素会影响MapReduce 作业的性能 ............................. 198\n6.2.2　map 端异常 ...................................................................................... 200\n技术点28　发现输入数据中的坑 ........................................................ 200\n技术点29　确定map 端数据倾斜问题 ............................................... 201\n技术点30　判定map 任务吞吐量 ....................................................... 203\n技术点31　小文件 ................................................................................ 204\n技术点32　不可切割的文件 ................................................................ 206\n6.2.3　reduce 端问题 .................................................................................. 207\n技术点33　reducer 任务数过大或过小 ............................................... 208\n技术点34　定位reduce 端数据倾斜问题 ............................................ 209\n技术点35　确定reduce 任务是否存在整体吞吐量过低 .................... 211\n技术点36　缓慢的洗牌（shuffle）和排序 ......................................... 213\n6.2.4　任务的一般性能问题 ...................................................................... 213\n技术点37　作业竞争和调度器限制 .................................................... 215\n技术点38　使用堆转储来查找未优化的用户代码 ............................ 216\n6.2.5　硬件性能问题 .................................................................................. 218\n技术点39　查找硬件的失效 ................................................................ 218\n技术点40　CPU 竞争 ........................................................................... 219\n技术点41　内存交换 ............................................................................ 220\n技术点42　磁盘健康 ............................................................................ 222\n技术点43　网络 .................................................................................... 224\n6.3　可视化 .......................................................................................................... 226\n技术点44　提取并可视化任务执行时间 ............................................ 227\n6.4　优化 ............................................................................................................. 229\n6.4.1　剖析MapReduce 的用户代码 ......................................................... 230\n技术点45　剖析map 和reduce 任务 ................................................... 230\n6.4.2　参数配置 .......................................................................................... 232\n6.4.3　优化 shuffle 和 sort 阶段 ................................................................. 234\n技术点46　避免reducer ....................................................................... 234\n技术点47　过滤和投影 ........................................................................ 235\n技术点48　使用 combiner .................................................................... 236\n技术点49　超炫的使用比较器的快速排序 ........................................ 237\n6.4.4　减轻倾斜 .......................................................................................... 241\n技术点50　收集倾斜数据 .................................................................... 242\n技术点51　减轻reducer 阶段倾斜 ...................................................... 243\n6.4.5　在MapReduce 中优化用户的Java 代码 ........................................ 244\n6.4.6　数据序列化 ...................................................................................... 248\n6.5　本章小结 ...................................................................................................... 249\n第4 部分 数据科学.......................................................251\n7　数据结构和算法的运用.......................................................... 253\n7.1　使用图进行数据建模和解决问题 .............................................................. 254\n7.1.1　模拟图 .............................................................................................. 255\n7.1.2　最短路径算法 .................................................................................. 255\n技术点52　找出两个用户间的最短距离 ............................................ 256\n7.1.3　friends-of-friends（FoF） ................................................................. 263\n技术点53　计算FoF ............................................................................. 263\n7.1.4　PageRank .......................................................................................... 269\n技术点54　通过Web 图计算PageRank .............................................. 269\n7.2　Bloom filter ................................................................................................... 275\n技术点55　在MapReduce 中并行创建Bloom filter ......................... 277\n技术点56　通过MapReduce 对Bloom filter 进行semi-join ............. 281\n7.3　本章小结 ...................................................................................................... 284\n8　结合R 和Hadoop 进行数据统计............................................ 285\n8.1　比较R 和MapReduce 集成的几种方法 .................................................... 286\n8.2　R 基础知识 ................................................................................................... 288\n8.3　R 和Streaming ............................................................................................. 290\n8.3.1　Streaming 和map-only R ................................................................. 290\n技术点57　计算股票日平均值 ............................................................ 290\n8.3.2　Streaming、R 和完整的MapReduce .............................................. 293\n技术点58　计算股票的累积均值 ........................................................ 293\n8.4　Rhipe——将客户端R 和Hadoop 进行集成 ............................................. 297\n技术点59　使用Rhipe 计算CMA ....................................................... 297\n8.5　 RHadoop——更简单地在客户端集成R 和Hadoop 的技术 .................... 301\n技术点60　使用RHadoop 计算CMA ................................................. 302\n8.6　本章小结 ...................................................................................................... 304\n9　使用Mahout 进行预测分析................................................... 305\n9.1　使用recommender 提供产品建议 .............................................................. 306\n9.1.1　相似性度量的可视化 ...................................................................... 307\n9.1.2　GroupLens 数据集 ........................................................................... 308\n9.1.3　基于用户的recommender ............................................................... 310\n9.1.4　基于物品的recommender ............................................................... 310\n技术点61　使用基于物品的recommender 进行电影评级 ................ 311\n9.2　classification ................................................................................................. 314\n9.2.1　编写一个手动naïve Bayesian 分类器 ............................................ 315\n9.2.2　可扩展的垃圾邮件侦测分类系统 .................................................. 321\n技术点62　使用Mahout 训练和测试垃圾邮件分类器 ...................... 321\n9.2.3　其他分类算法 .................................................................................. 325\n9.3　K-means clustering ....................................................................................... 325\n9.3.1　简单介绍 .......................................................................................... 326\n9.3.2　并行执行K-means ........................................................................... 327\n技术点63　K-means 处理合成的二维数据集 ..................................... 327\n9.3.3　K-means 和文本 ............................................................................... 331\n9.3.4　其他Mahout clustering 算法 ........................................................... 332\n9.4　本章小结 ...................................................................................................... 332\n第5 部分　驯服大象......................................................333\n10　深入解析 Hive.................................................................. 335\n10.1　Hive 基础 ................................................................................................ 336\n10.1.1　安装 .......................................................................................... 336\n10.1.2　元存储 ...................................................................................... 336\n10.1.3　数据库、表、分区和存储 ...................................................... 336\n10.1.4　数据模型 .................................................................................. 337\n10.1.5　查询语言 .................................................................................. 337\n10.1.6　交互式和非交互式Hive ......................................................... 337\n10.2　使用Hive 进行数据分析 ....................................................................... 338\n10.2.1　序列化和反序列化 .................................................................. 338\n技术点64　载入日志文件 .............................................................. 338\n10.2.2　UDF、分区、分桶和压缩 ...................................................... 344\n技术点65　编写UDF 和压缩分区表 ............................................ 344\n10.2.3　数据合并 .................................................................................. 350\n技术点66　优化Hive 合并 ............................................................ 350\n10.2.4　分组、排序和explain ............................................................. 355\n10.3　本章小结 ................................................................................................ 358\n11　Pig 流管道......................................................................... 359\n11.1　Pig 基础 .................................................................................................. 360\n11.1.1　安装 .......................................................................................... 360\n11.1.2　架构 .......................................................................................... 360\n11.1.3　PigLatin..................................................................................... 360\n11.1.4　数据类型 .................................................................................. 361\n11.1.5　操作符和函数 .......................................................................... 361\n11.1.6　交互式和非交互式的Pig ........................................................ 362\n11.2　使用Pig 在日志数据中发现恶意行为者 ............................................. 362\n11.2.1　加载数据 .................................................................................. 363\n技术点67　加载Apache 日志文件 ................................................ 363\n11.2.2　过滤和投影 .............................................................................. 368\n技术点68　通过过滤和投影减少数据处理量 .............................. 368\n11.2.3　分组和聚合UDF ..................................................................... 370\n技术点69　IP 地址的分组和计数 ................................................. 370\n11.2.4　使用UDF 进行定位 ................................................................ 374\n技术点70　使用分布式缓存进行IP 地理定位 ............................ 375\n11.2.5　流 .............................................................................................. 378\n技术点71　使用你的脚本合并Pig ............................................... 378\n11.2.6　合并 .......................................................................................... 379\n技术点72　在Pig 中合并数据 ...................................................... 380\n11.2.7　排序 .......................................................................................... 381\n技术点73　元组排序 ...................................................................... 381\n11.2.8　存储数据 .................................................................................. 382\n技术点74　在SequenceFiles 中存储数据 ..................................... 382\n11.3　使用Pig 优化用户的工作流程 ............................................................. 385\n技术点75　通过4 步快速处理大数据 .......................................... 385\n11.4　性能 ......................................................................................................... 390\n技术点76　Pig 优化 ....................................................................... 390\n11.5　本章小结 ................................................................................................. 393\n12　Crunch 及相关技术............................................................ 394\n12.1　什么是Crunch ........................................................................................ 395\n12.1.1　背景和概念 .............................................................................. 395\n12.1.2　基本原理 .................................................................................. 395\n12.1.3　简单示例 .................................................................................. 398\n12.2　发现日志中最热门的URL .................................................................... 401\n技术点77　使用Crunch 进行日志解析和基本分析 .................... 402\n12.3　合并 ........................................................................................................ 405\n技术点78　Crunch 的repartition join ............................................ 405\n12.4　Cascading ................................................................................................ 407\n12.5　本章小结 ................................................................................................ 409\n13　测试和调试....................................................................... 410\n13.1　测试 ........................................................................................................ 410\n13.1.1　有效的单元测试的基本要素 .................................................. 411\n13.1.2　MRUnit ..................................................................................... 413\n技术点79　MapReduce 函数、作业和管道的单元测试 ............. 413\n13.1.3　LocalJobRunner ........................................................................ 420\n技术点80　用LocalJobRunner 进行重量级的作业测试 ............. 421\n13.1.4　集成和QA 测试 ...................................................................... 423\n13.2　调试用户空间的问题 ............................................................................ 424\n13.2.1　访问任务日志 .......................................................................... 424\n技术点81　检查任务日志 .............................................................. 424\n13.2.2　调试不可预期的输入 .............................................................. 429\n技术点82　定位input split 问题 .................................................... 429\n13.2.3　调试JVM 配置 ........................................................................ 432\n技术点83　解决任务的JVM 启动参数 ........................................ 433\n13.2.4　高效调试的编码准则 .............................................................. 433\n技术点84　调试和错误处理 .......................................................... 433\n13.3　MapReduce 陷阱 .................................................................................... 437\n技术点85　MapReduce 反模式 ..................................................... 438\n13.4　本章小结 ................................................................................................ 441\n附录A　相关技术..................................................................... 443\n附录B　Hadoop 内置的数据导入导出工具.................................. 471\n附录C　HDFS 解剖................................................................. 486\n附录D　优化MapReduce 合并框架............................................ 493\n索引.......................................................................................... 503","pages":"536","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27983775.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27983775.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27983775.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26301704\/","id":"26301704","publisher":"电子工业出版社","isbn10":"7121250721","isbn13":"9787121250729","title":"Hadoop硬实战","url":"https:\/\/api.douban.com\/v2\/book\/26301704","alt_title":"Hadoop in Practice","author_intro":"Alex Holmes是高级软件工程师，在使用Hadoop解决大数据问题上经验十分丰富。他曾在JavaOne和Jazoon做过演讲并在VeriSign负责技术指导。","summary":"Hadoop 是一个开源的MapReduce 平台，设计运行在大型分布式集群环境中，为开发者进行数据存储、管理以及分析提供便利的方法。《Hadoop硬实战》详细讲解了Hadoop 和MapReduce 的基本概念，并收集了85 个问题及其解决方案。在关键问题领域对基础概念和实战方法做了权衡。\n《Hadoop硬实战》适合使用Hadoop 进行数据存储、管理和分析的技术人员使用。","price":"99.00"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"The Workflow Scheduler for Hadoop","author":["Islam, Mohammad Kamrul","Srinivasan, Aravind"],"pubdate":"2015-5-31","tags":[{"count":3,"name":"计算机","title":"计算机"},{"count":3,"name":"Oozie","title":"Oozie"},{"count":3,"name":"Apache","title":"Apache"},{"count":2,"name":"英文版","title":"英文版"},{"count":2,"name":"数据平台","title":"数据平台"},{"count":2,"name":"oozie","title":"oozie"},{"count":1,"name":"调度","title":"调度"},{"count":1,"name":"workflow","title":"workflow"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28031016.jpg","binding":"平装","translator":[],"catalog":"","pages":"250","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28031016.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28031016.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28031016.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26348732\/","id":"26348732","publisher":"O'Reilly Media, Inc, USA","isbn10":"1449369928","isbn13":"9781449369927","title":"Apache Oozie","url":"https:\/\/api.douban.com\/v2\/book\/26348732","alt_title":"","author_intro":"","summary":"","price":"USD 45.19"},{"rating":{"max":10,"numRaters":15,"average":"7.6","min":0},"subtitle":"","author":["Eric Sammer"],"pubdate":"2013-11-27","tags":[{"count":18,"name":"Hadoop","title":"Hadoop"},{"count":7,"name":"计算机","title":"计算机"},{"count":7,"name":"编程","title":"编程"},{"count":7,"name":"hadoop","title":"hadoop"},{"count":5,"name":"技术","title":"技术"},{"count":3,"name":"专业书","title":"专业书"},{"count":2,"name":"大数据","title":"大数据"},{"count":2,"name":"Cloud","title":"Cloud"}],"origin_title":"Hadoop Operations","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27187771.jpg","binding":"平装","translator":["刘敏","麦耀锋","李冀蕾等"],"catalog":"第1章  简介\t1\n第2章  HDFS\t6\n2.1　目标和动机\t6\n2.2　设计\t7\n2.3　守护进程\t8\n2.4　读写数据\t10\n2.4.1　数据读取流程\t10\n2.4.2　数据写操作流程\t11\n2.5　管理文件系统元数据\t13\n2.6　NameNode的高可用性\t14\n2.7　NameNode联盟\t16\n2.8　访问与集成\t17\n2.8.1　命令行工具\t18\n2.8.2　用户空间文件系统（FUSE）\t21\n2.8.3　表示状态传输（REST）的支持\t21\n第3章  MapReduce\t23\n3.1　MapReduce的若干阶段\t24\n3.2　Hadoop MapReduce简介\t30\n3.2.1　后台程序\t31\n3.2.2　出错处理\t33\n3.3　YARN\t35\n第4章  规划一个Hadoop集群\t37\n4.1　挑选Hadoop的发行版本\t37\n4.1.1　Apache Hadoop\t37\n4.1.2　Cloudera的Apache Hadoop发行版本\t38\n4.1.3　版本和功能\t38\n4.1.4　我应该使用哪个版本\t40\n4.2　硬件选型\t41\n4.2.1　主节点硬件的选择\t42\n4.2.2　工作节点的硬件选择\t43\n4.2.3　集群的大小\t45\n4.2.4　刀片服务器、存储区域网络（SAN）和虚拟化\t47\n4.3　操作系统的选择和准备\t49\n4.3.1　部署规划\t49\n4.3.2　软件\t50\n4.3.3　主机名、DNS和标识\t51\n4.3.4　用户、组和特权\t54\n4.4　内核调整\t56\n4.4.1　vm.swappiness\t56\n4.4.2　vm.overcommit_memory\t57\n4.5　磁盘配置\t58\n4.5.1　选择文件系统\t58\n4.5.2　挂载选项\t60\n4.6　网络设计\t60\n4.6.1　Hadoop中的网络使用：回顾\t60\n4.6.2　1 Gb与10 Gb网络\t62\n4.6.3　典型的网络拓扑\t63\n第5章　安装和配置\t67\n5.1　安装Hadoop\t67\n5.1.1　Apache Hadoop\t68\n5.1.2　CDH\t72\n5.2　配置概述\t76\n5.3　环境变量和Shell脚本\t80\n5.4　日志配置\t82\n5.5　HDFS\t84\n5.5.1　识别和定位\t84\n5.5.2　优化与调整\t86\n5.5.3　格式化NameNode\t89\n5.5.4　创建\/tmp目录\t91\n5.6　NameNode的高可靠性\t92\n5.6.1　隔离（Fencing）选项\t93\n5.6.2　基本配置\t95\n5.6.3　自动失效备援配置\t96\n5.6.4　格式化和引导NameNode启动\t99\n5.7　NameNode联盟（Federation）\t105\n5.8　MapReduce\t113\n5.8.1　识别和定位\t113\n5.8.2　优化和调整\t115\n5.9　机架拓扑\t122\n5.10　安全\t125\n第6章　用户标识、身份验证和授权\t126\n6.1　用户标识\t127\n6.2　Kerberos和Hadoop\t128\n6.2.1　Kerberos\t128\n6.2.2　Hadoop上的Kerberos支持\t130\n6.3　授权\t143\n6.3.1　HDFS\t144\n6.3.2　MapReduce\t146\n6.3.3　其他工具和系统\t149\n6.4　集成试试\t153\n第7章　资源管理\t156\n7.1　何谓资源管理\t156\n7.2　HDFS配额\t156\n7.3　MapReduce 调度器\t159\n7.3.1　先进先出（FIFO）调度器\t160\n7.3.2　公平调度器\t162\n7.3.3　计算能力调度器（Capacity Scheduler）\t174\n7.3.4　未来发展\t181\n第8章　集群维护\t183\n8.1　Hadoop流程管理\t183\n8.1.1　用初始化脚本管理进程\t183\n8.1.2　手动管理进程\t184\n8.2　HDFS维护任务\t184\n8.2.1　添加一个DataNode\t184\n8.2.2　卸载DataNode\t185\n8.2.3　用fsck来检查文件系统的一致性\t185\n8.2.4　HDFS块数据均衡\t190\n8.2.5　处理坏磁盘\t192\n8.3　MapReduce维护任务\t193\n8.3.1　添加tasktracker\t193\n8.3.2　卸载tasktracker\t193\n8.3.3　终结MapReduce 作业\t194\n8.3.4　终结MapReduce任务\t194\n8.3.5　处理列入黑名单的tasktracker\t195\n第9章　故障分析与排查\t196\n9.1　鉴别诊断（Differential Diagnosis）\t196\n9.2  故障和问题\t197\n9.2.1　人类（自己）\t198\n9.2.2　配置错误\t198\n9.2.3　硬件故障\t199\n9.2.4　资源枯竭\t200\n9.2.5　主机标识和命名\t200\n9.2.6　网络分区\t200\n9.3 “计算机插好了么？”\t201\n9.4　治疗和护理\t203\n9.5　实战案例\t206\n9.5.1　神秘的瓶颈\t206\n9.5.2　127.0.0.1这个地址不存在\t209\n第10章　监控\t213\n10.1　概览\t213\n10.2　Hadoop度量(Metrics)\t214\n10.2.1　Apache Hadoop 0.20.0和CDH3 (metrics1)\t214\n10.2.2　Apache Hadoop 0.20.203及之后的版本、CDH4(metrics2)\t221\n10.2.3　SNMP\t222\n10.3　健康监控\t222\n10.3.1　主机级别的检查\t223\n10.3.2　所有Hadoop进程\t225\n10.3.3　HDFS检查\t226\n10.3.4　MapReduce检查\t229\n第11章　备份与恢复\t232\n11.1　数据备份\t232\n11.1.1　分布式拷贝（distcp）\t233\n11.1.2　并行提取数据\t235\n11.2　NameNode元数据\t237\n附录　弃用的配置属性\t239","pages":"250","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27187771.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27187771.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27187771.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25798081\/","id":"25798081","publisher":"人民邮电出版社","isbn10":"7115333327","isbn13":"9787115333322","title":"hadoop技术详解","url":"https:\/\/api.douban.com\/v2\/book\/25798081","alt_title":"Hadoop Operations","author_intro":"Eric Sammer目前是Cloudera公司的首席方案架构师，协助客户规划、配置、开发和使用Hadoop以及相关的大型项目。他在开发和运营分布式的、高并发的数据摄取和处理系统方面很有经验。在过去十年里，他参加了开源社区并且为许多项目做出了贡献。","summary":"本书将向读者详细介绍Hadoop的各项操作，从最初的设计，到安装、设置，以帮助读者提供稳定持续的系统表现。而对于那些希望通过学习Hadoop工作原理以提高NapReduce工作效率的开发者来说，也将会从本书收益。","price":"59.00"},{"rating":{"max":10,"numRaters":13,"average":"8.0","min":0},"subtitle":"Building Data Analytics Applications with Hadoop","author":["Russell Jurney"],"pubdate":"2013-10-25","tags":[{"count":13,"name":"数据挖掘","title":"数据挖掘"},{"count":6,"name":"数据分析","title":"数据分析"},{"count":5,"name":"DataScience","title":"DataScience"},{"count":4,"name":"计算机科学","title":"计算机科学"},{"count":4,"name":"机器学习","title":"机器学习"},{"count":3,"name":"数据科学","title":"数据科学"},{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"大数据","title":"大数据"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29614702.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"178","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29614702.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29614702.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29614702.jpg"},"alt":"https:\/\/book.douban.com\/subject\/11549313\/","id":"11549313","publisher":"O'Reilly Media","isbn10":"1449326269","isbn13":"9781449326265","title":"Agile Data Science","url":"https:\/\/api.douban.com\/v2\/book\/11549313","alt_title":"","author_intro":"About the Author\nRussell Jurney cut his data teeth in casino gaming, building web apps to analyze the performance of slot machines in the US and Mexico. After dabbling in entrepreneurship, interactive media and journalism, he moved to silicon valley to build analytics applications at scale at Ning and LinkedIn. He lives on the ocean in Pacifica, California with his wife Kate and two fuzzy dogs.","summary":"Mining data requires a deep investment in people and time. How can you be sure you're building the right models? What tools help you connect with the customer's needs? With this hands-on book, you'll learn a flexible toolset and methodology for building effective analytics applications. Agile Data shows you how to create an environment for exploring data, using lightweight tools such as Ruby, Python, Apache Pig, and the D3.js (Data-Driven Documents) JavaScript library. You'll learn an iterative approach that allows you to quickly change the kind of analysis you're doing, as you discover what the data is telling you. All the example code in this book is available as working Heroku apps. Build an application to mine your own email inbox Use several data structures to extract multiple features from a single dataset, and learn how different perspectives can yield insight Rapidly boot your applications as simple front-ends to key\/value stores Add features driven by descriptive and inferential statistics, machine learning, and data visualization Gather usage data and talk to real users to help guide your data-driven exploration You can provide constructive comments on the manuscript through O'Reilly's Open Feedback Publishing System (OFPS). Learn more at http:\/\/labs.oreilly.com\/ofps.html.","price":"USD 39.99"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["欧文斯 (Jonathan R.Owens)","伦茨 (Jon Lentz)","费米亚诺 (Brian Femiano)"],"pubdate":"2014-3","tags":[{"count":10,"name":"Hadoop","title":"Hadoop"},{"count":6,"name":"MapReduce","title":"MapReduce"},{"count":4,"name":"BigData","title":"BigData"},{"count":2,"name":"数据分析","title":"数据分析"},{"count":2,"name":"Python","title":"Python"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"Hadoop Real World Solutions Cookbook","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27316881.jpg","binding":"平装","translator":["傅杰","赵磊","卢学裕"],"catalog":"《hadoop实战手册》\n第1章　hadoop分布式文件系统——导入和导出数据　1\n1.1　介绍　1\n1.2　使用hadoop shell命令导入和导出数据到hdfs　2\n1.3　使用distcp实现集群间数据复制　7\n1.4　使用sqoop从mysql数据库导入数据到hdfs　9\n1.5　使用sqoop从hdfs导出数据到mysql　12\n1.6　配置sqoop以支持sql server　15\n1.7　从hdfs导出数据到mongodb　17\n1.8　从mongodb导入数据到hdfs　20\n1.9　使用pig从hdfs导出数据到mongodb　23\n1.10　在greenplum外部表中使用hdfs　24\n1.11　利用flume加载数据到hdfs中　26\n第2章　hdfs　28\n2.1　介绍　28\n2.2　读写hdfs数据　29\n2.3　使用lzo压缩数据　31\n2.4　读写序列化文件数据　34\n2.5　使用avro序列化数据　37\n2.6　使用thrift序列化数据　41\n.2.7　使用protocol buffers序列化数据　44\n2.8　设置hdfs备份因子　48\n2.9　设置hdfs块大小　49\n第3章　抽取和转换数据　51\n3.1　介绍　51\n3.2　使用mapreduce将apache日志转换为tsv格式　52\n3.3　使用apache pig过滤网络服务器日志中的爬虫访问量　54\n3.4　使用apache pig根据时间戳对网络服务器日志数据排序　57\n3.5　使用apache pig对网络服务器日志进行会话分析　59\n3.6　通过python扩展apache pig的功能　61\n3.7　使用mapreduce及二次排序计算页面访问量　62\n3.8　使用hive和python清洗、转换地理事件数据　67\n3.9　使用python和hadoop streaming执行时间序列分析　71\n3.10　在mapreduce中利用multipleoutputs输出多个文件　75\n3.11　创建用户自定义的hadoop writable及inputformat读取地理事件数据　78\n第4章　使用hive、pig和mapreduce处理常见的任务　85\n4.1　介绍　85\n4.2　使用hive将hdfs中的网络日志数据映射为外部表　86\n4.3　使用hive动态地为网络日志查询结果创建hive表　87\n4.4　利用hive字符串udf拼接网络日志数据的各个字段　89\n4.5　使用hive截取网络日志的ip字段并确定其对应的国家　92\n4.6　使用mapreduce对新闻档案数据生成n-gram　94\n4.7　通过mapreduce使用分布式缓存查找新闻档案数据中包含关键词的行　98\n4.8　使用pig加载一个表并执行包含group by的select操作　102\n第5章　高级连接操作　104\n5.1　介绍　104\n5.2　使用mapreduce对数据进行连接　104\n5.3　使用apache pig对数据进行复制连接　108\n5.4　使用apache pig对有序数据进行归并连接　110\n5.5　使用apache pig对倾斜数据进行倾斜连接　111\n5.6　在apache hive中通过map端连接对地理事件进行分析　113\n5.7　在apache hive通过优化的全外连接分析地理事件数据　115\n5.8　使用外部键值存储(redis)连接数据　118\n第6章　大数据分析　123\n6.1　介绍　123\n6.2　使用mapreduce和combiner统计网络日志数据集中的独立ip数　124\n6.3　运用hive日期udf对地理事件数据集中的时间日期进行转换与排序　129\n6.4　使用hive创建基于地理事件数据的每月死亡报告　131\n6.5　实现hive用户自定义udf用于确认地理事件数据的来源可靠性　133\n6.6　使用hive的map\/reduce操作以及python标记最长的无暴力发生的时间区间　136\n6.7　使用pig计算audioscrobbler数据集中艺术家之间的余弦相似度　141\n6.8　使用pig以及datafu剔除audioscrobbler数据集中的离群值　145\n第7章　高级大数据分析　147\n7.1　介绍　147\n7.2　使用apache giraph计算pagerank　147\n7.3　使用apache giraph计算单源最短路径　150\n7.4　使用apache giraph执行分布式宽度优先搜索　158\n7.5　使用apache mahout计算协同过滤　165\n7.6　使用apache mahout进行聚类　168\n7.7　使用apache mahout进行情感分类　171\n第8章　调试　174\n8.1　介绍　174\n8.2　在mapreduce中使用counters监测异常记录　174\n8.3　使用mrunit开发和测试mapreduce　177\n8.4　本地模式下开发和测试mapreduce　179\n8.5　运行mapreduce作业跳过异常记录　182\n8.6　在流计算作业中使用counters　184\n8.7　更改任务状态显示调试信息　185\n8.8　使用illustrate调试pig作业　187\n第9章　系统管理　189\n9.1　介绍　189\n9.2　在伪分布模式下启动hadoop　189\n9.3　在分布式模式下启动hadoop　192\n9.4　添加一个新节点　195\n9.5　节点安全退役　197\n9.6　namenode故障恢复　198\n9.7　使用ganglia监控集群　199\n9.8　mapreduce作业参数调优　201\n第10章　使用apache accumulo进行持久化　204\n10.1　介绍　204\n10.2　在accumulo中设计行键存储地理事件　205\n10.3　使用mapreduce批量导入地理事件数据到accumulo　213\n10.4　设置自定义字段约束accumulo中的地理事件数据　220\n10.5　使用正则过滤器限制查询结果　225\n10.6　使用sumcombiner计算同一个键的不同版本的死亡数总和　228\n10.7　使用accumulo实行单元级安全的扫描　232\n10.8　使用mapreduce聚集accumulo中的消息源　237","pages":"242","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27316881.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27316881.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27316881.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25839989\/","id":"25839989","publisher":"人民邮电出版社","isbn10":"7115337950","isbn13":"9787115337955","title":"Hadoop实战手册","url":"https:\/\/api.douban.com\/v2\/book\/25839989","alt_title":"Hadoop Real World Solutions Cookbook","author_intro":"jonathan r. owens：软件工程师，拥有java和c++技术背景，最近主要从事hadoop及相关分布式处理技术工作。目前就职于comscore公司，为核心数据处理团队成员。comscore是一家知名的从事数字测量与分析的公司，公司使用hadoop及其他定制的分布式系统对数据进行聚合、分析和管理，每天处理超过400亿单的交易。\njon lentz：comscore核心数据处理团队软件工程师。他更倾向于使用pig脚本来解决问题。在加入comscore之前，他主要开发优化供应链和分配固定收益证券的软件。\nbrian femiano：本科毕业于计算机科学专业，并且从事相关专业软件开发工作6年，最近两年主要利用hadoop构建高级分析与大数据存储。他拥有商业领域的相关经验，以及丰富的政府合作经验。他目前就职于potomac fusion公司，这家公司主要从事可扩展算法的开发，并致力于学习并改进政府领域中最先进和最复杂的数据集。他通过教授课程和会议培训在公司内部普及hadoop和云计算相关的技术。\n傅杰，硕士，毕业于清华大学高性能所，现就职于优酷土豆集团，任数据平台架构师，负责集团大数据基础平台建设，支撑其他团队的存储与计算需求，包含hadoop基础平台、日志采集系统、实时计算平台、消息系统、天机镜系统等。个人专注于大数据基础平台架构及安全研究，积累了丰富的平台运营经验，擅长hadoop平台性能调优、jvm调优及诊断各种mapreduce作业，还担任china hadoop submit 2013大会专家委员、优酷土豆大数据系列课程策划&讲师、easyhadoop社区讲师。\n赵磊，硕士，毕业于中国科学技术大学，现就职于优酷土豆集团，任数据挖掘算法工程师，负责集团个性化推荐和无线消息推送系统的搭建和相关算法的研究。个人专注于基于大数据的推荐算法的研究与应用，积累了丰富的大数据分析与数据挖掘的实践经验，对分布式计算和海量数据处理有深刻的认识。\n卢学裕，硕士，毕业于武汉大学，曾供职腾讯公司即通部门，现就职于优酷土豆集团，担任大数据技术负责人，负责优酷土豆集团大数据系统平台、大数据分析、数据挖掘和推荐系统。有丰富的hadoop平台使用及优化经验，尤其擅长mapreduce的性能优化。基于hadoop生态系统构建了优酷土豆的推荐系统，bi分析平台。","summary":"这是一本hadoop实用手册，主要针对实际问题给出相应的解决方案。《hadoop实战手册》特色是以实践结合理论分析，手把手教读者如何操作，并且对每个操作都做详细的解释，对一些重要的知识点也做了必要的拓展。全书共包括3个部分，第一部分为基础篇，主要介绍hadoop数据导入导出、hdfs的概述、pig与hive的使用、etl和简单的数据处理，还介绍了mapreduce的调试方式；第二部分为数据分析高级篇，主要介绍高级聚合、大数据分析等技巧；第三部分为系统管理篇，主要介绍hadoop的部署的各种模式、添加新节点、退役节点、快速恢复、mapreduce调优等。\n《hadoop实战手册》适合各个层次的hadoop技术人员阅读。通过阅读《hadoop实战手册》，hadoop初学者可以使用hadoop来进行数据处理，hadoop工程师或者数据挖掘工程师可以解决复杂的业务分析，hadoop系统管理员可以更好地进行日常运维。《hadoop实战手册》也可作为一本hadoop技术手册，针对要解决的相关问题，在工作中随时查阅。","price":"59.00元"},{"rating":{"max":10,"numRaters":10,"average":"8.6","min":0},"subtitle":"","author":["萨米尔·瓦德卡 (Sameer Wadkar)","马杜·西德林埃 (Madhu Siddalingaiah)","杰森·文纳 (Jason Venner)"],"pubdate":"2016-1-1","tags":[{"count":15,"name":"Hadoop","title":"Hadoop"},{"count":14,"name":"大数据","title":"大数据"},{"count":3,"name":"软件开发","title":"软件开发"},{"count":2,"name":"好书","title":"好书"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"图书馆","title":"图书馆"},{"count":1,"name":"Java","title":"Java"}],"origin_title":"Pro Apache Hadoop","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28360607.jpg","binding":"平装","translator":["于博","冯傲风"],"catalog":"目录\n译者序\n作者简介\n前言\n第1章为什么会有大数据1\n1.1什么是大数据1\n1.2大数据技术背后的核心思想2\n1.2.1把数据分发到多个节点2\n1.2.2把计算逻辑移动到数据附近3\n1.2.3计算节点进行本地数据处理3\n1.2.4优选顺序读，次之随机读4\n1.2.5一个例子4\n1.3大数据的编程模型5\n1.3.1大规模并行处理数据库系统5\n1.3.2内存数据库系统6\n1.3.3MapReduce系统6\n1.3.4整体同步并行系统8\n1.4大数据和事务性系统8\n1.5我们能处理多大的数据量9\n1.5.1一个计算密集型的例子10\n1.5.2Amdhal定律10\n1.6大数据商业用例11\n1.7本章小结12\n第2章Hadoop中的概念13\n2.1Hadoop简介13\n2.2MapReduce编程模型简介15\n2.3Hadoop系统的组成19\n2.3.1Hadoop 分布式文件系统20\n2.3.2辅助名称节点25\n2.3.3任务跟踪器26\n2.3.4作业跟踪器26\n2.4Hadoop 2.027\n2.4.1容器29\n2.4.2节点管理器29\n2.4.3资源管理器30\n2.4.4应用程序管理器30\n2.4.5分步详解YARN请求31\n2.5HDFS 的高可用性33\n2.6本章小结33\n第3章初识Hadoop框架34\n3.1安装类型34\n3.1.1单机模式35\n3.1.2伪分布式集群模式35\n3.1.3多节点集群安装模式35\n3.1.4基于Amazon EMR预安装模式35\n3.2使用Cloudera虚拟机搭建开发环境36\n3.3一个MapReduce程序的组成37\n3.4第一个Hadoop程序38\n3.4.1以本地模式运行程序的必要条件39\n3.4.2使用旧API编写的单词计数程序39\n3.4.3构建程序42\n3.4.4在集群模式下运行单词计数程序42\n3.4.5使用新API编写的单词计数程序43\n3.4.6构建程序44\n3.4.7在集群模式下运行单词计数程序45\n3.5Hadoop作业中的第三方函数库45\n3.6本章小结50\n第4章Hadoop系统管理51\n4.1Hadoop的配置文件51\n4.2配置Hadoop守护进程52\n4.3Hadoop配置文件的优先级53\n4.4深入探究Hadoop配置文件54\n4.4.1core—site.xml54\n4.4.2hdfs—*.xml55\n4.4.3mapred—site.xml56\n4.4.4yarn—site.xml58\n4.4.5YARN中的内存分配60\n4.5调度器61\n4.5.1计算能力调度器62\n4.5.2公平调度器65\n4.5.3公平调度器配置65\n4.5.4 yarn—site.xml 配置66\n4.5.5策略文件的格式和配置67\n4.5.6按照drf策略来确定优势资源的分配68\n4.6从属文件69\n4.7机架感知69\n4.8 集群管理工具71\n4.8.1检查HDFS71\n4.8.2 HDFS管理命令行73\n4.8.3 均衡HDFS上的数据分布75\n4.8.4从HDFS中复制海量数据76\n4.9本章小结76\n第5章MapReduce开发基础78\n5.1 Hadoop和数据处理78\n5.2 航空公司数据集介绍79\n5.2.1 准备开发环境80\n5.2.2 准备Hadoop系统81\n5.3 MapReduce编程模式81\n5.3.1 只有Map阶段的作业（SELECT和WHERE查询）82\n5.3.2 问题定义—SELECT子句82\n5.3.3 问题定义—WHERE子句90\n5.3.4 Map和Reduce作业（聚合查询）93\n5.3.5 问题定义—GROUP BY和SUM子句93\n5.3.6 应用Combiner提高Aggregation性能99\n5.3.7 问题定义—优化后的Aggregators99\n5.3.8 Partitioner的作用104\n5.3.9 问题定义—按月分离航空数据105\n5.4 综合分析108\n5.5 本章小结110\n第6章MapReduce开发进阶111\n6.1 MapReduce编程模式111\n6.2 Hadoop I／O 介绍111\n6.3 问题定义—排序114\n6.3.1 主要挑战：全排序115\n6.3.2 在Cluster中运行Sorting作业125\n6.3.3 仅根据Writable键排序125\n6.3.4 根据排序回顾Hadoop的关键特性128\n6.4 问题定义—分析连续的记录128\n6.4.1 支持二次排序的重要组件129\n6.4.2 在没有Grouping Comparator的情况下实现Secondary Sort136\n6.4.3 在Cluster中运行SecondarySort作业137\n6.4.4 利用Secondary Sort回顾Hadoop的关键特性137\n6.5 问题定义—使用MapReducer进行连接138\n6.5.1 处理多输入：Multiple—Inputs 类138\n6.5.2 具备多个输入的Mapper类139\n6.5.3 自定义 Partitioner： Carrier—CodeBasedPartioner141\n6.5.4 在Reducer中实现连接141\n6.5.5 在集群中运行MapReduce连接作业143\n6.5.6 探讨与MapReduce相关的Hadoop主要特性144\n6.6 问题定义—使用Map—Only 作业进行连接144\n6.6.1 基于DistributeCache的解决方案145\n6.6.2 在集群中运行Map—Only的连接作业147\n6.6.3 总结探讨Map—Only连接时的Hadoop关键特性149\n6.7 在MR作业中保存结果到多输出文件149\n6.8 使用计数器收集统计数据151\n6.9 本章小结153\n第7章 Hadoop输入／输出155\n7.1 压缩方式155\n7.1.1 压缩内容的选择156\n7.1.2 各种压缩方式157\n7.1.3 配置压缩方式158\n7.2 Hadoop的I／O处理过程内部159\n7.2.1 Inputformat159\n7.2.2 OutputFormat161\n7.2.3 自定义OutputFormat：将文本转换成XML161\n7.2.4 自定义 InputFormat：使用自定义的XML文件165\n7.3 Hadoop文件173\n7.3.1 SequenceFile173\n7.3.2 MapFiles178\n7.3.3 Avro Files180\n7.4 本章小结185\n第8章 测试Hadoop程序186\n8.1 回顾一下单词统计的程序186\n8.2 MRUnit概述188\n8.2.1 安装MRUnit188\n8.2.2 MRUnit 核心类188\n8.2.3 编写一个MRUnit测试用例189\n8.2.4 测试计数器191\n8.2.5 MRUnit的特性194\n8.2.6 MRUnit的局限性194\n8.3 用LocalJobRunner测试195\n8.3.1 setUp（ ）方法196\n8.3.2 LocalJobRunner的局限性197\n8.4 用MiniMRCluster测试198\n8.4.1 配置开发环境198\n8.4.2 MiniMRCluster例子199\n8.4.3 MiniMRCluster的局限性201\n8.5 对访问网络资源的MR作业进行测试202\n8.6 本章小结202\n第9章Hadoop的监控203\n9.1 在Hadoop MapReduce Jobs中写日志消息203\n9.2 在Hadoop MapReduce Jobs中查看日志消息206\n9.3 在Hadoop 2.x中使用日志管理208\n9.3.1 Hadoop 2.x中的日志存储208\n9.3.2 日志管理提升210\n9.3.3 使用基于Web的界面查看日志210\n9.3.4 命令行界面211\n9.3.5 日志的保存211\n9.4 Hadoop集群性能监控211\n9.5 使用YARN REST API212\n9.6 使用供应商工具管理Hadoop集群213\n9.7 本章小结214\n第10章使用Hadoop构建数据仓库215\n10.1 Apache Hive215\n10.1.1 安装Hive216\n10.1.2 Hive的架构217\n10.1.3 元数据存储217\n10.1.4 HiveQL编译基础217\n10.1.5 Hive使用的概念218\n10.1.6 HiveQL编译细节222\n10.1.7 数据定义语言226\n10.1.8 数据操作语言226\n10.1.9 扩展接口227\n10.1.10 Hive脚本229\n10.1.11 性能表现229\n10.1.12 整合MapReduce230\n10.1.13 创建分区230\n10.1.14 用户定义函数232\n10.2 Impala234\n10.2.1 Impala架构234\n10.2.2 Impala特性235\n10.2.3 Impala的局限235\n10.3 Shark235\n10.4 本章小结237\n第11章使用Pig进行数据处理238\n11.1 Pig简介238\n11.2 运行Pig240\n11.2.1 在Grunt Shell中执行241\n11.2.2 执行Pig脚本241\n11.2.3 嵌入式Java程序242\n11.3 Pig Latin243\n11.3.1 Pig脚本中的注释243\n11.3.2 Pig语句的执行243\n11.3.3 Pig命令244\n11.4 UDF249\n11.4.1 Mapper中的Eval函数调用249\n11.4.2 Reducer中的Eval函数调用250\n11.4.3 编写并使用自定义Filter—Func256\n11.5 Pig与Hive对比258\n11.6 Crunch API259\n11.6.1 Crunch与Pig的区别259\n11.6.2 Crunch管道的例子260\n11.7 本章小结265\n第12章HCatalog和企业级Hadoop266\n12.1 HCataolg和企业级数据仓库用户266\n12.2 HCatalog技术背景简介 267\n12.2.1 HCatalog命令行接口269\n12.2.2 WebHCat269\n12.2.3 HCatalog的MapReduce接口270\n12.2.4 HCatalog的Pig接口273\n12.2.5 HCatalog通知接口274\n12.3 HCatalog的安全和认证机制274\n12.4 完整的解决方案275\n12.5 本章小结275\n第13章使用Hadoop分析日志277\n13.1 日志文件分析应用277\n13.1.1 网络分析277\n13.1.2 安全规范与法务278\n13.1.3 监控和报警279\n13.1.4 物联网279\n13.2 分析步骤280\n13.2.1 载入280\n13.2.2 提取280\n13.2.3 可视化281\n13.3 Apache Flume281\n13.4 Netflix Suro283\n13.5 云解决方案285\n13.6 本章小结285\n第14章使用HBase构建实时系统286\n14.1 HBase是什么286\n14.2 典型的HBase用例场景287\n14.3 HBase数据模型288\n14.3.1 HBase逻辑视图和客户端视图288\n14.3.2 HBase与RDBMS的区别289\n14.3.3 HBase表290\n14.3.4 HBase单元格290\n14.3.5 HBase列簇290\n14.4 HBase命令和API291\n14.4.1 获取命令列表：帮助命令291\n14.4.2 创建表：create命令292\n14.4.3 向表中加入行：put命令293\n14.4.4 从表中检索行：get命令293\n14.4.5 读取多行：scan命令293\n14.4.6 统计表中的行数：count命令293\n14.4.7 删除行：delete命令294\n14.4.8 清空表：truncate命令294\n14.4.9 删除表：drop命令294\n14.4.10 更换表：alter命令294\n14.5 HBase架构295\n14.5.1 HBase组件295\n14.5.2 HBase中的压缩与分区302\n14.5.3 压缩303\n14.6 HBase配置概览304\n14.7 HBase应用程序设计305\n14.7.1 长表vs宽表vs窄表305\n14.7.2 行键设计306\n14.8 使用Java API操作HBase307\n14.8.1 一切都是字节307\n14.8.2 创建HBase表307\n14.8.3 使用HBaseAdmin类管理HBase308\n14.8.4 使用Java API访问数据308\n14.9 HBase与MapReduce集成312\n14.9.1 使用MapReduce任务读取HBase表312\n14.9.2 HBase和MapReduce集群315\n14.10 本章小结316\n第15章Hadoop与数据科学317\n15.1 Hadoop中的数据科学方法318\n15.2 Apache Hama318\n15.2.1 整体同步并行计算模型318\n15.2.2 Hama Hello World！319\n15.2.3 蒙特卡洛方法321\n15.2.4 K—Means聚类324\n15.3 Apache Spark327\n15.3.1 弹性分布式数据集（RDD）327\n15.3.2 Spark与蒙特卡洛算法328\n15.3.3 Spark与KMeans聚类330\n15.4 RHadoop332\n15.5 本章小结333\n第16章Hadoop与云计算334\n16.1 经济性334\n16.1.1 自有集群335\n16.1.2 基于云平台的集群335\n16.1.3 弹性336\n16.1.4 按需付费336\n16.1.5 竞价336\n16.1.6 混合集群336\n16.2 后勤保障337\n16.2.1 导入／导出337\n16.2.2 数据保存337\n16.3 安全性337\n16.4 云端应用模型338\n16.5 云服务商339\n16.5.1 亚马逊网络服务（AWS）339\n16.5.2 谷歌云平台341\n16.5.3 微软Azure342\n16.5.4 选择云服务商342\n16.6 案例学习： AWS342\n16.6.1 EMR343\n16.6.2 EC2345\n16.7 本章小结348\n第17章构建YARN应用程序349\n17.1 YARN：通用分布式系统349\n17.2 YARN：快速浏览351\n17.3 创建YARN应用程序353\n17.4 DownloadService.java类354\n17.5 Client.java类356\n17.5.1 从客户端启动应用管理器的步骤356\n17.5.2 创建YarnClient357\n17.5.3 配置应用程序357\n17.5.4 启动应用管理器360\n17.5.5 监控应用360\n17.6 ApplicationMaster.java362\n17.6.1 启动工作任务的步骤363\n17.6.2 初始化应用管理器协议和容器管理协议364\n17.6.3 在资源管理器中注册应用管理器364\n17.6.4 配置容器参数364\n17.6.5 向资源管理器请求容器364\n17.6.6 在任务节点上启动容器364\n17.6.7 等待容器结束工作任务365\n17.6.8 在资源管理器中注销应用管理器365\n17.7 运行应用管理器367\n17.7.1 在非托管模式中启动应用管理器367\n17.7.2 在托管模式中启动应用管理器367\n17.8 本章小结367\n附录Ａ安装Hadoop\n附录B使用Maven和Eclipse\n附录CApache Ambari","pages":"384","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28360607.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28360607.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28360607.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26684358\/","id":"26684358","publisher":"机械工业出版社","isbn10":"711151565X","isbn13":"9787111515654","title":"深入理解Hadoop（原书第2版）","url":"https:\/\/api.douban.com\/v2\/book\/26684358","alt_title":"Pro Apache Hadoop","author_intro":"","summary":"本书作者基于对Hadoop系统的实践，深入浅出地对Hadoop进行了详细的讲解，包含大量的实例和技巧，可帮助有一定基础的开发者快速掌握分布式系统。主要内容包括：第1章～第4章讲解大数据系统的基本概念、Hadoop系统的关键概念，以及进行Hadoop平台管理的关键概念要素。第5章～第7章是本书的重点，深入分析了MapReduce框架，不仅包括MapReduce框架的API，还介绍MapReduce框架的更复杂概念及其设计理念。第8章～第14章介绍Hadoop生态系统，包括支持MapReduce程序的单元测试和集成测试框架、Hadoop系统的监控和日志系统、Hive框架、Pig和Crunch框架、HCatalog框架、Hadoop日志流处理、HBase等。第15章～第17章介绍了数据科学基本概念及应用、云计算实例、分布式下载服务实例等。","series":{"id":"19432","title":"大数据技术丛书"},"price":"56.00"},{"rating":{"max":10,"numRaters":20,"average":"6.0","min":0},"subtitle":"","author":["刘刚"],"pubdate":"2014-1-1","tags":[{"count":5,"name":"Hadoop","title":"Hadoop"},{"count":3,"name":"hadoop应用开发技术详解","title":"hadoop应用开发技术详解"},{"count":2,"name":"大数据","title":"大数据"},{"count":1,"name":"开发编程","title":"开发编程"},{"count":1,"name":"开发","title":"开发"},{"count":1,"name":"互联网","title":"互联网"},{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Java","title":"Java"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27783700.jpg","binding":"平装","translator":[],"catalog":"前言\n第1章 Hadoop概述\n1.1 Hadoop起源\n1.1.1 Google与Hadoop模块\n1.1.2 为什么会有Hadoop\n1.1.3 Hadoop版本介绍\n1.2 Hadoop生态系统\n1.3 Hadoop常用项目介绍\n1.4 Hadoop在国内的应用\n1.5 本章小结\n第2章 Hadoop安装\n2.1 Hadoop环境安装配置\n2.1.1 安装VMware\n2.1.2 安装Ubuntu\n2.1.3 安装VMwareTools\n2.1.4 安装JDK\n2.2 Hadoop安装模式\n2.2.1 单机安装\n2.2.2 伪分布式安装\n2.2.3 分布式安装\n2.3 如何使用Hadoop\n2.3.1 Hadoop的启动与停止\n2.3.2 Hadoop配置文件\n2.4 本章小结\n第3章 MapReduce快速入门\n3.1 WordCount实例准备开发环境\n3.1.1 使用Eclipse创建一个Java工程\n3.1.2 导入Hadoop的JAR文件\n3.2 MapReduce代码的实现\n3.2.1 编写WordMapper类\n3.2.2 编写WordReducer类\n3.2.3 编写WordMain驱动类\n3.3 打包、部署和运行\n3.3.1 打包成JAR文件\n3.3.2 部署和运行\n3.3.3 测试结果\n3.4 本章小结\n第4章 Hadoop分布式文件系统详解\n4.1 认识HDFS\n4.1.1 HDFS的特点\n4.1.2 Hadoop文件系统的接口\n4.1.3 HDFS的Web服务\n4.2 HDFS架构\n4.2.1 机架\n4.2.2 数据块\n4.2.3 元数据节点\n4.2.4 数据节点\n4.2.5 辅助元数据节点\n4.2.6 名字空间\n4.2.7 数据复制\n4.2.8 块备份原理\n4.2.9 机架感知\n4.3 Hadoop的RPC机制\n4.3.1 RPC的实现流程\n4.3.2 RPC的实体模型\n4.3.3 文件的读取\n4.3.4 文件的写入\n4.3.5 文件的一致模型\n4.4 HDFS的HA机制\n4.4.1 HA集群\n4.4.2 HA架构\n4.4.3 为什么会有HA机制\n4.5 HDFS的Federation机制\n4.5.1 单个NameNode的HDFS架构的局限性\n4.5.2 为什么引入Federation机制\n4.5.3 Federation架构\n4.5.4 多个名字空间的管理问题\n4.6 Hadoop文件系统的访问\n4.6.1 安全模式\n4.6.2 HDFS的Shell访问\n4.6.3 HDFS处理文件的命令\n4.7 JavaAPI接口\n4.7.1 HadoopURL读取数据\n4.7.2 FileSystem类\n4.7.3 FileStatus类\n4.7.4 FSDataInputStream类\n4.7.5 FSDataOutputStream类\n4.7.6 列出HDFS下所有的文件\n4.7.7 文件的匹配\n4.7.8 PathFilter对象\n4.8 维护HDFS\n4.8.1 追加数据\n4.8.2 并行复制\n4.8.3 升级与回滚\n4.8.4 添加节点\n4.8.5 删除节点\n4.9 HDFS权限管理\n4.9.1 用户身份\n4.9.2 权限管理的原理\n4.9.3 设置权限的Shell命令\n4.9.4 超级用户\n4.9.5 HDFS权限配置参数\n4.10 本章小结\n第5章 Hadoop文件I\/O详解\n5.1 Hadoop文件的数据结构\n5.1.1 SequenceFile存储\n5.1.2 MapFile存储\n5.1.3 SequenceFile转换为MapFile\n5.2 HDFS数据完整性\n5.2.1 校验和\n5.2.2 数据块检测程序\n5.3 文件序列化\n5.3.1 进程间通信对序列化的要求\n5.3.2 Hadoop文件的序列化\n5.3.3 Writable接口\n5.3.4 WritableComparable接口\n5.3.5 自定义Writable接口\n5.3.6 序列化框架\n5.3.7 数据序列化系统Avro\n5.4 Hadoop的Writable类型\n5.4.1 Writable类的层次结构\n5.4.2 Text类型\n5.4.3 NullWritable类型\n5.4.4 ObjectWritable类型\n5.4.5 GenericWritable类型\n5.5 文件压缩\n5.5.1 Hadoop支持的压缩格式\n5.5.2 Hadoop中的编码器和解码器\n5.5.3 本地库\n5.5.4 可分割压缩LZO\n5.5.5 压缩文件性能比较\n5.5.6 Snappy压缩\n5.5.7 gzip、LZO和Snappy比较\n5.6 本章小结\n第6章 MapReduce工作原理\n6.1 MapReduce的函数式编程概念\n6.1.1 列表处理\n6.1.2 Mapping数据列表\n6.1.3 Reducing数据列表\n6.1.4 Mapper和Reducer如何工作\n6.1.5 应用实例：词频统计\n6.2 MapReduce框架结构\n6.2.1 MapReduce模型\n6.2.2 MapReduce框架组成\n6.3 MapReduce运行原理\n6.3.1 作业的提交\n6.3.2 作业初始化\n6.3.3 任务的分配\n6.3.4 任务的执行\n6.3.5 进度和状态的更新\n6.3.6 MapReduce的进度组成\n6.3.7 任务完成\n6.4 MapReduce容错\n6.4.1 任务失败\n6.4.2 TaskTracker失败\n6.4.3 JobTracker失败\n6.4.4 子任务失败\n6.4.5 任务失败反复次数的处理方法\n6.5 Shuffle阶段和Sort阶段\n6.5.1 Map端的Shuffle\n6.5.2 Reduce端的Shuffle\n6.5.3 Shuffle过程参数调优\n6.6 任务的执行\n6.6.1 推测执行\n6.6.2 任务JVM重用\n6.6.3 跳过坏的记录\n6.6.4 任务执行的环境\n6.7 作业调度器\n6.7.1 先进先出调度器\n6.7.2 容量调度器\n6.7.3 公平调度器\n6.8 自定义Hadoop调度器\n6.8.1 Hadoop调度器框架\n6.8.2 编写Hadoop调度器\n6.9 YARN介绍\n6.9.1 异步编程模型\n6.9.2 YARN支持的计算框架\n6.9.3 YARN架构\n6.9.4 YARN工作流程\n6.10 本章小结\n第7章 Eclipse插件的应用\n7.1 编译Hadoop源码\n7.1.1 下载Hadoop源码\n7.1.2 准备编译环境\n7.1.3 编译common组件\n7.2 Eclipse安装MapReduce插件\n7.2.1 查找MapReduce插件\n7.2.2 新建一个Hadooplocation\n7.2.3 Hadoop插件操作HDFS\n7.2.4 运行MapReduce的驱动类\n7.3 MapReduce的Debug调试\n7.3.1 进入Debug运行模式\n7.3.2 Debug调试具体操作\n7.4 单元测试框架MRUnit\n7.4.1 认识MRUnit框架\n7.4.2 准备测试案例\n7.4.3 Mapper单元测试\n7.4.4 Reducer单元测试\n7.4.5 MapReduce单元测试\n7.5 本章小结\n第8章 MapReduce编程开发\n8.1 WordCount案例分析\n8.1.1 MapReduce工作流程\n8.1.2 WordCount的Map过程\n8.1.3 WordCount的Reduce过程\n8.1.4 每个过程产生的结果\n8.1.5 Mapper抽象类\n8.1.6 Reducer抽象类\n8.1.7 MapReduce驱动\n8.1.8 MapReduce最小驱动\n8.2 输入格式\n8.2.1 InputFormat接口\n8.2.2 InputSplit类\n8.2.3 RecordReader类\n8.2.4 应用实例：随机生成100个小数并求最大值\n8.3 输出格式\n8.3.1 OutputFormat接口\n8.3.2 RecordWriter类\n8.3.3 应用实例：把首字母相同的单词放到一个文件里\n8.4 压缩格式\n8.4.1 如何在MapReduce中使用压缩\n8.4.2 Map作业输出结果的压缩\n8.5 MapReduce优化\n8.5.1 Combiner类\n8.5.2 Partitioner类\n8.5.3 分布式缓存\n8.6 辅助类\n8.6.1 读取Hadoop配置文件\n8.6.2 设置Hadoop的配置文件属性\n8.6.3 GenericOptionsParser选项\n8.7 Streaming接口\n8.7.1 Streaming工作原理\n8.7.2 Streaming编程接口参数\n8.7.3 作业配置属性\n8.7.4 应用实例：抓取网页的标题\n8.8 本章小结\n第9章 MapReduce高级应用\n9.1 计数器\n9.1.1 默认计数器\n9.1.2 自定义计数器\n9.1.3 获取计数器\n9.2 MapReduce二次排序\n9.2.1 二次排序原理\n9.2.2 二次排序的算法流程\n9.2.3 代码实现\n9.3 MapReduce中的Join算法\n9.3.1 Reduce端Join\n9.3.2 Map端Join\n9.3.3 半连接SemiJoin\n9.4 MapReduce从MySQL读写数据\n9.4.1 读数据\n9.4.2 写数据\n9.5 Hadoop系统调优\n9.5.1 小文件优化\n9.5.2 Map和Reduce个数设置\n9.6 本章小结\n第10章 数据仓库工具Hive\n10.1 认识Hive\n10.1.1 Hive工作原理\n10.1.2 Hive数据类型\n10.1.3 Hive的特点\n10.1.4 Hive下载与安装\n10.2 Hive架构\n10.2.1 Hive用户接口\n10.2.2 Hive元数据库\n10.2.3 Hive的数据存储\n10.2.4 Hive解释器\n10.3 Hive文件格式\n10.3.1 TextFile格式\n10.3.2 SequenceFile格式\n10.3.3 RCFile文件格式\n10.3.4 自定义文件格式\n10.4 Hive操作\n10.4.1 表操作\n10.4.2 视图操作\n10.4.3 索引操作\n10.4.4 分区操作\n10.4.5 桶操作\n10.5 Hive复合类型\n10.5.1 Struct类型\n10.5.2 Array类型\n10.5.3 Map类型\n10.6 Hive的JOIN详解\n10.6.1 JOIN操作语法\n10.6.2 JOIN原理\n10.6.3 外部JOIN\n10.6.4 Map端JOIN\n10.6.5 JOIN中处理NULL值的语义区别\n10.7 Hive优化策略\n10.7.1 列裁剪\n10.7.2 MapJoin操作\n10.7.3 GroupBy操作\n10.7.4 合并小文件\n10.8 Hive内置操作符与函数\n10.8.1 字符串函数\n10.8.2 集合统计函数\n10.8.3 复合类型操作\n10.9 Hive用户自定义函数接口\n10.9.1 用户自定义函数UDF\n10.9.2 用户自定义聚合函数UDAF\n10.10 Hive的权限控制\n10.10.1 角色的创建和删除\n10.10.2 角色的授权和撤销\n10.10.3 超级管理员权限\n10.11 应用实例：使用JDBC开发Hive程序\n10.11.1 准备测试数据\n10.11.2 代码实现\n10.12 本章小结\n第11章 开源数据库HBase\n11.1 认识HBase\n11.1.1 HBase的特点\n11.1.2 HBase访问接口\n11.1.3 HBase存储结构\n11.1.4 HBase存储格式\n11.2 HBase设计\n11.2.1 逻辑视图\n11.2.2 框架结构及流程\n11.2.3 Table和Region的关系\n11.2.4 -ROOT-表和.META.表\n11.3 关键算法和流程\n11.3.1 Region定位\n11.3.2 读写过程\n11.3.3 Region分配\n11.3.4 RegionServer上线和下线\n11.3.5 Master上线和下线\n11.4 HBase安装\n11.4.1 HBase单机安装\n11.4.2 HBase分布式安装\n11.5 HBase的Shell操作\n11.5.1 一般操作\n11.5.2 DDL操作\n11.5.3 DML操作\n11.5.4 HBaseShell脚本\n11.6 HBase客户端\n11.6.1 JavaAPI交互\n11.6.2 MapReduce操作HBase\n11.6.3 向HBase中写入数据\n11.6.4 读取HBase中的数据\n11.6.5 Avro、REST和Thrift接口\n11.7 本章小结\n第12章 Mahout算法\n12.1 Mahout的使用\n12.1.1 安装Mahout\n12.1.2 运行一个Mahout案例\n12.2 Mahout数据表示\n12.2.1 偏好Perference类\n12.2.2 数据模型DataModel类\n12.2.3 Mahout链接MySQL数据库\n12.3 认识Taste框架\n12.4 Mahout推荐器\n12.4.1 基于用户的推荐器\n12.4.2 基于项目的推荐器\n12.4.3 SlopeOne推荐策略\n12.5 推荐系统\n12.5.1 个性化推荐\n12.5.2 商品推荐系统案例\n12.6 本章小结\n附录A Hive内置操作符与函数\n附录B HBase默认配置解释[1]\n附录C Hadoop三个配置文件的参数含义说明","ebook_url":"https:\/\/read.douban.com\/ebook\/15354961\/","pages":"408","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27783700.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27783700.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27783700.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25844776\/","id":"25844776","publisher":"机械工业出版社","isbn10":"7111452445","isbn13":"9787111452447","title":"Hadoop应用开发技术详解","url":"https:\/\/api.douban.com\/v2\/book\/25844776","alt_title":"","author_intro":"","summary":"《大数据技术丛书：Hadoop应用开发技术详解》共12章。第1～2章详细地介绍了Hadoop的生态系统、关键技术以及安装和配置；第3章是MapReduce的使用入门，让读者了解整个开发过程；第4～5章详细讲解了分布式文件系统HDFS和Hadoop的文件I\/O；第6章分析了MapReduce的工作原理；第7章讲解了如何利用Eclipse来编译Hadoop的源代码，以及如何对Hadoop应用进行测试和调试；第8～9章细致地讲解了MapReduce的开发方法和高级应用；第10～12章系统地讲解了Hive、HBase和Mahout。","ebook_price":"30.00","series":{"id":"19432","title":"大数据技术丛书"},"price":"79.00元"},{"rating":{"max":10,"numRaters":13,"average":"7.9","min":0},"subtitle":"","author":["Mark Grover","Ted Malaska","Jonathan Seidman","Gwen Shapira"],"pubdate":"2017-1","tags":[{"count":14,"name":"大数据","title":"大数据"},{"count":13,"name":"Hadoop","title":"Hadoop"},{"count":6,"name":"计算机","title":"计算机"},{"count":2,"name":"架构","title":"架构"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"Overview","title":"Overview"},{"count":1,"name":"HADOOP","title":"HADOOP"}],"origin_title":"Hadoop Application Architectures: Designing Real-World Big Data Applications","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29335153.jpg","binding":"平装","translator":["郭文超"],"catalog":"版权声明\nO'Reilly Media, Inc. 介绍\n译者序\n序\n前言\n第一部分　考虑 Hadoop 应用的架构设计\n第 1 章　Hadoop 数据建模\n第 2 章　Hadoop 数据移动\n第 3 章　Hadoop 数据处理\n第 4 章　Hadoop 数据处理通用范式\n第 5 章　Hadoop 图处理\n第 6 章　协调调度\n第 7 章　Hadoop 近实时处理\n第二部分　案例研究\n第 8 章　点击流分析\n第 9 章　欺诈检测\n第 10 章　数据仓库\n附录 A　Impala 中的关联\n作者简介\n封面介绍","pages":"304","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29335153.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29335153.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29335153.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26971353\/","id":"26971353","publisher":"人民邮电出版社","isbn10":"7115442436","isbn13":"9787115442437","title":"Hadoop应用架构","url":"https:\/\/api.douban.com\/v2\/book\/26971353","alt_title":"Hadoop Application Architectures: Designing Real-World Big Data Applications","author_intro":"Mark Grover\nApache Sentry项目管理委员会成员，《Hive编程指南》作者之一，曾参与Apache Hadoop、Apache Hive、Apache Sqoop以及Apache Flume等项目，并为Apache Bigtop项目和Apache Sentry（项目孵化中）项目贡献代码。\nTed Malaska\nCloudera公司的资深解决方案架构师，致力于帮助客户更好地掌握Hadoop及其生态系统。曾任美国金融业监管局（FINRA，Financial Industry Regulatory Authority）首席架构师，指导建设了包括网络应用、服务型架构以及大数据应用在内的大量解决方案。曾为Apache Flume、Apache Avro、YARN以及Apache Pig等项目贡献代码。\nJonathan Seidman\nCloudera公司的解决方案架构师，协助合作伙伴将的解决方案集成到Cloudera的软件栈中。芝加哥Hadoop用户组（Chicago Hadoop User Group）及芝加哥大数据（Chicago Big Data）的联合创始人、《Hadoop实战》技术编辑。曾任Orbiz Worldwide公司大数据团队技术主管，为最为繁忙的站点管理了承载海量数据的Hadoop集群。也曾多次在Hadoop及大数据专业会议上发言。\nGwen Shapira\nCloudera公司的解决方案架构师，知名博主，拥有15年从业经验，协助客户设计高扩展性的数据架构。曾任Pythian高级顾问、Oracle ACE主管以及NoCOUG董事会成员，活跃于诸多业内会议","summary":"-使用Hadoop进行数据存储和建模的着眼点和思路\n-将数据输入、输出系统的最佳方案\n-MapReduce、Spark和Hive等数据处理框架介绍\n-数据去重、窗口分析等常见Hadoop处理模式应用\n-在Hadoop上采用Giraph、GraphX等图形处理工具\n-综合使用工作流以及Apache Oozie等调度工具\n-以Apache Oozie、Apache Spark Streaming和Apache Flume进行近实时流处理\n-点击流分析、欺诈检验和数据仓库的架构案例\n本书就使用Apache Hadoop端到端数据管理方案提供专业架构指导。其他书籍大多针对Hadoop生态系统中的软件，讲解较为单一的使用方法，而本书偏重实践，在架构的高度详细阐释诸多工具如何相互配合，搭建出打磨之后的完整应用。书中提供了诸多案例，易于理解，配有详细的代码解析，知识点一目了然。\n为加强训练，本书后半部分提供了详细的案例，涵盖最为常见的Hadoop应用架构。无论是设计Hadoop应用，还是将Hadoop同现有数据基础架构集成，本书都可以提供详实的参考。","series":{"id":"697","title":"O'reilly系列"},"price":"69"},{"rating":{"max":10,"numRaters":13,"average":"6.6","min":0},"subtitle":"","author":["刘军"],"pubdate":"2013-9-1","tags":[{"count":10,"name":"Hadoop","title":"Hadoop"},{"count":9,"name":"大数据","title":"大数据"},{"count":3,"name":"计算机","title":"计算机"},{"count":2,"name":"软件开发","title":"软件开发"},{"count":2,"name":"开发","title":"开发"},{"count":2,"name":"人民邮电出版社","title":"人民邮电出版社"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":2,"name":"2015","title":"2015"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27240438.jpg","binding":"平装","translator":[],"catalog":"","pages":"289","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27240438.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27240438.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27240438.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25848490\/","id":"25848490","publisher":"人民邮电出版社","isbn10":"7115323240","isbn13":"9787115323248","title":"Hadoop大数据处理","url":"https:\/\/api.douban.com\/v2\/book\/25848490","alt_title":"","author_intro":"","summary":"","price":"CNY 59.00"},{"rating":{"max":10,"numRaters":12,"average":"7.9","min":0},"subtitle":"技术详解与项目实战","author":[],"pubdate":"2015-3-1","tags":[{"count":11,"name":"Hadoop","title":"Hadoop"},{"count":10,"name":"大数据","title":"大数据"},{"count":3,"name":"编程","title":"编程"},{"count":3,"name":"数据挖掘","title":"数据挖掘"},{"count":3,"name":"数据平台","title":"数据平台"},{"count":2,"name":"计算机科学","title":"计算机科学"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"技术","title":"技术"}],"origin_title":"范东来","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28103305.jpg","binding":"平装","translator":[],"catalog":"","pages":"316","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28103305.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28103305.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28103305.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26418592\/","id":"26418592","publisher":"人民邮电出版社","isbn10":"7115380996","isbn13":"9787115380999","title":"Hadoop海量数据处理","url":"https:\/\/api.douban.com\/v2\/book\/26418592","alt_title":"范东来","author_intro":"","summary":"Hadoop是目前最受关注的大数据处理平台和解决方案，并且已经广泛应用于生产环境。本书主要介绍Hadoop技术的相关知识，不但详细介绍了Hadoop、MapReduce、HDFS、Hive和Sqoop，还深入探讨了Hadoop的运维和调优，并包含了一个具有代表性的完整的基于Hadoop的商业智能系统的设计和实现。\n本书的最大特点是面向实践。基础篇介绍Hadoop及相关组件的同时，包含了大量动手实例，而应用篇包含的基于Hadoop的完整实例脱胎于生产环境的真实项目。在应用篇中，读者不仅能够通过项目实战巩固基础篇的学习效果，还能学习商业智能系统的开发过程。\n本书由浅至深，从理论基础到项目实战，适合Hadoop的初学者阅读，也适合作为高等院校相关课程的教学参考书。","price":"59.00元"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["Danil Zburivsky","Sudheesh Narayanan"],"pubdate":"2014-10-1","tags":[{"count":4,"name":"大数据","title":"大数据"},{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"软件","title":"软件"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"工具书","title":"工具书"}],"origin_title":"Hadoop Cluster Deployment，Securing Hadoop","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27728852.jpg","binding":"平装","translator":["刘杰","沈鑫"],"catalog":"目　录\n译者序\n作者简介\n审校者简介\n前言\n第1章　构建Hadoop集群1\n1.1　选择Hadoop集群硬件2\n1.1.1　选择DataNode硬件3\n1.1.2　低存储密度集群4\n1.1.3　高存储密度集群5\n1.1.4　NameNode和JobTracker硬件配置6\n1.1.5　网关和其他辅助服务8\n1.1.6　网络配置8\n1.1.7　Hadoop硬件总结9\n1.2　Hadoop发行版10\n1.2.1　Hadoop版本10\n1.2.2　选择Hadoop发行版11\n1.2.3　Cloudera Hadoop 发行版11\n1.2.4　Hortonworks Hadoop发行版12\n1.2.5　MapR12\n1.3　为Hadoop集群选择操作系统13\n1.4　小结14\n第2章　安装和配置Hadoop15\n2.1　在Hadoop集群中配置操作系统15\n2.1.1　选择和设置文件系统15\n2.1.2　设置Java开发包16\n2.1.3　其他操作系统设定17\n2.1.4　设置CDH存储库18\n2.2　设置NameNode18\n2.2.1　JournalNode节点、ZooKeeper以及故障转移控制器22\n2.2.2Hadoop配置文件23\n2.2.3　NameNode高可用方案配置25\n2.2.4　JobTracker配置31\n2.2.5DataNode配置36\n2.3　小结47\n第3章　配置Hadoop生态系统48\n3.1托管Hadoop生态项目48\n3.2　Sqoop49\n3.2.1安装和配置Sqoop49\n3.2.2　Sqoop导入示例50\n3.2.3　Sqoop导出示例52\n3.3　Hive52\n3.3.1Hive架构53\n3.3.2安装Hive Metastore54\n3.3.3　安装Hive客户端　56\n3.3.4　安装Hive Server57\n3.4Impala59\n3.4.1　Impala架构59\n3.4.2　安装Impala state store60\n3.4.3　安装Impala server60\n3.5　小结63\n第4章　Hadoop安全64\n4.1　Hadoop安全概述64\n4.2　Hadoop分布式文件系统安全65\n4.3　MapReduce安全66\n4.4　Hadoop服务级别验证\t68\n4.5　Hadoop和Kerberos69\n4.5.1　Kerberos概述70\n4.5.2　Hadoop中的Kerberos71\n4.6　小结76\n第5章　监控Hadoop集群77\n5.1　监控策略介绍77\n5.2　Hadoop参数78\n5.2.1　JMX参数79\n5.2.2　使用Nagios监控Hadoop80\n5.2.3　监控Hadoop分布式文件系统81\n5.2.4　NameNode校验81\n5.2.5　JournalNode检查83\n5.2.6　ZooKeeper检查83\n5.3　监控MapReduce84\n5.4　使用Ganglia监控Hadoop85\n5.5　小结86\n第6章　在云端使用Hadoop87\n6.1　Amazon Elastic MapReduce87\n6.1.1　安装EMR命令行接口88\n6.1.2　选择Hadoop版本89\n6.1.3　启动EMR集群89\n6.2　使用Whirr93\n6.3　小结94\n第7章　Hadoop平台安全概述95\n7.1　为什么需要保障Hadoop生态系统的安全96\n7.2　确保Hadoop生态系统安全面临的挑战96\n7.3　关键安全因素97\n7.4　小结99\n第8章　Hadoop安全体系设计100\n8.1　什么是Kerberos100\n8.1.1　Kerberos关键术语101\n8.1.2　Kerberos如何工作102\n8.1.3　Kerberos 的优点103\n8.2　不采用Kerberos的Hadoop默认安全模型103\n8.3　Hadoop Kerberos 安全模型实现105\n8.3.1　用户层次的访问控制105\n8.3.2　服务层次的访问控制105\n8.3.3　用户和服务认证106\n8.3.4　授权令牌106\n8.3.5　作业令牌106\n8.3.6　数据块访问令牌107\n8.4　小结108\n第9章　配置一个安全Hadoop集群109\n9.1　前提条件109\n9.2　设置Kerberos110\n9.3　配置Hadoop使用Kerberos认证117\n9.3.1　在所有Hadoop节点设置Kerberos客户端117\n9.3.2　配置Hadoop服务标识118\n9.4　Hadoop用户设置124\n9.5　安全Hadoop自动部署124\n9.6　小结125\n第10章　Hadoop生态系统安全保障126\n10.1　为Hadoop生态系统组件配置Kerberos127\n10.1.1　Hive安全设置127\n10.1.2　Oozie安全设置130\n10.1.3　Flume安全设置131\n10.1.4　HBase安全设置134\n10.1.5　Sqoop安全设置137\n10.1.6　Pig安全设置138\n10.2　Hadoop生态系统组件安全保障最佳实践138\n10.3　小结139\n第11章　集成Hadoop与企业安全系统140\n11.1　集成EIM系统141\n11.1.1　配置EIM与Hadoop集成142\n11.1.2　集成基于Active Directory的EIM系统与Hadoop生态系统143\n11.2　从企业网络访问安全Hadoop集群144\n11.2.1　HttpFS145\n11.2.2　HUE145\n11.2.3　Knox Gateway Server146\n11.3　小结147\n第12章　Hadoop中敏感数据安全保护148\n12.1　Hadoop中敏感数据及保护方法148\n12.2　小结154\n第13章　安全事件与审计日志155\n13.1　Hadoop集群安全事故和事件监控155\n13.2　Hadoop集群审计日志设置158\n13.3　小结160\n附录　Hadoop安全机制解决方案161","ebook_url":"https:\/\/read.douban.com\/ebook\/29512809\/","pages":"184","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27728852.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27728852.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27728852.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26220174\/","id":"26220174","publisher":"机械工业出版社","isbn10":"7111480627","isbn13":"9787111480624","title":"Hadoop集群与安全","url":"https:\/\/api.douban.com\/v2\/book\/26220174","alt_title":"Hadoop Cluster Deployment，Securing Hadoop","author_intro":"作者简介\nDanil Zburivsky　资深数据库管理员，目前是全球数据基础构架管理公司Pythian的咨询师，其客户涉及金融、娱乐以及通信领域，主要方向是创建各种Hadoop集群。研究兴趣包括Python编程、机器学习等。\nSudheesh Narayanan　在大数据解决方案咨询与实施领域具有丰富经验的实践者和技术战略家。他在IT领域的经验超过15年，涉及信息管理、商务智能、大数据分析及云应用和J2EE应用开发等。\n译者简介\n刘杰　中国科学院软件所副研究员，具有多年Hadoop平台研发与实施经验，与团队一起研发基于Hadoop的可视化大数据分析工具Haflow，该工具应用于医疗、交通等多个领域。研究方向包括企业数据集成、面向大数据的系统软件、数据挖掘等。\n沈鑫　 毕业于同济大学计算机科学与技术系，资深网络工程师，从事网络安全、管理信息系统的开发与维护，参与开发了多个相关的项目。兴趣爱好是网络安全技术与嵌入式技术。","summary":"本书手把手教你手动配置高效的Hadoop集群，以便充分利用Hadoop平台的优势, 并为Hadoop生态系统实现强健的端到端的安全保障。\n本书分为两部分，共13章：第1章概述主要的Hadoop组件以及选择规划；第2章讲解安装和配置主要Hadoop组件的详细步骤；第3章介绍Sqoop、Hive和Impala的配置步骤；第4章讲解确保各种Hadoop组件安全的方法；第5章指导读者逐步将集群开发至实际应用阶段；第6章介绍如何在虚拟环境中使用Hadoop；第7章详细介绍大数据安全参考框架；第8章详细介绍Hadoop安全保障系统的内部设计细节以及关键概念；第9章提供配置Kerberos并建立安全Hadoop集群的详细步骤；第10章介绍Hadoop生态系统组件之间的交互和通信协议；第11章关注如何集成Hadoop安全模型与企业已有的安全系统；第12章提供保护Hadoop生态系统中敏感数据的详细实现方法；第13章深入介绍大数据平台中安全事件监控系统，提供实现安全流程和策略的最新实践。","ebook_price":"20.00","price":"49"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["Tom White"],"pubdate":"2011-6","tags":[{"count":10,"name":"hadoop","title":"hadoop"},{"count":6,"name":"计算机","title":"计算机"},{"count":3,"name":"O'Reilly","title":"O'Reilly"},{"count":1,"name":"混口饭吃","title":"混口饭吃"},{"count":1,"name":"想读","title":"想读"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8469008.jpg","binding":"平装","translator":[],"catalog":"","pages":"600","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s8469008.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s8469008.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s8469008.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6710640\/","id":"6710640","publisher":"东南大学出版社","isbn10":"7564126760","isbn13":"9787564126766","title":"Hadoop权威指南","url":"https:\/\/api.douban.com\/v2\/book\/6710640","alt_title":"","author_intro":"","summary":"《Hadoop权威指南（影印版）（第2版修订版）》揭示了ApacheHadoop如何为你释放数据的力量。这本内容全面的书籍展示了如何使用Hadoop架构搭建和维护可靠、可伸缩的分布式系统。Hadoop架构是MapReduce算法的一种开源应用，是Google开创其帝国的重要基石。程序员可从中探索如何分析海量数据集，管理员可以了解如何建立与运行Had00p集群。本修订版涵盖了Hadoop最近的更新，包括诸如Hive、Sqoop和Avr0之类的新特性。它也提供了案例学习来展示Hadoop如何解决特殊问题。期待尽情享受你的数据？这就是你要的书。","price":"98.00元"},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"","author":["[斯里兰卡] 萨那斯•佩雷拉（Srinath Perera）","蒂里那•冈纳拉森（Thilina Gunarathne）"],"pubdate":"2015-3","tags":[{"count":8,"name":"Hadoop","title":"Hadoop"},{"count":7,"name":"MapReduce","title":"MapReduce"},{"count":2,"name":"编程","title":"编程"},{"count":1,"name":"程序设计","title":"程序设计"},{"count":1,"name":"学习","title":"学习"},{"count":1,"name":"千万别买这本书！！！","title":"千万别买这本书！！！"},{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Programming","title":"Programming"}],"origin_title":"Hadoop MapReduce Cookbook","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28023091.jpg","binding":"","translator":["杨卓荦"],"catalog":"第1章 搭建Hadoop并在集群中运行\t1\n1.1 简介\t1\n1.2 在你的机器上安装Hadoop\t2\n1.3 写WordCountMapReduce示例程序，打包并使用独立的Hadoop运行它\t3\n1.4 给WordCount MapReduce程序增加combiner步骤\t8\n1.5 安装HDFS\t9\n1.6 使用HDFS监控UI\t14\n1.7 HDFS的基本命令行文件操作\t15\n1.8 在分布式集群环境中设置Hadoop\t17\n1.9 在分布式集群环境中运行WordCount程序\t22\n1.10 使用MapReduce监控UI\t24\n第2章 HDFS进阶\t26\n2.1 简介\t26\n2.2 HDFS基准测试\t27\n2.3 添加一个新的DataNode\t28\n2.4 DataNode下架\t30\n2.5 使用多个磁盘\/卷以及限制HDFS的磁盘使用情况\t32\n2.6 设置HDFS块大小\t33\n2.7 设置文件冗余因子\t34\n2.8 使用HDFS的Java API\t35\n2.9 使用HDFS的C API（libhdfs）\t40\n2.10 挂载HDFS（Fuse-DFS）\t45\n2.11 在HDFS中合并文件\t48\n第3章 高级Hadoop MapReduce运维\t49\n3.1 简介\t49\n3.2 调优集群部署的Hadoop配置\t49\n3.3 运行基准测试来验证Hadoop的安装\t52\n3.4 复用Java虚拟机以提高性能\t54\n3.5 容错和推测执行\t54\n3.6 调试脚本——分析任务失败\t55\n3.7 设置失败百分比以及跳过不良记录\t59\n3.8 共享用户的Hadoop集群——使用公平调度器和其他调度器\t61\n3.9 Hadoop的安全性——整合使用Kerberos\t62\n3.10 使用Hadoop的工具接口\t69\n第4章 开发复杂的Hadoop MapReduce应用程序\t72\n4.1 简介\t72\n4.2 选择合适的Hadoop数据类型\t73\n4.3 实现自定义的Hadoop Writable数据类型\t75\n4.4 实现自定义Hadoop key类型\t79\n4.5 从mapper中输出不同值类型的数据\t83\n4.6 为输入数据格式选择合适的Hadoop InputFormat\t87\n4.7 添加新的输入数据格式的支持——实现自定义的InputFormat\t90\n4.8 格式化MapReduce计算的结果——使用Hadoop的OutputFormat\t94\n4.9 Hadoop的中间（map到reduce）数据分区\t96\n4.10 将共享资源传播和分发到MapReduce作业的任务中——Hadoop DistributedCache\t98\n4.11 在Hadoop上使用传统应用程序——Hadoop Streaming\t103\n4.12 添加MapReduce作业之间的依赖关系\t106\n4.13 用于报告自定义指标的Hadoop计数器\t108\n第5章 Hadoop生态系统\t110\n5.1 简介\t110\n5.2 安装HBase\t111\n5.3 使用Java客户端API随机存取数据\t114\n5.4 基于HBase（表输入\/输出）运行MapReduce作业\t116\n5.5 安装Pig\t120\n5.6 运行第一条Pig命令\t121\n5.7 使用Pig执行集合操作（join，union）与排序\t123\n5.8 安装Hive\t125\n5.9 使用Hive运行SQL风格的查询\t127\n5.10 使用Hive执行join\t129\n5.11 安装Mahout\t132\n5.12 使用Mahout运行K-means\t133\n5.13 可视化K-means结果\t136\n第6章 分析\t138\n6.1 简介\t138\n6.2 使用MapReduce的简单分析\t139\n6.3 使用MapReduce执行Group-By\t143\n6.4 使用MapReduce计算频率分布和排序\t146\n6.5 使用GNU Plot绘制Hadoop计算结果\t148\n6.6 使用MapReduce计算直方图\t151\n6.7 使用MapReduce计算散点图\t154\n6.8 用Hadoop解析复杂的数据集\t158\n6.9 使用MapReduce连接两个数据集\t164\n第7章 搜索和索引\t170\n7.1 简介\t170\n7.2 使用Hadoop MapReduce生成倒排索引\t170\n7.3 使用Apache Nutch构建域内网络爬虫\t175\n7.4 使用Apache Solr索引和搜索网络文档\t180\n7.5 配置Apache HBase作为Apache Nutch的后端数据存储\t182\n7.6 在Hadoop集群上部署Apache HBase\t185\n7.7 使用Hadoop\/HBase集群构建Apache Nutch全网爬虫服务\t188\n7.8 用于索引和搜索的ElasticSearch\t191\n7.9 生成抓取网页的内链图\t193\n第8章 聚类、推荐和关系发现\t197\n8.1 简介\t197\n8.2 基于内容的推荐\t198\n8.3 层次聚类\t204\n8.4 对亚马逊销售数据集进行聚类操作\t208\n8.5 基于协同过滤的推荐\t212\n8.6 使用朴素贝叶斯分类器的分类\t216\n8.7 使用Adwords平衡算法给广告分配关键字\t222\n第9章 海量文本数据处理\t231\n9.1 简介\t231\n9.2 使用Hadoop Streaming和Python预处理数据（抽取、清洗和格式转换）\t231\n9.3 使用Hadoop Streaming进行数据去重\t235\n9.4 使用importtsv和批量加载工具把大型数据集加载到Apache HBase数据存储中\t237\n9.5 创建用于文本数据的TF向量和TF-IDF向量\t242\n9.6 聚类文本数据\t246\n9.7 使用隐含狄利克雷分布（LDA）发现主题\t249\n9.8 使用Mahout的朴素贝叶斯分类器分类文件\t252\n第10章 云端部署——在云上使用Hadoop\t255\n10.1 简介\t255\n10.2 使用亚马逊弹性MapReduce运行Hadoop MapReduce计算\t256\n10.3 使用亚马逊EC2竞价实例来执行EMR作业流以节约开支\t259\n10.4 使用EMR执行Pig脚本\t261\n10.5 使用EMR执行Hive脚本\t263\n10.6 使用命令行界面创建亚马逊EMR作业流\t267\n10.7 使用EMR在亚马逊EC2云上部署Apache HBase集群\t270\n10.8 使用EMR引导操作来配置亚马逊EMR作业的虚拟机\t275\n10.9 使用Apache Whirr在云环境中部署Apache Hadoop集群\t277\n10.10 使用Apache Whirr在云环境中部署Apache HBase集群\t281","pages":"300","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28023091.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28023091.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28023091.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26340991\/","id":"26340991","publisher":"人民邮电出版社","isbn10":"7115384371","isbn13":"9787115384379","title":"Hadoop MapReduce实战手册","url":"https:\/\/api.douban.com\/v2\/book\/26340991","alt_title":"Hadoop MapReduce Cookbook","author_intro":"作者介绍\nSrinath Perera是WSO2公司的高级软件架构师，与CTO一同全观整个WSO2平台架构。同时，他也是斯里兰卡软件基金会的一位研究科学家，并作为访问学者在莫勒图沃大学计算机科学与工程系授课。他是Apache Axis2开源软件项目的联合创始人，他自2002年以来一直参与Apache Web Service项目，并且是Apache软件基金会和Apache Web服务项目PMC的成员。Srinath也是Apache Axis、Axis2和Geronimo开源项目的committer。\n他在美国印第安纳大学伯明顿分校获得博士和硕士学位，在斯里兰卡莫勒图沃大学获得了计算科学与工程学士学位。\nSrinath已经撰写了许多技术文章和同行评审的研究文章，可以从他的个人网站找到更多细节。他还经常在技术会议上做演讲。\n他长期研究大规模分布式系统。他的日常工作与大数据技术（如Hadoop和Cassandra）结合很紧密。他还在莫勒图沃大学研究生班教授并行计算，主要是基于Hadoop。\nThilina Gunarathne是印第安纳大学信息与计算学院博士。他在使用Apache Hadoop以及大规模数据密集型计算技术方面有着丰富的经验。他目前的主要工作是致力于研发在云环境执行可扩展的、高效的大规模数据密集型计算的技术。\nThilina发表了很多论文，并且同行评审了很多分布式计算和并行计算领域的研究论文，包括一些在云环境扩展MapReduce模型进行有效的数据挖掘和数据分析的论文。Thilina经常在学术界和工业界会议上发表演讲。\nThilina自2005年以来，在Apache软件基金会下贡献了若干个开源项目，并成为committer和PMC成员。在开始研究生学习之前，Thilina在WSO2公司担任高级软件工程师，专注于开源中间件开发。Thilina 2006年在斯里兰卡莫勒图沃大学获得计算机科学与工程学士学位，2009年在美国印第安纳大学伯明顿分校获得计算机科学硕士学位，2013年获得分布式和并行计算领域博士学位。\n译者介绍\n杨卓荦 阿里巴巴集团数据平台事业部资深研发工程师。2011年起，在阿里巴巴从事Hadoop五年，集团SQL on Hadoop负责人，Hadoop\/Yarn\/Hive contributor，开源软件爱好者。","summary":"这是一本学习Hadoop MapReduce的一站式指南，完整介绍了Hadoop生态体系，包括Hadoop平台安装、部署、运维等，Hadoop生态系统成员Hive、Pig、HBase、Mahout等。最重要的是，书中包含丰富的示例和多样的实际应用场景，以一种简单而直接的方式呈现了90个实战攻略，并给出一步步的指导。本书从获取Hadoop并在集群中运行讲起，依次介绍了高级HDFS，高级Hadoop MapReduce管理，开发复杂的Hadoop MapReduce应用程序，Hadoop的生态系统，统计分析，搜索与索引，聚类、推荐和寻找关联，海量文本数据处理，云部署等内容。","price":"59.00"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["翟周伟"],"pubdate":"2015-4-1","tags":[{"count":9,"name":"Hadoop","title":"Hadoop"},{"count":6,"name":"大数据","title":"大数据"},{"count":5,"name":"计算机","title":"计算机"},{"count":2,"name":"技术","title":"技术"},{"count":1,"name":"数据","title":"数据"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28045346.jpg","binding":"平装","translator":[],"catalog":"前　言\n基　础　篇\n第1章　认识Hadoop  2\n1.1　缘于搜索的小象  2\n1.1.1　Hadoop的身世  2\n1.1.2　Hadoop简介  3\n1.1.3　Hadoop发展简史  6\n1.2　大数据、Hadoop和云计算  7\n1.2.1　大数据  7\n1.2.2　大数据、Hadoop和云计算的关系  8\n1.3　设计思想与架构  9\n1.3.1　数据存储与切分  9\n1.3.2　MapReduce模型  11\n1.3.3　MPI和MapReduce  13\n1.4　国外Hadoop的应用现状  13\n1.5　国内Hadoop的应用现状  17\n1.6　Hadoop发行版  20\n1.6.1　Apache Hadoop  20\n1.6.2　Cloudera Hadoop  20\n1.6.3　Hortonworks Hadoop发行版  21\n1.6.4　MapR Hadoop发行版  22\n1.6.5　IBM Hadoop发行版  24\n1.6.6　Intel Hadoop发行版  24\n1.6.7　华为Hadoop发行版  25\n1.7　小结  26\n第2章　Hadoop使用之初体验  27\n2.1　搭建测试环境  27\n2.1.1　软件与准备  27\n2.1.2　安装与配置  28\n2.1.3　启动与停止  29\n2.2　算法分析与设计  31\n2.2.1　Map设计  31\n2.2.2　Reduce设计  32\n2.3　实现接口  32\n2.3.1　Java API实现  33\n2.3.2　Streaming接口实现  36\n2.3.3　Pipes接口实现  38\n2.4　编译  40\n2.4.1　基于Java API实现的编译  40\n2.4.2　基于Streaming实现的编译  40\n2.4.3　基于Pipes实现的编译  41\n2.5　提交作业  41\n2.5.1　基于Java API实现作业提交  41\n2.5.2　基于Streaming实现作业提交  42\n2.5.3　基于Pipes实现作业提交  43\n2.6　小结  44\n第3章　Hadoop存储系统  45\n3.1　基本概念  46\n3.1.1　NameNode  46\n3.1.2　DateNode  46\n3.1.3　客户端  47\n3.1.4　块  47\n3.2　HDFS的特性和目标  48\n3.2.1　HDFS的特性  48\n3.2.2　HDFS的目标  48\n3.3　HDFS架构  49\n3.3.1　Master\/Slave架构  49\n3.3.2　NameNode和Secondary NameNode通信模型  51\n3.3.3　文件存取机制  52\n3.4　HDFS核心设计  54\n3.4.1　Block大小  54\n3.4.2　数据复制  55\n3.4.3　数据副本存放策略  56\n3.4.4　数据组织  57\n3.4.5　空间回收  57\n3.4.6　通信协议  58\n3.4.7　安全模式  58\n3.4.8　机架感知  59\n3.4.9　健壮性  59\n3.4.10　负载均衡  60\n3.4.11　升级和回滚机制  62\n3.5　HDFS权限管理  64\n3.5.1　用户身份  64\n3.5.2　系统实现  65\n3.5.3　超级用户  65\n3.5.4　配置参数  65\n3.6　HDFS配额管理  66\n3.7　HDFS的缺点  67\n3.8　小结  68\n第4章　HDFS的使用  69\n4.1　HDFS环境准备  69\n4.1.1　HDFS安装配置  69\n4.1.2　HDFS格式化与启动  70\n4.1.3　HDFS运行检查  70\n4.2　HDFS命令的使用  71\n4.2.1　fs shell  71\n4.2.2　archive  77\n4.2.3　distcp  78\n4.2.4　fsck  81\n4.3　HDFS Java API的使用方法  82\n4.3.1　Java API简介  82\n4.3.2　读文件  82\n4.3.3　写文件  86\n4.3.4　删除文件或目录  90\n4.4　C接口libhdfs  91\n4.4.1　libhdfs介绍  91\n4.4.2　编译与部署  91\n4.4.3　libhdfs接口介绍  92\n4.4.4　libhdfs使用举例  95\n4.5　WebHDFS接口  97\n4.5.1　WebHDFS REST API简介  97\n4.5.2　WebHDFS配置  98\n4.5.3　WebHDFS使用  98\n4.5.4　WebHDFS错误响应和查询参数  101\n4.6　小结  103\n第5章　MapReduce计算框架  104\n5.1　Hadoop MapReduce简介  104\n5.2　MapReduce模型  105\n5.2.1　MapReduce编程模型  105\n5.2.2　MapReduce实现原理  106\n5.3　计算流程与机制  108\n5.3.1　作业提交和初始化  108\n5.3.2　Mapper  110\n5.3.3　Reducer  111\n5.3.4　Reporter和OutputCollector  112\n5.4　MapReduce的输入\/输出格式  113\n5.4.1　输入格式  113\n5.4.2　输出格式  118\n5.5　核心问题  124\n5.5.1　Map和Reduce数量  124\n5.5.2　作业配置  126\n5.5.3　作业执行和环境  127\n5.5.4　作业容错机制  129\n5.5.5　作业调度  131\n5.6　有用的MapReduce特性  132\n5.6.1　计数器  132\n5.6.2　DistributedCache  134\n5.6.3　Tool  135\n5.6.4　IsolationRunner  136\n5.6.5　Prof?iling  136\n5.6.6　MapReduce调试  136\n5.6.7　数据压缩  137\n5.6.8　优化  138\n5.7　小结  138\n第6章　Hadoop命令系统  139\n6.1　Hadoop命令系统的组成  139\n6.2　用户命令  141\n6.3　管理员命令  144\n6.4　测试命令  148\n6.5　应用命令  156\n6.6　Hadoop的streaming命令  163\n6.6.1　streaming命令  163\n6.6.2　参数使用分析  164\n6.7　Hadoop的pipes命令  168\n6.7.1　pipes命令  168\n6.7.2　参数使用分析  169\n6.8　小结  170\n高　级　篇\n第7章　MapReduce深度分析  172\n7.1　MapReduce总结构分析  172\n7.1.1　数据流向分析  172\n7.1.2　处理流程分析  174\n7.2　MapTask实现分析  176\n7.2.1　总逻辑分析  176\n7.2.2　Read阶段  178\n7.2.3　Map阶段  178\n7.2.4　Collector和Partitioner阶段  180\n7.2.5　Spill阶段   181\n7.2.6　Merge阶段  185\n7.3　ReduceTask实现分析  186\n7.3.1　总逻辑分析  186\n7.3.2　Shuffle阶段  187\n7.3.3　Merge阶段  189\n7.3.4　Sort阶段  190\n7.3.5　Reduce阶段  191\n7.4　JobTracker分析  192\n7.4.1　JobTracker服务分析  192\n7.4.2　JobTracker启动分析  193\n7.4.3　JobTracker核心子线程分析  195\n7.5　TaskTracker分析  201\n7.5.1　TaskTracker启动分析  201\n7.5.2　TaskTracker核心子线程分析  205\n7.6　心跳机制实现分析  207\n7.6.1　心跳检测分析  207\n7.6.2　TaskTracker.transmitHeart-Beat()  207\n7.6.3　JobTracker.heartbeat()  209\n7.6.4　JobTracker.processHeartbeat()  212\n7.7　作业创建分析  213\n7.7.1　初始化分析  214\n7.7.2　作业提交分析  215\n7.8　作业执行分析  217\n7.8.1　JobTracker初始化  218\n7.8.2　TaskTracker.startNewTask()  220\n7.8.3　TaskTracker.localizeJob()  220\n7.8.4　TaskRunner.run()  221\n7.8.5　MapTask.run()  222\n7.9　小结  223\n第8章　Hadoop Streaming和Pipes原理与实现  224\n8.1　Streaming原理浅析  224\n8.2　Streaming实现架构  226\n8.3　Streaming核心实现机制  227\n8.3.1　主控框架实现  227\n8.3.2　用户进程管理  228\n8.3.3　框架和用户程序的交互  229\n8.3.4　PipeMapper和PiperReducer  230\n8.4　Pipes原理浅析  231\n8.5　Pipes实现架构  233\n8.6　Pipes核心实现机制  234\n8.6.1　主控类实现  234\n8.6.2　用户进程管理  235\n8.6.3　PipesMapRunner  235\n8.6.4　PipesReducer  238\n8.6.5　C++端HadoopPipes  238\n8.7　小结  239\n第9章　Hadoop作业调度系统  240\n9.1　作业调度概述  241\n9.1.1　相关概念  241\n9.1.2　作业调度流程  242\n9.1.3　集群资源组织与管理  243\n9.1.4　队列控制和权限管理  244\n9.1.5　插件式调度框架  245\n9.2　FIFO调度器  246\n9.2.1　基本调度策略  246\n9.2.2　FIFO实现分析  247\n9.2.3　FIFO初始化与停止  248\n9.2.4　作业监听控制  249\n9.2.5　任务分配算法  250\n9.2.6　配置与使用  254\n9.3　公平调度器  254\n9.3.1　产生背景  254\n9.3.2　主要功能  255\n9.3.3　基本调度策略  255\n9.3.4　FairScheduler实现分析  257\n9.3.5　FairScheduler启停分析  258\n9.3.6　作业监听控制  260\n9.3.7　资源池管理  260\n9.3.8　作业更新策略  262\n9.3.9　作业权重和资源量的计算  266\n9.3.10　任务分配算法  267\n9.3.11　FairScheduler配置参数  268\n9.3.12　使用与管理  270\n9.4　容量调度器  272\n9.4.1　产生背景  272\n9.4.2　主要功能  272\n9.4.3　基本调度策略  274\n9.4.4　CapacityScheduler实现分析  274\n9.4.5　CapacityScheduler启停分析  275\n9.4.6　作业监听控制  277\n9.4.7　作业初始化分析  277\n9.4.8　任务分配算法  278\n9.4.9　内存匹配机制  279\n9.4.10　配置与使用  280\n9.5　调度器对比分析  283\n9.5.1　调度策略对比  283\n9.5.2　队列和优先级  283\n9.5.3　资源分配保证  283\n9.5.4　作业限制  284\n9.5.5　配置管理  284\n9.5.6　扩展性支持  284\n9.5.7　资源抢占和延迟调度  284\n9.5.8　优缺点分析  285\n9.6　其他调度器  285\n9.6.1　HOD调度器  285\n9.6.2　LATE调度器  286\n9.7　小结  288\n实　战　篇\n第10章　Hadoop集群搭建  290\n10.1　Hadoop版本的选择  290\n10.2　集群基础硬件需求  291\n10.2.1　内存  291\n10.2.2　CPU  292\n10.2.3　磁盘  292\n10.2.4　网卡  293\n10.2.5　网络拓扑  293\n10.3　集群基础软件需求  294\n10.3.1　操作系统  294\n10.3.2　JVM和SSH  295\n10.4　虚拟化需求  295\n10.5　事前准备  296\n10.5.1　创建安装用户  296\n10.5.2　安装Java  297\n10.5.3　安装SSH并设置  297\n10.5.4　防火墙端口设置  298\n10.6　安装Hadoop  298\n10.6.1　安装HDFS  299\n10.6.2　安装MapReduce  299\n10.7　集群配置  300\n10.7.1　配置管理  300\n10.7.2　环境变量配置  301\n10.7.3　核心参数配置  302\n10.7.4　HDFS参数配置  303\n10.7.5　MapReduce参数配置  306\n10.7.6　masters和slaves配置  313\n10.7.7　客户端配置  313\n10.8　启动和停止  314\n10.8.1　启动\/停止HDFS  314\n10.8.2　启动\/停止MapReduce  315\n10.8.3　启动验证  315\n10.9　集群基准测试  316\n10.9.1　HDFS基准测试  316\n10.9.2　MapReduce基准测试  317\n10.9.3　综合性能测试  318\n10.10　集群搭建实例  319\n10.10.1　部署策略  319\n10.10.2　软件和硬件环境  320\n10.10.3　Hadoop安装  321\n10.10.4　配置core-site.xml  321\n10.10.5　配置hdfs-site.xml  322\n10.10.6　配置mapred-site.xml  322\n10.10.7　SecondaryNameNode和Slave  324\n10.10.8　配置作业队列  324\n10.10.9　配置第三方调度器  325\n10.10.10　启动与验证  327\n10.11　小结  327\n第11章　Hadoop Streaming和Pipes编程实战  328\n11.1　Streaming基础编程  328\n11.1.1　Streaming编程入门  328\n11.1.2　Map和Reduce数目  331\n11.1.3　队列、优先级及权限  332\n11.1.4　分发文件和压缩包  333\n11.1.5　压缩参数的使用  336\n11.1.6　本地作业的调试  338\n11.2　Streaming高级应用  338\n11.2.1　参数与环境变量传递  339\n11.2.2　自定义分隔符  340\n11.2.3　自定义Partitioner  343\n11.2.4　自定义计数器  347\n11.2.5　处理二进制数据  347\n11.2.6　使用聚合函数  351\n11.3　Pipes编程接口  352\n11.3.1　TaskContext  352\n11.3.2　Mapper  353\n11.3.3　Reducer  354\n11.3.4　Partitioner  354\n11.3.5　RecordReader  355\n11.3.6　RecordWriter  356\n11.4　Pipes编程应用  357\n11.5　小结  359\n第12章　Hadoop MapReduce应用开发  360\n12.1　开发环境准备  360\n12.2　Eclipse集成环境开发  361\n12.2.1　构建MapReduce Eclipse IDE  361\n12.2.2　开发示例  363\n12.3　MapReduce Java API编程  368\n12.3.1　Mapper编程接口  369\n12.3.2　Reducer编程接口  370\n12.3.3　驱动类编写  372\n12.3.4　编译运行  373\n12.4　压缩功能使用  374\n12.4.1　Hadoop数据压缩  374\n12.4.2　压缩特征与性能  374\n12.4.3　本地压缩库  375\n12.4.4　使用压缩  376\n12.5　排序应用  378\n12.5.1　Hadoop排序问题  378\n12.5.2　二次排序  378\n12.5.3　比较器和组合排序  380\n12.5.4　全局排序  381\n12.6　多路输出  382\n12.7　常见问题与处理方法  384\n12.7.1　常见的开发问题  384\n12.7.2　运行时错误问题  386\n12.8　小结  387","pages":"387","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28045346.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28045346.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28045346.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26363312\/","id":"26363312","publisher":"机械工业出版社","isbn10":"7111494687","isbn13":"9787111494683","title":"Hadoop核心技术","url":"https:\/\/api.douban.com\/v2\/book\/26363312","alt_title":"","author_intro":"翟周伟\n就职于百度，资深Hadoop技术专家，专注于Hadoop&大数据，数据挖掘，自然语言处理领域。2009年便开始利用Hadoop构建商业级大数据系统，是国内该领域最早的一批人之一，负责设计过多个基于Hadoop的大数据平台和分析系统。2011年合著出版《Hadoop开源云计算平台》，并在自然语言处理领域申请过一项发明专利。","summary":"百度资深Hadoop技术专家和高级算法工程师撰写，结合百度大数据实践，直击企业痛点，多位大数据技术专家联袂推荐！\n从使用、原理、运维和开发4个方面深度讲解Hadoop最核心的技术\n这是一本技术深度与企业实践并重的著作，由百度顶尖的Hadoop技术工程师撰写，是百度Hadoop技术实践经验的总结。本书使用、实现原理、运维和开发4个方面对Hadoop的核心技术进行了深入的讲解：\n（1）使用：详细讲解了HDFS存储系统、MapReduce计算框架，以及HDFS的命令系统；\n（2）原理：结合源代码，深度分析了MapReduce、HDFS、Streaming、Pipes、Hadoop作业调度系统等重要技术和组件的架构设计、工作机制和实现原理；\n（3）运维：结合百度的实际生产环境，详细讲解了Hadoop集群的安装、配置、测试以及管理和运维；\n（4）开发：详细讲解了Hadoop Streaming、Pipes的使用和开发实践，以及MapReduce的编程实践和常见问题。\n与市面上已有的Hadoop相比，本书的最大不同之处是它直切企业应用和实践Hadoop技术的痛点，深入讲解了企业最需要和最头疼的技术和问题，内容上非常聚焦。","series":{"id":"19432","title":"大数据技术丛书"},"price":"69.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["Jonathan R. Owens","Brian Femiano","Jon Lentz"],"pubdate":"2013-2-11","tags":[{"count":4,"name":"Hadoop","title":"Hadoop"},{"count":2,"name":"2013","title":"2013"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"程序设计","title":"程序设计"},{"count":1,"name":"分布式","title":"分布式"},{"count":1,"name":"Programming","title":"Programming"},{"count":1,"name":"Packt","title":"Packt"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27131931.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"316","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27131931.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27131931.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27131931.jpg"},"alt":"https:\/\/book.douban.com\/subject\/22165654\/","id":"22165654","publisher":"Packt Publishing","isbn10":"1849519129","isbn13":"9781849519120","title":"Hadoop Real World Solutions Cookbook","url":"https:\/\/api.douban.com\/v2\/book\/22165654","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["刘刚","侯宾","翟周伟"],"pubdate":"2011-8","tags":[{"count":6,"name":"云计算","title":"云计算"},{"count":4,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"技术","title":"技术"},{"count":1,"name":"开源","title":"开源"},{"count":1,"name":"分布式","title":"分布式"},{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s6995388.jpg","binding":"","translator":[],"catalog":"","pages":"217","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s6995388.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s6995388.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s6995388.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6813433\/","id":"6813433","publisher":"北京邮电大学出版社","isbn10":"7563526900","isbn13":"9787563526901","title":"Hadoop开源云计算平台","url":"https:\/\/api.douban.com\/v2\/book\/6813433","alt_title":"","author_intro":"","summary":"刘刚、侯宾等编著的《Hadoop开源云计算平台》首先介绍了云计算的基本概念以及谷歌云计算的关键技术，然后全面系统地介绍了实现云计算关键技术层的理想开源工具Hadoop及其应用。《Hadoop开源云计算平台》阐述了Hadoop中每个部分的实现机制与用法，包括HDFS、Hadoop FS shell、Map\/Reduce、Hadoop流与管道机制、Hadoop I\/O、Hadoop命令简介、部署Hadoop，并介绍了Zookeeper、HBase、Pig、Hive、CloudBase、Mahout。除此之外本书还介绍了基于Hadoop的开发与应用。","price":"26.00元"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["怀特"],"pubdate":"2013-1","tags":[{"count":4,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"BI","title":"BI"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26354909.jpg","binding":"","translator":[],"catalog":"","pages":"657","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s26354909.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s26354909.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26354909.jpg"},"alt":"https:\/\/book.douban.com\/subject\/23066032\/","id":"23066032","publisher":"东南大学出版社","isbn10":"7564138939","isbn13":"9787564138936","title":"Hadoop权威指南","url":"https:\/\/api.douban.com\/v2\/book\/23066032","alt_title":"","author_intro":"","summary":"《Hadoop权威指南(影印版)(第3版)(修订版)》的内容包括：使用Hadoop分布式文件系统（HDFS）保存大数据集；使用MapReduce运行分布式计算；使用Hadoop的数据和I／O构件实现压缩、数据完整性、序列化（包括Avro）和持久化；了解常见的陷阱和高级特性，以编写实用的MapReduce程序；设计、构建和管理专用的Hadoop集群——或者在云中运行Hadoop；使用Sqoop从关系型数据库载入数据到HDFS；使用Pig查询语言进行大规模数据处理；使用Hadoop的数据仓库系统Hive分析数据集；利用HBase处理结构化和半结构化数据，以及利用ZooKeeper构建分布式系统。","price":"98.00元"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["中野猛","山下真一","猿田浩辅"],"pubdate":"2013-12-15","tags":[{"count":3,"name":"非常实用！","title":"非常实用！"},{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"很实用","title":"很实用"},{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"Hadoop Hacks ―プロフェッショナルが使う実践テクニック","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27263652.jpg","binding":"平装","translator":["陈新","常娜"],"catalog":"前言\n第1章 系统架构／运用技巧\n运行HDFS环境的参数\n运行MapReduce环境需要的参数\n总结\n文件描述符的设置\nJava的安装\n总结\n本技巧中介绍的HA的构成\nHA集群的构建过程\n疑难解答\n总结\n可以获取的统计信息\n总结\n关于CDH3同一版本间的更新\n总结\n准备\n理解操作\n使用Oracle的操作确认\n总结\nSqoop的PostgreSQL联合功能\n在PostgreSQL中的使用\nPostgreSQL联合的挑战\n总结\n什么是Azkaban\nAzkaban的安装\n总结\n作业的定制\n总结\n第2章 应用程序开发技巧\n第3章 HBase技巧\n第4章 Hive技巧\n第5章 Pig技巧\n第6章 Mahout技巧\n第7章 ZooKeeper技巧","pages":"394","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27263652.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27263652.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27263652.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25870158\/","id":"25870158","publisher":"中国电力出版社","isbn10":"7512346352","isbn13":"9787512346352","title":"Hadoop Hacks：专家使用的实践技巧","url":"https:\/\/api.douban.com\/v2\/book\/25870158","alt_title":"Hadoop Hacks ―プロフェッショナルが使う実践テクニック","author_intro":"中野猛（nakano takeshi）1976年出生于兵库县。从奈良先端大学院大学进入招聘股份公司工作。在信息系统部门MIT中，从事web基础设施的构建以及R25等网站建立\/开发\/运用等。期间，推进了Solr等OSS的导入和高速缓存、中间设备开发等。近两年正在以Hadoop为中心进行探索研究。爱好是潜水（最喜欢的地方是墨西哥、拉巴斯）。","summary":"《Hadoop Hacks：专家使用的实践技巧》以理解了Hadoop基础知识的读者为对象，总结了实际环境下熟练操作Hadoop的技术和技巧。这些技巧涵盖了广泛的内容，包括从系统构建∕运用、应用程序开发等熟练使用Hadoop特性的方法，到关于HBase、Hive、Pig、Mahout、ZooKeeper等子项目的技巧。书中描述了高效利用Hadoop所必备的工具及其使用方法、以及了解内部运行的方法、更先进的技术等开发环境必备的74个技巧。《Hadoop Hacks：专家使用的实践技巧》由较早开始关注Hadoop并在实际中灵活使用Hadoop的技术者执笔，是那些希望灵活运用Hadoop的工程师必备的一本书。","price":"58.00"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["太田 一樹","下垣 徹","山下 真一","猿田 浩輔","藤井 達朗"],"pubdate":"2011-1-28","tags":[{"count":2,"name":"软件架构","title":"软件架构"},{"count":2,"name":"架构设计","title":"架构设计"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"索引","title":"索引"},{"count":1,"name":"programming","title":"programming"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4627490.jpg","binding":"大型本","translator":[],"catalog":"","pages":"400","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s4627490.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s4627490.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4627490.jpg"},"alt":"https:\/\/book.douban.com\/subject\/5435448\/","id":"5435448","publisher":"翔泳社","isbn10":"4798122335","isbn13":"9784798122335","title":"Hadoop徹底入門","url":"https:\/\/api.douban.com\/v2\/book\/5435448","alt_title":"","author_intro":"","summary":"","price":"JPY 3990"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Perera, Srinath; Gunarathne, Thilina;"],"pubdate":"","tags":[{"count":2,"name":"mapreduce","title":"mapreduce"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s25922658.jpg","binding":"","translator":[],"catalog":"","pages":"300","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s25922658.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s25922658.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s25922658.jpg"},"alt":"https:\/\/book.douban.com\/subject\/22165650\/","id":"22165650","publisher":"","isbn10":"1849517282","isbn13":"9781849517287","title":"Hadoop Mapreduce Cookbook","url":"https:\/\/api.douban.com\/v2\/book\/22165650","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"云计算、虚拟化、Nova、Swift、Quantum和Hadoop","author":["戢友"],"pubdate":"2014-8-1","tags":[{"count":9,"name":"云计算","title":"云计算"},{"count":7,"name":"openstack","title":"openstack"},{"count":4,"name":"计算机","title":"计算机"},{"count":2,"name":"架构","title":"架构"},{"count":2,"name":"OpenStack","title":"OpenStack"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"专业书","title":"专业书"},{"count":1,"name":"programming","title":"programming"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27786745.jpg","binding":"平装","translator":[],"catalog":"第1篇 基础篇\n第1章 OpenStack概述\n1.1 云计算简介\n1.1.1 什么是云计算\n1.1.2 什么是云存储\n1.1.3 私有云与公有云\n1.2 为什么使用云计算\n1.2.1 方案1：简单的服务部署\n1.2.2 方案2：分布式服务部署\n1.2.3 方案3：基于虚拟化的服务部署\n1.2.4 方案4：云计算的解决方案\n1.3 OpenStack架构\n1.3.1 OpenStack与云计算\n1.3.2 OpenStack发展与现状\n1.3.3 OpenStack优势\n1.3.4 OpenStack学习建议\n1.4 OpenStack各个组件及功能\n1.4.1 虚拟机管理系统Nova\n1.4.2 磁盘存储系统Glance与Swift\n1.4.3 虚拟网络管理Quantum\n1.4.4 OpenStack三大组件\n1.5 小结\n第2章 虚拟化技术\n2.1 虚拟化技术简介\n2.1.1 KVM\n2.1.2 Xen\n2.1.3 Libvirt\n2.2 安装Libvirt虚拟化工具\n2.2.1 安装KVM\n2.2.2 安装Libvirt\n2.3 虚拟机配置文件详解\n2.3.1 xml描述hypervisor\n2.3.2 虚拟机整体信息\n2.3.3 系统信息\n2.3.4 硬件资源特性\n2.3.5 突发事件处理\n2.3.6 raw格式image\n2.3.7 qcow2格式image\n2.3.8 格式的选择\n2.3.9 多个image\n2.3.10 虚拟光盘\n2.3.11 虚拟网络\n2.3.12 vnc配置\n2.4 制作image\n2.4.1 virt-manager创建image\n2.4.2 virsh命令创建image\n2.5 快速启动虚拟机\n2.5.1 手动安装\n2.5.2 直接复制\n2.5.3 qcow2快速创建\n2.5.4 修改qcow2 image\n2.5.5 大批量创建虚拟机\n2.6 虚拟机桌面显示\n2.6.1 准备工作\n2.6.2 创建Windows 7 Image\n2.6.3 创建Windows 7虚拟机\n2.6.4 spice桌面显示\n2.7 常见错误与分析\n2.8 小结\n2.8.1 常用的virsh命令\n2.8.2 磁盘快照管理\n第2篇 安装篇\n第3章 安装Keystone安全认证服务\n3.1 Keystone简介\n3.2 搭建局域网源\n3.2.1 局域网apt-get源搭建方法\n3.2.2 局域网python源搭建方法\n3.2.3 Ubuntu-12.10局域网源\n……\n第4章 安装Swift存储服务\n第5章 安装Glance镜像服务\n第6章 安装Quantum虚拟网络服务\n第7章 安装Cinder块存储服务\n第8章 安装Nova虚拟机管理系统\n第9章 安装Dashboard Web界面\n第10章 OpenStack部署示例\n第3篇 剖析篇\n第11章 OpenStack服务分析\n第12章 Keystone的安全认证\n第13章 Swift存储服务\n第14章 Quantum虚拟网络\n第15章 Nova框架\n第16章 Nova Compute服务\n第4篇 扩展篇\n第17章 从OpenStack到云应用\n第18章 基于Nova的扩展\n第19章 添加自定义组件","pages":"633","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27786745.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27786745.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27786745.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26256907\/","id":"26256907","publisher":"清华大学出版社","isbn10":"7302367000","isbn13":"9787302367000","title":"OpenStack开源云王者归来","url":"https:\/\/api.douban.com\/v2\/book\/26256907","alt_title":"","author_intro":"戢友，毕业于华东师范大学。计算机应用技术硕士。研究方向为机器学习与模式识别。现就职于英特尔亚太研发有限公司，从事OpenStack与云计算的研发工作。对云计算、云存储、大数据和分布式系统有强烈的兴趣和较长时间的研究。","summary":"《OpenStack开源云王者归来：云计算虚拟化Nova、Swift、Quantum与Hadoop》按照入门、剖析、扩展的讲授方式，由浅入深地介绍了开源云计算平台OpenStack（Grizzly版本）的整体框架、安装部署、源码剖析及扩展开发。本书附带的所有源代码和安装脚本均可以在Github上获得。\n《OpenStack开源云王者归来：云计算虚拟化Nova、Swift、Quantum与Hadoop》共19章，分为4篇。第1篇介绍了云计算常识及虚拟化技术（KVM、Libvirt）必备知识；第2篇着重讲解了OpenStack主要组件的安装部署，以及OpenStack整个框架的参考部署；第3篇主要从源码剖析的角度讲解了Keystone、Swift、Quantum和Nova重要组件的设计思想与实现方法；第4篇介绍了如何利用OpenStack进行扩展开发，包括如何在OpenStack平台上搭建Hadoop，对Nova进行扩展，以及如何开发独立的OpenStack组件。\n《OpenStack开源云王者归来：云计算虚拟化Nova、Swift、Quantum与Hadoop》内容全面，实例众多，实践性强，讲解清晰，适合想要从事开源云OpenStack开发的技术人员阅读。对于IT首席技术官、云计算研发和运维等相关人员，本书有很高的参考价值。","price":"99.80元"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["[法]卡勒德•坦尼尔（Khaled Tannir）"],"pubdate":"2015-3","tags":[{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"程序设计","title":"程序设计"},{"count":1,"name":"性能优化","title":"性能优化"},{"count":1,"name":"性能","title":"性能"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"MapReduce","title":"MapReduce"}],"origin_title":"Optimizing Hadoop for MapReduce","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28023088.jpg","binding":"","translator":["范欢动"],"catalog":"目录\n第1章 了解Hadoop MapReduce\t1\n1.1 MapReduce模型\t1\n1.2 Hadoop MapReduce概述\t3\n1.3 Hadoop MapReduce的工作原理\t4\n1.4 影响MapReduce性能的因素\t5\n1.5 小结\t8\n第2章 Hadoop参数概述\t9\n2.1 研究Hadoop参数\t9\n2.1.1 配置文件mapred-site.xml\t10\n2.1.2 配置文件hdfs-site.xml\t15\n2.1.3 配置文件core-site.xml\t18\n2.2 Hadoop MapReduce性能指标\t19\n2.3 性能监测工具\t20\n2.3.1 用Chukwa监测Hadoop\t21\n2.3.2 使用Ganglia监测Hadoop\t21\n2.3.3 使用Nagios监测Hadoop\t21\n2.4 用Apache Ambari监测Hadoop\t22\n2.5 小结\t23\n第3章 检测系统瓶颈\t25\n3.1 性能调优\t25\n3.2 创建性能基线\t27\n3.3 识别资源瓶颈\t30\n3.3.1 识别内存瓶颈\t30\n3.3.2 识别CPU瓶颈\t31\n3.3.3 识别存储瓶颈\t32\n3.3.4 识别网络带宽瓶颈\t33\n3.4 小结\t34\n第4章 识别资源薄弱环节\t35\n4.1 识别集群薄弱环节\t35\n4.1.1 检查Hadoop集群节点的健康状况\t36\n4.1.2 检查输入数据大小\t37\n4.1.3 检查海量I\/O和网络阻塞\t38\n4.1.4 检查并发任务不足\t39\n4.1.5 检查CPU过饱和\t40\n4.2 量化Hadoop集群\t41\n4.3 正确配置集群\t44\n4.4 小结\t47\n第5章 强化map和reduce任务\t49\n5.1 强化map任务\t49\n5.1.1 输入数据和块大小的影响\t51\n5.1.2 处置小文件和不可拆分文件\t51\n5.1.3 在Map阶段压缩溢写记录\t53\n5.1.4 计算map任务的吞吐量\t55\n5.2 强化reduce任务\t57\n5.2.1 计算reduce任务的吞吐量\t58\n5.2.2 改善Reduce执行阶段\t59\n5.3 调优map和reduce参数\t60\n5.4 小结\t64\n第6章 优化MapReduce任务\t65\n6.1 使用Combiner\t65\n6.2 使用压缩技术\t68\n6.3 使用正确Writable类型\t72\n6.4 明智地复用类型\t74\n6.5 优化mapper和reducer的代码\t76\n6.6 小结\t78\n第7章 最佳实践与建议\t81\n7.1 硬件调优与操作系统推荐\t81\n7.1.1 Hadoop集群检查表\t81\n7.1.2 Bios调优检查表\t82\n7.1.3 OS配置建议\t82\n7.2 Hadoop最佳实践与建议\t83\n7.2.1 部署Hadoop\t83\n7.2.2 Hadoop调优建议\t84\n7.2.3 使用MapReduce模板类代码\t86\n7.3 小结\t90","pages":"90","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28023088.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28023088.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28023088.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26340985\/","id":"26340985","publisher":"人民邮电出版社","isbn10":"7115381275","isbn13":"9787115381279","title":"Hadoop MapReduce性能优化","url":"https:\/\/api.douban.com\/v2\/book\/26340985","alt_title":"Optimizing Hadoop for MapReduce","author_intro":"作者介绍\nKhaled Tannirhas从1980年开始从事计算机相关工作。他是微软认证的开发人员（MCSD），他在领导软件解决方案的开发和实施以及技术演说方面，拥有20多年技术经验。如今，他是一名独立IT咨询师，并在法国、加拿大的许多大公司担任基础设施工程师、高级研发工程师、企业\/解决方案架构师等职务。\n他在Microsoft .NET、Microsoft服务器系统、Oracle Java技术等领域拥有丰富的经验，并且熟练驾驭在线和离线应用系统设计、系统转换以及多语言的互联网\/桌面应用程序开发。\nKhaled Tnnirhas总是热衷于探索和学习新的技术，并基于这些技术在法国、北美、中东等地区寻求商机。他现在拥有一个IT电子实验室，实验室中配备了很多服务器、监控器、开源电子板（如Arduino、Netduino、RaspBerry Pi和.Net Gadgeteer），还有一些装有Windows Phone、Android和iOS操作系统的智能设备。\n2012年，他协助组织并出席了法国波尔多大学的复杂数据挖掘国际论坛——EGC 2012。\n他还是《RavenDB 2.x Beginner’s Guide》一书的作者。\n译者简介\n范欢动 信息技术领域的一名老兵。1994年获得电力系统及其自动化专业学士学位。1997年获得信号与信息处理专业硕士学位。兴趣广泛，涉及技术领域和非技术领域，但大多浅尝辄止。参与过航天、通信、电子出版和金融领域的信息处理、软件架构与开发，以第一作者或合作者身份拥有三项实用新型专利，并获得第十八届北京市优秀青年工程师称号。曾在佳讯飞鸿电气股份有限公司、英国雅讯（xarios）北京代表处、博云科技等公司担任产品技术总监。目前，终于把全部的兴趣聚焦到了数据分析，尤其是大数据分析上，主要目标是利用数据分析手段发现模式，从而降低决策风险、改善产业价值链。冀望在大数据时代与读者一起学习并分享大数据相关技术，共同发掘大数据带来的价值。","summary":"大数据时代，MapReduce的重要性不言而喻。Hadoop作为MapReduce框架的一个实现，受到业界广泛的认同，并被广泛部署和应用。尽管Hadoop为数据开发工程师入门和编程提供了极大便利，但构造一个真正满足性能要求的MapReduce程序并不简单。数据量巨大是大数据工作的现实问题，而对低响应时间的要求则时常困扰着数据开发工程师。\n本书采用原理与实践相结合的方式，通过原理讲解影响MapReduce性能的因素，透过实例一步步地教读者如何发现性能瓶颈并消除瓶颈，如何识别系统薄弱环节并改善薄弱环节，讲解过程中融合了作者在优化实践过程中积累的丰富经验，具有很强的针对性。读完本书，能让读者对Hadoop具有更强的驾驭能力，从而构造出性能最优的MapReduce程序。\nHadoop性能问题既是程序层面的问题，也是系统层面的问题。本书既覆盖了系统层面的优化又覆盖了程序层面的优化，非常适合Hadoop管理员和有经验的数据开发工程师阅读。对于初学者，本书第1章也作了必要的技术铺垫，避免对后面章节的理解产生梯度。\n","price":"35.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["Lublinsky, Boris; Smith, Kevin T.; Yakubovich, Alexey"],"pubdate":"2013-10","tags":[{"count":3,"name":"计算机","title":"计算机"},{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"文件系統","title":"文件系統"},{"count":1,"name":"數據庫","title":"數據庫"},{"count":1,"name":"数据库","title":"数据库"},{"count":1,"name":"云计算","title":"云计算"},{"count":1,"name":"wrox","title":"wrox"},{"count":1,"name":"technology","title":"technology"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s26667405.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"504","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s26667405.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s26667405.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s26667405.jpg"},"alt":"https:\/\/book.douban.com\/subject\/22024056\/","id":"22024056","publisher":"Wrox","isbn10":"1118611934","isbn13":"9781118611937","title":"Professional Hadoop Solutions","url":"https:\/\/api.douban.com\/v2\/book\/22024056","alt_title":"","author_intro":"","summary":"The go-to guidebook for deploying Big Data solutions with Hadoop  Today's enterprise architects need to understand how the Hadoop frameworks and APIs fit together, and how they can be integrated to deliver real-world solutions. This book is a practical, detailed guide to building and implementing those solutions, with code-level instruction in the popular Wrox tradition. It covers storing data with HDFS and Hbase, processing data with MapReduce, and automating data processing with Oozie. Hadoop security, running Hadoop with Amazon Web Services, best practices, and automating Hadoop processes in real time are also covered in depth. With in-depth code examples in Java and XML and the latest on recent additions to the Hadoop ecosystem, this complete resource also covers the use of APIs, exposing their inner workings and allowing architects and developers to better leverage and customize them. The ultimate guide for developers, designers, and architects who need to build and deploy Hadoop applications Covers storing and processing data with various technologies, automating data processing, Hadoop security, and delivering real-time solutions Includes detailed, real-world examples and code-level guidelines Explains when, why, and how to use these tools effectively Written by a team of Hadoop experts in the programmer-to-programmer Wrox style Professional Hadoop Solutions  is the reference enterprise architects and developers need to maximize the power of Hadoop.","price":"$ 56.49"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["Garry Turkington"],"pubdate":"2013-2-22","tags":[{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"软件开发","title":"软件开发"},{"count":1,"name":"程序设计","title":"程序设计"},{"count":1,"name":"分布式文件系统","title":"分布式文件系统"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28370764.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"398","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28370764.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28370764.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28370764.jpg"},"alt":"https:\/\/book.douban.com\/subject\/22165649\/","id":"22165649","publisher":"Packt Publishing","isbn10":"1849517304","isbn13":"9781849517300","title":"Hadoop Beginner's Guide","url":"https:\/\/api.douban.com\/v2\/book\/22165649","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["周  品"],"pubdate":"2012-10","tags":[{"count":5,"name":"hadoop","title":"hadoop"},{"count":1,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"云计算","title":"云计算"},{"count":1,"name":"Hadoop云计算实战","title":"Hadoop云计算实战"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24412711.jpg","binding":"平装","translator":[],"catalog":"第1章  云计算概论\t1\n1.1  云计算概述\t1\n1.1.1  云计算的定义\t1\n1.1.2  云计算产生的背景\t2\n1.1.3  云时代谁是主角\t3\n1.1.4  云计算的特征\t4\n1.1.5  云计算的发展史\t5\n1.1.6  云计算的服务层次\t7\n1.1.7  云计算的服务形式\t7\n1.1.8  云计算的实现机制\t9\n1.1.9  云计算研究方向\t11\n1.1.10  云计算发展趋势\t12\n1.2  云计算关键技术研究\t14\n1.2.1  虚拟化技术\t14\n1.2.2  数据存储技术\t15\n1.2.3  资源管理技术\t17\n1.2.4  能耗管理技术\t18\n1.2.5  云监测技术\t19\n1.3  云计算应用研究\t22\n1.3.1  语义分析应用\t22\n1.3.2  IT企业应用\t22\n1.3.3  生物学应用\t23\n1.3.4  电信企业应用\t24\n1.3.5  数据库的应用\t27\n1.3.6  地理信息应用\t28\n1.3.7  医学应用\t29\n1.4  云安全\t30\n1.4.1  云安全发展趋势\t31\n1.4.2  云安全与网络安全的差别\t31\n1.4.3  云安全研究的方向\t31\n1.4.4  云安全难点问题\t32\n1.4.5  云安全新增及增强功能\t32\n1.5  云计算生命周期\t33\n1.6  云计算存在的问题\t34\n1.7  云计算的优缺点\t35\n第2章  Hadoop相关项目介绍\t37\n2.1  Hadoop简介\t37\n2.1.1  Hadoop的基本架构\t37\n2.1.2  Hadoop文件系统结构\t40\n2.1.3  Hadoop文件读操作\t41\n2.1.4  Hadoop文件写操作\t42\n2.2  Hadoop系统性质\t42\n2.2.1  可靠存储性\t43\n2.2.2  数据均衡\t43\n2.3  比较SQL数据库与Hadoop\t44\n2.4  MapReduce概述\t45\n2.4.1  MapReduce实现机制\t45\n2.4.2  MapReduce执行流程\t46\n2.4.3  MapReduce映射和化简\t47\n2.4.4  MapReduce输入格式\t47\n2.4.5  MapReduce输出格式\t48\n2.4.6  MapReduce运行速度\t48\n2.5  HBase概述\t48\n2.5.1  HBase的系统框架\t49\n2.5.2  HBase访问接口\t51\n2.5.3  HBase的存储格式\t52\n2.5.4  HBase的读写流程\t52\n2.5.5  Hbase的优缺点\t53\n2.6  ZooKeeper概述\t53\n2.6.1  为什么需要ZooKeeper\t54\n2.6.2  ZooKeeper设计目标\t54\n2.6.3  ZooKeeper数据模型\t54\n2.6.4  ZooKeeper工作原理\t55\n2.6.5  ZooKeeper实现机制\t56\n2.6.6  ZooKeeper的特性\t57\n2.7  Hive概述\t58\n2.7.1  Hive的组成\t59\n2.7.2  Hive结构解析\t59\n2.8  Pig概述\t63\n2.9  Cassandra概述\t64\n2.9.1  Cassandra主要功能\t64\n2.9.2  Cassandra的体系结构\t65\n2.9.3  Cassandra存储机制\t65\n2.9.4  Cassandra的写过程\t66\n2.9.5  Cassandra的读过程\t67\n2.9.6  Cassandra的删除\t68\n2.10  Chukwa概述\t68\n2.10.1  使用Chukwa的原因\t68\n2.10.2  Chukwa的不是\t69\n2.10.3  Chukwa的定义\t69\n2.10.4  Chukwa架构与设计\t70\n第3章  Hadoop配置与实战\t74\n3.1  Hadoop的安装\t74\n3.1.1  在Linux下安装Hadoop\t74\n3.1.2  运行模式\t75\n3.1.3  在Windows下安装Hadoop\t80\n3.2  运行Hadoop\t86\n3.3  Hadoop的Avatar机制\t87\n3.3.1  系统架构\t88\n3.3.2  元数据同步机制\t89\n3.3.3  切换故障过程\t91\n3.3.4  运行流程\t92\n3.3.5  切换故障流程\t96\n3.4  Hadoop实战\t99\n3.4.1  使用Hadoop运行wordcount实例\t99\n3.4.2  使用Eclipse编写Hadoop程序\t101\n第4章  Hadoop的分布式数据HDFS\t102\n4.1  HDFS的操作\t102\n4.1.1  文件操作\t102\n4.1.2  管理与更新\t103\n4.2  FS Shell使用指南\t104\n4.3  API使用\t111\n4.3.1  文件系统的常见操作\t111\n4.3.2  API的Java操作实例\t113\n第5章  Hadoop编程模型MapReduce\t118\n5.1  MapReduce基础\t118\n5.1.1  MapReduce编程模型\t118\n5.1.2  MapReduce实现机制\t119\n5.1.3  Java MapReduce\t121\n5.2  MapReduce的容错性\t124\n5.3  MapReduce实例分析\t125\n5.4  不带map()、reduce()的MapReduce\t131\n5.5  Shuffle过程\t133\n5.6  新增Hadoop API\t136\n5.7  Hadoop的Streaming\t138\n5.7.1  通过UNIX命令使用Streaming\t138\n5.7.2  通过Ruby版本使用Streaming\t139\n5.7.3  通过Python版本使用Streaming\t141\n5.8  MapReduce实战\t142\n5.8.1  MapReduce排序\t142\n5.8.2  MapReduce二次排序\t145\n5.9  MapReduce作业分析\t153\n5.10  定制MapReduce数据类型\t156\n5.10.1  内置的数据输入格式和RecordReader\t156\n5.10.2  定制输入数据格式与RecordReader\t157\n5.10.3  定制数据输出格式实现多集合文件输出\t160\n5.11  链接MapReduce作业\t162\n5.11.1  顺序链接MapReduce作业\t162\n5.11.2  复杂的MapReduce链接\t163\n5.11.3  前后处理的链接\t163\n5.11.4  链接不同的数据\t166\n5.12  Hadoop的Pipes\t172\n5.13  创建Bloom filter\t174\n5.13.1  Bloom filter作用\t175\n5.13.2  Bloom filter实现\t175\n第6章  Hadoop的数据库HBase\t182\n6.1  HBase数据模型\t182\n6.1.1  数据模型\t182\n6.1.2  概念视图\t183\n6.1.3  物理视图\t184\n6.2  HBase与RDBMS对比\t185\n6.3  Bigtable的应用实例\t188\n6.4  HBase的安装与配置\t189\n6.5  Java API\t196\n6.6  HBase实例分析\t204\n6.6.1  RowLock\t204\n6.6.2  HBase的HFileOutputFormat\t207\n6.6.3  HBase的TableOutputFormat\t210\n6.6.4  在HBase中使用MapReduce\t213\n6.6.5  HBase分布式模式\t215\n第7章  Hadoop的数据仓库Hive\t220\n7.1  Hive的安装\t220\n7.1.1  准备的软件包\t220\n7.1.2  内嵌模式安装\t220\n7.1.3  安装独立模式\t221\n7.1.4  远程模式安装\t222\n7.1.5  查看数据信息\t222\n7.2  Hive的入口\t223\n7.2.1  类CliDriver\t225\n7.2.2  类CliSessionState\t229\n7.2.3  类CommandProcessor\t230\n7.3  Hive QL详解\t232\n7.3.1  Hive的数据类型\t232\n7.3.2  Hive与数据库比较\t233\n7.3.3  DDL操作\t234\n7.3.4  join查询\t241\n7.3.5  DML操作\t243\n7.3.6  SQL操作\t245\n7.3.7  Hive QL的应用实例\t248\n7.4  Hive的服务\t250\n7.4.1  JDBC\/ODBC服务\t250\n7.4.2  Thrift服务\t253\n7.4.3  Web接口\t255\n7.5  Hive SQL的优化\t256\n7.5.1  Hive SQL优化选项\t256\n7.5.2  Hive SQL优化应用实例\t258\n7.6  Hive的扩展性\t261\n7.6.1  SerDe\t262\n7.6.2  Map\/Reduce脚本\t263\n7.6.3  UDF\t263\n7.6.4  UDAF\t264\n7.7  Hive实战\t266\n第8章  Hadoop的大规模数据平台Pig\t274\n8.1  Pig的安装与运行\t274\n8.1.1  Pig的安装\t274\n8.1.2  Pig的运行\t274\n8.2  Pig实现\t278\n8.3  Pig Latin语言\t279\n8.3.1  Pig Latin语言概述\t280\n8.3.2  Pig Latin数据类型\t282\n8.3.3  Pig Latin运算符\t284\n8.3.4  Pig Latin关键字\t287\n8.3.5  Pig内置函数\t288\n8.4  自定义函数\t291\n8.4.1  UDF的编写\t292\n8.4.2  UDFS的使用\t293\n8.5  Jaql和Pig查询语言的比较\t293\n8.5.1  Pig和Jaql运行环境和执行形式的比较\t294\n8.5.2  Pig和Jaql支持数据类型的比较\t294\n8.5.3  Pig和Jaql操作符和内建函数以及自定义函数的比较\t295\n8.5.4  其他\t299\n8.6  Pig实战\t300\n第9章  Hadoop的非关系型数据Cassandra\t308\n9.1  Cassandra的安装\t308\n9.1.1  在Windows 7中安装\t308\n9.1.2  在Linux中安装\t310\n9.2  Cassandra的数据模型\t311\n9.2.1  Column\t311\n9.2.2  SuperColumn\t312\n9.2.3  ColumnFamily\t312\n9.2.4  Row\t313\n9.2.5  排序\t313\n9.3  Cassandra的实例分析\t315\n9.3.1  Cassandra的数据存储结构\t315\n9.3.2  跟踪客户端代码\t319\n9.4  Cassandra常用的编程语言\t324\n9.4.1  Java使用Cassandra\t324\n9.4.2  PHP使用Cassandra\t325\n9.4.3  Python使用Cassandra\t326\n9.4.4  C#使用Cassandra\t327\n9.4.5  Ruby使用Cassandra\t328\n9.5  Cassandra与MapReduce结合\t328\n9.5.1  需求分析\t329\n9.5.2  代码分析\t330\n9.5.3  MapReduce代码\t330\n9.6  Cassandra实战\t331\n9.6.1  BuyerDao功能验证\t331\n9.6.2  SellerDao功能验证\t332\n9.6.3  ProductDao功能验证\t333\n9.6.4  新建Schema在线功能\t336\n9.6.5  功能验证\t337\n第10章  Hadoop的收集数据Chukwa\t339\n10.1  Chukwa的安装与配置\t339\n10.1.1  配置要求\t339\n10.1.2  Chukwa的安装\t340\n10.1.3  基本命令\t341\n10.2  Chukwa数据流处理\t344\n10.2.1  支持数据类型\t344\n10.2.2  数据处理\t345\n10.2.3  自定义数据模块\t351\n10.3  Chukwa源代码分析\t352\n10.3.1  Chukwa适配器\t352\n10.3.2  Chukwa连接器\t357\n10.3.3  Chukwa收集器\t362\n10.4  Chukwa实例分析\t366\n10.4.1  生成数据\t366\n10.4.2  收集数据\t367\n10.4.3  处理数据\t367\n10.4.4  析取数据\t368\n10.4.5  稀释数据\t368\n第11章  Hadoop的分布式系统ZooKeeper\t369\n11.1  ZooKeeper的安装与配置\t369\n11.1.1  ZooKeeper的安装\t369\n11.1.2  ZooKeeper的配置\t371\n11.1.3  ZooKeeper数据模型\t373\n11.1.4  ZooKeeper的API接口\t373\n11.1.5  ZooKeeper编程实现\t375\n11.2  ZooKeeper的Leader流程\t378\n11.3  ZooKeeper锁服务\t379\n11.3.1  ZooKeeper中的锁机制\t379\n11.3.2  ZooKeeper的写锁实现\t380\n11.3.3  ZooKeeper锁服务实现例子\t381\n11.4  创建ZooKeeper应用程序\t383\n11.5  ZooKeeper的应用开发\t387\n11.6  ZooKeeper的典型应用\t395\n11.6.1  统一命名服务\t396\n11.6.2  配置管理\t396\n11.6.3  集群管理\t397\n11.6.4  共享锁\t398\n11.6.5  队列管理\t399\n11.7  实现NameNode自动切换\t402\n网上参考资源\t410\n参考文献\t412","pages":"411","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s24412711.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s24412711.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24412711.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20259696\/","id":"20259696","publisher":"清华大学出版社","isbn10":"7302296731","isbn13":"9787302296737","title":"Hadoop云计算实战","url":"https:\/\/api.douban.com\/v2\/book\/20259696","alt_title":"","author_intro":"","summary":"《Hadoop云计算实战》全面介绍了云计算的基本概念、Google（谷歌）云计算的关键技术，以及Hadoop云计算的相关配套项目及其实战，包括Hadoop的HDFS、MapReduce、HBase、Hive、Pig、Cassandra、Chukwa及ZooKeeper等配套项目的实现机制、用法及应用。","price":"46.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["中野 猛","山下 真一","猿田 浩輔","上新 卓也","小林 隆"],"pubdate":"2012-4-25","tags":[{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s9066648.jpg","binding":"単行本（ソフトカバー）","translator":[],"catalog":"","pages":"434","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s9066648.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s9066648.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s9066648.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10608445\/","id":"10608445","publisher":"オライリージャパン","isbn10":"4873115469","isbn13":"9784873115467","title":"Hadoop Hacks ―プロフェッショナルが使う実践テクニック","url":"https:\/\/api.douban.com\/v2\/book\/10608445","alt_title":"","author_intro":"","summary":"","price":"JPY 3780"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Thilina Gunarathne"],"pubdate":"2015-1-25","tags":[{"count":1,"name":"mapreduce","title":"mapreduce"},{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28019791.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"293","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28019791.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28019791.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28019791.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26337688\/","id":"26337688","publisher":"Packt Publishing - ebooks Account","isbn10":"1783285478","isbn13":"9781783285471","title":"Hadoop MapReduce v2 Cookbook Second Edition","url":"https:\/\/api.douban.com\/v2\/book\/26337688","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Schneider, Robert D."],"pubdate":"2012","tags":[{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s24634196.jpg","binding":"","translator":[],"catalog":"","pages":"64","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s24634196.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s24634196.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s24634196.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20559637\/","id":"20559637","publisher":"John Wiley & Sons Canada, Ltd.","isbn10":"1118250516","isbn13":"9781118250518","title":"Hadoop For Dummies (Special Edition)","url":"https:\/\/api.douban.com\/v2\/book\/20559637","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Hrishikesh Karambelkar"],"pubdate":"2013-8-26","tags":[{"count":2,"name":"Solr","title":"Solr"},{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"搜索引擎","title":"搜索引擎"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27213543.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"144","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27213543.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27213543.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27213543.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25822198\/","id":"25822198","publisher":"Packt Publishing","isbn10":"1783281375","isbn13":"9781783281374","title":"Scaling Big Data with Hadoop and Solr","url":"https:\/\/api.douban.com\/v2\/book\/25822198","alt_title":"","author_intro":"","summary":"","price":"USD 44.99"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"Protecting Your Big Data Platform","author":["Ben Spivey","Joey Echeverria"],"pubdate":"2015-7-16","tags":[{"count":3,"name":"Security","title":"Security"},{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"Bigdata","title":"Bigdata"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28272682.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"340","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28272682.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28272682.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28272682.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26588595\/","id":"26588595","publisher":"O'Reilly Media","isbn10":"1491900989","isbn13":"9781491900987","title":"Hadoop Security","url":"https:\/\/api.douban.com\/v2\/book\/26588595","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["Sameer Wadkar","Madhu Siddalingaiah","Jason Venner"],"pubdate":"2014-9-10","tags":[{"count":3,"name":"数据分析","title":"数据分析"},{"count":3,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27507386.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"444","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27507386.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27507386.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27507386.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20780560\/","id":"20780560","publisher":"Apress","isbn10":"1430248637","isbn13":"9781430248637","title":"Pro Apache Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/20780560","alt_title":"","author_intro":"","summary":"","price":"USD 44.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Garry Turkington","Gabriele Modena"],"pubdate":"2014-12-29","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"英文版","title":"英文版"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28031291.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"316","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28031291.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28031291.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28031291.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26349038\/","id":"26349038","publisher":"Packt Publishing - ebooks Account","isbn10":"1783285516","isbn13":"9781783285518","title":"Learning Hadoop 2","url":"https:\/\/api.douban.com\/v2\/book\/26349038","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"","author":["林意群"],"pubdate":"2017-4-1","tags":[{"count":3,"name":"hadoop","title":"hadoop"},{"count":3,"name":"HDFS","title":"HDFS"},{"count":2,"name":"大数据","title":"大数据"},{"count":2,"name":"分布式系统","title":"分布式系统"},{"count":2,"name":"Java","title":"Java"},{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"分布式","title":"分布式"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29488328.jpg","binding":"平装","translator":[],"catalog":"前言\n第一部分 核心设计篇\n第1章 HDFS的数据存储2\n1.1 HDFS内存存储2\n1.1.1 HDFS内存存储原理2\n1.1.2 Linux 虚拟内存盘4\n1.1.3 HDFS的内存存储流程分析4\n1.1.4 LAZY_PERSIST内存存储的使用14\n1.2 HDFS异构存储15\n1.2.1 异构存储类型16\n1.2.2 异构存储原理17\n1.2.3 块存储类型选择策略22\n1.2.4 块存储策略集合24\n1.2.5 块存储策略的调用27\n1.2.6 HDFS异构存储策略的不足之处28\n1.2.7 HDFS存储策略的使用30\n1.3 小结31\n第2章 HDFS的数据管理与策略选择32\n2.1 HDFS缓存与缓存块32\n2.1.1 HDFS物理层面缓存块33\n2.1.2 缓存块的生命周期状态34\n2.1.3 CacheBlock、UnCacheBlock场景触发36\n2.1.4 CacheBlock、UnCacheBlock缓存块的确定38\n2.1.5 系统持有的缓存块列表如何更新39\n2.1.6 缓存块的使用40\n2.1.7 HDFS缓存相关配置40\n2.2 HDFS中心缓存管理42\n2.2.1 HDFS缓存适用场景43\n2.2.2 HDFS缓存的结构设计43\n2.2.3 HDFS缓存管理机制分析45\n2.2.4 HDFS中心缓存疑问点55\n2.2.5 HDFS CacheAdmin命令使用56\n2.3 HDFS快照管理58\n2.3.1 快照概念59\n2.3.2 HDFS中的快照相关命令59\n2.3.3 HDFS内部的快照管理机制60\n2.3.4 HDFS的快照使用71\n2.4 HDFS副本放置策略72\n2.4.1 副本放置策略概念与方法72\n2.4.2 副本放置策略的有效前提73\n2.4.3 默认副本放置策略的分析73\n2.4.4 目标存储好坏的判断82\n2.4.5 chooseTargets的调用83\n2.4.6 BlockPlacementPolicyWithNodeGroup继承类84\n2.4.7 副本放置策略的结果验证85\n2.5 HDFS内部的认证机制85\n2.5.1 BlockToken认证85\n2.5.2 HDFS的Sasl认证91\n2.5.3 BlockToken认证与HDFS的Sasl认证对比97\n2.6 HDFS内部的磁盘目录服务98\n2.6.1 HDFS的三大磁盘目录检测扫描服务98\n2.6.2 DiskChecker：坏盘检测服务99\n2.6.3 DirectoryScanner：目录扫描服务104\n2.6.4 VolumeScanner：磁盘目录扫描服务110\n2.7 小结116\n第3章 HDFS的新颖功能特性117\n3.1 HDFS视图文件系统：ViewFileSystem117\n3.1.1 ViewFileSystem： 视图文件系统118\n3.1.2 ViewFileSystem内部实现原理119\n3.1.3 ViewFileSystem的使用125\n3.2 HDFS的Web文件系统：WebHdfsFileSystem126\n3.2.1 WebHdfsFileSystem的REST API操作127\n3.2.2 WebHdfsFileSystem的流程调用129\n3.2.3 WebHdfsFileSystem执行器调用130\n3.2.4 WebHDFS的OAuth2认证133\n3.2.5 WebHDFS的使用135\n3.3 HDFS数据加密空间：Encryption zone136\n3.3.1 Encryption zone原理介绍136\n3.3.2 Encryption zone源码实现136\n3.3.3 Encryption zone的使用144\n3.4 HDFS纠删码技术145\n3.4.1 纠删码概念145\n3.4.2 纠删码技术的优劣势146\n3.4.3 Hadoop纠删码概述147\n3.4.4 纠删码技术在Hadoop中的实现148\n3.5 HDFS对象存储：Ozone152\n3.5.1 Ozone介绍153\n3.5.2 Ozone的高层级设计154\n3.5.3 Ozone的实现细节157\n3.5.4 Ozone的使用157\n3.6 小结158\n第二部分 细节实现篇\n第4章 HDFS的块处理160\n4.1 HDFS块检查命令fsck160\n4.1.1 fsck参数使用160\n4.1.2 fsck过程调用161\n4.1.3 fsck原理分析162\n4.1.4 fsck使用场景171\n4.2 HDFS如何检测并删除多余副本块171\n4.2.1 多余副本块以及发生的场景172\n4.2.2 OverReplication多余副本块处理172\n4.2.3 多余副本块清除的场景调用177\n4.3 HDFS数据块的汇报与处理179\n4.3.1 块处理的五大类型179\n4.3.2 toAdd：新添加的块181\n4.3.3 toRemove：待移除的块184\n4.3.4 toInvalidate：无效的块186\n4.3.5 toCorrupt：损坏的块189\n4.3.6 toUC：正在构建中的块191\n4.4 小结193\n第5章 HDFS的流量处理194\n5.1 HDFS的内部限流194\n5.1.1 数据的限流194\n5.1.2 DataTransferThrottler限流原理196\n5.1.3 数据流限流在Hadoop中的使用198\n5.1.4 Hadoop限流优化点202\n5.2 数据平衡204\n5.2.1 Balancer和Dispatcher204\n5.2.2 数据不平衡现象207\n5.2.3 Balancer性能优化207\n5.3 HDFS节点内数据平衡210\n5.3.1 磁盘间数据不平衡现象及问题211\n5.3.2 传统的磁盘间数据不平衡解决方案211\n5.3.3 社区解决方案：DiskBalancer212\n5.4 小结216\n第6章 HDFS的部分结构分析217\n6.1 HDFS镜像文件的解析与反解析217\n6.1.1 HDFS的FsImage镜像文件218\n6.1.2 FsImage的解析218\n6.1.3 FsImage的反解析221\n6.1.4 HDFS镜像文件的解析与反解析命令226\n6.2 DataNode数据处理中心DataXceiver227\n6.2.1 DataXceiver的定义和结构228\n6.2.2 DataXceiver下游处理方法232\n6.2.3 ShortCircuit232\n6.2.4 DataXceiver的上游调用233\n6.2.5 DataXceiver与DataXceiverServer234\n6.3 HDFS邻近信息块：BlockInfoContiguous235\n6.3.1 triplets对象数组236\n6.3.2 BlockInfoContiguous的链表操作239\n6.3.3 块迭代器BlockIterator244\n6.4 小结246\n第三部分 解决方案篇\n第7章 HDFS的数据管理248\n7.1 HDFS的读写限流方案248\n7.1.1 限流方案实现要点以及可能造成的影响248\n7.1.2 限流方案实现249\n7.1.3 限流测试结果250\n7.2 HDFS数据资源使用量分析以及趋势预测250\n7.2.1 要获取哪些数据251\n7.2.2 如何获取这些数据251\n7.2.3 怎么用这些数据254\n7.3 HDFS数据迁移解决方案257\n7.3.1 数据迁移使用场景257\n7.3.2 数据迁移要素考量258\n7.3.3 HDFS数据迁移解决方案：DistCp259\n7.3.4 DistCp优势特性260\n7.3.5 Hadoop DistCp命令264\n7.3.6 DistCp解决集群间数据迁移实例265\n7.4 DataNode迁移方案265\n7.4.1 迁移方案的目标266\n7.4.2 DataNode更换主机名、ip地址时的迁移方案267\n7.5 HDFS集群重命名方案268\n7.6 HDFS的配置管理方案271\n7.6.1 HDFS配置管理的问题271\n7.6.2 现有配置管理工具272\n7.6.3 运用Git来做配置管理272\n7.7 小结273\n第8章 HDFS的数据读写274\n8.1 DataNode引用计数磁盘选择策略274\n8.1.1 HDFS现有磁盘选择策略274\n8.1.2 自定义磁盘选择策略279\n8.2 Hadoop节点“慢磁盘”监控282\n8.2.1 慢磁盘的定义以及如何发现282\n8.2.2 慢磁盘监控284\n8.3 小结287\n第9章 HDFS的异常场景288\n9.1 DataNode慢启动问题288\n9.1.1 DataNode慢启动现象288\n9.1.2 代码追踪分析290\n9.1.3 参数可配置化改造293\n9.2 Hadoop中止下线操作后大量剩余复制块问题295\n9.2.1 节点下线操作的含义及问题295\n9.2.2 死节点“复活”297\n9.2.3 Decommission下线操作如何运作299\n9.2.4 中止下线操作后移除残余副本块解决方案303\n9.3 DFSOutputStream的DataStreamer线程泄漏问题306\n9.3.1 DFSOutputStream写数据过程及周边相关类、变量306\n9.3.2 DataStreamer数据流对象307\n9.3.3 ResponseProcessor回复获取类311\n9.3.4 DataStreamer与DFSOutputStream的关系313\n9.3.5 Streamer线程泄漏问题316\n9.4 小结319\n附录 如何向开源社区提交自己的代码320","pages":"322","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29488328.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29488328.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29488328.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27082353\/","id":"27082353","publisher":"","isbn10":"7111562070","isbn13":"9787111562078","title":"深度剖析Hadoop HDFS","url":"https:\/\/api.douban.com\/v2\/book\/27082353","alt_title":"","author_intro":"林意群，唯品会上海研发中心数据平台与应用部研发工程师，Apache Hadoop Committer，主要专注于HDFS模块的研究。对大数据处理、分布式计算兴趣浓厚，在实际工作中努力钻研，分享了大量技术文章，贡献了很多实践经验。","summary":"《深度剖析Hadoop HDFS》基于Hadoop 2.7.1版本进行分析，全面描述了HDFS 2.X的核心技术与解决方案，书中描述了HDFS内存存储、异构存储等几大核心设计，包括源码细节层面的分析，对于HDFS中比较特殊的几个场景过程也做了细粒度的分析。还分享了作者在实际应用中的解决方案及扩展思路。阅读《深度剖析Hadoop HDFS》可以帮助读者从架构设计与功能实现角度了解HDFS 2.X，同时还能学习HDFS 2.X框架中优秀的设计思想、设计模式、Java语言技巧等。这些对于读者全面提高自己分布式技术水平有很大的帮助。《深度剖析Hadoop HDFS》分为三大部分：核心设计篇、细节实现篇、解决方案篇，“核心设计篇”包括HDFS的数据存储原理、HDFS的数据管理与策略选择机制、HDFS的新颖功能特性；“细节实现篇”包括HDFS的块处理、流量处理等细节，以及部分结构分析；“解决方案篇”包括HDFS的数据管理、HDFS的数据读写、HDFS的异常场景等。","series":{"id":"19432","title":"大数据技术丛书"},"price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Jimmy Lin","Chris Dyer"],"pubdate":"2011-10-1","tags":[{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"大型本","translator":[],"catalog":"","pages":"210","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/6844737\/","id":"6844737","publisher":"オライリージャパン","isbn10":"4873115124","isbn13":"9784873115122","title":"Hadoop MapReduce デザインパターン ―MapReduceによる大規模テキストデータ処理","url":"https:\/\/api.douban.com\/v2\/book\/6844737","alt_title":"","author_intro":"","summary":"","price":"JPY 2940"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Big Data Analytics with Oracle R Enterprise and Oracle R Connector for Hadoop","author":["Mark Hornick","Tom Plunkett"],"pubdate":"2013-6-6","tags":[{"count":2,"name":"R","title":"R"},{"count":1,"name":"数据挖掘","title":"数据挖掘"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29824509.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"77","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29824509.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29824509.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29824509.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24757777\/","id":"24757777","publisher":"McGraw-Hill Education","isbn10":"0071824383","isbn13":"9780071824385","title":"Using R to Unlock the Value of Big Data","url":"https:\/\/api.douban.com\/v2\/book\/24757777","alt_title":"","author_intro":"","summary":"","price":"GBP 18.80"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Husain, Mohammad Farhan"],"pubdate":"","tags":[{"count":1,"name":"mapreduce","title":"mapreduce"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s18663479.jpg","binding":"","translator":[],"catalog":"","pages":"136","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s18663479.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s18663479.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s18663479.jpg"},"alt":"https:\/\/book.douban.com\/subject\/16140754\/","id":"16140754","publisher":"","isbn10":"1249038197","isbn13":"9781249038191","title":"Data Intensive Query Processing for Semantic Web Data Using Hadoop and Mapreduce.","url":"https:\/\/api.douban.com\/v2\/book\/16140754","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Ofer Mendelevitch","Casey Stella","Douglas Eadline"],"pubdate":"2016-6-27","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"Programming","title":"Programming"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29306821.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"400","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29306821.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29306821.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29306821.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26675913\/","id":"26675913","publisher":"Addison-Wesley Professional","isbn10":"0134024141","isbn13":"9780134024141","title":"Data Science with Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26675913","alt_title":"","author_intro":"","summary":"","price":"USD 44.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Ted Dunning","Ellen Friedman"],"pubdate":"2015-4-12","tags":[{"count":1,"name":"MapR","title":"MapR"},{"count":1,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"HDFS","title":"HDFS"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28237468.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"104","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28237468.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28237468.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28237468.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26553689\/","id":"26553689","publisher":"O'Reilly Media","isbn10":"1491922664","isbn13":"9781491922668","title":"Real-World Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26553689","alt_title":"","author_intro":"","summary":"","price":"USD 24.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Benoy Antony","Konstantin Boudnik","Cheryl Adams"],"pubdate":"2016-5-23","tags":[{"count":2,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"yy","title":"yy"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29133431.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"216","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29133431.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29133431.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29133431.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26907953\/","id":"26907953","publisher":"Wrox","isbn10":"111926717X","isbn13":"9781119267171","title":"Professional Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26907953","alt_title":"","author_intro":"From the Back Cover\nLeverage Hadoop functionality to build better big data solutions Open-source and Java-based, with almost no barrier to entry, Hadoop offers a practical big data solution that's quickly gaining market usage. Written by an expert team of certified Hadoop developers, committers, and Summit speakers, this book functions as a self-led training course on the framework's processes and capabilities. Each component is covered individually, culminating in a hands-on project that brings everything together to build a sample application. Skipping over the basics of database development, this book gets right to the point to help experienced developers get up to speed quickly and start employing Hadoop in real-world scenarios. Professional Hadoop:  Shows you how to configure storage, user experience, and in-memory computing using the Hadoop Stack Explains how to use Kafka real-time messaging and Storm data streaming to integrate Hadoop with other systems Demonstrates critical security features and techniques, with expert advice on keeping your data safe Teaches you the fundamentals of Apache Big Top packaging, testing and configuration, along with faster Map Reduce using Ignite Walks you through a sample application build to show how key components work together, with all sample code provided  Wrox Professional guides are planned and written by working programmers to meet the real-world needs of programmers, developers, and IT professionals. Focused and relevant, they address the issues technology professionals face every day. They provide examples, practical solutions, and expert education in new technologies, all designed to help programmers do a better job.\nRead more\nAbout the Author\nAbout the authors Benoy Antony is an Apache Hadoop Committer and Hadoop Architect at eBay. Konstantin Boudnik is co-founder and CEO of Memcore.io, and is one of the early developers of Hadoop and a co-author of Apache Bigtop. Cheryl Adams is a Senior Cloud Data & Infrastructure Architect in the healthcare data realm. Branky Shao is a software engineer at eBay, and a contributor to the Cascading project. Cazen Lee is a Software Architect at Samsung SDS. Kai Sasaki is a Software Engineer at Treasure Data Inc. Visit us at wrox.com where you have access to free code samples, Programmer to Programmer forums, and discussions on the latest happenings in the industry from around the world.\nRead more","summary":"The professional's one-stop guide to this open-source, Java-based big data framework\nProfessional Hadoop is the complete reference and resource for experienced developers looking to employ Apache Hadoop in real-world settings. Written by an expert team of certified Hadoop developers, committers, and Summit speakers, this book details every key aspect of Hadoop technology to enable optimal processing of large data sets. Designed expressly for the professional developer, this book skips over the basics of database development to get you acquainted with the framework's processes and capabilities right away. The discussion covers each key Hadoop component individually, culminating in a sample application that brings all of the pieces together to illustrate the cooperation and interplay that make Hadoop a major big data solution. Coverage includes everything from storage and security to computing and user experience, with expert guidance on integrating other software and more.\nHadoop is quickly reaching significant market usage, and more and more developers are being called upon to develop big data solutions using the Hadoop framework. This book covers the process from beginning to end, providing a crash course for professionals needing to learn and apply Hadoop quickly.\nConfigure storage, UE, and in-memory computing Integrate Hadoop with other programs including Kafka and Storm Master the fundamentals of Apache Big Top and Ignite Build robust data security with expert tips and advice\nHadoop's popularity is largely due to its accessibility. Open-source and written in Java, the framework offers almost no barrier to entry for experienced database developers already familiar with the skills and requirements real-world programming entails. Professional Hadoop gives you the practical information and framework-specific skills you need quickly.","price":"USD 34.64"},{"rating":{"max":10,"numRaters":18,"average":"7.6","min":0},"subtitle":"","author":["林大贵"],"pubdate":"","tags":[{"count":20,"name":"大数据","title":"大数据"},{"count":16,"name":"hadoop","title":"hadoop"},{"count":16,"name":"Python","title":"Python"},{"count":12,"name":"spark","title":"spark"},{"count":5,"name":"AI","title":"AI"},{"count":4,"name":"计算机","title":"计算机"},{"count":2,"name":"图书馆","title":"图书馆"},{"count":1,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29759914.jpg","binding":"","translator":[],"catalog":"目   录\n\n\n第1章  Python Spark机器学习与Hadoop大数据     1\n1.1  机器学习的介绍   2\n1.2 Spark的介绍 5\n1.3 Spark数据处理 RDD、DataFrame、Spark SQL  7\n1.4  使用Python开发 Spark机器学习与大数据应用       8\n1.5 Python Spark 机器学习         9\n1.6 Spark ML Pipeline机器学习流程介绍  10\n1.7 Spark 2.0的介绍    12\n1.8  大数据定义   13\n1.9 Hadoop 简介          14\n1.10 Hadoop HDFS分布式文件系统  14\n1.11 Hadoop MapReduce的介绍        17\n1.12 结论      18\n第2章  VirtualBox虚拟机软件的安装        19\n2.1 VirtualBox的下载和安装      20\n2.2  设置VirtualBox存储文件夹          23\n2.3  在VirtualBox创建虚拟机     25\n2.4  结论        29\n第3章  Ubuntu Linux 操作系统的安装      30\n3.1 Ubuntu Linux 操作系统的安装    31\n3.2  在Virtual设置Ubuntu虚拟光盘文件 33\n3.3  开始安装Ubuntu  35\n3.4  启动Ubuntu  40\n3.5  安装增强功能        41\n3.6  设置默认输入法   45\n3.7  设置“终端”程序        48\n3.8  设置“终端”程序为白底黑字   49\n3.9  设置共享剪贴板   50\n3.10 设置最佳下载服务器 52\n3.11 结论      56\n第4章  Hadoop Single Node Cluster的安装        57\n4.1  安装JDK         58\n4.2  设置SSH无密码登录    61\n4.3  下载安装Hadoop  64\n4.4  设置Hadoop环境变量 67\n4.5  修改Hadoop配置设置文件 69\n4.6  创建并格式化HDFS目录     73\n4.7  启动Hadoop  74\n4.8  打开HadoopResource-Manager Web界面 76\n4.9 NameNode HDFS Web界面   78\n4.10 结论      79\n第5章  Hadoop Multi Node Cluster的安装         80\n5.1  把Single NodeCluster复制到data1    83\n5.2  设置VirtualBox网卡     84\n5.3  设置data1服务器         87\n5.4  复制data1服务器到data2、data3、master     94\n5.5  设置data2服务器         97\n5.6  设置data3服务器         100\n5.7  设置master服务器      102\n5.8 master连接到data1、data2、data3 创建HDFS目录      107\n5.9  创建并格式化NameNodeHDFS目录  110\n5.10 启动Hadoop Multi Node Cluster         112\n5.11 打开Hadoop ResourceManager Web界面         114\n5.12 打开NameNode Web界面 115\n5.13 停止Hadoop Multi Node Cluster         116\n5.14 结论      116\n第 6 章  Hadoop HDFS命令        117\n6.1  启动HadoopMulti-Node Cluster  118\n6.2  创建与查看HDFS目录 120\n6.3  从本地计算机复制文件到HDFS  122\n6.4  将HDFS上的文件复制到本地计算机 127\n6.5  复制与删除HDFS文件 129\n6.6  在Hadoop HDFSWeb用户界面浏览HDFS  131\n6.7  结论        134\n第7章  Hadoop MapReduce         135\n7.1  简单介绍WordCount.java     136\n7.2  编辑WordCount.java     137\n7.3  编译WordCount.java     141\n7.4  创建测试文本文件        143\n7.5  运行WordCount.java     145\n7.6  查看运行结果        146\n7.7  结论        147\n第8章  Python Spark的介绍与安装   148\n8.1 Scala的介绍与安装       150\n8.2  安装Spark      153\n8.3  启动pyspark交互式界面     156\n8.4  设置pyspark显示信息 157\n8.5  创建测试用的文本文件        159\n8.6  本地运行pyspark程序 161\n8.7  在Hadoop YARN运行pyspark      163\n8.8  构建SparkStandalone Cluster运行环境      165\n8.9  在SparkStandalone运行pyspark         171\n8.10 Spark Web UI界面        173\n8.11 结论      175\n第9章  在 IPythonNotebook 运行 Python Spark 程序   176\n9.1  安装Anaconda       177\n9.2  在IPythonNotebook使用Spark   180\n9.3  打开IPythonNotebook笔记本     184\n9.4  插入程序单元格   185\n9.5  加入注释与设置程序代码说明标题   186\n9.6  关闭IPythonNotebook 188\n9.7  使用IPythonNotebook在Hadoop YARN-client模式运行   189\n9.8  使用IPythonNotebook在Spark Stand Alone模式运行       192\n9.9  整理在不同的模式运行IPythonNotebook的命令     194\n9.9.1 在 Local 启动 IPython Notebook     195\n9.9.2 在Hadoop YARN-client 模式启动 IPython Notebook       195\n9.9.3 在Spark Stand Alone 模式启动 IPython Notebook 195\n9.10 结论      196\n第10章  Python Spark RDD 197\n10.1 RDD的特性 198\n10.2 开启IPython Notebook        199\n10.3 基本RDD“转换”运算     201\n10.4 多个RDD“转换”运算     206\n10.5 基本“动作”运算      208\n10.6 RDD Key-Value 基本“转换”运算   209\n10.7 多个RDD Key-Value“转换”运算     212\n10.8 Key-Value“动作”运算      215\n10.9 Broadcast 广播变量   217\n10.10 accumulator累加器  220\n10.11 RDD Persistence持久化   221\n10.12 使用Spark创建WordCount      223\n10.13 Spark WordCount详细解说       226\n10.14 结论   228\n第11章  Python Spark的集成开发环境     229\n11.1 下载与安装eclipse Scala IDE      232\n11.2 安装PyDev  235\n11.3 设置字符串替代变量 240\n11.4 PyDev 设置 Python 链接库       243\n11.5 PyDev设置anaconda2链接库路径   245\n11.6 PyDev设置Spark Python链接库         247\n11.7 PyDev设置环境变量  248\n11.8 新建PyDev项目 251\n11.9 加入WordCount.py程序     253\n11.10 输入WordCount.py程序  254\n11.11 创建测试文件并上传至HDFS目录 257\n11.12 使用spark-submit执行WordCount程序         259\n11.13 在Hadoop YARN-client上运行WordCount程序      261\n11.14 在Spark Standalone Cluster上运行WordCount程序      264\n11.15 在eclipse外部工具运行Python Spark程序    267\n11.16 在eclipse运行spark-submit YARN-client          273\n11.17 在eclipse运行spark-submit Standalone 277\n11.18 结论   280\n第12章  Python Spark创建推荐引擎 281\n12.1 推荐算法介绍      282\n12.2 “推荐引擎”大数据分析使用场景 282\n12.3 ALS推荐算法的介绍   283\n12.4 如何搜索数据      285\n12.5 启动IPython Notebook        289\n12.6 如何准备数据      290\n12.7 如何训练模型      294\n12.8 如何使用模型进行推荐      295\n12.9 显示推荐的电影名称 297\n12.10 创建Recommend项目      299\n12.11 运行RecommendTrain.py 推荐程序代码        302\n12.12 创建Recommend.py推荐程序代码         304\n12.13 在eclipse运行Recommend.py         307\n12.14 结论   310\n第13章  Python Spark MLlib决策树二元分类   311\n13.1 决策树介绍 312\n13.2 “StumbleUpon Evergreen”大数据问题  313\n13.2.1 Kaggle网站介绍       313\n13.2.2 “StumbleUpon Evergreen”大数据问题场景分析        313\n13.3 决策树二元分类机器学习 314\n13.4 如何搜集数据      315\n13.4.1 StumbleUpon数据内容    315\n13.4.2 下载 StumbleUpon 数据         316\n13.4.3 用LibreOffice Calc 电子表格查看train.tsv    319\n13.4.4 复制到项目目录       322\n13.5  使用IPython Notebook示范       323\n13.6 如何进行数据准备      324\n13.6.1 导入并转换数据       324\n13.6.2 提取 feature 特征字段  327\n13.6.3 提取分类特征字段  328\n13.6.4 提取数值特征字段  331\n13.6.5 返回特征字段  331\n13.6.6 提取 label 标签字段       331\n13.6.7 建立训练评估所需的数据       332\n13.6.8 以随机方式将数据分为 3 部分并返回         333\n13.6.9 编写 PrepareData(sc) 函数    333\n13.7 如何训练模型      334\n13.8 如何使用模型进行预测      335\n13.9 如何评估模型的准确率      338\n13.9.1 使用 AUC 评估二元分类模型        338\n13.9.2 计算 AUC 339\n13.10 模型的训练参数如何影响准确率   341\n13.10.1 建立 trainEvaluateModel       341\n13.10.2 评估impurity参数 343\n13.10.3 训练评估的结果以图表显示         344\n13.10.4 编写 evalParameter       347\n13.10.5 使用 evalParameter 评估 maxDepth 参数        347\n13.10.6 使用 evalParameter 评估 maxBins 参数  348\n13.11 如何找出准确率最高的参数组合   349\n13.12 如何确认是否过度训练   352\n13.13 编写RunDecisionTreeBinary.py程序        352\n13.14 开始输入RunDecisionTreeBinary.py程序        353\n13.15 运行RunDecisionTreeBinary.py         355\n13.15.1 执行参数评估         355\n13.15.2 所有参数训练评估找出最好的参数组合    355\n13.15.3 运行 RunDecisionTreeBinary.py 不要输入参数  357\n13.16 查看DecisionTree的分类规则          358\n13.17 结论   360\n第14章  Python Spark MLlib 逻辑回归二元分类       361\n14.1 逻辑回归分析介绍      362\n14.2 RunLogisticRegression WithSGDBinary.py程序说明 363\n14.3 运行RunLogisticRegression WithSGDBinary.py进行参数评估          367\n14.4 找出最佳参数组合      370\n14.5 修改程序使用参数进行预测      370\n14.6 结论      372\n第15章  Python Spark MLlib支持向量机SVM二元分类  373\n15.1 支持向量机SVM算法的基本概念    374\n15.2 运行SVMWithSGD.py进行参数评估          376\n15.3 运行SVMWithSGD.py 训练评估参数并找出最佳参数组合    378\n15.4 运行SVMWithSGD.py 使用最佳参数进行预测        379\n15.5 结论      381\n第16章  Python Spark MLlib朴素贝叶斯二元分类   382\n16.1 朴素贝叶斯分析原理的介绍      383\n16.2 RunNaiveBayesBinary.py程序说明     384\n16.3 运行NaiveBayes.py进行参数评估    386\n16.4 运行训练评估并找出最好的参数组合      387\n16.5 修改RunNaiveBayesBinary.py 直接使用最佳参数进行预测  388\n16.6 结论      390\n第17章  Python Spark MLlib决策树多元分类   391\n17.1 “森林覆盖植被”大数据问题分析场景 392\n17.2 UCI Covertype数据集介绍 393\n17.3 下载与查看数据 394\n17.4 修改PrepareData() 数据准备   396\n17.5 修改trainModel 训练模型程序         398\n17.6 使用训练完成的模型预测数据 399\n17.7 运行RunDecisionTreeMulti.py 进行参数评估  401\n17.8 运行RunDecisionTreeMulti.py 训练评估参数并找出最好的参数组合  403\n17.9 运行RunDecisionTreeMulti.py 不进行训练评估      404\n17.10 结论   406\n第18章  Python Spark MLlib决策树回归分析   407\n18.1 Bike Sharing大数据问题分析     408\n18.2 Bike Sharing数据集     409\n18.3 下载与查看数据 409\n18.4 修改 PrepareData() 数据准备  412\n18.5 修改DecisionTree.trainRegressor训练模型      415\n18.6 以 RMSE 评估模型准确率         416\n18.7 训练评估找出最好的参数组合 417\n18.8 使用训练完成的模型预测数据 417\n18.9 运行RunDecisionTreeMulti.py进行参数评估   419\n18.10 运行RunDecisionTreeMulti.py训练评估参数并找出最好的参数组合 421\n18.11 运行RunDecisionTreeMulti.py 不进行训练评估    422\n18.12 结论   424\n第19章  Python Spark SQL、DataFrame、RDD数据统计与可视化         425\n19.1 RDD、DataFrame、Spark SQL 比较  426\n19.2 创建RDD、DataFrame与Spark SQL 427\n19.2.1 在 local 模式运行 IPython Notebook    427\n19.2.2 创建RDD  427\n19.2.3 创建DataFrame        428\n19.2.4 设置 IPython Notebook 字体 430\n19.2.5 为DataFrame 创建别名 431\n19.2.6 开始使用 Spark SQL         431\n19.3 SELECT显示部分字段          434\n19.3.1 使用 RDD 选取显示部分字段       434\n19.3.2 使用 DataFrames 选取显示字段  434\n19.3.3 使用 Spark SQL 选取显示字段       435\n19.4 增加计算字段      436\n19.4.1 使用 RDD 增加计算字段       436\n19.4.2 使用 DataFrames 增加计算字段  436\n19.4.3 使用 Spark SQL 增加计算字段       437\n19.5 筛选数据      438\n19.5.1 使用 RDD 筛选数据       438\n19.5.2 使用 DataFrames 筛选数据  438\n19.5.3 使用 Spark SQL 筛选数据       439\n19.6 按单个字段给数据排序      439\n19.6.1 RDD 按单个字段给数据排序          439\n19.6.2 使用 Spark SQL排序        440\n19.6.3 使用 DataFrames按升序给数据排序   441\n19.6.4 使用 DataFrames按降序给数据排序   442\n19.7 按多个字段给数据排序      442\n19.7.1 RDD 按多个字段给数据排序          442\n19.7.2 Spark SQL 按多个字段给数据排序         443\n19.7.3 DataFrames 按多个字段给数据排序    443\n19.8 显示不重复的数据      444\n19.8.1 RDD 显示不重复的数据          444\n19.8.2 Spark SQL 显示不重复的数据         445\n19.8.3 Dataframes显示不重复的数据      445\n19.9 分组统计数据      446\n19.9.1 RDD 分组统计数据          446\n19.9.2 Spark SQL分组统计数据 447\n19.9.3 Dataframes分组统计数据      448\n19.10 Join 联接数据   450\n19.10.1 创建 ZipCode 450\n19.10.2 创建 zipcode_tab  452\n19.10.3 Spark SQL 联接 zipcode_table 数据表         454\n19.10.4 DataFrame user_df 联接 zipcode_df   455\n19.11 使用 Pandas DataFrames 绘图       457\n19.11.1 按照不同的州统计并以直方图显示    457\n19.11.2 按照不同的职业统计人数并以圆饼图显示         459\n19.12 结论   461\n第20章  Spark ML Pipeline 机器学习流程二元分类         462\n20.1 数据准备      464\n20.1.1 在 local 模式执行 IPython Notebook    464\n20.1.2 编写 DataFrames UDF 用户自定义函数       466\n20.1.3 将数据分成 train_df 与 test_df    468\n20.2 机器学习pipeline流程的组件   468\n20.2.1 StringIndexer     468\n20.2.2 OneHotEncoder         470\n20.2.3 VectorAssembler       472\n20.2.4 使用 DecisionTreeClassi?er 二元分类  474\n20.3 建立机器学习pipeline流程        475\n20.4 使用pipeline进行数据处理与训练   476\n20.5 使用pipelineModel 进行预测    477\n20.6 评估模型的准确率      478\n20.7 使用TrainValidation进行训练验证找出最佳模型    479\n20.8 使用crossValidation交叉验证找出最佳模型   481\n20.9 使用随机森林 RandomForestClassi?er分类器         483\n20.10 结论   485\n第21章  Spark ML Pipeline 机器学习流程多元分类         486\n21.1 数据准备      487\n21.1.1 读取文本文件  488\n21.1.2  创建 DataFrame      489\n21.1.3 转换为 double 490\n21.2 建立机器学习pipeline流程        492\n21.3 使用dt_pipeline进行数据处理与训练      493\n21.4 使用pipelineModel 进行预测    493\n21.5 评估模型的准确率      495\n21.4 使用TrainValidation进行训练验证找出最佳模型    496\n21.7 结论      498\n第22章  Spark ML Pipeline 机器学习流程回归分析         499\n22.1 数据准备      501\n22.1.1 在local 模式执行 IPython Notebook     501\n22.1.2 将数据分成 train_df 与 test_df    504\n22.2 建立机器学习pipeline流程        504\n22.3 使用dt_pipeline进行数据处理与训练      506\n22.4 使用pipelineModel 进行预测    506\n22.5 评估模型的准确率      507\n22.6 使用TrainValidation进行训练验证找出最佳模型    508\n22.7 使用crossValidation进行交叉验证找出最佳模型   510\n22.8 使用GBT Regression   511\n22.9 结论      513\n附录A  本书范例程序下载与安装说明      514\nA.1  下载范例程序        515\nA.2  打开本书IPythonNotebook范例程序         516\nA.3  打开 eclipsePythonProject 范例程序         518","pages":"519","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29759914.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29759914.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29759914.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30203128\/","id":"30203128","publisher":"清华大学出版社","isbn10":"7302490732","isbn13":"9787302490739","title":"Python+Spark 2.0+Hadoop机器学习与大数据实战","url":"https:\/\/api.douban.com\/v2\/book\/30203128","alt_title":"","author_intro":"林大贵，从事IT行业多年，在系统设计、网站开发、数字营销、商业智慧、大数据、机器学习等领域具有丰富的实战经验。","summary":"本书从浅显易懂的“大数据和机器学习”原理说明入手，讲述大数据和机器学习的基本概念，如分类、分析、训练、建模、预测、机器学习（推荐引擎）、机器学习（二元分类）、机器学习（多元分类）、机器学习（回归分析）和数据可视化应用等。书中不仅加入了新近的大数据技术，还丰富了“机器学习”内容。 为降低读者学习大数据技术的门槛，书中提供了丰富的上机实践操作和范例程序详解，展示了如何在单机Windows系统上通过Virtual Box虚拟机安装多机Linux虚拟机，如何建立Hadoop集群，再建立Spark开发环境。书中介绍搭建的上机实践平台并不限制于单台实体计算机。对于有条件的公司和学校，参照书中介绍的搭建过程，同样可以实现将自己的平台搭建在多台实体计算机上，以便更加接近于大数据和机器学习真实的运行环境。 本书非常适合于学习大数据基础知识的初学者阅读，更适合正在学习大数据理论和技术的人员作为上机实践用的教材。","price":"99"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"","author":["（印）　Vignesh Prajapati"],"pubdate":"2014-11-1","tags":[{"count":12,"name":"R","title":"R"},{"count":10,"name":"大数据","title":"大数据"},{"count":4,"name":"互联网","title":"互联网"},{"count":2,"name":"统计","title":"统计"},{"count":2,"name":"数据可视化","title":"数据可视化"},{"count":2,"name":"工具书","title":"工具书"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"计算机","title":"计算机"}],"origin_title":"Big Data Analytics with R and Hadoop","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27869028.jpg","binding":"平装","translator":["李明","王威扬","孙思栋"],"catalog":"目　　录\n译者序\n前言\n审校者简介\n致谢\n第1章　R和Hadoop入门\t1\n1.1　安装R\t2\n1.2　安装RStudio\t3\n1.3　R语言的功能特征\t3\n1.3.1　使用R程序包\t3\n1.3.2　执行数据操作\t3\n1.3.3　日渐增多的社区支持\t4\n1.3.4　R语言数据建模\t4\n1.4　Hadoop的安装\t5\n1.4.1　不同的Hadoop模式\t6\n1.4.2　Hadoop的安装步骤\t6\n1.5　Hadoop的特点\t12\n1.5.1　HDFS简介\t13\n1.5.2　MapReduce简介\t13\n1.6　HDFS和MapReduce架构\t14\n1.6.1　HDFS架构\t14\n1.6.2　MapReduce架构\t15\n1.6.3　通过图示了解HDFS和MapReduce架构\t15\n1.7　Hadoop的子项目\t16\n1.8　小结\t19\n第2章　编写Hadoop MapReduce程序\t20\n2.1　MapReduce基础概念\t20\n2.2　Hadoop MapReduce技术简介\t22\n2.2.1　MapReduce中包含的实体\t22\n2.2.2　MapReduce中的主要执行进程\t23\n2.2.3　MapReduce的局限\t25\n2.2.4　MapReduce 可以解决的问题\t26\n2.2.5　使用Hadoop编程时用到不同的Java概念\t26\n2.3　Hadoop MapReduce原理\t27\n2.3.1　MapReduce对象\t27\n2.3.2　MapReduce中实现Map阶段的执行单元数目\t28\n2.3.3　MapReduce中实现Reduce阶段的执行单元数目\t28\n2.3.4　MapReduce的数据流\t28\n2.3.5　深入理解HadoopMapReduce\t30\n2.4　编写Hadoop MapReduce示例程序\t32\n2.4.1　MapReduce job运行的步骤\t33\n2.4.2　MapReduce可解决的商业问题\t38\n2.5　在R环境中编写Hadoop MapReduce程序的方式\t39\n2.5.1　RHadoop\t39\n2.5.2　RHIPE\t40\n2.5.3　Hadoop streaming\t40\n2.6　小结\t40\n第3章　集成R和Hadoop\t41\n3.1　RHIPE\t42\n3.1.1　安装RHIPE\t42\n3.1.2　RHIPE架构\t44\n3.1.3　RHIPE实例\t45\n3.1.4　RHIPE参考函数\t48\n3.2　RHadoop\t51\n3.2.1　RHadoop架构\t51\n3.2.2　安装RHadoop\t52\n3.2.3　RHadoop案例\t53\n3.2.4　RHadoop参考函数\t56\n3.3　小结\t58\n第4章　Hadoop Streaming中使用R\t59\n4.1　Hadoop Streaming基础概念\t59\n4.2　使用R运行Hadoop streaming\t62\n4.2.1　MapReduce应用程序基础\t63\n4.2.2　如何编写MapReduce应用程序\t65\n4.2.3　如何运行MapReduce应用程序\t67\n4.2.4　如何浏览MapRecuce应用程序的输出\t69\n4.2.5　Hadoop MapReduce脚本的基础R函数\t70\n4.2.6　管理Hadoop MapReduce任务\t71\n4.3　R语言扩展包HadoopStreaming介绍\t72\n4.3.1　hsTableReader函数\t73\n4.3.2　hsKeyValReader函数\t75\n4.3.3　hasLineReader函数\t75\n4.3.4　运行Hadoop streaming任务\t78\n4.3.5　执行Hadoop Streaming任务\t79\n4.4　小结\t79\n第5章　利用R和Hadoop学习数据分析\t80\n5.1　数据分析项目生命周期\t80\n5.1.1　问题定义\t81\n5.1.2　设计数据需求\t81\n5.1.3　数据预处理\t81\n5.1.4　数据分析\t82\n5.1.5　数据可视化\t82\n5.2　数据分析问题\t83\n5.2.1　展示网页分类 \t83\n5.2.2　计算股市变动频率\t92\n5.2.3　案例研究：预测推土机售价\t98\n5.3　小结\t107\n第6章　应用机器学习做大数据分析\t108\n6.1　机器学习介绍\t108\n6.2　有监督机器学习算法\t109\n6.2.1　线性回归\t109\n6.2.2　logistic回归\t115\n6.3　无监督机器学习算法\t118\n6.4　推荐算法\t123\n6.4.1　在R中产生推荐商品的步骤\t125\n6.4.2　使用R和Hadoop产生推荐商品\t128\n6.5　小结\t131\n第7章　从各种数据库中导入与导出数据\t132\n7.1　文件型数据库\t134\n7.1.1　不同类型的文件\t134\n7.1.2　安装R包\t134\n7.1.3　将数据导入R\t134\n7.1.4　从R导出数据\t135\n7.2　MySQL\t135\n7.2.1　安装MySQL\t135\n7.2.2　安装RMySQL\t136\n7.2.3　列出数据表及其结构\t136\n7.2.4　导入数据进R\t136\n7.2.5　数据操纵\t137\n7.3　Excel\t137\n7.3.1　安装Excel\t138\n7.3.2　导入数据进R\t138\n7.3.3　R和Excel的数据操纵\t138\n7.3.4　导出数据到Excel\t138\n7.4　MongoDB\t138\n7.4.1　安装MongoDB\t139\n7.4.2　安装rmongodb\t141\n7.4.3　导入数据进R\t141\n7.4.4　数据操纵\t142\n7.5　SQLite\t143\n7.5.1　SQLite的特性\t143\n7.5.2　安装SQLite\t144\n7.5.3　安装RSQLite\t144\n7.5.4　将数据导师入R\t144\n7.5.5　数据操纵\t145\n7.6　PostgreSQL\t145\n7.6.1　PostgreSQL的特性\t145\n7.6.2　安装PostgreSQL\t145\n7.6.3　安装RPostgreSQL\t146\n7.6.4　从R导出数据\t146\n7.7　Hive\t147\n7.7.1　Hive的特性\t147\n7.7.2　安装Hive\t147\n7.7.3　安装RHive\t149\n7.7.4　RHive操作\t149\n7.8　HBase\t150\n7.8.1　HBase的特性\t150\n7.8.2　安装HBase\t151\n7.8.3　安装Thrift\t152\n7.8.4　安装RHBase\t153\n7.8.5　导入数据进R\t153\n7.8.6　数据操纵\t153\n7.9　小结\t154\n附录　参考资源\t155","ebook_url":"https:\/\/read.douban.com\/ebook\/29569514\/","pages":"180","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27869028.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27869028.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27869028.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26268908\/","id":"26268908","publisher":"机械工业出版社","isbn10":"7111483529","isbn13":"9787111483526","title":"R与Hadoop大数据分析实战","url":"https:\/\/api.douban.com\/v2\/book\/26268908","alt_title":"Big Data Analytics with R and Hadoop","author_intro":"Vignesh Prajapati 资深大数据分析师，现为Pingax公司顾问、Enjay公司软件工程师，精通R、Hadoop、Mahout、Pig、Hive等技术，在机器学习和大数据技术方面拥有丰富经验。目前他专注于利用大数据和云技术为客户提供有价值产品。\n译者简介\n李明\n毕业于沈阳理工大学信息工程学院电子科技与技术系，曾就职于凡客诚品、居然之家等大型电子商务公司，目前就职于优酷土豆网。他的研究兴趣是用R语言进行互联网数据分析\/挖掘，撰写过大量有关R语言基础和高级应用的文章，对互联网数据统计系统的R语言实践有较深研究，撰写了《R语言与网站分析》一书。他的个人博客为www.bassary.com。\n王威扬\n2008年毕业于清华大学航天航空学院，同年获得清华大学经济学双学位，2010年获得芝加哥大学统计学硕士学位。毕业后曾先后任职于芝加哥大学计算机系、文思海辉技术有限公司、京东世纪贸易集团有限公司及互联网初创企业，在科研、证券、银行、电商、O2O行业负责数据仓库建设及数据分析、挖掘工作，同时对高性能计算与开源分布式技术架构有浓厚兴趣。\n孙思栋\n中南财经政法大学经济学、信息与计算科学双学士，现为清华大学中国应急管理研究基地助理研究员，参与了国家清史编撰委员会文献等3个省部级科研项目，对非结构化大数据处理有深入理解。","summary":"本书全面而系统地讲解了如何将R语言与Hadoop技术结合并应用于大数据分析，不仅系统且深入地阐释了R与Hadoop集成技术的工具、方法、原则和最佳实践，而且通过大量实践案例深入剖析各种常见问题，能为用户高效利用R语言与Hadoop技术进行大数据处理提供翔实指导。\n全书分为四部分，共7章：第一部分（第1~2章）是基础知识，主要讲解R语言以及Hadoop的安装过程、计算原理和基本概念；第二部分（第3~4章）是初级应用，主要讲解RHIPE、RHadoop和streaming三种实现方案；第三部分（第5~6章）是高级实例，主要以RHadoop为技术背景，讲解多个实际应用案例；第四部分（第7章）介绍数据库连接，主要讲解在RHadoop下如何与各类数据库进行连接。","ebook_price":"20.00","series":{"id":"19432","title":"大数据技术丛书"},"price":"49.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["邓杰"],"pubdate":"2018-6","tags":[{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"前言\n第1章 集群及开发环境搭建\t1\n1.1 环境准备\t1\n1.1.1 基础软件下载\t1\n1.1.2 准备Linux操作系统\t2\n1.2 安装Hadoop\t4\n1.2.1 基础环境配置\t4\n1.2.2 Zookeeper部署\t7\n1.2.3 Hadoop部署\t9\n1.2.4 效果验证\t21\n1.2.5 集群架构详解\t24\n1.3 Hadoop版Hello World\t25\n1.3.1 Hadoop Shell介绍\t25\n1.3.2 WordCount初体验\t27\n1.4 开发环境\t28\n1.4.1 搭建本地开发环境\t28\n1.4.2 运行及调试预览\t31\n1.5 小结\t34\n第2章 实战：快速构建一个Hadoop项目并线上运行\t35\n2.1 构建一个简单的项目工程\t35\n2.1.1 构建Java Project结构工程\t35\n2.1.2 构建Maven结构工程\t36\n2.2 操作分布式文件系统（HDFS）\t39\n2.2.1 基本的应用接口操作\t39\n2.2.2 在高可用平台上的使用方法\t42\n2.3 利用IDE提交MapReduce作业\t43\n2.3.1 在单点上的操作\t43\n2.3.2 在高可用平台上的操作\t46\n2.4 编译应用程序并打包\t51\n2.4.1 编译Java Project工程并打包\t51\n2.4.2 编译Maven工程并打包\t55\n2.5 部署与调度\t58\n2.5.1 部署应用\t58\n2.5.2 调度任务\t59\n2.6 小结\t60\n第3章 Hadoop套件实战\t61\n3.1 Sqoop——数据传输工具\t61\n3.1.1 背景概述\t61\n3.1.2 安装及基本使用\t62\n3.1.3 实战：在关系型数据库与分布式文件系统之间传输数据\t64\n3.2 Flume——日志收集工具\t66\n3.2.1 背景概述\t67\n3.2.2 安装与基本使用\t67\n3.2.3 实战：收集系统日志并上传到分布式文件系统（HDFS）上\t72\n3.3 HBase——分布式数据库\t74\n3.3.1 背景概述\t74\n3.3.2 存储架构介绍\t75\n3.3.3 安装与基本使用\t75\n3.3.4 实战：对HBase业务表进行增、删、改、查操作\t79\n3.4 Zeppelin——数据集分析工具\t85\n3.4.1 背景概述\t85\n3.4.2 安装与基本使用\t85\n3.4.3 实战：使用解释器操作不同的数据处理引擎\t88\n3.5 Drill——低延时SQL查询引擎\t92\n3.5.1 背景概述\t93\n3.5.2 安装与基本使用\t93\n3.5.3 实战：对分布式文件系统（HDFS）使用SQL进行查询\t95\n3.5.4 实战：使用SQL查询HBase数据库\t99\n3.5.5 实战：对数据仓库（Hive）使用类实时统计、查询操作\t101\n3.6 Spark——实时流数据计算\t104\n3.6.1 背景概述\t104\n3.6.2 安装部署及使用\t105\n3.6.3 实战：对接Kafka消息数据，消费、计算及落地\t108\n3.7 小结\t114\n第4章 Hive编程——使用SQL提交MapReduce任务到Hadoop集群\t115\n4.1 环境准备与Hive初识\t115\n4.1.1 背景介绍\t115\n4.1.2 基础环境准备\t116\n4.1.3 Hive结构初识\t116\n4.1.4 Hive与关系型数据库（RDBMS）\t118\n4.2 安装与配置Hive\t118\n4.2.1 Hive集群基础架构\t119\n4.2.2 利用HAProxy实现Hive Server负载均衡\t120\n4.2.3 安装分布式Hive集群\t123\n4.3 可编程方式\t126\n4.3.1 数据类型\t126\n4.3.2 存储格式\t128\n4.3.3 基础命令\t129\n4.3.4 Java编程语言操作数据仓库（Hive）\t131\n4.3.5 实践Hive Streaming\t134\n4.4 运维和监控\t138\n4.4.1 基础命令\t138\n4.4.2 监控工具Hive Cube\t140\n4.5 小结\t143\n第5章 游戏玩家的用户行为分析——特征提取\t144\n5.1 项目应用概述\t144\n5.1.1 场景介绍\t144\n5.1.2 平台架构与数据采集\t145\n5.1.3 准备系统环境和软件\t147\n5.2 分析与设计\t148\n5.2.1 整体分析\t148\n5.2.2 指标与数据源分析\t149\n5.2.3 整体设计\t151\n5.3 技术选型\t153\n5.3.1 套件选取简述\t154\n5.3.2 套件使用简述\t154\n5.4 编码实践\t157\n5.4.1 实现代码\t157\n5.4.2 统计结果处理\t163\n5.4.3 应用调度\t169\n5.5 小结\t174\n第6章 Hadoop平台管理与维护\t175\n6.1 Hadoop分布式文件系统（HDFS）\t175\n6.1.1 HDFS特性\t175\n6.1.2 基础命令详解\t176\n6.1.3 解读NameNode Standby\t179\n6.2 Hadoop平台监控\t182\n6.2.1 Hadoop日志\t183\n6.2.2 常用分布式监控工具\t187\n6.3 平台维护\t196\n6.3.1 安全模式\t196\n6.3.2 节点管理\t198\n6.3.3 HDFS快照\t200\n6.4 小结\t203\n第7章 Hadoop异常处理解决方案\t204\n7.1 定位异常\t204\n7.1.1 跟踪日志\t204\n7.1.2 分析异常信息\t208\n7.1.3 阅读开发业务代码\t209\n7.2 解决问题的方式\t210\n7.2.1 搜索关键字\t211\n7.2.2 查看Hadoop JIRA\t212\n7.2.3 阅读相关源码\t213\n7.3 实战案例分析\t216\n7.3.1 案例分析1：启动HBase失败\t216\n7.3.2 案例分析2：HBase表查询失败\t219\n7.3.3 案例分析3：Spark的临时数据不自动清理\t222\n7.4 小结\t223\n第8章 初识Hadoop核心源码\t224\n8.1 基础准备与源码编译\t224\n8.1.1 准备环境\t224\n8.1.2 加载源码\t228\n8.1.3 编译源码\t230\n8.2 初识Hadoop 2\t233\n8.2.1 Hadoop的起源\t233\n8.2.2 Hadoop 2源码结构图\t234\n8.2.3 Hadoop模块包\t235\n8.3 MapReduce框架剖析\t236\n8.3.1 第一代MapReduce框架\t236\n8.3.2 第二代MapReduce框架\t238\n8.3.3 两代MapReduce框架的区别\t239\n8.3.4 第二代MapReduce框架的重构思路\t240\n8.4 序列化\t241\n8.4.1 序列化的由来\t242\n8.4.2 Hadoop序列化\t243\n8.4.3 Writable实现类\t245\n8.5 小结\t247\n第9章 Hadoop通信机制和内部协议\t248\n9.1 Hadoop RPC概述\t248\n9.1.1 通信模型\t248\n9.1.2 Hadoop RPC特点\t250\n9.2 Hadoop RPC的分析与使用\t251\n9.2.1 基础结构\t251\n9.2.2 使用示例\t257\n9.2.3 其他开源RPC框架\t264\n9.3 通信协议\t266\n9.3.1 MapReduce通信协议\t266\n9.3.2 RPC协议的实现\t273\n9.4 小结\t277\n第10章 Hadoop分布式文件系统剖析\t278\n10.1 HDFS介绍\t278\n10.1.1 HDFS概述\t278\n10.1.2 其他分布式文件系统\t282\n10.2 HDFS架构剖析\t283\n10.2.1 设计特点\t283\n10.2.2 命令空间和节点\t285\n10.2.3 数据备份剖析\t289\n10.3 数据迁移实战\t292\n10.3.1 HDFS跨集群迁移\t292\n10.3.2 HBase集群跨集群数据迁移\t297\n10.4 小结\t301\n第11章 ELK实战案例——游戏应用实时日志分析平台\t302\n11.1 Logstash——实时日志采集、分析和传输\t302\n11.1.1 Logstash介绍\t302\n11.1.2 Logstash安装\t306\n11.1.3 实战操作\t308\n11.2 Elasticsearch——分布式存储及搜索引擎\t309\n11.2.1 应用场景\t309\n11.2.2 基本概念\t310\n11.2.3 集群部署\t312\n11.2.4 实战操作\t317\n11.3 Kibana——可视化管理系统\t323\n11.3.1 Kibana特性\t324\n11.3.2 Kibana安装\t324\n11.3.3 实战操作\t328\n11.4 实时日志分析平台案例\t331\n11.4.1 案例概述\t331\n11.4.2 平台体系架构与剖析\t332\n11.4.3 实战操作\t334\n11.5 小结\t339\n第12章 Kafka实战案例——实时处理游戏用户数据\t340\n12.1 应用概述\t340\n12.1.1 Kafka回顾\t340\n12.1.2 项目简述\t347\n12.1.3 Kafka工程准备\t348\n12.2 项目的分析与设计\t349\n12.2.1 项目背景和价值概述\t349\n12.2.2 生产模块\t350\n12.2.3 消费模块\t352\n12.2.4 体系架构\t352\n12.3 项目的编码实践\t354\n12.3.1 生产模块\t354\n12.3.2 消费模块\t356\n12.3.3 数据持久化\t362\n12.3.4 应用调度\t364\n12.4 小结\t369\n第13章 Hadoop拓展——Kafka剖析\t370\n13.1 Kafka开发与维护\t370\n13.1.1 接口\t370\n13.1.2 新旧API编写\t372\n13.1.3 Kafka常用命令\t380\n13.2 运维监控\t383\n13.2.1 监控指标\t384\n13.2.2 Kafka开源监控工具——Kafka Eagle\t384\n13.3 Kafka源码分析\t391\n13.3.1 源码工程环境构建\t391\n13.3.2 分布式选举算法剖析\t394\n13.3.3 Kafka Offset解读\t398\n13.3.4 存储机制和副本\t398\n13.4 小结\t402","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30765117\/","id":"30765117","publisher":"机械工业出版社","isbn10":"711160010X","isbn13":"9787111600107","title":"Hadoop大数据挖掘从入门到进阶实战（视频教学版）","url":"https:\/\/api.douban.com\/v2\/book\/30765117","alt_title":"","author_intro":"邓杰 博客园资深博主，资深大数据全栈开发者，极客学院大数据讲师，开源爱好者。善于开发大数据监控系统辅助日常工作，提升工作效率。主导开发了大数据自助类平台系统。开发并在GitHub上发布了Kafka系统监控管理工具Kafka Eagle，深受业内开发者的赞誉。作为极客学院特邀讲师，制作了多个技术视频，讲授Hadoop和Kafka等相关技术课程，广受学员好评。","summary":"本书采用“理论+实战”的形式编写，全面介绍了Hadoop大数据挖掘的相关知识。本书秉承循序渐进、易于理解、学以致用和便于查询的讲授理念，讲解时结合了大量实例和作者多年积累的一线开发经验。本书作者拥有丰富的视频制作与在线教学经验，曾经与极客学院合作开设过在线视频教学课程。为了帮助读者高效、直观地学习本书内容，作者特意为本书录制了配套教学视频，这些教学视频和本书配套源代码文件读者都可以免费获取。\n本书共分为13章，涵盖的主要内容有：集群及开发环境搭建；快速构建一个Hadoop项目并线上运行；Hadoop套件实战；Hive编程——使用SQL提交MapReduce任务到Hadoop集群；游戏玩家的用户行为分析——特征提取；Hadoop平台管理与维护；Hadoop异常处理解决方案；初识Hadoop核心源码；Hadoop通信机制和内部协议；Hadoop分布式文件系统剖析；ELK实战案例——游戏应用实时日志分析平台；Kafka实战案例——实时处理游戏用户数据；Hadoop拓展——Kafka剖析。\n本书通俗易懂，案例丰富，实用性强，不但适合初学者系统学习Hadoop的各种基础语法和开发技巧，而且也适合有开发经验的程序员进阶提高。另外，本书还适合社会培训机构和相关院校作为教材或者教学参考书。","price":"99元"},{"rating":{"max":10,"numRaters":107,"average":"8.3","min":0},"subtitle":"","author":["[美] Lars George"],"pubdate":"2012-4","tags":[{"count":132,"name":"HBase","title":"HBase"},{"count":91,"name":"大数据","title":"大数据"},{"count":53,"name":"hadoop","title":"hadoop"},{"count":45,"name":"分布式","title":"分布式"},{"count":43,"name":"数据库","title":"数据库"},{"count":24,"name":"计算机","title":"计算机"},{"count":14,"name":"Hadoop","title":"Hadoop"},{"count":9,"name":"计算机科学","title":"计算机科学"}],"origin_title":"HBase: The Definitive Guide","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s10199109.jpg","binding":"平装","translator":["代志远","刘佳","蒋杰"],"catalog":"第1章　简介　1\n1.1　海量数据的黎明　1\n1.2　关系数据库系统的问题　5\n1.3　非关系型数据库系统Not-Only-SQL(简称NoSQL)　7\n1.3.1　维度　9\n1.3.2　可扩展性　12\n1.3.3　数据库的范式化和反范式化　12\n1.4　结构　15\n1.4.1　背景　15\n1.4.2　表、行、列和单元格　16\n1.4.3　自动分区　20\n1.4.4　存储API　21\n1.4.5　实现　22\n1.4.6　小结　25\n1.5　HBase：Hadoop数据库　25\n1.5.1　历史　26\n1.5.2　命名　27\n1.5.3　小结　27\n第2章　安装　28\n2.1　快速启动指南　28\n2.2　必备条件　31\n2.2.1　硬件　31\n2.2.2　软件　37\n2.3　HBase使用的文件系统　47\n2.3.1　本地模式　48\n2.3.2　HDFS　49\n2.3.3　S3　49\n2.3.4　其他文件系统　50\n2.4　安装选项　50\n2.4.1　Apache二进制发布包　50\n2.4.2　编译源码　52\n2.5　运行模式　53\n2.5.1　单机模式　53\n2.5.2　分布式模式　53\n2.6　配置　57\n2.6.1　hbase-site.xml与hbase-default.xml　58\n2.6.2　hbase-env.sh　59\n2.6.3　regionserver　59\n2.6.4　log4j.properties　59\n2.6.5　配置示例　59\n2.6.6　客户端配置　61\n2.7　部署　61\n2.7.1　基于脚本　62\n2.7.2　Apache Whirr　63\n2.7.3　Puppet与Chef　63\n2.8　操作集群　64\n2.8.1　确定安装运行　64\n2.8.2　Web UI介绍　65\n2.8.3　Shell介绍　66\n2.8.4　关闭集群　66\n第3章　客户端API：基础知识　68\n3.1　概述　68\n3.2　CRUD操作　69\n3.2.1　put方法　69\n3.2.2　get方法　87\n3.2.3　删除方法　97\n3.3　批量处理操作　107\n3.4　行锁　110\n3.5　扫描　114\n3.5.1　介绍　114\n3.5.2　ResultScanner类　117\n3.5.3　缓存与批量处理　119\n3.6　各种特性　125\n3.6.1　HTable的实用方法　125\n3.6.2　Bytes类　127\n第4章　客户端API：高级特性　129\n4.1　过滤器　129\n4.1.1　过滤器简介　129\n4.1.2　比较过滤器　132\n4.1.3　专用过滤器　139\n4.1.4　附加过滤器　147\n4.1.5　FilterList　151\n4.1.6　自定义过滤器　153\n4.1.7　过滤器总结　159\n4.2　计数器　160\n4.2.1　计数器简介　160\n4.2.2　单计数器　163\n4.2.3　多计数器　164\n4.3　协处理器　166\n4.3.1　协处理器简介　167\n4.3.2　Coprocessor类　168\n4.3.3　协处理器加载　171\n4.3.4　RegionObserver类　174\n4.3.5　MasterObserver类　180\n4.3.6　endpoint　184\n4.4　HTablePool　190\n4.5　连接管理　194\n第5章　客户端API：管理功能　197\n5.1　模式定义　197\n5.1.1　表　197\n5.1.2　表属性　199\n5.1.3　列族　202\n5.2　HBaseAdmin　207\n5.2.1　基本操作　208\n5.2.2　表操作　209\n5.2.3　模式操作　217\n5.2.4　集群管理　219\n5.2.5　集群状态信息　222\n第6章　可用客户端　230\n6.1　REST、Thrift和Avro的介绍　230\n6.2　交互客户端　233\n6.2.1　原生Java　233\n6.2.2　REST　233\n6.2.3　Thrift　240\n6.2.4　Avro　244\n6.2.5　其他客户端　245\n6.3　批处理客户端　246\n6.3.1　MapReduce　246\n6.3.2　Hive　246\n6.3.3　Pig　252\n6.3.4　Cascading　256\n6.4　Shell　257\n6.4.1　基础　257\n6.4.2　命令　259\n6.4.3　脚本　263\n6.5　基于Web的UI　265\n6.5.1　master的UI　265\n6.5.2　region服务器的UI　270\n6.5.3　共享页面　272\n第7章　与MapReduce集成　275\n7.1　框架　275\n7.1.1　MapReduce介绍　275\n7.1.2　类　276\n7.1.3　支撑类　279\n7.1.4　MapReduce的执行地点　279\n7.1.5　表拆分　280\n7.2　在HBase之上的MapReduce　281\n7.2.1　准备　281\n7.2.2　数据流向　286\n7.2.3　数据源　291\n7.2.4　数据源与数据流向　293\n7.2.5　自定义处理　296\n第8章　架构　299\n8.1　数据查找和传输　299\n8.1.1　B+树　299\n8.1.2　LSM树　300\n8.2　存储　302\n8.2.1　概览　303\n8.2.2　写路径　304\n8.2.3　文件　305\n8.2.4　HFile格式　313\n8.2.5　KeyValue格式　316\n8.3　WAL　316\n8.3.1　概述　317\n8.3.2　HLog类　318\n8.3.3　HLogKey类　319\n8.3.4　WALEdit类　319\n8.3.5　LogSyncer类　319\n8.3.6　LogRoller类　320\n8.3.7　回放　321\n8.3.8　持久性　324\n8.4　读路径　325\n8.5　region查找　328\n8.6　region生命周期　330\n8.7　ZooKeeper　330\n8.8　复制　333\n8.8.1　Log Edit的生命周期　334\n8.8.2　内部机制　335\n第9章　高级用法　339\n9.1　行键设计　339\n9.1.1　概念　339\n9.1.2　高表与宽表　341\n9.1.3　部分键扫描　342\n9.1.4　分页　343\n9.1.5　时间序列　344\n9.1.6　时间顺序关系　348\n9.2　高级模式　350\n9.3　辅助索引　350\n9.4　搜索集成　354\n9.5　事务　357\n9.6　布隆过滤器　358\n9.7　版本管理　361\n9.7.1　隐式版本控制　361\n9.7.2　自定义版本控制　364\n第10章　集群监控　366\n10.1　介绍　366\n10.2　监控框架　367\n10.2.1　上下文、记录和监控指标　367\n10.2.2　master监控指标　372\n10.2.3　region服务器监控指标　373\n10.2.4　RPC监控指标　375\n10.2.5　JVM监控指标　376\n10.2.6　info监控指标　377\n10.3　Ganglia　378\n10.3.1　安装　379\n10.3.2　用法　383\n10.4　JMX　386\n10.4.1　JConsole　388\n10.4.2　JMX远程API　390\n10.5　Nagios　394\n第11章　性能优化　395\n11.1　垃圾回收优化　395\n11.2　本地memstore分配缓冲区　398\n11.3　压缩　399\n11.3.1　可用的编解码器　400\n11.3.2　验证安装　401\n11.3.3　启用压缩　403\n11.4　优化拆分和合并　404\n11.4.1　管理拆分　404\n11.4.2　region热点　405\n11.4.3　预拆分region　406\n11.5　负载均衡　407\n11.6　合并region　408\n11.7　客户端API：最佳实践　409\n11.8　配置　411\n11.9　负载测试　414\n11.9.1　性能评价　414\n11.9.2　YCSB　416\n第12章　集群管理　421\n12.1　运维任务　421\n12.1.1　减少节点　421\n12.1.2　滚动重启　423\n12.1.3　新增服务器　424\n12.2　数据任务　428\n12.2.1　导入\/导出　428\n12.2.2　CopyTable工具　433\n12.2.3　批量导入　435\n12.2.4　复制　438\n12.3　额外的任务　440\n12.3.1　集群共存　440\n12.3.2　端口要求　442\n12.4　改变日志级别　442\n12.5　故障处理　443\n12.5.1　HBase Fsck　443\n12.5.2　日志分析　445\n12.5.3　常见问题　447\n附录A　HBase配置属性　451\n附录B　计划　467\n附录C　版本升级　469\n附录D　分支　471\n附录E　Hush SQL Schema　473\n附录F　对比HBase和BigTable　475","pages":"522","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s10199109.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s10199109.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s10199109.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10748460\/","id":"10748460","publisher":"东南大学出版社","isbn10":"7564133929","isbn13":"9787564133924","title":"HBase权威指南","url":"https:\/\/api.douban.com\/v2\/book\/10748460","alt_title":"HBase: The Definitive Guide","author_intro":"Lars George，HBase项目组成员，他是cloudera的解决方案架构师，提供了关于Hadoop和HBase的技术支持、咨询服务和培训工作。他曾经在多个不同的Hadoop用户组会议发言，并且在如布鲁塞尔的自由及开源软件开发者欧洲会议(FOSDEM)这样的大型会议中发言。","summary":"《HBase权威指南》探讨了如何通过使用与HBase高度集成的Hadoop将HBase的可伸缩性变得简单；把大型数据集分布到相对廉价的商业服务器集群中；使用本地Java客户端，或者通过提供了REST、Avro和Thrift应用编程接口的网关服务器来访问HBase；了解HBase架构的细节，包括存储格式、预写日志、后台进程等；在HBase中集成MapReduce框架；了解如何调节集群、设计模式、拷贝表、导入批量数据和删除节点等。\n《HBase权威指南》适合使用HBase进行数据库开发的高级数据库研发人员阅读。","price":"72.00元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"Stream data to Hadoop using Apache Flume","author":["Steve Hoffman"],"pubdate":"2013-7","tags":[{"count":1,"name":"分布式","title":"分布式"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27498652.jpg","binding":"","translator":[],"catalog":"Chapter 1: Overview and Architecture\nChapter 2: Flume Quick Start\nChapter 3: Channels\nChapter 4: Sinks and Sink Processors\nChapter 5: Sources and Channel Selectors\nChapter 6: Interceptors, ETL, and Routing\nChapter 7: Monitoring Flume\nChapter 8: There Is No Spoon","pages":"108","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27498652.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27498652.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27498652.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26013531\/","id":"26013531","publisher":"Packt Publishing Ltd","isbn10":"1782167919","isbn13":"9781782167914","title":"Apache Flume: Distributed Log Collection for Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26013531","alt_title":"","author_intro":"Steve Hoffman has 30 years of software development experience and holds\na B.S. in computer engineering from the University of Illinois Urbana-Champaign\nand a M.S. in computer science from the DePaul University. He is currently\na Principal Engineer at Orbitz Worldwide.\nMore information on Steve can be found at http:\/\/bit.ly\/bacoboy or on\nTwitter @bacoboy .\nThis is Steve's first book.","summary":"Hadoop is a great open source tool for sifting tons of unstructured data into something\nmanageable, so that your business can gain better insight into your customers, needs.\nIt is cheap (can be mostly free), scales horizontally as long as you have space and\npower in your data center, and can handle problems your traditional data warehouse\nwould be crushed under. That said, a little known secret is that your Hadoop cluster\nrequires you to feed it with data; otherwise, you just have a very expensive heat\ngenerator. You will quickly find, once you get past the “playing around” phase\nwith Hadoop, that you will need a tool to automatically feed data into your cluster.\nIn the past, you had to come up with a solution for this problem, but no more! Flume\nstarted as a project out of Cloudera when their integration engineers had to keep\nwriting tools over and over again for their customers to import data automatically.\nToday the project lives with the Apache Foundation, is under active development,\nand boasts users who have been using it in their production environments for years.\nIn this book I hope to get you up and running quickly with an architectural overview\nof Flume and a quick start guide. After that we’ll deep-dive into the details on many\nof the more useful Flume components, including the very important File Channel\nfor persistence of in-flight data records and the HDFS Sink for buffering and writing\ndata into HDFS, the Hadoop Distributed File System. Since Flume comes with\na wide variety of modules, chances are that the only tool you’ll need to get started\nis a text editor for the configuration file.\nBy the end of the book, you should know enough to build out a highly available,\nfault tolerant, streaming data pipeline feeding your Hadoop cluster.","price":""},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"挖掘、Hadoop、架构,更精准地发现业务与营销","author":["黄宏程","舒毅","欧阳春","舒娜"],"pubdate":"2016-8-1","tags":[{"count":1,"name":"金融","title":"金融"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29086673.jpg","binding":"平装","translator":[],"catalog":"","pages":"250","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29086673.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29086673.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29086673.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26889280\/","id":"26889280","publisher":"电子工业出版社","isbn10":"7121293447","isbn13":"9787121293443","title":"大数据之美","url":"https:\/\/api.douban.com\/v2\/book\/26889280","alt_title":"","author_intro":"","summary":"","price":"CNY 49.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Distributed Log Collection for Hadoop - Second Edition","author":["Steve Hoffman"],"pubdate":"2015-2-27","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"英文版","title":"英文版"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28018462.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"175","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28018462.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28018462.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28018462.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26336213\/","id":"26336213","publisher":"Packt Publishing - ebooks Account","isbn10":"1784392170","isbn13":"9781784392178","title":"Apache Flume","url":"https:\/\/api.douban.com\/v2\/book\/26336213","alt_title":"","author_intro":"","summary":"","price":"USD 36.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"A Working Guide to the Complete Hadoop Toolset","author":["Michael Frampton"],"pubdate":"2014-12-23","tags":[{"count":1,"name":"Tooset","title":"Tooset"},{"count":1,"name":"Data","title":"Data"},{"count":1,"name":"Big","title":"Big"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27981203.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"392","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27981203.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27981203.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27981203.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26299001\/","id":"26299001","publisher":"Apress","isbn10":"1484200950","isbn13":"9781484200957","title":"Big Data Made Easy","url":"https:\/\/api.douban.com\/v2\/book\/26299001","alt_title":"","author_intro":"","summary":"","price":"USD 44.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"Hadoop on Windows","author":["Debarchan Sarkar"],"pubdate":"2014-2-18","tags":[{"count":1,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27265621.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"272","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27265621.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27265621.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27265621.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25871997\/","id":"25871997","publisher":"Apress","isbn10":"1430260556","isbn13":"9781430260554","title":"Pro Microsoft HDInsight","url":"https:\/\/api.douban.com\/v2\/book\/25871997","alt_title":"","author_intro":"","summary":"","price":"USD 59.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Dataflow Scripting with Hadoop","author":["Alan Gates","Daniel Dai"],"pubdate":"2016-12-5","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29149580.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"347","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29149580.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29149580.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29149580.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26914412\/","id":"26914412","publisher":"O'Reilly Media","isbn10":"1491937092","isbn13":"9781491937099","title":"Programming Pig","url":"https:\/\/api.douban.com\/v2\/book\/26914412","alt_title":"","author_intro":"","summary":"","price":"USD 39.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Learning Hadoop Investigations","author":["Joe Sremack"],"pubdate":"2015-9-1","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28288842.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"296","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28288842.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28288842.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28288842.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26604941\/","id":"26604941","publisher":"Packt Publishing - ebooks Account","isbn10":"1785288105","isbn13":"9781785288104","title":"Big Data Forensics","url":"https:\/\/api.douban.com\/v2\/book\/26604941","alt_title":"","author_intro":"","summary":"","price":"USD 44.99"},{"rating":{"max":10,"numRaters":7,"average":"0.0","min":0},"subtitle":"","author":["[美] 斯科特·肖","[南非] 安德烈亚斯·弗朗索瓦·弗穆尔恩","[印] 安库尔 • 古普塔","[美] 戴维 • 杰鲁姆加德"],"pubdate":"2018-11","tags":[{"count":1,"name":"自我提升","title":"自我提升"},{"count":1,"name":"图灵","title":"图灵"},{"count":1,"name":"2019","title":"2019"}],"origin_title":"Practical Hive: A Guide to Hadoop's Data Warehouse System","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29911657.jpg","binding":"平装","translator":["唐富年"],"catalog":"第1章　为Hive打好基础：Hadoop　　1\n1.1　一只小象出生了　　2\n1.2　Hadoop的结构　　3\n1.3　数据冗余　　6\n1.3.1　传统的高可用性　　6\n1.3.2　Hadoop的高可用性　　9\n1.4　MapReduce处理　　12\n1.4.1　超越MapReduce　　16\n1.4.2　YARN和现代数据架构　　17\n1.4.3　Hadoop和开源社区　　19\n1.4.4　我们身在何处　　22\n第2章　Hive简介　　24\n2.1　Hadoop发行版　　25\n2.2　集群架构　　27\n2.3　Hive的安装　　30\n2.4　探寻你的方式　　32\n2.5　Hive CLI　　35\n第3章　Hive架构　　37\n3.1　Hive组件　　37\n3.2　HCatalog　　38\n3.3　HiveServer2　　40\n3.4　客户端工具　　42\n3.5　执行引擎：Tez　　46\n第4章　Hive表DDL　　48\n4.1　schema-on-read　　48\n4.2　Hive数据模型　　49\n4.2.1　模式\/数据库　　49\n4.2.2　为什么使用多个模式\/数据库　　49\n4.2.3　创建数据库　　49\n4.2.4　更改数据库　　50\n4.2.5　删除数据库　　50\n4.2.6　列出数据库　　51\n4.3　Hive中的数据类型　　51\n4.3.1　基本数据类型　　51\n4.3.2　选择数据类型　　51\n4.3.3　复杂数据类型　　52\n4.4　表　　53\n4.4.1　创建表　　53\n4.4.2　列出表　　54\n4.4.3　内部表\/外部表　　54\n4.4.4　内部表\/受控表　　55\n4.4.5　内部表\/外部表示例　　55\n4.4.6　表的属性　　59\n4.4.7　生成已有表的CREATE TABLE命令　　60\n4.4.8　分区和分桶　　61\n4.4.9　分区注意事项　　63\n4.4.10　对日期列进行高效分区　　63\n4.4.11　分桶的注意事项　　65\n4.4.12　更改表　　66\n4.4.13　ORC文件格式　　67\n4.4.14　更改表分区　　68\n4.4.15　修改列　　72\n4.4.16　删除表\/分区　　72\n4.4.17　保护表\/分区　　73\n4.4.18　其他CREATE TABLE命令选项　　73\n第5章　数据操作语言　　75\n5.1　将数据装载到表中　　75\n5.1.1　使用存储在HDFS中的文件装载数据　　75\n5.1.2　使用查询装载数据　　77\n5.1.3　将查询到的数据写入文件系统　　80\n5.1.4　直接向表插入值　　81\n5.1.5　直接更新表中数据　　83\n5.1.6　在表中直接删除数据　　84\n5.1.7　创建结构相同的表　　85\n5.2　连接　　86\n5.2.1　使用等值连接来整合表　　86\n5.2.2　使用外连接　　87\n5.2.3　使用左半连接　　89\n5.2.4　用单次MapReduce实现连接　　90\n5.2.5　最后使用最大的表　　91\n5.2.6　事务处理　　92\n5.2.7　ACID是什么，以及为什么要用到它　　92\n5.2.8　Hive配置　　92\n第6章　将数据装载到Hive　　94\n6.1　装载数据之前的设计注意事项　　94\n6.2　将数据装载到HDFS　　95\n6.2.1　Ambari文件视图　　95\n6.2.2　Hadoop命令行　　97\n6.2.3　HDFS的NFS Gateway　　97\n6.2.4　Sqoop　　98\n6.2.5　Apache NiFi　　101\n6.3　用Hive访问数据　　105\n6.3.1　外部表　　105\n6.3.2　LOAD DATA语句　　106\n6.4　在Hive中装载增量变更数据　　107\n6.5　Hive流处理　　107\n6.6　小结　　108\n第7章　查询半结构化数据　　109\n7.1　点击流数据　　111\n7.1.1　摄取数据　　113\n7.1.2　创建模式　　116\n7.1.3　装载数据　　116\n7.1.4　查询数据　　116\n7.2　摄取JSON数据　　119\n7.2.1　使用UDF查询JSON　　121\n7.2.2　使用SerDe访问JSON　　122\n第8章　Hive分析　　125\n8.1　构建分析模型　　125\n8.1.1　使用太阳模型获取需求　　125\n8.1.2　将太阳模型转换为星型模式　　129\n8.1.3　构建数据仓库　　137\n8.2　评估分析模型　　140\n8.2.1　评估太阳模型　　140\n8.2.2　评估聚合结果　　142\n8.2.3　评估数据集市　　143\n8.3　掌握数据仓库管理　　144\n8.3.1　必备条件　　144\n8.3.2　检索数据库　　144\n8.3.3　评估数据库　　147\n8.3.4　过程数据库　　160\n8.3.5　转换数据库　　185\n8.3.6　你掌握了什么　　192\n8.3.7　组织数据库　　192\n8.3.8　报表数据库　　196\n8.3.9　示例报表　　197\n8.4　高级分析　　199\n8.5　接下来学什么　　199\n第9章　Hive性能调优　　200\n9.1　Hive性能检查表　　200\n9.2　执行引擎　　201\n9.2.1　MapReduce　　201\n9.2.2　Tez　　201\n9.3　存储格式　　203\n9.3.1　ORC格式　　203\n9.3.2　Parquet格式　　205\n9.4　矢量化查询执行　　206\n9.5　查询执行计划　　206\n9.5.1　基于代价的优化　　208\n9.5.2　执行计划　　210\n9.5.3　性能检查表小结　　212\n第10章　Hive的安全性　　213\n10.1　数据安全性的几个方面　　213\n10.1.1　身份认证　　214\n10.1.2　授权　　214\n10.1.3　管理　　214\n10.1.4　审计　　214\n10.1.5　数据保护　　214\n10.2　Hadoop的安全性　　215\n10.3　Hive的安全性　　215\n10.3.1　默认授权模式　　215\n10.3.2　基于存储的授权模式　　216\n10.3.3　基于SQL标准的授权模式　　217\n10.3.4　管理通过SQL进行的访问　　218\n10.4　使用Ranger进行Hive授权　　219\n10.4.1　访问Ranger用户界面　　220\n10.4.2　创建Ranger策略　　220\n10.4.3　使用Ranger审计　　222\n第11章　Hive的未来　　224\n11.1　LLAP　　224\n11.2　Hive-on-Spark　　225\n11.3　Hive：ACID和MERGE　　225\n11.4　可调隔离等级　　225\n11.5　ROLAP\/基于立方体的分析　　226\n11.6　HiveServer2的发展　　226\n11.7　面向不同工作负载的多个HiveServer2实例　　226\n附录A　建立大数据团队　　227\n附录B　Hive函数　　231","pages":"248","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29911657.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29911657.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29911657.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30367739\/","id":"30367739","publisher":"人民邮电出版社","isbn10":"711549391X","isbn13":"9787115493910","title":"Hive实战","url":"https:\/\/api.douban.com\/v2\/book\/30367739","alt_title":"Practical Hive: A Guide to Hadoop's Data Warehouse System","author_intro":"斯科特·肖（Scott Shaw）\nHortonworks公司高级解决方案工程师，曾为微软公司的商业智能项目担任顾问，拥有近20年的数据管理经验。作为演讲者和培训师，他致力于普及分布式计算、大数据概念、商业智能、Hive和Hadoop。\n安德烈亚斯·弗朗索瓦·弗穆尔恩（Andreas François Vermeulen）\n集数据科学家、数据仓库架构师、博士研究员、企业顾问等角色于一身，曾获“英国数据科学技术先锋”称号，广泛涉足数据工程、商业智能、云架构、深度学习等多个领域。\n安库尔·古普塔（Ankur Gupta）\nHortonworks公司高级解决方案工程师，曾在Oracle公司担任顾问，有多年从事数据架构师和Oracle数据库管理员的经验，著有Oracle GoldenGate 11g Complete Cookbook。\n戴维·杰鲁姆加德（David Kjerrumgaard）\nStreamlio公司解决方案架构主管，曾是Hortonworks公司的系统架构师和数据流实践主管，拥有Certified Developer for Apache Hadoop认证，精通Hive、Kafka、Spark、Storm等技术。","summary":"Hive“出身名门”，是最初由Facebook公司开发的数据仓库工具。它简单且容易上手，是深入学习Hadoop技术的一个很好的切入点。本书由数据库专家和大数据专家共同撰写，具体内容包括：Hive的安装和配置，其核心组件和架构，Hive数据操作语言，如何加载、查询和分析数据，Hive的性能调优以及安全性，等等。本书旨在为读者打牢基础，从而踏上专业的大数据处理之旅。","series":{"id":"660","title":"图灵程序设计丛书"},"price":"69.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"The Comprehensive, Up-to-Date Apache Hadoop Administration Handbook and Reference","author":["Sam R. Alapati"],"pubdate":"2016-12-19","tags":[{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"dba","title":"dba"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29195344.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"848","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29195344.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29195344.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29195344.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26928002\/","id":"26928002","publisher":"Addison","isbn10":"0134597192","isbn13":"9780134597195","title":"Expert Hadoop Administration: Managing, Tuning, and Securing Spark, YARN, and HDFS (Addison-Wesley Data & Analytics Series)","url":"https:\/\/api.douban.com\/v2\/book\/26928002","alt_title":"","author_intro":"About the Author\nSam R. Alapati has been working with various aspects of the Hadoop environment for the past six years. He is currently the principal Hadoop administrator at Sabre Corporation in Westlake, Texas, and works on a daily basis with multiple large Hadoop 2 clusters. In addition to being the point person for all Hadoop administration at Sabre, Sam manages multiple critical data-science- and data-analysis-related Hadoop job flows and is also an expert Oracle Database Administrator. His vast knowledge of relational databases and SQL contributes to his work with Hadoop related projects. Sam’s recognition in the database and middleware area includes having published 18 well-received books over the past 14 years, mostly on Oracle Database Administration and Oracle Weblogic Server. His experience dealing with numerous configuration, architectural, and performance-related Hadoop issues over the years led him to the realization that many working Hadoop administrators and developers would appreciate having a handy reference such as this book to turn to when creating, managing, securing and optimizing their Hadoop infrastructure.\nRead more","summary":"The Comprehensive, Up-to-Date Apache Hadoop Administration Handbook and Reference\n“Sam Alapati has worked with production Hadoop clusters for six years. His unique depth of experience has enabled him to write the go-to resource for all administrators looking to spec, size, expand, and secure production Hadoop clusters of any size.”  –Paul Dix, Series Editor\nIn  Expert Hadoop® Administration,  leading Hadoop administrator Sam R. Alapati brings together authoritative knowledge for creating, configuring, securing, managing, and optimizing production Hadoop clusters in any environment. Drawing on his experience with large-scale Hadoop administration, Alapati integrates action-oriented advice with carefully researched explanations of both problems and solutions. He covers an unmatched range of topics and offers an unparalleled collection of realistic examples.\nAlapati demystifies complex Hadoop environments, helping you understand exactly what happens behind the scenes when you administer your cluster. You’ll gain unprecedented insight as you walk through building clusters from scratch and configuring high availability, performance, security, encryption, and other key attributes. The high-value administration skills you learn here will be indispensable no matter what Hadoop distribution you use or what Hadoop applications you run.\nUnderstand Hadoop’s architecture from an administrator’s standpoint Create simple and fully distributed clusters Run MapReduce and Spark applications in a Hadoop cluster Manage and protect Hadoop data and high availability Work with HDFS commands, file permissions, and storage management Move data, and use YARN to allocate resources and schedule jobs Manage job workflows with Oozie and Hue Secure, monitor, log, and optimize Hadoop Benchmark and troubleshoot Hadoop","price":"USD 46.09"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Integrate Elasticsearch into Hadoop to effectively visualize and analyze your data","author":["Vishal Shukla"],"pubdate":"2015-10","tags":[{"count":1,"name":"搜索引擎","title":"搜索引擎"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29188433.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29188433.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29188433.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29188433.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26926192\/","id":"26926192","publisher":"","isbn10":"1785288997","isbn13":"9781785288999","title":"Elasticsearch for Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26926192","alt_title":"","author_intro":"","summary":"","price":"USD 31.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Harnessing Cloud Features and Flexibility for Hadoop Clusters","author":["Bill Havanki"],"pubdate":"2017-7-24","tags":[{"count":1,"name":"大数据","title":"大数据"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29519710.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"338","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29519710.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29519710.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29519710.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27115199\/","id":"27115199","publisher":"O'Reilly Media","isbn10":"1491959630","isbn13":"9781491959633","title":"Moving Hadoop to the Cloud","url":"https:\/\/api.douban.com\/v2\/book\/27115199","alt_title":"","author_intro":"","summary":"","price":"USD 39.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"使用Hadoop生态系统设计和构建大数据系统","author":["[美]Kerry Koitzsch"],"pubdate":"2017-12-1","tags":[],"origin_title":"Pro Hadoop Data Analytics:Designing and Building Big Data Systems Using the Hadoop Ecosystem","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29825773.jpg","binding":"平装","translator":["王建峰","王瑛琦","于金峰"],"catalog":"目录\n第Ⅰ部分概念\n第1章概述：用Hadoop构建数据分析系统3\n1.1构建DAS的必要性4\n1.2HadoopCore及其简史4\n1.3Hadoop生态系统概述5\n1.4AI技术、认知计算、深度学习以及BDA6\n1.5自然语言处理与BDAS6\n1.6SQL与NoSQL查询处理6\n1.7必要的数学知识7\n1.8设计及构建BDAS的循环过程7\n1.9如何利用Hadoop生态系统实现BDA10\n1.10“图像大数据”(IABD)基本思想10\n1.10.1使用的编程语言12\n1.10.2Hadoop生态系统的多语言组件12\n1.10.3Hadoop生态系统架构13\n1.11有关软件组合件与框架的注意事项13\n1.12ApacheLucene、Solr及其他：开源搜索组件14\n1.13建立BDAS的架构15\n1.14你需要了解的事情15\n1.15数据可视化与报表17\n1.15.1使用EclipseIDE作为开发环境18\n1.15.2本书未讲解的内容19\n1.16本章小结21\n第2章Scala及Python进阶23\n2.1动机：选择正确的语言定义应用23\n2.2Scala概览24\n2.3Python概览29\n2.4错误诊断、调试、配置文件及文档31\n2.4.1Python的调试资源32\n2.4.2Python文档33\n2.4.3Scala的调试资源33\n2.5编程应用与示例33\n2.6本章小结34\n2.7参考文献34\n第3章Hadoop及分析的标准工具集35\n3.1库、组件及工具集：概览35\n3.2在评估系统中使用深度学习方法38\n3.3使用Spring框架及SpringData44\n3.4数字与统计库：R、Weka及其他44\n3.5分布式系统的OLAP技术44\n3.6用于分析的Hadoop工具集：ApacheMahout及相关工具45\n3.7ApacheMahout的可视化46\n3.8ApacheSpark库与组件46\n3.8.1可供选择的不同类型的shell46\n3.8.2ApacheSpark数据流47\n3.8.3SparklingWater与H2O机器学习48\n3.9组件使用与系统建立示例48\n3.10封包、测试和文档化示例系统50\n3.11本章小结51\n3.12参考文献51\n第4章关系、NoSQL及图数据库53\n4.1图查询语言：Cypher及Gremlin55\n4.2Cypher示例55\n4.3Gremlin示例56\n4.4图数据库：ApacheNeo4J58\n4.5关系数据库及Hadoop生态系统59\n4.6Hadoop以及UA组件59\n4.7本章小结63\n4.8参考文献64\n第5章数据管道及其构建方法65\n5.1基本数据管道66\n5.2ApacheBeam简介67\n5.3ApacheFalcon简介68\n5.4数据源与数据接收：使用ApacheTika构建数据管道68\n5.5计算与转换70\n5.6结果可视化及报告71\n5.7本章小结74\n5.8参考文献74\n第6章Hadoop、Lucene、Solr与高级搜索技术75\n6.1Lucene\/Solr生态系统简介75\n6.2Lucene查询语法76\n6.3使用Solr的编程示例79\n6.4使用ELK栈(Elasticsearch、Logstash、Kibana)85\n6.5Solr与Elasticsearch：特点与逻辑93\n6.6应用于Elasticsearch和Solr的SpringData组件95\n6.7使用LingPipe和GATE实现定制搜索99\n6.8本章小结108\n6.9参考文献108\n第Ⅱ部分架构及算法\n第7章分析技术及算法概览111\n7.1算法类型综述111\n7.2统计\/数值技术112\n7.3贝叶斯技术113\n7.4本体驱动算法114\n7.5混合算法：组合算法类型115\n7.6代码示例116\n7.7本章小结119\n7.8参考文献119\n第8章规则引擎、系统控制与系统编排121\n8.1规则系统JBossDrools介绍121\n8.2基于规则的软件系统控制124\n8.3系统协调与JBossDrools125\n8.4分析引擎示例与规则控制126\n8.5本章小结129\n8.6参考文献129\n第9章综合提升：设计一个完整的分析系统131\n9.1本章小结136\n9.2参考文献136\n第Ⅲ部分组件与系统\n第10章数据可视化：可视化与交互分析139\n10.1简单的可视化139\n10.2AngularJS和Friends简介143\n10.3使用JHipster集成SpringXD\n和AngularJS143\n10.4使用d3.js、sigma.js及其他\n工具152\n10.5本章小结153\n10.6参考文献153\n第Ⅳ部分案例研究与应用","pages":"225","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29825773.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29825773.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29825773.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30280487\/","id":"30280487","publisher":"清华大学出版社","isbn10":"7302487308","isbn13":"9787302487302","title":"Hadoop高级数据分析","url":"https:\/\/api.douban.com\/v2\/book\/30280487","alt_title":"Pro Hadoop Data Analytics:Designing and Building Big Data Systems Using the Hadoop Ecosystem","author_intro":"Kerry Koitzsch在计算机科学、图像处理和软件工程等领域拥有超过二十年的工作经验，致力于研究Apache Hadoop和Apache Spark技术。Kerry擅长软件咨询，精通一些定制的大数据应用，包括分布式搜索、图像分析、立体视觉和智能图像检索系统。Kerry目前就职于Kildane软件技术股份有限公司，该公司是加州桑尼维尔市的一个机器人系统和图像分析软件提供商。","summary":"掌握Hadoop高级数据分析技术\n学习高级分析技术，并利用现有工具包使分析应用更加强大、精确和高效！《Hadoop高级数据分析使用Hadoop生态系统设计和构建大数据系统》将架构、设计及实现信息恰当地融为一体，将指导你创建*基础方法(SF分类、聚类、推荐)的分析系统。\n在《Hadoop高级数据分析使用Hadoop生态系统设计和构建大数据系统》中，*佳实践强调“确保连贯、高效的开发”。将使用包含工具箱、库、可视化组件和报表代码在内的标准第三方组件，借助集成“组合件”开发一个可运行的、可扩展的、端到端的完整示例系统。\n《Hadoop高级数据分析使用Hadoop生态系统设计和构建大数据系统》强调以下四点：\n●具有分析组件及合理可视化结果的完整、灵活、可配置、高性能数据管道系统的重要性。深入探讨的主题包括Spark、H2O、VopalWabbit(NLP)、StanfordNLP、ApacheMahout，以及其他适用的工具包、库和插件。\n●*佳实践和结构化设计原则。包括重要主题及示例部分。\n●用混合搭配或混合系统实现应用目标的重要性。你在学习深度示例时可体会到混合方法的重要性。\n●使用现有第三方库是有效开发的关键。在开发示例系统时，深度示例将展示一些第三方工具包的功能。","series":{"id":"43020","title":"大数据应用与技术丛书"},"price":"59.80元"}]}
2	{"count":100,"start":100,"total":244,"books":[{"rating":{"max":10,"numRaters":189,"average":"7.4","min":0},"subtitle":"","author":["卡普廖洛 (Edward Capriolo)","万普勒 (Dean Wampler)","卢森格林 (Jason Rutherglen)"],"pubdate":"2013-12-1","tags":[{"count":125,"name":"Hive","title":"Hive"},{"count":93,"name":"大数据","title":"大数据"},{"count":61,"name":"hadoop","title":"hadoop"},{"count":37,"name":"数据挖掘","title":"数据挖掘"},{"count":34,"name":"数据分析","title":"数据分析"},{"count":32,"name":"HQL","title":"HQL"},{"count":29,"name":"计算机","title":"计算机"},{"count":23,"name":"hive","title":"hive"}],"origin_title":"Programming Hive","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28019858.jpg","binding":"平装","translator":["曹坤"],"catalog":"第1章基础知识\n1.1Hadoop和MapReduce综述\n1.2Hadoop生态系统中的Hive\n1.2.1Pig\n1.2.2HBase\n1.2.3Cascading、Crunch及其他\n1.3Java和Hive：词频统计算法\n1.4后续事情\n第2章基础操作\n2.1安装预先配置好的虚拟机\n2.2安装详细步骤\n2.2.1装Java\n2.2.2安装Hadoop\n2.2.3本地模式、伪分布式模式和分布式模式\n2.2.4测试Hadoop\n2.2.5安装Hive\n2.3Hive内部是什么\n2.4启动Hive\n2.5配置Hadoop环境\n2.5.1本地模式配置\n2.5.2分布式模式和伪分布式模式配置\n2.5.3使用JDBC连接元数据\n2.6Hive命令\n2.7命令行界面\n2.7.1CLI选项\n2.7.2变量和属性\n2.7.3Hive中“一次使用”命令\n2.7.4从文件中执行Hive查询\n2.7.5hiverc文件\n2.7.6使用HiveCLI的更多介绍\n2.7.7查看操作命令历史\n2.7.8执行shell命令\n2.7.9在Hive内使用Hadoop的dfs命令\n2.7.10Hive脚本中如何进行注释\n2.7.11显示字段名称\n第3章数据类型和文件格式\n3.1基本数据类型\n3.2集合数据类型\n3.3文本文件数据编码\n3.4读时模式\n第4章HiveQL：数据定义\n4.1Hive中的数据库\n4.2修改数据库\n4.3创建表\n4.3.1管理表\n4.3.2外部表\n4.4分区表、管理表\n4.4.1外部分区表\n4.4.2自定义表的存储格式\n4.5删除表\n4.6修改表\n4.6.1表重命名\n4.6.2增加、修改和删除表分区\n4.6.3修改列信息\n4.6.4增加列\n4.6.5删除或者替换列\n4.6.6修改表属性\n4.6.7修改存储属性\n4.6.8众多的修改表语句\n第5章HiveQL：数据操作\n5.1向管理表中装载数据\n5.2通过查询语句向表中插入数据\n5.3单个查询语句中创建表并加载数据\n5.4导出数据\n第6章HiveQL：查询\n6.1SELECT…FROM语句\n6.1.1使用正则表达式来指定列\n6.1.2使用列值进行计算\n6.1.3算术运算符\n6.1.4使用函数\n6.1.5LIMIT语句\n6.1.6列别名\n6.1.7嵌套SELECT语句\n6.1.8CASE…WHEN…THEN句式\n6.1.9什么情况下Hive可以避免进行MapReduce\n6.2WHERE语句\n6.2.1谓词操作符\n6.2.2关于浮点数比较\n6.2.3LIKE和RLIKE\n6.3GROUPBY语句\n6.4JOIN语句\n6.4.1INNERJOIN\n6.4.2JOIN优化\n6.4.3LEFTOUTERJOIN\n6.4.4OUTERJOIN\n6.4.5RIGHTOUTERJOIN\n6.4.6FULLOUTERJOIN\n6.4.7LEFTSEMI—JOIN\n6.4.8笛卡尔积JOIN\n6.4.9map—sideJOIN\n6.5ORDERBY和SORTBY\n6.6含有SORTBY的DISTRIBUTEBY\n6.7CLUSTERBY\n6.8类型转换\n6.9抽样查询\n6.9.1数据块抽样\n6.9.2分桶表的输入裁剪\n6.10UNIONALL\n第7章HiveQL：视图\n7.1使用视图来降低查询复杂度\n7.2使用视图来限制基于条件过滤的数据\n7.3动态分区中的视图和map类型\n7.4视图零零碎碎相关的事情\n第8章HiveQL：索引\n8.1创建索引\n8.2重建索引\n8.3显示索引\n8.4删除索引\n8.5实现一个定制化的索引处理器\n第9章模式设计\n9.1按天划分的表\n9.2关于分区\n9.3唯一键和标准化\n9.4同一份数据多种处理\n9.5对于每个表的分区\n9.6分桶表数据存储\n9.7为表增加列\n9.8使用列存储表\n9.8.1重复数据\n9.8.2多列\n9.9（几乎）总是使用压缩\n第10章调优\n10.1使用EXPLAIN\n10.2EXPLAINEXTENDED\n10.3限制调整\n10.4JOIN优化\n10.5本地模式\n10.6并行执行\n10.7严格模式\n10.8调整mapper和reducer个数\n10.9JVM重用\n10.10索引\n10.11动态分区调整\n10.12推测执行\n10.13单个MapReduce中多个GROUPBY\n10.14虚拟列\n第11章其他文件格式和压缩方法\n11.1确定安装编解码器\n11.2选择一种压缩编／解码器\n11.3开启中间压缩\n11.4最终输出结果压缩\n11.5sequencefile存储格式\n11.6使用压缩实践\n11.7存档分区\n11.8压缩：包扎\n……\n第12章开发\n第13章函数\n第14章Streaming\n第15章自定义Hive文件和记录格式\n第16章Hive的Thrift服务\n第17章存储处理程序和NoSQL\n第18章安全\n第19章锁\n第20章Hive和Oozie整合\n第21章Hive和亚马逊网络服务系统（AWS）\n第22章HCatalog\n第23章案例研究\n术语词汇表","pages":"318","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28019858.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28019858.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28019858.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25791255\/","id":"25791255","publisher":"人民邮电出版社","isbn10":"7115333831","isbn13":"9787115333834","title":"Hive编程指南","url":"https:\/\/api.douban.com\/v2\/book\/25791255","alt_title":"Programming Hive","author_intro":"Edward Capriolo：Media6degrees公司系统管理员，他是Apache软件基金会成员，还是Hadoop-Hive项目成员。\nDean Wampler：Think Big Analytics公司总顾问，对大数据问题以及Hadoop和机器学习有专门的研究。\nJason Rutherglen：Think Big Analytics公司软件架构师，对大数据、Hadoop、搜索和安全有专门的研究。","summary":"市场中第一本Hive图书。\nHive在Hadoop系统中的应用趋势比较可观。","price":"69"},{"rating":{"max":10,"numRaters":32,"average":"8.7","min":0},"subtitle":"","author":["王雪迎"],"pubdate":"2017-7","tags":[{"count":29,"name":"数据仓库","title":"数据仓库"},{"count":25,"name":"大数据","title":"大数据"},{"count":19,"name":"hadoop","title":"hadoop"},{"count":10,"name":"计算机","title":"计算机"},{"count":5,"name":"数据平台","title":"数据平台"},{"count":5,"name":"~大数据","title":"~大数据"},{"count":4,"name":"编程人生","title":"编程人生"},{"count":3,"name":"技术","title":"技术"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29481723.jpg","binding":"","translator":[],"catalog":"目 录\n第1章 数据仓库简介\n1.1 什么是数据仓库 1\n1.1.1 数据仓库的定义 1\n1.1.2 建立数据仓库的原因 3\n1.2 操作型系统与分析型系统 5\n1.2.1 操作型系统 5\n1.2.2 分析型系统 8\n1.2.3 操作型系统和分析型系统对比 9\n1.3 数据仓库架构 10\n1.3.1 基本架构 10\n1.3.2 主要数据仓库架构 12\n1.3.3 操作数据存储 16\n1.4 抽取-转换-装载 17\n1.4.1 数据抽取 17\n1.4.2 数据转换 19\n1.4.3 数据装载 20\n1.4.4 开发ETL系统的方法 21\n1.4.5 常见ETL工具 21\n1.5 数据仓库需求 22\n1.5.1 基本需求 22\n1.5.2 数据需求 23\n1.6 小结 24\n第2章 数据仓库设计基础\n2.1 关系数据模型 25\n2.1.1 关系数据模型中的结构 25\n2.1.2 关系完整性 28\n2.1.3 规范化 30\n2.1.4 关系数据模型与数据仓库 33\n2.2 维度数据模型 34\n2.2.1 维度数据模型建模过程 35\n2.2.2 维度规范化 36\n2.2.3 维度数据模型的特点 37\n2.2.4 星型模式 38\n2.2.5 雪花模式 40\n2.3 Data Vault模型 42\n2.3.1 Data Vault模型简介 42\n2.3.2 Data Vault模型的组成部分 43\n2.3.3 Data Vault模型的特点 44\n2.3.4 Data Vault模型的构建 44\n2.3.5 Data Vault模型实例 46\n2.4 数据集市 49\n2.4.1 数据集市的概念 50\n2.4.2 数据集市与数据仓库的区别 50\n2.4.3 数据集市设计 50\n2.5 数据仓库实施步骤 51\n2.6 小结 54\n第3章 Hadoop生态圈与数据仓库\n3.1 大数据定义 55\n3.2 Hadoop简介 56\n3.2.1 Hadoop的构成 57\n3.2.2 Hadoop的主要特点 58\n3.2.3 Hadoop架构 58\n3.3 Hadoop基本组件 59\n3.3.1 HDFS 60\n3.3.2 MapReduce 65\n3.3.3 YARN 72\n3.4 Hadoop生态圈的其他组件 77\n3.5 Hadoop与数据仓库 81\n3.5.1 关系数据库的可扩展性瓶颈 82\n3.5.2 CAP理论 84\n3.5.3 Hadoop数据仓库工具 85\n3.6 小结 88\n第4章 安装Hadoop\n4.1 Hadoop主要发行版本 89\n4.1.1 Cloudera Distribution for Hadoop（CDH） 89\n4.1.2 Hortonworks Data Platform（HDP） 90\n4.1.3 MapR Hadoop 90\n4.2 安装Apache Hadoop 91\n4.2.1 安装环境 91\n4.2.2 安装前准备 92\n4.2.3 安装配置Hadoop 93\n4.2.4 安装后配置 97\n4.2.5 初始化及运行 97\n4.3 配置HDFS Federation 99\n4.4 离线安装CDH及其所需的服务 104\n4.4.1 CDH安装概述 104\n4.4.2 安装环境 106\n4.4.3 安装配置 106\n4.4.4 Cloudera Manager许可证管理 114\n4.5 小结 115\n第5章 Kettle与Hadoop\n5.1 Kettle概述 117\n5.2 Kettle连接Hadoop 119\n5.2.1 连接HDFS 119\n5.2.2 连接Hive 124\n5.3 导出导入Hadoop集群数据 128\n5.3.1 把数据从HDFS抽取到RDBMS 128\n5.3.2 向Hive表导入数据 132\n5.4 执行Hive的HiveQL语句 134\n5.5 MapReduce转换示例 135\n5.6 Kettle提交Spark作业 143\n5.6.1 安装Spark 143\n5.6.2 配置Kettle向Spark集群提交作业 146\n5.7 小结 149\n第6章 建立数据仓库示例模型\n6.1 业务场景 150\n6.2 Hive相关配置 152\n6.2.1 选择文件格式 152\n6.2.2 支持行级更新 159\n6.2.3 Hive事务支持的限制 164\n6.3 Hive表分类 164\n6.4 向Hive表装载数据 169\n6.5 建立数据库表 174\n6.6 装载日期维度数据 179\n6.7 小结 180\n第7章 数据抽取\n7.1 逻辑数据映射 182\n7.2 数据抽取方式 185\n7.3 导出成文本文件 191\n7.4 分布式查询 196\n7.5 使用Sqoop抽取数据 200\n7.5.1 Sqoop简介 200\n7.5.2 CDH 5.7.0中的Sqoop 203\n7.5.3 使用Sqoop抽取数据 203\n7.5.4 Sqoop优化 207\n7.6 小结 208\n第8章 数据转换与装载\n8.1 数据清洗 210\n8.2 Hive简介 214\n8.2.1 Hive的体系结构 215\n8.2.2 Hive的工作流程 216\n8.2.3 Hive服务器 218\n8.2.4 Hive客户端 221\n8.3 初始装载 231\n8.4 定期装载 236\n8.5 Hive优化 246\n8.6 小结 254\n第9章 定期自动执行ETL作业\n9.1 crontab 256\n9.2 Oozie简介 260\n9.2.1 Oozie的体系结构 260\n9.2.2 CDH 5.7.0中的Oozie 262\n9.3 建立定期装载工作流 262\n9.4 建立协调器作业定期自动执行工作流 271\n9.5 Oozie优化 275\n9.6 小结 276\n第10章 维度表技术\n10.1 增加列 278\n10.2 维度子集 285\n10.3 角色扮演维度 292\n10.4 层次维度 298\n10.4.1 固定深度的层次 299\n10.4.2 递归 302\n10.4.3 多路径层次 310\n10.4.4 参差不齐的层次 312\n10.5 退化维度 313\n10.6 杂项维度 316\n10.7 维度合并 323\n10.8 分段维度 329\n10.9 小结 335\n第11章 事实表技术\n11.1 事实表概述 336\n11.2 周期快照 337\n11.3 累积快照 343\n11.4 无事实的事实表 349\n11.5 迟到的事实 354\n11.6 累积度量 360\n11.7 小结 366\n第12章 联机分析处理\n12.1 联机分析处理简介 367\n12.1.1 概念 367\n12.1.2 分类 368\n12.1.3 性能 371\n12.2 Impala简介 371\n12.3 Hive、SparkSQL、Impala比较 377\n12.3.1 Spark SQL简介 377\n12.3.2 Hive、Spark SQL、Impala比较 379\n12.3.3 Hive、Spark SQL、Impala性能对比 382\n12.4 联机分析处理实例 387\n12.5 Apache Kylin与OLAP 399\n12.5.1 Apache Kylin架构 399\n12.5.2 Apache Kylin安装 401\n12.6 小结 407\n第13章 数据可视化\n13.1 数据可视化简介 408\n13.2 Hue简介 410\n13.2.1 Hue功能快速预览 411\n13.2.2 配置元数据存储 412\n13.3 Zeppelin简介 415\n13.3.1 Zeppelin架构 415\n13.3.2 Zeppelin安装配置 416\n13.3.3 在Zeppelin中添加MySQL翻译器 421\n13.4 Hue、Zeppelin比较 425\n13.5 数据可视化实例 426\n13.6 小结 434","ebook_url":"https:\/\/read.douban.com\/ebook\/40133829\/","pages":"434","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29481723.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29481723.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29481723.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27075781\/","id":"27075781","publisher":"清华大学出版社","isbn10":"7302469806","isbn13":"9787302469803","title":"Hadoop构建数据仓库实践","url":"https:\/\/api.douban.com\/v2\/book\/27075781","alt_title":"","author_intro":"王雪迎，毕业于中国地质大学计算机专业，高级工程师，拥有20年数据库、数据仓库相关技术经验。曾先后供职于北京现代商业信息技术有限公司、北京在线九州信息技术服务有限公司、华北计算技术研究所、北京优贝在线网络科技有限公司，担任DBA、数据架构师等职位。","summary":"","ebook_price":"44.50","price":"89.00"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["[印] Sandeep Karanth"],"pubdate":"2016-1","tags":[{"count":2,"name":"大数据","title":"大数据"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"开发","title":"开发"},{"count":1,"name":"图灵推荐","title":"图灵推荐"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28371739.jpg","binding":"平装","translator":["刘　淼","唐觊隽","陈智威"],"catalog":"第1章　Hadoop 2.X　　1\n1.1　Hadoop的起源　　1\n1.2　Hadoop的演进　　2\n1.3　Hadoop 2.X　　6\n1.3.1　Yet Another Resource Negotiator（YARN）　　7\n1.3.2　存储层的增强　　8\n1.3.3　支持增强　　11\n1.4　Hadoop的发行版　　11\n1.4.1　选哪个Hadoop发行版　　12\n1.4.2　可用的发行版　　14\n1.5　小结　　16\n第2章　MapReduce进阶　　17\n2.1　MapReduce输入　　18\n2.1.1　InputFormat类　　18\n2.1.2　InputSplit类　　18\n2.1.3　RecordReader类　　19\n2.1.4　Hadoop的“小文件”问题　　20\n2.1.5　输入过滤　　24\n2.2　Map任务　　27\n2.2.1　dfs.blocksize属性　　28\n2.2.2　中间输出结果的排序与溢出　　28\n2.2.3　本地reducer和Combiner　　31\n2.2.4　获取中间输出结果——Map 侧　　31\n2.3　Reduce任务　　32\n2.3.1　获取中间输出结果——Reduce侧　　32\n2.3.2　中间输出结果的合并与溢出　　33\n2.4　MapReduce的输出　　34\n2.5　MapReduce作业的计数器　　34\n2.6　数据连接的处理　　36\n2.6.1　Reduce侧的连接　　36\n2.6.2　Map侧的连接　　42\n2.7　小结　　45\n第3章　Pig进阶　　47\n3.1　Pig对比SQL　　48\n3.2　不同的执行模式　　48\n3.3　Pig的复合数据类型　　49\n3.4　编译Pig脚本　　50\n3.4.1　逻辑计划　　50\n3.4.2　物理计划　　51\n3.4.3　MapReduce计划　　52\n3.5　开发和调试助手　　52\n3.5.1　DESCRIBE命令　　52\n3.5.2　EXPLAIN命令　　53\n3.5.3　ILLUSTRATE命令　　53\n3.6　Pig 操作符的高级特性　　54\n3.6.1　FOREACH操作符进阶　　54\n3.6.2　Pig的特殊连接　　58\n3.7　用户定义函数　　61\n3.7.1　运算函数　　61\n3.7.2　加载函数　　66\n3.7.3　存储函数　　68\n3.8　Pig的性能优化　　69\n3.8.1　优化规则　　69\n3.8.2　Pig脚本性能的测量　　71\n3.8.3　Pig的Combiner　　72\n3.8.4　Bag数据类型的内存　　72\n3.8.5　Pig的reducer数量　　72\n3.8.6　Pig的multiquery模式　　73\n3.9　最佳实践　　73\n3.9.1　明确地使用类型　　74\n3.9.2　更早更频繁地使用投影　　74\n3.9.3　更早更频繁地使用过滤　　74\n3.9.4　使用LIMIT操作符　　74\n3.9.5　使用DISTINCT操作符　　74\n3.9.6　减少操作　　74\n3.9.7　使用Algebraic UDF　　75\n3.9.8　使用Accumulator UDF　　75\n3.9.9　剔除数据中的空记录　　75\n3.9.10　使用特殊连接　　75\n3.9.11　压缩中间结果　　75\n3.9.12　合并小文件　　76\n3.10　小结　　76\n第4章　Hive进阶　　77\n4.1　Hive架构　　77\n4.1.1　Hive元存储　　78\n4.1.2　Hive编译器　　78\n4.1.3　Hive执行引擎　　78\n4.1.4　Hive的支持组件　　79\n4.2　数据类型　　79\n4.3　文件格式　　80\n4.3.1　压缩文件　　80\n4.3.2　ORC文件　　81\n4.3.3　Parquet文件　　81\n4.4　数据模型　　82\n4.4.1　动态分区　　84\n4.4.2　Hive表索引　　85\n4.5　Hive查询优化器　　87\n4.6　DML进阶　　88\n4.6.1　GROUP BY操作　　88\n4.6.2　ORDER BY与SORT BY　　88\n4.6.3　JOIN类型　　88\n4.6.4　高级聚合　　89\n4.6.5　其他高级语句　　90\n4.7　UDF、UDAF和UDTF　　90\n4.8　小结　　93\n第5章　序列化和Hadoop I\/O　　95\n5.1　Hadoop数据序列化　　95\n5.1.1　Writable与WritableComparable　　96\n5.1.2　Hadoop与Java序列化的区别　　 98\n5.2　Avro序列化　　100\n5.2.1　Avro与MapReduce　　102\n5.2.2　Avro与Pig　　105\n5.2.3　Avro与Hive　　106\n5.2.4　比较Avro与Protocol Buffers\/Thrift　　107\n5.3　文件格式　　108\n5.3.1　Sequence文件格式　　108\n5.3.2　MapFile格式　　111\n5.3.3　其他数据结构　　113\n5.4　压缩　　113\n5.4.1　分片与压缩　　114\n5.4.2　压缩范围　　115\n5.5　小结　　115\n第6章　YARN——其他应用模式进入Hadoop的引路人　　116\n6.1　YARN的架构　　117\n6.1.1　资源管理器　　117\n6.1.2　Application Master　　118\n6.1.3　节点管理器　　119\n6.1.4　YARN客户端　　120\n6.2　开发YARN的应用程序　　120\n6.2.1　实现YARN客户端　　120\n6.2.2　实现AM实例　　125\n6.3　YARN的监控　　129\n6.4　YARN中的作业调度　　134\n6.4.1　容量调度器　　134\n6.4.2　公平调度器　　137\n6.5　YARN命令行　　139\n6.5.1　用户命令　　140\n6.5.2　管理员命令　　140\n6.6　小结　　141\n第7章　基于YARN的Storm——Hadoop中的低延时处理　　142\n7.1　批处理对比流式处理　　142\n7.2　Apache Storm　　144\n7.2.1　Apache Storm的集群架构　　144\n7.2.2　Apache Storm的计算和数据模型　　145\n7.2.3　Apache Storm用例　　146\n7.2.4　Apache Storm的开发　　147\n7.2.5　Apache Storm 0.9.1　　153\n7.3　基于YARN的Storm　　154\n7.3.1　在YARN上安装Apache Storm　　154\n7.3.2　安装过程　　154\n7.4　小结　　161\n第8章　云上的Hadoop　　162\n8.1　云计算的特点　　162\n8.2　云上的Hadoop　　163\n8.3　亚马逊Elastic MapReduce　　164\n8.4　小结　　175\n第9章　HDFS替代品　　176\n9.1　HDFS的优缺点　　176\n9.2　亚马逊AWS S3　　177\n9.3　在Hadoop中实现文件系统　　179\n9.4　在Hadoop中实现S3原生文件系统　　179\n9.5　小结　　189\n第10章　HDFS联合　　190\n10.1　旧版HDFS架构的限制　　190\n10.2　HDFS联合的架构　　192\n10.2.1　HDFS联合的好处　　193\n10.2.2　部署联合NameNode　　193\n10.3　HDFS高可用性　　195\n10.3.1　从NameNode、检查节点和备份节点　　195\n10.3.2　高可用性——共享edits　　196\n10.3.3　HDFS实用工具　　197\n10.3.4　三层与四层网络拓扑　　197\n10.4　HDFS块放置策略　　198\n10.5　小结　　200\n第11章　Hadoop安全　　201\n11.1　安全的核心　　201\n11.2　Hadoop中的认证　　202\n11.2.1　Kerberos认证　　202\n11.2.2　Kerberos的架构和工作流　　203\n11.2.3　Kerberos认证和Hadoop　　204\n11.2.4　HTTP接口的认证　　204\n11.3　Hadoop中的授权　　205\n11.3.1　HDFS的授权　　205\n11.3.2　限制HDFS的使用量　　208\n11.3.3　Hadoop中的服务级授权　　209\n11.4　Hadoop中的数据保密性　　211\n11.5　Hadoop中的日志审计　　216\n11.6　小结　　217\n第12章　使用Hadoop进行数据分析　　 218\n12.1　数据分析工作流　　218\n12.2　机器学习　　220\n12.3　Apache Mahout　　222\n12.4　使用Hadoop和Mahout进行文档分析　　223\n12.4.1　词频　　223\n12.4.2　文频　　224\n12.4.3　词频－逆向文频　　224\n12.4.4　Pig中的Tf-idf　　225\n12.4.5　余弦相似度距离度量　　228\n12.4.6　使用k-means 的聚类　　228\n12.4.7　使用Apache Mahout进行k-means聚类　　229\n12.5　RHadoop　　233\n12.6　小结　　233\n附录 微软Windows中的Hadoop　　235","pages":"268","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28371739.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28371739.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28371739.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26696632\/","id":"26696632","publisher":"人民邮电出版社","isbn10":"7115411050","isbn13":"9787115411051","title":"精通Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26696632","alt_title":"","author_intro":"Sandeep Karanth\nScibler公司联合创始人，负责数据智能产品的架构；DataPhi Labs公司联合创始人兼首席架构师，专注于构建和实施软件系统。他拥有14年以上的软件行业从业经验，既设计过企业数据应用，也开发过新一代移动应用。他曾就职于微软总部和微软印度研究院。他的Twitter账号是@karanths，GitHub账号是https:\/\/github.com\/Karanth。","summary":"本书是一本循序渐进的指导手册，重点介绍了Hadoop的高级概念和特性。内容涵盖了Hadoop 2.X版的改进，MapReduce、Pig和Hive等的优化及其高级特性，Hadoop 2.0的专属特性（如YARN和HDFS联合），以及如何使用Hadoop 2.0版本扩展Hadoop的能力。\n如果你想拓展自己的Hadoop知识和技能，想应对具有挑战性的数据处理问题，想让Hadoop作业、Pig脚本和Hive查询运行得更快，或者想了解升级Hadoop的好处，那么本书便是你的不二选择。\n通过阅读本书，你将能够：\n理解从Hadoop 1.0到Hadoop 2.0的变化\n定制和优化Hadoop 2.0中的MapReduce作业\n探究Hadoop I\/O和不同的数据格式\n深入学习YARN和Storm，并通过YARN集成Hadoop和Storm\n基于亚马逊Elastic MapReduce部署Hadoop\n探究HDFS替代品，学习HDFS联合\n掌握Hadoop安全方面的主要内容\n使用Mahout和RHadoop进行Hadoop数据分析","price":"49.00元"},{"rating":{"max":10,"numRaters":8,"average":"0.0","min":0},"subtitle":"","author":["张良均","樊哲","赵云龙","李成华"],"pubdate":"2015-12-1","tags":[{"count":7,"name":"数据挖掘","title":"数据挖掘"},{"count":6,"name":"数据分析","title":"数据分析"},{"count":5,"name":"大数据","title":"大数据"},{"count":2,"name":"【已读1】","title":"【已读1】"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"挖掘实战","title":"挖掘实战"},{"count":1,"name":"大数据分析","title":"大数据分析"},{"count":1,"name":"【已购】","title":"【已购】"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28552777.jpg","binding":"平装","translator":[],"catalog":"前　言\n基　础　篇\n第1章　数据挖掘基础2\n1.1　某知名连锁餐饮企业的困惑2\n1.2　从餐饮服务到数据挖掘3\n1.3　数据挖掘的基本任务4\n1.4　数据挖掘建模过程4\n1.4.1　定义挖掘目标4\n1.4.2　数据取样5\n1.4.3　数据探索6\n1.4.4　数据预处理12\n1.4.5　挖掘建模14\n1.4.6　模型评价14\n1.5　餐饮服务中的大数据应用15\n1.6　小结15\n第2章　Hadoop基础16\n2.1　概述16\n2.1.1　Hadoop简介16\n2.1.2　Hadoop生态系统17\n2.2　安装与配置19\n2.3　Hadoop原理26\n2.3.1　Hadoop HDFS原理26\n2.3.2　Hadoop MapReduce原理27\n2.3.3　Hadoop YARN原理28\n2.4　动手实践30\n2.5　小结33\n第3章　Hadoop生态系统：Hive34\n3.1　概述34\n3.1.1　Hive简介34\n3.1.2　Hive安装与配置35\n3.2　Hive原理38\n3.2.1　Hive架构38\n3.2.2　Hive的数据模型40\n3.3　动手实践41\n3.4　小结45\n第4章　Hadoop生态系统：HBase46\n4.1　概述46\n4.1.1　HBase简介46\n4.1.2　HBase安装与配置47\n4.2　HBase原理50\n4.2.1　HBase架构50\n4.2.2　HBase与RDBMS51\n4.2.3　HBase访问接口52\n4.2.4　HBase数据模型53\n4.3　动手实践54\n4.4　小结61\n第5章　大数据挖掘建模平台62\n5.1　常用的大数据平台62\n5.2　TipDM-HB大数据挖掘建模平台63\n5.2.1　TipDM-HB大数据挖掘建模平台的功能63\n5.2.2　TipDM-HB大数据挖掘建模平台操作流程及实例65\n5.2.3　TipDM-HB大数据挖掘建模平台的特点67\n5.3　小结68\n第6章　挖掘建模69\n6.1　分类与预测69\n6.1.1　实现过程69\n6.1.2　常用的分类与预测算法70\n6.1.3　决策树71\n6.1.4　Mahout中Random Forests算法的实现原理75\n6.1.5　动手实践79\n6.2　聚类分析83\n6.2.1　常用聚类分析算法83\n6.2.2　K-Means聚类算法84\n6.2.3　Mahout中K-Means算法的实现原理88\n6.2.4　动手实践90\n6.3　关联规则93\n6.3.1　常用的关联规则算法93\n6.3.2　FP-Growth关联规则算法94\n6.3.3　Mahout中Parallel Frequent Pattern Mining算法的实现原理98\n6.3.4　动手实践100\n6.4　协同过滤102\n6.4.1　常用的协同过滤算法102\n6.4.2　基于项目的协同过滤算法简介102\n6.4.3　Mahout中Itembased Collaborative Filtering算法的实现原理103\n6.4.4　动手实践106\n6.5　小结109\n实　战　篇\n第7章　法律咨询数据分析与服务推荐112\n7.1　背景与挖掘目标112\n7.2　分析方法与过程114\n7.2.1　数据抽取120\n7.2.2　数据探索分析120\n7.2.3　数据预处理125\n7.2.4　模型构建130\n7.3　上机实验139\n7.4　拓展思考140\n7.5　小结145\n第8章　电商产品评论数据情感分析146\n8.1　背景与挖掘目标146\n8.2　分析方法与过程146\n8.2.1　评论数据采集147\n8.2.2　评论预处理150\n8.2.3　文本评论分词155\n8.2.4　构建模型155\n8.3　上机实验167\n8.4　拓展思考168\n8.5　小结169\n第9章　航空公司客户价值分析170\n9.1　背景与挖掘目标170\n9.2　分析方法与过程171\n9.2.1　数据抽取174\n9.2.2　数据探索分析174\n9.2.3　数据预处理175\n9.2.4　模型构建177\n9.3　上机实验182\n9.4　拓展思考183\n9.5　小结183\n第10章　基站定位数据商圈分析184\n10.1　背景与挖掘目标184\n10.2　分析方法与过程186\n10.2.1　数据抽取186\n10.2.2　数据探索分析187\n10.2.3　数据预处理188\n10.2.4　构建模型191\n10.3　上机实验194\n10.4　拓展思考195\n10.5　小结195\n第11章　互联网电影智能推荐196\n11.1　背景与挖掘目标196\n11.2　分析方法与过程197\n11.2.1　数据抽取199\n11.2.2　构建模型199\n11.3　上机实验201\n11.4　拓展思考202\n11.5　小结203\n第12章　家电故障备件储备预测分析204\n12.1　背景与挖掘目标204\n12.2　分析方法与过程206\n12.2.1　数据探索分析207\n12.2.2　数据预处理209\n12.2.3　构建模型212\n12.3　上机实验216\n12.4　拓展思考217\n12.5　小结217\n第13章　市供水混凝投药量控制分析218\n13.1　背景与挖掘目标218\n13.2　分析方法与过程220\n13.2.1　数据抽取221\n13.2.2　数据探索分析221\n13.2.3　数据预处理223\n13.2.4　构建模型227\n13.3　上机实验237\n13.4　拓展思考238\n13.5　小结239\n第14章　基于图像处理的车辆压双黄线检测240\n14.1　背景与挖掘目标240\n14.2　分析方法与过程241\n14.2.1　数据抽取242\n14.2.2　数据探索分析242\n14.2.3　数据预处理242\n14.2.4　构建模型249\n14.3　上机实验250\n14.4　拓展思考250\n14.5　小结251\n高　级　篇\n第15章　基于Mahout的大数据挖掘开发254\n15.1　概述254\n15.2　环境配置255\n15.3　基于Mahout算法接口的二次开发258\n15.3.1　Mahout算法实例258\n15.3.2　Mahout算法接口的二次开发示例259\n15.4　小结271\n第16章　基于TipDM-HB的数据挖掘二次开发272\n16.1　概述272\n16.1.1　TipDM-HB大数据挖掘建模平台服务接口272\n16.1.2　Apache CXF简介276\n16.2　TipDM-HB大数据挖掘建模平台服务开发实例277\n16.2.1　环境配置277\n16.2.2　开发实例280\n16.3　小结288\n参考资料289","pages":"289","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28552777.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28552777.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28552777.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26755994\/","id":"26755994","publisher":"机械工业出版社","isbn10":"7111522656","isbn13":"9787111522652","title":"Hadoop大数据分析与挖掘实战","url":"https:\/\/api.douban.com\/v2\/book\/26755994","alt_title":"","author_intro":"","summary":"《Hadoop大数据分析与挖掘实战》共14章，分三个部分：基础篇、实战篇、高级篇。基础篇介绍了数据挖掘、Hadoop大数据的基本原理，实战篇介绍了一个个真实案例，通过对案例深入浅出的剖析，使读者在不知不觉中通过案例实践获得大数据项目挖掘分析经验，同时快速领悟看似难懂的大数据分析与挖掘理论知识。读者在阅读过程中，应充分利用随书配套的案例建模数据，借助TipDM-HB大数据挖掘建模平台，通过上机实验，以快速理解相关知识与理论。","series":{"id":"19432","title":"大数据技术丛书"},"price":"69.00元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Alex Holmes"],"pubdate":"2014-10-12","tags":[{"count":1,"name":"工程","title":"工程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27755759.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"512","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27755759.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27755759.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27755759.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26238123\/","id":"26238123","publisher":"Manning Publications","isbn10":"1617292222","isbn13":"9781617292224","title":"Hadoop in Practice","url":"https:\/\/api.douban.com\/v2\/book\/26238123","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"High-impact Strategies - What You Need to Know: Definitions, Adoptions, Impact, Benefits, Maturity, Vendors","author":["Kevin Roebuck"],"pubdate":"2011-6-13","tags":[{"count":1,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"数据库","title":"数据库"},{"count":1,"name":"nosql","title":"nosql"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s7057775.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"232","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s7057775.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s7057775.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s7057775.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10462723\/","id":"10462723","publisher":"Tebbo","isbn10":"1743045743","isbn13":"9781743045749","title":"Storing and managing big data- NoSql, Hadoop and more","url":"https:\/\/api.douban.com\/v2\/book\/10462723","alt_title":"","author_intro":"","summary":"","price":"USD 49.97"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["Benjamin Bengfort","Jenny Kim"],"pubdate":"2015-10-25","tags":[{"count":1,"name":"数据分析","title":"数据分析"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28110794.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"150","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28110794.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28110794.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28110794.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26425879\/","id":"26425879","publisher":"O'Reilly Media","isbn10":"1491913703","isbn13":"9781491913703","title":"Data Analytics with Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26425879","alt_title":"","author_intro":"","summary":"","price":"USD 24.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["赵书兰"],"pubdate":"2013-1","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"云计算","title":"云计算"},{"count":1,"name":"TP393计算机技术","title":"TP393计算机技术"},{"count":1,"name":"!B2专业学习","title":"!B2专业学习"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24502960.jpg","binding":"","translator":[],"catalog":"","pages":"475","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s24502960.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s24502960.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24502960.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20411529\/","id":"20411529","publisher":"","isbn10":"7121188074","isbn13":"9787121188077","title":"典型Hadoop云计算","url":"https:\/\/api.douban.com\/v2\/book\/20411529","alt_title":"","author_intro":"","summary":"《典型Hadoop云计算》系统地阐述了当今IT业界最热门的话题——云计算，全书共分为9章。第1章介绍云计算背景与Hadoop；第2章介绍Hadoop的安装与配置；第3～8章系统、详细地介绍了Hadoop的子项目及相关项目的基本概念和实例分析，主要包括Hadoop的MapReduce、ZooKeeper、Mahout、Avro、Chukwa、HBase、Hive、Pig及Cassandra等项目；第9章总结了Hadoop云计算的综合实例。可以作为高等学校教材，也可供广大科研人员、工程技术人员自学或参考。","price":"65.00元"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["【美】Rajiv Tiwari"],"pubdate":"2017-5","tags":[{"count":2,"name":"大数据","title":"大数据"},{"count":1,"name":"金融","title":"金融"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29419064.jpg","binding":"平装","translator":["王小宁"],"catalog":"第1 章　大数据回顾 1\n大数据是什么 1\n数据量 2\n数据速度  2\n数据类型  3\n大数据技术的演进  3\n过去  3\n现在  4\n未来  5\n大数据愿景  5\n存储  6\nNoSQL  6\nNoSQL 数据库类型  7\n资源管理  7\n数据治理  8\n批量计算  8\n实时计算  8\n数据整合工具 9\n机器学习  9\n商务智能和可视化  9\n大数据相关的职业  10\nHadoop 架构 11\nHDFS 集群  12\nMapReduce V1  14\nMapReduce V2——YARN  15\nHadoop 生态圈简介  18\n驯服大数据  18\nHadoop——英雄  19\nHDFS——Hadoop 分布式系统 19\nHadoop 版本  23\n发行版——本地部署  25\n发行版——云端 27\n总结  28\n第2 章　金融服务中的大数据 29\n各个行业的大数据使用情况  29\n卫生保健 30\n人类科学 30\n电信  31\n在线零售商  31\n为什么金融部门需要大数据  31\n金融部门的大数据应用案例  34\nHDFS 上的数据归档  34\n监管  35\n欺诈检测 35\n交易数据 36\n风险管理 36\n客户行为预测  36\n情感分析——非结构化 36\n其他应用案例  37\n金融大数据的演进过程 37\n应该如何学习金融大数据  41\n把你的数据上传到HDFS 上 41\n从HDFS 上查询数据 42\n在Hadoop 上的SQL 43\n实时  44\n数据治理和运营 44\nETL 工具  45\n数据分析和商业智能  45\n金融大数据的实现  46\n关键挑战 46\n克服挑战 47\n总结  50\n第3 章　在云端使用Hadoop. 51\n大数据云的故事 51\n原因  52\n时机  53\n收获  54\n项目细节——在云中进行风险模拟  54\n解决方案 55\n现实世界 55\n目标世界 57\n数据转换 60\n数据分析 62\n总结  63\n第4 章　使用Hadoop 进行数据迁移. 65\n项目细节——归档你的交易数据 65\n解决方案 67\n项目第一阶段——分裂交易数据到数据仓库和Hadoop 68\n项目第二阶段——完成数据从关系型数据仓库到Hadoop 的迁移  77\n总结  83\n第5 章　入门 85\n项目详细信息——风险和监管报告  86\n解决方案 87\n现实世界 87\n目标世界 88\n数据收集 89\n数据转换 97\n数据分析 112\n总结 116\n第6 章　变得有经验. 117\n实时大数据 117\n项目细节——识别欺诈交易 119\n解决方案  120\n现实世界  120\n目标世界  120\n马尔科夫链模型执行——批处理模式  121\n数据收集  126\n数据转换  128\n总结 132\n第7 章　深入扩展Hadoop 的企业级应用. 133\n扩展开来——实际上的水平 134\n更多的大数据使用案例  135\n使用案例——再谈欺诈问题  136\n解决方案  136\n使用案例——用户投诉  137\n解决方案  137\n使用案例——算法交易  137\n解决方案  138\n使用案例——外汇交易  138\n解决方案  138\n使用案例——基于社交媒体的交易数据 139\n解决方案  139\n使用案例——非大数据  140\n解决方案  140\n数据湖  140\nLambda 架构  143\n大数据管理 144\nApache Falcon 概览  146\n安全性  147\n总结 149\n第8 章　Hadoop 的快速增长 151\nHadoop 发行版的升级周期  151\n最佳实践和标准  154\n环境 154\n与BI 和ETL 工具的集成 155\n提示 155\n新的趋势  157\n总结 158","pages":"176","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29419064.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29419064.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29419064.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27013711\/","id":"27013711","publisher":"电子工业出版社","isbn10":"7121310511","isbn13":"9787121310515","title":"Hadoop金融大数据分析","url":"https:\/\/api.douban.com\/v2\/book\/27013711","alt_title":"","author_intro":"Rajiv Tiwari 是一位有着超过 15年经验的自由大数据架构师，他的研究方向包括大数据、数据分析、数据管理、数据架构、数据清洗 \/数据整合、数据仓库，以及银行和其他金融组织中的数据智能等。\n他毕业于瓦拉纳西印度理工学院（ IIT）电子工程专业，在英国工作了 10年有余，大部分时间居住在英国金融城——伦敦。从 2010年起， Rajiv 就开始使用 Hadoop，当时银行部门使用 Hadoop 的还很少。他目前正在帮助 1级投资银行（ Tier 1 Investment Bank）在 Hadoop平台上实施一个大型风险分析项目。\n如果想联系 Rajiv，则可以通过他的网站 http:\/\/www.bigdatacloud.net或推特 @ bigdataoncloud。\n我一直认为当作家把自己的书献给他们的妻子、合作伙伴或孩子时有点俗气，但是近几个月来，让我明白了为什么一个家庭的支持对写一本书那么重要。\n考虑到我目前在投资银行每天工作时间很长，且很难抽出时间来写这本书，所以，我一直在深夜和周末写这本书。我要感谢我的妻子 Seema，她几乎帮我照料一切能分散我写作注意力的东西；还有我的儿子 Rivaan。\n审稿人简介\nHarshit Bakliwal 是一位印度领先的 IT公司的 Hadoop开发者。他有 6年左右的工作经验和超过 3年的大数据 \/Hadoop经验。他从 2010年开始使用 Hadoop，当时 Hadoop 刚刚在科技界崭露头角，并没有太多的在线帮助。从那时起，他继续用自己的方式学习这门语言及其他高水平的语言，如 Pig、 Hive、Sqoop、Oozie和 HBase。现如今他能处理 4～ 5个集群（每个集群大约有 200个节点）上 PB级的数据。\nDr.Daniel Fasel是 Scigility 公司的创始人和 CEO。Scigility公司为瑞士和欧洲其他国家的大规模信息系统和大数据技术提供解决方案。它的专业团队在大数据技术上有超过 7年的极强的学术背景和实际知识经验。\n他是瑞士电信（瑞士第一大电信运营商）商业智能团队的第一位数据科学家，并在就职期间实现了 NoSQL技术在瑞士电信公司的探索性分析技术。在注重科学数据和 NoSQL技术之前，他是合同和客户域（瑞士电信数据仓库的核心组件）的商业智能工程师。他还担任商业情报架构师和 Oracle Hyperion Essbase立方体管理员。\n他在瑞士福里堡大学（ University of Fribourg）获得经济学博士学位。他写了一篇关于模糊数据仓库的文章，让他获得了最高的成绩。除了他的博士研究，他一直担任福里堡大学信息学系的系统工程师和系统管理员团队的领导。2009年（当时大数据还不是一个流行词），他安装和维护了分布式计算集群和 NoSQL技术。他还经常在大数据和数据仓库领域出版英语或德语的书籍与文章。\nMark Reddy 是软件工程师和分布式系统爱好者。他从爱尔兰的高威梅奥理工学院（ Galway-Mayo Institute of Technology）荣誉毕业后，曾在 Hewlett-Packard 和 Avaeon Solutions公司任职。他目前在 Boxever工作，这是一家专\n注于旅游行业大数据和预测分析的爱尔兰初创企业。他使用 Hadoop、Spark、 Cassandra、ZooKeeper、Storm、Kafka等工具设计并实现了大规模分布式的解决方案，这些系统处理的数据达 TB级。他喜欢利用他的知识和经验为开源项目做贡献，并对行业热点话题进行公开演讲。\n当他不写代码的时候，他喜欢公开演讲或写博客（ http:\/\/markreddy.ie\/），他也喜欢旅游、健身，以及发推特随想 @ markreddy。","summary":"随着数据的增长以及企业每天处理越来越多的数据， Hadoop作为一个数据平台已经变得很流行。金融行业想要最小化风险和最大化收益， Hadoop作为一个主宰大数据市场的工具，在其中起着很大的作用。\n《Hadoop金融大数据分析》介绍了大数据和 Hadoop的基础知识，让读者掌握项目管理、欺诈检测等 TOP大数据金融项目，其中不仅包含行业参考和代码模板，同时包括实现中使用的多个 Hadoop组件。\n读完《Hadoop金融大数据分析》，读者会理解一些行业领先的架构模式、大数据管理经验、窍门和大数据最佳实践方案，以便基于 Hadoop成功地开发出适合自己的解决方案。","price":"59"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Jian, Li"],"pubdate":"","tags":[{"count":1,"name":"架构","title":"架构"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s21698218.jpg","binding":"","translator":[],"catalog":"","pages":"68","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s21698218.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s21698218.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s21698218.jpg"},"alt":"https:\/\/book.douban.com\/subject\/18020981\/","id":"18020981","publisher":"","isbn10":"3659155160","isbn13":"9783659155161","title":"Large Scale Data Processing in Hadoop Mapreduce Scenario","url":"https:\/\/api.douban.com\/v2\/book\/18020981","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":4,"name":"大数据","title":"大数据"},{"count":3,"name":"人工智能","title":"人工智能"},{"count":1,"name":"Spark","title":"Spark"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29475343.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29475343.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29475343.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29475343.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26989525\/","id":"26989525","publisher":"","isbn10":"7302453756","isbn13":"9787302453758","title":"Hadoop+Spark大数据巨量分析与机器学习整合开发实战","url":"https:\/\/api.douban.com\/v2\/book\/26989525","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["李宁"],"pubdate":"2013-9-17","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27064604.jpg","binding":"平装","translator":[],"catalog":"前言\n理论部分\t1\n第1章 云计算理论\t1\n1.1 云计算的概念\t1\n1.2 云计算发展现状\t1\n1.3 网格计算与云计算\t4\n1.4 云计算的发展环境\t5\n1.5 各大IT厂商云计算平台特点概述\t8\n1.6 开源云计算系统概述\t20\n第2章 Hadoop理论\t27\n2.1 Hadoop简介\t27\n2.2 Hadoop架构\t28\n2.3 Hadoop分布式文件系统HDFS\t29\n2.4 分布式数据处理MapReduce\t33\n第3章 Linux命令操作\t35\n3.1 Linux操作系统介绍\t35\n3.2 Linux常用shell命令\t36\n基础实践部分\t40\n第4章 集群搭建\t40\n4.1 CentOS安装\t40\n4.1.1 实验目的\t40\n4.1.2 实验设备\t40\n4.1.3 实验内容\t40\n4.1.4 实验步骤\t40\n4.2 集群搭建\t57\n4.2.1 实验目的\t57\n4.2.2 实验设备\t57\n4.2.3 实验内容\t57\n4.2.4 实验步骤\t57\n4.3 获取Hadoop安装包\t79\n4.3.1 实验目的\t79\n4.3.2 实验设备\t79\n4.3.3 实验内容\t79\n4.3.4 实验步骤\t79\n4.4 启动和关闭hadoop集群\t83\n4.4.1 实验目的\t83\n4.4.2 实验设备\t83\n4.4.3 实验内容\t83\n4.4.4 实验步骤\t83\n第5章 熟悉Hadoop本地集群\t87\n5.1 熟悉hadoop一些常用命令\t87\n5.1.1 实验目的\t87\n5.1.2 实验设备\t87\n5.1.3 实验内容\t87\n5.1.4 实验步骤\t87\n5.2 使用distcp进行并行复制\t91\n5.3 Web浏览Hadoop集群\t92\n5.3.1 实验目的\t92\n5.3.2 实验设备\t92\n5.3.3 实验内容\t92\n5.3.4 实验步骤\t92\n5.4 使用hadoop命令归档文件\t93\n第6章 Hadoop管理应用\t96\n6.1 系统体检和报告\t96\n6.2 了解HDFS的平衡命令\t98\n6.3 权限设置\t99\n6.4 配额管理\t99\n6.5 启用回收站\t99\n第7章 HDFS实践\t101\n7.1 使用HDFS上传文件\t101\n7.1.1 实验目的\t101\n7.1.2 实验设备\t101\n7.1.3 实验内容\t101\n7.1.4 实验原理\t101\n7.1.5 实验步骤\t102\n7.2 使用HDFS浏览文件和目录\t104\n7.2.1 实验目的\t104\n7.2.2 实验设备\t104\n7.2.3 实验内容\t104\n7.2.4 实验原理\t105\n7.2.5 实验步骤\t107\n7.3 使用HDFS打开、下载和删除文件\t108\n7.3.1 实验目的\t108\n7.3.2 实验设备\t108\n7.3.3 实验内容\t108\n7.3.4 实验原理\t108\n7.3.5 实验步骤\t110\n第8章 MapReduce实践\t113\n8.1 数据去重实验\t113\n8.1.1 实验目的\t113\n8.1.2 实验设备\t113\n8.1.3 实验内容\t113\n8.1.4 实验原理\t114\n8.1.5 实验步骤\t116\n8.2 数据排序实验\t119\n8.2.1 实验目的\t119\n8.2.2 实验设备\t119\n8.2.3 实验内容\t120\n8.2.4 实验原理\t121\n8.2.5 实验步骤\t123\n8.3 平均成绩实验\t126\n8.3.1 实验目的\t126\n8.3.2 实验设备\t126\n8.3.3 实验内容\t126\n8.3.4 实验原理\t126\n8.3.5 实验步骤\t129\n8.4 单表关联实验\t131\n8.4.1 实验目的\t131\n8.4.2 实验设备\t131\n8.4.3 实验内容\t131\n8.4.4 实验原理\t133\n8.4.5 实验步骤\t137\n项目实训\t142\n第9章 个人存储私有云综合实训\t142\n9.1 实验目的\t142\n9.2 实验设备\t142\n9.3 实验内容\t142\n9.4 实验原理\t142\n9.5 实验步骤\t146\n第10章 气象数据分析云综合实训\t155\n10.1 实验目的\t155\n10.2 实验设备\t155\n10.3 实验内容\t155\n10.4 实验原理\t155\n10.5 实验步骤\t161\n第11章 微信人物关系综合实训\t165\n11.1 实验目的\t165\n11.2 实验设备\t165\n11.3 实验内容\t165\n11.4 实验原理\t165\n11.5 实验步骤\t173\n第12章 云图书馆实例综合实训\t178\n12.1 实验目的\t178\n12.2 实验设备\t178\n12.3 实验内容\t178\n12.4 实验原理\t178\n12.5 实验步骤\t188\n第13章 物联网与云计算（快递）实例\t192\n13.1 实验目的\t192\n13.2 实验设备\t192\n13.3 实验内容\t192\n13.4 实验原理\t192\n13.5 实验步骤\t197\n参考文献\t203","pages":"212","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27064604.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27064604.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27064604.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25735030\/","id":"25735030","publisher":"机械工业出版社","isbn10":"711143496X","isbn13":"9787111434962","title":"Hadoop云计算一体机实践指南","url":"https:\/\/api.douban.com\/v2\/book\/25735030","alt_title":"","author_intro":"","summary":"全书书分为3篇：第1篇（理论部分）对云计算、Hadoop及Linux操作系统进行了简单介绍；第2篇（基础实践部分）主要详细介绍了CentOS系统的安装和集群的搭建、Hadoop集群的常用命令及管理应用等；第3篇（项目实训部分）主要以实际项目开发为例，从易到难，对源程序进行了详细解释。\n本书以详细的实践操作介绍为特色，可作为电子、通信、自动化、计算机等电类专业Hadoop云计算教学系统课程实验教材，也可供Hadoop系统相关工程技术人员参考。","price":"39.90元"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["凯文·斯托 (Kevin Sitto)","马歇尔·普瑞斯 (Marshall Presser)"],"pubdate":"2016-11-1","tags":[{"count":1,"name":"科普","title":"科普"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"IT","title":"IT"}],"origin_title":"凯文·斯托 (Kevin Sitto)","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29413936.jpg","binding":"平装","translator":["陈新"],"catalog":"前言\n第1章关键技术\n1.1 Hadoop分布式文件系统（HDFS）\n1.2 MapReduce\n1.3 YARN\n1.4 Spark\n第2章数据库及数据管理\n2.1 Cassandra\n2.2 HBase\n2.3 Accumulo\n2.4 Memcached\n2.5 Blur\n2.6 Solr\n2.7 MongoDB\n2.8 Hive\n2.9 Spark SQL（前身是Shark）\n2.10 Giraph\n第3章序列化\n3.1 Avro\n3.2 JSON\n3.3 Protocol Buffers（protobuf）\n3.4 Parquet\n第4章管理与监控\n4.1 Ambari\n4.2 Hcatalog\n4.3 Nagios\n4.4 Puppet\n4.5 Chef\n4.6 ZooKeeper\n4.7 Oozie\n4.8 Ganglia\n第5章分析辅助\n5.1 MapReduce接口\n5.2分析库\n5.3 Pig\n5.4 Hadoop Streaming\n5.5 Mahout\n5.6 MLLib\n5.7 Hadoop图像处理接口（HIPI）\n5.8 Spatial Hadoop\n第6章数据传输\n6.1 Sqoop\n6.2 Flume\n6.3 DistCp\n6.4 Storm\n第7章安全、访问控制和审计\n7.1 Sentry\n7.2 Kerberos\n7.3 Knox\n第8章云计算和虚拟化\n8.1 Serengeti\n8.2 Docker\n8.3 Whirr","pages":"109","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29413936.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29413936.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29413936.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27008893\/","id":"27008893","publisher":"中国电力出版社","isbn10":"7512395981","isbn13":"9787512395985","title":"Hadoop生态系统","url":"https:\/\/api.douban.com\/v2\/book\/27008893","alt_title":"凯文·斯托 (Kevin Sitto)","author_intro":"Kevin Sitto是Pivotal Software公司的领域解决方案工程师，主要为客户提供咨询服务，帮助客户理解和描述大数据需求。\nMarshall Presser是Pivotal Data Engineering集团的成员。他帮助客户使用Hadoop、关系数据库和内存数据网格来解决复杂的分析问题。","summary":"《Hadoop生态系统》本书每一章都介绍了不同的主题（例如核心技术或数据传输），并且解释了为什么特定组件适用或不适用特定的需求。对于数据处理来说，使用Hadoop是一个全新的挑战，但如果有了这本便利的参考书，你将很容易领会使用Hadoop的精妙所在。\n主要包括如下主题：核心技术，Hadoop分布式文件系统（HDFS）、MapReduce、YARN和Spark。数据库和数据管理，Cassandra、HBase、MongoDB和Hive。序列化，Avro、JSON和Parquet。管理和监视，Puppet、Chef、Zookeeper和Oozie。分析辅助，Pig、Mahout和MLLib。数据传输，Scoop、Flume、distcp和Storm。安全、访问控制和审计，Sentry、Kerberos和Knox。云计算和虚拟化，Serengeti、Docker和Whirr。","price":"21.8"},{"rating":{"max":10,"numRaters":10,"average":"6.1","min":0},"subtitle":"","author":["Venkat Ankam"],"pubdate":"2017-7","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29729364.jpg","binding":"","translator":["吴今朝"],"catalog":"","pages":"234","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29729364.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29729364.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29729364.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27090419\/","id":"27090419","publisher":"机械工业出版社","isbn10":"7111569415","isbn13":"9787111569411","title":"Spark与Hadoop大数据分析\/大数据技术丛书","url":"https:\/\/api.douban.com\/v2\/book\/27090419","alt_title":"","author_intro":"","summary":"","series":{"id":"19432","title":"大数据技术丛书"},"price":"59.00"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Danil Zburivsky"],"pubdate":"2013-11-25","tags":[{"count":1,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27260583.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"126","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27260583.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27260583.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27260583.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25867189\/","id":"25867189","publisher":"Packt Publishing","isbn10":"1783281715","isbn13":"9781783281718","title":"Hadoop Cluster Deployment","url":"https:\/\/api.douban.com\/v2\/book\/25867189","alt_title":"","author_intro":"","summary":"","price":"USD 34.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["太田 一樹","岩崎 正剛","猿田 浩輔","下垣 徹","藤井 達朗","山下 真一"],"pubdate":"2013-7-9","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26811987.jpg","binding":"大型本","translator":[],"catalog":"","pages":"592","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s26811987.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s26811987.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26811987.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24840384\/","id":"24840384","publisher":"翔泳社","isbn10":"479812964X","isbn13":"9784798129648","title":"Hadoop徹底入門 第2版 オープンソース分散処理環境の構築","url":"https:\/\/api.douban.com\/v2\/book\/24840384","alt_title":"","author_intro":"","summary":"","price":"JPY 3990"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Rajiv Tiwari"],"pubdate":"2015-4-30","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28065462.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"168","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28065462.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28065462.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28065462.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26383195\/","id":"26383195","publisher":"Packt Publishing","isbn10":"1784395161","isbn13":"9781784395162","title":"Hadoop for Finance Essentials","url":"https:\/\/api.douban.com\/v2\/book\/26383195","alt_title":"","author_intro":"","summary":"","price":"USD 29.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Kerry Koitzsch"],"pubdate":"2016-12-29","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29310018.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"298","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29310018.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29310018.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29310018.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26963396\/","id":"26963396","publisher":"Apress","isbn10":"1484219090","isbn13":"9781484219096","title":"Pro Hadoop Data Analytics: Designing and Building Big Data Systems using the Hadoop Ecosystem","url":"https:\/\/api.douban.com\/v2\/book\/26963396","alt_title":"","author_intro":"From the Back Cover\nLearn advanced analytical techniques and leverage existing toolkits to make your analytic applications more powerful, precise, and efficient. This book provides the right combination of architecture, design, and implementation information to create analytical systems which go beyond the basics of classification, clustering, and recommendation.InPro Hadoop Data Analyticsbest practices are emphasized to ensure coherent, efficient development. A complete example system will be developed using standard third-party components which will consist of the toolkits, libraries, visualization and reporting code, as well as support glue to provide a working and extensible end-to-end system.The book emphasizes four important topics:The importance of end-to-end,flexible, configurable, high-performance data pipeline systems withanalytical components as well as appropriate visualization results.Deep-dive topics will include Spark, H20, Vopal Wabbit (NLP), StanfordNLP, and other appropriate toolkits and plugins.Best practices and structured design principles. This will include strategic topics as well as the how to example portions.The importance of mix-and-matchor hybrid systems,using different analytical components in oneapplication to accomplish application goals. The hybrid approach willbe prominent in the examples.Use of existing third-partylibraries is key to effective development. Deep dive examples of thefunctionality of some of these toolkits will be showcased as you developthe example system.\nRead more\nAbout the Author\nKerry Koitzsch is a software engineer and student of history interested in the early history of science, particularly chemistry. He frequently publishes papers and attends conferences on scientific and historical topics, including early chemistry and alchemy, sociology of science, and other historical subjects. He has presented many lectures, talks, and demonstrations on a variety of subjects for the United States Army, the Society for Utopian Studies, American Association for Artificial Intelligence (AAAI), Association for Studies in Esotericism (ASE), and others, and has published many papers, with two books on historical subjects to be published in 2016. His most recent published work is a chapter in “The Individual and Utopia”, a collection of sociological papers, published by Ashgate Press.He was educated at Interlochen Arts Academy, MIT, and the San Francisco Conservatory of Music. He served in the United States Army and United States Army Reserve, and is the recipient of the United States Army Achievement Medal. For the last thirty years he has been a software engineer specializing in computer vision, machine learning, and database technologies, and currently lives and works in Sunnyvale, California.\nRead more","summary":"Learn advanced analytical techniques and leverage existing toolkits to make your analytic applications more powerful, precise, and efficient. This book provides the right combination of architecture, design, and implementation information to create analytical systems which go beyond the basics of classification, clustering, and recommendation.InPro Hadoop Data Analyticsbest practices are emphasized to ensure coherent, efficient development. A complete example system will be developed using standard third-party components which will consist of the toolkits, libraries, visualization and reporting code, as well as support glue to provide a working and extensible end-to-end system.The book emphasizes four important topics:The importance of end-to-end,flexible, configurable, high-performance data pipeline systems withanalytical components as well as appropriate visualization results.Best practices and structured design principles. This will include strategic topics as well as the how to example portions.The importance of mix-and-matchor hybrid systems,using different analytical components in oneapplication to accomplish application goals. The hybrid approach willbe prominent in the examples.Use of existing third-partylibraries is key to effective development. Deep dive examples of thefunctionality of some of these toolkits will be showcased as you developthe example system.\nWhat You'll LearnThe what, why, and how of building big data analytic systems with the Hadoop ecosystemLibraries, toolkits, and algorithms to make development easier and more effectiveBest practices to use when building analytic systems with Hadoop, and metrics to measure performance and efficiency of components and systemsHow to connect to standard relational databases, noSQL data sources, and moreUseful case studies and example components which assist you in creating your own systemsWho This Book Is ForSoftware engineers, architects, and data scientists with an interest in the design and implementation of big data analytical systems using Hadoop, the Hadoop ecosystem, and other associated technologies.","price":"USD 41.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Deepak Vohra"],"pubdate":"2016-10-1","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29100376.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"421","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29100376.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29100376.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29100376.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26894193\/","id":"26894193","publisher":"Apress","isbn10":"1484221982","isbn13":"9781484221983","title":"Practical Hadoop Ecosystem: A Definitive Guide to Hadoop-Related Frameworks and Tools","url":"https:\/\/api.douban.com\/v2\/book\/26894193","alt_title":"","author_intro":"","summary":"This book is a practical guide on using the Apache Hadoop projects including MapReduce, HDFS, Apache Hive, Apache HBase, Apache Kafka, Apache Mahout and Apache Solr.From setting up the environment to running sample applications each chapter is a practical tutorial on using a Apache Hadoop ecosystem project. While several books on Apache Hadoop are available, most are based on the main projects MapReduce and HDFS and none discusses the other Apache Hadoop ecosystem projects and how these all work together as a cohesive big data development platform.\nWhat you'll learnHow to set up environment in Linux for Hadoop projects using Cloudera Hadoop Distribution CDH 5.How to run a MapReduce jobHow to store data with Apache Hive, Apache HBaseHow to index data in HDFS with Apache SolrHow to develop a Kafka messaging systemHow to develop a Mahout User Recommender SystemHow to stream Logs to HDFS with Apache FlumeHow to transfer data from MySQL database to Hive, HDFS and HBase with SqoopHow create a Hive table over Apache Solr\nWho this book is for:\nThe primary audience is Apache Hadoop developers. Pre-requisite knowledge of Linux and some knowledge of Hadoop is required.","price":"USD 39.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Bhushan Lakhe"],"pubdate":"2016-8-11","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29035735.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"305","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29035735.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29035735.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29035735.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26871757\/","id":"26871757","publisher":"Apress","isbn10":"1484212886","isbn13":"9781484212882","title":"Practical Hadoop Migration: How to Integrate Your RDBMS with the Hadoop Ecosystem and Re-Architect Relational Applications to NoSQL","url":"https:\/\/api.douban.com\/v2\/book\/26871757","alt_title":"","author_intro":"Bhushan Lakhe is a Database Strategist, Technology evangelist, and avid blogger residing in the windy city of Chicago. After graduating in 1988 from one of India's leading universities (Birla Institute of Technology & Science, Pilani), he started his career with India's biggest software house, Tata Consultancy Services. Soon sent to the UK on a database assignment, he joined ICL, a British computer company, and worked with prestigious British clients on database assignments. Moving to Chicago in 1995, he worked as a consultant with such Fortune 50 companies as Leo Burnett, Blue Cross and Blue Shield of Illinois, CNA Insurance, ABN AMRO Bank, Abbott Laboratories, Motorola, JPMorgan Chase and British Petroleum, often in a critical and pioneering role.\nAfter a seven-year stint executing successful Big Data (as well as Data Warehouse) projects for IBM's clients (and receiving the company's prestigious Gerstner Award in 2012), Mr. Lakhe spent two years helping Unisys Corporation's clients with Data Warehouse and Big Data implementations. Mr. Lakhe is currently working as Senior Vice President of Information and Data Architecture at Ipsos, the world's third largest market research corporation, and is responsible for the company's Global Data Architecture and Big Data strategy.\nMr. Lakhe is active in the Chicago Hadoop community and is co-organizer of an active big data meetup in Chicago area (http:\/\/www.meetup.com\/ambariCloud-Big-Data-Meetup). He regularly answers queries on various Hadoop user forums. You can find Mr. Lakhe on LinkedIn at https:\/\/www.linkedin.com\/in\/bhushanlakhe.","summary":"Re-architect relational applications to NoSQL, integrate relational database management systems with the Hadoop ecosystem, and transform and migrate relational data to and from Hadoop components. This book covers the best-practice design approaches to re-architecting your relational applications and transforming your relational data to optimize concurrency, security, denormalization, and performance.\nWinner of IBM’s 2012 Gerstner Award for his implementation of big data and data warehouse initiatives and author of Practical Hadoop Security, author Bhushan Lakhe walks you through the entire transition process. First, he lays out the criteria for deciding what blend of re-architecting, migration, and integration between RDBMS and HDFS best meets your transition objectives. Then he demonstrates how to design your transition model.\nLakhe proceeds to cover the selection criteria for ETL tools, the implementation steps for migration with SQOOP- and Flume-based data transfers, and transition optimization techniques for tuning partitions, scheduling aggregations, and redesigning ETL. Finally, he assesses the pros and cons of data lakes and Lambda architecture as integrative solutions and illustrates their implementation with real-world case studies.\nHadoop\/NoSQL solutions do not offer by default certain relational technology features such as role-based access control, locking for concurrent updates, and various tools for measuring and enhancing performance. Practical Hadoop Migration shows how to use open-source tools to emulate such relational functionalities in Hadoop ecosystem components.\nWhat You'll Learn\nThe requirements and design methodologies of relational data and NoSQL modelsHow to decide whether you should migrate your relational applications to big data technologies or integrate themHow to transition your relational applications to Hadoop\/NoSQL platforms in terms of logical design and physical implementationRDBMS-to-HDFS integration, data transformation, and optimization techniquesThe situations in which Lambda architecture and data lake solutions should be consideredHow to select and implement Hadoop-based components and applications to speed transition, optimize integrated performance, and emulate relational functionalities\nWho This Book Is For\nThe primary readership for Practical Hadoop Migration is database developers, database administrators, enterprise architects, Hadoop\/NoSQL developers, and IT leaders. Its secondary readership is project and program managers and advanced students of database and management information systems.","price":"USD 44.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29521171.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29521171.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29521171.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29521171.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27118302\/","id":"27118302","publisher":"","isbn10":"0134049942","isbn13":"9780134049946","title":"Hadoop 2 Quick-Start Guide: Learn the Essentials of Big Data Computing in the Apache Hadoop 2 Ecosystem","url":"https:\/\/api.douban.com\/v2\/book\/27118302","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31665956.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s31665956.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s31665956.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31665956.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32775608\/","id":"32775608","publisher":"","isbn10":"1500910643","isbn13":"9781500910648","title":"Hadoop Essence: The Beginneræs Guide to Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/32775608","alt_title":"","author_intro":"","summary":"Hadoop bought capabilities to store massive amount of data in distributed environment and provide the way to process them effectively. It’s a distributed data processing system which support distributed file systems and it offers a way to parallelize and execute programs on a cluster of machines. It could be installed on cluster with using large number of commodities hardware which intern optimized the overall solution costs.Apache Hadoop already adopted by technologies giant such as Yahoo, Facebook, Twitter, LinkedIn etc. to address their big data needs, and it’s making inroads across all industrial sectorsHadoop Essence is the basic guide for developer, architect, engineer and anyone who want to start leveraging Hadoop to build a distributed, scalable concurrent application. This book is a concise guide on getting started with Hadoop and Hive. It provides overall understanding on Hadoop and how it works and same time provide the sample code to speed up development with very minimum effort. It will refer to easy-to-explain concept & examples, as they are likely to be the best teaching aids. It will explain the logic, code, and configurations needed to build a successful, distributed, concurrent application, as well as the reason behind those decisionsThe book has been written considering for beginner and intermediate developer who want to get introduce in Hadoop.Table of Contents1. Big Data2. Hadoop3. The Hadoop Distribution Filesystem(HDFS)4. Getting Started with Hadoop5. Interface to Access HDFS File System6. MapReduce7. YARN8. Hive9. Getting Started with Hive","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32082260.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32082260.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32082260.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32082260.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33193042\/","id":"33193042","publisher":"","isbn10":"1717577512","isbn13":"9781717577511","title":"Data Engineering Skills - Hadoop Shell: A Comprehensive Guide to Hadoop Fs Commands","url":"https:\/\/api.douban.com\/v2\/book\/33193042","alt_title":"","author_intro":"","summary":"Hadoop is the most acceptable distributed storage and processing framework for very large datasets in the world today. Although it had started as a small research project, less famously known as Apache Nutch, back in 2006 but later moved to a new subproject called Hadoop. Doug Cutting who was one of the founders of Hadoop, named it after his son’s toy elephant. His son used to call the toy as hadoop, so that’s how Hadoop got its name. The idea of Hadoop originated from a white paper that Google had published back in 2003 called “Google File System”. This paper talked about specifically how Google designed its applications around a distributed storage and processing framework. Doug Cutting and Mike Cafarella took same concept and made it more generalized so it fits use cases of many other companies around the globe.Hadoop is famous for its distributed storage which is provided by its file system - commonly known as HDFS and distributed processing engine which is supported by something called - MapReduce. The MapReduce enabled processing of distributed datasets possible by running the code where data resides, which was a big paradigm shift compared to previous generations of processing engines. Earlier data needed to be transferred to machines where code is residing so further processing can be done on that data and results could be generated. But since data is usually bigger in size than actual code is, it used to take more time in setting the environment than actual processing would take. Hadoop adopted opposite approach where data doesn’t move between machines much but code binaries are sent to machine where data is residing and then that code will locally run on that particular machine and return the results back. This approach provides obvious benefits in overall performance as setting time has reduced substantially and multiple processes can be ran on same data across distributed network of machines in parallel.I decided to write this book as the first in a series of books that I am planning to publish in future on various big data technologies. The goal of this book is to help data engineers build enough foundation in Hadoop before moving on to more high level technologies such as Spark, Hive, etc.This book is designed to be more hands on rather than plain theory. In this book, I will explain the Hadoop framework and how it works behind the scenes. Then we will shift our focus to learn specifically about Hadoop Shell. Hadoop comes with an inbuilt shell which is inspired from Linux Shell and has many similar concepts. To make our learning interesting, I have categorized various important shell commands in such a way that can be used to solve some real world like problems. These problems are inspired by real scenarios faced during several years of my working as a big data specialist.","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2011-4-22","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"大型本","translator":[],"catalog":"","pages":"144","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/6127204\/","id":"6127204","publisher":"アスキー・メディアワークス","isbn10":"4048705741","isbn13":"9784048705745","title":"ビッグデータを征す クラウドの技術 Hadoop&NoSQL","url":"https:\/\/api.douban.com\/v2\/book\/6127204","alt_title":"","author_intro":"","summary":"","price":"JPY 2415"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Hrishikesh Vijay Karambelkar"],"pubdate":"2015-3-31","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28062523.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"156","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28062523.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28062523.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28062523.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26380166\/","id":"26380166","publisher":"Packt Publishing - ebooks Account","isbn10":"1783553391","isbn13":"9781783553396","title":"Scaling Big Data with Hadoop and Solr - Second Edition","url":"https:\/\/api.douban.com\/v2\/book\/26380166","alt_title":"","author_intro":"","summary":"","price":"USD 44.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Shiva Achari"],"pubdate":"2015-4-24","tags":[{"count":1,"name":"分布式","title":"分布式"},{"count":1,"name":"NoSQL","title":"NoSQL"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28065463.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"172","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28065463.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28065463.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28065463.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26383196\/","id":"26383196","publisher":"Packt Publishing - ebooks Account","isbn10":"1784396680","isbn13":"9781784396688","title":"Hadoop Essentials","url":"https:\/\/api.douban.com\/v2\/book\/26383196","alt_title":"","author_intro":"","summary":"","price":"USD 29.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Gaurav Barot","Chintan Mehta","Amij Patel"],"pubdate":"2015-7","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28295224.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"206","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s28295224.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s28295224.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s28295224.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26610861\/","id":"26610861","publisher":"Packt Publishing - ebooks Account","isbn10":"178328904X","isbn13":"9781783289042","title":"Hadoop Backup and Recovery solutions","url":"https:\/\/api.douban.com\/v2\/book\/26610861","alt_title":"","author_intro":"","summary":"","price":"USD 29.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Shumin Guo"],"pubdate":"2013-7-24","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28365480.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"368","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28365480.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28365480.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28365480.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24833387\/","id":"24833387","publisher":"Packt Publishing","isbn10":"1782165169","isbn13":"9781782165163","title":"Hadoop Operations and Cluster Management Cookbook","url":"https:\/\/api.douban.com\/v2\/book\/24833387","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["deRoos, Dirk; Zikopolous, Paul; Coss, Rafael; Melnyk, Roman B.; Brown, Bruce"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s24634489.jpg","binding":"","translator":[],"catalog":"","pages":"384","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s24634489.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s24634489.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s24634489.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20560317\/","id":"20560317","publisher":"","isbn10":"1118607554","isbn13":"9781118607558","title":"Hadoop For Dummies","url":"https:\/\/api.douban.com\/v2\/book\/20560317","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["凯西·斯特拉"],"pubdate":"2018-6","tags":[{"count":4,"name":"大数据","title":"大数据"}],"origin_title":"practical data science with hadoop and spark","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29915469.jpg","binding":"","translator":["唐金川"],"catalog":"目录\n目 录\n译者序\n序\n前言\n致谢\n关于作者\n第一部分 Hadoop中的数据科学概览\n第1章 数据科学概述2\n1.1 数据科学究竟是什么2\n1.2 示例：搜索广告3\n1.3 数据科学史一瞥4\n1.3.1 统计学与机器学习4\n1.3.2 互联网巨头的创新5\n1.3.3 现代企业中的数据科学6\n1.4 数据科学家的成长之路6\n1.4.1 数据工程师7\n1.4.2 应用科学家7\n1.4.3 过渡到数据科学家角色8\n1.4.4 数据科学家的软技能9\n1.5 数据科学团队的组建10\n1.6 数据科学项目的生命周期11\n1.6.1 问正确的问题11\n1.6.2 数据摄取12\n1.6.3 数据清洗：注重数据质量12\n1.6.4 探索数据和设计模型特征13\n1.6.5 构建和调整模型13\n1.6.6 部署到生产环境14\n1.7 数据科学项目的管理14\n1.8 小结15\n第2章 数据科学用例16\n2.1 大数据—变革的驱动力16\n2.1.1 容量：更多可用数据17\n2.1.2 多样性：更多数据类型17\n2.1.3 速度：快速数据摄取18\n2.2 商业用例18\n2.2.1 产品推荐18\n2.2.2 客户流失分析19\n2.2.3 客户细分19\n2.2.4 销售线索的优先级20\n2.2.5 情感分析20\n2.2.6 欺诈检测21\n2.2.7 预测维护22\n2.2.8 购物篮分析22\n2.2.9 预测医学诊断23\n2.2.10 预测患者再入院23\n2.2.11 检测异常访问24\n2.2.12 保险风险分析24\n2.2.13 预测油气井生产水平24\n2.3 小结25\n第3章 Hadoop与数据科学26\n3.1 Hadoop 究竟为何物26\n3.1.1 分布式文件系统27\n3.1.2 资源管理器和调度程序28\n3.1.3 分布式数据处理框架29\n3.2 Hadoop的演进历史31\n3.3 数据科学的Hadoop工具32\n3.3.1 Apache Sqoop33\n3.3.2 Apache Flume33\n3.3.3 Apache Hive34\n3.3.4 Apache Pig35\n3.3.5 Apache Spark36\n3.3.6 R37\n3.3.7 Python38\n3.3.8 Java机器学习软件包39\n3.4 Hadoop为何对数据科学家有用39\n3.4.1 成本有效的存储39\n3.4.2 读取模式40\n3.4.3 非结构化和半结构化数据40\n3.4.4 多语言工具41\n3.4.5 强大的调度和资源管理功能41\n3.4.6 分布式系统抽象分层42\n3.4.7 可扩展的模型创建42\n3.4.8 模型的可扩展应用43\n3.5 小结43\n第二部分 用Hadoop准备和可视化数据\n第4章 将数据导入Hadoop46\n4.1 Hadoop数据湖46\n4.2 Hadoop分布式文件系统47\n4.3 直接传输文件到 HDFS48\n4.4 将数据从文件导入Hive表49\n4.5 使用Spark将数据导入Hive表52\n4.5.1 使用Spark将CSV文件导入Hive52\n4.5.2 使用Spark将JSON文件导入Hive54\n4.6 使用Apache Sqoop获取关系数据55\n4.6.1 使用Sqoop导入和导出数据55\n4.6.2 Apache Sqoop版本更改56\n4.6.3 使用Sqoop版本2：基本示例57\n4.7 使用Apache Flume获取数据流63\n4.8 使用Apache Oozie管理Hadoop工作和数据流67\n4.9 Apache Falcon68\n4.10 数据摄取的下一步是什么69\n4.11 小结70\n第5章 使用 Hadoop 进行数据再加工 71\n5.1 为什么选择Hadoop做数据再加工72\n5.2 数据质量72\n5.2.1 什么是数据质量72\n5.2.2 处理数据质量问题73\n5.2.3 使用Hadoop进行数据质量控制76\n5.3 特征矩阵78\n5.3.1 选择“正确”的特征78\n5.3.2 抽样：选择实例79\n5.3.3 生成特征80\n5.3.4 文本特征81\n5.3.5 时间序列特征84\n5.3.6 来自复杂数据类型的特征84\n5.3.7 特征操作85\n5.3.8 降维86\n5.4 小结88\n第6章 探索和可视化数据89\n6.1 为什么要可视化数据89\n6.1.1 示例：可视化网络吞吐量89\n6.1.2 想象未曾发生的突破92\n6.2 创建可视化93\n6.2.1 对比图94\n6.2.2 组成图96\n6.2.3 分布图98\n6.2.4 关系图99\n6.3 针对数据科学使用可视化101\n6.4 流行的可视化工具101\n6.4.1 R101\n6.4.2 Python：Matplotlib、Seaborn和其他102\n6.4.3 SAS102\n6.4.4 Matlab103\n6.4.5 Julia103\n6.4.6 其他可视化工具103\n6.5 使用Hadoop可视化大数据103\n6.6 小结104\n第三部分 使用Hadoop进行数据建模\n第7章 Hadoop与机器学习106\n7.1 机器学习概述106\n7.2 术语107\n7.3 机器学习中的任务类型107\n7.4 大数据和机器学习108\n7.5 机器学习工具109\n7.6 机器学习和人工智能的未来110\n7.7 小结110\n第8章 预测建模111\n8.1 预测建模概述111\n8.2 分类与回归112\n8.3 评估预测模型113\n8.3.1 评估分类器114\n8.3.2 评估回归模型116\n8.3.3 交叉验证117\n8.4 有监督学习算法117\n8.5 构建大数据预测模型的解决方案118\n8.5.1 模型训练118\n8.5.2 批量预测120\n8.5.3 实时预测120\n8.6 示例：情感分析121\n8.6.1 推文数据集121\n8.6.2 数据准备122\n8.6.3 特征生成122\n8.6.4 建立一个分类器125\n8.7 小结126\n第9章 聚类127\n9.1 聚类概述127\n9.2 聚类的使用128\n9.3 设计相似性度量128\n9.3.1 距离函数129\n9.3.2 相似函数129\n9.4 聚类算法130\n9.5 示例：聚类算法131\n9.5.1 k均值聚类131\n9.5.2 LDA131\n9.6 评估聚类和选择集群数量132\n9.7 构建大数据集群解决方案133\n9.8 示例：使用LDA进行主题建模134\n9.8.1 特征生成135\n9.8.2 运行 LDA136\n9.9 小结137","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29915469.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29915469.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29915469.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30371333\/","id":"30371333","publisher":"机械工业出版社","isbn10":"7111600347","isbn13":"9787111600343","title":"数据科学与大数据技术导论","url":"https:\/\/api.douban.com\/v2\/book\/30371333","alt_title":"practical data science with hadoop and spark","author_intro":"作者:(美)奥弗·曼德勒维奇 作者:凯西·斯特拉 作者:道格拉斯·伊德理恩 译者:唐金川\nOfer Mendelevitch是Lendup公司的数据科学副总裁，领导着Lendup的机器学习和高级分析小组。之前，Ofer是Hortonworks的数据科学总监，负责帮助Hortonworks的客户使用Hadoop和Spark数据科学应用于医疗保健、金融、零售和其他行业。Casey Stella是Hortonworks的首席数据科学家，领导着正在孵化开源Apache Metron网络安全项目的分析和数据科学团队。之前，Casey是Explorys医疗信息创业公司的架构师。Douglas Eadline是以Linux集群高性能计算(HPC)解决方案的实践者和高性能计算发展编年史撰写者开始职业生涯的。而后他以作家和咨询师的身份在高性能计算和数据分析行业撰写了很多大数据相关的文献。他也是《HadoopFUndamentaIs LiVeLessons，Second Edition》和《Hadoop 2 Quick—Start Guide：Learn the Essentials of Big Data Computingin the Apache Hadoop 2 Ecosystem》(均由Addison-Wesley出版)这两本书的作者。","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Xie, Jiong"],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s18668605.jpg","binding":"","translator":[],"catalog":"","pages":"112","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s18668605.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s18668605.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s18668605.jpg"},"alt":"https:\/\/book.douban.com\/subject\/16145479\/","id":"16145479","publisher":"","isbn10":"124909173X","isbn13":"9781249091738","title":"Improving Performance of Hadoop Clusters.","url":"https:\/\/api.douban.com\/v2\/book\/16145479","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Dipayan Dev"],"pubdate":"2017-3-6","tags":[{"count":1,"name":"机器学习","title":"机器学习"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29362544.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"259","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29362544.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29362544.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29362544.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26981439\/","id":"26981439","publisher":"Packt Publishing - ebooks Account","isbn10":"1787124762","isbn13":"9781787124769","title":"Deep Learning with Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26981439","alt_title":"","author_intro":"","summary":"","price":"USD 44.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2013-8","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27227588.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"98","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s27227588.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s27227588.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s27227588.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25836048\/","id":"25836048","publisher":"Packt Publishing","isbn10":"1782177981","isbn13":"9781782177982","title":"Microsoft SQL Server 2012 with Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/25836048","alt_title":"","author_intro":"","summary":"With the explosion of data, the open source Apache Hadoop ecosystem is gaining traction, thanks to its huge ecosystem that has arisen around the core functionalities of its distributed file system (HDFS) and Map Reduce. As of today, being able to have SQL Server talking to Hadoop has become increasingly important because the two are indeed complementary. While petabytes of unstructured data can be stored in Hadoop taking hours to be queried, terabytes of structured data can be stored in SQL Server 2012 and queried in seconds. This leads to the need to transfer and integrate data between Hadoop and SQL Server.\nMicrosoft SQL Server 2012 with Hadoop is aimed at SQL Server developers. It will quickly show you how to get Hadoop activated on SQL Server 2012 (it ships with this version). Once this is done, the book will focus on how to manage big data with Hadoop and use Hadoop Hive to query the data. It will also cover topics such as using in-memory functions by SQL Server and using tools for BI with big data.\nMicrosoft SQL Server 2012 with Hadoop focuses on data integration techniques between relational (SQL Server 2012) and non-relational (Hadoop) worlds. It will walk you through different tools for the bi-directional movement of data with practical examples.\nYou will learn to use open source connectors like SQOOP to import and export data between SQL Server 2012 and Hadoop, and to work with leading in-memory BI tools to create ETL solutions using the Hive ODBC driver for developing your data movement projects. Finally, this book will give you a glimpse of the present day self-service BI tools such as Excel and PowerView to consume Hadoop data and provide powerful insights on the data.","price":""},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"Ensuring Quality of Service in Multi-Tenant Environments","author":["Andy Oram"],"pubdate":"2016-7-15","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29085963.jpg","binding":"pdf","translator":[],"catalog":"","pages":"20","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29085963.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29085963.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29085963.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26889053\/","id":"26889053","publisher":"O'reilly","isbn10":"1491963190","isbn13":"9781491963197","title":"Hadoop and Spark Performance for the Enterprise","url":"https:\/\/api.douban.com\/v2\/book\/26889053","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["【美】Douglas Eadline（道格拉斯•伊德理恩）"],"pubdate":"2016-5","tags":[{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"机器学习","title":"机器学习"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"互联网","title":"互联网"},{"count":1,"name":"YARN","title":"YARN"},{"count":1,"name":"MR","title":"MR"},{"count":1,"name":"HDFS","title":"HDFS"},{"count":1,"name":"HADOOP","title":"HADOOP"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28827869.jpg","binding":"平装","translator":["卢涛"],"catalog":"1 背景和概念  1\n定义Apache Hadoop  1\nApache Hadoop 的发展简史  3\n大数据的定义 4\nHadoop 作为数据湖 5\n使用Hadoop:管理员、用户或两种身份兼具 7\n原始的MapReduce. 7\nApache Hadoop 的设计原则 8\nApache Hadoop MapReduce 示例 8\nMapReduce 的优势  10\nApache Hadoop V1 MapReduce 操作 11\n使用Hadoop V2 超越MapReduce 13\nHadoop V2 YARN 操作设计 14\nApache Hadoop 项目生态系统  16\n总结和补充资料 18\n2 安装攻略 21\n核心Hadoop 服务  21\nHadoop 配置文件 22\n规划你的资源 23\n硬件的选择  23\n软件的选择  24\n在台式机或笔记本电脑上安装 25\n安装Hortonworks HDP 2.2 沙箱  25\n用Apache 源代码安装Hadoop  32\n配置单节点YARN 服务器的步骤 33\n运行简单的MapReduce 示例 42\n安装 Apache Pig（可选）  42\n安装Apache Hive（可选）  43\n使用Ambari 安装Hadoop 44\n执行Ambari 安装  45\n撤消Ambari 安装  59\n使用Apache Whirr 在云中安装Hadoop  59\n总结和补充资料 65\n3 HDFS 基础知识 67\nHDFS 设计的特点  67\nHDFS 组件 68\nHDFS 块复制 71\nHDFS 安全模式 72\n机架的识别  73\nNameNode 高可用性 73\nHDFS NameNode 联邦  75\nHDFS 检查点和备份 76\nHDFS 快照 76\nHDFS NFS 网关 76\nHDFS 用户命令  77\n简要HDFS 命令参考  77\n一般HDFS 命令  78\n列出HDFS 中的文件  79\n在HDFS 中创建一个目录  80\n将文件复制到HDFS 80\n从HDFS 复制文件  81\n在HDFS 中复制文件  81\n删除在HDFS 中的文件  81\n删除在HDFS 中的目录  81\n获取HDFS 状态报告  81\nHDFS 的Web 图形用户界面  82\n在程序中使用HDFS 82\nHDFS Java 应用程序示例 82\nHDFS C 应用程序示例  86\n总结和补充资料 88\n4 运行示例程序和基准测试程序 91\n运行MapReduce 示例  91\n列出可用的示例  92\n运行Pi 示例 93\n使用Web 界面监控示例 95\n运行基本Hadoop 基准测试程序  101\n运行Terasort 测试 101\n运行TestDFSIO 基准  102\n管理Hadoop MapReduce 作业 104\n总结和补充资料 105\n5 Hadoop MapReduce 框架 107\nMapReduce 模型 107\nMapReduce 并行数据流. 110\n容错和推测执行 114\n推测执行. 114\nHadoop MapReduce 硬件  115\n总结和补充资料 115\n6 MapReduce 编程  117\n编译和运行Hadoop WordCount 的示例 117\n使用流式接口 122\n使用管道接口 125\n编译和运行Hadoop Grep 链示例 127\n调试MapReduce. 131\n作业的列举、清除和状态查询  131\nHadoop 日志管理 131\n启用YARN 日志聚合  132\nWeb 界面日志查看  133\n命令行日志查看  133\n总结和补充资料 135\n7 基本的Hadoop 工具 137\n使用Apache Pig 137\nPig 示例演练  138\n使用Apache Hive 140\nHive 示例演练  140\n更高级的Hive 示例 142\n使用Apache Sqoop 获取关系型数据 145\nApache Sqoop 导入和导出方法  145\nApache Sqoop 版本更改  147\nSqoop 示例演练 148\n使用Apache Flume 获取数据流 155\nFlume 的示例演练 157\n使用Apache Oozie 管理 Hadoop 工作流  160\nOozie 示例演练  162\n使用Apache HBase  170\nHBase 数据模型概述 170\nHBase 示例演练 171\n总结和补充资料 176\n8 Hadoop YARN 应用程序 179\nYARN 分布式shell  179\n使用YARN 分布式shell 180\n一个简单的示例  181\n使用更多的容器  182\n带有shell 参数的分布式 shell 示例 183\nYARN 应用程序的结构 185\nYARN 应用程序框架 187\nHadoop MapReduce 188\nApache Tez  188\nApache Giraph  189\nHoya：HBase on YARN  189\nDryad on YARN  189\nApache Spark  189\nApache Storm  190\nApache REEF：可持续计算执行框架 190\nHamster：Hadoop 和MPI 在同一集群  190\nApache Flink：可扩展的批处理和流式数据处理 191\nApache Slider：动态应用程序管理  191\n总结和补充资料 192\n9 用Apache Ambari 管理Hadoop 193\n快速浏览 Apache Ambari  194\n仪表板视图  194\n服务视图. 197\n主机视图. 199\n管理视图. 201\n查看视图. 201\nAdmin 下拉菜单  202\n更改Hadoop 属性  206\n总结和补充资料 212\n10 基本的Hadoop 管理程序  213\n基本的Hadoop YARN 管理  214\n停用YARN 节点  214\nYARN WebProxy  214\n使用 JobHistoryServer  215\n管理YARN 作业  215\n设置容器内存  215\n设置容器核心  216\n设置MapReduce 属性 216\n基本的HDFS 管理 217\nNameNode 用户界面 217\n将用户添加到HDFS 219\n在HDFS 上执行FSCK 220\n平衡HDFS 221\nHDFS 安全模式 222\n停用HDFS 节点  222\nSecondaryNameNode 223\nHDFS 快照 223\n配置到HDFS 的NFSv3 网关 225\n容量调度程序背景知识 229\nHadoop 2 的MapReduce 兼容性 231\n启用应用主控程序的重新启动功能  231\n计算一个节点的承载容量  232\n运行Hadoop 1 的应用程序 233\n总结和补充资料 235\n附录A 本书的网页和代码下载  237\n附录B 入门流程图和故障排除指南  239\n入门流程图 239\n常见的Hadoop 故障排除指南  239\n规则1：不要惊慌 239\n规则2：安装并使用Ambari  244\n规则3：检查日志 244\n规则4：简化情况 245\n规则5：在互联网上提问 245\n其他有用的提示  246\n附录C 按主题列出的Apache Hadoop 资源汇总  253\n常规的Hadoop 信息 253\nHadoop 安装攻略 253\nHDFS  254\n示例  255\nMapReduce. 255\nMapReduce 编程  255\n基本工具  256\nYARN 应用程序框架 257\nAmbari 管理  257\n基本的Hadoop 管理 257\n附录D 安装Hue Hadoop GUI 259\nHue 安装  259\n安装和配置Hue 262\n启动Hue  263\nHue 用户界面 263\n附录E 安装Apache Spark 267\n在集群上安装Spark. 267\n在整个集群中启动Spark. 268\n在伪分布式的单节点安装版本中安装和启动Spark  270\n运行Spark 示例  271","pages":"288","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28827869.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28827869.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28827869.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26821598\/","id":"26821598","publisher":"电子工业出版社","isbn10":"7121288052","isbn13":"9787121288050","title":"写给大忙人的Hadoop 2","url":"https:\/\/api.douban.com\/v2\/book\/26821598","alt_title":"","author_intro":"Douglas Eadline，博士，作为一个Linux 集群HPC 革命的践行者和记录者开始他的职业生涯，而现在他在记录大数据分析。从开始第一份操作文档以来，道格写了数百篇文章、白皮书，以及说明文档，涵盖高性能计算（HPC）的几乎所有方面。在2005年启动和编辑颇受欢迎的ClusterMonkey.net 网站之前，他担任ClusterWorld 杂志的主编，并曾是Linux 杂志的HPC 资深编辑。\n他具有多方面的HPC 实际操作经验，包括硬件和软件设计、基准测试、存储、GPU、云计算和并行计算。\n目前， 他是一名作家和 HPC 行业顾问， 并且是Limulus 个人集群项目（http:\/\/limulus.basement-supercomputing.com）的领导。他是Addison-Wesley 出版的HadoopFundamentals LiveLessons 和Apache Hadoop YARN Fundamentals LiveLessons 教学视频的作者和Apache Hadoop™ YARN: Moving beyond MapReduce and Batch Processing withApache Hadoop™ 2 一书的合著者。","summary":"《写给大忙人的Hadoop 2》首先介绍了Hadoop 的背景知识，包括Hadoop 2 和YARN 的工作原理和对Hadoop 1 的改进，然后将数据湖与传统存储比较。第2 章到第8 章，分别介绍了Hadoop 2 和核心服务的安装方法、Hadoop 分布式文件系统、MapReduce 和YARN 编程，以及利用Apache Pig 等Hadoop 工具简化编程。最后两章讲述了利用Apache Ambari 等工具管理Hadoop 和基本的管理程序。附录包括Hadoop 2 故障诊断和排除的基础知识、Apache Hue 和Apache Spark 安装等。\n《写给大忙人的Hadoop 2》通俗易懂，具有大量操作实例，易于上手，适合Hadoop 用户、管理员、开发和运维人员、程序员、架构师、分析师和数据科学工作者阅读。","price":"69.00元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["Scott Shaw","Andreas François Vermeulen","Ankur Gupta"],"pubdate":"2016-1-27","tags":[{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"hive","title":"hive"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29035729.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"265","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29035729.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29035729.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29035729.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26871756\/","id":"26871756","publisher":"Apress","isbn10":"1484202724","isbn13":"9781484202722","title":"Practical Hive: A Guide to Hadoop's Data Warehouse System","url":"https:\/\/api.douban.com\/v2\/book\/26871756","alt_title":"","author_intro":"","summary":"Dive into the world of SQL on Hadoop and get the most out of your Hive data warehouses. This book is your go-to resource for using Hive: authors Scott Shaw, Ankur Gupta, David Kjerrumgaard, and Andreas Francois Vermeulen take you through learning HiveQL, the SQL-like language specific to Hive, to analyze, export, and massage the data stored across your Hadoop environment. From deploying Hive on your hardware or virtual machine and setting up its initial configuration to learning how Hive interacts with Hadoop, MapReduce, Tez and other big data technologies, Practical Hive gives you a detailed treatment of the software.\nIn addition, this book discusses the value of open source software, Hive performance tuning, and how to leverage semi-structured and unstructured data.\nWhat You Will Learn\nInstall and configure Hive for new and existing datasetsPerform DDL operationsExecute efficient DML operationsUse tables, partitions, buckets, and user-defined functionsDiscover performance tuning tips and Hive best practices\nWho This Book Is For\nDevelopers, companies, and professionals who deal with large amounts of data and could use software that can efficiently manage large volumes of input. It is assumed that readers have the ability to work with SQL.","price":"USD 39.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Liu, Henry H."],"pubdate":"2012-10","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26703647.jpg","binding":"","translator":[],"catalog":"","pages":"356","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s26703647.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s26703647.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26703647.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20972579\/","id":"20972579","publisher":"","isbn10":"1480216372","isbn13":"9781480216372","title":"Hadoop Essentials","url":"https:\/\/api.douban.com\/v2\/book\/20972579","alt_title":"","author_intro":"","summary":"","price":"$ 67.79"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Kwabena Mensah Patrick"],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s24819005.jpg","binding":"","translator":[],"catalog":"","pages":"100","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s24819005.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s24819005.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s24819005.jpg"},"alt":"https:\/\/book.douban.com\/subject\/21209183\/","id":"21209183","publisher":"","isbn10":"3659294675","isbn13":"9783659294679","title":"Availability of Jobtracker in Hadoop\/Mapreduce Zookeeper Clusters","url":"https:\/\/api.douban.com\/v2\/book\/21209183","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["西普教育研究院","时允田","林雪纲"],"pubdate":"2017-5-1","tags":[{"count":1,"name":"数据分析","title":"数据分析"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29543384.jpg","binding":"平装","translator":[],"catalog":"基础篇\n第1章　Hadoop概述　1\n1．1　Hadoop简介　1\n1．2　Hadoop相关项目　2\n1．3　Hadoop来源　3\n1．4　Hadoop的发展史　4\n1．5　Hadoop特点　5\n1．6　Hadoop体系架构　6\n1．6．1　HDFS体系结构　7\n1．6．2　MapReduce体系结构　7\n本章小结　8\n习题　8\n第2章　Hadoop基础环境配置　9\n2．1　准备Linux环境　9\n2．1．1　安装VMware12虚拟机　9\n2．1．2　部署CentOS 64位操作系统　11\n2．2　Linux配置　16\n2．2．1　什么是Linux　16\n2．2．2　Linux发行版　16\n2．2．3　配置网络　16\n2．2．4　Linux终端　17\n2．3　Hadoop环境搭建　21\n2．3．1　JDK安装和测试　21\n2．3．2　Hadoop安装和配置　25\n2．3．3　SSH免密码配置　31\n本章小结　33\n习题　34\n第3章　分布式存储HDFS　35\n3．1　HDFS概念　35\n3．1．1　HDFS简介　35\n3．1．2　HDFS设计思路和理念　35\n3．2　HDFS体系结构　36\n3．3　HDFS文件存储机制　36\n3．4　HDFS Shell介绍　39\n3．4．1　命令格式　39\n3．4．2　HDFS用户命令　40\n3．4．3　HDFS管理员命令　40\n3．5　Hadoop项目创建　47\n3．6　RPC通信原理　53\n3．6．1　什么是Hadoop的RPC　53\n3．6．2　RPC采用的模式　53\n3．7　分布式文件系统操作类　59\n本章小结　69\n习题　69\n第4章　计算系统MapReduce　70\n4．1　MapReduce概念　70\n4．1．1　MapReduce简介　70\n4．1．2　MapReduce 数据类型与格式　71\n4．1．3　数据类型Writable接口　71\n4．1．4　Hadoop序列化机制　72\n4．2　MapReduce架构　72\n4．2．1　数据分片　72\n4．2．2　MapReduce执行过程　73\n4．2．3　Mapper执行过程　73\n4．2．4　Reducer执行过程　74\n4．2．5　Shuffle过程　75\n4．3　第一个MapReduce案例　75\n4．4　MapReduce接口类　79\n4．4．1　MapReduce输入的处理类　79\n4．4．2　MapReduce输出的处理类　80\n本章小结　87\n习题　87\n第5章　计算模型Yarn　88\n5．1　Yarn概述　88\n5．1．1　Yarn简介　88\n5．1．2　Yarn的组成　89\n5．2　Yarn的执行过程　89\n5．3　新旧MapReduce的对比　90\n本章小结　101\n习题　101\n第6章　数据云盘　102\n6．1　项目概述　102\n6．2　功能需求　102\n6．3　软件开发需求　102\n6．4　效果展示　103\n6．5　系统开发　104\n本章小结　125\n习题　125\n提高篇\n第7章　协调系统Zookeeper　126\n7．1　Zookeeper概述　126\n7．1．1　Zookeeper简介　126\n7．1．2　Zookeeper数据模型　127\n7．1．3　Zookeeper特征　127\n7．1．4　Zookeeper工作原理　128\n7．2　Zookeeper术语　129\n7．2．1　节点　129\n7．2．2　角色　129\n7．2．3　顺序号　129\n7．2．4　观察　129\n7．2．5　Leader选举　129\n7．3　事件　130\n7．4　Zookeeper Shell操作　130\n7．4．1　Zookeeper服务命令　130\n7．4．2　Zookeeper客户端命令　134\n7．5　Zookeeper API操作　137\n本章小结　156\n习题　156\n第8章　Hadoop数据库Hbase　157\n8．1　Hbase概述　157\n8．1．1　Hbase简介　157\n8．1．2　Hbase优势和特点　158\n8．1．3　Hbase专业术语　158\n8．2　Hbase架构　158\n8．2．1　角色　159\n8．2．2　Hbase物理存储和逻辑视图　160\n8．3　Hbase Shell操作　163\n8．4　Hbase API操作　168\n8．5　Hbase 过滤器　182\n8．5．1　过滤器的含义　182\n8．5．2　过滤器的比较操作符　182\n8．5．3　过滤器的比较器　183\n本章小结　193\n习题　193\n第9章　Hadoop数据仓库Hive　194\n9．1　Hive概述　194\n9．1．1　Hive简介　194\n9．1．2　Hive数据类型　194\n9．1．3　Hive Metastore　195\n9．1．4　Hive存储和压缩　195\n9．1．5　Hive与传统数据库对比　195\n9．2　Hive的系统架构　196\n9．3　Hive的数据模型　200\n9．3．1　内部表　200\n9．3．2　外部表　200\n9．3．3　分区表　201\n9．3．4　桶表　201\n9．4　Hive Shell操作　201\n9．5　Hive API操作　208\n9．6　Hive内置函数和UDF　215\n9．6．1　内置函数　215\n9．6．2　UDF函数　215\n本章小结　222\n习题　222\n第10章　Hadoop数据采集Flume　223\n10．1　Flume概述　223\n10．1．1　Flume简介　223\n10．1．2　Flume核心概念　223\n10．1．3　Flume 系统要求　224\n10．2　Flume架构　224\n10．3　Flume常见操作命令　225\n10．4　Flume环境搭建　226\n10．4．1　设置一个Agent　226\n10．4．2　启动Agent　226\n本章小结　231\n习题　231\n第11章　OTA离线数据分析平台　232\n11．1　项目概述　232\n11．2　功能需求　233\n11．3　软件开发关键技术　233\n11．4　效果展示　233\n11．5　平台搭建与测试　233\n11．5．1　配置ssh免密码登录　233\n11．5．2　配置JDK　234\n11．5．3　配置Hadoop　236\n11．5．4　配置Hive　242\n11．6　数据收集　247\n11．6．1　解压Flume　247\n11．6．2　修改配置文件　248\n11．6．3　启动Flume　248\n11．6．4　校验数据　248\n11．7　数据分析　249\n11．7．1　数据清洗　249\n11．7．2　ETL编程　256\n11．7．3　业务分析　261\n11．7．4　配置Sqoop　264\n11．7．5　从HDFS导出数据至MySQL　267\n11．8　数据展示　268\n11．8．1　搭建Web开发环境　268\n11．8．2　添加代码　272\n11．8．3　项目结构　282\n11．8．4　启动Tomcat　283\n11．8．5　访问Web页面　283\n本章小结　283\n习题　284","pages":"284","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29543384.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29543384.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29543384.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27139689\/","id":"27139689","publisher":"人民邮电出版社","isbn10":"7115453608","isbn13":"9787115453600","title":"Hadoop大数据开发案例教程与项目实战","url":"https:\/\/api.douban.com\/v2\/book\/27139689","alt_title":"","author_intro":"时允田，IT教育培训高级讲师，现任西普教育教研部经理。先后就职清华同方、SK、森纵艾德、八维教育和西普教育等机构，担任中北大学、南京大学、大连理工软件学院等多所高校外聘企业讲师。拥有十余年的IT从业和教育培训经验，精通Java、Android、HTML5、大数据等技术。\n林雪纲，博士，CCF理事，现任北京西普阳光教育科技股份有限公司常务副总裁。十余年信息安全及教育培训行业经验，具有丰富的信息安全和数据领域大型项目咨询、管理及教学培训经验。精通网络安全、安全架构及技术管理、大数据分析，领导参与多个安全平台研发、数字城市解决方案、移动互联网平台开发项目。","summary":"本书是一本Hadoop学习入门参考书，全书共11章，分为基础篇和提高篇两部分。基础篇包括第1~6章，具体包括Hadoop概述、Hadoop基础环境配置、分布式存储HDFS、计算系统MapReduce、计算模型Yarn、数据云盘。提高篇包括第7~11章，具体包括协调系统Zookeeper、Hadoop数据库Hbase、Hadoop数据仓库Hive、Hadoop数据采集Flume、OTA离线数据分析平台。全书内容结构合理，知识点全面，讲解详细，重点难点突出。\n本书适合作为院校计算机及相关专业大数据课程的教材，也可供学习者自学参考。","price":"49.8"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Seears, Tim; Baldeschwieler, Eric; Murthy, Aron C."],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"384","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/20560289\/","id":"20560289","publisher":"","isbn10":"1118589777","isbn13":"9781118589779","title":"Advanced Hadoop Programming - Pushing the Limits","url":"https:\/\/api.douban.com\/v2\/book\/20560289","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"技术详解与项目实战","author":["范东来"],"pubdate":"2016-7","tags":[{"count":5,"name":"大数据","title":"大数据"},{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29481521.jpg","binding":"","translator":[],"catalog":"目录\n基础篇：Hadoop基础\n第1章 绪论 2\n1.1 Hadoop和云计算 2\n1.1.1 Hadoop的电梯演讲 2\n1.1.2 Hadoop生态圈 3\n1.1.3 云计算的定义 6\n1.1.4 云计算的类型 7\n1.1.5 Hadoop和云计算 8\n1.2 Hadoop和大数据 9\n1.2.1 大数据的定义 9\n1.2.2 大数据的结构类型 10\n1.2.3 大数据行业应用实例 12\n1.2.4 Hadoop和大数据 13\n1.2.5 其他大数据处理平台 14\n1.3 数据挖掘和商业智能 15\n1.3.1 数据挖掘的定义 15\n1.3.2 数据仓库 17\n1.3.3 操作数据库系统和数据仓库系统的区别 18\n1.3.4 为什么需要分离的数据仓库 19\n1.3.5 商业智能 19\n1.3.6 大数据时代的商业智能 20\n1.4 小结 21\n第2章 环境准备 22\n2.1 Hadoop的发行版本选择 22\n2.1.1 Apache Hadoop 22\n2.1.2 CDH 22\n2.1.3 Hadoop的版本 23\n2.1.4 如何选择Hadoop的版本 25\n2.2 Hadoop架构 26\n2.2.1 Hadoop HDFS架构 27\n2.2.2 YARN架构 28\n2.2.3 Hadoop架构 28\n2.3 安装Hadoop 29\n2.3.1 安装运行环境 30\n2.3.2 修改主机名和用户名 36\n2.3.3 配置静态IP地址 36\n2.3.4 配置SSH无密码连接 37\n2.3.5 安装JDK 38\n2.3.6 配置Hadoop 39\n2.3.7 格式化HDFS 42\n2.3.8 启动Hadoop并验证安装 42\n2.4 安装Hive 43\n2.4.1 安装元数据库 44\n2.4.2 修改Hive配置文件 44\n2.4.3 验证安装 45\n2.5 安装HBase 46\n2.5.1 解压文件并修改Zookeeper相关配置 46\n2.5.2 配置节点 46\n2.5.3 配置环境变量 47\n2.5.4 启动并验证 47\n2.6 安装Sqoop 47\n2.7 Cloudera Manager 48\n2.8 小结 51\n第3章 Hadoop的基石：HDFS 52\n3.1 认识HDFS 52\n3.1.1 HDFS的设计理念 54\n3.1.2 HDFS的架构 54\n3.1.3 HDFS容错 58\n3.2 HDFS读取文件和写入文件 58\n3.2.1 块的分布 59\n3.2.2 数据读取 60\n3.2.3 写入数据 61\n3.2.4 数据完整性 62\n3.3 如何访问HDFS 63\n3.3.1 命令行接口 63\n3.3.2 Java API 66\n3.3.3 其他常用的接口 75\n3.3.4 Web UI 75\n3.4 HDFS中的新特性 76\n3.4.1 NameNode HA 76\n3.4.2 NameNode Federation 78\n3.4.3 HDFS Snapshots 79\n3.5 小结 79\n第4章 YARN：统一资源管理和调平台 80\n4.1 YARN是什么 80\n4.2 统一资源管理和调度平台范型 81\n4.2.1 集中式调度器 81\n4.2.2 双层调度器 81\n4.2.3 状态共享调度器 82\n4.3 YARN的架构 82\n4.3.1 ResourceManager 83\n4.3.2 NodeManager 85\n4.3.3 ApplicationMaster 87\n4.3.4 YARN的资源表示模型Container 87\n4.4 YARN的工作流程 88\n4.5 YARN的调度器 89\n4.5.1 YARN的资源管理机制 89\n4.5.2 FIFO Scheduler 90\n4.5.3 Capacity Scheduler 90\n4.5.4 Fair Scheduler 91\n4.6 YARN命令行 92\n4.7 Apache Mesos 95\n4.8 小结 96\n第5章 分而治之的智慧：MapReduce 97\n5.1 认识MapReduce 97\n5.1.1 MapReduce的编程思想 98\n5.1.2 MapReduce运行环境 100\n5.1.3 MapReduce作业和任务 102\n5.1.4 MapReduce的计算资源划分 102\n5.1.5 MapReduce的局限性 103\n5.2 Hello Word Count 104\n5.2.1 Word Count的设计思路 104\n5.2.2 编写Word Count 105\n5.2.3 运行程序 107\n5.2.4 还能更快吗 109\n5.3 MapReduce的过程 109\n5.3.1 从输入到输出 109\n5.3.2 input 110\n5.3.3 map及中间结果的输出 112\n5.3.4 shuffle 113\n5.3.5 reduce及最后结果的输出 115\n5.3.6 sort 115\n5.3.7 作业的进度组成 116\n5.4 MapReduce的工作机制 116\n5.4.1 作业提交 117\n5.4.2 作业初始化 118\n5.4.3 任务分配 118\n5.4.4 任务执行 118\n5.4.5 任务完成 118\n5.4.6 推测执行 119\n5.4.7 MapReduce容错 119\n5.5 MapReduce编程 120\n5.5.1 Writable类 120\n5.5.2 编写Writable类 123\n5.5.3 编写Mapper类 124\n5.5.4 编写Reducer类 125\n5.5.5 控制shuffle 126\n5.5.6 控制sort 128\n5.5.7 编写main函数 129\n5.6 MapReduce编程实例：连接 130\n5.6.1 设计思路 131\n5.6.2 编写Mapper类 131\n5.6.3 编写Reducer类 132\n5.6.4 编写main函数 133\n5.7 MapReduce编程实例：二次排序 134\n5.7.1 设计思路 134\n5.7.2 编写Mapper类 135\n5.7.3 编写Partitioner类 136\n5.7.4 编写SortComparator类 136\n5.7.5 编写Reducer类 137\n5.7.6 编写main函数 137\n5.8 MapReduce编程实例：全排序 139\n5.8.1 设计思路 139\n5.8.2 编写代码 140\n5.9 小结 141\n第6章 SQL on Hadoop：Hive 142\n6.1 认识Hive 142\n6.1.1 从MapReduce到SQL 143\n6.1.2 Hive架构 144\n6.1.3 Hive与关系型数据库的区别 146\n6.1.4 Hive命令的使用 147\n6.2 数据类型和存储格式 149\n6.2.1 基本数据类型 149\n6.2.2 复杂数据类型 149\n6.2.3 存储格式 150\n6.2.4 数据格式 151\n6.3 HQL：数据定义 152\n6.3.1 Hive中的数据库 152\n6.3.2 Hive中的表 154\n6.3.3 创建表 154\n6.3.4 管理表 156\n6.3.5 外部表 156\n6.3.6 分区表 156\n6.3.7 删除表 158\n6.3.8 修改表 158\n6.4 HQL：数据操作 159\n6.4.1 装载数据 159\n6.4.2 通过查询语句向表中插入数据 160\n6.4.3 利用动态分区向表中插入数据 160\n6.4.4 通过CTAS加载数据 161\n6.4.5 导出数据 161\n6.5 HQL：数据查询 162\n6.5.1 SELECT…FROM语句 162\n6.5.2 WHERE语句 163\n6.5.3 GROUP BY和HAVING语句 164\n6.5.4 JOIN语句 164\n6.5.5 ORDER BY和SORT BY语句 166\n6.5.6 DISTRIBUTE BY和SORT BY语句 167\n6.5.7 CLUSTER BY 167\n6.5.8 分桶和抽样 168\n6.5.9 UNION ALL 168\n6.6 Hive函数 168\n6.6.1 标准函数 168\n6.6.2 聚合函数 168\n6.6.3 表生成函数 169\n6.7 Hive用户自定义函数 169\n6.7.1 UDF 169\n6.7.2 UDAF 170\n6.7.3 UDTF 171\n6.7.4 运行 173\n6.8 小结 173\n第7章 SQL to Hadoop : Sqoop 174\n7.1 一个Sqoop示例 174\n7.2 导入过程 176\n7.3 导出过程 178\n7.4 Sqoop的使用 179\n7.4.1 codegen 180\n7.4.2 create-hive-table 180\n7.4.3 eval 181\n7.4.4 export 181\n7.4.5 help 182\n7.4.6 import 182\n7.4.7 import-all-tables 183\n7.4.8 job 184\n7.4.9 list-databases 184\n7.4.10 list-tables 184\n7.4.11 merge 184\n7.4.12 metastore 185\n7.4.13 version 186\n7.5 小结 186\n第8章 HBase:HadoopDatabase 187\n8.1 酸和碱：两种数据库事务方法论 187\n8.1.1 ACID 188\n8.1.2 BASE 188\n8.2 CAP定理 188\n8.3 NoSQL的架构模式 189\n8.3.1 键值存储 189\n8.3.2 图存储 190\n8.3.3 列族存储 191\n8.3.4 文档存储 192\n8.4 HBase的架构模式 193\n8.4.1 行键、列族、列和单元格 193\n8.4.2 HMaster 194\n8.4.3 Region和RegionServer 195\n8.4.4 WAL 195\n8.4.5 HFile 195\n8.4.6 Zookeeper 197\n8.4.7 HBase架构 197\n8.5 HBase写入和读取数据 198\n8.5.1 Region定位 198\n8.5.2 HBase写入数据 199\n8.5.3 HBase读取数据 199\n8.6 HBase基础API 200\n8.6.1 创建表 201\n8.6.2 插入 202\n8.6.3 读取 203\n8.6.4 扫描 204\n8.6.5 删除单元格 206\n8.6.6 删除表 207\n8.7 HBase高级API 207\n8.7.1 过滤器 208\n8.7.2 计数器 208\n8.7.3 协处理器 209\n8.8 小结 214\n第9章 Hadoop性能调优和运维 215\n9.1 Hadoop客户端 215\n9.2 Hadoop性能调优 216\n9.2.1 选择合适的硬件 216\n9.2.2 操作系统调优 218\n9.2.3 JVM调优 219\n9.2.4 Hadoop参数调优 219\n9.3 Hive性能调优 225\n9.3.1 JOIN优化 226\n9.3.2 Reducer的数量 226\n9.3.3 列裁剪 226\n9.3.4 分区裁剪 226\n9.3.5 GROUP BY优化 226\n9.3.6 合并小文件 227\n9.3.7 MULTI-GROUP BY和MULTI-INSERT 228\n9.3.8 利用UNION ALL 特性 228\n9.3.9 并行执行 228\n9.3.10 全排序 228\n9.3.11 Top N 229\n9.4 HBase调优 229\n9.4.1 通用调优 229\n9.4.2 客户端调优 230\n9.4.3 写调优 231\n9.4.4 读调优 231\n9.4.5 表设计调优 232\n9.5 Hadoop运维 232\n9.5.1 集群节点动态扩容和卸载 233\n9.5.2 利用SecondaryNameNode恢复NameNode 234\n9.5.3 常见的运维技巧 234\n9.5.4 常见的异常处理 235\n9.6 小结 236\n应用篇：商业智能系统项目实战\n第10章 在线图书销售商业智能系统 238\n10.1 项目背景 238\n10.2 功能需求 239\n10.3 非功能需求 240\n10.4 小结 240\n第11章 系统结构设计 241\n11.1 系统架构 241\n11.2 功能设计 242\n11.3 数据仓库结构 243\n11.4 系统网络拓扑与硬件选型 246\n11.4.1 系统网络拓扑 246\n11.4.2 系统硬件选型 248\n11.5 技术选型 249\n11.5.1 平台选型 249\n11.5.2 系统开发语言选型 249\n11.6 小结 249\n第12章 在开发之前 250\n12.1 新建一个工程 250\n12.1.1 安装Python 250\n12.1.2 安装PyDev插件 251\n12.1.3 新建PyDev项目 252\n12.2 代码目录结构 253\n12.3 项目的环境变量 253\n12.4 如何调试 254\n12.5 小结 254\n第13章 实现数据导入导出模块 255\n13.1 处理流程 255\n13.2 导入方式 256\n13.2.1 全量导入 256\n13.2.2 增量导入 256\n13.3 读取配置文件 257\n13.4 SqoopUtil 261\n13.5 整合 262\n13.6 导入说明 262\n13.7 导出模块 263\n13.8 小结 265\n第14章 实现数据分析工具模块 266\n14.1 处理流程 266\n14.2 读取配置文件 266\n14.3 HiveUtil 268\n14.4 整合 268\n14.5 数据分析和报表 269\n14.5.1 OLAP和Hive 269\n14.5.2 OLAP和多维模型 270\n14.5.3 选MySQL还是选HBase 272\n14.6 小结 273\n第15章 实现业务数据的数据清洗模块 274\n15.1 ETL 274\n15.1.1 数据抽取 274\n15.1.2 数据转换 274\n15.1.3 数据清洗工具 275\n15.2 处理流程 275\n15.3 数据去重 276\n15.3.1 产生原因 276\n15.3.2 去重方法 277\n15.3.3 一个很有用的UDF： RowNum 277\n15.3.4 第二种去重方法 279\n15.3.5 进行去重 279\n15.4 小结 282\n第16章 实现点击流日志的数据清洗模块 283\n16.1 数据仓库和Web 283\n16.2 处理流程 285\n16.3 字段的获取 285\n16.4 编写MapReduce作业 288\n16.4.1 编写IP地址解析器 288\n16.4.2 编写Mapper类 291\n16.4.3 编写Partitioner类 295\n16.4.4 编写SortComparator类 295\n16.4.5 编写Reducer类 297\n16.4.6 编写main函数 298\n16.4.7 通过Python调用jar文件 299\n16.5 还能做什么 300\n16.5.1 网站分析的指标 300\n16.5.2 网站分析的决策支持 301\n16.6 小结 301\n第17章 实现购书转化率分析模块 302\n17.1 漏斗模型 302\n17.2 处理流程 303\n17.3 读取配置文件 303\n17.4 提取所需数据 304\n17.5 编写转化率分析MapReduce作业 305\n17.5.1 编写Mapper类 306\n17.5.2 编写Partitioner类 308\n17.5.3 编写SortComparator类 309\n17.5.4 编写Reducer类 310\n17.5.5 编写Driver类 312\n17.5.6 通过Python模块调用jar文件 314\n17.6 对中间结果进行汇总得到最终 结果 314\n17.7 整合 316\n17.8 小结 316\n第18章 实现购书用户聚类模块 317\n18.1 物以类聚 317\n18.2 聚类算法 318\n18.2.1 k-means算法 318\n18.2.2 Canopy算法 319\n18.2.3 数据向量化 320\n18.2.4 数据归一化 321\n18.2.5 相似性度量 322\n18.3 用MapReduce实现聚类算法 323\n18.3.1 Canopy算法与MapReduce 323\n18.3.2 k-means算法与MapReduce 323\n18.3.3 Apache Mahout 324\n18.4 处理流程 324\n18.5 提取数据并做归一化 325\n18.6 维度相关性 327\n18.6.1 维度的选取 327\n18.6.2 相关系数与相关系数矩阵 328\n18.6.3 计算相关系数矩阵 328\n18.7 使用Mahout完成聚类 329\n18.7.1 使用Mahout 329\n18.7.2 解析Mahout的输出 332\n18.7.3 得到聚类结果 334\n18.8 得到最终结果 335\n18.9 评估聚类结果 337\n18.9.1 一份不适合聚类的数据 337\n18.9.2 簇间距离和簇内距离 337\n18.9.3 计算平均簇间距离 338\n18.10 小结 339\n第19章 实现调度模块 340\n19.1 工作流 340\n19.2 编写代码 341\n19.3 crontab 342\n19.4 让数据说话 343\n19.5 小结 344\n结束篇：总结和展望\n第20章 总结和展望 346\n20.1 总结 346\n20.2 BDAS 347\n20.3 Dremel系技术 348\n20.4 Pregel系技术 349\n20.5 Docker和Kubernetes 350\n20.6 数据集成工具NiFi 350\n20.7 小结 351\n参考文献 352","pages":"351","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29481521.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29481521.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29481521.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27075552\/","id":"27075552","publisher":"人民邮电出版社","isbn10":"7115427461","isbn13":"9787115427465","title":"Hadoop海量数据处理（第2版）","url":"https:\/\/api.douban.com\/v2\/book\/27075552","alt_title":"","author_intro":"范东来，北京航空航天大学硕士，技术图书作者和译者，著有《Hadoop海量数据处理》（该书台湾繁体字版为《Hadoop：BigData技術詳解與專案實作》），译有《解读NoSQL》。BBD（数联铭品）大数据技术部负责人，大数据平台架构师，极客学院布道师。研究方向：并行图挖掘、去中心化应用。","summary":"","price":"59.00"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"","author":["谭磊","范磊"],"pubdate":"2017-1","tags":[{"count":1,"name":"垃圾","title":"垃圾"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"","pages":"279","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/27116156\/","id":"27116156","publisher":"清华大学出版社","isbn10":"7302459274","isbn13":"9787302459279","title":"Hadoop应用实战","url":"https:\/\/api.douban.com\/v2\/book\/27116156","alt_title":"","author_intro":"","summary":"","price":"48"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["黄东军"],"pubdate":"2017-7","tags":[{"count":4,"name":"大数据","title":"大数据"},{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29675556.jpg","binding":"平装","translator":[],"catalog":"第一篇 大数据的基本概念和技术\n第1章 绪论 3\n1.1 时代背景 3\n1.1.1 全球大数据浪潮 3\n1.1.2 我国的大数据国家战略 5\n1.2 大数据的概念 7\n1.2.1 概念 7\n1.2.2 特征 8\n1.3 技术支撑体系 9\n1.3.1 概览 9\n1.3.2 大数据采集层 9\n1.3.3 大数据存储层 10\n1.3.4 大数据分析（处理与服务）层 11\n1.3.5 大数据应用层 11\n1.3.6 垂直视图 13\n1.4 大数据人才及其能力要求 14\n1.4.1 首席数据官 14\n1.4.2 数据科学家（数据分析师） 15\n1.4.3 大数据开发工程师 16\n1.4.4 大数据运维工程师 17\n1.5 本章小结 17\n第2章 Hadoop大数据关键技术 19\n2.1 Hadoop生态系统 19\n2.1.1 架构的基本理论 19\n2.1.2 主要组件及其关系 21\n2.2 数据采集 24\n2.2.1 结构化数据采集工具 24\n2.2.2 日志文件采集工具与技术 25\n2.3 大数据存储技术 29\n2.3.1 相关概念 29\n2.3.2 分布式文件存储系统 34\n2.3.3 数据库与数据仓库 38\n2.4 分布式计算框架 43\n2.4.1 离线计算框架 43\n2.4.2 实时流计算平台 50\n2.5 数据分析平台与工具 57\n2.5.1 面向大数据的数据挖掘与分析工具 57\n2.5.2 机器学习 61\n2.6 本章小结 66\n第二篇 Hadoop大数据平台搭建与基本应用\n第3章 Linux操作系统与集群搭建 69\n3.1 Linux操作系统 69\n3.1.1 概述 69\n3.1.2 特点 70\n3.1.3 Linux的组成 72\n3.2 Linux安装与集群搭建 75\n3.2.1 安装VMware Workstation 75\n3.2.2 在VMware上安装Linux（CentOS7） 79\n3.3 集群的配置 91\n3.3.1 设置主机名 91\n3.3.2 网络设置 93\n3.3.3 关闭防火墙 98\n3.3.4 安装JDK 99\n3.3.5 免密钥登录配置 102\n3.4 Linux基本命令 105\n3.5 本章小结 112\n第4章 HDFS安装与基本应用 113\n4.1 HDFS概述 113\n4.1.1 特点 113\n4.1.2 主要组件与架构 114\n4.2 HDFS架构分析 114\n4.2.1 数据块 114\n4.2.2 NameNode 115\n4.2.3 DataNode 116\n4.2.4 SecondaryNameNode 117\n4.2.5 数据备份 117\n4.2.6 通信协议 118\n4.2.7 可靠性保证 118\n4.3 文件操作过程分析 119\n4.3.1 读文件 119\n4.3.2 写文件 120\n4.3.3 删除文件 122\n4.4 Hadoop HDFS安装与配置 122\n4.4.1 解压Hadoop安装包 122\n4.4.2 配置Hadoop环境变量 123\n4.4.3 配置Yarn环境变量 124\n4.4.4 配置核心组件文件 125\n4.4.5 配置文件系统 125\n4.4.6 配置yarn-site.xml文件 126\n4.4.7 配置MapReduce计算框架文件 128\n4.4.8 配置Master的slaves文件 129\n4.4.9 复制Master上的Hadoop到Slave节点 129\n4.5 Hadoop集群的启动 130\n4.5.1 配置操作系统环境变量 130\n4.5.2 创建Hadoop数据目录 131\n4.5.3 格式化文件系统 132\n4.5.4 启动和关闭Hadoop 133\n4.5.5 验证Hadoop是否启动成功 133\n4.6 Hadoop集群的基本应用 136\n4.6.1 HDFS基本命令 136\n4.6.2 在Hadoop集群中运行程序 139\n4.7 本章小结 141\n第5章 MapReduce与Yarn 143\n5.1 MapReduce程序的概念 143\n5.1.1 基本编程模型 143\n5.1.2 计算过程分析 144\n5.2 深入理解Yarn 147\n5.2.1 Yarn的基本架构 147\n5.2.2 Yarn的工作流程 151\n5.3 在Linux平台安装Eclipse 152\n5.3.1 Eclipse简介 153\n5.3.2 安装并启动Eclipse 154\n5.4 开发MapReduce程序的基本方法 155\n5.4.1 为Eclipse安装Hadoop插件 156\n5.4.2 WordCount：第一个MapReduce程序 160\n5.5 本章小结 175\n第6章 Hive和HBase的安装与应用 177\n6.1 在CentOS7下安装MySQL 177\n6.1.1 下载或复制MySQL安装包 177\n6.1.2 执行安装命令 178\n6.1.3 启动MySQL 179\n6.1.4 登录MySQL 179\n6.1.5 使用MySQL 181\n6.1.6 问题与解决办法 182\n6.2 Hive安装与应用 183\n6.2.1 下载并解压Hive安装包 183\n6.2.2 配置Hive 184\n6.2.3 启动并验证Hive 187\n6.2.4 Hive的基本应用 189\n6.3 ZooKeeper集群安装 190\n6.3.1 ZooKeeper简介 190\n6.3.2 安装ZooKeeper 191\n6.3.3 配置ZooKeeper 191\n6.3.4 启动和测试 193\n6.4 HBase的安装与应用 195\n6.4.1 解压并安装HBase 195\n6.4.2 配置HBase 196\n6.4.3 启动并验证HBase 199\n6.4.4 HBase的基本应用 200\n6.4.5 应用HBase中常见问题及其解决办法 203\n6.5 本章小结 204\n第7章 Sqoop和Kafka的安装与应用 205\n7.1 安装部署Sqoop 205\n7.1.1 下载或复制Sqoop安装包 205\n7.1.2 解压并安装Sqoop 206\n7.1.3 配置Sqoop 206\n7.1.4 启动并验证Sqoop 208\n7.1.5 测试Sqoop与MySQL的连接 209\n7.2 安装部署Kafka集群 211\n7.2.1 下载或复制Kafka安装包 211\n7.2.2 解压缩Kafka安装包 211\n7.2.3 配置Kafka集群 211\n7.2.4 Kafka的初步应用 213\n7.3 本章小结 218\n第8章 Spark集群安装与开发环境配置 219\n8.1 深入理解Spark 219\n8.1.1 Spark系统架构 219\n8.1.2 关键概念 221\n8.2 安装与配置Scala 224\n8.2.1 下载Scala安装包 225\n8.2.2 安装Scala 225\n8.2.3 启动并应用Scala 226\n8.3 Spark集群的安装与配置 226\n8.3.1 安装模式 226\n8.3.2 Spark的安装 227\n8.3.3 启动并验证Spark 230\n8.3.4 几点说明 234\n8.4 开发环境安装与配置 236\n8.4.1 IDEA简介 236\n8.4.2 IDEA的安装 236\n8.4.3 IDEA的配置 238\n8.5 本章小结 243\n第9章 Spark应用基础 245\n9.1 Spark程序的运行模式 245\n9.1.1 Spark on Yarn-cluster 245\n9.1.2 Spark on Yarn-client 246\n9.2 Spark应用设计 247\n9.2.1 分布式估算圆周率 248\n9.2.2 基于Spark MLlib的贷款风险预测 265\n9.3 本章小结 285\n第三篇 数据处理与项目开发术\n第10章 交互式数据处理 289\n10.1 数据预处理 289\n10.1.1 查看数据 289\n10.1.2 数据扩展 291\n10.1.3 数据过滤 292\n10.1.4 数据上传 293\n10.2 创建数据仓库 294\n10.2.1 创建Hive数据仓库的基本命令 294\n10.2.2 创建Hive分区表 296\n10.3 数据分析 299\n10.3.1 基本统计 299\n10.3.2 用户行为分析 301\n10.3.3 实时数据 303\n10.4 本章小结 304\n第11章 协同过滤推荐系统 305\n11.1 推荐算法概述 305\n11.1.1 基于人口统计学的推荐 305\n11.1.2 基于内容的推荐 306\n11.1.3 协同过滤推荐 307\n11.2 协同过滤推荐算法分析 308\n11.2.1 基于用户的协同过滤推荐 308\n11.2.2 基于物品的协同过滤推荐 310\n11.3 Spark MLlib推荐算法应用 312\n11.3.1 ALS算法原理 312\n11.3.2 ALS的应用设计 315\n11.4 本章小结 329\n第12章 销售数据分析系统 331\n12.1 数据采集 331\n12.1.1 在Windows下安装JDK 331\n12.1.2 在Windows下安装Eclipse 334\n12.1.3 将WebCollector项目导入Eclipse 335\n12.1.4 在Windows下安装MySQL 336\n12.1.5 连接JDBC 339\n12.1.6 运行爬虫程序 340\n12.2 在HBase集群上准备数据 342\n12.2.1 将数据导入到MySQL 342\n12.2.2 将MySQL表中的数据导入到HBase表中 344\n12.3 安装Phoenix中间件 347\n12.3.1 Phoenix架构 347\n12.3.2 解压安装Phoenix 348\n12.3.3 Phoenix环境配置 349\n12.3.4 使用Phoenix 350\n12.4 基于Web的前端开发 353\n12.4.1 将Web前端项目导入Eclipse 353\n12.4.2 安装Tomcat 355\n12.4.3 在Eclipse中配置Tomcat 355\n12.4.4 在Web浏览器中查看执行结果 359\n12.5 本章小结 361","ebook_url":"https:\/\/read.douban.com\/ebook\/58108676\/","pages":"380","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29675556.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29675556.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29675556.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30126096\/","id":"30126096","publisher":"电子工业出版社","isbn10":"7121318210","isbn13":"9787121318214","title":"Hadoop大数据实战权威指南","url":"https:\/\/api.douban.com\/v2\/book\/30126096","alt_title":"","author_intro":"","summary":"大数据贵在落实！ 本书是一本讲解大数据实战的图书，按照“深入分析组件原理、充分展示搭建过程、详细指导应用开发”编写。全书分为三篇，第一篇为大数据的基本概念和技术，主要介绍大数据的背景、发展及关键技术；第二篇为Hadoop大数据平台搭建与基本应用，内容涉及Linux、HDFS、MapReduce、YARN、Hive、HBase、Sqoop、Kafka、Spark等；第三篇为大数据处理与项目开发，包括交互式数据处理、协同过滤推荐系统、销售数据分析系统，并就京东的部分销售数据应用大数据进行处理分析。","ebook_price":"30.60","series":{"id":"40847","title":"大数据科学与应用丛书"},"price":"68.00元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"工作","title":"工作"},{"count":1,"name":"C","title":"C"},{"count":1,"name":"*收藏","title":"*收藏"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30296647\/","id":"30296647","publisher":"人民邮电出版社","isbn10":"7115454108","isbn13":"9787115454102","title":"大数据技术基础——基于Hadoop与Spark","url":"https:\/\/api.douban.com\/v2\/book\/30296647","alt_title":"","author_intro":"","summary":"","series":{"id":"45630","title":"大数据创新人才培养系列"},"price":"49.8"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["温春水、毕洁馨"],"pubdate":"2019-3","tags":[{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32132510.jpg","binding":"","translator":[],"catalog":"前言\n第1篇 Hadoop基础知识\n第1章 初识Hadoop\t2\n1.1 大数据初探\t2\n1.1.1 大数据技术\t2\n1.1.2 大数据技术框架\t3\n1.1.3 大数据的特点\t3\n1.1.4 大数据在各个行业中的应用\t4\n1.1.5 大数据计算模式\t4\n1.1.6 大数据与云计算、物联网的关系\t4\n1.2 Hadoop简介\t5\n1.2.1 Hadoop应用现状\t6\n1.2.2 Hadoop简介与意义\t6\n1.3 小结\t6\n第2章 Hadoop的安装与配置\t7\n2.1 虚拟机的创建\t7\n2.2 安装Linux系统\t10\n2.3 配置网络信息\t11\n2.4 克隆服务器\t12\n2.5 SSH免密码登录\t13\n2.6 安装和配置JDK\t15\n2.6.1 上传安装包\t15\n2.6.2 安装JDK\t16\n2.6.3 配置环境变量\t16\n2.7 Hadoop环境变量配置\t16\n2.7.1 解压缩Hadoop压缩包\t17\n2.7.2 配置Hadoop的bin和sbin文件夹到环境变量中\t17\n2.7.3 修改\/etc\/hadoop\/hadoop-env.sh\t17\n2.8 Hadoop分布式安装\t17\n2.8.1 伪分布式安装\t17\n2.8.2 完全分布式安装\t19\n2.9 小结\t21\n第3章 Hadoop分布式文件系统\t22\n3.1 DFS介绍\t22\n3.1.1 什么是DFS\t22\n3.1.2 DFS的结构\t22\n3.2 HDFS介绍\t23\n3.2.1 HDFS的概念及体系结构\t23\n3.2.2 HDFS的设计\t23\n3.2.3 HDFS的优点和缺点\t24\n3.2.4 HDFS的执行原理\t24\n3.2.5 HDFS的核心概念\t25\n3.2.6 HDFS读文件流程\t27\n3.2.7 HDFS写文件流程\t28\n3.2.8 Block的副本放置策略\t29\n3.3 Hadoop中HDFS的常用命令\t30\n3.3.1 对文件的操作\t30\n3.3.2 管理与更新\t31\n3.4 HDFS的应用\t31\n3.4.1 基于Shell的操作\t31\n3.4.2 基于Java API的操作\t33\n3.4.3 创建文件夹\t34\n3.4.4 递归显示文件\t34\n3.4.5 文件上传\t35\n3.4.6 文件下载\t35\n3.5 小结\t36\n第4章 基于Hadoop 3的HDFS高可用\t37\n4.1 Hadoop 3.x的发展\t37\n4.1.1 Hadoop 3新特性\t37\n4.1.2 Hadoop 3 HDFS集群架构\t38\n4.2 Hadoop 3 HDFS完全分布式搭建\t39\n4.2.1 安装JDK\t40\n4.2.2 配置JDK环境变量\t40\n4.2.3 配置免密码登录\t40\n4.2.4 配置IP和主机名字映射关系\t41\n4.2.5 SSH免密码登录设置\t41\n4.2.6 配置Hadoop 3.1.0\t42\n4.3 什么是HDFS高可用\t47\n4.3.1 HDFS高可用实现原理\t47\n4.3.2 HDFS高可用实现\t48\n4.4 搭建HDFS高可用\t50\n4.4.1 配置ZooKeeper\t50\n4.4.2 配置Hadoop配置文件\t52\n4.4.3 将配置文件复制到其他节点上\t54\n4.4.4 启动JN节点\t54\n4.4.5 格式化\t55\n4.4.6 复制元数据到node2节点上\t55\n4.4.7 格式化ZKFC\t55\n4.4.8 启动集群\t56\n4.4.9 通过浏览器查看集群状态\t56\n4.4.10 高可用测试\t57\n4.5 小结\t58\n第2篇 Hadoop核心技术\n第5章 Hadoop的分布式协调服务——ZooKeeper\t60\n5.1 ZooKeeper的核心概念\t60\n5.1.1 Session会话机制\t60\n5.1.2 数据节点、版本与Watcher的关联\t61\n5.1.3 ACL策略\t61\n5.2 ZooKeeper的安装与运行\t61\n5.3 ZooKeeper服务器端的常用命令\t63\n5.4 客户端连接ZooKeeper的相关操作\t64\n5.4.1 查看ZooKeeper常用命令\t64\n5.4.2 connect命令与ls命令\t65\n5.4.3 create命令——创建节点\t65\n5.4.4 get命令——获取数据与信息\t66\n5.4.5 set命令——修改节点内容\t66\n5.4.6 delete命令——删除节点\t67\n5.5 使用Java API访问ZooKeeper\t67\n5.5.1 环境准备与创建会话实例\t68\n5.5.2 节点创建实例\t69\n5.5.3 Java API访问ZooKeeper实例\t70\n5.6 小结\t73\n第6章 分布式离线计算框架——MapReduce\t74\n6.1 MapReduce概述\t74\n6.1.1 MapReduce的特点\t74\n6.1.2 MapReduce的应用场景\t75\n6.2 MapReduce执行过程\t76\n6.2.1 单词统计实例\t76\n6.2.2 MapReduce执行过程\t77\n6.2.3 MapReduce的文件切片Split\t77\n6.2.4 Map过程和Reduce过程\t78\n6.2.5 Shuffle过程\t78\n6.3 MapReduce实例\t79\n6.3.1 WordCount本地测试实例\t79\n6.3.2 ETL本地测试实例\t84\n6.4 温度排序实例\t86\n6.4.1 时间和温度的封装类MyKey.Java\t87\n6.4.2 Map任务MyMapper.java\t88\n6.4.3 数据分组类MyGroup.Java\t89\n6.4.4 温度排序类MySort.java\t89\n6.4.5 数据分区MyPartitioner.java\t90\n6.4.6 Reducer任务MyReducer.java\t90\n6.4.7 主函数RunJob.java\t91\n6.5 小结\t94\n第7章 Hadoop的集群资源管理系统——YARN\t95\n7.1 为什么要使用YARN\t95\n7.2 YARN的基本架构\t96\n7.2.1 ResourceManager进程\t96\n7.2.2 ApplicationMaster和NodeManager\t97\n7.3 YARN工作流程\t97\n7.4 YARN搭建\t98\n7.5 小结\t100\n第8章 Hadoop的数据仓库框架——Hive\t101\n8.1 Hive的理论基础\t101\n8.1.1 什么是Hive\t101\n8.1.2 Hive和数据库的异同\t102\n8.1.3 Hive设计的目的与应用\t104\n8.1.4 Hive的运行架构\t104\n8.1.5 Hive的执行流程\t105\n8.1.6 Hive服务\t106\n8.1.7 元数据存储Metastore\t106\n8.1.8 Embedded模式\t107\n8.1.9 Local模式\t108\n8.1.10 Remote模式\t109\n8.2 Hive的配置与安装\t109\n8.2.1 安装MySQL\t110\n8.2.2 配置Hive\t112\n8.3 Hive表的操作\t113\n8.3.1 创建Hive表\t114\n8.3.2 导入数据\t114\n8.4 表的分区与分桶\t115\n8.4.1 表的分区\t115\n8.4.2 表的分桶\t117\n8.5 内部表与外部表\t118\n8.5.1 内部表\t119\n8.5.2 外部表\t119\n8.6 内置函数与自定义函数\t121\n8.6.1 内置函数实例\t121\n8.6.2 自定义UDAF函数实例\t123\n8.7 通过Java访问Hive\t124\n8.8 Hive优化\t125\n8.8.1 MapReduce优化\t126\n8.8.2 配置优化\t126\n8.9 小结\t127\n第9章 大数据快速读写——HBase\t128\n9.1 关于NoSQL\t128\n9.1.1 什么是NoSQL\t128\n9.1.2 NoSQL数据库的分类\t129\n9.1.3 NoSQL数据库的应用\t129\n9.1.4 关系型数据库与非关系型数据库的区别\t130\n9.2 HBase基础\t130\n9.2.1 HBase简介\t130\n9.2.2 HBase数据模型\t131\n9.2.3 HBase体系架构及组件\t132\n9.2.4 HBase执行原理\t134\n9.3 HBase安装\t135\n9.4 HBase的Shell操作\t138\n9.5 Java API访问HBase实例\t139\n9.5.1 创建表\t139\n9.5.2 插入数据\t140\n9.5.3 查询数据\t141\n9.6 小结\t142\n第10章 海量日志采集工具——Flume\t143\n10.1 什么是Flume\t143\n10.2 Flume的特点\t143\n10.3 Flume架构\t144\n10.4 Flume的主要组件\t144\n10.4.1 Event、Client与Agent——数据传输\t145\n10.4.2 Source—Event接收\t145\n10.4.3 Channel—Event传输\t146\n10.4.4 Sink—Event发送\t147\n10.4.5 其他组件\t148\n10.5 Flume安装\t148\n10.6 Flume应用典型实例\t149\n10.6.1 本地数据读取（conf1）\t149\n10.6.2 收集至HDFS\t150\n10.6.3 基于日期分区的数据收集\t152\n10.7 通过exec命令实现数据收集\t153\n10.7.1 安装工具\t153\n10.7.2 编辑配置文件conf4\t155\n10.7.3 运行Flume\t156\n10.7.4 查看生成的文件\t156\n10.7.5 查看HDFS中的数据\t157\n10.8 小结\t158\n第11章 Hadoop和关系型数据库间的数据传输工具——Sqoop\t159\n11.1 什么是Sqoop\t159\n11.2 Sqoop工作机制\t159\n11.3 Sqoop的安装与配置\t161\n11.3.1 下载Sqoop\t161\n11.3.2 Sqoop配置\t162\n11.4 Sqoop数据导入实例\t163\n11.4.1 向HDFS中导入数据\t165\n11.4.2 将数据导入Hive\t167\n11.4.3 向HDFS中导入查询结果\t170\n11.5 Sqoop数据导出实例\t172\n11.6 小结\t173\n第12章 分布式消息队列——Kafka\t174\n12.1 什么是Kafka\t174\n12.2 Kafka的架构和主要组件\t174\n12.2.1 消息记录的类别名——Topic\t175\n12.2.2 Producer与Consumer——数据的生产和消费\t176\n12.2.3 其他组件——Broker、Partition、Offset、Segment\t177\n12.3 Kafka的下载与集群安装\t177\n12.3.1 安装包的下载与解压\t177\n12.3.2 Kafka的安装配置\t178\n12.4 Kafka应用实例\t181\n12.4.1 Producer实例\t181\n12.4.2 Consumer实例\t182\n12.5 小结\t184\n第13章 开源的内存数据库——Redis\t185\n13.1 Redis简介\t185\n13.1.1 什么是Redis\t185\n13.1.2 Redis的特点\t186\n13.2 Redis安装与配置\t186\n13.3 客户端登录\t187\n13.3.1 密码为空登录\t187\n13.3.2 设置密码登录\t188\n13.4 Redis的数据类型\t188\n13.4.1 String类型\t188\n13.4.2 List类型\t190\n13.4.3 Hash类型\t191\n13.4.4 Set类型\t194\n13.5 小结\t197\n第14章 Ambari和CDH\t198\n14.1 Ambari的安装与集群管理\t198\n14.1.1 认识HDP与Ambari\t198\n14.1.2 Ambari的搭建\t199\n14.1.3 配置网卡与修改本机名\t199\n14.1.4 定义DNS服务器与修改hosts主机映射关系\t200\n14.1.5 关闭防火墙并安装JDK\t200\n14.1.6 升级OpenSSL安全套接层协议版本\t201\n14.1.7 关闭SELinux的强制访问控制\t201\n14.1.8 SSH免密码登录\t202\n14.1.9 同步NTP\t202\n14.1.10 关闭Linux的THP服务\t204\n14.1.11 配置UMASK与HTTP服务\t204\n14.1.12 安装本地源制作相关工具与Createrepo\t205\n14.1.13 禁止离线更新与制作本地源\t205\n14.1.14 安装Ambari-server与MySQL\t208\n14.1.15 安装Ambari\t210\n14.1.16 安装Agent与Ambari登录安装\t211\n14.1.17 安装部署问题解决方案\t214\n14.2 CDH的安装与集群管理\t216\n14.2.1 什么是CDH和Cloudera Manager介绍\t216\n14.2.2 Cloudera Manager与Ambari对比的优势\t216\n14.2.3 CDH安装和网卡配置\t217\n14.2.4 修改本机名与定义DNS服务器\t217\n14.2.5 修改hosts主机映射关系\t218\n14.2.6 关闭防火墙\t218\n14.2.7 安装JDK\t219\n14.2.8 升级OpenSSL安全套接层协议版本\t219\n14.2.9 禁用SELinux的强制访问功能\t220\n14.2.10 SSH 免密码登录\t220\n14.2.11 同步NTP安装\t220\n14.2.12 安装MySQL\t222\n14.2.13 安装Cloudera Manager\t222\n14.2.14 添加MySQL驱动包和修改Agent配置\t223\n14.2.15 初始化CM5数据库和创建cloudera-scm用户\t223\n14.2.16 准备Parcels\t223\n14.2.17 CDH的安装配置\t224\n14.3 小结\t227\n第15章 快速且通用的集群计算系统——Spark\t228\n15.1 Spark基础知识\t228\n15.1.1 Spark的特点\t228\n15.1.2 Spark和Hadoop的比较\t229\n15.2 弹性分布式数据集RDD\t230\n15.2.1 RDD的概念\t230\n15.2.2 RDD的创建方式\t230\n15.2.3 RDD的操作\t230\n15.2.4 RDD的执行过程\t231\n15.3 Spark作业运行机制\t232\n15.4 运行在YARN上的Spark\t233\n15.4.1 在YARN上运行Spark\t233\n15.4.2 Spark在YARN上的两种部署模式\t233\n15.5 Spark集群安装\t234\n15.5.1 Spark安装包的下载\t234\n15.5.2 Spark安装环境\t236\n15.5.3 Scala安装和配置\t236\n15.5.4 Spark分布式集群配置\t238\n15.6 Spark实例详解\t241\n15.6.1 网站用户浏览次数最多的URL统计\t241\n15.6.2 用户地域定位实例\t243\n15.7 小结\t246\n第3篇 Hadoop项目案例实战\n第16章 基于电商产品的大数据业务分析系统实战\t248\n16.1 项目背景、实现目标和项目需求\t248\n16.2 功能与流程\t249\n16.2.1 用户信息\t250\n16.2.2 商品信息\t251\n16.2.3 购买记录\t251\n16.3 数据收集\t252\n16.3.1 Flume的配置文件\t252\n16.3.2 启动Flume\t253\n16.3.3 查看采集后的文件\t253\n16.3.4 通过后台命令查看文件\t254\n16.3.5 查看文件内容\t255\n16.3.6 上传user.list文件\t256\n16.3.7 上传brand.list目录\t256\n16.4 数据预处理\t257\n16.5 数据分析——创建外部表\t261\n16.6 建立模型\t264\n16.6.1 各年龄段用户消费总额\t264\n16.6.2 查询各品牌销售总额\t265\n16.6.3 查询各省份消费总额\t266\n16.6.4 使用Sqoop将数据导入MySQL数据库\t266\n16.7 数据可视化\t268\n16.8 小结\t272\n第17章 用户画像分析实战\t273\n17.1 项目背景\t273\n17.2 项目目标与项目开发过程\t274\n17.2.1 数据采集\t274\n17.2.2 数据预处理\t275\n17.2.3 模型构建\t275\n17.2.4 数据分析\t276\n17.3 核心代码解读\t277\n17.3.1 项目流程介绍\t277\n17.3.2 核心类的解读\t278\n17.3.3 core-site.xml配置文件\t279\n17.3.4 hdfs-site.xml配置文件\t279\n17.3.5 UserProfile.properties配置文件\t280\n17.3.6 LoadConfig.java：读取配置信息\t280\n17.3.7 ReadFile.java：读取文件\t281\n17.3.8 ReadFromHdfs.java：提取信息\t281\n17.3.9 UserProfile.java：创建用户画像\t282\n17.3.10 TextArrayWritable.java：字符串处理工具类\t285\n17.3.11 MapReduce任务1：UserProfileMapReduce.java\t285\n17.3.12 MapReduce任务2：UserProfileMapReduce2.java\t289\n17.3.13 UserProfilePutInHbaseMap.java：提取用户画像\t291\n17.3.14 UserProfilePutInHbaseReduce：存储用户画像\t292\n17.4 项目部署\t293\n17.5 小结\t294\n第18章 基于个性化的视频推荐系统实战\t295\n18.1 项目背景\t295\n18.2 项目目标与推荐系统简介\t295\n18.2.1 推荐系统的分类\t295\n18.2.2 推荐模型的构建流程\t296\n18.2.3 推荐系统核心算法\t297\n18.2.4 如何基于Mahout框架完成商品推荐\t300\n18.2.5 基于Mahout框架的商品推荐实例\t300\n18.3 推荐系统项目架构\t302\n18.4 推荐系统模型构建\t303\n18.5 核心代码\t304\n18.5.1 公共部分\t305\n18.5.2 离线部分\t307\n18.5.3 在线部分\t311\n18.6 小结\t314\n第19章 电信离网用户挽留实战\t315\n19.1 商业理解\t315\n19.2 数据理解\t316\n19.2.1 收集数据\t316\n19.2.2 了解数据\t317\n19.2.3 保证数据质量\t318\n19.3 数据整理\t318\n19.3.1 数据整合\t318\n19.3.2 数据过滤\t319\n19.4 数据清洗\t319\n19.4.1 噪声识别\t320\n19.4.2 离群值和极端值的定义\t321\n19.4.3 离群值处理方法\t321\n19.4.4 数据空值处理示例\t323\n19.5 数据转换\t324\n19.5.1 变量转换\t324\n19.5.2 压缩分类水平数\t324\n19.5.3 连续数据离散化\t325\n19.5.4 变换哑变量\t326\n19.5.5 数据标准化\t326\n19.5.6 数据压缩\t326\n19.6 建模\t327\n19.6.1 决策树算法概述\t327\n19.6.2 决策树的训练步骤\t327\n19.6.3 训练决策树\t328\n19.6.4 C4.5算法\t329\n19.6.5 决策树剪枝\t332\n19.7 评估\t335\n19.7.1 混淆矩阵\t335\n19.7.2 ROC曲线\t336\n19.8 部署\t338\n19.9 用户离网案例代码详解\t339\n19.9.1 数据准备\t339\n19.9.2 相关性分析\t341\n19.9.3 最终建模\t342\n19.9.4 模型评估\t343\n19.10 小结\t346","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32132510.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32132510.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32132510.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33243567\/","id":"33243567","publisher":"机械工业出版社","isbn10":"7111619315","isbn13":"9787111619314","title":"从零开始学Hadoop大数据分析（视频教学版）","url":"https:\/\/api.douban.com\/v2\/book\/33243567","alt_title":"","author_intro":"","summary":"版本: 第1版, 平装, 机械工业出版社","price":"89"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Gurmukh Singh"],"pubdate":"2015-4-30","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29416960.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"112","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29416960.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29416960.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29416960.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27011341\/","id":"27011341","publisher":"Packt Publishing - ebooks Account","isbn10":"1783281553","isbn13":"9781783281558","title":"Monitoring Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/27011341","alt_title":"","author_intro":"","summary":"","price":"USD 29.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Venkat Ankam"],"pubdate":"2016-10-6","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29084046.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"309","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29084046.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29084046.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29084046.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26888159\/","id":"26888159","publisher":"Packt Publishing","isbn10":"1785884697","isbn13":"9781785884696","title":"Big Data Analytics with Spark and Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/26888159","alt_title":"","author_intro":"About the Author\nVenkat Ankam Venkat Ankam has over 18 years of IT experience and over 5 years in big data technologies, working with customers to design and develop scalable big data applications. Having worked with multiple clients globally, he has tremendous experience in big data analytics using Hadoop and Spark. He is a Cloudera Certified Hadoop Developer and Administrator and also a Databricks Certified Spark Developer. He is the founder and presenter of a few Hadoop and Spark meetup groups globally and loves to share knowledge with the community. Venkat has delivered hundreds of trainings, presentations, and white papers in the big data sphere. While this is his first attempt at writing a book, many more books are in the pipeline.\nRead more","summary":"Key Features\nThis book is based on the latest 2.0 version of Apache Spark and 2.7 version of Hadoop integrated with most commonly used tools.Learn all Spark stack components including latest topics such as DataFrames, DataSets, GraphFrames, Structured Streaming, DataFrame based ML Pipelines and SparkR.Integrations with frameworks such as HDFS, YARN and tools such as Jupyter, Zeppelin, NiFi, Mahout, HBase Spark Connector, GraphFrames, H2O and Hivemall.\nBook Description\nBig Data Analytics book aims at providing the fundamentals of Apache Spark and Hadoop. All Spark components – Spark Core, Spark SQL, DataFrames, Data sets, Conventional Streaming, Structured Streaming, MLlib, Graphx and Hadoop core components – HDFS, MapReduce and Yarn are explored in greater depth with implementation examples on Spark + Hadoop clusters.\nIt is moving away from MapReduce to Spark. So, advantages of Spark over MapReduce are explained at great depth to reap benefits of in-memory speeds. DataFrames API, Data Sources API and new Data set API are explained for building Big Data analytical applications. Real-time data analytics using Spark Streaming with Apache Kafka and HBase is covered to help building streaming applications. New Structured streaming concept is explained with an IOT (Internet of Things) use case. Machine learning techniques are covered using MLLib, ML Pipelines and SparkR and Graph Analytics are covered with GraphX and GraphFrames components of Spark.\nReaders will also get an opportunity to get started with web based notebooks such as Jupyter, Apache Zeppelin and data flow tool Apache NiFi to analyze and visualize data.\nWhat you will learn\nFind out and implement the tools and techniques of big data analytics using Spark on Hadoop clusters with wide variety of tools used with Spark and HadoopUnderstand all the Hadoop and Spark ecosystem componentsGet to know all the Spark components: Spark Core, Spark SQL, DataFrames, DataSets, Conventional and Structured Streaming, MLLib, ML Pipelines and GraphxSee batch and real-time data analytics using Spark Core, Spark SQL, and Conventional and Structured StreamingGet to grips with data science and machine learning using MLLib, ML Pipelines, H2O, Hivemall, Graphx, SparkR and Hivemall.\nAbout the Author\nVenkat Ankam has over 18 years of IT experience and over 5 years in big data technologies, working with customers to design and develop scalable big data applications. Having worked with multiple clients globally, he has tremendous experience in big data analytics using Hadoop and Spark.\nHe is a Cloudera Certified Hadoop Developer and Administrator and also a Databricks Certified Spark Developer. He is the founder and presenter of a few Hadoop and Spark meetup groups globally and loves to share knowledge with the community.\nVenkat has delivered hundreds of trainings, presentations, and white papers in the big data sphere. While this is his first attempt at writing a book, many more books are in the pipeline.\nTable of Contents\nBig Data Analytics at 10,000 foot viewGetting Started with Apache Hadoop and Apache SparkDeep Dive into Apache SparkBig Data Analytics with Spark SQL, DataFrames, and DatasetsReal-Time Analytics with Spark Streaming and Structured StreamingNotebooks and Dataflows with Spark and HadoopMachine Learning with Spark and HadoopBuilding Recommendation Systems with Spark and MahoutGraph Analytics with GraphXInteractive Analytics with SparkR","price":"USD 43.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["Tom White"],"pubdate":"2015-8","tags":[{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Programming","title":"Programming"},{"count":1,"name":"BigData","title":"BigData"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29633256.jpg","binding":"平装","translator":[],"catalog":"Foreword\nPreface\nPart Ⅰ.Hadoop Fundamentals\n1.MeetHadoop\nData！\nData Storage and Analysis\nQuerying All Your Data\nBeyond Batch\nComparison with Other Systems\nRelational Database Management Systems\nGrid Computing\nVolunteer Computing\nA Brief History of Apache Hadoop\nWhat's in This Book？\n2.MapReduce\nA Weather Dataset\nData Format\nAnalyzing the Data with Unix Tools\nAnalyzing the Data with Hadoop\nMap and Reduce\nJava MapReduce\nScaling Out\nData Flow\nCombiner Functions\nRunning a Distributed MapReduce Job\nHadoop Streaming\nRuby\nPython\n3.The Hadoop Distributed Filesystem\nThe Design of HDFS\nHDFS Concepts\nBlocks\nNamenodes and Datanodes\nBlock Caching\nHDFS Federation\nHDFS High Availability\nThe Command—Line Interface\nBasic Filesystem Operations\nHadoop Filesystems\nInterfaces\nThe Java Interface\nReading Data from a Hadoop URL\nReading Data Using the FileSystem API\nWriting Data\nDirectories\nQuerying the Filesystem\nDeleting Data\nData Flow\nAnatomy of a File Read\nAnatomy of a File Write\nCoherency Model\nParallel Copying with distcp\nKeeping an HDFS Cluster Balanced\n4.YARN\nAnatomy of a YARN Application Run\nResource Requests\nApplication Lifespan\nBuilding YARN Applications\nYARN Compared to MapReduce 1\nScheduling in YARN\nScheduler Options\nCapacity Scheduler Configuration\nFair Scheduler Configuration\nDelay Scheduling\nDominant Resource Fairness\nFurther Reading\n5.Hadoop I／O\nData Integrity\nData Integrity in HDFS\nLocaIFileSystem\nChecksumFileSystem\nCompression\nCodecs\nCompression and Input Splits\nUsing Compression in MapReduce\nSerialization\nThe Writable Interface\nWritable Classes\nImplementing a Custom Writable\nSerialization Frameworks\nFile—Based Data Structures\nSequenceFile\nMapFile\nOther File Formats and Column—Oriented Formats\nPart Ⅱ.MapReduce\n6.Developing a MapReduce Application\nThe Conflguration API\nCombining Resources\nVariable Expansion\nSetting Up the Development Environment\nManaging Configuration\nGenericOptionsParser， Tool， and ToolRunner\nWriting a Unit Test with MRUnit\nMapper\nReducer\nRunning Locally on Test Data\nRunning a Job in a Local Job Runner\nTesting the Driver\nRunning on a Cluster\nPackaging a Job\nLaunching a Job\nThe MapReduce Web UI\nRetrieving the Results\nDebugging a Job\nHadoop Logs\nRemote Debugging\nTuning a Job\nProfiling Tasks\nMapReduce Workflows\nDecomposing a Problem into MapReduce Jobs\nIobControl\nApache Oozie\n7.How MapReduce Works\nAnatomy ofa MapReduce Job Run\nJob Submission\nJob Initialization\nTask Assignmenl\nTask Execution\nProgress and Status Updates\nJob Completion\nFailures\nTask Failure\nApplication Master Failure\nNode Manager Failure\nResource Manager Failure\nShuffle and Sort\nThe Map Side\nThe Reduce Side\nConfiguration Tuning\nTask Execution\nThe Task Execution Environment\nSpeculative Execution\nOutput Committers\n8.MapReduce Typesand Formats\nMapReduce Types\nThe Default MapReduce Job\nInput Formats\nInput Splits and Records\nText Input\nBinary Input\nMultiple Inputs\nDatabase Input （and Output）\nOutput Formats\nText Output\nBinary Output\nMultiple Outputs\nLazy Output\nDatabase Output\n……\n9.MapReduce Features\nPart Ⅲ.Hadoop Operations\n10.Setting Up a Hadoop Cluster\n11.Administering Hadoop\nPart Ⅳ.RelatedProjects\n12.Avro\n13.Parquet\n14.Flume\n15.Sqoop\n16.Pig\n17.Hive\n18.Crunch\n19.Spark\n20.HBase\n21.ZooKeeper\nPart Ⅴ.Case Studies\n22.Composable Data at Cerner\n23.Biological Data Saence： Saving Lives with Software\n24.Cascading\nA.Installing Apache Hadoop\nB.Cloudera's Distribution Including Apache Hadoop\nC.Preparing the NCDC Weather Data\nD.The Old and New Java MapReduce APls\nIndex","pages":"726","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29633256.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29633256.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29633256.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27600204\/","id":"27600204","publisher":"东南大学出版社","isbn10":"7564159170","isbn13":"9787564159177","title":"Hadoop权威指南 (第4版 英文影印版)","url":"https:\/\/api.douban.com\/v2\/book\/27600204","alt_title":"","author_intro":"怀特（Tom White），Tom White是Cloudera的工程师和Apache软件基金会的成员，从2007年起就是Apache Hadoop的代码提交者。他在oreilly.com、java.net和IBM的developerWorks写了大量文章，并且经常在产业大会上作关于Hadoop的演讲。","summary":"《Hadoop权威指南(第4版)(修订版)(影印版)(英文版)》作者Tom White增加了关于YARN和一些Hadoop相关项目，如Parquet、Flume、Crunch和Spark的新章节。你将会了解到Hadoop版本的最新变化，并且研究在医疗健康系统和基因数据处理中Hadoop的应用案例。","price":"99.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"大数据平台隐私保护","author":["[美] Ben Spivey","[美] Joey Echeverria"],"pubdate":"2017-10","tags":[{"count":3,"name":"数据平台","title":"数据平台"},{"count":3,"name":"Security","title":"Security"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29553224.jpg","binding":"平装","translator":["赵　双","白　波"],"catalog":"序　　xi\n前言　　xii\n第1章　引言　　1\n1.1　安全概览　　1\n1.1.1　机密性　　2\n1.1.2　完整性　　2\n1.1.3　可用性　　2\n1.1.4　验证、授权和审计　　3\n1.2　Hadoop 安全：简史　　5\n1.3　Hadoop 组件和生态系统　　5\n1.3.1　Apache HDFS　　6\n1.3.2　Apache YARN　　7\n1.3.3　Apache MapReduce　　8\n1.3.4　Apache Hive　　9\n1.3.5　Cloudera Impala　　9\n1.3.6　Apache Sentry　　10\n1.3.7　Apache　HBase　　11\n1.3.8　Apache Accumulo　　11\n1.3.9　Apache Solr　　13\n1.3.10　Apache Oozie　　13\n1.3.11　Apache ZooKeeper　　13\n1.3.12　Apache Flume　　13\n1.3.13　Apache Sqoop　　14\n1.3.14　Cloudera　Hue　　14\n1.4　小结　　14\n第一部分　安全架构\n第2章　保护分布式系统　　16\n2.1　威胁种类　　17\n2.1.1　非授权访问／伪装　　17\n2.1.2　内在威胁　　17\n2.1.3　拒绝服务　　18\n2.1.4　数据威胁　　18\n2.2　威胁和风险评估　　18\n2.2.1　用户评估　　19\n2.2.2　环境评估　　19\n2.3　漏洞　　19\n2.4　深度防御　　20\n2.5　小结　　21\n第3章　系统架构　　22\n3.1　运行环境　　22\n3.2　网络安全　　23\n3.2.1　网络划分　　23\n3.2.2　网络防火墙　　24\n3.2.3　入侵检测和防御　　25\n3.3　Hadoop 角色和隔离策略　　27\n3.3.1　主节点　　28\n3.3.2　工作节点　　29\n3.3.3　管理节点　　29\n3.3.4　边界节点　　30\n3.4　操作系统安全　　31\n3.4.1　远程访问控制　　31\n3.4.2　主机防火墙　　31\n3.4.3　SELinux　　33\n3.5　小结　　34\n第4章　Kerberos　　35\n4.1　为什么是Kerberos　　35\n4.2　Kerberos 概览　　36\n4.3　Kerberos 工作流：一个简单示例　　37\n4.4　Kerberos 信任　　38\n4.5　MIT Kerberos　　39\n4.5.1　服务端配置　　41\n4.5.2　客户端配置　　44\n4.6　小结　　46\n第二部分　验证、授权和审计\n第5章　身份和验证　　48\n5.1　身份　　48\n5.1.1　将Kerberos 主体映射为用户名　　49\n5.1.2　Hadoop 用户到组的映射　　50\n5.1.3　Hadoop 用户配置　　54\n5.2　身份验证　　54\n5.2.1　Kerberos　　55\n5.2.2　用户名和密码验证　　56\n5.2.3　令牌　　56\n5.2.4　用户模拟　　59\n5.2.5　配置　　60\n5.3　小结　　70\n第6章　授权　　71\n6.1　HDFS 授权　　71\nHDFS 扩展ACL　　72\n6.2　服务级授权　　74\n6.3　MapReduce 和YARN 的授权　　85\n6.3.1　MapReduce（MR1）　　86\n6.3.2　YARN　(MR2)　　87\n6.6　HBase 和Accumulo 的授权　　95\n6.6.1　系统、命名空间和表级授权　　95\n6.6.2　列级别和单元级别授权　　99\n6.7　小结　　99\n第7章　Apache Sentry（孵化中）　　100\n7.1　Sentry 概念　　100\n7.2　Sentry 服务　　102\n7.3　Hive 授权　　105\n7.4　Impala 授权　　110\n7.5　Solr 授权　　112\n7.6　Sentry 特权模型　　113\n7.6.1　SQL 特权模型　　114\n7.6.2　Solr 特权模型　　116\n7.7　Sentry 策略管理　　118\n7.7.1　SQL 命令　　118\n7.7.2　SQL 策略文件　　121\n7.7.3　Solr 策略文件　　123\n7.7.4　策略文件的验证和校验　　124\n7.7.5　从策略文件迁移　　126\n7.8　小结　　127\n第8章　审计　　128\n8.1　HDFS 审计日志　　129\n8.2　MapReduce 审计日志　　130\n8.3　YARN 审计日志　　132\n8.4　Hive 审计日志　　134\n8.5　Cloudera　Impala 审计日志　　134\n8.6　HBase 审计日志　　135\n8.7　Accumulo 审计日志　　137\n8.8　Sentry 审计日志　　139\n8.9　日志聚合　　140\n8.10　小结　　141\n第三部分　数据安全\n第9章　数据保护　　144\n9.1　加密算法　　144\n9.2　静态数据加密　　145\n9.2.1　加密和密钥管理　　146\n9.2.2　HDFS 静态数据加密　　146\n9.2.3　MapReduce2 中间数据加密　　151\n9.2.4　Impala 磁盘溢出加密　　152\n9.2.5　全盘加密　　152\n9.2.6　文件系统加密　　154\n9.2.7　Hadoop 中重要数据的安全考虑　　155\n9.3　动态数据加密　　156\n9.3.1　传输层安全　　156\n9.3.2　Hadoop 动态数据加密　　157\n9.4　数据销毁和删除　　162\n9.5　小结　　163\n第10章　数据导入安全　　164\n10.1　导入数据的完整性　　165\n10.2　数据导入的机密性　　166\n10.2.1　Flume 加密　　167\n10.2.2　Sqoop 加密　　173\n10.3　导入工作流　　178\n10.4　企业架构　　179\n10.5　小结　　180\n第11章　数据提取和客户端访问安全　　181\n11.1　Hadoop 命令行接口　　182\n11.2　保护应用安全　　183\n11.3　HBase　　184\n11.3.1　HBase shell　　184\n11.3.2　HBase REST 网关　　186\n11.3.3　HBase Thrift 网关　　189\n11.4　Accumulo　　190\n11.4.1　Accumulo shell　　190\n11.4.2　Accumulo 代理服务　　192\n11.5　Oozie　　192\n11.6　Sqoop　　194\n11.7　SQL 访问　　195\n11.7.1　Impala　　195\n11.7.2　Hive　　200\n11.8　WebHDFS\/HttpFS　　208\n11.9　小结　　209\n第12章　Cloudera Hue　　210\n12.1　Hue HTTPS　　211\n12.2　Hue 身份验证　　212\n12.2.1　SPNEGO 后端　　212\n12.2.2　SAML 后端　　213\n12.2.3　LDAP 后端　　215\n12.3　Hue 授权　　218\n12.4　Hue SSL 客户端配置　　219\n12.5　小结　　219\n第四部分　综合应用\n第13章　案例分析　　222\n13.1　案例分析：Hadoop 数据仓库　　222\n13.1.1　环境搭建　　223\n13.1.2　用户体验　　226\n13.1.3　小结　　229\n13.2　案例分析：交互式HBase　Web 应用　　230\n13.2.1　设计与架构　　230\n13.2.2　安全需求　　231\n13.2.3　集群配置　　232\n13.2.4　实现中的注意事项　　236\n13.2.5　小结　　237\n后记　　238\n关于作者　　240\n关于封面　　240","pages":"256","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29553224.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29553224.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29553224.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27148522\/","id":"27148522","publisher":"人民邮电出版社","isbn10":"7115467714","isbn13":"9787115467713","title":"Hadoop安全","url":"https:\/\/api.douban.com\/v2\/book\/27148522","alt_title":"","author_intro":"Ben Spivey\n目前是Cloudera的一名解决方案架构师，负责为客户在Hadoop部署方面提供咨询。Ben曾在多家世界500强企业工作，涉及金融服务、零售、医疗保健等多个行业。他的专长在于对客户的Hadoop集群进行规划、安装、配置以及安全保护。\n在Cloudera之前，Ben与某个国防承包商一起为美国国家安全局（NSA）工作。在此期间，Ben的工作之一就是建立一系列应用，这些应用被集成到企业安全基础设施中以保护敏感信息。\nJoey Echeverria\n是Rocana的一位软件工程师，其工作是在Apache Hadoop平台建立下一代IT运行分析系统。Joey还是一位Kite SDK贡献者，Kite SDK是一个Apache许可的Hadoop生态系统数据API。Joey之前是Cloudera的软件工程师，在Cloudera期间，他为Apache Flume、Apache Sqoop、Apache Hadoop、Apache HBase等众多ASF项目做出了贡献。","summary":"本书阐述了Hadoop从早期开放的消费互联网时代到现在作为敏感数据可信平台的演变历程，介绍了包括身份验证、加密、密钥管理和商业实践在内的诸多主题，并在实际环境下加以讨论。第1章是介绍性内容，随后分为四大部分：第一部分是安全架构，第二部分是验证、授权和安全审计，第三部分是数据安全，第四部分是归纳总结。最后介绍了几个使用案例，融合了书中诸多概念。","price":"79.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["编者:饶文碧\/\/袁景凌\/\/张露\/\/熊盛武\/\/刘荣英"],"pubdate":"2017-04-01","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29473612.jpg","binding":"","translator":[],"catalog":"","pages":"227","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29473612.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29473612.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29473612.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27067686\/","id":"27067686","publisher":"武汉大学","isbn10":"7307128403","isbn13":"9787307128408","title":"Hadoop核心技术与实验\/云计算与大数据实验教材系列","url":"https:\/\/api.douban.com\/v2\/book\/27067686","alt_title":"","author_intro":"","summary":" 由饶文碧\/\/袁景凌\/\/张露\/\/熊盛武\/\/刘荣英《Hadoop核心技术与实验\/云计算与大数据实验教材系列》是一本学习Hadoop数据处理技术的入门级实验教材，包括Hadoop知识点、关键技术和实验案例等内容。知识点部分对学生在Hadoop应用实践中碰到的概\n念、模型和机制进行简要的介绍；关键技术与经典实验案例相结合．帮助学生通过实践掌握研发的关键技\n术。\n本书最大的特点是把知识点、关键技术和实验案例相结合，在对Hadoop技术体系进行描述基础上，还为主要知识点设计了经典的小案例，易于理解，可操作性强。\n","price":"36.0"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Gurmukh Singh"],"pubdate":"2017-5-26","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29474806.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"348","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29474806.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29474806.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29474806.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27068892\/","id":"27068892","publisher":"Packt Publishing","isbn10":"1787126730","isbn13":"9781787126732","title":"Hadoop 2.x Administration Cookbook","url":"https:\/\/api.douban.com\/v2\/book\/27068892","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["余辉"],"pubdate":"2017-09-01","tags":[{"count":1,"name":"资料全面","title":"资料全面"},{"count":1,"name":"编程","title":"编程"},{"count":1,"name":"系统","title":"系统"},{"count":1,"name":"帮助理解","title":"帮助理解"},{"count":1,"name":"实践","title":"实践"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"专业","title":"专业"},{"count":1,"name":"spark","title":"spark"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","ebook_url":"https:\/\/read.douban.com\/ebook\/45333468\/","pages":"337","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/27153381\/","id":"27153381","publisher":"清华大学","isbn10":"7302479674","isbn13":"9787302479673","title":"Hadoop+Spark生态系统操作与实战指南","url":"https:\/\/api.douban.com\/v2\/book\/27153381","alt_title":"","author_intro":"","summary":"","ebook_price":"34.50","price":"69.0"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29592627.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29592627.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29592627.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29592627.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27183421\/","id":"27183421","publisher":"","isbn10":"7111567870","isbn13":"9787111567875","title":"Hadoop与大数据挖掘","url":"https:\/\/api.douban.com\/v2\/book\/27183421","alt_title":"","author_intro":"","summary":"","series":{"id":"19432","title":"大数据技术丛书"},"price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Sandeep Karanth"],"pubdate":"2015-2-23","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29497564.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"398","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29497564.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29497564.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29497564.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27091627\/","id":"27091627","publisher":"Packt Publishing - ebooks Account","isbn10":"1783983647","isbn13":"9781783983643","title":"Mastering Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/27091627","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Vinit Yadav"],"pubdate":"2017-6-1","tags":[{"count":1,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29489550.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"207","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29489550.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29489550.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29489550.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27083529\/","id":"27083529","publisher":"Apress","isbn10":"1484228685","isbn13":"9781484228685","title":"Processing Big Data with Azure HDInsight: Building Real-World Big Data Systems on Azure HDInsight Using the Hadoop Ecosystem","url":"https:\/\/api.douban.com\/v2\/book\/27083529","alt_title":"","author_intro":"From the Back Cover\nGet a jump start on using Azure HDInsight and Hadoop Ecosystem components. As most Hadoop and Big Data projects are written in either Java, Scala, or Python, this book minimizes the effort to learn another language and is written from the perspective of a .NET developer. Hadoop components are covered, including Hive, Pig, HBase, Storm, and Spark on Azure HDInsight, and code samples are written in .NET only.Processing Big Data with Azure HDInsightcovers the fundamentals of big data, howbusinesses are using it to their advantage, and how Azure HDInsight fits into thebig data world. This book introduces Hadoop and big data concepts and then divesinto creating different solutions with HDInsight and the Hadoop Ecosystem. It covers concepts with real-world scenarios and code examples, making sure you get hands-on experience. The best way to utilize this book is to practice while reading. After reading this book you will be familiar with Azure HDInsight and how it can be utilized to build big data solutions, including batch processing, stream analytics, interactive processing, and storing and retrieving data in an efficient manner.What You Will Learn:Understand the fundamentals of HDInsight and HadoopWork with HDInsight clusterQuery with Apache Hive and Apache PigStore and retrieve data with Apache HBaseStream data processing using Apache StormWork with Apache Spark\nRead more\nAbout the Author\nVinit Yadavis Founder and CEO of Veloxcore. He started working with Azure when it first came out in 2010, and since then he has been continuously involved in designing solutions around the Microsoft Azure platform. At Veloxcore, he continues to build and deliver highly scalable big data solutions. He is also a machine learning and data science enthusiastic, passionate programmer, and has over 12 years of experience in designing and developing enterprise applications using various .NETtechnologies.  Vinit founded Veloxcore to help organizations leverage big data and machine learning. He and his team at Veloxcore are actively engaged in developing software solutions for their global customers using agile methodologies. On a side note, he likes to travel, read, and watch sci-fi content and loves to draw, paint, and create something new.\nRead more","summary":"Get a jump start on using Azure HDInsight and Hadoop Ecosystem components. As most Hadoop and Big Data projects are written in either Java, Scala, or Python, this book minimizes the effort to learn another language and is written from the perspective of a .NET developer. Hadoop components are covered, including Hive, Pig, HBase, Storm, and Spark on Azure HDInsight, and code samples are written in .NET only.Processing Big Data with Azure HDInsightcovers the fundamentals of big data, howbusinesses are using it to their advantage, and how Azure HDInsight fits into thebig data world. This book introduces Hadoop and big data concepts and then divesinto creating different solutions with HDInsight and the Hadoop Ecosystem. It covers concepts with real-world scenarios and code examples, making sure you get hands-on experience. The best way to utilize this book is to practice while reading. After reading this book you will be familiar with Azure HDInsight and how it can be utilized to build big data solutions, including batch processing, stream analytics, interactive processing, and storing and retrieving data in an efficient manner.What You'll LearnUnderstand the fundamentals of HDInsight and HadoopWork with HDInsight clusterQuery with Apache Hive and Apache PigStore and retrieve data with Apache HBaseStream data processing using Apache StormWork with Apache SparkWho This Book Is For\nSoftware developers, technical architects, data scientists\/analyts, and Hadoop administrators who want to develop on Microsoft’s managed Hadoop offering, HDInsight","price":"USD 39.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["编者:魏祖宽\/\/刘兆宏"],"pubdate":"2017-06-01","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"260","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/27080775\/","id":"27080775","publisher":"电子工业","isbn10":"7121317397","isbn13":"9787121317392","title":"基于Hadoop的大数据分析和处理","url":"https:\/\/api.douban.com\/v2\/book\/27080775","alt_title":"","author_intro":"","summary":"","price":"45.0"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["[美] Benjamin Bengfort","[美] Jenny Kim"],"pubdate":"2018-4","tags":[{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"美国","title":"美国"},{"count":1,"name":"未资源","title":"未资源"},{"count":1,"name":"数据平台","title":"数据平台"},{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Python","title":"Python"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29725694.jpg","binding":"平装","translator":["王纯超"],"catalog":"前言　　ix\n第一部分　分布式计算入门\n第1章　数据产品时代　　2\n1.1　什么是数据产品　　2\n1.2　使用Hadoop构建大规模数据产品　　4\n1.2.1　利用大型数据集　　4\n1.2.2　数据产品中的Hadoop　　5\n1.3　数据科学流水线和Hadoop生态系统　　6\n1.4　小结　　8\n第2章　大数据操作系统　　9\n2.1　基本概念　　10\n2.2　Hadoop架构　　11\n2.2.1　Hadoop集群　　12\n2.2.2　HDFS　　14\n2.2.3　YARN　　15\n2.3　使用分布式文件系统　　16\n2.3.1　基本的文件系统操作　　16\n2.3.2　HDFS文件权限　　18\n2.3.3　其他HDFS接口　　19\n2.4　使用分布式计算　　20\n2.4.1　MapReduce：函数式编程模型　　20\n2.4.2　MapReduce：集群上的实现　　22\n2.4.3　不止一个MapReduce：作业链　　27\n2.5　向YARN 提交MapReduce 作业　　28\n2.6　小结　　30\n第3章　Python 框架和Hadoop Streaming　　31\n3.1　Hadoop Streaming　　32\n3.1.1　使用Streaming在CSV 数据上运行计算　　34\n3.1.2　执行Streaming作业　　38\n3.2　Python 的MapReduce框架　　39\n3.2.1　短语计数　　42\n3.2.2　其他框架　　45\n3.3　MapReduce进阶　　46\n3.3.1　combiner　　46\n3.3.2　partitioner　　47\n3.3.3　作业链　　47\n3.4　小结　　50\n第4章　Spark内存计算　　52\n4.1　Spark基础　　53\n4.1.1　Spark栈　　54\n4.1.2　RDD　　55\n4.1.3　使用RDD 编程　　56\n4.2　基于PySpark的交互性Spark　　59\n4.3　编写Spark应用程序　　61\n4.4　小结　　67\n第5章　分布式分析和模式　　69\n5.1　键计算　　70\n5.1.1　复合键　　71\n5.1.2　键空间模式　　74\n5.1.3　pair与stripe　　78\n5.2　设计模式　　80\n5.2.1　概要　　81\n5.2.2　索引　　85\n5.2.3　过滤　　90\n5.3　迈向最后一英里分析　　95\n5.3.1　模型拟合　　96\n5.3.2　模型验证　　97\n5.4　小结　　98\n第二部分　大数据科学的工作流和工具\n第6章　数据挖掘和数据仓　　102\n6.1　Hive 结构化数据查询　　103\n6.1.1　Hive 命令行接口（CLI）　　103\n6.1.2　Hive 查询语言　　104\n6.1.3　Hive 数据分析　　108\n6.2　HBase　　113\n6.2.1　NoSQL 与列式数据库　　114\n6.2.2　HBase 实时分析　　116\n6.3　小结　　122\n第7章　数据采集　　123\n7.1　使用Sqoop 导入关系数据　　124\n7.1.1　从MySQL 导入HDFS　　124\n7.1.2　从MySQL 导入Hive　　126\n7.1.3　从MySQL 导入HBase　　128\n7.2　使用Flume 获取流式数据　　130\n7.2.1　Flume 数据流　　130\n7.2.2　使用Flume 获取产品印象数据　　133\n7.3　小结　　136\n第8章　使用高级API 进行分析　　137\n8.1　Pig　　137\n8.1.1　Pig Latin　　138\n8.1.2　数据类型　　142\n8.1.3　关系运算符　　142\n8.1.4　用户定义函数　　143\n8.1.5　Pig 小结　　144\n8.2　Spark 高级API　　144\n8.2.1　Spark SQL　　146\n8.2.2　DataFrame　　148\n8.3　小结　　153\n第9章　机器学习　　154\n9.1　使用Spark 进行可扩展的机器学习　　154\n9.1.1　协同过滤　　156\n9.1.2　分类　　161\n9.1.3　聚类　　163\n9.2　小结　　166\n第10章　总结：分布式数据科学实战　　167\n10.1　数据产品生命周期　　168\n10.1.1　数据湖泊　　169\n10.1.2　数据采集　　171\n10.1.3　计算数据存储　　172\n10.2　机器学习生命周期　　173\n10.3　小结　　175\n附录A　创建Hadoop 伪分布式开发环境　　176\n附录B　安装Hadoop 生态系统产品　　184\n术语表　　193\n关于作者　　211\n关于封面　　211","pages":"228","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29725694.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29725694.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29725694.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30180515\/","id":"30180515","publisher":"人民邮电出版社","isbn10":"711547964X","isbn13":"9787115479648","title":"Hadoop数据分析","url":"https:\/\/api.douban.com\/v2\/book\/30180515","alt_title":"","author_intro":"Benjamin Bengfort\n数据科学家，目前正在马里兰大学攻读博士学位，方向为机器学习和分布式计算；熟悉自然语言处理、Python数据科学、Hadoop和Spark分析等。\nJenny Kim\n经验丰富的大数据工程师，不仅进行商业软件的开发，在学术界也有所建树，在海量数据、机器学习以及生产和研究环境的Hadoop实施方面有深入研究。目前就职于Cloudera的Hue团队。","summary":"通过提供分布式数据存储和并行计算框架，Hadoop已经从一个集群计算的抽象演化成了一个大数据的操作系统。本书旨在通过以可读且直观的方式提供集群计算和分析的概览，为数据科学家深入了解特定主题领域铺平道路，从数据科学家的视角介绍Hadoop集群计算和分析。本书分为两大部分，第一部分从非常高的层次介绍分布式计算，讨论如何在集群上运行计算；第二部分则重点关注数据科学家应该了解的工具和技术，意在为各种分析和大规模数据管理提供动力。","series":{"id":"660","title":"图灵程序设计丛书"},"price":"69.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2017-7-1","tags":[{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29707431.jpg","binding":"平装","translator":[],"catalog":"","pages":"298","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29707431.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29707431.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29707431.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30161283\/","id":"30161283","publisher":"中国水利水电出版社","isbn10":"7517056433","isbn13":"9787517056430","title":"Hadoop & Spark大数据开发实战","url":"https:\/\/api.douban.com\/v2\/book\/30161283","alt_title":"","author_intro":"","summary":"","series":{"id":"41357","title":"大数据开发工程师系列"},"price":"CNY 58.00"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"Uncover the power of MySQL 8 for Big Data","author":["Shabbir Challawala","Jaydip Lakhatariya","Chintan Mehta"],"pubdate":"2017-10-20","tags":[{"count":1,"name":"mysql","title":"mysql"},{"count":1,"name":"data","title":"data"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29697840.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"296","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29697840.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29697840.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29697840.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30150575\/","id":"30150575","publisher":"Packt Publishing","isbn10":"1788397185","isbn13":"9781788397186","title":"MySQL 8 for Big Data: Effective data processing with MySQL 8, Hadoop, NoSQL APIs, and other Big Data tools","url":"https:\/\/api.douban.com\/v2\/book\/30150575","alt_title":"","author_intro":"From the Author\nIhave relied on many people, both directly and indirectly, in writing this book.First,I would like to thank my co-authors and the wonderful team at PacktPub for thiseffort. I would like to especially thank my wonderful wife, Mittal, and mysweet son, Devam, for putting up with the long days, nights, and weekends whereI was camped out in front of my laptop.Manypeople have inspired and made contributions to this book and provided comments,edits, insights, and ideas -- specifically Krupal Khatri and Chintan Gajjar. There were several things that could haveinterfered with my book. I also want to thank all the reviewers of this book. Last, but not least, I want to thank all my Mom& Dad, friends, family and colleagues for supporting me throughout thewriting of this book\nRead more\nAbout the Author\nShabbir Challawala has over 8 years of rich experience in providing solutions based on MySQL and PHP technologies. He is currently working with KNOWARTH Technologies. He has worked in various PHP-based e-commerce solutions and learning portals for enterprises. He has worked on different PHP-based frameworks, such as Magento E-commerce, Drupal CMS, and Laravel.Shabbir has been involved in various enterprise solutions at different phases, such as architecture design, database optimization, and performance tuning. He has been carrying good exposure of Software Development Life Cycle process thoroughly. He has worked on integrating Big Data technologies such as MongoDB and Elasticsearch with a PHP-based framework.Jaydip Lakhatariya has rich experience in portal and J2EE frameworks. He adapts quickly to any new technology and has a keen desire for constant improvement. Currently, Jaydip is associated with a leading open source enterprise development company, KNOWARTH Technologies, where he is engaged in various enterprise projects.Jaydip, a full-stack developer, has proven his versatility by adopting technologies such as Liferay, Java, Spring, Struts, Hadoop, MySQL, Elasticsearch, Cassandra, MongoDB, Jenkins, SCM, PostgreSQL, and many more.He has been recognized with awards such as Merit, Commitment to Service, and also as a Star Performer. He loves mentoring people and has been delivering training for Portals and J2EE frameworks.Chintan Mehta is the co-founder at KNOWARTH Technologies and heads Cloud\/RIMS\/DevOps. He has rich progressive experience in Systems and Server Administration of Linux, AWS Cloud, DevOps, RIMS, and Server Administration on Open Source Technologies. He is also an AWS Certified Solutions Architect-Associate.Chintan's vital role during his career in Infrastructure and Operations has also included Requirement Analysis, Architecture design, Security design, High-availability and Disaster recovery planning, Automated monitoring, Automated deployment, Build processes to help customers, performance tuning, infrastructure setup and deployment, and application setup and deployment. He has also been responsible for setting up various offices at different locations, with fantastic sole ownership to achieve Operation Readiness for the organizations he had been associated with.He headed Managed Cloud Services practices with his previous employer and received multiple awards in recognition of very valuable contributions made to the business of the group. He also led the ISO 27001:2005 implementation team as a joint management representative. Chintan has authored Hadoop Backup and Recovery Solutions and reviewed Liferay Portal Performance Best Practices and Building Serverless Web Applications.He has a Diploma in Computer Hardware and Network from a reputed institute in India.Kandarp Patel leads PHP practices at KNOWARTH Technologies. He has vast experience in providing end-to-end solutions in CMS, LMS, WCM, and e-commerce, along with various integrations for enterprise customers. He has over 9 years of rich experience in providing solutions in MySQL, MongoDB, and PHP-based frameworks. Kandarp is also a certified MongoDB and Magento developer.Kandarp has experience in various Enterprise Application development phases of the Software Development Life Cycle and has played prominent role in requirement gathering, architecture design, database design, application development, performance tuning, and CD\/CI.Kandarp has a Bachelor of Engineering in Information Technology from a reputed university in India.\nRead more","summary":"About This Book\nCombine the powers of MySQL and Hadoop to build a solid Big Data solution for your organizationIntegrate MySQL with different NoSQL APIs and Big Data tools such as Apache SqoopA comprehensive guide with practical examples on building a high performance Big Data pipeline with MySQL\nWho This Book Is For\nThis book is intended for MySQL database administrators and Big Data professionals looking to integrate MySQL 8 and Hadoop to implement a high performance Big Data solution. Some previous experience with MySQL will be helpful, although the book will highlight the newer features introduced in MySQL 8.\nWhat You Will Learn\nExplore the features of MySQL 8 and how they can be leveraged to handle Big DataUnlock the new features of MySQL 8 for managing structured and unstructured Big DataIntegrate MySQL 8 and Hadoop for efficient data processingPerform aggregation using MySQL 8 for optimum data utilizationExplore different kinds of join and union in MySQL 8 to process Big Data efficientlyAccelerate Big Data processing with MemcachedIntegrate MySQL with the NoSQL APIImplement replication to build highly available solutions for Big Data\nIn Detail\nWith organizations handling large amounts of data on a regular basis, MySQL has become a popular solution to handle this structured Big Data. In this book, you will see how DBAs can use MySQL 8 to handle billions of records, and load and retrieve data with performance comparable or superior to commercial DB solutions with higher costs.\nMany organizations today depend on MySQL for their websites and a Big Data solution for their data archiving, storage, and analysis needs. However, integrating them can be challenging. This book will show you how to implement a successful Big Data strategy with Apache Hadoop and MySQL 8. It will cover real-time use case scenario to explain integration and achieve Big Data solutions using technologies such as Apache Hadoop, Apache Sqoop, and MySQL Applier. Also, the book includes case studies on Apache Sqoop and real-time event processing.\nBy the end of this book, you will know how to efficiently use MySQL 8 to manage data for your Big Data applications.\nStyle and approach\nStep by Step guide filled with real-world practical examples.","price":"USD 40.23"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"Get command of your organizational Big Data using the power of data science and analytics","author":["Nataraj Dasgupta"],"pubdate":"2018-1-15","tags":[{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"统计","title":"统计"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29702172.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"412","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29702172.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29702172.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29702172.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30154927\/","id":"30154927","publisher":"Packt Publishing","isbn10":"1783554398","isbn13":"9781783554393","title":"Practical Big Data Analytics: Hands-on techniques to implement enterprise analytics and machine learning using Hadoop, Spark, NoSQL and R","url":"https:\/\/api.douban.com\/v2\/book\/30154927","alt_title":"","author_intro":"About the Author\nNataraj Dasgupta is the vice president of Advanced Analytics at RxDataScience Inc. Nataraj has been in the IT industry for more than 19 years and has worked in the technical and analytics divisions of Philip Morris, IBM, UBS Investment Bank and Purdue Pharma. He led the data science division at Purdue Pharma L.P. where he developed the company's award-winning big data and machine learning platform. Prior to Purdue, at UBS, he held the role of associate director working with high frequency and algorithmic trading technologies in the Foreign Exchange trading division of the bank.\nRead more","summary":"Key Features\nA perfect companion to boost your Big Data storing, processing, analyzing skills to help you take informed business decisionsWork with the best tools such as Apache Hadoop, R, Python, and Spark for NoSQL platforms to perform massive online analysesGet expert tips on statistical inference, machine learning, mathematical modeling, and data visualization for Big Data\nBook Description\nBig Data analytics relates to the strategies used by organizations to collect, organize and analyze large amounts of data to uncover valuable business insights that otherwise cannot be analyzed through traditional systems. Crafting an enterprise-scale cost-efficient Big Data and machine learning solution to uncover insights and value from your organization's data is a challenge. Today, with hundreds of new Big Data systems, machine learning packages and BI Tools, selecting the right combination of technologies is an even greater challenge. This book will help you do that.\nWith the help of this guide, you will be able to bridge the gap between the theoretical world of technology with the practical ground reality of building corporate Big Data and data science platforms. You will get hands-on exposure to Hadoop and Spark, build machine learning dashboards using R and R Shiny, create web-based apps using NoSQL databases such as MongoDB and even learn how to write R code for neural networks.\nBy the end of the book, you will have a very clear and concrete understanding of what Big Data analytics means, how it drives revenues for organizations, and how you can develop your own Big Data analytics solution using different tools and methods articulated in this book.\nWhat you will learn\nGet a 360-degree view into the world of Big Data, data science and machine learningBroad range of technical and business Big Data analytics topics that caters to the interests of the technical experts as well as corporate IT executivesGet hands-on experience with industry-standard Big Data and machine learning tools such as Hadoop, Spark, MongoDB, KDB+ and RCreate production-grade machine learning BI Dashboards using R and R Shiny with step-by-step instructionsLearn how to combine open-source Big Data, machine learning and BI Tools to create low-cost business analytics applicationsUnderstand corporate strategies for successful Big Data and data science projectsGo beyond general-purpose analytics to develop cutting-edge Big Data applications using emerging technologies\nWho This Book Is For\nThe book is intended for existing and aspiring Big Data professionals who wish to become the go-to person in their organization when it comes to Big Data architecture, analytics, and governance. While no prior knowledge of Big Data or related technologies is assumed, it will be helpful to have some programming experience.\nTable of Contents\nToo Big Or Not Too BigBig Data Mining For The MassesFrom Big Data to Data AnalyticsBig Data Mining & HadoopBig Data Mining & NoSQLBig Data Mining & SparkMachine Learning For The MassesMachine Learning Deep DiveThe Analytics InfrastructureClosing thoughts on Big DataAppendix","price":"USD 44.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Benoy Antony","Cazen Lee","Kai Sasaki"],"pubdate":"2017-3-15","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29751629.jpg","binding":"平装","translator":[],"catalog":"第1章  Hadoop概述 1\n1.1  商业分析与大数据 2\n1.1.1  Hadoop的组件 3\n1.1.2  Hadoop分布式文件系统(HDFS) 3\n1.1.3  MapReduce是什么 4\n1.1.4  YARN是什么 5\n1.2  ZooKeeper是什么 6\n1.3  Hive是什么 7\n1.4  与其他系统集成 8\n1.4.1  Hadoop生态系统 9\n1.4.2  数据集成与Hadoop 11\n1.5  小结 16\n第2章  存储 19\n2.1  Hadoop HDFS的基础知识 20\n2.1.1  概念 21\n2.1.2  架构 25\n2.1.3  接口 29\n2.2  在分布式模式下设置HDFS群集 35\n2.3  HDFS的高级特性 40\n2.3.1  快照 41\n2.3.2  离线查看器 44\n2.3.3  分层存储 52\n2.3.4  纠删码 55\n2.4  文件格式 59\n2.5  云存储 63\n2.6  小结 64\n第3章  计算 65\n3.1  Hadoop MapReduce的基础 66\n3.1.1  概念 66\n3.1.2  架构 69\n3.2  如何启动MapReduce作业 76\n3.2.1  编写Map任务 77\n3.2.2  编写reduce任务 79\n3.2.3  编写MapReduce作业 80\n3.2.4  配置 83\n3.3  MapReduce的高级特性 85\n3.3.1  分布式缓存 85\n3.3.2  计数器 87\n3.3.3  作业历史服务器 89\n3.4  与Spark作业的区别 91\n3.5  小结 92\n第4章  用户体验 93\n4.1  Apache Hive 94\n4.1.1  安装Hive 96\n4.1.2  HiveQL 97\n4.1.3  UDF\/SerDe 103\n4.1.4  Hive调优 105\n4.2  Apache Pig 106\n4.2.1  安装Pig 107\n4.2.2  Pig Latin 108\n4.3  UDF 110\n4.4  Hue 111\n4.5  Apache Oozie 114\n4.5.1  安装Oozie 115\n4.5.2  Oozie的工作原理 118\n4.5.3  工作流\/协调器 119\n4.5.4  Oozie CLI 124\n4.6  小结 124\n第5章  与其他系统集成 125\n5.1  Apache Sqoop 126\n5.2  Apache Flume 130\n5.3  Apache Kafka 136\n5.3.1  工作原理 138\n5.3.2  Kafka Connect 141\n5.3.3  流处理 143\n5.4  Apache Storm 144\n5.4.1  工作原理 145\n5.4.2  Trident 148\n5.4.3  Kafka集成 149\n5.5  小结 152\n第6章  Hadoop安全 153\n6.1  提升Hadoop群集安全性 154\n6.1.1  边界安全 154\n6.1.2  Kerberos认证 156\n6.1.3  Hadoop中的服务级授权 162\n6.1.4  用户模拟 167\n6.1.5  提升HTTP信道的安全性 170\n6.2  提升数据安全性 174\n6.2.1  数据分类 175\n6.2.2  将数据传到群集 176\n6.2.3  保护群集中的数据 182\n6.3  增强应用程序安全性 189\n6.3.1  YARN架构 189\n6.3.2  YARN中的应用提交 190\n6.4  小结 195\n第7章  自由的生态圈：Hadoop与Apache BigTop 197\n7.1  基础概念 198\n7.1.1  软件栈 199\n7.1.2  测试栈 200\n7.1.3  在我的笔记本电脑上工作 201\n7.2  开发定制的软件栈 201\n7.2.1  Apache Bigtop：历史 201\n7.2.2  Apache Bigtop：概念和哲学思想 202\n7.2.3  项目结构 204\n7.2.4  谈谈构建系统 205\n7.2.5  工具链和开发环境 206\n7.2.6  BOM定义 207\n7.3  部署 208\n7.3.1  Bigtop Provisioner 208\n7.3.2  群集的无主节点Puppet部署 209\n7.3.3  使用Puppet进行配置管理 213\n7.4  集成验证 215\n7.4.1  iTests和验证应用程序 216\n7.4.2  栈集成测试开发 217\n7.4.3  栈的验证 220\n7.4.4  群集故障测试 221\n7.4.5  栈的冒烟测试 222\n7.5  将所有工作组合在一起 223\n7.6  小结 224\n第8章  Hadoop软件栈的In-Memory计算 227\n8.1  In-Memory计算简介 229\n8.2  Apache Ignite：内存优先 231\n8.2.1  Apache Ignite的系统体系架构 232\n8.2.2  数据网格 233\n8.2.3  高可用性讨论 236\n8.2.4  计算网格 237\n8.2.5  服务网格 238\n8.2.6  内存管理 238\n8.2.7  持久化存储 240\n8.3  使用Ignite加速旧式Hadoop 240\n8.3.1  In-Memory存储的好处 241\n8.3.2  内存文件系统：HDFS缓存 242\n8.3.3  In-Memory MapReduce 243\n8.4  Apache Ignite的高级用法 247\n8.4.1  Spark和Ignite 247\n8.4.2  共享状态 249\n8.4.3  Hadoop上的In-Memory SQL 251\n8.4.4  使用Ignite的SQL 252\n8.4.5  使用Apache Ignite进行流处理 255\n8.5  小结 256\n术语表 259","pages":"264","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29751629.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29751629.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29751629.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30205926\/","id":"30205926","publisher":"清华大学出版社","isbn10":"7302466459","isbn13":"9787302466451","title":"Hadoop大数据解决方案","url":"https:\/\/api.douban.com\/v2\/book\/30205926","alt_title":"","author_intro":"Benoy Antony是Apache Hadoop Committer，在eBay公司担任Hadoop架构师。\nKonstantin Boudnik是Memcore.io的共同创始人兼CEO，他是Hadoop的早期开发者之一，与他人共同创建了Apache Bigtop。\nCheryl Adams是医疗数据领域的一位资深云数据和基础设施架构师。\nBranky Shao是eBay的软件工程师，同时也是Cascading项目的贡献者。\nCazen Lee是三星SDS公司的一位软件架构师。\nKai Sasaki是Treasure Data公司的一位软件工程师。","summary":"使用Hadoop构建更优秀的大数据解决方案\nHadoop开源且基于Java、几乎没有入门障碍，它提供了迅速占据市场的实用大数据解决方案。\n《Hadoop大数据解决方案》由包括已认证Hadoop开发者、Committers和峰会演讲者在内的专家团队编写，可以作为有关该框架流程和功能的自学教程。书中单独介绍了各个组件，最后用实际项目将它们联系起来并构建示例应用。本书跳过数据库开发基础知识，直奔主题，帮助有经验的开发者快速上手，并开始在真实场景中使用Hadoop。\n主要内容\n◆ 向你展示使用Hadoop Stack配置存储、用户体验和内存计算的方法\n◆ 解释使用Kafka实时消息和Storm数据流将Hadoop与其他系统集成的方法\n◆ 演示关键安全特性与技术，同时给出保证数据安全的专家建议\n◆ 讲授使用Apache BigTop打包、测试和配置的基础知识，以及使用Ignite更快速执行MapReduce的方法\n◆ 带你领略示例应用构建过程，展示核心组件如何协同工作，同时提供了所有示例代码","series":{"id":"43020","title":"大数据应用与技术丛书"},"price":"49.80元"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["[印] 迪帕延 • 德夫"],"pubdate":"2018-5","tags":[{"count":3,"name":"大数据","title":"大数据"},{"count":2,"name":"机器学习","title":"机器学习"},{"count":2,"name":"人工智能","title":"人工智能"},{"count":1,"name":"计算科学","title":"计算科学"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"深度学习","title":"深度学习"},{"count":1,"name":"未资源","title":"未资源"},{"count":1,"name":"图灵","title":"图灵"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29765443.jpg","binding":"平装","translator":["范东来","赵运枫","封　强"],"catalog":"第1章　深度学习介绍　　1\n1.1　开始深度学习之旅　　5\n1.1.1　深度前馈网络　　6\n1.1.2　各种学习算法　　6\n1.2　深度学习的相关术语　　10\n1.3　深度学习——一场人工智能革命　　12\n1.4　深度学习网络的分类　　18\n1.4.1　深度生成或无监督模型　　19\n1.4.2　深度判别模型　　20\n1.5　小结　　22\n第2章　大规模数据的分布式深度学习　　23\n2.1　海量数据的深度学习　　24\n2.2　大数据深度学习面临的挑战　　27\n2.2.1　海量数据带来的挑战（第一个V）　　28\n2.2.2　数据多样性带来的挑战（第二个V）　　28\n2.2.3　数据快速处理带来的挑战（第三个V）　　29\n2.2.4　数据真实性带来的挑战（第四个V）　　29\n2.3　分布式深度学习和Hadoop　　29\n2.3.1　Map-Reduce　　31\n2.3.2　迭代Map-Reduce　　31\n2.3.3　YARN　　32\n2.3.4　分布式深度学习设计的重要特征　　32\n2.4　深度学习的开源分布式框架Deeplearning4j　　34\n2.4.1　Deeplearning4j的主要特性　　34\n2.4.2　Deeplearning4j功能总结　　35\n2.5　在Hadoop YARN上配置Deeplearning4j　　35\n2.5.1　熟悉Deeplearning4j　　36\n2.5.2　为进行分布式深度学习集成Hadoop YARN和Spark　　40\n2.5.3　Spark在Hadoop YARN上的内存分配规则　　40\n2.6　小结　　44\n第3章　卷积神经网络　　45\n3.1　卷积是什么　　46\n3.2　卷积神经网络的背景　　47\n3.3　卷积神经网络的基本层　　48\n3.3.1　卷积神经网络深度的重要性　　49\n3.3.2　卷积层　　49\n3.3.3　为卷积层选择超参数　　52\n3.3.4　ReLU层　　56\n3.3.5　池化层　　57\n3.3.6　全连接层　　58\n3.4　分布式深度卷积神经网络　　58\n3.4.1　最受欢迎的深度神经网络及其配置　　58\n3.4.2　训练时间——深度神经网络面临的主要挑战　　59\n3.4.3　将Hadoop应用于深度卷积神经网络　　59\n3.5　使用Deeplearning4j构建卷积层　　61\n3.5.1　加载数据　　61\n3.5.2　模型配置　　62\n3.5.3　训练与评估　　63\n3.6　小结　　64\n第4章　循环神经网络　　65\n4.1　循环网络与众不同的原因　　66\n4.2　循环神经网络　　67\n4.2.1　展开循环计算　　68\n4.2.2　循环神经网络的记忆　　69\n4.2.3　架构　　70\n4.3　随时间反向传播　　71\n4.4　长短期记忆　　73\n4.4.1　随时间深度反向传播的问题　　73\n4.4.2　长短期记忆　　73\n4.5　双向循环神经网络　　75\n4.5.1　循环神经网络的不足　　75\n4.5.2　解决方案　　76\n4.6　分布式深度循环神经网络　　77\n4.7　用Deeplearning4j训练循环神经网络　　77\n4.8　小结　　80\n第5章　受限玻尔兹曼机　　81\n5.1　基于能量的模型　　82\n5.2　玻尔兹曼机　　83\n5.2.1　玻尔兹曼机如何学习　　84\n5.2.2　玻尔兹曼机的不足　　85\n5.3　受限玻尔兹曼机　　85\n5.3.1　基础架构　　85\n5.3.2　受限玻尔兹曼机的工作原理　　86\n5.4　卷积受限玻尔兹曼机　　88\n5.5　深度信念网络　　90\n5.6　分布式深度信念网络　　91\n5.6.1　受限玻尔兹曼机的分布式训练　　91\n5.6.2　深度信念网络的分布式训练　　92\n5.7　用Deeplearning4j实现受限玻尔兹曼机和深度信念网络　　94\n5.7.1　受限玻尔兹曼机　　94\n5.7.2　深度信念网络　　95\n5.8　小结　　97\n第6章　自动编码器　　98\n6.1　自动编码器　　98\n6.2　稀疏自动编码器　　101\n6.2.1　稀疏编码　　101\n6.2.2　稀疏自动编码器　　102\n6.3　深度自动编码器　　104\n6.3.1　训练深度自动编码器　　104\n6.3.2　使用Deeplearning4j实现深度自动编码器　　107\n6.4　降噪自动编码器　　108\n6.4.1　降噪自动编码器的架构　　109\n6.4.2　堆叠式降噪自动编码器　　109\n6.4.3　使用Deeplearning4j实现堆叠式降噪自动编码器　　110\n6.5　自动编码器的应用　　112\n6.6　小结　　112\n第7章　用Hadoop玩转深度学习　　113\n7.1　Hadoop中的分布式视频解码　　114\n7.2　使用Hadoop进行大规模图像处理　　116\n7.3　使用Hadoop进行自然语言处理　　117\n7.3.1　Web爬虫　　118\n7.3.2　自然语言处理的关键词提取和模块　　118\n7.3.3　从页面评估相关关键词　　118\n7.4　小结　　119\n参考文献　　120","pages":"140","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29765443.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29765443.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29765443.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30219200\/","id":"30219200","publisher":"人民邮电出版社","isbn10":"7115482187","isbn13":"9787115482181","title":"Hadoop深度学习","url":"https:\/\/api.douban.com\/v2\/book\/30219200","alt_title":"","author_intro":"Dipayan Dev\n多年大数据开发经验，擅长非关系型数据库技术和Hadoop框架，曾在IEEE和Springer的期刊上多次发表相关研究论文。现任印度PromptCloud公司软件工程师。","summary":"本书主要目标是处理很多深度学习应用的热点问题并向读者披露解决方案的细节。主要内容分为7章：第1章介绍深度学习基础知识，第2章介绍大规模数据的分布式深度学习，第3章介绍卷积神经网络，第4章介绍循环神经网络，第5章介绍受限玻尔兹曼机，第6章介绍自动编码器，第7章介绍如何用Hadoop玩转深度学习。","series":{"id":"660","title":"图灵程序设计丛书"},"price":"39.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["[美] Zachary Radtka","[美] Donald Miner"],"pubdate":"2015-10","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29775193.jpg","binding":"","translator":[],"catalog":"Source Code. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii\n1. Hadoop Distributed File System (HDFS). . . . . . . . . . . . . . . . . . . . . . . . . 1\nOverview of HDFS 2\nInteracting with HDFS 3\nSnakebite 7\nChapter Summary 13\n2. MapReduce with Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15\nData Flow 15\nHadoop Streaming 18\nmrjob 22\nChapter Summary 26\n3. Pig and Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\nWordCount in Pig 28\nRunning Pig 29\nPig Latin 31\nExtending Pig with Python 35\nChapter Summary 40\n4. Spark with Python. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41\nWordCount in PySpark 41\nPySpark 43\nResilient Distributed Datasets (RDDs) 44\nText Search with PySpark 50\n5. Workflow Management with Python. . . . . . . . . . . . . . . . . . . . . . . . . . 53\nInstallation 53\nWorkflows 54\nAn Example Workflow 55\nHadoop Workflows 58\nChapter Summary 62","pages":"71","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29775193.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29775193.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29775193.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30229786\/","id":"30229786","publisher":"O'Reilly","isbn10":"1491942274","isbn13":"9781491942277","title":"hadoop with python","url":"https:\/\/api.douban.com\/v2\/book\/30229786","alt_title":"","author_intro":"Zachary Radtka, a platform engineer at Miner & Kasch, has extensive experience creating custom analytics that run on petabyte-scale data sets.","summary":"Hadoop is mostly written in Java, but that doesn't exclude the use of other programming languages with this distributed storage and processing framework, particularly Python. With this concise book, you'll learn how to use Python with the Hadoop Distributed File System (HDFS), MapReduce, the Apache Pig platform and Pig Latin script, and the Apache Spark cluster-computing framework.\nAuthors Zachary Radtka and Donald Miner from the data science firm Miner & Kasch take you through the basic concepts behind Hadoop, MapReduce, Pig, and Spark. Then, through multiple examples and use cases, you'll learn how to work with these technologies by applying various Python tools.\nUse the Python library Snakebite to access HDFS programmatically from within Python applications\nWrite MapReduce jobs in Python with mrjob, the Python MapReduce library\nExtend Pig Latin with user-defined functions (UDFs) in Python\nUse the Spark Python API (PySpark) to write Spark programs with Python\nLearn how to use the Luigi Python workflow scheduler to manage MapReduce jobs and Pig scripts","price":"USD 0.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["V Naresh Kumar","Prashant Shindgikar"],"pubdate":"2018-3-29","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29753374.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"394","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29753374.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29753374.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29753374.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30207700\/","id":"30207700","publisher":"Packt Publishing","isbn10":"178712276X","isbn13":"9781787122765","title":"Modern Big Data Processing with Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/30207700","alt_title":"","author_intro":"","summary":"","price":"GBP 45.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30502824\/","id":"30502824","publisher":"","isbn10":"7115497540","isbn13":"9787115497543","title":"Hadoop虚拟化","url":"https:\/\/api.douban.com\/v2\/book\/30502824","alt_title":"","author_intro":"","summary":"","price":"80.50"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["【美】Sam R. Alapati（山姆·阿拉帕蒂）"],"pubdate":"2019-3","tags":[{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s30026412.jpg","binding":"平装","translator":["赵国贤"],"catalog":"第Ⅰ部分  Hadoop架构与Hadoop集群介绍\n第1章  Hadoop与Hadoop环境介绍  3\nHadoop简介  4\nHadoop 的特性  5\nHadoop 与大数据  5\nHadoop 的典型应用场景  6\n传统数据库系统  7\n数据湖  9\n大数据、数据科学和Hadoop  10\nHadoop集群与集群计算  11\n集群计算  11\nHadoop 集群  12\nHadoop组件和Hadoop生态  14\nHadoop管理员需要做些什么  16\nHadoop 管理—新的范式  17\n关于Hadoop 管理你需要知道的  18\nHadoop 管理员的工具集  19\nHadoop 1和Hadoop 2的关键区别  19\n架构区别  20\n高可用性  20\n多计算引擎  21\n分离处理和调度  21\nHadoop 1 和Hadoop 2 中的资源分配  22\n分布式数据处理：MapReduce和Spark、Hive、Pig  22\nMapReduce  22\nApache Spark  23\nApache Hive  24\nApache Pig  24\n数据整合：Apache Sqoop、Apache Flume和Apache Kafka  25\nHadoop管理中的关键领域  26\n集群存储管理  26\n集群资源分配  26\n作业调度  27\nHadoop 数据安全  27\n总结  28\n第2章  Hadoop架构介绍  31\nHadoop与分布式计算  31\nHadoop 架构  32\nHadoop 集群  33\n主节点和工作节点  33\nHadoop 服务  34\n数据存储—Hadoop分布式文件系统  35\nHDFS 特性  35\nHDFS 架构  36\nHDFS 文件系统  38\nNameNode 操作  41\n利用YARN（Hadoop操作系统）进行数据处理  45\nYARN 的架构  46\nApplicationMaster 如何与ResourceManager 协作进行资源分配  51\n总结  54\n第3章  创建和配置一个简单的Hadoop集群  55\nHadoop发行版本和安装类型  56\nHadoop 发行版本  56\nHadoop 安装类型  57\n设置一个伪分布式Hadoop集群  58\n满足操作系统的要求  58\n修改内核参数  59\n设置SSH  64\nJava 需求  65\n安装Hadoop  66\n创建必要的Hadoop 用户  66\n创建必要的目录  67\nHadoop初始配置  67\n环境变量配置文件  69\n只读默认配置文件  70\nsite 专用配置文件  70\n其他Hadoop 相关的配置文件  71\n配置文件的优先级  72\n可变扩展和配置参数  74\n配置Hadoop 守护进程环境变量  74\n配置Hadoop 的核心属性（使用core-site.xml 文件）  76\n配置MapReduce（使用mapred-site.xml 文件）  78\n配置YARN（使用yarn-site.xml 文件）  79\n配置HDFS（使用hdfs-site.xml 文件）  80\n操作新的Hadoop集群  82\n格式化分布式文件系统  82\n设置环境变量  82\n启动HDFS 和YARN 服务  83\n验证服务启动  85\n关闭服务  85\n总结  86\n第4章  规划和创建一个完全分布式集群  87\n规划Hadoop集群  88\n集群规划注意事项  88\n安排服务器  90\n节点选择的标准  90\n从单机架到多机架  91\n调整Hadoop 集群  91\nCPU、内存和存储选择的一般性原则  92\n主节点的特殊要求  95\n关于服务器大小的几点建议  96\n集群增长  97\n大型集群指南  97\n创建一个多节点集群  98\n如何设置测试集群  98\n修改Hadoop的配置  102\n更改HDFS 的配置（hdfs-site.xml 文件）  102\n更改YARN 的配置  105\n修改MapReduce 的配置  109\n启动集群  110\n使用脚本启动和关闭集群  112\n快速检查新集群的文件系统  113\n配置Hadoop服务、Web界面和端口  114\n服务配置和Web 界面  115\n设置Hadoop 服务的端口  117\nHadoop 客户端  120\n总结  122\n第Ⅱ部分  Hadoop应用架构\n第5章  在集群上运行一个应用—MapReduce框架和Hive、Pig  125\nMapReduce框架  125\nMapReduce 模型  126\nMapReduce 怎样工作  127\nMapReduce 作业处理  129\n一个简单的MapReduce 程序  130\n通过运行WordCount 程序理解Hadoop 作业的处理过程  132\nMapReduce 输入\/ 输出目录  133\nHadoop 如何展示作业细节  133\nHadoop Streaming  135\nApache Hive  137\nHive 数据组织  138\n使用Hive 表  138\n将数据导入Hive  138\n使用Hive 查询  139\nApache Pig  139\nPig 执行模型  140\n一个简单的Pig 示例  140\n总结  141\n第6章  集群上的应用—Spark框架介绍  143\nSpark是什么  144\n为什么使用Spark  145\n速度  145\n易用性  147\n通用框架  148\nSpark 和Hadoop  148\nSpark技术栈  149\n安装Spark  151\nSpark 示例  152\nSpark 的主要文件和目录  153\n编译Spark 二进制文件  153\n减少Spark 日志  153\nSpark运行模式  154\n本地模式  154\n集群模式  154\n集群管理器  154\n独立集群管理器  155\n基于Apache Mesos 的Spark  157\n基于YARN 的Spark  158\nYARN 和Spark 如何协同合作  159\n设置基于Hadoop 集群的Spark  159\nSpark和数据获取  159\n从Linux 文件系统加载数据  160\n从HDFS 加载数据  160\n从关系型数据库获取数据  161\n总结  162\n第7章  运行Spark应用程序  163\nSpark编程模型  163\nSpark 编程和RDD  164\nSpark 编程  166\nSpark应用程序  167\nRDD 基础  168\n创建RDD  168\nRDD 操作  171\nRDD 持久化  173\nSpark应用的结构  174\nSpark 术语  174\nSpark 应用程序的组件  174\n交互式运行Spark应用程序  175\nSpark shell 和Spark 应用程序  176\nSpark shell  176\n使用Spark shell  176\nSpark 集群执行概述  179\n创建和提交Spark应用  180\n构建Spark 应用  180\n在独立的Spark 集群上运行应用  180\n使用spark-submit 执行应用  181\n在Mesos 上运行Spark 应用  183\n在Hadoop YARN 集群上运行Spark 应用  183\n使用JDBC\/ODBC 服务  186\n配置Spark应用  187\nSpark 的配置属性  187\n运行spark-submit 时的配置  187\n监控Spark应用  188\n使用Spark Streaming处理流式计算  189\nSpark Streaming 如何工作  189\nSpark Streaming 示例，又是WordCount  191\n使用Spark SQL 处理结构化数据  192\n数据框架  192\nHiveContext 和SQLContext  193\n使用Spark SQL  193\n创建DataFrames  195\n总结  195\n第Ⅲ部分  管理和保护Hadoop数据和高可用性\n第8章  NameNode的作用和HDFS的工作原理  199\nHDFS—NameNode与DataNode之间的交互  200\n客户端和HDFS 之间的交互  200\nNameNode 与DataNode 之间的通信  201\n机架感知与拓扑逻辑  203\n如何在集群中配置机架感知策略  204\n找出集群的机架信息  204\nHDFS 数据副本  206\nHDFS 数据组织和数据块  207\n数据复制  207\n文件块和副本状态  209\n客户端如何读写HDFS数据  213\n客户端如何读取HDFS 数据  213\n客户端如何向HDFS 写数据  214\n了解HDFS恢复过程  217\n生成戳  218\n租约恢复  218\n块恢复  219\n管道恢复  219\nHDFS中的集中式缓存管理  220\nHadoop 和OS 的页面缓存  221\n集中式缓存管理的关键原则  221\n集中式缓存管理如何工作  221\n配置缓存  222\n缓存指令  223\n缓存池  223\n使用缓存  223\nHadoop归档存储、SSD和内存（异构存储）  225\n不同存储类型的性能特点  225\n对异构HDFS 存储的需求  226\n存储体系结构的变化  227\n文件的存储首选项  228\n设置归档存储  228\n管理存储策略  232\n移动数据  232\n实现归档  233\n总结  234\n第9章  HDFS命令、HDFS权限和HDFS存储  235\n使用HDFS Shell命令管理HDFS  235\n使用hdfs dfs 实用程序来管理HDFS  237\n列出HDFS 文件和目录  239\n创建HDFS 目录  241\n删除HDFS 文件和目录  242\n更改文件和目录所有权和组  242\n使用dfsadmin实用程序执行HDFS操作  243\ndfsadmin -report 命令  245\n管理HDFS权限和用户  247\nHDFS 文件权限  247\nHDFS 用户和超级用户  249\n管理HDFS存储  252\n检查HDFS 磁盘使用情况  252\n分配HDFS 空间配额  255\n重新均衡HDFS数据  259\nHDFS 数据不均衡的原因  260\n运行均衡器以均衡HDFS 数据  260\n使用hdfs dfsadmin 使事情更简单  263\n何时运行均衡器  265\n回收HDFS空间  266\n删除文件和目录  266\n降低复制因子  266\n总结  268\n第10章  数据保护、文件格式和访问HDFS  269\n保护数据  270\n使用HDFS 回收站防止意外数据删除  270\n使用HDFS 快照保护重要数据  272\n通过文件系统检查确保数据完整性  276\n数据压缩  281\n常用压缩格式  282\n评估各种压缩方案  282\nMapReduce 的各个阶段的压缩  283\nSpark 的压缩  286\n数据序列化  286\nHadoop文件格式  287\n确定正确文件格式的标准  288\nHadoop 支持的文件格式  289\n理想文件格式  294\nHadoop 小文件问题和合并文件  294\n使用NameNode 联合架构克服小文件问题  295\n使用Hadoop Archives 管理小文件  295\n减小小文件的性能影响  298\n使用Hadoop WebHDFS和HttpFS  299\nWebHDFS—Hadoop REST API  299\n使用WebHDFS API  300\n了解WebHDFS 命令  301\n使用HttpFS 网关从防火墙后面访问HDFS  304\n总结  306\n第11章  NameNode操作、高可用性和联合  307\n了解NameNode操作  308\nHDFS 元数据  309\nNameNode 启动过程  311\nNameNode 和DataNode 如何协同工作  311\n检查点操作  313\nSecondary NameNode、检查点节点、备份节点和Standby NameNode  314\n配置检查点操作频率  315\n管理检查点性能  316\n检查点的机制  317\nNameNode安全模式操作  319\n自动安全模式操作  319\n将NameNode 置于安全模式  320\nNameNode 如何进行模式转换  321\n备份和恢复NameNode 元数据  322\n配置HDFS高可用性  324\nNameNode HA 架构（QJM）  325\n设置HDFS HA Quorum 集群  327\n部署高可用性NameNode  331\n管理HA NameNode 设置  335\nHA 手动和自动故障转移  336\nHDFS联合  338\n联合NameNode 的体系结构  339\n总结  340\n第Ⅳ部分  数据迁移、资源分配、作业调度及安全\n第12章  将数据导入和导出Hadoop  343\nHadoop数据传输工具简介  343\n通过命令行将数据加载到HDFS  344\n使用-cat 命令转储文件的内容  344\n检测HDFS 文件  345\n从HDFS 或向HDFS 复制或移动文件  346\n使用-get 命令移动文件  347\n向HDFS 或从HDFS 移动文件  348\n使用-tail 和head 命令  348\n使用DistCp在HDFS集群之间复制数据  349\n如何使用DistCp 命令移动数据  349\nDistCp 选项  351\n使用Sqoop从关系型数据库获取数据  353\nSqoop 架构  354\n部署Sqoop  355\n使用Sqoop 移动数据  356\n使用Sqoop 导入数据  356\n将数据导入Hive  367\n使用Sqoop 导出数据  369\n通过Flume从外部来源采集数据  376\nFlume 架构简介  376\n配置Flume agent  378\n简单的Flume 示例  379\n使用Flume 将数据移动到HDFS  381\n更复杂的Flume 示例  383\n与Kafka交互数据  385\nKafka 的优点  386\nKafka 是如何工作的  386\n设置Apache Kafka 集群  388\n将Kafka 与Hadoop 和Storm 集成  392\n总结  393\n第13章  Hadoop集群中的资源分配  395\nHadoop中的资源分配  395\n管理集群的工作负载  396\nHadoop 的资源调度器  397\nFIFO调度器  398\n容量调度器  399\n队列和子队列  400\n集群如何分配资源  405\n抢占申请  408\n启用容量调度器  409\n一个典型的容量调度器  409\n公平调度器  413\n队列  414\n配置公平调度器  415\n作业是如何被放置到队列中的  417\n公平调度器中的应用抢占  418\n安全和资源池  419\n一个fair-scheduler.xml 示例文件  419\n将作业提交到调度器  421\n在队列之间移动应用程序  421\n监控公平调度器  422\n容量调度器和公平调度器的对比  422\n两个调度器之间的相似之处  422\n两个调度器之间的差异  422\n总结  423\n第14章  使用Oozie管理作业工作流  425\n使用Apache Oozie调度作业  425\nOozie架构  427\nOozie 服务器  427\nOozie 客户端  428\nOozie 数据库  428\n在集群中部署Oozie  429\n安装和配置Oozie  430\n为Oozie 配置Hadoop  432\n了解Oozie工作流  434\n工作流、控制流和节点  434\n使用workﬂow.xml 文件定义工作流  435\nOozie如何运行一个动作  436\n配置动作节点  437\n创建Oozie工作流  442\n配置控制节点  443\n配置作业  448\n运行Oozie工作流作业  449\n指定作业属性  449\n部署Oozie 作业  451\n创建动态工作流  451\nOozie 协调器  452\n基于时间的协调器  453\n基于数据的协调器  455\n基于时间和数据的协调器  456\n从命令行提交Oozie 协调器  457\n管理和治理Oozie  458\n常见的Oozie 命令  458\nOozie 故障排除  460\nOozie cron 调度和Oozie SLA  461\n总结  462\n第15章  Hadoop安全  463\nHadoop安全概览  464\n认证、授权和审计  466\n使用Kerberos进行Hadoop认证  467\nKerberos 及其工作原理  467\nKerberos 认证过程  469\nKerberos 互信  470\n一个特殊主体  471\n将Kerberos 添加到集群中  471\nHadoop 相关的Kerberos 设置  476\n使用Kerberos 保护Hadoop 集群  480\nKerberos 如何验证用户和服务  486\n管理Kerberized Hadoop 集群  487\nHadoop授权  490\nHDFS 权限  491\n服务级授权  495\n基于角色的Apache Sentry 权限设置  497\nHadoop审计  503\n审计HDFS 操作  504\n审计YARN 操作  504\nHadoop数据安全  505\nHDFS 透明加密  505\n加密转换中的数据  508\n其他Hadoop安全举措  509\n使用Apache Knox 网关保护Hadoop 基础设施  509\nApache Ranger 安全管理  509\n总结  510\n第Ⅴ部分  监控、优化和故障排除\n第16章  管理作业、使用Hue和执行常规任务  513\n使用YARN命令管理Hadoop作业  514\n查看YARN 应用程序  515\n检查应用程序的状态  516\nKill 正在执行的作业  516\n检查节点状态  517\n检查YARN 的队列状态  517\n获取作业的日志  517\nYARN 管理命令  518\n下线和上线节点  519\n包含和剔除主机  520\n下线DataNodes 和NodeManagers  521\n重新上线节点  522\n关于下线和重新上线的注意事项  523\n添加新的DataNode 和NodeManager  524\n高可用性ResourceManager  524\n高可用性ResourceManager 架构  525\n设置高可用性ResourceManager  525\nResourceManager 故障转移  526\n使用ResourceManager 高可用性命令  528\n执行常规管理任务  529\n将NameNode 移动到不同的主机  529\n管理高可用性NameNode  529\n使用关闭\/ 启动脚本来管理集群  530\n均衡HDFS  530\n均衡DataNodes 上存储  531\n管理MySQL数据库  532\n配置MySQL 数据库  532\n配置高可用性MySQL  533\n备份重要集群数据  535\n备份HDFS 元数据  535\n备份Metastore 数据库  537\n使用Hue管理集群  537\n允许用户使用Hue  538\n安装Hue  538\n配置集群以使用Hue  540\n管理Hue  544\n使用Hue  544\n使用HDFS的附加功能  545\n在多宿主网络中部署HDFS 和YARN  545\n短路本地读取  546\n可挂载的HDFS  548\n使用NFS 网关将HDFS 挂载到本地文件系统  549\n总结  551\n第17章  监控、指标和Hadoop日志  553\n监控Linux服务器  554\nLinux 系统监控基础  554\nLinux 系统监控工具  556\nHadoop指标  559\nHadoop 指标类型  560\n使用Hadoop 指标  561\n收集文件系统的指标  561\n使用Ganglia进行监测  563\nGanglia 架构  563\nGanglia 和Hadoop 整合  564\n设置Hadoop 指标  565\nHadoop日志记录  566\nHadoop 日志消息  566\n守护进程和应用程序日志以及如何查看这些日志  568\n应用程序日志记录的工作原理  568\nHadoop 如何使用HDFS 目录和本地目录  570\nNodeManager 如何使用本地目录  571\n通过日志聚合将作业日志存储在HDFS 中  576\n使用Hadoop 守护程序日志  580\n使用Hadoop的Web UI进行监控  582\n使用ResourceManager Web UI 监控作业  583\nJobHistoryServer Web UI  589\n使用NameNode Web UI 进行监控  591\n监控其他Hadoop组件  592\n监控Hive  592\n监控Spark  593\n总结  593\n第18章  调优集群资源，优化MapReduce作业和基准测试  595\n如何分配YARN内存和CPU  596\n分配内存  596\n配置CPU 内核数量  604\n内存与CPU 之间的关系  605\n配置高性能  605\n推测执行  605\n减少系统上的I\/O 负载  608\n调整map和reduce任务，管理员可以做什么  608\nmap 任务调优  609\n输入和输出  610\nreduce 任务调优  613\nMapReduce shufﬂe 进程调优  615\n优化Pig和Hive作业  617\n优化Hive 作业  618\n优化pig 作业  619\n对集群进行基准测试  621\n使用TestDFSIO 测试I \/ O 性能  621\n使用TeraSort 进行基准测试  623\n使用Hadoop 的Rumen 和GridMix 进行基准测试  625\nHadoop计数器  629\n文件系统计数器  629\n作业计数器  631\nMapReduce 框架计数器  632\n自定义Java 计数器  633\n限制计数器数量  633\n优化MapReduce  633\nmap-only 与map 及reduce 作业  634\n使用combiners 提升MapReduce 性能  634\n使用partitioner 提高性能  635\n在MapReduce 过程中压缩数据  636\n太多的map 和reduce 任务  637\n总结  639\n第19章  在YARN上配置和调优Apache Spark  641\n在YARN上配置Spark的资源分配  642\n分配CPU  642\n分配内存  642\n如何把资源分配给Spark  642\nSpark 应用程序的资源分配限制  643\n将资源分配给驱动程序  645\n为执行器配置资源  648\nSpark 如何使用内存  652\n要注意的事情  654\n集群或客户端模式  656\n配置Spark 相关网络参数  657\nYARN Spark动态资源分配  658\n动态和静态资源分配  658\n如何管理动态资源分配  658\n启用动态资源分配  659\n存储格式和压缩数据  660\n存储格式  660\n文件大小  662\n压缩  662\n监控Spark应用程序  663\n使用Spark Web UI 了解性能  663\nSpark 系统和Metrics REST API  666\nYARN 上的Spark 历史记录服务器  666\n从命令行跟踪作业  668\n调优垃圾回收  668\n垃圾回收机制  668\n如何收集GC 统计数据  669\n调优Spark Streaming应用程序  670\n减少批处理时间  670\n设置正确的批次间隔  670\n调优内存和垃圾回收  671\n总结  671\n第20章  优化Spark应用程序  673\n重新审视Spark执行模型  674\nSpark 执行模型  674\nshufﬂe操作以及如何减少shufﬂe操作  676\nWordCount 示例（再一次展示）  676\nshufﬂe 操作的影响  678\n配置shufﬂe 参数  679\n分区和并行性（任务数）  684\n并行度  685\n极少数任务的问题  687\n设置默认分区数  687\n如何增加分区数量  688\n使用Repartition（重新分区）和Coalesce（合并）\n操作来更改RDD 中的分区数  689\n两种类型的分区器  690\n数据分区和如何避免shufﬂe  690\n数据的序列化和压缩优化  691\n数据序列化  691\n配置压缩  692\nSpark的SQL查询优化器  693\n优化步骤  693\nSpark 的推测执行功能  695\n数据本地化的重要性  696\n缓存数据  698\n缓存容错  699\n如何指定缓存  699\n总结  704\n第21章  Hadoop故障排除—样例  705\n空间相关问题  705\n处理Linux 文件系统100% 使用的情况  706\nHDFS 空间问题  707\n本地目录以及日志目录空间超出  707\n磁盘容错  709\n处理卡住的YARN作业  710\nJVM内存分配与垃圾回收策略  712\n理解JVM 垃圾回收  712\n优化垃圾回收  713\nAnalyzing Memory Usage  713\n内存不足问题  714\nApplicationMaster 内存问题  715\n处理不同类型的错误  716\n处理守护进程失败的情况  716\n启动Hadoop 守护进程失败  717\n任务和作业失败  718\nSpark作业故障排除  719\nSpark 的容错机制  720\n杀死Spark 作业  720\n一个作业的最大尝试次数  720\n一个作业最大的失败次数  720\n调试Spark应用  720\n通过日志聚合访问日志  720\n当日志聚合未开启时访问日志  721\n重新审视启动环境  721\n总结  722\n附录A  安装VirtualBox和Linux以及虚拟机的克隆  723","pages":"760","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s30026412.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s30026412.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s30026412.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30490057\/","id":"30490057","publisher":"电子工业出版社","isbn10":"7121356694","isbn13":"9787121356698","title":"Hadoop专家：管理、调优与SparkYARNHDFS安全","url":"https:\/\/api.douban.com\/v2\/book\/30490057","alt_title":"","author_intro":"Sam R. Alapati 是Sabre 的首席Hadoop 管理员，公司总部位于得克萨斯州的南湖，他每天都要管理多个Hadoop 集群。作为Sabre 企业数据分析（EDA）部门所有Hadoop管理相关工作的负责人，Sam 管理并优化了与Hadoop 相关的多个关键数据科学和数据分析工作的流程。Sam 还是一名Oracle 数据库管理专家，具有丰富的关系型数据库和SQL 的相关知识，因而他能成功地完成Hadoop 相关的项目。Sam 在数据库和中间件领域取得了多项成就，包括在过去14 年出版了18 本受欢迎的书籍，主要是关于Oracle数据库管理和Oracle Weblogic Server 方面的。Sam 也是《现代Linux 管理》（O’Reilly,2017）一书的作者。Sam 多年来在配置、体系结构和管理Hadoop 性能方面的从业经历使他认识到，许多Hadoop 管理员和开发人员都希望有一个方便的指南，比如本书，以便在创建、管理、保护和优化Hadoop 基础架构时参考。","summary":"《Hadoop专家：管理、调优与SparkYARNHDFS安全》翻译自 Sam R. Alapati 的 Expert Hadoop Administration。Sam R. Alapati 是 Sabre 公司的首席 Hadoop 管理员，具有多年的 Hadoop 运维管理经验。他希望通过本书，为 Hadoop 集群开发与管理人员提供一些有益指导。\n从事 Hadoop 的管理工作， 首先要了解 Hadoop 的架构，只进行单纯的操作并不能被称为合格的管理员。基于此，本书在介绍 Hadoop 及其生态组件时，都会首先介绍其架构，以期读者能够从更高的层次认识管理工作。\n《Hadoop专家：管理、调优与SparkYARNHDFS安全》首先介绍了 Hadoop 的整体架构及其部署与使用；然后着重介绍了两个重要的计算引擎MapReduce 与 Spark；接着介绍了 Hadoop 的数据存储与安全、数据均衡等特性；最后则介绍了如何进行参数调优与故障排除。整个流程下来，读者能够建立起完整的关于 Hadoop 管理的体系架构。\n《Hadoop专家：管理、调优与SparkYARNHDFS安全》为 Hadoop 管理员而编写，同时也适合Hadoop 开发人员使用。","price":"168.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30498513\/","id":"30498513","publisher":"","isbn10":"7564160896","isbn13":"9787564160890","title":"Hadoop MapReduce V2参考手册（第2版 影印版 英文版）","url":"https:\/\/api.douban.com\/v2\/book\/30498513","alt_title":"","author_intro":"","summary":"","price":"50.50"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Wrox国际IT认证项目组"],"pubdate":"2018-12-1","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29973869.jpg","binding":"平装","translator":["顾晨"],"catalog":"模块1　额外的Hadoop工具：ZooKeeper、Sqoop、Flume、YARN和Storm\n第1讲　用ZooKeeper进行分布式处理协调　3\n1．1　ZooKeeper简介　4\n1．1．1　ZooKeeper的好处　4\n1．1．2　ZooKeeper术语　6\n1．1．3　ZooKeeper命令行界面（CLI）　7\n1．2　安装和运行ZooKeeper　9\n1．2．1　支持的平台　9\n1．2．2　所需的软件　9\n1．2．3　单服务器的安装　9\n1．3　使用ZooKeeper　10\n1．4　ZooKeeper应用程序　12\n1．4．1　FS爬取　13\n1．4．2　Katta　14\n1．4．3　Yahoo!消息代理（YMB）　14\n1．5　使用ZooKeeper构建应用程序　15\n1．5．1　Exec．java　15\n1．5．2　处理事件　17\n1．5．3　监控数据　19\n1．5．4　实现屏障和生产者-消费者队列　22\n练习　30\n备忘单　33\n第2讲　利用Sqoop有效地传输批量数据　34\n2．1　Sqoop简介　35\n2．1．1　Sqoop中的工作流　36\n2．1．2　Sqoop的特性　36\n2．2　使用Sqoop 1　37\n2．3　用Sqoop导入数据　41\n2．3．1　导入完整的表　41\n2．3．2　用HBase Sqoop导入带有复合键的表　42\n2．3．3　指定目标目录　43\n2．3．4　导入选择的行　43\n2．3．5　密码保护　44\n2．3．6　用不同的文件格式导入数据　44\n2．3．7　导入数据压缩　45\n2．4　控制并行　45\n2．5　编码NULL值　47\n2．6　将数据导入Hive表　47\n2．7　将数据导入HBase　47\n2．7．1　使用自由形式查询　48\n2．7．2　重命名Sqoop作业　48\n2．8　导出数据　49\n2．8．1　批量导出　50\n2．8．2　原子导出　50\n2．9　将数据导出至列的子集　50\n2．10　Sqoop中的驱动程序和连接器　51\n2．10．1　驱动程序　51\n2．10．2　连接器　52\n2．10．3　连接到数据库　52\n2．11　Sqoop架构概览　54\n2．12　Sqoop 2　55\n2．12．1　Sqoop 2的优势　56\n2．12．2　易于扩展　56\n2．12．3　安全　57\n练习　58\n备忘单　60\n第3讲　Flume　62\n3．1　Flume简介　63\n3．1．1　Flume架构　64\n3．1．2　流可靠性　66\n3．2　Flume配置文件　66\n3．2．1　流定义　67\n3．2．2　配置单个组件　67\n3．2．3　在代理中添加多个流　68\n3．2．4　配置多代理流　69\n3．2．5　配置流扇出　70\n3．3　设置Flume　71\n3．3．1　安装Flume　71\n3．3．2　配置Flume代理　72\n3．3．3　数据消费　74\n3．4　构建Flume　77\n3．4．1　获得源点　77\n3．4．2　编译\/测试Flume　77\n3．4．3　开发自定义组件　77\n练习　90\n备忘单　92\n第4讲　超越MapReduce—YARN　94\n4．1　YARN简介　95\n4．2　为什么用YARN　96\n4．2．1　提高可扩展性　96\n4．2．2　效率　97\n4．2．3　集群共享　97\n4．3　YARN生态系统　98\n4．3．1　YARN架构　99\n4．3．2　资源　100\n4．3．3　资源管理器　101\n4．3．4　ApplicationMaster　103\n4．3．5　YARN的局限性　106\n4．4　YARN API例子　107\n4．4．1　YARN应用程序剖析　107\n4．4．2　客户端　108\n4．4．3　把它们整合到一起　115\n4．5　Mesos和YARN的比较　116\n4．5．1　Mesos简介　116\n4．5．2　Mesos和Hadoop　118\n练习　120\n备忘单　122\n第5讲　Storm on YARN　124\n5．1　Storm和Hadoop　125\n5．2　Storm简介　126\n5．2．1　Storm架构　126\n5．2．2　Storm应用剖析　129\n5．3　Storm API　132\n5．3．1　spout　132\n5．3．2　bolt　134\n5．4　Storm on YARN　134\n5．4．1　Storm on YARN架构　135\n5．4．2　Storm on YARN的局限性　136\n5．5　安装Storm on YARN　136\n5．5．1　先决条件　136\n5．5．2　安装步骤　137\n5．5．3　排错　138\n5．5．4　管理YARN on Storm　138\n5．6　Storm on YARN的例子　139\n5．6．1　传感器数据spout　139\n5．6．2　仪表盘bolt　140\n5．6．3　HDFS日志记录器bolt　142\n5．6．4　主程序　144\n5．6．5　运行示例　146\n练习　148\n备忘单　151\n模块2　利用NoSQL和Hadoop：实时、安全和云\n第1讲　Hello NoSQL　155\n1．1　看两个简单的例子　156\n1．1．1　持久化偏好数据的一个简单集合——MongoDB　156\n1．1．2　存储汽车品牌和型号数据——Apache Cassandra　162\n1．2　利用语言绑定进行工作　171\n1．2．1　MongoDB的驱动程序　171\n1．2．2　初识Thrift　174\n1．3　存储和访问数据　177\n1．4　在MongoDB中存储和访问数据　178\n1．5　在HBase中存储和访问数据　185\n1．6　在Apache Cassandra中存储和访问数据　189\n1．7　NoSQL数据存储的语言绑定　191\n1．7．1　用Thrift进行诊断　191\n1．7．2　Java的语言绑定　191\n1．7．3　PHP的语言绑定　194\n练习　195\n备忘单　198\n第2讲　使用NoSQL　199\n2．1　创建记录　200\n2．2　访问数据　213\n2．2．1　访问来自MongoDB的文档　213\n2．2．2　访问来自HBase的数据　214\n2．2．3　查询Redis　215\n2．3　更新和删除数据　216\n2．4　MongoDB查询语言的能力　217\n2．4．1　加载MovieLens数据　219\n2．4．2　获取评级数据　221\n2．4．3　MongoDB中的MapReduce　224\n2．5　访问来自HBase这样的面向列的数据库的数据　228\n练习　230\n备忘单　234\n第3讲　Hadoop安全　236\n3．1　Hadoop安全挑战　238\n3．2　认证　239\n3．2．1　Kerberos认证　239\n3．2．2　Kerberos RPC　244\n3．2．3　基于Web的控制台的Kerberos　245\n3．3　委托安全凭证　248\n3．4　授权　253\n3．4．1　HDFS文件权限　253\n3．4．2　服务级别授权　257\n3．4．3　作业授权　260\n练习　261\n备忘单　263\n第4讲　在AWS上运行Hadoop应用程序　265\n4．1　开始了解AWS　266\n4．2　在AWS上运行Hadoop的选项　267\n4．2．1　使用EC2实例的自定义安装　267\n4．2．2　弹性MapReduce　268\n4．3　了解EMR-Hadoop的关系　269\n4．3．1　EMR架构　270\n4．3．2　使用S3存储　271\n4．3．3　最大化地利用EMR　272\n4．3．4　使用CloudWatch和其他AWS组件　274\n4．3．5　访问和使用EMR　274\n4．4　使用AWS S3　280\n4．4．1　了解桶的用法　280\n4．4．2　利用控制台的内容浏览　282\n4．4．3　编程访问S3中的文件　283\n4．4．4　使用MapReduce上传多个文件至S3　294\n4．5　自动化EMR作业流的创建和作业执行　296\n4．6　组织协调EMR中作业的执行　301\n4．6．1　使用EMR集群上的Oozie　301\n4．6．2　AWS简单工作流　303\n4．6．3　AWS数据管道　304\n练习　306\n备忘单　309\n第5讲　实时Hadoop　311\n5．1　实时Hadoop应用　312\n5．2　使用HBase实现实时应用　313\n5．2．1　将HBase用作照片管理系统　315\n5．2．2　将HBase用作Lucene的后端　322\n5．3　使用专门的实时Hadoop查询系统　342\n5．3．1　Apache Drill　344\n5．3．2　Impala　345\n5．3．3　将实时查询系统与MapReduce比较　347\n5．4　使用基于Hadoop的事件处理系统　347\n5．4．1　HFlame　348\n5．4．2　Storm　350\n5．4．3　将事件处理与MapReduce作比较　352\n练习　353\n备忘单　356\n模块3　Hadoop商业发行版和管理工具\n第1讲　大数据简介　359\n1．1　Cloudera基础　360\n1．1．1　包含Apache Hadoop的Cloudera发行版　360\n1．1．2　Cloudera管理器　361\n1．1．3　Cloudera标准版　362\n1．1．4　Cloudera企业版　363\n1．2　Cloudera管理器简介　365\n1．3　Cloudera管理器的管理控制台　367\n1．3．1　启动并登录管理控制台　370\n1．3．2　主页　370\n1．4　添加和管理服务　371\n1．4．1　添加新服务　371\n1．4．2　启动服务　372\n1．4．3　停止服务　372\n1．4．4　重启服务　373\n1．5　使用Cloudera管理器的业务案例　373\n1．6　Cloudera管理器的安装要求　374\n练习　375\n备忘单　377\n第2讲　Cloudera上的Hive和Cloudera管理　379\n2．1　Apache Hive简介　380\n2．1．1　Hive特性　380\n2．1．2　HiveQL　380\n2．2　Hive服务　381\n2．2．1　Hive元数据服务器　382\n2．2．2　Hive网关　382\n2．2．3　升级Cloudera管理器　382\n2．3　为Hive元存储配置模式　383\n2．3．1　嵌入模式　383\n2．3．2　本地模式　384\n2．3．3　远程模式　385\n2．4　配置Hive元存储　386\n2．4．1　Red Hat操作系统　386\n2．4．2　SLES操作系统　388\n2．4．3　Debian\/Ubuntu操作系统　388\n2．5　为Hive设置Cloudera Manager 4．5　389\n2．6　Hive复制　391\n练习　394\n备忘单　396\n第3讲　Hortonworks和Greenplum Pivotal HD　397\n3．1　Hortonworks数据平台　398\n3．1．1　核心服务　400\n3．1．2　数据服务　400\n3．1．3　操作服务　401\n3．2　系统需求和环境　402\n3．2．1　系统需求　402\n3．2．2　构建一个受支持的环境　404\n3．3　安装HDP　405\n3．4　使用Talend Open Studio　409\n3．4．1　安装Talend Open Studio　410\n3．4．2　将数据导入Talend Open Studio　411\n3．4．3　执行数据分析　413\n3．5　Greenplum Pivotal HD　417\n练习　420\n备忘单　422\n第4讲　IBM InfoSphere BigInsights和MapR　424\n4．1　InfoSphere BigInsights简介　425\n4．1．1　Apache Hadoop发行版的InfoSphere BigInsights组件　426\n4．1．2　额外的Hadoop技术　427\n4．1．3　文本分析　428\n4．1．4　IBM Big SQL服务器　428\n4．1．5　InfoSphere BigInsights控制台　428\n4．1．6　InfoSphere BigInsights的Eclipse工具　429\n4．2　安装准备　430\n4．2．1　复核系统需求　431\n4．2．2　选择一个用户　431\n4．2．3　配置浏览器　432\n4．2．4　下载InfoSphere BigInsights　437\n4．2．5　完成常见先决条件的任务　437\n4．3　安装InfoSphere BigInsights　440\n4．4　MapR简介　442\n练习　445\n备忘单　447\n第5讲　应聘准备　449\n5．1　大数据开发者需要的关键技术工具和框架　451\n5．2　大数据开发者的工作角色和职责　452\n5．3　大数据开发者职业机会领域　453","pages":"457","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29973869.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29973869.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29973869.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30428437\/","id":"30428437","publisher":"人民邮电出版社","isbn10":"7115493715","isbn13":"9787115493712","title":"NoSQL Hadoop组件及大数据实施","url":"https:\/\/api.douban.com\/v2\/book\/30428437","alt_title":"","author_intro":"本书作者均为国际知名IT培训机构的知名讲师，他们通过对技术、IT市场需求以及当今就业培训方面的全球行业标准进行了广泛并严格的调研之后，集结成这套“大数据开发者**教程”。作者们的目标是通过这套书为有志于在大数据开发领域取得事业成功的人技术人员和决策者提供bi备的技术和技能。\n顾晨，男，硕士、PMP、信息系统项目管理师。毕业于上海交通大学。曾获邀参加旧金山的Google I\/O大会。喜欢所有与编程相关的事物，拥有14年的编程经验。对于大数据、SAP HANA数据库和思科技术有着极其浓厚的兴趣，是国内较早从事HANA数据库研究的人员之一。先后录制了MCSE、CCNP等多种教学视频，在多家知名网站发布。精通C#、Java编程，目前正致力于人脸识别、室内定位和门店人流统计方面的研究。","summary":"“大数据”近年来成为IT领域的热点话题，人们每天都会通过互联网、移动设备等产生大量数据。如何管理大数据、掌握大数据的核心技术、理解大数据相关的生态系统等，是作为大数据开发者必须学习和熟练掌握的知识。本系列书以“大数据开发者”应掌握的技术为主线，共分两卷，以7个模块分别介绍如何管理大数据生态系统、如何存储和处理数据、如何利用Hadoop工具、如何利用NoSQL与Hadoop协同工作，以及如何利用Hadoop商业发行版和管理工具。本系列书涵盖了大数据开发工作的核心内容，全面且详尽地涵盖了大数据开发的各个领域。\n本书为第2卷，共3个模块，分别介绍Hadoop工具（如ZooKeeper、Sqoop、Flume、YARN和Storm等），利用NoSQL和Hadoop完成实时、安全和云的相关工作，以及Hadoop商业发行版和管理工具（如Cloudera、Hortonworks、Greenplum Pivotal HD等），最后介绍几个实用软件的功能、指南和安装步骤。\n本书适用于想成为大数据开发人员以及所有对大数据开发感兴趣的技术人员和决策者阅读。","series":{"id":"43399","title":"大数据分析师权威教程"},"price":"109.00元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"Java","title":"Java"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29691644.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s29691644.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s29691644.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s29691644.jpg"},"alt":"https:\/\/book.douban.com\/subject\/27071486\/","id":"27071486","publisher":"","isbn10":"7302469679","isbn13":"9787302469674","title":"Elasticsearch集成Hadoop最佳实践","url":"https:\/\/api.douban.com\/v2\/book\/27071486","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30552703\/","id":"30552703","publisher":"","isbn10":"7115483043","isbn13":"9787115483041","title":"Hadoop集群程序设计与开发","url":"https:\/\/api.douban.com\/v2\/book\/30552703","alt_title":"","author_intro":"","summary":"","series":{"id":"47095","title":"数据科学与大数据技术专业系列规划教材"},"price":"50.70"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30527074\/","id":"30527074","publisher":"","isbn10":"7302411395","isbn13":"9787302411390","title":"Hadoop 2.0-YARN核心技术实践","url":"https:\/\/api.douban.com\/v2\/book\/30527074","alt_title":"","author_intro":"","summary":"","price":"47.80"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30538788\/","id":"30538788","publisher":"","isbn10":"7302514275","isbn13":"9787302514275","title":"大数据与人工智能技术丛书：Hadoop+Spark大数据技术（微课版）","url":"https:\/\/api.douban.com\/v2\/book\/30538788","alt_title":"","author_intro":"","summary":"","price":"67.30"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"大数据","title":"大数据"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30509809\/","id":"30509809","publisher":"","isbn10":"7302517533","isbn13":"9787302517535","title":"Cloudera Hadoop大数据平台实战指南","url":"https:\/\/api.douban.com\/v2\/book\/30509809","alt_title":"","author_intro":"","summary":"","price":"46.60"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30540044\/","id":"30540044","publisher":"","isbn10":"7509642256","isbn13":"9787509642252","title":"大数据：财务分析R与Hadoop实训","url":"https:\/\/api.douban.com\/v2\/book\/30540044","alt_title":"","author_intro":"","summary":"","price":"36.00"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30634056\/","id":"30634056","publisher":"","isbn10":"9863792993","isbn13":"9789863792994","title":"学Hadoop永远都不迟：从MapReduce到YARN的演化","url":"https:\/\/api.douban.com\/v2\/book\/30634056","alt_title":"","author_intro":"","summary":"","price":"102.70元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30637841\/","id":"30637841","publisher":"","isbn10":"7040491001","isbn13":"9787040491005","title":"Hadoop大数据平台构建与应用\/云计算技术与应用专业校企合作系列教材","url":"https:\/\/api.douban.com\/v2\/book\/30637841","alt_title":"","author_intro":"","summary":"","price":"24.60元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30645780\/","id":"30645780","publisher":"","isbn10":"7115370664","isbn13":"9787115370662","title":"Hadoop%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%BC%80%E5%8F%91%E5%9F%BA%E7%A1%80","url":"https:\/\/api.douban.com\/v2\/book\/30645780","alt_title":"","author_intro":"","summary":"","price":"31.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30603396\/","id":"30603396","publisher":"","isbn10":"7115477647","isbn13":"9787115477644","title":"基于Hadoop与Spark的大数据开发实战","url":"https:\/\/api.douban.com\/v2\/book\/30603396","alt_title":"","author_intro":"","summary":"","price":"52.10元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30718904\/","id":"30718904","publisher":"","isbn10":"7564365668","isbn13":"9787564365660","title":"基于Hadoop的大数据平台构建","url":"https:\/\/api.douban.com\/v2\/book\/30718904","alt_title":"","author_intro":"","summary":"","price":"59.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30708936\/","id":"30708936","publisher":"","isbn10":"7121285649","isbn13":"9787121285646","title":"实战Hadoop 2.0（第二版）――从云计算到大数据","url":"https:\/\/api.douban.com\/v2\/book\/30708936","alt_title":"","author_intro":"","summary":"","price":"63.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30874819\/","id":"30874819","publisher":"","isbn10":"7517069039","isbn13":"9787517069034","title":"Hadoop大数据开发\/普通高等教育新工科人才培养规划教材（大数据专业）","url":"https:\/\/api.douban.com\/v2\/book\/30874819","alt_title":"","author_intro":"","summary":"","price":"27.20元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30721626\/","id":"30721626","publisher":"","isbn10":"7518930137","isbn13":"9787518930135","title":"数据馆员的Hadoop简明手册","url":"https:\/\/api.douban.com\/v2\/book\/30721626","alt_title":"","author_intro":"","summary":"","price":"21.00元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30647829\/","id":"30647829","publisher":"","isbn10":"711549813X","isbn13":"9787115498137","title":"Hadoop应用开发基础","url":"https:\/\/api.douban.com\/v2\/book\/30647829","alt_title":"","author_intro":"","summary":"","price":"39.70元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"CS","title":"CS"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30904246\/","id":"30904246","publisher":"","isbn10":"711160153X","isbn13":"9787111601531","title":"高性能分布式计算系统开发与实现：基于Hadoop、Scalding和Spark","url":"https:\/\/api.douban.com\/v2\/book\/30904246","alt_title":"","author_intro":"","summary":"","series":{"id":"36676","title":"数据科学与工程技术丛书"},"price":"61.20元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30977163\/","id":"30977163","publisher":"","isbn10":"7030566181","isbn13":"9787030566188","title":"Hadoop云技术：从入门到精通","url":"https:\/\/api.douban.com\/v2\/book\/30977163","alt_title":"","author_intro":"","summary":"","price":"47.10元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30975253\/","id":"30975253","publisher":"","isbn10":"9863792926","isbn13":"9789863792925","title":"王者归来：OpenStack云端系统Nova+Swift+Quantum+Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/30975253","alt_title":"","author_intro":"","summary":"","price":"178.50元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/31127174\/","id":"31127174","publisher":"","isbn10":"7115400741","isbn13":"9787115400741","title":"Hadoop大数据处理技术基础与实践","url":"https:\/\/api.douban.com\/v2\/book\/31127174","alt_title":"","author_intro":"","summary":"","price":"32.80元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["(美)本·斯皮维","乔伊·爱彻利维亚"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30817045\/","id":"30817045","publisher":"东南大学出版社","isbn10":"7564168714","isbn13":"9787564168711","title":"Hadoop安全（影印版）","url":"https:\/\/api.douban.com\/v2\/book\/30817045","alt_title":"","author_intro":"","summary":"","price":"78元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30808291\/","id":"30808291","publisher":"","isbn10":"7302411441","isbn13":"9787302411444","title":"实战Hadoop大数据处理","url":"https:\/\/api.douban.com\/v2\/book\/30808291","alt_title":"","author_intro":"","summary":"","price":"28.70元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["(美)萨默尔"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30791864\/","id":"30791864","publisher":"东南大学出版社","isbn10":"7564142588","isbn13":"9787564142582","title":"Hadoop操作手册（影印版）","url":"https:\/\/api.douban.com\/v2\/book\/30791864","alt_title":"","author_intro":"","summary":"","price":"59元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["：(美)Mark Grover\/\/Ted Malaska\/\/Jonathan Seidman\/\/Gwen Shapira"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/30818543\/","id":"30818543","publisher":"东南大学出版社","isbn10":"7564170018","isbn13":"9787564170011","title":"Hadoop应用架构（影印版）","url":"https:\/\/api.douban.com\/v2\/book\/30818543","alt_title":"","author_intro":"","summary":"","price":"89元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["杨力"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"226","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/31689323\/","id":"31689323","publisher":"人民邮电出版社","isbn10":"711550217X","isbn13":"9787115502179","title":"Hadoop大数据开发实战","url":"https:\/\/api.douban.com\/v2\/book\/31689323","alt_title":"","author_intro":"","summary":"","price":"49.8元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["杨治明 许桂秋"],"pubdate":"","tags":[{"count":1,"name":"大数据","title":"大数据"}],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"平装-胶订","translator":[],"catalog":"","pages":"287","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/31691342\/","id":"31691342","publisher":"人民邮电出版社","isbn10":"7115503532","isbn13":"9787115503534","title":"Hadoop大数据技术与应用","url":"https:\/\/api.douban.com\/v2\/book\/31691342","alt_title":"","author_intro":"","summary":"","price":"55元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31598402.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s31598402.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s31598402.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31598402.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32708019\/","id":"32708019","publisher":"","isbn10":"3319134965","isbn13":"9783319134963","title":"Guide to High Performance Distributed Computing: Case Studies with Hadoop, Scalding and Spark","url":"https:\/\/api.douban.com\/v2\/book\/32708019","alt_title":"","author_intro":"","summary":"This timely text\/reference describes the development and implementation of large-scale distributed processing systems using open source tools and technologies. Comprehensive in scope, the book presents state-of-the-art material on building high performance distributed computing systems, providing practical guidance and best practices as well as describing theoretical software frameworks. Features: describes the fundamentals of building scalable software systems for large-scale data processing in the new paradigm of high performance distributed computing; presents an overview of the Hadoop ecosystem, followed by step-by-step instruction on its installation, programming and execution; Reviews the basics of Spark, including resilient distributed datasets, and examines Hadoop streaming and working with Scalding; Provides detailed case studies on approaches to clustering, data classification and regression analysis; Explains the process of creating a working recommender system using Scalding and Spark.","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31654613.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s31654613.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s31654613.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31654613.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32764234\/","id":"32764234","publisher":"","isbn10":"1430265442","isbn13":"9781430265443","title":"Practical Hadoop Security","url":"https:\/\/api.douban.com\/v2\/book\/32764234","alt_title":"","author_intro":"","summary":"Practical Hadoop Security is an excellent resource for administrators planning a production Hadoop deployment who want to secure their Hadoop clusters. A detailed guide to the security options and configuration within Hadoop itself, author Bhushan Lakhe takes you through a comprehensive study of how to implement defined security within a Hadoop cluster in a hands-on way.   You will start with a detailed overview of all the security options available for Hadoop, including popular extensions like Kerberos and OpenSSH, and then delve into a hands-on implementation of user security (with illustrated code samples) with both in-the-box features and with security extensions implemented by leading vendors.   No security system is complete without a monitoring and tracing facility, so Practical Hadoop Security next steps you through audit logging and monitoring technologies for Hadoop, as well as ready to use implementation and configuration examples--again with illustrated code samples.   The book concludes with the most important aspect of Hadoop security – encryption. Both types of encryptions, for data in transit and data at rest, are discussed at length with leading open source projects that integrate directly with Hadoop at no licensing cost.   Practical Hadoop Security:   Explains importance of security, auditing and encryption within a Hadoop installation  Describes how the leading players have incorporated these features within their Hadoop distributions and provided extensions  Demonstrates how to set up and use these features to your benefit and make your Hadoop installation secure without impacting performance or ease of use","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31721514.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s31721514.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s31721514.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31721514.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32831197\/","id":"32831197","publisher":"","isbn10":"1548942596","isbn13":"9781548942595","title":"Hadoop for Busies","url":"https:\/\/api.douban.com\/v2\/book\/32831197","alt_title":"","author_intro":"","summary":"An Apache open source project, Hadoop stores huge amounts of data in safe, reliable storage and runs complex queries over data in an efficient way. It is at the core of a whole host of the most popular Big Data tools. Mastering Hadoop ensures you get the best out of all these tools and better insight from your data. Elton Stoneman’s Hadoop explains how Hadoop works, what goes on in the cluster, demonstrates how to move data in and out of Hadoop, and how to query it efficiently. It also walks through a Java MapReduce example, illustrates how to write the same query in Python and .NET, and discusses the wider Hadoop ecosystem.This updated and expanded second edition of Book provides a user-friendly introduction to the subject, Taking a clear structural framework, it guides the reader through the subject's core elements. A flowing writing style combines with the use of illustrations and diagrams throughout the text to ensure the reader understands even the most complex of concepts. This succinct and enlightening overview is a required reading for all those interested in the subject .We hope you find this book useful in shaping your future career & Business.","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32087479.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32087479.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32087479.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32087479.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33198229\/","id":"33198229","publisher":"","isbn10":"1979454078","isbn13":"9781979454070","title":"Apache Hadoop: A Clear and Concise Reference","url":"https:\/\/api.douban.com\/v2\/book\/33198229","alt_title":"","author_intro":"","summary":"Are improvement team members fully trained on Apache Hadoop? Does our organization need more Apache Hadoop education? Have all basic functions of Apache Hadoop been defined? How does the organization define, manage, and improve its Apache Hadoop processes? What are the usability implications of Apache Hadoop actions?Defining, designing, creating, and implementing a process to solve a business challenge or meet a business objective is the most valuable role… In EVERY company, organization and department.Unless you are talking a one-time, single-use project within a business, there should be a process. Whether that process is managed and implemented by humans, AI, or a combination of the two, it needs to be designed by someone with a complex enough perspective to ask the right questions. Someone capable of asking the right questions and step back and say, 'What are we really trying to accomplish here? And is there a different way to look at it?'For more than twenty years, The Art of Service's Self-Assessments empower people who can do just that - whether their title is marketer, entrepreneur, manager, salesperson, consultant, business process manager, executive assistant, IT Manager, CxO etc... - they are the people who rule the future. They are people who watch the process as it happens, and ask the right questions to make the process work better.This book is for managers, advisors, consultants, specialists, professionals and anyone interested in Apache Hadoop assessment.All the tools you need to an in-depth Apache Hadoop Self-Assessment. Featuring 693 new and updated case-based questions, organized into seven core areas of process design, this Self-Assessment will help you identify areas in which Apache Hadoop improvements can be made.In using the questions you will be better able to: - diagnose Apache Hadoop projects, initiatives, organizations, businesses and processes using accepted diagnostic standards and practices - implement evidence-based best practice strategies aligned with overall goals - integrate recent advances in Apache Hadoop and process design strategies into practice according to best practice guidelinesUsing a Self-Assessment tool known as the Apache Hadoop Scorecard, you will develop a clear picture of which Apache Hadoop areas need attention.Included with your purchase of the book is the Apache Hadoop Self-Assessment downloadable resource, which contains all questions and Self-Assessment areas of this book in a ready to use Excel dashboard, including the self-assessment, graphic insights, and project planning automation - all with examples to get you started with the assessment right away. Access instructions can be found in the book.You are free to use the Self-Assessment contents in your presentations and materials for customers without asking us - we are here to help.","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32038209.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s32038209.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s32038209.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s32038209.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33148290\/","id":"33148290","publisher":"","isbn10":"154894260X","isbn13":"9781548942601","title":"Hadoop for Bizzies","url":"https:\/\/api.douban.com\/v2\/book\/33148290","alt_title":"","author_intro":"","summary":"An Apache open source project, Hadoop stores huge amounts of data in safe, reliable storage and runs complex queries over data in an efficient way. It is at the core of a whole host of the most popular Big Data tools. Mastering Hadoop ensures you get the best out of all these tools and better insight from your data. Elton Stoneman’s Hadoop explains how Hadoop works, what goes on in the cluster, demonstrates how to move data in and out of Hadoop, and how to query it efficiently. It also walks through a Java MapReduce example, illustrates how to write the same query in Python and .NET, and discusses the wider Hadoop ecosystem.This updated and expanded second edition of Book provides a user-friendly introduction to the subject, Taking a clear structural framework, it guides the reader through the subject's core elements. A flowing writing style combines with the use of illustrations and diagrams throughout the text to ensure the reader understands even the most complex of concepts. This succinct and enlightening overview is a required reading for all those interested in the subject .We hope you find this book useful in shaping your future career & Business.","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31876133.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s31876133.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s31876133.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31876133.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32985976\/","id":"32985976","publisher":"","isbn10":"154854874X","isbn13":"9781548548742","title":"Hadoop for Finance Essentials","url":"https:\/\/api.douban.com\/v2\/book\/32985976","alt_title":"","author_intro":"","summary":"Body worries are increasingly affecting younger children. Girls as young as five are worried about the way they look and their size, and a third of boys aged 8-12 are dieting to lose weight.This 16-session curriculum aims to provide children with the information and understanding they need in order to maintain and celebrate a healthy and positive body image. Focusing on building individual strengths and self-esteem, the sessions develop children's sense of identity and the ability to recognise and celebrate each other's strengths and talents. The influence of the media, peer pressure and healthy lifestyles are also covered. This ready-to-use curriculum includes a training session for staff, information about how to deliver the programme, guidelines on creating a whole-school approach, a parent workshop and creative activities with photocopiable worksheets","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31774006.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s31774006.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s31774006.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s31774006.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32883706\/","id":"32883706","publisher":"","isbn10":"3659692077","isbn13":"9783659692079","title":"Data Analysis on Multinode Cluster Using Hadoop","url":"https:\/\/api.douban.com\/v2\/book\/32883706","alt_title":"","author_intro":"","summary":"CLOUD AND HADOOP: THE PERFECT MATCH Hadoop is an open source cloud computing platform of the Apache Foundation that provides a software programming framework called MapReduce and distributed file system, HDFS. Cloud computing is a model for enabling convenient, on-demand network access to a shared pool of configurable computing resources (e.g., networks, servers, storage, applications, and services) that can be rapidly provisioned and released with minimal management effort Hadoop has the capability of processing large amount of unstructured or semi-structured data in a distributed fashion over large number of clusters. Cloud Computing provides the necessary flexibility and elasticity to Hadoop whenever needed on pay per use basis. In this work, Hadoop, an open source framework, is explained and used to analyze traffic files captured by packet sniffing tool in pcap format using a proposed analyzer, HPA (Hadoop Pcap Analyzer","price":""}]}
3	{"count":44,"start":200,"total":244,"books":[{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31875062.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s31875062.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s31875062.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s31875062.jpg"},"alt":"https:\/\/book.douban.com\/subject\/32984899\/","id":"32984899","publisher":"","isbn10":"1783285656","isbn13":"9781783285655","title":"Optimizing Hadoop for MapReduce","url":"https:\/\/api.douban.com\/v2\/book\/32984899","alt_title":"","author_intro":"","summary":"This book is an example-based tutorial that deals with Optimizing Hadoop for MapReduce job performance. If you are a Hadoop administrator, developer, MapReduce user, or beginner, this book is the best choice available if you wish to optimize your clusters and applications. Having prior knowledge of creating MapReduce applications is not necessary, but will help you better understand the concepts and snippets of MapReduce class template code.","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32241244.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32241244.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32241244.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32241244.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33352327\/","id":"33352327","publisher":"","isbn10":"9863797391","isbn13":"9789863797395","title":"科技巨頭:Hadoop+Spark大規模實際運作進行式","url":"https:\/\/api.douban.com\/v2\/book\/33352327","alt_title":"","author_intro":"","summary":"页面: 352, 平装, 佳魁數位-佳魁資訊","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32224495.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32224495.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32224495.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32224495.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33335578\/","id":"33335578","publisher":"","isbn10":"9862769971","isbn13":"9789862769973","title":"Hadoop管理手冊","url":"https:\/\/api.douban.com\/v2\/book\/33335578","alt_title":"","author_intro":"","summary":"如果您曾被要求管理大型而複雜的Hadoop叢集，本書就是您必備的參考書。目前Hadoop已經成為資料中心中，真正能處理巨量資料的工業標準，因此針對系統管理的書籍需求也就逐日增加。本書作者是Cloudera的首席解決方案架構師，他將為您說明將Hadoop用於商業運轉的工作項目，從規劃、安裝到設定，甚至包括如何在上線期間進行維護。這本書並不談論空泛的理論，而是明確地指出，在商業佈署環境中，哪些是可行的方案。．HDFS與MapReduce的巨觀概論：為何存在這類技術、背後的工作原理為何。．佈署Hadoop的前期規劃，從硬體、作業系統挑選，到網路架構需求。．學習Hadoop安裝與設定的細節，包括重要參數的完整列表。．跨群組共享一座叢集時該如何管理資源。．學習如何管理一般叢集運作的各種任務．監控Hadoop叢集─並從現實世界的實例中，學習如何進行故障排解。．使用基本的工具與技術來處理備份工作，以因應災難復原。 目錄：前言chapter 01 緒論 chapter 02 HDFSchapter 03 MapReducechapter 04 規劃一座 Hadoop 叢集chapter 05 安裝與設定chapter 06 身份識別、身份驗證與授權chapter 07 資源管理 chapter 08 叢集維運 chapter 09 故障排解 chapter 10 系統監控 chapter 11 備份與還原appendix 過期的設定參數索引","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32006462.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s32006462.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s32006462.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s32006462.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33116500\/","id":"33116500","publisher":"","isbn10":"3656435596","isbn13":"9783656435594","title":"Hadoop: Technik, Einsatzbereiche, Geschichte","url":"https:\/\/api.douban.com\/v2\/book\/33116500","alt_title":"","author_intro":"","summary":"Facharbeit (Schule) aus dem Jahr 2012 im Fachbereich Informatik - Sonstiges, Note: 99,5%, Sprache: Deutsch, Abstract: Diese Hausarbeit aus meiner Berufsschulzeit thematisiert die Geschichte, die Einsatzbereiche und die Technik von Hadoop. Neben der Entstehung von Hadoop wird auf aktuelle Einsatzbereiche von Hadoop eingegangen (Stand September 2012) und die Technik, also der Grundgedanken, der sich hinter Hadoop befindet näher betrachtet. Die Entwicklung von Computersystemen war und ist stets eng mit den Datenmengen verbunden, die auf diesen gespeichert und ausgewertet werden können. Eine anhaltend steigende Speicherkapazität dieser Systeme sorgt dafür, dass einerseits mehr Daten gespeichert werden müssen und somit auch die Kosten für eben diese steigen. Andererseits entstehen so auch deutlich mehr Daten, die ausgewertet werden können. Gerade diese Daten bilden eine Grundlage für heutige analytische Prozesse, wie sie untere anderem in den Bereichen Marketing und Werbung benötigt werden. Dieses sogenannte Data Mining [1], bei dem aus einer riesigen Menge von Daten, die entscheidenden Daten herausgefiltert werden, stellt für die moderne Wirtschaft einen überaus wichtigen Faktor bei der täglichen Arbeit dar. Die weltweit agierenden Unternehmen der IT-Branche Google, Amazon oder IBM sind stellvertretend als die Firmen zu nennen, die auf diesen großen Daten ihren Erfolg begründen. Im Allgemeinen werden diese großen Datenmengen, aus denen sich die wichtigen Informationen extrahieren lassen, mit dem Begriff Big Data [2] zusammengefasst. Mit wachsender Größe von eben dieser Big Data wird es umso aufwendiger und ebenso kostspieliger diese Daten einerseits bereit zu stellen, aber was noch viel wichtiger ist, diese Daten zu durchsuchen. Mit immer größeren Datenmengen steigen auch die Laufzeiten für Programme, die eben diese Daten nach den gesuchten Informationen durchsuchen. Inspiriert von diesem Zustand hat Doug Cutting seine Idee umgesetzt, statt einem leistungsstarken Re","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32197024.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32197024.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32197024.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32197024.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33308089\/","id":"33308089","publisher":"","isbn10":"9862016736","isbn13":"9789862016732","title":"掌握Hadoop翱翔雲端：Windoop應用實作指南(附光碟)","url":"https:\/\/api.douban.com\/v2\/book\/33308089","alt_title":"","author_intro":"","summary":"《掌握Hadoop翱翔雲端:Windoop應用實作指南(附光碟)》 資訊技術的突飛猛進和大量的e化系統不斷地導入民間企業與國營事業,龐大的推力使資訊系統如雨後春筍般的不斷冒出,重複循環下便有二大課題產生:第一,如何有效運用分散於各地的電腦資源;第二,如何有效整合分散於各地的儲存資料。 Hadoop(哈度婆),這頭巨象,如同自己的體積般擁有龐大的運算能力,可協助我們打倒資訊界的令人頭痛難解的毒蛇猛獸,並如天使般引領我們漫步於雲端(Cloud)世界,透過牠除了可以解決當前電腦運算能力的瓶頸外,亦能解決資料儲存空間不足或資料無法有效整合的難題。 本書特色 (1) 精要論述新一代分散式運算技術Hadoop的應用藍圖與實務,引領您進入雲端運算新世界。 (2) 自製快速運行Windoop環境程式包,讓您不用辛苦安裝與設定Hadoop環境立即體驗開發MapReduce分散式應用程式。 (3) 市面上第一本完整教授架設Hadoop執行環境與包含完整程式原始碼,讓您感受巨量運算的驚人魅力。 (4) 最經典的生活化程式範例,讓您了解Hadoop如何在總統大選計票功能上發揮極致效能。 (5) 掌握未來技術的先驅,提升您的個人價值,讓您成為職場上的箇中翹楚。 光碟內容 *可執行分散式應用程式完整範例檔 *獨創Windoop環境程式包","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33298217.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33298217.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33298217.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33298217.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34432177\/","id":"34432177","publisher":"","isbn10":"7121365391","isbn13":"9787121365393","title":"Hadoop构建数据仓库与实战分析","url":"https:\/\/api.douban.com\/v2\/book\/34432177","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33418474\/","id":"33418474","publisher":"","isbn10":"7564755709","isbn13":"9787564755706","title":"大数据时代Hadoop技术及应用分析","url":"https:\/\/api.douban.com\/v2\/book\/33418474","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33384499\/","id":"33384499","publisher":"","isbn10":"711162016X","isbn13":"9787111620167","title":"Hadoop大数据技术基础及应用","url":"https:\/\/api.douban.com\/v2\/book\/33384499","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32313604.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s32313604.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s32313604.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s32313604.jpg"},"alt":"https:\/\/book.douban.com\/subject\/33438310\/","id":"33438310","publisher":"","isbn10":"7302524408","isbn13":"9787302524403","title":"Hadoop大数据技术原理与应用","url":"https:\/\/api.douban.com\/v2\/book\/33438310","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/33463601\/","id":"33463601","publisher":"","isbn10":"730252789X","isbn13":"9787302527893","title":"Hadoop大数据分析实战","url":"https:\/\/api.douban.com\/v2\/book\/33463601","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33453077.jpg","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33453077.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33453077.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33453077.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34788902\/","id":"34788902","publisher":"","isbn10":"7113259197","isbn13":"9787113259198","title":"高等学校大数据技术与应用规划教材：Hadoop大数据分析","url":"https:\/\/api.douban.com\/v2\/book\/34788902","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["张鑫"],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33438938.jpg","binding":"平装","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s33438938.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s33438938.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s33438938.jpg"},"alt":"https:\/\/book.douban.com\/subject\/34658292\/","id":"34658292","publisher":"中国铁道出版社","isbn10":"7113186246","isbn13":"9787113186241","title":"深入云计算：Hadoop源代码分析（修订版）（全新修订，重装上市；细致讲解融入经典实例，打造云计算操作系统源码分析经典图书。完善代码，轻松下载）","url":"https:\/\/api.douban.com\/v2\/book\/34658292","alt_title":"","author_intro":"","summary":"","price":"89元"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34855227\/","id":"34855227","publisher":"","isbn10":"7302534020","isbn13":"9787302534020","title":"Hadoop大数据技术开发实战","url":"https:\/\/api.douban.com\/v2\/book\/34855227","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34844455\/","id":"34844455","publisher":"","isbn10":"7121370336","isbn13":"9787121370335","title":"Hadoop大数据实战权威指南（第2版）","url":"https:\/\/api.douban.com\/v2\/book\/34844455","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34840822\/","id":"34840822","publisher":"","isbn10":"7561864760","isbn13":"9787561864760","title":"Hadoop生态体系项目实战","url":"https:\/\/api.douban.com\/v2\/book\/34840822","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"","tags":[],"origin_title":"","image":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","binding":"","translator":[],"catalog":"","pages":"","images":{"small":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","large":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif","medium":"https://img1.doubanio.com\/f\/shire\/5522dd1f5b742d1e1394a17f44d590646b63871d\/pics\/book-default-lpic.gif"},"alt":"https:\/\/book.douban.com\/subject\/34837848\/","id":"34837848","publisher":"","isbn10":"7115494177","isbn13":"9787115494177","title":"Hadoop大数据平台集群部署与开发\/华晟经世ICT专业群系列教材","url":"https:\/\/api.douban.com\/v2\/book\/34837848","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":78,"average":"8.5","min":0},"subtitle":"The Definitive Guide","author":["Lars George"],"pubdate":"2011-9-20","tags":[{"count":118,"name":"Hbase","title":"Hbase"},{"count":64,"name":"分布式","title":"分布式"},{"count":51,"name":"hadoop","title":"hadoop"},{"count":35,"name":"数据库","title":"数据库"},{"count":27,"name":"nosql","title":"nosql"},{"count":23,"name":"云计算","title":"云计算"},{"count":23,"name":"O'Reilly","title":"O'Reilly"},{"count":10,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6973656.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"554","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s6973656.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s6973656.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s6973656.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6049009\/","id":"6049009","publisher":"O'Reilly Media","isbn10":"1449396100","isbn13":"9781449396107","title":"HBase","url":"https:\/\/api.douban.com\/v2\/book\/6049009","alt_title":"","author_intro":"Lars George has been involved with HBase since 2007, and became a full HBase committer in 2009. He has spoken at various Hadoop User Group meetings, as well as large conferences such as FOSDEM in Brussels. He also started the Munich OpenHUG meetings. He now works closely with Cloudera to support Hadoop and HBase in and around Europe through technical support, consulting work, and training.","summary":"If your organization is looking for a storage solution to accommodate a virtually endless amount of data, this book will show you how Apache HBase can fulfill your needs. As the open source implementation of Google's BigTable architecture, HBase scales to billions of rows and millions of columns, while ensuring that write and read performance remain constant. HBase: The Definitive Guide provides the details you require, whether you simply want to evaluate this high-performance, non-relational database, or put it into practice right away. HBase's adoption rate is beginning to climb, and several IT executives are asking pointed questions about this high-capacity database. This is the only book available to give you meaningful answers. * Learn how to distribute large datasets across an inexpensive cluster of commodity servers * Develop HBase clients in many programming languages, including Java, Python, and Ruby * Get details on HBase's primary storage system, HDFS-Hadoop's distributed and replicated filesystem * Learn how HBase's native interface to Hadoop's MapReduce framework enables easy development and execution of batch jobs that can scan entire tables * Discover the integration between HBase and other facets of the Apache Hadoop project","price":"USD 39.99"},{"rating":{"max":10,"numRaters":89,"average":"8.1","min":0},"subtitle":"","author":["Sean Owen","Robin Anil","Ted Dunning","Ellen Friedman"],"pubdate":"2010-11-28","tags":[{"count":168,"name":"机器学习","title":"机器学习"},{"count":136,"name":"数据挖掘","title":"数据挖掘"},{"count":112,"name":"推荐系统","title":"推荐系统"},{"count":101,"name":"mahout","title":"mahout"},{"count":59,"name":"hadoop","title":"hadoop"},{"count":36,"name":"算法","title":"算法"},{"count":28,"name":"分布式","title":"分布式"},{"count":24,"name":"集体智慧","title":"集体智慧"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4462933.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"375","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s4462933.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s4462933.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s4462933.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4893547\/","id":"4893547","publisher":"Manning Publications","isbn10":"1935182684","isbn13":"9781935182689","title":"Mahout in Action","url":"https:\/\/api.douban.com\/v2\/book\/4893547","alt_title":"","author_intro":"","summary":"When computers harness prior experience to improve future performance, a type of artificial intelligence called machine learning has been applied. The Apache Mahout project is focused on three types of machine learning that are of particular interest to modern web developers \"recommendation systems, classification, and clustering. \n\n   Through real-world examples,  Mahout in Action  introduces the sorts of problems that these techniques are appropriate for, and then illustrates how Mahout can be applied to solve them. It places particular focus on issues of scalability, and how to apply these techniques at very large scale with the Apache Hadoop framework.","price":"USD 44.99"},{"rating":{"max":10,"numRaters":54,"average":"8.8","min":0},"subtitle":"Synthesis Lectures on Human Language Technologies","author":["Jimmy Lin","Chris Dyer"],"pubdate":"2010-4-30","tags":[{"count":70,"name":"mapreduce","title":"mapreduce"},{"count":53,"name":"数据挖掘","title":"数据挖掘"},{"count":46,"name":"hadoop","title":"hadoop"},{"count":34,"name":"分布式","title":"分布式"},{"count":31,"name":"机器学习","title":"机器学习"},{"count":24,"name":"map-reduce","title":"map-reduce"},{"count":19,"name":"算法","title":"算法"},{"count":18,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s4385798.jpg","binding":"Paperback","translator":[],"catalog":"1.Introduction\n2.MapReduce Basics\n3.MapReduce Algorithm Design\n4. Inverted Indexing for Text Retrieval\n5.Graph Algorithms\n6.EM Algorithms for Text Processing\n7.Closing Remarks","pages":"178","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s4385798.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s4385798.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s4385798.jpg"},"alt":"https:\/\/book.douban.com\/subject\/4879588\/","id":"4879588","publisher":"Morgan and Claypool Publishers","isbn10":"1608453421","isbn13":"9781608453429","title":"Data-intensive Text Processing With Mapreduce","url":"https:\/\/api.douban.com\/v2\/book\/4879588","alt_title":"","author_intro":"","summary":"Our world is being revolutionized by data-driven methods: access to large amounts of data has generated new insights and opened exciting new opportunities in commerce, science, and computing applications. Processing the enormous quantities of data necessary for these advances requires large clusters, making distributed computing paradigms more crucial than ever. MapReduce is a programming model for expressing distributed computations on massive datasets and an execution framework for large-scale data processing on clusters of commodity servers. The programming model provides an easy-to-understand abstraction for designing scalable algorithms, while the execution framework transparently handles many system-level details, ranging from scheduling to synchronization to fault tolerance. This book focuses on MapReduce algorithm design, with an emphasis on text processing algorithms common in natural language processing, information retrieval, and machine learning. We introduce the notion of MapReduce design patterns, which represent general reusable solutions to commonly occurring problems across a variety of problem domains. This book not only intends to help the reader \"think in MapReduce\", but also discusses limitations of the programming model as well.","price":"USD 40.00"},{"rating":{"max":10,"numRaters":60,"average":"8.2","min":0},"subtitle":"","author":["Edward Capriolo","Dean Wampler","Jason Rutherglen"],"pubdate":"2012-10-3","tags":[{"count":42,"name":"hive","title":"hive"},{"count":35,"name":"hadoop","title":"hadoop"},{"count":26,"name":"大数据","title":"大数据"},{"count":15,"name":"Programming","title":"Programming"},{"count":14,"name":"Hive","title":"Hive"},{"count":12,"name":"O'Reilly","title":"O'Reilly"},{"count":7,"name":"编程","title":"编程"},{"count":6,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27116075.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"352","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27116075.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27116075.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27116075.jpg"},"alt":"https:\/\/book.douban.com\/subject\/11229710\/","id":"11229710","publisher":"O'Reilly Media","isbn10":"1449319335","isbn13":"9781449319335","title":"Programming Hive","url":"https:\/\/api.douban.com\/v2\/book\/11229710","alt_title":"","author_intro":"","summary":"Hive makes life much easier for developers who work with stored and managed data in Hadoop clusters, such as data warehouses. With this example-driven guide, you'll learn how to use the Hive infrastructure to provide data summarization, query, and analysis - particularly with HiveQL, the query language dialect of SQL. You'll learn how to set up Hive in your environment and optimize its use, and how it interoperates with other tools, such as HBase. You'll also learn how to extend Hive with custom code written in Java or scripting languages. Ideal for developers with prior SQL experience, this book shows you how Hive simplifies many tasks that would be much harder to implement in the lower-level MapReduce API provided by Hadoop.","price":"USD 34.99"},{"rating":{"max":10,"numRaters":58,"average":"4.8","min":0},"subtitle":"","author":["彭渊"],"pubdate":"2014-3","tags":[{"count":77,"name":"分布式","title":"分布式"},{"count":41,"name":"架构","title":"架构"},{"count":20,"name":"系统架构","title":"系统架构"},{"count":20,"name":"大规模","title":"大规模"},{"count":15,"name":"hadoop","title":"hadoop"},{"count":13,"name":"计算机","title":"计算机"},{"count":4,"name":"软件开发","title":"软件开发"},{"count":4,"name":"软件工程","title":"软件工程"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27235063.jpg","binding":"平装","translator":[],"catalog":"前　言\n第1章概述\t1\n1.1分布式计算、并行计算、云计算概述\t1\n1.2分布式产品Hadoop、ZooKeeper、HBase概述\t6\n1.3Fourinone的产生背景\t12\n第2章分布式并行计算的原理与实践\t14\n2.1分布式并行计算模式\t14\n2.1.1最初想到的master-slave结构\t14\n2.1.2“包工头-职介所-手工仓库-工人”模式\t15\n2.1.3基于消息中枢的计算模式\t17\n2.1.4基于网状直接交互的计算模式\t18\n2.1.5并行结合串行模式\t22\n2.1.6包工头内部批量多阶段处理模式\t23\n2.1.7计算集群模式和兼容遗留计算系统\t24\n2.1.8工人计算的服务化模式\t26\n2.2跟Hadoop的区别\t28\n2.3关于分布式的一些概念与产品\t30\n2.4配置文件和核心API介绍\t35\n2.5实践与应用\t36\n2.5.1一个简单的示例\t36\n2.5.2工头工人计算模式更完整的示例\t39\n2.5.3工人合并互相say hello的示例\t44\n2.5.4 实现Hadoop经典实例Word Count\t48\n2.5.5分布式多机部署的示例\t52\n2.5.6分布式计算自动部署的示例\t53\n2.5.7计算过程中的故障和容灾处理\t57\n2.5.8计算过程中的相关时间属性设置\t60\n2.5.9如何在一台计算机上一次性启动多个进程\t63\n2.5.10如何调用C\/C++程序实现\t68\n2.5.11如何中止工人计算和超时中止\t68\n2.5.12使用并行计算大幅提升递归算法效率\t73\n2.5.13使用并行计算求圆周率π\t81\n2.5.14从赌钱游戏看PageRank算法\t86\n2.5.15使用并行计算实现上亿排序\t96\n2.5.16工人服务化模式应用示例\t104\n2.6实时流计算\t107\n第3章分布式协调的实现\t111\n3.1协调架构原理简介\t111\n3.2核心API\t113\n3.3权限机制\t115\n3.4相对于ZooKeeper的区别\t116\n3.5与Paxos算法的区别\t117\n3.6实践与应用\t119\n3.6.1如何实现公共配置管理\t119\n3.6.2如何实现分布式锁\t126\n3.6.3如何实现集群管理\t129\n3.6.4多节点权限操作示例\t134\n3.6.5领导者选举相关属性设置\t137\n第4章分布式缓存的实现\t139\n4.1小型网站或企业应用的缓存实现架构\t139\n4.2大型分布式缓存系统实现过程\t140\n4.3一致性哈希算法的原理、改进和实现\t147\n4.4解决任意扩容的问题\t152\n4.5解决扩容后数据均匀的问题\t153\n4.6分布式Session的架构设计和实现\t154\n4.7缓存容量的相关属性设置\t156\n4.8缓存清空的相关属性设置\t158\n第5章消息队列的实现\t162\n5.1闲话中间件与MQ\t162\n5.2JMS的两种经典模式\t163\n5.3如何实现发送接收的队列模式\t164\n5.4如何实现主题订阅模式\t168\n第6章分布式文件系统的实现\t173\n6.1FTTP架构原理解析 \t174\n6.2搭建配置FttpAdapter环境\t177\n6.3访问集群文件根目录\t179\n6.4访问和操作远程文件\t181\n6.5集群内文件复制和并行复制\t184\n6.6读写远程文件\t187\n6.7解析远程文件\t189\n6.8并行读写远程文件\t191\n6.9批量并行读写远程文件和事务补偿处理\t194\n6.10如何进行整型读写\t198\n6.11基于整型读写的上亿排序\t205\n第7章分布式作业调度平台的实现\t219\n7.1调度平台的设计与实现\t219\n7.2资源隔离的实现\t224\n7.3资源调度算法\t226\n7.4其他作业调度平台简介\t227\n7.4.1其他MPI作业资源调度技术\t227\n7.4.2Mesos和Yarn简介\t229","ebook_url":"https:\/\/read.douban.com\/ebook\/10258930\/","pages":"231","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27235063.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27235063.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27235063.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25843316\/","id":"25843316","publisher":"机械工业出版社","isbn10":"7111455037","isbn13":"9787111455035","title":"大规模分布式系统架构与设计实战（含光盘）","url":"https:\/\/api.douban.com\/v2\/book\/25843316","alt_title":"","author_intro":"彭渊　资深架构师，现任华为企业中间件首席架构师，主要负责中间件和大数据。前淘宝高级专家（花名：千峰），先后在淘宝交易、淘宝中间件、集团核心系统、阿里金融等部门工作。曾任金蝶总体架构部SOA架构师，负责设计ESB。曾艰苦创业，编写和销售财务软件。在Java技术领域从业十多年，撰写过多款开源软件，其中，淘宝分布式技术框架Fourinone为其代表作。他拥有软件著作权的代表作有：BS系列软件（包括财务进销存、OA产品、CRM等）、FMS视频会议、Flash网站生成软件（华军可下载），所有软件作品均贡献99%代码。","summary":"【编辑推荐】\n\t绝技源于江湖、将军发于卒伍，本书包含作者从程序员到首席架构师十多年职业生涯所积累的实战经验。\n\t这不是一本讲怎么使用Hadoop的书，而是一本讲实现Hadoop功能的书，本书系统讲解构建大规模分布式系统的核心技术和实现方法，包含开源的代码，手把手教你掌握分布式技术\n【内容简介】\n本书从作者的实战经验出发，深入浅出地讲解了如何建立一个Hadoop那样的分布式系统，实现对多台计算机CPU、内存、硬盘的统一利用，从而获取强大计算能力去解决复杂问题。一般互联网企业的分布式存储计算系统都是个大平台，系统复杂、代码庞大，而且只适合公司的业务，工程师很难下载安装到自己的电脑里学习和吃透。本书对分布式核心技术进行了大量归纳和总结，并从中抽取出一套简化的框架和编程API进行讲解，方便工程师了解分布式系统的主要技术实现。这不是一本空谈概念、四处摘抄的书，这本书包含了大量精炼示例，手把手教你掌握分布式核心技术。\n本书主要内容\n\t分布式并行计算的基本原理解剖；\n\t分布式协调的实现，包括如何实现公共配置管理，如何实现分布式锁，如何实现集群管理等；\n\t分布式缓存的实现，包括如何提供完整的分布式缓存来利用多机内存能力；\n\t消息队列的实现，包括如何实现发送和接收模式；\n\t分布式文件系统的实现，包括如何像操作本地文件一样操作远程文件，并利用多机硬盘存储能力；\n\t分布式作业调度平台的实现，包括资源隔离、资源调度等。\n【参考阅读】\n978-7-111-43052-0  大规模分布式存储系统:原理解析与架构实战\n978-7-111-40392-0  分布式系统：概念与设计（原书第5版）\n978-7-111-45244-7 Hadoop应用开发技术详解\n978-7-111-41766-8  Hadoop技术内幕：深入解析Hadoop Common和HDFS架构设计与实现原理\n978-7-111-42226-6 Hadoop技术内幕：深入解析MapReduce架构设计与实现原理\n978-7-111-44534-0  Hadoop技术内幕：深入解析YARN架构设计与实现原理\n978-7-111-43514-3 网站数据分析：数据驱动的网站管理、优化和运营\n978-7-111-42591-5 数据挖掘：实用案例分析","ebook_price":"25.00","series":{"id":"19432","title":"大数据技术丛书"},"price":"59.00"},{"rating":{"max":10,"numRaters":71,"average":"7.8","min":0},"subtitle":"从业务需求到技术方案","author":["黄申"],"pubdate":"2016-5-1","tags":[{"count":140,"name":"大数据","title":"大数据"},{"count":45,"name":"架构","title":"架构"},{"count":33,"name":"数据分析","title":"数据分析"},{"count":30,"name":"商业","title":"商业"},{"count":28,"name":"系统架构","title":"系统架构"},{"count":24,"name":"业务需求","title":"业务需求"},{"count":22,"name":"商业智能","title":"商业智能"},{"count":16,"name":"人工智能","title":"人工智能"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29779643.jpg","binding":"平装","translator":[],"catalog":"推荐序一\n推荐序二\n前　　言\n第1章　抉择 1\n第2章　数据收集 4\n2.1　互联网数据收集 4\n2.1.1　网络爬虫 5\n2.1.2　Apache Nutch简介 11\n2.1.3　Heritrix简介 14\n2.2　内部数据收集 15\n2.2.1　Apache Flume简介 17\n2.2.2　Facebook Scribe和Logstash 21\n2.3　本章心得 21\n2.4　参考资料 22\n第3章　数据存储 23\n3.1　持久化存储 23\n3.1.1　Hadoop和HDFS 25\n3.1.2　HBase简介 28\n3.1.3　MongoDB 35\n3.2　非持久化存储 37\n3.2.1　缓存和散列 37\n3.2.2　Memcached和Berkeley DB简介 41\n3.2.3　Redis简介 41\n3.3　本章心得 44\n3.4　参考资料 44\n第4章　数据处理 46\n4.1　离线批量处理 46\n4.1.1　Hadoop的MapReduce 47\n4.1.2　Spark简介 52\n4.1.3　Hive简介 53\n4.1.4　Pig、Impala和Spark SQL 56\n4.2　提升及时性：消息机制 58\n4.2.1　ActiveMQ简介 60\n4.2.2　Kafka简介 61\n4.3　在线实时处理 63\n4.3.1　Storm简介 63\n4.3.2　Spark Streaming简介 66\n4.4　本章心得 66\n4.5　参考资料 67\n第5章　信息检索 69\n5.1　基本理念 70\n5.2　相关性 70\n5.2.1　布尔模型 70\n5.2.2　基于排序的布尔模型 71\n5.2.3　向量空间模型 74\n5.2.4　语言模型 75\n5.3　及时性 77\n5.4　与数据库查询的对比 81\n5.5　搜索引擎 82\n5.5.1　Web搜索中的链接分析 83\n5.5.2　电子商务中的商品排序 86\n5.5.3　多因素和基于学习的排序 88\n5.5.4　系统框架 89\n5.5.5　Lucene简介 93\n5.5.6　Solr简介 98\n5.5.7　Elasticsearch简介 104\n5.6　推荐系统 108\n5.6.1　推荐的核心要素 109\n5.6.2　推荐系统的分类 110\n5.6.3　混合模型 115\n5.6.4　系统架构 116\n5.6.5　Mahout 116\n5.7　在线广告 119\n5.8　本章心得 127\n5.9　参考资料 128\n第6章　数据挖掘 130\n6.1　基本理念 131\n6.2　数据的表示和预处理 133\n6.3　机器学习算法 136\n6.4　挖掘工具 157\n6.5　本章心得 165\n6.6　参考资料 165\n第7章　效能评估 167\n7.1　效果评估 168\n7.2　性能评估 190\n7.3　本章心得 202\n7.4　参考资料 202\n第8章　大数据技术全景 204\n第9章　商品太多啦！需要搜索引擎 207\n9.1　业务需求 207\n9.2　产品设计和技术选型 208\n9.3　实现方案 211\n第10章　能否更主动？还需要推荐引擎 223\n10.1　业务需求 223\n10.2　产品设计和技术选型 225\n10.3　实现方案 230\n第11章　这样做的效果如何 241\n11.1　业务需求 241\n11.2　产品设计和技术选型 242\n11.3　实现方案 243\n第12章　这个搜索有点逊 258\n12.1　业务需求：还要搜得更多 258\n12.2　“还要搜得更多”：产品设计和技术选型 259\n12.3　“还要搜得更多”的方案实现 261\n12.4　业务需求：还要搜得更准 265\n12.5　“还要搜得更准”：产品设计和技术选型 266\n12.6　“还要搜得更准”的方案实现 271\n12.7　业务需求：还要更快 273\n12.8　还要“变”得更快：产品设计和技术选型 274\n12.9　还要“搜”得更快：产品设计和技术选型 275\n12.10　业务需求：给点提示吧 280\n12.11　给点提示吧：产品设计和技术选型 282\n第13章　支持更高效的运营 287\n13.1　业务需求：互联网时代的CRM 287\n13.2　互联网时代的CRM：产品设计和技术选型 288\n13.3　业务需求：抓住捣蛋鬼 291\n13.4　抓住捣蛋鬼：产品设计和技术选型 292\n13.5　业务需求：销售之战 295\n13.6　销售之战：产品设计和技术选型 296\n后记 299","pages":"298","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29779643.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29779643.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29779643.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26818024\/","id":"26818024","publisher":"机械工业出版社","isbn10":"7111535286","isbn13":"9787111535287","title":"大数据架构商业之路","url":"https:\/\/api.douban.com\/v2\/book\/26818024","alt_title":"","author_intro":"黄申，博士，毕业于上海交通大学计算机科学与工程专业，师从俞勇教授。微软学者，IBMExtremeBlue天才计划成员。长期专注于大数据相关的搜索、推荐、广告以及用户精准化领域。曾在微软亚洲研究院、eBay中国、沃尔玛1号店和大润发飞牛网担任要职，带队完成了若干公司级的战略项目。同时著有20多篇国际论文和10多项国际专利，兼任《计算机工程》期刊特邀审稿专家。因其对业界的卓越贡献，2015年获得美国政府颁发的“美国杰出人才”称号。","summary":"目前大数据技术已经日趋成熟，但是业界发现与大数据相关的产品设计和研发仍然非常困难，技术、产品和商业的结合度还远远不够。这主要是因为大数据涉及范围广、技术含量高、更新换代快，门槛也比其他大多数IT行业更高。人们要么使用昂贵的商业解决方案，要么花费巨大的精力摸索。本书通过一个虚拟的互联网O2O创业故事，来逐步展开介绍创业各个阶段可能遇到的大数据课题、业务需求，以及相对应的技术方案，甚至是实践解析；让读者身临其境，一起来探寻大数据的奥秘。书中会覆盖较广泛的技术点，并提供相应的背景知识介绍，对于想进一步深入研究细节的读者，也可轻松获得继续阅读的方向和指导性建议。","series":{"id":"19432","title":"大数据技术丛书"},"price":"69.00元"},{"rating":{"max":10,"numRaters":15,"average":"8.6","min":0},"subtitle":"","author":["[美]Donald Miner","[美]Adam Shook"],"pubdate":"2014-9-1","tags":[{"count":20,"name":"大数据","title":"大数据"},{"count":16,"name":"hadoop","title":"hadoop"},{"count":13,"name":"mapreduce","title":"mapreduce"},{"count":8,"name":"MapReduce","title":"MapReduce"},{"count":5,"name":"计算机","title":"计算机"},{"count":2,"name":"设计模式","title":"设计模式"},{"count":2,"name":"互联网","title":"互联网"},{"count":2,"name":"Hadoop","title":"Hadoop"}],"origin_title":"MapReduce Design Patterns","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27676871.jpg","binding":"平装","translator":["徐钊","赵重庆"],"catalog":"第1章　设计模式与MapReduce　1\n1．1　设计模式　2\n1．2　MapReduce简史　3\n1．3　MapReduce和Hadoop简介　4\n1．4　Hadoop示例：单词计数　6\n1．5　Pig和Hive　10\n第2章　概要模式　12\n2．1　数值概要　12\n2．1．1　模式描述　12\n2．1．2　数值概要示例　16\n2．2　倒排索引概要　30\n2．2．1　模式描述　30\n2．2．2　倒排索引示例　32\n2．3　计数器计数　34\n2．3．1　模式描述　34\n2．3．2　计数器计数示例　36\n第3章　过滤模式　39\n3．1　过滤　40\n3．1．1　模式描述　40\n3．1．2　过滤示例　43\n3．2　布隆过滤　45\n3．2．1　模式描述　45\n3．2．2　布隆过滤器示例　48\n3．3　Top 10　53\n3．3．1　模式描述　53\n3．3．2　Top 10示例　58\n3．4　去重　60\n3．4．1　模式描述　60\n3．4．2　去重示例　63\n第4章　数据组织模式　65\n4．1　分层结构　65\n4．1．1　模式描述　65\n4．1．2　分层结构示例　69\n4．2　分区　76\n4．2．1　模式描述　76\n4．2．2　分区示例　79\n4．3　分箱　81\n4．3．1　模式描述　81\n4．3．2　分箱示例　83\n4．4　全排序　85\n4．4．1　模式描述　85\n4．4．2　全排序示例　88\n4．5　混排　92\n4．5．1　模式描述　92\n4．5．2　混排示例　93\n第5章　连接模式　96\n5．1　连接简介　97\n5．2　reduce端连接　102\n5．2．1　模式描述　102\n5．2．2　reduce端连接示例　104\n5．2．3　使用布隆过滤器的reduce端连接　110\n5．3　复制连接　112\n5．3．1　模式描述　112\n5．3．2　复制连接示例　114\n5．4　组合连接　116\n5．4．1　模式描述　116\n5．4．2　组合连接示例　119\n5．5　笛卡儿积　121\n5．5．1　模式描述　121\n5．5．2　笛卡儿积示例　124\n第6章　元模式　131\n6．1　作业链　131\n6．1．1　关于驱动程序　132\n6．1．2　作业链示例　133\n6．1．3　关于shell脚本　142\n6．1．4　关于JobControl　145\n6．2　链折叠　149\n6．2．1　ChainMapper方法和ChainReducer方法　153\n6．2．2　链折叠示例　153\n6．3　作业归并　158\n作业归并示例　160\n第7章　输入和输出模式　166\n7．1　在Hadoop中自定义输入和输出　166\n7．1．1　InputFormat　167\n7．1．2　RecordReader　168\n7．1．3　OutputFormat　169\n7．1．4　RecordWriter　170\n7．2　生成数据　170\n7．2．1　模式描述　170\n7．2．2　生成数据示例　172\n7．3　外部源输出　177\n7．3．1　模式描述　177\n7．3．2　外部源输出示例　179\n7．4　外部源输入　183\n7．4．1　模型描述　183\n7．4．2　外部源输入示例　185\n7．5　分区裁剪　190\n7．5．1　模式描述　190\n7．5．2　分区裁剪示例　192\n第8章　最后的思考与设计模式的未来　203\n8．1　数据的本质趋势　203\n8．1．1　图像、音频和视频　203\n8．1．2　流式数据　204\n8．2　YARN的影响　204\n8．3　作为库或者组件的模式　205\n8．4　读者可以帮到什么　205\n附录　布隆过滤器　207","pages":"213","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27676871.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27676871.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27676871.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26184193\/","id":"26184193","publisher":"人民邮电出版社","isbn10":"7115360944","isbn13":"9787115360946","title":"MapReduce设计模式","url":"https:\/\/api.douban.com\/v2\/book\/26184193","alt_title":"MapReduce Design Patterns","author_intro":"Donald Miner目前是EMC Greenplum的解决方案架构师，为实现与使用基于Greenplum的大数据系统的用户提供咨询和帮助。在加入Greenplum之前，Miner博士作为承包商为美国政府部署和构建了多个规模巨大且涉及关键任务的Hadoop集群。他还参与了教学，在马里兰大学巴尔的摩分校（UMBC）讲授Hadoop方面的业界前沿相关的课程以及各种人工智能课程。Miner博士在UMBC获得了计算机科学的博士学位，读博士期间他的研究主题为机器学习，博士论文的主题是多智能体系统。\nAdam Shook是ClearEdge IT Solutions公司的软件工程师，从事一些大数据技术工作，如Hadoop、Accumulo、Pig以及ZooKeeper。Shook在马里兰大学巴尔的摩分校（UMBC）获得了计算机科学的学士学位，并得到了一份为游戏工作室构建一个全新的高性能图像引擎的工作。为了寻求新的挑战，他在UMBC就读研究生，主要专注的研究方向是分布式计算的相关技术。他很快找到了一份开发工作，作为美国政府承包商，从事大规模的Hadoop部署。Shook参与了Hadoop和Pig的开发及培训课程的指导。在繁忙工作的间隙他喜欢参与相关项目，玩视频游戏。","summary":"MapReduce作为一种分布式海量数据处理的编程框架，已经得到业界的广泛关注。随着Hadoop的普及，MapReduce目前已经成为海量数据处理的最基础但也是最重要的方法之一。\n《MapReduce设计模式》是一本关于设计模式的书，为读者提供解决问题的模板或通用指南。书中主要介绍编程模式，即如何利用MapReduce框架解决一类问题，重在提供解决问题的方法和思路。作者花大量篇幅介绍各种模式的原理及实现机制，并给出相应的应用实例，让读者对每种模式能有更直观的理解。\n由于本书不会过多涉及底层框架及MapReduce API，所以希望读者阅读《MapReduce设计模式》之前，能够对Hadoop系统有所了解，知道如何编写MapReduce程序，并了解MapReduce程序框架的工作原理。《MapReduce设计模式》面向中高级MapReduce开发者，涵盖了绝大部分MapReduce编程可能面对的场景，相信初学者和专家同样可以在本书中得到一些启示。","price":"49.00"},{"rating":{"max":10,"numRaters":29,"average":"8.3","min":0},"subtitle":"","author":["Alan Gates"],"pubdate":"2011-10-20","tags":[{"count":39,"name":"Hadoop","title":"Hadoop"},{"count":14,"name":"数据挖掘","title":"数据挖掘"},{"count":14,"name":"Pig","title":"Pig"},{"count":13,"name":"Programming","title":"Programming"},{"count":6,"name":"编程","title":"编程"},{"count":6,"name":"O'Reilly","title":"O'Reilly"},{"count":4,"name":"数据库","title":"数据库"},{"count":3,"name":"计算机","title":"计算机"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s8334246.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"222","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s8334246.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s8334246.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s8334246.jpg"},"alt":"https:\/\/book.douban.com\/subject\/6397441\/","id":"6397441","publisher":"O'Reilly Media","isbn10":"1449302645","isbn13":"9781449302641","title":"Programming Pig","url":"https:\/\/api.douban.com\/v2\/book\/6397441","alt_title":"","author_intro":"","summary":"This guide is an ideal learning tool and reference for Apache Pig, the programming language that helps you describe and run large data projects on Hadoop. With Pig, you can analyze data without having to create a full-fledged application - making it easy for you to experiment with new data sets. Programming Pig shows newcomers how to get started, and teaches intermediate users the benefits of using Pig Latin, the data flow language for building and maintaining pipelines for processing data. Advanced users learn how to build complex data processing pipelines with Pig's macros and modularity features, and discover how to build systems for complex data processing needs by embedding Pig Latin into scripting languages. * Learn the advantages and disadvantages of using Pig instead of MapReduce * Understand how Pig fits in with other Hadoop components, such as HDFS, Hive, MapReduce, and HBase * Follow examples that explain built-in Pig Latin functions, and data operators such as join and group * Use grunt, the shell that Pig provides for exploring and working with HDFS * Get performance tuning tips for running Pig Latin scripts on Hadoop clusters in less time * Extend Pig with powerful user defined functions written in Java or Python","price":"USD 39.99"},{"rating":{"max":10,"numRaters":26,"average":"7.3","min":0},"subtitle":"","author":["Nick Dimiduk","Amandeep Khurana"],"pubdate":"2012-11-14","tags":[{"count":36,"name":"HBase","title":"HBase"},{"count":16,"name":"Hadoop","title":"Hadoop"},{"count":12,"name":"BigData","title":"BigData"},{"count":6,"name":"Map\/Reduce","title":"Map\/Reduce"},{"count":5,"name":"计算机","title":"计算机"},{"count":3,"name":"计算机科学","title":"计算机科学"},{"count":3,"name":"Programming","title":"Programming"},{"count":2,"name":"英文版","title":"英文版"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27120816.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"360","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27120816.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27120816.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27120816.jpg"},"alt":"https:\/\/book.douban.com\/subject\/11554138\/","id":"11554138","publisher":"Manning Publications","isbn10":"1617290521","isbn13":"9781617290527","title":"HBase in Action","url":"https:\/\/api.douban.com\/v2\/book\/11554138","alt_title":"","author_intro":"","summary":"When dealing with big data, traditional databases don't cut it. It's best to use the right tool for the job. HBase is a NoSQL storage system designed from the ground up for fast, random access to large volumes of data. Built on Hadoop, it runs on commodity hardware and scales from modest datasets up to millions of columns and billions of rows. HBase in Action provides all the knowledge needed to design, build, and run applications using HBase. First, it introduces the fundamentals of distributed systems and large scale data handling. Then, it explores real-world applications and code samples with just enough theory to explain practical techniques. It shows readers how to build applications with HBase and take advantage of the MapReduce processing framework as they learn patterns and best practices. ABOUT THE TECHNOLOGY HBase is an open-source, column-oriented database management system written in Java. It runs on top of the Hadoop Distributed File System (HDFS) and is fast enough to directly power websites and integrates tightly with the MapReduce processing framework, a programming model for processing large data sets. HBase has become the data backbone for production deployments worldwide in companies like StumbleUpon, Facebook, and Twitter.","price":"USD 39.99"},{"rating":{"max":10,"numRaters":23,"average":"8.1","min":0},"subtitle":"","author":["盖茨 (Alan Gates)"],"pubdate":"2013-2-1","tags":[{"count":23,"name":"Hadoop","title":"Hadoop"},{"count":12,"name":"大数据","title":"大数据"},{"count":11,"name":"数据挖掘","title":"数据挖掘"},{"count":11,"name":"Pig编程指南","title":"Pig编程指南"},{"count":8,"name":"pig","title":"pig"},{"count":5,"name":"计算机","title":"计算机"},{"count":4,"name":"软件开发","title":"软件开发"},{"count":4,"name":"Programming","title":"Programming"}],"origin_title":"Programming Pig","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27327616.jpg","binding":"平装","translator":["曹坤"],"catalog":"第1章 初识Pig\n1.1 Pig是什么？\n1.1.1 Pig是基于Hadoop的\n1.1.2 Pig Latin，一种并行数据流语言\n1.1.3 Pig的用途\n1.1.4 Pig的设计思想\n1.2 Pig发展简史\n第2章 安装和运行Pig\n2.1 下载和安装Pig\n2.1.1 从Apache下载Pig软件包\n2.1.2 从Cloudera下载Pig\n2.1.3 使用Maven下载Pig\n2.1.4 下载Pig源码\n2.2 运行Pig\n2.2.1 本地单机运行Pig\n2.2.2 在Hadoop集群上运行Pig\n2.2.3 在云服务上运行Pig\n2.2.4 命令行使用以及配置选项介绍\n2.2.5 返回码\n第3章 命令行交互工具Grunt\n3.1 在Grunt中输入Pig Latin脚本\n3.2 在Grunt中使用HDFS命令\n3.3 在Grunt中控制Pig\n第4章 Pig数据模型\n4.1 数据类型\n4.1.1 基本类型\n4.1.2 复杂类型\n4.1.3 NULL值\n4.2 模式\n第5章 Pig Latin介绍\n5.1 基础知识\n5.1.1 大小写敏感\n5.1.2 注释\n5.2 输入和输出\n5.2.1 加载\n5.2.2 存储\n5.2.3 输出\n5.3 关系操作\n5.3.1 foreach\n5.3.2 Filter\n5.3.3 Group\n5.3.4 Order by\n5.3.5 Distinct\n5.3.6 Join\n5.3.7 Limit\n5.3.8 Sample\n5.3.9 Parallel\n5.4 用户自定义函数UDF\n5.4.1 注册UDF\n5.4.2 define命令和UDF\n5.4.3 调用静态Java函数\n第6章 Pig Latin高级应用\n6.1 高级关系操作\n6.1.1 foreach的高级功能\n6.1.2 使用不同的Join实现方法\n6.1.3 cogroup\n6.1.4 union\n6.1.5 cross\n6.2 在Pig中集成遗留代码和MapReduce程序\n6.2.1 stream\n6.2.2 mapreduce\n6.3 非线性数据流\n6.4 执行过程控制\n6.4.1 set\n6.4.2 设置分割器\n6.5 Pig Latin预处理器\n6.5.1 参数传入\n6.5.2 宏\n6.5.3 包含其他的Pig Latin脚本\n第7章 开发和测试Pig Latin脚本\n7.1 开发工具\n7.1.1 语法高亮和语法检查\n7.1.2 describe\n7.1.3 explain\n7.1.4 illustrate\n7.1.5 Pig统计信息\n7.1.6 MapReduce任务运行状态信息\n7.1.7 调试技巧\n7.2 使用PigUnit测试用户的脚本\n第8章 让Pig飞起来\n8.1 编写优质的脚本\n8.1.1 尽早地并经常地进行过滤\n8.1.2 尽早地并经常地进行映射\n8.1.3 正确并合理使用join\n8.1.4 适当的情况下使用multiquery\n8.1.5 选择正确的数据类型\n8.1.6 选择合适的并行值\n8.2 编写优质的UDF\n8.3 调整Pig和Hadoop\n8.4 对计算中间结果进行压缩\n8.5 数据层优化\n8.6 垃圾数据处理\n第9章 在Python中嵌入Pig Latin脚本\n9.1 编译\n9.2 绑定\n9.3 运行\n9.4 工具方法\n第10章 编写评估函数和过滤函数\n10.1 使用Java编写评估函数\n10.1.1 UDF将在哪里执行\n10.1.2 求值函数基本概念\n10.1.3 输入和输出模式\n10.1.4 错误处理和处理过程信息报告\n10.1.5 构造器和将数据从前端传送到后端\n10.1.6 重载UDF\n10.1.7 运算函数的内存问题\n10.2 代数运算接口\n10.3 累加器接口\n10.4 使用Python写UDF\n10.5 书写过滤器函数\n第11章 编写加载函数和存储函数\n11.1 加载函数\n11.1.1 前端执行计划函数\n11.1.2 从前端调用传递信息到后端调用\n11.1.3 后端数据读取\n11.1.4 可扩展的加载函数接口\n11.2 存储函数\n11.2.1 存储函数前端执行计划\n11.2.2 存储函数和UDFContext\n11.2.3 写数据\n11.2.4 任务失败后数据的清理\n11.2.5 存储元数据信息\n第12章 Pig和其他Hadoop社区的成员\n12.1 Pig和Hive\n12.2 Cascading\n12.3 NoSQL数据库\n12.3.1 HBase\n12.3.2 Cassandra\n12.4 Hadoop中的元数据\n附录A 内置的用户自定义函数和Piggybank\n内置UDF\n内置加载函数和存储函数\n内置求值函数和过滤函数\nPiggybank\n附录B Hadoop综述\nMapReduce\nMap阶段\nCombiner阶段\nShuffle阶段\nReduce阶段\n输出阶段\n分布式缓存\n故障处理\nHDFS\n作者介绍\n书末说明","pages":"191","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s27327616.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s27327616.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s27327616.jpg"},"alt":"https:\/\/book.douban.com\/subject\/21357721\/","id":"21357721","publisher":"人民邮电出版社","isbn10":"7115301115","isbn13":"9787115301116","title":"Pig编程指南","url":"https:\/\/api.douban.com\/v2\/book\/21357721","alt_title":"Programming Pig","author_intro":"","summary":"《Pig编程指南》不仅为初学者讲解ApachePig的基础知识，同时也向有一定使用经验的高级用户介绍更加综合全面的Pig重要特性，如PigLatin脚本语言、控制台shell交互命令以及用于对Pig进行拓展的用户自定义函数(UDF)等。当读者有大数据处理需求时，《Pig编程指南》提供了如何更高效地使用Pig来完成需求的方法。\n《Pig编程指南》适合各个层次的Pig用户及开发人员阅读使用。","price":"49.00元"},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"数据集成的技术、方法与最佳实践","author":["April Reeve"],"pubdate":"2014-3-27","tags":[{"count":14,"name":"大数据","title":"大数据"},{"count":6,"name":"数据管理","title":"数据管理"},{"count":5,"name":"技术","title":"技术"},{"count":3,"name":"理论","title":"理论"},{"count":2,"name":"集成","title":"集成"},{"count":1,"name":"法学与经济","title":"法学与经济"},{"count":1,"name":"数据分析","title":"数据分析"},{"count":1,"name":"数据仓库","title":"数据仓库"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27244321.jpg","binding":"","translator":["余水清","潘黎萍"],"catalog":"译者序\n序言\n前言\n第一部分　数据集成导论\n第1章　数据集成的重要性 \/ 2\n1.1　数据接口的天然复杂性 \/ 2\n1.2　购买供应商应用包的数量日益增加 \/ 3\n1.3　大数据和虚拟化的催化剂 \/ 3\n第2章　什么是数据集成 \/ 5\n2.1　运动中的数据 \/ 5\n2.2　集成为通用格式—数据转换 \/ 5\n2.3　数据从一个系统迁移到另一个系统 \/ 6\n2.4　在组织内部移动数据 \/ 6\n2.5　从非结构化数据中抽取信息 \/ 8\n2.6　将处理移动到数据端 \/ 9\n第3章　数据集成的类型和复杂性 \/ 10\n3.1　管理运动中的数据和持久化数据的异同点 \/ 10\n3.2　批处理数据集成 \/ 10\n3.3　实时数据集成 \/ 11\n3.4　大数据集成 \/ 11\n3.5　数据虚拟化 \/ 12\n第4章　数据集成开发过程 \/ 13\n4.1　数据集成开发生命周期 \/ 13\n4.2　包含业务知识和专家经验 \/ 14\n第二部分　批处理数据集成\n第5章　批处理数据集成简介 \/ 18\n5.1　什么是批处理数据集成 \/ 18\n5.2　批处理数据集成生命周期 \/ 19\n第6章　抽取、转换和加载 \/ 20\n6.1　什么是ETL \/ 20\n6.2　概要分析 \/ 20\n6.3　抽取 \/ 21\n6.4　暂存 \/ 22\n6.5　访问层次 \/ 22\n6.6　转换 \/ 23\n6.6.1　简单映射 \/ 23\n6.6.2　查找表 \/ 24\n6.6.3　聚合和规范化 \/ 24\n6.6.4　计算 \/ 24\n6.7　加载 \/ 24\n第7章　数据仓库 \/ 26\n7.1　什么是数据仓库 \/ 26\n7.2　企业数据仓库架构中的层次 \/ 26\n7.2.1　操作型应用层 \/ 26\n7.2.2　外部数据 \/ 27\n7.2.3　数据仓库中的数据暂存区 \/ 27\n7.2.4　数据仓库数据结构 \/ 28\n7.2.5　从数据仓库到数据集市或者商务智能层的暂存 \/ 28\n7.2.6　商务智能层 \/ 28\n7.3　加载到数据仓库中的数据类型 \/ 29\n7.3.1　数据仓库中的主数据 \/ 29\n7.3.2　数据仓库中的余额和快照数据 \/ 30\n7.3.3　数据仓库中的事务型数据 \/ 31\n7.3.4　事件 \/ 31\n7.3.5　调整 \/ 31\n第8章　数据转换 \/ 39\n8.1　什么是数据转换 \/ 39\n8.2　数据转换生命周期 \/ 39\n8.3　数据转换分析 \/ 39\n8.4　数据加载最佳实践 \/ 40\n8.5　提高源数据质量 \/ 40\n8.6　映射到目标系统 \/ 41\n8.7　配置数据 \/ 41\n8.8　测试和依赖 \/ 42\n8.9　私有数据 \/ 42\n8.10　校对 \/ 43\n8.11　环境 \/ 43\n第9章　数据归档 \/ 47\n9.1　什么是数据归档 \/ 47\n9.2　归档数据选择 \/ 47\n9.3　已归档数据可以恢复吗 \/ 48\n9.4　归档环境下数据结构的确认 \/ 48\n9.5　灵活的数据结构 \/ 49\n第10章　批处理数据集成架构和元数据 \/ 54\n10.1　什么是批处理数据集成架构 \/ 54\n10.2　概要分析工具 \/ 55\n10.3　建模工具 \/ 55\n10.4　元数据存储库 \/ 55\n10.5　数据移动 \/ 56\n10.6　转换 \/ 56\n10.7　调度 \/ 57\n第三部分　实时数据集成\n第11章　实时数据集成简介 \/ 64\n11.1　为什么需要实时数据集成 \/ 64\n11.2　为什么需要两组技术 \/ 64\n第12章　数据集成模式 \/ 66\n12.1　交互模式 \/ 66\n12.2　松耦合 \/ 66\n12.3　中心和节点模式 \/ 66\n12.4　同步交互和异步交互 \/ 69\n12.5　请求和应答 \/ 70\n12.6　发布和订阅 \/ 70\n12.7　两阶段提交 \/ 70\n12.8　集成交互类型 \/ 71\n第13章　核心实时数据集成技术 \/ 72\n13.1　令人困惑的术语 \/ 72\n13.2　企业服务总线 \/ 72\n13.3　面向服务架构 \/ 75\n13.4　可扩展标记语言 \/ 77\n13.5　数据复制和变化数据捕获 \/ 81\n13.6　企业应用集成 \/ 82\n13.7　企业信息集成 \/ 82\n第14章　数据集成建模 \/ 84\n14.1　规范化建模 \/ 84\n14.2　消息建模 \/ 88\n第15章　主数据管理 \/ 89\n15.1　主数据管理简介 \/ 89\n15.2　需要主数据管理方案的原因 \/ 89\n15.3　购买的软件包与主数据 \/ 90\n15.4　参考数据 \/ 90\n15.5　主和从 \/ 91\n15.6　外部数据 \/ 93\n15.7　主数据管理功能 \/ 93\n15.8　主数据管理方案的类型—注册表以及数据中心 \/ 94\n第16章　实时更新数据仓库 \/ 95\n16.1　企业信息工厂 \/ 95\n16.2　操作型数据存储 \/ 96\n16.3　移动到数据仓库的主数据 \/ 97\n第17章　实时数据集成架构和元数据 \/ 99\n17.1　实时数据集成元数据简介 \/ 99\n17.2　建模 \/ 100\n17.3　概要分析 \/ 100\n17.4　元数据库 \/ 101\n17.5　企业服务总线—数据转换和调度 \/ 101\n17.5.1　技术中介 \/ 101\n17.5.2　业务内容 \/ 102\n17.6　数据移动和中间件 \/ 102\n17.7　外部交互 \/ 102\n第四部分　大数据集成\n第18章　大数据集成简介 \/ 106\n18.1　数据集成及非结构化数据 \/ 106\n18.2　大数据、云数据及数据虚拟化 \/ 106\n第19章　云架构和数据集成 \/ 107\n19.1　为什么云中的数据集成比较重要 \/ 107\n19.2　公共云 \/ 107\n19.3　云安全 \/ 108\n19.4　云延迟 \/ 109\n19.5　云冗余 \/ 110\n第20章　数据虚拟化 \/ 111\n20.1　恰逢其时的一项技术 \/ 111\n20.2　数据虚拟化的商业用途 \/ 112\n20.2.1　商务智能方案 \/ 112\n20.2.2　集成不同类型的数据 \/ 113\n20.2.3　快速向数据仓库中增加或者原型增加数据 \/ 113\n20.2.4　将物理上不同的数据一起展现 \/ 113\n20.2.5　利用不同的数据和模型触发交易 \/ 114\n20.3　数据虚拟化架构 \/ 114\n20.3.1　源和适配器 \/ 114\n20.3.2　映射、模型和视图 \/ 114\n20.3.3　转换和展现 \/ 115\n第21章　大数据集成 \/ 116\n21.1　什么是大数据 \/ 116\n21.2　大数据维度—量 \/ 116\n21.2.1　大规模并行处理—将处理过程移动到数据端 \/ 116\n21.2.2　Hadoop和MapReduce \/ 117\n21.2.3　与外部数据集成 \/ 117\n21.2.4　虚拟化 \/ 118\n21.3　大数据维度—多样性 \/ 118\n21.3.1　数据类型 \/ 118\n21.3.2　集成不同类型的数据 \/ 118\n21.4　大数据维度—速度 \/ 120\n21.4.1　流式数据 \/ 121\n21.4.2　传感器和GPS数据 \/ 121\n21.4.3　社会化媒体数据 \/ 121\n21.5　传统大数据应用案例 \/ 121\n21.6　更多大数据应用案例 \/ 122\n21.6.1　医疗 \/ 122\n21.6.2　物流 \/ 122\n21.6.3　国家安全 \/ 122\n21.7　利用大数据的力量—实施决策支持 \/ 123\n21.7.1　触发行动 \/ 123\n21.7.2　从内存以及磁盘中检索数据的速度 \/ 123\n21.7.3　从数据分析到模型，从流式数据到决策 \/ 124\n21.8　大数据架构 \/ 125\n21.8.1　操作型系统和数据存储 \/ 125\n21.8.2　中间数据中心 \/ 126\n21.8.3　商务智能工具 \/ 126\n21.8.4　数据虚拟化服务器 \/ 127\n21.8.5　批处理和实时数据集成工具 \/ 127\n21.8.6　分析型沙盒 \/ 127\n21.8.7　风险响应系统\/推荐引擎 \/ 127\n第22章　移动数据管理总结 \/ 132\n22.1　数据集成架构 \/ 132\n22.1.1　为什么需要数据集成架构 \/ 132\n22.1.2　数据集成生命周期和专家经验 \/ 132\n22.1.3　安全和隐私 \/ 133\n22.2　数据集成引擎 \/ 134\n22.2.1　操作连贯性 \/ 134\n22.2.2　ETL引擎 \/ 134\n22.2.3　企业服务总线 \/ 135\n22.2.4　数据虚拟化服务器 \/ 135\n22.2.5　数据移动 \/ 136\n22.3　数据集成中心 \/ 136\n22.3.1　主数据 \/ 137\n22.3.2　数据仓库和操作型数据存储 \/ 137\n22.3.3　企业内容管理 \/ 138\n22.3.4　数据归档 \/ 138\n22.4　元数据管理 \/ 138\n22.4.1　数据发现 \/ 138\n22.4.2　数据概要分析 \/ 139\n22.4.3　数据建模 \/ 139\n22.4.4　数据流建模 \/ 139\n22.4.5　元数据存储库 \/ 139\n22.5　结束语 \/ 140\n参考文献 \/ 141","pages":"","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27244321.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27244321.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27244321.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25848790\/","id":"25848790","publisher":"机械工业出版社","isbn10":"7111459059","isbn13":"9787111459057","title":"大数据管理","url":"https:\/\/api.douban.com\/v2\/book\/25848790","alt_title":"","author_intro":"April Reeve，资深数据集成专家、资深信息管理顾问、企业架构师和项目经理，拥有数十年行业从业经验，经历丰富，曾服务于多家大型跨国公司，主要负责开发数据战略以及管理开发和运行方案。她是数据转换、数据仓库、商务智能、主数据管理、数据集成和数据治理等数据管理领域的专家。目前，她作为企业信息管理实践的咨询顾问服务于EMC2咨询公司。","summary":"本书是数据集成领域的经典著作，由具有数十年从业经验的资深数据集成专家撰写，数据管理专家作序推荐！它为大数据时代的大中型企业管理企业内部大量的、复杂的应用系统之间的数据提供了解决方案，全面而深入地讲解数据集成的工具、方法、技巧、解决方案以及最佳实践。\n本书分为四部分，共22章，高屋建瓴地阐述了在大型组织环境中，不同计算机系统之间传输数据，以及将异构数据进行集成所用到的技巧、技术和最佳实践，内容涵盖数据集成导论、批处理数据集成、实时数据集成和大数据集成等。\n本书虽然介绍了各种数据集成问题的多种不同类型的技术解决方案，但读者无需具备广阔的技术背景就能理解，适合数据处理相关的项目经理、数据分析师、数据模型设计师、数据库工作者以及数据集成程序员等相关技术人员及数据管理专业学生阅读。","series":{"id":"19432","title":"大数据技术丛书"},"price":"59"},{"rating":{"max":10,"numRaters":44,"average":"7.2","min":0},"subtitle":"","author":["顾炯炯"],"pubdate":"2016-9","tags":[{"count":47,"name":"云计算","title":"云计算"},{"count":17,"name":"计算机","title":"计算机"},{"count":12,"name":"OpenStack","title":"OpenStack"},{"count":10,"name":"华为","title":"华为"},{"count":9,"name":"架构","title":"架构"},{"count":8,"name":"大数据","title":"大数据"},{"count":4,"name":"Hadoop","title":"Hadoop"},{"count":3,"name":"编程","title":"编程"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29138079.jpg","binding":"平装","translator":[],"catalog":"第 1 章 云计算的商业动力与技术趋势 1\n1.1 云计算基础概念与架构 2\n1.2 云计算的商业动力：企业ICT转型 3\n1.3 企业云计算的发展趋势 12\n第 2 章 云计算的架构内涵与关键技术 19\n2.1 云计算的总体架构 20\n2.2 云计算架构关键技术 34\n2.3 云计算核心架构竞争力衡量维度 47\n2.4 云计算解决方案的典型服务与落地架构 51\n第 3 章 云计算及大数据开源软件概览 65\n3.1 OpenStack概述 66\n3.2 容器开源软件：Kubernetes \/ Mesos \/ Docker 72\n3.3 大数据开源软件：Hadoop\/Spark 73\n3.4 开源还是闭源 81\n第 4 章 面向计算资源共享最大化和管理自动化的软件定义计算 83\n4.1 XEN\/KVM虚拟化引擎 84\n4.2 基于OpenStack Nova的计算资源池调度算法 86\n4.3 计算高可靠性保障 91\n4.4 针对企业关键应用云化的虚拟化调优 92\n4.5 基于OpenStack Ironic的裸金属服务 101\n4.6 异构适配多种Hypervisor类型 106\n第 5 章 面向应用敏捷化部署的Docker容器及其调度 108\n5.1 容器典型应用场景 109\n5.2 Docker容器关键技术 110\n5.3 容器操作系统 112\n5.4 Docker容器资源管理调度和应用编排 115\n5.5 Docker容器与软件定义计算的集成 123\n第 6 章 分布式软件定义存储概述 128\n6.1 分布式软件定义存储 129\n6.2 支持企业关键应用的软件定义块存储 135\n6.3 传统存储SAN\/NAS的管理整合及性能加速 142\n6.4 分布式对象存储 143\n6.5 面向云存储服务的QoS\/SLA管理 148\n6.6 分布式软件定义存储的Erasure Code，分布式重删压缩 149\n第 7 章 面向自动化、多租户的软件定义网络 153\n7.1 网络虚拟化的驱动力与关键需求 154\n7.2 软件Overlay SDN网络，L2\/L3网络 164\n7.3 硬件Underlay SDN网络 170\n7.4 软件化L4～L7网络功能 172\n7.5 网络虚拟化端到端解决方案 176\n第 8 章 无边界计算的混合云 186\n8.1 混和云的驱动力与背景 187\n8.2 典型的混合云架构模式 189\n8.3 基于OpenStack级联的开放异构混合云 190\n第 9 章 PaaS应用开发平台 193\n9.1 PaaS简介 194\n9.2 基于Docker的新型PaaS 195\n9.3 消息中间件服务 198\n9.4 数据库和缓存服务 200\n9.5 大数据服务 201\n第 10 章 大数据平台核心技术与架构 205\n10.1 大数据特点与支撑技术 206\n10.2 企业级Hadoop 208\n10.3 流处理技术 220\n10.4 大数据在金融领域的探索与实践 225\n10.5 未来大数据应用畅想 230\n第 11 章 企业桌面云接入的关键技术架构与应用 235\n11.1 桌面云接入概述 236\n11.2 桌面云接入的架构 239\n11.3 桌面云接入的典型应用 239\n11.4 桌面云接入的关键技术 244\n11.5 面向多租户的企业桌面公有云服务 252\n11.6 终端无关的移动办公接入 254\n第 12 章 第三方云应用生态Marketplace及应用编排自动化 259\n12.1 基于开放云平台的云生态系统构建 260\n12.2 Marketplace系统架构 262\n12.3 面向电信网络和业务云化的CT编排自动化-MANO 262\n12.4 面向IT应用的IT编排自动化—— Heat & TOSCA 270\n12.5 TOSCA(云应用的拓扑编排标准) 272\n第 13 章 云微服务敏捷治理架构与组织流程 275\n13.1 从瀑布式到敏捷式，从服务到微服务 276\n13.2 微服务的治理架构 278\n13.3 支撑敏捷开发与上线的微服务CI\/CD工具链 286\n13.4 面向微服务的DevOps研发运维组织变革 288\n第 14 章 云安全架构与应用实践 290\n14.1 端到端云安全架构 291\n14.2 可信计算TPM\/vTPM 294\n14.3 虚拟机的安全隔离 298\n14.4 虚拟化环境中的网络安全 300\n14.5 云数据安全 301\n14.6 公有云、私有云的安全组 303\n14.7 云安全管理 304\n14.8 安全即服务 306\n14.9 云安全应用实施案例 306\n14.10 云计算安全的其他考虑 307\n14.11 云计算服务法律风险及其应对 308\n缩略语 319\n后 记 329","pages":"327","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29138079.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29138079.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29138079.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26883690\/","id":"26883690","publisher":"清华大学出版社","isbn10":"7302448779","isbn13":"9787302448778","title":"云计算架构技术与实践","url":"https:\/\/api.douban.com\/v2\/book\/26883690","alt_title":"","author_intro":"顾炯炯，华为公司云计算首席架构师，主导完成华为公司云计算产品与解决方案的技术规划与架构设计，支撑了德国电信公有云、西班牙电信公有云、华为企业云、某世界500强大型银行OpenStack私有云、浙江移动IDC公有云、上海联通私有云、华为开发测试及桌面云等数百个云计算项目的商用落地。曾历任华为公司移动软交换产品首席架构师、融合IMS解决方案首席架构师，拥有已获授权并发布的个人专利30多项。","summary":"云计算概念诞生至今已约十年的时间，这十年来，相比云计算诞生初期，技术条件、行业和市场环境均发生了巨大的变化，广大读者对云计算的认知需求，也从当初的粗浅概念阶段，发展到希望深度探索的阶段。\n本书以云计算架构技术为核心，从讨论云计算发展为起点，围绕云计算架构涉及的核心技术与商业实践展开。论及的核心技术包括计算、存储、网络、数据、管理、接入、安全等方面，涵盖了云计算的*新趋势、原理、特性与实践。\n本书在第2版做了与时俱进的更新，分享了华为在云计算核心竞争力构建与价值转换方面的经验与建议，并补充了业界在公有云、私有云、行业云，以及电信网络云化商用落地与技术应用方面的成功优秀实践。与此同时，针对两年来云计算在前沿创新领域*新进入人们视野的新热点，如Docker容器与微服务敏捷迭代、大数据与数据库云化、行业建模与机器学习算法、混合云与管理自动化编排、云生态建设等，第2版重点新增了对其技术与架构发展动态以及应用前景的探讨，希望能给大家带来更多的启发与帮助。\n本书对希望了解云计算技术*新进展的读者和希望深入探索云计算架构技术的读者有所帮助，适用于企业IT部门首席信息官（CIO）、IT主管、IT技术工程师、技术类人员、IT技术公司员工、互联网公司员工、教育机构的师生等。","price":"68"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["周彦伟","蒲聪","娄帅"],"pubdate":"2015-9","tags":[{"count":7,"name":"hbase","title":"hbase"},{"count":3,"name":"计算机","title":"计算机"},{"count":2,"name":"分布式","title":"分布式"},{"count":2,"name":"Hbase","title":"Hbase"},{"count":1,"name":"大数据系统","title":"大数据系统"},{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"Tutorial","title":"Tutorial"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28305430.jpg","binding":"","translator":[],"catalog":"第 1 章\t了解 HBase 生态系统\t1\n基于 Hadoop 的 HBase 架构\t2\nRDBMS 和 HBase 的架构对比\t3\nHBase 的特征\t3\nHBase 在 Hadoop 生态系统中的位置\t4\nHBase 中的数据表示\t5\nHadoop\t6\nHBase 与关系型数据库的功能对比\t8\n行存储数据库的逻辑展现\t9\n列存储数据库的逻辑展现\t9\nHBase 的内部存储架构\t11\n开始使用 HBase\t11\nHBase 是何时出现的\t11\nHBase 的组件和功能\t14\nZooKeeper\t14\n谁在用 HBase？为什么要用？\t19\n什么时候考虑使用 HBase？\t20\n什么时候不使用 HBase？\t21\n了解一些开源的 HBase 工具\t21\nHadoop 和 HBase 版本兼容性对照表\t22\nHBase 的应用\t23\nHBase 的优点和缺点\t24\n小结\t25\n第 2 章\t开启 HBase 之旅\t26\n深入理解 HBase 的组件\t27\nHFile\t27\nRegion\t27\n可扩展性——理解纵向扩展和横向扩展的过程\t29\n读写周期\t32\nWrite-Ahead Logs\t33\nMemStore\t33\nHBase 内部管理\t34\n合并\t34\nRegion 分裂\t35\nRegion 分配\t36\nRegion 合并\t37\nRegionServer 故障转移\t37\nHBase 的删除请求\t37\n读写周期\t37\n可用的 HBase 发行版本列表\t38\nHBase 的必备条件和容量规划\t39\nDNS 正向解析\t39\nDNS 反向解析\t40\nSSH\t41\n小结\t45\n第 3 章\t搭建 HBase\t46\n在 Ubuntu 上下载 Java\t46\n主机配置\t52\n基于主机文件\t52\n基于命令\t52\n基于文件\t52\n基于 DNS\t54\n安装和配置 SSH\t54\n在 Ubuntu\/Red Hat\/CentOS 上安装 SSH\t55\n配置 SSH\t55\n安装和配置 NTP\t56\n容量规划\t57\n安装和配置 Hadoop\t58\ncore-site.xml\t63\nhdfs-site.xml\t63\nyarn-site.xml\t65\nmapred-site.xml\t66\nhadoop-env.sh\t67\nyarn-env.sh\t67\nHadoop 的启动步骤\t67\n配置 Apache HBase\t69\n在单机模式中配置 HBase\t69\n在分布式模式中配置 HBase\t70\n安装和配置ZooKeeper\t74\n安装 Cloudera 版本的Hadoop 和 HBase\t76\n下载 RPM 包\t76\n简易安装 Cloudera\t77\n安装 Hadoop 和 MapReduce 包\t77\n在 Windows 上安装 Hadoop\t78\n小结\t81\n第 4 章\t优化 HBase\/Hadoop 集群\t82\nHadoop\/HBase 集群的类型\t82\nCDH 集群的推荐配置\t84\n容量规划\t85\n优化 Hadoop\t86\n通用优化技巧\t86\n优化 Java GC\t86\n优化 Linux 操作系统\t87\n优化 Hadoop 参数\t87\n优化 MapReduce\t88\n优化 HBase\t91\nHadoop\t91\n内存\t93\nJava\t93\n操作系统\t94\nHBase\t94\n优化 ZooKeeper\t96\nHadoop 中的重要配置文件\t96\nHBase 中的重要配置文件\t97\n小结\t98\n第 5 章\tHBase 的存储、框架以及数据类型\t99\nHBase 的数据类型\t100\nHBase中的数据存储——逻辑视图 vs. 真实物理视图\t101\n命名空间\t102\nHBase 服务\t103\n行键（Row key）\t104\n列族（Column family）\t104\n列（Column）\t104\n单元格（Cell）\t104\n版本（Version）\t104\n时间戳（Timestamp）\t105\n数据模型的操作\t105\n读（Get）\t105\n写（Put）\t106\n扫描（Scan）\t106\n删除（Delete）\t106\n版本和原因\t107\n决定版本数量\t108\n版本的下界\t108\n版本的上界\t108\n模式设计\t109\n表类型的设计\t113\n短宽和高瘦设计模式的好处\t114\n复合键设计\t115\n在 HBase 中计算存储的数据大小\t118\n小结\t119\n第 6 章\tHBase 集群运维与故障处理\t120\nHadoop shell 命令\t121\nHadoop shell 命令的类型\t121\nHBase shell 命令\t140\nHBase 管理工具\t149\nhbck —— HBase 检查\t149\nHBase 健康检查脚本\t151\n写 HBase shell 脚本\t151\n使用 Hadoop 工具或者 JAR\t151\n用 Hive 连接 HBase\t153\nHBase region 管理\t155\n压缩\t155\n合并\t155\nHBase 节点管理\t155\n服役\t155\n退役\t156\n实现安全性\t157\n安全访问\t157\nKerberos KDC\t157\n客户端的安全配置\t158\n服务器端的安全配置\t159\n简单的安全\t160\n客户端配置\t161\n标签的安全特性\t162\nHBase 的访问控制\t163\n使用标签的单元格访问\t168\n配置 ZooKeeper 安全\t169\nHBase 常见错误的故障排查和相关说明\t170\n集群失败的可能情况\t171\n监控 HBase 的健康状况\t172\n小结\t175\n第 7 章\tHBase 脚本编程\t176\nHBase 中的备份与恢复技术\t176\n离线备份\/full-shutdown 备份\t177\n在线备份\t178\nWindows 上的 HBase\t185\n在 HBase 中进行脚本编程\t185\n.irbrc 文件\t187\n获取时间戳\t188\n开启调试\t189\n在 HBase 中开启 SQL\t189\n参与 HBase\t190\n小结\t190\n第 8 章\tHBase Java 编程\t191\n准备开发环境\t192\n构建 Java 客户端程序\t192\n数据类型\t196\n数据模型的 Java 操作\t196\n读操作\t196\n写操作\t204\n修改操作\t206\nHBase 过滤器\t208\n过滤器类型\t209\n客户端 API\t214\n小结\t215\n第 9 章\tHBase Java 高级编程\t216\n接口、类和异常\t216\n管理任务编程\t218\n数据操作代码\t224\nMapReduce 和 HBase\t226\nRESTful 和 Thrift 服务接口\t231\nRESTful 服务接口\t231\nThrift 服务接口\t232\nHDFS 编程\t233\n高级主题简介\t237\n协处理器\t237\n布隆过滤器\t238\nLily 项目\t238\n小结\t239\n第 10 章\tHBase 使用案例\t240\nHBase 在当今行业中的作用\t240\nHBase 和关系型数据库的未来的对比\t241\n一些现实世界中的工程使用案例\t241\nHBase 在 Facebook\t241\nHBase 在 Pinterest\t243\nHBase 在 Groupon\t244\nHBase 在 LongTail Video\t246\nHBase 在 Aadhaar（UIDAI）\t247\n有用的链接和参考\t248\n小结\t249","pages":"272","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28305430.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28305430.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28305430.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26630826\/","id":"26630826","publisher":"电子工业出版社","isbn10":"7121270722","isbn13":"9787121270727","title":"Learning Hbase中文版","url":"https:\/\/api.douban.com\/v2\/book\/26630826","alt_title":"","author_intro":"Shashwat Shriparv生于印度比哈尔邦穆扎法尔布尔县。他先后在穆扎法尔布尔和梅加拉亚邦西隆求学。他在德里英迪拉•甘地国立开放大学获得计算机应用学士（BCA）学位，在喀拉拉邦科钦科技大学（特里凡得琅 C-DAC）获得计算机应用硕士（MCA）学位。他在 2010年早些时候开始研究大数据技术，当时他需要做一个用大数据技术存储和处理日志的概念验证（POC）。同时他还有另一个项目，在此项目中需要存储巨大的不同文件头的二进制文件并要处理它们。这时，他开始配置、搭建并测试 Hadoop HBase集群，并为它们写了一些代码。在做了一个成功的POC之后，他用 Java REST和 SOAP Web服务做了些开发，并搭立了一个系统，在此系统中通过 Web服务利用 Hadoop存储和处理日志，然后在HBase中通过自定义表存储这些日志，通过 HBase API和 HBase-Hive映射查询来读取数据。Shashwat成功地实现了这个项目，紧接着开始了 1TB到 3TB的大规模二进制文件头的处理工作，他把文件的元数据存储在 HBase中，文件本身存在 HDFS上。\nShashwat在特里凡得琅 C-DAC网络取证中心开始他的软件开发生涯，为取证分析开发可移动相关软件。接着，他去了 Genilok Computer Solutions公司，在那里，他的工作包括：集群计算、HPC技术和 Web技术。\n在此之后，他从特里凡得琅到了班加罗尔并加入了 PointCross，在那里他开始了大数据技术工作，用 Java开发软件、Web服务和大数据平台。在 PointCross，他的很多项目都是围绕着大数据技术，例如 Hadoop、HBase、Hive、Pig、 Sqoop、 Flume等。从这里他又到了 HCL Infosystems公司，开始做 UIDAI项目，这是一个在印度非常有声望的项目，它为每一个印度居民提供一个唯一身份识别号。在这里，他工作中使用的技术有：HBase、Hive、 Hadoop、 Pig、 Linux、脚本语言、管理 HBase Hadoop集群、编写脚本、自动化任务和处理、为集群监控创建仪表盘。\n现在，Shashwat在 Cognilytics公司工作，专注于大数据技术、 HANA以及其他高性能技术。你可以通过 https:\/\/github.com\/shriparv和 http:\/\/helpmetocode.blogspot. com了解更多关于他的信息。可以通过 LinkedIn，http:\/\/www.linkedin.com\/pub\/ shashwat-shriparv\/19\/214\/2a9 跟他联系，也可以发邮件给他，dwivedishashwat@ gmail.com。\nShashwat曾经审校过 Pig Design Pattern, Pradeep Pasupuleti, Packt Publishing一书，他还曾担任过他大学杂志 InfinityTech的编辑。","summary":"内容提要\n《Learning Hbase中文版》是一本介绍HBase 知识的专业书籍，它系统地介绍了HBase 的基本概念，与传统关系数据库的功能和特点的对比，自身的配置方法以及安装方法，同时深入介绍了HBase 的运维管理和故障处理。《Learning Hbase中文版》还介绍了基于HBase的Java编程方法，以及HBase作为大数据工具的一些使用案例，这些足以帮助读者更好地理解HBase 的架构，更顺利地在自己的项目中使用HBase。\n《Learning Hbase中文版》不仅适合HBase 初学者自学使用，也适合有HBase 经验的开发人员作为工具查询之用，是一本针对HBase 技术的比较完整的通用工具书，希望本书能在实际工作中对读者有所帮助。","price":"65"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["徐强","王振江"],"pubdate":"2012-1","tags":[{"count":13,"name":"云计算","title":"云计算"},{"count":6,"name":"hadoop","title":"hadoop"},{"count":5,"name":"分布式","title":"分布式"},{"count":4,"name":"云计算应用开发实践","title":"云计算应用开发实践"},{"count":2,"name":"实践","title":"实践"},{"count":1,"name":"软件开发","title":"软件开发"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28339742.jpg","binding":"平装","translator":[],"catalog":"出版说明\n前言\n第1章在云上架构你的应用\n11Java 宠物商店简介\n111环境准备\n112部署Java宠物商店\n113宠物商店架构介绍\n12测试\n121宠物商店访问速度测试\n122其他的测试\n13针对测试结果改进应用\n131提高访问速度\n132主机管理\n14难道这就是云计算？\n141什么是云计算\n142云计算架构简介\n143云计算的起源与发展\n15小结\n第2章IaaS技术介绍\n21虚拟化技术\n211虚拟化技术中的重要名词及技术解释\n212全虚拟化技术\n213半虚拟化技术\n22PXE\n221PXE简介\n222PXE系统的组成及配置\n23负载均衡\n231Tomcat负载均衡\n232DNS负载均衡\n24构建企业IaaS环境\n241需求分析\n242系统架构\n243概要设计\n244动手搭建IaaS环境\n25小结\n第3章并行计算技术介绍\n31Hadoop\n311Hadoop简介\n312初探Hadoop\n313Hadoop的架构\n314多机环境配置Hadoop\n315分布式环境下运行Hadoop\n316使用Eclipse Hadoop集成开发环境\n317使用Hadoop MapReduce 编写程序\n32Platform Symphony\n321Platform Symphony简介\n322初探Symphony DE\n323Platform Symphony架构\n324多机环境配置Symphony DE\n325使用Symphony DE编写程序\n33云数据库\n331HBase\n332初探HBase\n333HBase概念\n334再探HBase\n34小结\n第4章公共云计算介绍\n41因特网数据中心IDC\n411IDC所提供的服务\n412使用IDC提供的主机服务\n413IDC虚拟主机业务实现分析\n414传统IDC所面临的机遇与挑战\n42Google App Engine\n421注册Google App Engine账户\n422安装Google App Engine SDK\n423使用Eclipse 集成开发环境\n424基于Google App Engine SDK开发应用\n425将应用部署到Google App Engine 中\n43Amazon AWS\n431注册AWS 账户\n432使用Amazon EC2\n433使用Eclipse 集成开发环境\n434基于AWS SDK开发应用程序\n435将应用程序部署到AWS 中\n44其他公共云计算平台\n441Microsoft Azure\n442Sina App Engine\n45小结\n第5章在云上开发你的应用\n51为应用选择合适的架构与技术\n511以计算为中心的应用架构选择\n512以数据为中心的应用架构选择\n513需要兼顾数据与计算的应用架构选择\n514MapReduce框架并不能解决所有问题\n52现有云计算技术存在的问题\n521NoSQL数据库API不兼容\n522使用JPA访问NoSQL数据库\n523各公共服务提供商所提供的服务不同\n53基于云计算平台的文件共享系统需求分析\n54基于云计算平台的文件共享系统设计\n541系统架构\n542平台及技术选择\n543系统功能\n544非功能性需求\n55基于云计算的文件共享平台实现\n551用户管理模块实现\n552文件管理模块实现\n553文件浏览及管理页面实现\n56使用GAE与AWS S3部署\n561配置GAE数据库\n562使用Applet编写文件管理界面\n563实现AWS S3 文件管理类\n57小结\n第6章云计算在数据挖掘中的应用\n61从宠物商店引出的商业智能\n62Apriori算法\n621Apriori算法的实现原理\n622利用Apriori小试牛刀\n63商品推荐功能在宠物商店中的程序实现\n631宠物商店JPetStore基础环境配置\n632Apriori算法在商品推荐功能中的程序实现\n633宠物商店商品销售记录测试数据准备\n634单机版测试效果及问题\n64使用云数据库进行计算\n641将MySQL中的数据复制到HBase中\n642使用MapReduce计算频繁项集L［1］\n643得到最终结果\n65小结\n第7章云计算在金融计算中的应用\n71金融计算简介\n72蒙特卡罗模拟算法\n721一个简单的蒙特卡罗模拟例子\n722编程实现蒙特卡罗计算圆周率\n73使用蒙特卡罗模拟解决问题\n731蒙特卡罗模拟投资分析基本编码实现\n732测试\n74云端金融应用需求分析\n741需求分析\n742技术可行性分析\n75云端金融应用概要设计\n751系统功能\n752系统软硬件架构\n76云端金融应用系统实现\n77管理软硬件资源\n78小结\n第8章提升办公效率——Excel与云计算集成\n81Excel简介\n811认识Excel宏\n812Excel VBA简介\n813Excel VBA编程环境\n814Excel VBA编程\n82使用Excel进行蒙特卡罗模拟\n821需求分析\n822VBA编码实现\n83将Excel与云计算环境集成\n831Symphony DE COM组件简介\n832Excel与Symphony DE集成\n833Excel蒙特卡罗模拟投资分析客户端编码实现\n834测试\n84小结\n第9章专业工具软件与云计算集成\n91MATLAB简介\n911安装 MATLAB\n912MATLAB基本使用\n913Parallel Computing Toolbox 简介\n914MATLAB PCT架构\n915配置Parallel Computing Toolbox\n92使用Parallel Computing Toolbox提高计算速度\n921使用MATLAB Job Manager\n922与Symphony DE集成\n923MATLAB与Java运行环境集成\n93将更多的工具运行在云计算环境中\n931通用集成架构探索\n932集成接口探索\n94小结\n第10章管理云计算服务平台\n101一个建立云计算服务平台的机会\n102IT服务标准\n1021ITIL简介\n1022ITSM 简介\n1023IT管理中的基本概念\n103实践IT服务标准\n1031OTRS简介\n1032安装OTRS\n1033创建服务台\n1034票单管理\n1035服务级别管理\n1036变更管理\n1037配置管理\n1038其他管理\n104小结\n附录\n附录A搭建Java运行环境\n附录B安装Tomcat应用服务器\n附录C安装JMeter测试工具\n附录D安装 MySQL 数据库\n致谢\n参考文献","pages":"312","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28339742.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28339742.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28339742.jpg"},"alt":"https:\/\/book.douban.com\/subject\/10433775\/","id":"10433775","publisher":"机械工业出版社","isbn10":"7111366875","isbn13":"9787111366874","title":"云计算应用开发实践","url":"https:\/\/api.douban.com\/v2\/book\/10433775","alt_title":"","author_intro":"徐强 Platform Computing 资深系统开发与预研工程师。对云计算有深入研究，实战经验丰富。直接参与设计开发多款大型并行计算软件Platform Symphony、Platform MapReduce，以及云资源管理软件ISF。现致力于云计算系统的预研工作。（Platform Computing于2011年底被IBM收购）","summary":"第1章内容主要通过实例介绍相关的云计算概念，并不详细讨论实现细节，您只要会上网下载\n程序，会安装程序，那么通过阅读这一章您将能够在您自己的云计算环境上部署一个宠物商店。对于想了解云计算能做什么，但却不太会编程的读者来说，您在阅读这一章时可以重点关注云计算环境搭建、部署以及基本概念，忽略性能提高等编程部分。\n第2章主要讲解搭建云计算基础架构所需要的虚拟化、主机管理以及负载均衡方面的技术和产品。\n第3章主要讲解搭建集群并行计算环境所需要的技术和产品，主要围绕Hadoop、HBase这些常用工具进行介绍。\n第4章主要讲解公共云计算平台，主要围绕Google APP Engine、Amazone AWS以及常见的IDC服务进行介绍。\n第5章主要是对前面二、三、四章的总结，并利用前面所介绍的工具实现一个基于云技术的文件共享系统。\n第6章主要介绍了Apriori数据挖掘算法，并使用云计算技术结合数据挖掘算法挖掘商品之间的相关性。\n第7章主要介绍蒙特卡罗金融算法，并使用云计算技术结合金融算法预测投资收益率。\n第8章主要介绍如何将云计算与常见的办公软件相结合，该章使用Microsoft Excel为例将它与云计算软件相结合，以达到充分利用本机计算资源的目的。\n第9章主要介绍常用科学计算软件与云计算的集成，该章使用Mathworks MATLAB为例，讲解了云计算如何与科学计算软件集成，并对集成进行分析，探索公共集成框架与接口。\n第10章主要围绕如何运营维护云计算环境来讲，重点在于如何使用现有的标准来规范云计算环境的管理与维护。","price":"53.00元"},{"rating":{"max":10,"numRaters":10,"average":"7.1","min":0},"subtitle":"","author":["Kathleen Ting","Jarek Jarcec Cecho"],"pubdate":"2013-7-26","tags":[{"count":6,"name":"hadoop","title":"hadoop"},{"count":5,"name":"sqoop","title":"sqoop"},{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"tech","title":"tech"},{"count":1,"name":"rdbms","title":"rdbms"},{"count":1,"name":"hive","title":"hive"},{"count":1,"name":"hdfs","title":"hdfs"},{"count":1,"name":"etl","title":"etl"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28370792.jpg","binding":"Paperback","translator":[],"catalog":"Chapter 1 Getting Started\nDownloading and Installing Sqoop\nInstalling JDBC Drivers\nInstalling Specialized Connectors\nStarting Sqoop\nGetting Help with Sqoop\nChapter 2 Importing Data\nTransferring an Entire Table\nSpecifying a Target Directory\nImporting Only a Subset of Data\nProtecting Your Password\nUsing a File Format Other Than CSV\nCompressing Imported Data\nSpeeding Up Transfers\nOverriding Type Mapping\nControlling Parallelism\nEncoding NULL Values\nImporting All Your Tables\nChapter 3 Incremental Import\nImporting Only New Data\nIncrementally Importing Mutable Data\nPreserving the Last Imported Value\nStoring Passwords in the Metastore\nOverriding the Arguments to a Saved Job\nSharing the Metastore Between Sqoop Clients\nChapter 4 Free-Form Query Import\nImporting Data from Two Tables\nUsing Custom Boundary Queries\nRenaming Sqoop Job Instances\nImporting Queries with Duplicated Columns\nChapter 5 Export\nTransferring Data from Hadoop\nInserting Data in Batches\nExporting with All-or-Nothing Semantics\nUpdating an Existing Data Set\nUpdating or Inserting at the Same Time\nUsing Stored Procedures\nExporting into a Subset of Columns\nEncoding the NULL Value Differently\nExporting Corrupted Data\nChapter 6 Hadoop Ecosystem Integration\nScheduling Sqoop Jobs with Oozie\nSpecifying Commands in Oozie\nUsing Property Parameters in Oozie\nInstalling JDBC Drivers in Oozie\nImporting Data Directly into Hive\nUsing Partitioned Hive Tables\nReplacing Special Delimiters During Hive Import\nUsing the Correct NULL String in Hive\nImporting Data into HBase\nImporting All Rows into HBase\nImproving Performance When Importing into HBase\nChapter 7 Specialized Connectors\nOverriding Imported boolean Values in PostgreSQL Direct Import\nImporting a Table Stored in Custom Schema in PostgreSQL\nExporting into PostgreSQL Using pg_bulkload\nConnecting to MySQL\nUsing Direct MySQL Import into Hive\nUsing the upsert Feature When Exporting into MySQL\nImporting from Oracle\nUsing Synonyms in Oracle\nFaster Transfers with Oracle\nImporting into Avro with OraOop\nChoosing the Proper Connector for Oracle\nExporting into Teradata\nUsing the Cloudera Teradata Connector\nUsing Long Column Names in Teradata\nColophon","pages":"94","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28370792.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28370792.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28370792.jpg"},"alt":"https:\/\/book.douban.com\/subject\/24807532\/","id":"24807532","publisher":"O'Reilly Media","isbn10":"1449364624","isbn13":"9781449364625","title":"Apache Sqoop Cookbook","url":"https:\/\/api.douban.com\/v2\/book\/24807532","alt_title":"","author_intro":"","summary":"Integrating data from multiple sources is essential in the age of big data, but it can be a challenging and time-consuming task. This handy cookbook provides dozens of ready-to-use recipes for using Apache Sqoop, the command-line interface application that optimizes data transfers between relational databases and Hadoop.\nSqoop is both powerful and bewildering, but with this cookbook’s problem-solution-discussion format, you’ll quickly learn how to deploy and then apply Sqoop in your environment. The authors provide MySQL, Oracle, and PostgreSQL database examples on GitHub that you can easily adapt for SQL Server, Netezza, Teradata, or other relational systems.\nTransfer data from a single database table into your Hadoop ecosystem\nKeep table data and Hadoop in sync by importing data incrementally\nImport data from more than one database table\nCustomize transferred data by calling various database functions\nExport generated, processed, or backed-up data from Hadoop to your database\nRun Sqoop within Oozie, Hadoop’s specialized workflow scheduler\nLoad data into Hadoop’s data warehouse (Hive) or database (HBase)\nHandle installation, connection, and syntax issues common to specific database vendors","price":"USD 14.99"},{"rating":{"max":10,"numRaters":6,"average":"0.0","min":0},"subtitle":"","author":["Yifeng Jiang"],"pubdate":"2012-8-16","tags":[{"count":14,"name":"HBase","title":"HBase"},{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":3,"name":"Cookbook","title":"Cookbook"},{"count":2,"name":"计算机科学","title":"计算机科学"},{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"hbase","title":"hbase"},{"count":1,"name":"英文版","title":"英文版"},{"count":1,"name":"云计算","title":"云计算"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s13798426.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"332","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s13798426.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s13798426.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s13798426.jpg"},"alt":"https:\/\/book.douban.com\/subject\/17802578\/","id":"17802578","publisher":"Packt Publishing","isbn10":"1849517142","isbn13":"9781849517140","title":"HBase Administration Cookbook","url":"https:\/\/api.douban.com\/v2\/book\/17802578","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"","author":["张魁","张粤磊","刘未昕","吴茂贵"],"pubdate":"2016-10-1","tags":[{"count":23,"name":"大数据","title":"大数据"},{"count":11,"name":"计算机","title":"计算机"},{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":2,"name":"云计算","title":"云计算"},{"count":1,"name":"计算机科学","title":"计算机科学"},{"count":1,"name":"自己动手","title":"自己动手"},{"count":1,"name":"hadoop","title":"hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29070162.jpg","binding":"平装","translator":[],"catalog":"第1章　为什么要自己动手做大数据系统  1\n1.1　大数据时代  1\n1.2　实战大数据项目  2\n1.3　大数据演练平台  2\n第2章　项目背景及准备  4\n2.1　项目背景  4\n2.2　项目简介  4\n2.3　项目架构  4\n2.4　操作系统  5\n2.5　数据存储  7\n2.6　数据处理  8\n2.7　开发工具  9\n2.8　调试工具  10\n2.9　版本管理  10\n第3章　大数据环境搭建和配置  11\n3.1　各组件功能说明  11\n3.1.1　各种数据源的采集工具  12\n3.1.2　企业大数据存储工具  12\n3.1.3　企业大数据系统的数据仓库工具  12\n3.1.4　企业大数据系统的分析计算工具  13\n3.1.5　企业大数据系统的数据库工具  13\n3.2　大数据系统各组件安装部署配置  13\n3.2.1　安装的前期准备工作  13\n3.2.2　Hadoop基础环境安装及配置  15\n3.2.3　Hive安装及配置  21\n3.2.4　Sqoop安装及配置  24\n3.2.5　Spark安装及配置  30\n3.2.6　Zookeeper安装及配置  31\n3.2.7　HBase安装及配置  33\n3.3　自动化安装及部署说明  35\n3.3.1　自动化安装及部署整体架构设计  35\n3.3.2　大数据系统自动化部署逻辑调用关系  36\n3.4　本章小结  43\n第4章　大数据的获取  44\n4.1　使用爬虫获取互联网数据  45\n4.2　Python和Scrapy 框架的安装  45\n4.3　抓取和解析招聘职位信息  47\n4.4　职位信息的落地  51\n4.5　两个爬虫配合工作  53\n4.6　让爬虫的架构设计更加合理  55\n4.7　获取数据的其他方式  57\n4.8　使用Sqoop同步论坛中帖子数据  57\n4.9　本章小结  59\n第5章　大数据的处理  60\n5.1　Hive是什么  60\n5.2　为什么使用Hive做数据仓库建模  60\n5.3　飞谷项目中Hive建模步骤  61\n5.3.1　逻辑模型的创建  62\n5.3.2　物理模型的创建  67\n5.3.3　将爬虫数据导入stg_job表  74\n5.4　使用Hive进行数据清洗转换  77\n5.5　数据清洗转换的必要性  78\n5.6　使用HiveQL清洗数据、提取维度信息  79\n5.6.1  使用HQL清洗数据  79\n5.6.2  提取维度信息  82\n5.7　定义Hive UDF封装处理逻辑  85\n5.7.1　Hive UDF的开发、部署和调用  86\n5.7.2　Python版本的UDF  89\n5.8　使用左外连接构造聚合表rpt_job  92\n5.9　让数据处理自动调度  96\n5.9.1　HQL的几种执行方式  96\n5.9.2　Hive Thrift服务  99\n5.9.3　使用JDBC连接Hive  100\n5.9.4　Python调用HiveServer服务  103\n5.9.5　用crontab实现的任务调度  105\n5.10　本章小结  107\n第6章　大数据的存储  108\n6.1　NoSQL及HBase简介  108\n6.2　HBase中的主要概念  110\n6.3　HBase客户端及JavaAPI  111\n6.4　Hive数据导入HBase的两种方案  114\n6.4.1　利用既有的JAR包实现整合  114\n6.4.2　手动编写MapReduce程序  116\n6.5　使用Java API查询HBase中的职位信息  122\n6.5.1　为什么是HBase而非Hive  122\n6.5.2　多条件组合查询HBase中的职位信息  123\n6.6　如何显示职位表中的某条具体信息  132\n6.7　本章小结  133\n第7章　大数据的展示  134\n7.1　概述  134\n7.2　数据分析的一般步骤  135\n7.3　用R来做数据分析展示  135\n7.3.1　在Ubuntu上安装R  135\n7.3.2　R的基本使用方式  137\n7.4　用Hive充当R的数据来源  139\n7.4.1　RHive组件  139\n7.4.2　把R图表整合到Web页面中  145\n7.5　本章小结  151\n第8章　大数据的分析挖掘  152\n8.1　基于Spark的数据挖掘技术  152\n8.2　Spark和Hadoop的关系  153\n8.3　在Ubuntu上安装Spark集群  154\n8.3.1　JDK和Hadoop的安装  154\n8.3.2　安装Scala  154\n8.3.3　安装Spark  155\n8.4　Spark的运行方式  157\n8.5　使用Spark替代Hadoop Yarn引擎  160\n8.5.1　使用spark-sql查看Hive表  160\n8.5.2　在beeline客户端使用Spark引擎  161\n8.5.3　在Java代码中引用Spark的ThriftServer  163\n8.6　对招聘公司名称做全文检索  168\n8.6.1　从HDFS数据源构造JavaRDD  169\n8.6.2　使用Spark SQL操作RDD  173\n8.6.3　把RDD运行结果展现在前端  174\n8.7　如何把Spark用得更好  175\n8.8　SparkR组件的使用  177\n8.8.1　SparkR的安装及启动  177\n8.8.2　运行自带的Sample例子  179\n8.8.3　利用SparkR生成职位统计饼图  179\n8.9　本章小结  181\n第9章　自己动手搭建支撑大数据系统的云平台  182\n9.1　云平台架构  182\n9.1.1　一期云基础平台架构  182\n9.1.2　二期云基础平台架构  184\n9.2　云平台搭建及部署  185\n9.2.1　安装组件前准备  185\n9.2.2　Identity（Keystone）组件  190\n9.2.3　Image（Glance）组件  198\n9.2.4　Compute（Nova）组件  201\n9.2.5　Storage（Cinder）组件  206\n9.2.6　Networking（Neutron）组件  210\n9.2.7　Ceph分布式存储系统  221\n9.2.8　Dashboard（Horizon）组件  230\n9.3　Identity（Keystone）与LDAP的整合  232\n9.4　配置Image组件大镜像部署  235\n9.5　配置业务系统无缝迁移  236\n9.6　本章小结  237\n参考文献  238","pages":"248","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s29070162.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s29070162.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s29070162.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26883727\/","id":"26883727","publisher":"电子工业出版社","isbn10":"7121295865","isbn13":"9787121295867","title":"自己动手做大数据系统","url":"https:\/\/api.douban.com\/v2\/book\/26883727","alt_title":"","author_intro":"张魁\n虚拟化工程师，Openstack架构师，苏州某高校云平台架构师，十余年Linux系统运维实践及虚拟化开发经验，4年Linux系统补丁开发经验。先后在美企担任虚拟化应用运维、服务器集群开发运维工程师或系统开发架构师，高校信息中心云平台架构师，主要关注Openstack、Docker及分布式存储等。\n张粤磊\nDBA、大数据架构师，十余年一线数据处理数据分析实战经验。先后在咨询、金融、互联网行业担任数据平台技术负责人或架构师。主要关注大数据基础平台、大数据模型构建和大数据分析。\n刘未昕\n从事IT研发和项目管理工作十余年以上。使用多种程序设计语言，目前研究方向主要是大数据生态系统，从事金融、数据仓库等领域研发。五年以上IT行业授课、培训经验，并在多所高校担任外聘讲师。\n吴茂贵\n运筹学与控制论专业研究生学历。毕业后主要参与数据仓库、商务智能等方面的项目，期间做过数据处理、数据分析、数据挖掘等工作，行业涉及金融、物流、制造业等。近期主要做复杂数据存储、清理、转换等工作，同时在大数据方面也很有兴趣并投入大量时间和精力，且将持续为之。","summary":"如果你是一位在校大学生，对大数据感兴趣，也知道使用的企业越来越多，市场需求更是日新月异，但苦于自己基础不够，心有余而力不足；也看过不少大数据方面的书籍、博客、视频等，但感觉进步不大；如果你是一位在职人员，但目前主要使用传统技术，虽然对大数据很有兴趣，也深知其对未来的影响，但因时间不够，虽有一定的基础，常常也是打两天鱼、晒三天网，进展不是很理想。\n如果你有上述疑惑或遇到相似问题，《自己动手做大数据系统》正好比较适合你。《自己动手做大数据系统》从OpenStack云平台搭建、软件部署、需求开发实现到结果展示，以纵向角度讲解了生产性大数据项目上线的整个流程；以完成一个实际项目需求贯穿各章节，讲述了Hadoop生态圈中互联网爬虫技术、Sqoop、Hive、HBase组件协同工作流程，并展示了Spark计算框架、R制图软件和SparkRHive组件的使用方法。《自己动手做大数据系统》的一大特色是提供了实际操作环境，用户可以在线登录云平台来动手操作书中的数据和代码，登录网址请参考http:\/\/www.feiguyun.com\/support。","price":"49"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"","author":["王晓华"],"pubdate":"2014-1-1","tags":[{"count":8,"name":"Hadoop","title":"Hadoop"},{"count":5,"name":"源码阅读","title":"源码阅读"},{"count":2,"name":"分布式","title":"分布式"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"架构设计","title":"架构设计"},{"count":1,"name":"图书馆","title":"图书馆"},{"count":1,"name":"互联网","title":"互联网"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28261098.jpg","binding":"平装","translator":[],"catalog":"第1章　大象也会跳舞\n1.1　大数据时代\n1.2　大数据分析时代\n1.3　简单、粗暴、有效这就是Hadoop\n1.4　MapReduce与Hadoop\n1.5　看，大象也会跳舞\n本章小结\n第2章　大象的肚子HDFS文件系统详解\n2.1　HDFS基础详解\n2.1.1　HDFS设计思路\n2.1.2　HDFS架构与基本存储单元\n2.2　HDFS数据存取流程分析\n2.2.1　HDFS数据存储位置与复制详解\n2.2.2　HDFS 输入流程分析\n2.2.3　HDFS输出流程分析\n2.3　HDFS命令行操作详解\n2.3.1　HDFS中4个通用的命令行操作\n2.3.2　HDFS文件18个基本命令行的操作\n2.3.3　HDFS文件访问权限详解\n2.4　通过Web浏览HDFS文件\n2.5　HDFS接口使用详解\n2.5.1　使用FileSystem API操作HDFS中的内容\n2.5.2　使用FileSystem API读取数据详解\n2.5.3　使用FileSystem API写入数据详解\n2.6　HDFS文件同步与并发访问\n本章小结\n第3章　“吃下去吐出来”Hadoop文件I\/O系统详解\n3.1　Hadoop的压缩类型介绍\n3.2　Hadoop的压缩类库\n3.2.1　从一个简单的例子开始\n3.2.2　CompressionCodec接口\n3.2.3　CompressionCodecFactory类详解\n3.2.4　压缩池\n3.2.5　在Hadoop中使用压缩\n3.3　I\/O中序列化类型详解\n3.3.1　Text类详解\n3.3.2　IntWritable类详解\n3.3.3　ObjectWritable类详解\n3.3.4　NullWritable类详解\n3.3.5　ByteWritable类详解\n3.4　实现自定义的Writable类型\n3.4.1　Writable接口\n3.4.2　WritableComparable接口与RawComparator接口\n3.4.3　自定义的Writable类\n3.4.4　为了更快的比较\n3.5　Hadoop中小文件处理详解\n3.5.1　SequenceFile详解\n3.5.2　MapFile详解\n本章小结\n第4章　“大象的大脑”MapReduce框架结构与源码分析\n4.1　MapReduce框架结构与源码分析\n4.1.1　MapReduce框架分析与执行过程详解\n4.1.2　MapReduce输入输出与源码分析\n4.1.3　MapReduce中Job类详解\n4.2　编程实战：经典的MapReduce单词计数程序\n4.2.1　准备工作\n4.2.2　 MapReduce过程分析\n4.2.3　计数程序的MapReduce实现\n4.2.4　计数程序的main方法\n4.2.5　注意事项\n4.2.6　运行结果\n4.2.7　Mapper中的Combiner详解\n本章小结\n第5章　深入！MapReduce配置与测试\n5.1　MapReduce环境变量配置详解\n5.1.1　使用XML配置新的配置文件\n5.1.2　修改已有的配置文件\n5.1.3　辅助类ToolRunner、Configured详解\n5.2　使用MRUnit对MapReduce进行测试\n5.2.1　MRUnit简介与使用\n5.2.2　使用MRUnit完成Mapper单元测试\n5.2.3　使用MRUnit完成Reduce单元测试\n5.2.4 使用MRUnit完成MapReduce单元测试\n5.3　在本地磁盘上进行MapReduce测试\n5.3.1　伪环境欺骗\n5.3.2　在Eclipse中配置Hadoop插件\n5.3.3　编写本地测试代码\n5.4　MapReduce计数器\n5.4.1　使用计数器的MapReduce程序设计\n5.4.2　通过Web接口进行任务分析\n5.4.3　通过Web接口查看计数器\n本章小结\n第6章　大象的思考流程MapReduce运行流程详解\n6.1　经典MapReduce任务的工作流程\n6.1.1　ClientNode执行任务的初始化\n6.1.2　消息传递\n6.1.3　MapReduce任务的执行\n6.1.4　任务的完成与状态更新\n6.2　经典MapReduce任务异常处理详解\n6.2.1　MapReduce任务异常的处理方式\n6.2.2　MapReduce任务失败的处理方式\n6.3　经典MapReduce任务的数据处理过程\n6.3.1　Map端的输入数据处理过程\n6.3.2　Reduce端的输入数据处理过程\n6.3.3　Java虚拟机重用\n6.4　MapReduce 2.0(YARN)工作流程详解\n6.4.1　YARN概述\n6.4.2　YARN任务过程分析\n6.4.3　YARN的异常处理\n本章小结\n第7章　更强的大象MapReduce高级程序设计续\n7.1　MapReduce程序设计默认格式类型详解\n7.1.1　map与reduce方法的默认输入输出类型\n7.1.2　自定义输入输出类型设置\n7.1.3　自定义全局类型变量设置要求\n7.1.4　默认的MapReduce程序设置\n7.2　InputFormat输入格式详解\n7.2.1　输入记录与分区\n7.2.2　InputFormat源码及执行过程分析\n7.2.3　实现自己的RecordReader类\n7.2.4　自定义的FileInputFormat类\n7.2.5　一些常用的InputFormat类详解\n7.3　OutputFormat输出格式详解\n7.3.1　OutputFormat默认输出格式\n7.3.2　自定义OutputFormat输出格式\n7.3.3　对Reduce任务数进行设置\n7.3.4　OutputFormat分区类Partitioner详解\n7.4　多种输入与输出使用介绍\n7.4.1　MultipleInputs多种输入方式详解\n7.4.2　MultipleOutputs多种输出方式详解\n本章小结\n第8章　MapReduce相关特性详解\n8.1　MapReduce计数器\n8.1.1　Hadoop框架内置的计数器\n8.1.2　自定义计数器\n8.1.3　动态计数器\n8.1.4　获取计数器值\n8.2　排序与查找\n8.2.1　普通排序规则与查找\n8.2.2　使用MapFile进行排序与查找\n8.3　对输出结果的值分组排序\n8.3.1　准备工作\n8.3.2　对结果进行分组处理\n8.3.3　对键的二次排序\n8.3.4　自定义输出分组\n8.4　编程实战：使用二次排序自动查找最小值\n8.4.1　思路分析\n8.4.2　验证输入输出结果\n8.4.3　对结果进行二次排序\n8.4.4　对结果进行分组\n8.4.5　分片处理排序与分组\n8.4.6　验证结果\n本章小结\n第9章　啤酒与尿布MapReduce连接与数据挖掘初步\n9.1　对于同样格式数据进行MapReduce连接\n9.2　对于不同格式数据进行MapReduce连接\n9.3　不能说的秘密啤酒与尿布\n9.3.1　销售清单的秘密\n9.3.2　设计程序\n9.3.3　程序执行结果\n9.4　数据挖掘初步\n本章小结\n第10章　MapReduce实战编程及深度分析\n10.1　编程实战：自定义数据库中读取数据\n10.1.1　准备工作\n10.1.2　程序分析\n10.1.3　自定义SQLInputFormat\n10.1.4　使用自定义程序从数据库中读取数据\n10.1.5　程序运行及数据分析\n10.1.6　使用合并记录进行性能调优\n10.2　编程实战：串联寻找共同转载微博\n10.2.1　应用分析\n10.2.2　第一步表转换\n10.2.3　建立关注连接\n10.2.4　自定义的OutputFormat\n10.2.5　串联解决共同转载微博\n10.2.6　性能调优及后续处理\n10.3　编程实战：云存储模型\n10.3.1　应用分析\n10.3.2　Tomcat简介\n10.3.3　配置Tomcat服务器\n10.3.4　测试Tomcat服务器\n10.3.5　在Eclipse中配置Tomcat\n10.3.6　创建云存储目录\n10.3.7　获取云存储列表\n10.3.8　将文件上传至数据云存储中\n10.3.9　删除文件\n10.3.10　下载云端存储文件\n10.3.11　程序执行与性能调优\n10.4　编程实战：多文档相似关键字检索\n10.4.1　应用分析\n10.4.2　自定义任务处理类\n10.4.3　程序执行及后续分析\n10.5　编程实战：学生成绩整理与分组\n10.5.1　应用分析\n10.5.2　自定义的ScoreWritable\n10.5.3　自定义的MapReduce\n10.5.4　自定义的分组\n10.5.5　程序运行结果\n10.5.6　采用更多分组类型\n本章小结","pages":"289","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28261098.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28261098.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28261098.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26302665\/","id":"26302665","publisher":"人民邮电出版社","isbn10":"7115332371","isbn13":"9787115332370","title":"MapReduce 2.0源码分析与编程实战","url":"https:\/\/api.douban.com\/v2\/book\/26302665","alt_title":"","author_intro":"王晓华，高校资深计算机专业讲师，给研究生和本科生讲授面向对象程序设计、数据结构、Hadoop程序设计等相关课程。主要研究方向为云计算、数据挖掘。曾主持和参与多项国家和省级科研课题，独立完成一项科研成果获省级成果认定，发表过多篇论文，申请一项专利。","summary":"Hadoop是一种分布式数据和计算的框架，在大数据处理中应用非常广泛。MapReduce是一种编程模型。Hadoop正是以MapReduce作为核心编程模型的。　　《MapReduce 2.0源码分析与编程实战》比较系统地介绍了新一代MapReduce 2.0的理论体系、架构和程序设计方法。全书分为10章，系统地介绍了HDFS存储系统，Hadoop的文件I\/O系统，MapReduce 2.0的框架结构和源码分析，MapReduce 2.0的配置与测试，MapReduce 2.0运行流程，MapReduce 2.0高级程序设计以及相关特性等内容。《MapReduce 2.0源码分析与编程实战》最后部分介绍了数据挖掘的初步知识，以及不同应用类型的MapReduce 2.0编程实战。　　《MapReduce 2.0源码分析与编程实战》强调理论联系实际，帮助读者在掌握MapReduce 2.0基本知识和特性的基础上，培养实际编程和解决大数据处理相关问题的能力。《MapReduce 2.0源码分析与编程实战》可作为学习MapReduce 2.0的源码、MapReduce 2.0程序设计、数据挖掘、机器学习等相关内容的程序设计人员的培训和自学读物，也可以作为高等院校相关专业的教学辅导书。","price":"49"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"Flexible, Scalable, and Reliable Data Streaming","author":["Hari Shreedharan"],"pubdate":"2014-10-2","tags":[{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":2,"name":"计算机","title":"计算机"},{"count":1,"name":"英文版","title":"英文版"},{"count":1,"name":"日志","title":"日志"},{"count":1,"name":"大数据","title":"大数据"},{"count":1,"name":"Data","title":"Data"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28062522.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"238","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28062522.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28062522.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28062522.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26267501\/","id":"26267501","publisher":"O'Reilly Media","isbn10":"1449368301","isbn13":"9781449368302","title":"Using Flume","url":"https:\/\/api.douban.com\/v2\/book\/26267501","alt_title":"","author_intro":"","summary":"","price":"USD 39.99"},{"rating":{"max":10,"numRaters":9,"average":"0.0","min":0},"subtitle":"","author":["[美]史蒂夫·霍夫曼（Steve Hoffman）","[美]斯里纳特·佩雷拉（Srinath Perera）"],"pubdate":"2015-6","tags":[{"count":3,"name":"大数据","title":"大数据"},{"count":3,"name":"Hadoop","title":"Hadoop"},{"count":2,"name":"日志","title":"日志"},{"count":1,"name":"互联网","title":"互联网"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28219059.jpg","binding":"平装","translator":["张龙"],"catalog":"","ebook_url":"https:\/\/read.douban.com\/ebook\/29503667\/","pages":"","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28219059.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28219059.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28219059.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26429013\/","id":"26429013","publisher":"机械工业出版社","isbn10":"7111502078","isbn13":"9787111502074","title":"Flume日志收集与MapReduce模式","url":"https:\/\/api.douban.com\/v2\/book\/26429013","alt_title":"","author_intro":"","summary":"","ebook_price":"18.00","series":{"id":"19432","title":"大数据技术丛书"},"price":"39.00"},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":["Nathan, Paco"],"pubdate":"2013-8","tags":[{"count":2,"name":"数据处理","title":"数据处理"},{"count":2,"name":"Cascading","title":"Cascading"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"框架","title":"框架"},{"count":1,"name":"架构","title":"架构"},{"count":1,"name":"技术","title":"技术"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26086258.jpg","binding":"","translator":[],"catalog":"","pages":"350","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s26086258.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s26086258.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s26086258.jpg"},"alt":"https:\/\/book.douban.com\/subject\/21866399\/","id":"21866399","publisher":"","isbn10":"1449358721","isbn13":"9781449358723","title":"Enterprise Data Workflows with Cascading","url":"https:\/\/api.douban.com\/v2\/book\/21866399","alt_title":"","author_intro":"","summary":"Despite its growing use in the enterprise, building applications for Hadoop is notoriously difficult. But there is a solution. This hands-on book introduces you to Cascading, the framework that enables you to build powerful data processing applications on Hadoop without having to spend months learning the intricacies of MapReduce. Whether you're a developer, data scientist, or system\/IT administrator, you'll quickly learn Cascading's streamlined approach to data processing, data filtering, and workflow optimization, using sample apps based on Java, Scala, and Clojure. Companies such as Etsy, Razorfish, TeleNav, and Twitter already use Cascading for mission-critical applications. This book shows you how this framework can help your organization extract meaningful information from large amounts of distributed data. Examine best practices for using data science in enterprise-scale apps  Learn how to use workflows that reach beyond MapReduce to integrate other popular Big Data frameworks  Quickly build and test applications with familiar constructs and reusable components, and instantly deploy them onto large clusters  Easily discover, model, and analyze both unstructured and semi-structured data in any format and from any source  Seamlessly move and scale application deployments from development to production, regardless of cluster location or data size","price":"$ 39.54"},{"rating":{"max":10,"numRaters":4,"average":"0.0","min":0},"subtitle":"The Definitive Guide","author":["Lars George"],"pubdate":"2015-12-25","tags":[{"count":1,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"Hbase","title":"Hbase"},{"count":1,"name":"Hadoop","title":"Hadoop"},{"count":1,"name":"HBase","title":"HBase"},{"count":1,"name":"DataScience","title":"DataScience"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28268961.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"600","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s28268961.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s28268961.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s28268961.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26585169\/","id":"26585169","publisher":"O'Reilly Media","isbn10":"1491905859","isbn13":"9781491905852","title":"HBase","url":"https:\/\/api.douban.com\/v2\/book\/26585169","alt_title":"","author_intro":"Lars George has been involved with HBase since 2007, and became a full HBase committer in 2009. He has spoken at various Hadoop User Group meetings, as well as large conferences such as FOSDEM in Brussels. He also started the Munich OpenHUG meetings. He now works closely with Cloudera to support Hadoop and HBase in and around Europe through technical support, consulting work, and training.","summary":"If you’re looking for a scalable storage solution to accommodate a virtually endless amount of data, this updated edition shows you how Apache HBase can meet your needs. Modeled after Google’s BigTable architecture, HBase scales to billions of rows and millions of columns, while ensuring that write and read performance remain constant.\nFully revised for HBase 1.0, this second edition brings you up to speed on the new HBase client API, as well as security features and new case studies that demonstrate HBase use in the real world. Whether you just started to evaluate this non-relational database, or plan to put it into practice right away, this book has your back.\nLaunch into basic, advanced, and administrative features of HBase’s new client-facing API\nUse new classes to integrate HBase with Hadoop’s MapReduce framework\nExplore HBase’s architecture, including the storage format, write-ahead log, and background processes\nDive into advanced usage, such extended client and server options\nLearn cluster sizing, tuning, and monitoring best practices\nDesign schemas, copy tables, import bulk data, decommission nodes, and other tasks\nGo deeper into HBase security, including Kerberos and encryption at rest","price":"$36.00"},{"rating":{"max":10,"numRaters":3,"average":"0.0","min":0},"subtitle":"","author":["Jeffrey Dean and Sanjay Ghemawat"],"pubdate":"2006-5-1","tags":[{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"计算机","title":"计算机"},{"count":1,"name":"经典","title":"经典"},{"count":1,"name":"wsw","title":"wsw"},{"count":1,"name":"python","title":"python"}],"origin_title":"","image":"https://img9.doubanio.com\/view\/subject\/m\/public\/s26385974.jpg","binding":"平装","translator":[],"catalog":"","pages":"13","images":{"small":"https://img9.doubanio.com\/view\/subject\/s\/public\/s26385974.jpg","large":"https://img9.doubanio.com\/view\/subject\/l\/public\/s26385974.jpg","medium":"https://img9.doubanio.com\/view\/subject\/m\/public\/s26385974.jpg"},"alt":"https:\/\/book.douban.com\/subject\/2087350\/","id":"2087350","publisher":"教育科学","isbn10":"7504134058","isbn13":"9787504134059","title":"MapReduce: Simplified Data Processing on Large Clusters","url":"https:\/\/api.douban.com\/v2\/book\/2087350","alt_title":"","author_intro":"","summary":"MapReduce是Google定义的一套并行程序设计模式(parallel programming paradigm)，由两名Google的研究员Jeffrey Dean和Sanjay Ghemawat在2004年时提出。\nGoogle 工程师发表的文章 “MapReduce: Simplified Data Processing on Large Clusters” 清楚地解释了 MapReduce 的工作方式。这篇文章导致的结果是，从 2004 年到现在出现了许多开放源码的 MapReduce 实现。\nMapReduce的发明者Jeff DeanJeffrey Dean和Sanjay Ghemawat在2008年时重新整理了这篇论文，并发表在”Communications of the ACM”上","price":"3.8"},{"rating":{"max":10,"numRaters":5,"average":"0.0","min":0},"subtitle":"A Problem - Solution Approach","author":["Nitin Sawant","Himanshu Shah"],"pubdate":"2013-12-17","tags":[{"count":2,"name":"计算机","title":"计算机"},{"count":2,"name":"Architecture","title":"Architecture"},{"count":1,"name":"云计算","title":"云计算"},{"count":1,"name":"Hadoop","title":"Hadoop"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27220480.jpg","binding":"Paperback","translator":[],"catalog":"","pages":"172","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s27220480.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s27220480.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s27220480.jpg"},"alt":"https:\/\/book.douban.com\/subject\/25829148\/","id":"25829148","publisher":"Apress","isbn10":"1430262923","isbn13":"9781430262923","title":"Big Data Application Architecture Q&A","url":"https:\/\/api.douban.com\/v2\/book\/25829148","alt_title":"","author_intro":"","summary":"","price":"USD 49.99"},{"rating":{"max":10,"numRaters":0,"average":"0.0","min":0},"subtitle":"","author":["Roebuck, Kevin"],"pubdate":"","tags":[{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"mapreduce","title":"mapreduce"},{"count":1,"name":"hive","title":"hive"},{"count":1,"name":"Programming","title":"Programming"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s21219441.jpg","binding":"","translator":[],"catalog":"","pages":"170","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s21219441.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s21219441.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s21219441.jpg"},"alt":"https:\/\/book.douban.com\/subject\/17723669\/","id":"17723669","publisher":"","isbn10":"1743049749","isbn13":"9781743049747","title":"Mapreduce","url":"https:\/\/api.douban.com\/v2\/book\/17723669","alt_title":"","author_intro":"","summary":"","price":""},{"rating":{"max":10,"numRaters":2,"average":"0.0","min":0},"subtitle":"","author":[],"pubdate":"2012-10","tags":[{"count":4,"name":"云计算","title":"云计算"},{"count":2,"name":"hadoop","title":"hadoop"},{"count":1,"name":"预购","title":"预购"},{"count":1,"name":"数据挖掘","title":"数据挖掘"},{"count":1,"name":"数据分析","title":"数据分析"}],"origin_title":"","image":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24412712.jpg","binding":"","translator":[],"catalog":"","pages":"437","images":{"small":"https://img3.doubanio.com\/view\/subject\/s\/public\/s24412712.jpg","large":"https://img3.doubanio.com\/view\/subject\/l\/public\/s24412712.jpg","medium":"https://img3.doubanio.com\/view\/subject\/m\/public\/s24412712.jpg"},"alt":"https:\/\/book.douban.com\/subject\/20270149\/","id":"20270149","publisher":"","isbn10":"7302302383","isbn13":"9787302302384","title":"深入浅出云计算","url":"https:\/\/api.douban.com\/v2\/book\/20270149","alt_title":"","author_intro":"","summary":"《深入浅出云计算》共分4篇。第1篇循序渐进地介绍云计算的基本概念，学习云计算需要掌握的基本知识和云计算环境搭建方法；第2篇基于Hadoop开源云计算平台，讲解如何构建一个基于云计算的应用系统，了解云计算应用系统的设计方法；第3篇以开源的Hadoop云计算平台为分析对象，在源代码层次上对分布式文件系统、MapReduce计算模型、NoSQL数据库和集群管理算法与技术等云计算核心技术进行深度剖析：第4篇为云计算应用篇，介绍了基于Hadoop云计算平台的4个高级应用框架，读者可以结合自己的应用需求与场景，使用这些框架解决实际问题。","price":"59.00元"},{"rating":{"max":10,"numRaters":1,"average":"0.0","min":0},"subtitle":"","author":["Karthik Ramachandran","Istvan Szededi","Richard L. Saltzer"],"pubdate":"2016-3-30","tags":[{"count":1,"name":"hadoop","title":"hadoop"},{"count":1,"name":"bigdata","title":"bigdata"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28332397.jpg","binding":"平装","translator":[],"catalog":"PART 1: INTRODUCTION\n1. HADOOP AND DATA WAREHOUSING\n1.1. What’s a Data Warehouse?\n1.1.1. Operational vs. analytic systems.\n1.1.2. Extract, transform and load\n1.1.3. Data Requirements\n1.1.4. Baseline Requirements.\n1.1.5. A traditional data warehouse architecture\n1.2. Defining big data - volume, velocity, variety and veracity\n1.2.1. The need for distributed computing\n1.3. What is the Hadoop Ecosystem?\n1.3.1. What is Apache Hadoop?\n1.3.2. The rest of the Hadoop Ecosystem\n1.3.3. The Hadoop Ecosystem's Philosophy on Distributed Computing\n1.3.4. Hadoop Distributions\n1.4. Putting it all together: a Big Data warehouse architecture.\n1.5. Who should read this book?\n1.6. What is not covered: BI Tools.\n1.7. Summary\n2. INTRODUCTORY EXAMPLES\n2.1. Following Along At Home\n2.1.1. Installing a Preconfigured Virtual Machine\n2.1.2. Understanding Local, Pseudo-distributed, and Distributed Modes.\n2.1.3. Utilizing a Cloud Providers\n2.1.4. Picking how you work with Hive — Hive CLI, Beeline, and Hue.\n2.1.5. Impala Shell & Hue Query Editor\n2.2. Analyzing data with Hive - Salary Data from Baltimore City\n2.2.1. Downloading the data from opendata.gov\n2.2.2. Uploading the Data into HDFS\n2.2.3. Creating a table to house the raw data in Hive\n2.3. Querying data with Impala - New York Social Media Stats.\n2.3.1. Analyzing your first dataset with Impala.\n2.4. Conclusion\nPART 2: DATA INGEST & ETL\n3. HDFS\n3.1. What is HDFS?\n3.2. Common HDFS commands.\n3.2.1. Following along at home\n3.2.2. Interacting with Hadoop - the fs command.\n3.2.3. Creating a directory in HDFS\n3.2.4. Uploading data into HDFS\n3.2.5. Viewing data in HDFS\n3.2.6. Copying and moving files in HDFS\n3.2.7. File permissions in HDFS.\n3.2.8. Deleting files and directories\n3.2.9. Downloading Files and Directories\n3.3. Other tools for working with HDFS\n3.4. Understanding How HDFS Works\n3.4.1. Blocks\n3.4.2. Data replication\n3.4.3. The architecture of HDFS : clients, name nodes and data nodes\n3.5. Conclusion\n4. DATABASES, TABLES AND VIEWS\n4.1. A simple extract, load, and transform workflow\n4.2. Following along at home.\n4.3. How data is organized in Hive and Impala\n4.4. Creating and Dropping Databases\n4.5. Creating, loading, altering and deleting tables in Hive and Impala\n4.5.1. Creating tables using CREATE TABLE\n4.5.2. Loading data using LOAD\n4.5.3. Partitioning and Bucketing Tables\n4.5.4. Altering Tables\n4.5.5. Deleting tables.\n4.5.6. Views\n4.6. Summary\n5. FILE FORMATS\n5.1. A simple extract, load, and transform workflow\n5.2. Following along at home.\n5.3. Why file formats matter.\n5.3.1. Revisiting the input\/output bottleneck.\n5.3.2. Why file structure matters - row vs. column-oriented formats.\n5.3.3. Why compression matters.\n5.3.4. Converting between file formats using INSERT\n5.3.5. Converting between file formats using CREATE TABLE AS SELECT\n5.4. Row-oriented file formats\n5.4.1. When should I use row-based storage?\n5.4.2. Text Files\n5.4.3. Sequence Files\n5.4.4. Avro\n5.5. Column -based Storage\n5.5.1. RCFile\n5.5.2. ORC File\n5.5.3. Parquet\n5.6. Summary\n6. EXTRACTING DATA WITH APACHE SQOOP.\n7. MODELING AND TRANSFORMING DATA\n8. AUTOMATING ETL WITH OOZIE\n9. DATA GOVERNANCE WITH APACHE FALCON.\nPART 3: QUERY ENGINES\n10. HIVE\n11. IMPALA\n12. SPARK SQL\nPART 4: OTHER CONSIDERATIONS\n13. SECURITY","pages":"425","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s28332397.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s28332397.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s28332397.jpg"},"alt":"https:\/\/book.douban.com\/subject\/26657164\/","id":"26657164","publisher":"","isbn10":"1633430286","isbn13":"9781633430280","title":"Big Data Warehousing","url":"https:\/\/api.douban.com\/v2\/book\/26657164","alt_title":"","author_intro":"Karthik Ramachandran is a software engineer and Big Data expert who makes big data technologies and machine learning accessible to business users. He has extensive experience both with traditional enterprise data warehousing solutions as well as with the Hadoop ecosystem. Istvan Szegedi is a senior technical solutions architect working with enterprise data technologies and Hadoop. Richard Saltzer is a Software Engineer on Cloudera's internal data platform team where he builds scalable ingestion pipelines with Impala.","summary":"Big Data Warehousing teaches you new techniques for common data warehousing tasks such as data ingest, SQL queries and report generation in a big data environment. You’ll get a quick tour of using Hive and Impala to query and analyze large semi-structured datasets and learn how to build an Extract, Load, and Transform (ETL) workflow You’ll explore data extraction with Sqoop and address the practical question of schemas for modeling and transforming big data. As you progress through the book, you’ll survey data governance with Falcon, how to build dataflows with Oozie, approaches to data processing, writing queries with SparkSQL, and data security using Apache Sentry and Knox.","price":"USD 49.99"},{"rating":{"max":10,"numRaters":23,"average":"8.0","min":0},"subtitle":"原理、架构与实践","author":["董西成"],"pubdate":"2018-4","tags":[{"count":31,"name":"大数据","title":"大数据"},{"count":9,"name":"hadoop","title":"hadoop"},{"count":4,"name":"分布式","title":"分布式"},{"count":3,"name":"图书馆","title":"图书馆"},{"count":2,"name":"架构","title":"架构"},{"count":2,"name":"技术","title":"技术"},{"count":1,"name":"数据","title":"数据"},{"count":1,"name":"图书馆k","title":"图书馆k"}],"origin_title":"","image":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29779648.jpg","binding":"平装","translator":[],"catalog":"前　言\n第一部分　概述篇\n第1章　企业级大数据技术体系概述 2\n1.1　大数据系统产生背景及应用场景 2\n1.1.1　产生背景 2\n1.1.2　常见大数据应用场景 3\n1.2　企业级大数据技术框架 5\n1.2.1　数据收集层 6\n1.2.2　数据存储层 7\n1.2.3　资源管理与服务协调层 7\n1.2.4　计算引擎层 8\n1.2.5　数据分析层 9\n1.2.6　数据可视化层 9\n1.3　企业级大数据技术实现方案 9\n1.3.1　Google大数据技术栈 10\n1.3.2　Hadoop与Spark开源大数据技术栈 12\n1.4　大数据架构：Lambda Architecture 15\n1.5　Hadoop与Spark版本选择及安装部署 16\n1.5.1　Hadoop与Spark版本选择 16\n1.5.2　Hadoop与Spark安装部署 17\n1.6　小结 18\n1.7　本章问题 18\n第二部分　数据收集篇\n第2章　关系型数据的收集 20\n2.1　Sqoop概述 20\n2.1.1　设计动机 20\n2.1.2　Sqoop基本思想及特点 21\n2.2　Sqoop基本架构 21\n2.2.1　Sqoop1基本架构 22\n2.2.2　Sqoop2基本架构 23\n2.2.3　Sqoop1与Sqoop2对比 24\n2.3　Sqoop使用方式 25\n2.3.1　Sqoop1使用方式 25\n2.3.2　Sqoop2使用方式 28\n2.4　数据增量收集CDC 31\n2.4.1　CDC动机与应用场景 31\n2.4.2　CDC开源实现Canal 32\n2.4.3　多机房数据同步系统Otter 33\n2.5　小结 35\n2.6　本章问题 35\n第3章　非关系型数据的收集 36\n3.1　概述 36\n3.1.1　Flume设计动机 36\n3.1.2　Flume基本思想及特点 37\n3.2　Flume NG基本架构 38\n3.2.1　Flume NG基本架构 38\n3.2.2　Flume NG高级组件 41\n3.3　Flume NG数据流拓扑构建方法 42\n3.3.1　如何构建数据流拓扑 42\n3.3.2　数据流拓扑实例剖析 46\n3.4　小结 50\n3.5　本章问题 50\n第4章　分布式消息队列Kafka 51\n4.1　概述 51\n4.1.1　Kafka设计动机 51\n4.1.2　Kafka特点 53\n4.2　Kafka设计架构 53\n4.2.1　Kafka基本架构 54\n4.2.2　Kafka各组件详解 54\n4.2.3　Kafka关键技术点 58\n4.3　Kafka程序设计 60\n4.3.1　Producer程序设计 61\n4.3.2　Consumer程序设计 63\n4.3.3　开源Producer与Consumer实现 65\n4.4　Kafka典型应用场景 65\n4.5　小结 67\n4.6　本章问题 67\n第三部分　数据存储篇\n第5章　数据序列化与文件存储格式 70\n5.1　数据序列化的意义 70\n5.2　数据序列化方案 72\n5.2.1　序列化框架Thrift 72\n5.2.2　序列化框架Protobuf 74\n5.2.3　序列化框架Avro 76\n5.2.4　序列化框架对比 78\n5.3　文件存储格式剖析 79\n5.3.1　行存储与列存储 79\n5.3.2　行式存储格式 80\n5.3.3　列式存储格式ORC、Parquet与CarbonData 82\n5.4　小结 88\n5.5　本章问题 89\n第6章　分布式文件系统 90\n6.1　背景 90\n6.2　文件级别和块级别的分布式文件系统 91\n6.2.1　文件级别的分布式系统 91\n6.2.2　块级别的分布式系统 92\n6.3　HDFS基本架构 93\n6.4　HDFS关键技术 94\n6.4.1　容错性设计 95\n6.4.2　副本放置策略 95\n6.4.3　异构存储介质 96\n6.4.4　集中式缓存管理 97\n6.5　HDFS访问方式 98\n6.5.1　HDFS shell 98\n6.5.2　HDFS API 100\n6.5.3　数据收集组件 101\n6.5.4　计算引擎 102\n6.6　小结 102\n6.7　本章问题 103\n第7章　分布式结构化存储系统 104\n7.1　背景 104\n7.2　HBase数据模型 105\n7.2.1　逻辑数据模型 105\n7.2.2　物理数据存储 107\n7.3　HBase基本架构 108\n7.3.1　HBase基本架构 108\n7.3.2　HBase内部原理 110\n7.4　HBase访问方式 114\n7.4.1　HBase shell 114\n7.4.2　HBase API 116\n7.4.3　数据收集组件 118\n7.4.4　计算引擎 119\n7.4.5　Apache Phoenix 119\n7.5　HBase应用案例 120\n7.5.1　社交关系数据存储 120\n7.5.2　时间序列数据库OpenTSDB 122\n7.6　分布式列式存储系统Kudu 125\n7.6.1　Kudu基本特点 125\n7.6.2　Kudu数据模型与架构 126\n7.6.3　HBase与Kudu对比 126\n7.7　小结 127\n7.8　本章问题 127\n第四部分　分布式协调与资源管理篇\n第8章　分布式协调服务ZooKeeper 130\n8.1　分布式协调服务的存在意义 130\n8.1.1　leader选举 130\n8.1.2　负载均衡 131\n8.2　ZooKeeper数据模型 132\n8.3　ZooKeeper基本架构 133\n8.4　ZooKeeper程序设计 134\n8.4.1　ZooKeeper API 135\n8.4.2　Apache Curator 139\n8.5　ZooKeeper应用案例 142\n8.5.1　leader选举 142\n8.5.2　分布式队列 143\n8.5.3　负载均衡 143\n8.6　小结 144\n8.7　本章问题 145\n第9章　资源管理与调度系统YARN 146\n9.1　YARN产生背景 146\n9.1.1　MRv1局限性 146\n9.1.2　YARN设计动机 147\n9.2　YARN设计思想 148\n9.3　YARN的基本架构与原理 149\n9.3.1　YARN基本架构 149\n9.3.2　YARN高可用 152\n9.3.3　YARN工作流程 153\n9.4　YARN资源调度器 155\n9.4.1　层级队列管理机制 155\n9.4.2　多租户资源调度器产生背景 156\n9.4.3　Capacity\/Fair Scheduler 157\n9.4.4　基于节点标签的调度 160\n9.4.5　资源抢占模型 163\n9.5　YARN资源隔离 164\n9.6　以YARN为核心的生态系统 165\n9.7　资源管理系统Mesos 167\n9.7.1　Mesos基本架构 167\n9.7.2　Mesos资源分配策略 169\n9.7.3　Mesos与YARN对比 170\n9.8　资源管理系统架构演化 170\n9.8.1　集中式架构 171\n9.8.2　双层调度架构 171\n9.8.3　共享状态架构 172\n9.9　小结 173\n9.10　本章问题 173\n第五部分　大数据计算引擎篇\n第10章　批处理引擎MapReduce 176\n10.1　概述 176\n10.1.1　MapReduce产生背景 176\n10.1.2　MapReduce设计目标 177\n10.2　MapReduce编程模型 178\n10.2.1　编程思想 178\n10.2.2　MapReduce编程组件 179\n10.3　MapReduce程序设计 187\n10.3.1　MapReduce程序设计基础 187\n10.3.2　MapReduce程序设计进阶 194\n10.3.3　Hadoop Streaming 198\n10.4　MapReduce内部原理 204\n10.4.1　MapReduce作业生命周期 204\n10.4.2　MapTask与ReduceTask 206\n10.4.3　MapReduce关键技术 209\n10.5　MapReduce应用实例 211\n10.6　小结 213\n10.7　本章问题 213\n第11章　DAG计算引擎Spark 215\n11.1　概述 215\n11.1.1　Spark产生背景 215\n11.1.2　Spark主要特点 217\n11.2　Spark编程模型 218\n11.2.1　Spark核心概念 218\n11.2.2　Spark程序基本框架 220\n11.2.3　Spark编程接口 221\n11.3　Spark运行模式 227\n11.3.1　Standalone模式 229\n11.3.2　YARN模式 230\n11.3.3　Spark Shell 232\n11.4　Spark程序设计实例 232\n11.4.1　构建倒排索引 232\n11.4.2　SQL GroupBy实现 234\n11.4.3　应用程序提交 235\n11.5　Spark内部原理 236\n11.5.1　Spark作业生命周期 237\n11.5.2　Spark Shuffle 241\n11.6　DataFrame、Dataset与SQL 247\n11.6.1　DataFrame\/Dataset与SQL的关系 248\n11.6.2　DataFrame\/Dataset程序设计 249\n11.6.3　DataFrame\/Dataset程序实例 254\n11.7　Spark生态系统 257\n11.8　小结 257\n11.9　本章问题 258\n第12章　交互式计算引擎 261\n12.1　概述 261\n12.1.1　产生背景 261\n12.1.2　交互式查询引擎分类 262\n12.1.3　常见的开源实现 263\n12.2　ROLAP 263\n12.2.1　Impala 263\n12.2.2　Presto 267\n12.2.3　Impala与Presto对比 271\n12.3　MOLAP 271\n12.3.1　Druid简介 271\n12.3.2　Kylin简介 272\n12.3.3　Druid与Kylin对比 274\n12.4　小结 274\n12.5　本章问题 274\n第13章　流式实时计算引擎 276\n13.1　概述 276\n13.1.1　产生背景 276\n13.1.2　常见的开源实现 278\n13.2　Storm基础与实战 278\n13.2.1　Storm概念与架构 279\n13.2.2　Storm程序设计实例 282\n13.2.3　Storm内部原理 285\n13.3　Spark Streaming基础与实战 290\n13.3.1　概念与架构 290\n13.3.2　程序设计基础 291\n13.3.3　编程实例详解 298\n13.3.4　容错性讨论 300\n13.4　流式计算引擎对比 303\n13.5　小结 304\n13.6　本章问题 304\n第六部分　数据分析篇\n第14章　数据分析语言HQL与SQL 308\n14.1　概述 308\n14.1.1　背景 308\n14.1.2　SQL On Hadoop 309\n14.2　Hive架构 309\n14.2.1　Hive基本架构 310\n14.2.2　Hive查询引擎 311\n14.3　Spark SQL架构 312\n14.3.1　Spark SQL基本架构 312\n14.3.2　Spark SQL与Hive对比 313\n14.4　HQL 314\n14.4.1　HQL基本语法 314\n14.4.2　HQL应用实例 320\n14.5　小结 322\n14.6　本章问题 322\n第15章　大数据统一编程模型 325\n15.1　产生背景 325\n15.2　Apache Beam基本构成 327\n15.2.1　Beam SDK 327\n15.2.2　Beam Runner 328\n15.3　Apache Beam编程模型 329\n15.3.1　构建Pipeline 330\n15.3.2　创建PCollection 331\n15.3.3　使用Transform 334\n15.3.4　side input与side output 340\n15.4　Apache Beam流式计算模型 341\n15.4.1　window简述 342\n15.4.2　watermark、trigger与accumulation 344\n15.5　Apache Beam编程实例 346\n15.5.1　WordCount 346\n15.5.2　移动游戏用户行为分析 348\n15.6　小结 350\n15.7　本章问题 350\n第16章　大数据机器学习库 351\n16.1　机器学习库简介 351\n16.2　MLLib 机器学习库 354\n16.2.1　Pipeline 355\n16.2.2　特征工程 357\n16.2.3　机器学习算法 360\n16.3　小结 361\n16.4　本章问题 361","pages":"361","images":{"small":"https://img1.doubanio.com\/view\/subject\/s\/public\/s29779648.jpg","large":"https://img1.doubanio.com\/view\/subject\/l\/public\/s29779648.jpg","medium":"https://img1.doubanio.com\/view\/subject\/m\/public\/s29779648.jpg"},"alt":"https:\/\/book.douban.com\/subject\/30213139\/","id":"30213139","publisher":"机械工业出版社","isbn10":"7111590724","isbn13":"9787111590729","title":"大数据技术体系详解：原理、架构与实践","url":"https:\/\/api.douban.com\/v2\/book\/30213139","alt_title":"","author_intro":"董西成，资深大数据技术实践者和研究者，对大数据基础架构有非常深刻的认识和理解，有着丰富的实践经验。熟悉常见的开源大数据解决方案，包括Hadoop和spark生态系统等，擅长底层分布式系统的优化和开发。撰写了大量Hadoop和spark等大数据相关的技术文章并分享在自己的博客上，由于文章技术含量高，所以非常受欢迎。出版有大数据领域负有盛名的专著：《Hadoop技术内幕：深入解析MapReduce架构设计与实现原理》和《Hadoop技术内幕：深入解析YARN架构设计与实现原理》。","summary":"","series":{"id":"19432","title":"大数据技术丛书"},"price":"CNY 79.00"}]}
