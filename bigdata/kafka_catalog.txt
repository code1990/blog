>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Apache Kafka源码剖析
第1章　快速入门
1.1　Kafka简介
1.2　以Kafka为中心的解决方案
1.3　Kafka核心概念
1.4　搭建Kafka源码环境
本章小结
第2章　生产者
2.1　 KafkaProducer使用示例
2.2　KafkaProducer分析
2.2.1　ProducerInterceptors&ProducerInterceptor
2.2.2　Kafka集群元数据
2.2.3　Serializer&Deserializer
2.2.4　Partitioner
2.3　RecordAccumulator分析
2.3.1　MemoryRecords
2.3.2　RecordBatch
2.3.3　BufferPool
2.3.4　RecordAccumulator
2.4　Sender分析
2.4.1　创建请求
2.4.2　KSelector
2.4.3　InFlightRequests
2.4.4　MetadataUpdater
2.4.5　NetworkClient
本章小结
第3章　消费者
3.1　KafkaConsumer使用示例
3.2　传递保证语义（Delivery guarantee semantic）
3.3　Consumer Group Rebalance设计
3.4　KafkaConsumer分析
3.4.1　ConsumerNetworkClient
3.4.2　SubscriptionState
3.4.3　ConsumerCoordinator
3.4.4　PartitionAssignor分析
3.4.5　Heartbeat分析
3.4.6　Rebalance实现
3.4.7　offset操作
3.4.8　Fetcher
3.4.9　KafkaConsumer分析总结
本章小结
第4章　Kafka服务端
4.1　网络层
4.1.1　Reactor模式
4.1.2　SocketServer
4.1.3　AbstractServerThread
4.1.4　Acceptor
4.1.5　Processor
4.1.6　RequestChannel
4.2　API层
4.2.1　KafkaRequestHandler
4.2.2　KafkaApis
4.3　日志存储
4.3.1　基本概念
4.3.2　FileMessageSet
4.3.3　ByteBufferMessageSet
4.3.4　OffsetIndex
4.3.5　LogSegment
4.3.6　Log
4.3.7　LogManager
4.4　DelayedOperationPurgatory组件
4.4.1　TimingWheel
4.4.2　SystemTimer
4.4.3　DelayedOperation
4.4.4　DelayedOperationPurgatory
4.4.5　DelayedProduce
4.4.6　DelayedFetch
4.5　副本机制
4.5.1　副本
4.5.2　分区
4.5.3　ReplicaManager
4.6　KafkaController
4.6.1　ControllerChannelManager
4.6.2　ControllerContext
4.6.3　ControllerBrokerRequestBatch
4.6.4　PartitionStateMachine
4.6.5　PartitionLeaderSelector
4.6.6　ReplicaStateMachine
4.6.7　ZooKeeper Listener
4.6.8　KafkaController初始化与故障转移
4.6.9　处理ControlledShutdownRequest
4.7　GroupCoordinator
4.7.1　GroupMetadataManager
4.7.2　GroupCoordinator分析
4.8　身份认证与权限控制
4.8.1　配置SASL/PLAIN认证
4.8.2　身份认证
4.8.3　权限控制
4.9　Kafka监控
4.9.1　JMX简介
4.9.2　Metrics简介
4.9.3　Kafka中的Metrics
4.9.4　Kafka的监控功能
4.9.5　监控KSelector的指标
第5章　Kafka Tool
5.1　kafka-server-start脚本
5.2　kafka-topics脚本
5.2.1　创建Topic
5.2.2　修改Topic
5.3　kafka-preferred-replica-election脚本
5.4　kafka-reassign-partitions脚本
5.5　kafka-console-producer脚本
5.6　kafka-console-consumer脚本
5.7　kafka-consumer-groups脚本
5.8　DumpLogSegments
5.9　kafka-producer-perf-test脚本
5.10　kafka-consumer-perf-test脚本
5.11　kafka-mirror-maker脚本
本章小结
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Apache Kafka源码剖析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka技术内幕
第1章　Kafka入门　　1
1.1　Kafka流式数据平台　　1
1.2　Kafka的基本概念　　3
1.2.1　分区模型　　3
1.2.2　消费模型　　4
1.2.3　分布式模型　　5
1.3　Kafka的设计与实现　　6
1.3.1　文件系统的持久化与数据传输效率　　6
1.3.2　生产者与消费者　　8
1.3.3　副本机制和容错处理　　10
1.4　快速开始　　11
1.4.1　单机模式　　12
1.4.2　分布式模式　　14
1.4.3　消费组示例　　16
1.5　环境准备　　18
第2章　生产者　　22
2.1　新生产者客户端　　22
2.1.1　同步和异步发送消息　　23
2.1.2　客户端消息发送线程　　29
2.1.3　客户端网络连接对象　　31
2.1.4　选择器处理网络请求　　35
2.2　旧生产者客户端　　43
2.2.1　事件处理器处理客户端发送的消息　　44
2.2.2　对消息集按照节点和分区进行整理　　46
2.2.3　生产者使用阻塞通道发送请求　　48
2.3　服务端网络连接　　49
2.3.1　服务端使用接收器接受客户端的连接　　50
2.3.2　处理器使用选择器的轮询处理网络请求　　53
2.3.3　请求通道的请求队列和响应队列　　56
2.3.4　Kafka请求处理线程　　58
2.3.5　服务端的请求处理入口　　58
2.4　小结　　60
第3章　消费者：高级API和低级API　　61
3.1　消费者启动和初始化　　67
3.1.1　创建并初始化消费者连接器　　69
3.1.2　消费者客户端的线程模型　　70
3.1.3　重新初始化消费者　　72
3.2　消费者再平衡操作　　73
3.2.1　分区的所有权　　74
3.2.2　为消费者分配分区　　75
3.2.3　创建分区信息对象　　78
3.2.4　关闭和更新拉取线程管理器　　80
3.2.5　分区信息对象的偏移量　　80
3.3　消费者拉取数据　　82
3.3.1　拉取线程管理器　　82
3.3.2　抽象拉取线程　　87
3.3.3　消费者拉取线程　　90
3.4　消费者消费消息　　94
3.4.1　Kafka消息流　　94
3.4.2　消费者迭代消费消息　　95
3.5　消费者提交分区偏移量　　97
3.5.1　提交偏移量到ZK　　98
3.5.2　提交偏移量到内部主题　　99
3.5.3　连接偏移量管理器　　101
3.5.4　服务端处理提交偏移量的请求　　103
3.5.5　缓存分区的偏移量　　106
3.6　消费者低级API示例　　108
3.6.1　消息消费主流程　　109
3.6.2　找出分区的主副本　　112
3.6.3　获取分区的读取偏移量　　113
3.6.4　发送拉取请求并消费消息　　116
3.7　小结　　117
3.7.1　消费者线程模型　　117
3.7.2　再平衡和分区分配　　119
第4章　新消费者　　121
4.1　新消费者客户端　　125
4.1.1　消费者的订阅状态　　125
4.1.2　消费者轮询的准备工作　　134
4.1.3　消费者轮询的流程　　138
4.1.4　消费者拉取消息　　146
4.1.5　消费者获取记录　　149
4.1.6　消费消息　　160
4.2　消费者的网络客户端轮询　　161
4.2.1　异步请求　　162
4.2.2　异步请求高级模式　　169
4.2.3　网络客户端轮询　　184
4.3　心跳任务　　188
4.3.1　发送心跳请求　　188
4.3.2　心跳状态　　189
4.3.3　运行心跳任务　　191
4.3.4　处理心跳结果的示例　　192
4.3.5　心跳和协调者的关系　　193
4.4　消费者提交偏移量　　195
4.4.1　自动提交任务　　195
4.4.2　将拉取偏移量作为提交偏移量　　197
4.4.3　同步提交偏移量　　201
4.4.4　消费者的消息处理语义　　202
4.5　小结　　206
第5章　协调者　　210
5.1　消费者加入消费组　　211
5.1.1　元数据与分区分配器　　212
5.1.2　消费者的加入组和同步组　　213
5.1.3　主消费者执行分配任务　　220
5.1.4　加入组的准备、完成和监听器　　224
5.2　协调者处理请求　　229
5.2.1　服务端定义发送响应结果的回调方法　　229
5.2.2　消费者和消费组元数据　　232
5.2.3　协调者处理请求前的条件检查　　236
5.2.4　协调者调用回调方法发送响应给客户端　　237
5.3　延迟的加入组操作　　242
5.3.1 “准备再平衡”　　242
5.3.2　延迟操作和延迟缓存　　244
5.3.3　尝试完成延迟的加入操作　　246
5.3.4　消费组稳定后，原有消费者重新加入消费组　　250
5.3.5　消费组未稳定，原有消费者重新加入消费组　　251
5.4　消费组状态机　　254
5.4.1　再平衡操作与监听器　　254
5.4.2　消费组的状态转换　　262
5.4.3　协调者处理“加入组请求”　　264
5.4.4　协调者处理“同步组请求”　　274
5.4.5　协调者处理“离开组请求”　　276
5.4.6　再平衡超时与会话超时　　278
5.4.7　延迟的心跳　　282
5.5　小结　　290
第6章　存储层　　293
6.1　日志的读写　　293
6.1.1　分区、副本、日志、日志分段　　294
6.1.2　写入日志　　297
6.1.3　日志分段　　305
6.1.4　读取日志　　315
6.1.5　日志管理　　329
6.1.6　日志压缩　　336
6.2　服务端处理读写请求　　348
6.2.1　副本管理器　　351
6.2.2　分区与副本　　362
6.3　延迟操作　　373
6.3.1　延迟操作接口　　374
6.3.2　延迟操作与延迟缓存　　383
6.3.3　延迟缓存　　391
6.4　小结　　400
第7章　控制器　　402
7.1　Kafka控制器　　402
7.1.1　控制器选举　　403
7.1.2　控制器上下文　　406
7.1.3　ZK监听器　　408
7.1.4　分区状态机和副本状态机　　410
7.1.5　删除主题　　430
7.1.6　重新分配分区　　436
7.1.7　控制器的网络通道管理器　　445
7.2　服务端处理LeaderAndIsr请求　　448
7.2.1　创建分区　　449
7.2.2　创建主副本、备份副本　　451
7.2.3　消费组元数据迁移　　463
7.3　元数据缓存　　468
7.3.1　服务端的元数据缓存　　472
7.3.2　客户端更新元数据　　473
7.4　Kafka服务关闭　　483
7.5　小结　　487
第8章　基于Kafka构建数据流管道　　490
8.1　Kafka集群同步工具：MirrorMaker　　490
8.1.1　单机模拟数据同步　　491
8.1.2　数据同步的流程　　493
8.2　Uber集群同步工具：uReplicator　　498
8.2.1　Apache Helix介绍　　498
8.2.2　Helix控制器　　501
8.2.3　Helix工作节点　　504
8.3　Kafka连接器　　505
8.3.1　连接器的使用示例　　507
8.3.2　开发一个简单的连接器　　510
8.3.3　连接器的架构模型　　515
8.3.4　Herder的实现　　520
8.3.5　Worker的实现　　524
8.3.6　配置存储与状态存储　　530
8.3.7　连接器与任务的实现　　550
8.4　小结　　565
第9章　Kafka流处理　　569
9.1　低级Processor API　　569
9.1.1　流处理应用程序示例　　569
9.1.2　流处理的拓扑　　575
9.1.3　流处理的线程模型　　580
9.1.4　状态存储　　613
9.2　高级流式DSL　　636
9.2.1　DSL应用程序示例　　636
9.2.2　KStream和KTable　　638
9.2.3　连接操作　　665
9.2.4　窗口操作　　672
9.3　小结　　684
第10章　高级特性介绍　　686
10.1　客户端配额　　686
10.2　消息与时间戳　　692
10.3　事务处理　　699
10.4　小结　　703


>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka技术内幕
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka权威指南
序 xiii
前言 xv
第 1 章　初识Kafka 1
1.1　发布与订阅消息系统 1
1.1.1　如何开始 2
1.1.2　独立的队列系统 3
1.2　Kafka登场 4
1.2.1　消息和批次 4
1.2.2　模式 4
1.2.3　主题和分区 5
1.2.4　生产者和消费者 5
1.2.5　broker和集群 6
1.2.6　多集群 7
1.3　为什么选择Kafka 8
1.3.1　多个生产者 8
1.3.2　多个消费者 8
1.3.3　基于磁盘的数据存储 9
1.3.4　伸缩性 9
1.3.5　高性能 9
1.4　数据生态系统 9
1.5　起源故事 11
1.5.1　LinkedIn的问题 11
1.5.2　Kafka的诞生 12
1.5.3　走向开源 12
1.5.4　命名 13
1.6　开始Kafka之旅 13
第 2 章　安装Kafka 14
2.1　要事先行 14
2.1.1　选择操作系统 14
2.1.2　安装Java 14
2.1.3　安装Zookeeper 15
2.2　安装Kafka Broker 17
2.3　broker配置 18
2.3.1　常规配置 18
2.3.2　主题的默认配置 19
2.4　硬件的选择 23
2.4.1　磁盘吞吐量 23
2.4.2　磁盘容量 23
2.4.3　内存 23
2.4.4　网络 24
2.4.5　CPU 24
2.5　云端的Kafka 24
2.6　Kafka集群 24
2.6.1　需要多少个broker 25
2.6.2　broker 配置 25
2.6.3　操作系统调优 26
2.7　生产环境的注意事项 28
2.7.1　垃圾回收器选项 28
2.7.2　数据中心布局 29
2.7.3　共享Zookeeper 29
2.8　总结 30
第 3 章　Kafka生产者——向Kafka写入数据 31
3.1　生产者概览 32
3.2　创建Kafka生产者 33
3.3　发送消息到Kafka 34
3.3.1　同步发送消息 35
3.3.2　异步发送消息 35
3.4　生产者的配置 36
3.5　序列化器 39
3.5.1　自定义序列化器 39
3.5.2　使用Avro序列化 41
3.5.3　在Kafka里使用Avro 42
3.6　分区 45
3.7　旧版的生产者API 46
3.8　总结 47
第 4 章　Kafka消费者——从Kafka读取数据 48
4.1　KafkaConsumer概念 48
4.1.1　消费者和消费者群组 48
4.1.2　消费者群组和分区再均衡 51
4.2　创建Kafka消费者 52
4.3　订阅主题 53
4.4　轮询 53
4.5　消费者的配置 55
4.6　提交和偏移量 57
4.6.1　自动提交 58
4.6.2　提交当前偏移量 59
4.6.3　异步提交 59
4.6.4　同步和异步组合提交 61
4.6.5　提交特定的偏移量 61
4.7　再均衡监听器 62
4.8　从特定偏移量处开始处理记录 64
4.9　如何退出 66
4.10　反序列化器 67
4.11　独立消费者——为什么以及怎样使用没有群组的消费者 71
4.12　旧版的消费者API 71
4.13　总结 72
第 5 章　深入Kafka 73
5.1　集群成员关系 73
5.2　控制器 74
5.3　复制 74
5.4　处理请求 76
5.4.1　生产请求 78
5.4.2　获取请求 78
5.4.3　其他请求 80
5.5　物理存储 81
5.5.1　分区分配 81
5.5.2　文件管理 82
5.5.3　文件格式 83
5.5.4　索引 84
5.5.5　清理 84
5.5.6　清理的工作原理 84
5.5.7　被删除的事件 86
5.5.8　何时会清理主题 86
5.9　总结 86
第 6 章　可靠的数据传递 87
6.1　可靠性保证 87
6.2　复制 88
6.3　broker配置 89
6.3.1　复制系数 89
6.3.2　不完全的首领选举 90
6.3.3　最少同步副本 91
6.4　在可靠的系统里使用生产者 92
6.4.1　发送确认 92
6.4.2　配置生产者的重试参数 93
6.4.3　额外的错误处理 94
6.5　在可靠的系统里使用消费者 94
6.5.1　消费者的可靠性配置 95
6.5.2　显式提交偏移量 95
6.6　验证系统可靠性 97
6.6.1　配置验证 98
6.6.2　应用程序验证 98
6.6.3　在生产环境监控可靠性 99
6.7　总结 100
第 7 章　构建数据管道 101
7.1　构建数据管道时需要考虑的问题 102
7.1.1　及时性 102
7.1.2　可靠性 102
7.1.3　高吞吐量和动态吞吐量 103
7.1.4　数据格式 103
7.1.5　转换 104
7.1.6　安全性 104
7.1.7　故障处理能力 104
7.1.8　耦合性和灵活性 105
7.2　如何在Connect API和客户端API之间作出选择 105
7.3　Kafka Connect 106
7.3.1　运行Connect 106
7.3.2　连接器示例——文件数据源和文件数据池 107
7.3.3　连接器示例——从MySQL到ElasticSearch 109
7.3.4　深入理解Connect 114
7.4　Connect之外的选择 116
7.4.1　用于其他数据存储的摄入框架 116
7.4.2　基于图形界面的ETL工具 117
7.4.3　流式处理框架 117
7.5　总结 117
第 8 章　跨集群数据镜像 118
8.1　跨集群镜像的使用场景 118
8.2　多集群架构 119
8.2.1　跨数据中心通信的一些现实情况 119
8.2.2　Hub和Spoke架构 120
8.2.3　双活架构 121
8.2.4　主备架构 123
8.2.5　延展集群 127
8.3　Kafka的MirrorMaker 128
8.3.1　如何配置 129
8.3.2　在生产环境部署MirrorMaker 130
8.3.3　MirrorMaker调优 132
8.4　其他跨集群镜像方案 134
8.4.1　优步的uReplicator 134
8.4.2　Confluent的Replicator 135
8.5　总结 135
第 9 章　管理Kafka 136
9.1　主题操作 136
9.1.1　创建主题 137
9.1.2　增加分区 138
9.1.3　删除主题 138
9.1.4　列出集群里的所有主题 139
9.1.5　列出主题详细信息 139
9.2　消费者群组 140
9.2.1　列出并描述群组 140
9.2.2　删除群组 142
9.2.3　偏移量管理 142
9.3　动态配置变更 143
9.3.1　覆盖主题的默认配置 143
9.3.2　覆盖客户端的默认配置 145
9.3.3　列出被覆盖的配置 145
9.3.4　移除被覆盖的配置 146
9.4　分区管理 146
9.4.1　首选的首领选举 146
9.4.2　修改分区副本 147
9.4.3　修改复制系数 150
9.4.4　转储日志片段 151
9.4.5　副本验证 152
9.5　消费和生产 153
9.5.1　控制台消费者 153
9.5.2　控制台生产者 155
9.6　客户端ACL 157
9.7　不安全的操作 157
9.7.1　移动集群控制器 157
9.7.2　取消分区重分配 157
9.7.3　移除待删除的主题 158
9.7.4　手动删除主题 158
9.8　总结 159
第 10 章　监控Kafka 160
10.1　度量指标基础 160
10.1.1　度量指标在哪里 160
10.1.2　内部或外部度量 161
10.1.3　应用程序健康检测 161
10.1.4　度量指标的覆盖面 161
10.2　broker的度量指标 162
10.2.1　非同步分区 162
10.2.2　broker度量指标 166
10.2.3　主题和分区的度量指标 173
10.2.4　Java虚拟机监控 174
10.2.5　操作系统监控 175
10.2.6　日志 176
10.3　客户端监控 177
10.3.1　生产者度量指标 177
10.3.2　消费者度量指标 179
10.3.3　配额 181
10.4　延时监控 182
10.5　端到端监控 183
10.6　总结 183
第 11 章　流式处理 184
11.1　什么是流式处理 185
11.2　流式处理的一些概念 186
11.2.1　时间 187
11.2.2　状态 188
11.2.3　流和表的二元性 188
11.2.4　时间窗口 189
11.3　流式处理的设计模式 190
11.3.1　单个事件处理 191
11.3.2　使用本地状态 191
11.3.3　多阶段处理和重分区 193
11.3.4　使用外部查找——流和表的连接 193
11.3.5　流与流的连接 195
11.3.6　乱序的事件 195
11.3.7　重新处理 196
11.4　Streams示例 197
11.4.1　字数统计 197
11.4.2　股票市场统计 199
11.4.3　填充点击事件流 201
11.5　Kafka Streams的架构概览 202
11.5.1　构建拓扑 202
11.5.2　对拓扑进行伸缩 203
11.5.3　从故障中存活下来 205
11.6　流式处理使用场景 205
11.7　如何选择流式处理框架 206
11.8　总结 208
附录A　在其他操作系统上安装Kafka 209
作者介绍 214
封面介绍 214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka权威指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入理解Kafka：核心设计与实践原理
第1章  初识Kafka
1.1  基本概念
1.2  安装与配置
1.3  生产与消费
1.4  服务端参数配置
1.5  总结
第2章  生产者
2.1  客户端开发
2.1.1  必要的参数配置
2.1.2  消息的发送
2.1.3  序列化
2.1.4  分区器
2.1.5  生产者拦截器
2.2  原理分析
2.2.1  整体架构
2.2.2  元数据的更新
2.3  重要的生产者参数
2.4  总结
第3章  消费者
3.1  消费者与消费组
3.2  客户端开发
3.2.1  必要的参数配置
3.2.2  订阅主题与分区
3.2.3  反序列化
3.2.4  消息消费
3.2.5  位移提交
3.2.6  控制或关闭消费
3.2.7  指定位移消费
3.2.8  再均衡
3.2.9  消费者拦截器
3.2.10  多线程实现
3.2.11  重要的消费者参数
3.3  总结
第4章  主题与分区
4.1  主题的管理
4.1.1  创建主题
4.1.2  分区副本的分配
4.1.3  查看主题
4.1.4  修改主题
4.1.5  配置管理
4.1.6  主题端参数
4.1.7  删除主题
4.2  初识KafkaAdminClient
4.2.1  基本使用
4.2.2  主题合法性验证
4.3  分区的管理
4.3.1  优先副本的选举
4.3.2  分区重分配
4.3.3  复制限流
4.3.4  修改副本因子
4.4  如何选择合适的分区数
4.4.1  性能测试工具
4.4.2  分区数越多吞吐量就越高吗
4.4.3  分区数的上限
4.4.4  考量因素
4.5  总结
第5章  日志存储
5.1  文件目录布局
5.2  日志格式的演变
5.2.1  v0版本
5.2.2  v1版本
5.2.3  消息压缩
5.2.4  变长字段
5.2.5  v2版本
5.3  日志索引
5.3.1  偏移量索引
5.3.2  时间戳索引
5.4  日志清理
5.4.1  日志删除
5.4.2  日志压缩
5.5  磁盘存储
5.5.1  页缓存
5.5.2  磁盘I/O流程
5.5.3  零拷贝
5.6  总结
第6章  深入服务端
6.1  协议设计
6.2  时间轮
6.3  延时操作
6.4  控制器
6.4.1  控制器的选举及异常恢复
6.4.2  优雅关闭
6.4.3  分区leader的选举
6.5  参数解密
6.5.1  broker.id
6.5.2  bootstrap.servers
6.5.3  服务端参数列表
6.6  总结
第7章  深入客户端
7.1  分区分配策略
7.1.1  RangeAssignor分配策略
7.1.2  RoundRobinAssignor分配策略
7.1.3  StickyAssignor分配策略
7.1.4  自定义分区分配策略
7.2  消费者协调器和组协调器
7.2.1  旧版消费者客户端的问题
7.2.2  再均衡的原理
7.3  __consumer_offsets剖析
7.4  事务
7.4.1  消息传输保障
7.4.2  幂等
7.4.3  事务
7.5  总结
第8章  可靠性探究
8.1  副本剖析
8.1.1  失效副本
8.1.2  ISR的伸缩
8.1.3  LEO与HW
8.1.4  Leader Epoch的介入
8.1.5  为什么不支持读写分离
8.2  日志同步机制
8.3  可靠性分析
8.4  总结
第9章  Kafka应用
9.1  命令行工具
9.1.1  消费组管理
9.1.2  消费位移管理
9.1.3  手动删除消息
9.2  Kafka Connect
9.2.1  独立模式
9.2.2  REST API
9.2.3  分布式模式
9.3  Kafka Mirror Maker
9.4  Kafka Streams
9.5  总结
第10章  Kafka监控
10.1  监控数据的来源
10.1.1  OneMinuteRate
10.1.2  获取监控指标
10.2  消费滞后
10.3  同步失效分区
10.4  监控指标说明
10.5  监控模块
10.6  总结
第11章  高级应用
11.1  过期时间（TTL）
11.2  延时队列
11.3  死信队列和重试队列
11.4  消息路由
11.5  消息轨迹
11.6  消息审计
11.7  消息代理
11.7.1  快速入门
11.7.2  REST API介绍及示例
11.7.3  服务端配置及部署
11.7.4  应用思考
11.8  消息中间件选型
11.8.1  各类消息中间件简述
11.8.2  选型要点概述
11.8.3  消息中间件选型误区探讨
11.9  总结
第12章  Kafka与Spark的集成
12.1  Spark的安装及简单应用
12.2  Spark编程模型
12.3  Spark的运行结构
12.4  Spark Streaming简介
12.5  Kafka与Spark Streaming的整合
12.6  Spark SQL
12.7  Structured Streaming
12.8  Kafka与Structured Streaming的整合
12.9  总结
附录A  Kafka源码环境搭建
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入理解Kafka：核心设计与实践原理
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Apache Kafka实战
第1章  认识Apache Kafka  1
1.1  Kafka快速入门  1
1.1.1  下载并解压缩Kafka二进制代码压缩包文件  2
1.1.2  启动服务器  3
1.1.3  创建topic  3
1.1.4  发送消息  4
1.1.5  消费消息  4
1.2  消息引擎系统  5
1.2.1  消息设计  6
1.2.2  传输协议设计  6
1.2.3  消息引擎范型  6
1.2.4  Java消息服务  8
1.3  Kafka概要设计  8
1.3.1  吞吐量/延时  8
1.3.2  消息持久化  11
1.3.3  负载均衡和故障转移  12
1.3.4  伸缩性  13
1.4  Kafka基本概念与术语  13
1.4.1  消息  14
1.4.2  topic和partition  16
1.4.3  offset  17
1.4.4  replica  18
1.4.5  leader和follower  18
1.4.6  ISR  19
1.5  Kafka使用场景  20
1.5.1  消息传输  20
1.5.2  网站行为日志追踪  20
1.5.3  审计数据收集  20
1.5.4  日志收集  20
1.5.5  Event Sourcing  21
1.5.6  流式处理  21
1.6  本章小结  21
第2章  Kafka发展历史  22
2.1  Kafka的历史  22
2.1.1  背景  22
2.1.2  Kafka横空出世  23
2.1.3  Kafka开源  24
2.2  Kafka版本变迁  25
2.2.1  Kafka的版本演进  25
2.2.2  Kafka的版本格式  26
2.2.3  新版本功能简介  26
2.2.4  旧版本功能简介  31
2.3  如何选择Kafka版本  35
2.3.1  根据功能场景  35
2.3.2  根据客户端使用场景  35
2.4  Kafka与Confluent  36
2.5  本章小结  37
第3章  Kafka线上环境部署  38
3.1  集群环境规划  38
3.1.1  操作系统的选型  38
3.1.2  磁盘规划  40
3.1.3  磁盘容量规划  42
3.1.4  内存规划  43
3.1.5  CPU规划  43
3.1.6  带宽规划  44
3.1.7  典型线上环境配置  45
3.2  伪分布式环境安装  45
3.2.1  安装Java  46
3.2.2  安装ZooKeeper  47
3.2.3  安装单节点Kafka集群  48
3.3  多节点环境安装  49
3.3.1  安装多节点ZooKeeper集群  50
3.3.2  安装多节点Kafka  54
3.4  验证部署  55
3.4.1  测试topic创建与删除  55
3.4.2  测试消息发送与消费  57
3.4.3  生产者吞吐量测试  58
3.4.4  消费者吞吐量测试  58
3.5  参数设置  59
3.5.1  broker端参数  59
3.5.2  topic级别参数  62
3.5.3  GC参数  63
3.5.4  JVM参数  64
3.5.5  OS参数  64
3.6  本章小结  65
第4章  producer开发  66
4.1  producer概览  66
4.2  构造producer  69
4.2.1  producer程序实例  69
4.2.2  producer主要参数  75
4.3  消息分区机制  80
4.3.1  分区策略  80
4.3.2  自定义分区机制  80
4.4  消息序列化  83
4.4.1  默认序列化  83
4.4.2  自定义序列化  84
4.5  producer拦截器  87
4.6  无消息丢失配置  90
4.6.1  producer端配置  91
4.6.2  broker端配置  92
4.7  消息压缩  92
4.7.1  Kafka支持的压缩算法  93
4.7.2  算法性能比较与调优  93
4.8  多线程处理  95
4.9  旧版本producer  96
4.10  本章小结  98
第5章  consumer开发  99
5.1  consumer概览  99
5.1.1  消费者（consumer）  99
5.1.2  消费者组（consumer group）  101
5.1.3  位移（offset）  102
5.1.4  位移提交  103
5.1.5  __consumer_offsets  104
5.1.6  消费者组重平衡（consumer group rebalance）  106
5.2  构建consumer  106
5.2.1  consumer程序实例  106
5.2.2  consumer脚本命令  111
5.2.3  consumer主要参数  112
5.3  订阅topic  115
5.3.1  订阅topic列表  115
5.3.2  基于正则表达式订阅topic  115
5.4  消息轮询  115
5.4.1  poll内部原理  115
5.4.2  poll使用方法  116
5.5  位移管理  118
5.5.1  consumer位移  119
5.5.2  新版本consumer位移管理  120
5.5.3  自动提交与手动提交  121
5.5.4  旧版本consumer位移管理  123
5.6  重平衡（rebalance）  123
5.6.1  rebalance概览  123
5.6.2  rebalance触发条件  124
5.6.3  rebalance分区分配  124
5.6.4  rebalance generation  126
5.6.5  rebalance协议  126
5.6.6  rebalance流程  127
5.6.7  rebalance监听器  128
5.7  解序列化  130
5.7.1  默认解序列化器  130
5.7.2  自定义解序列化器  131
5.8  多线程消费实例  132
5.8.1  每个线程维护一个KafkaConsumer  133
5.8.2  单KafkaConsumer实例+多worker线程  135
5.8.3  两种方法对比  140
5.9  独立consumer  141
5.10  旧版本consumer  142
5.10.1  概览  142
5.10.2  high-level consumer  143
5.10.3  low-level consumer  147
5.11  本章小结  153
第6章  Kafka设计原理  154
6.1  broker端设计架构  154
6.1.1  消息设计  155
6.1.2  集群管理  166
6.1.3  副本与ISR设计  169
6.1.4  水印（watermark）和leader epoch  174
6.1.5  日志存储设计  185
6.1.6  通信协议（wire protocol）  194
6.1.7  controller设计  205
6.1.8  broker请求处理  216
6.2  producer端设计  219
6.2.1  producer端基本数据结构  219
6.2.2  工作流程  220
6.3  consumer端设计  223
6.3.1  consumer group状态机  223
6.3.2  group管理协议  226
6.3.3  rebalance场景剖析  227
6.4  实现精确一次处理语义  230
6.4.1  消息交付语义  230
6.4.2  幂等性producer（idempotent producer）  231
6.4.3  事务（transaction）  232
6.5  本章小结  234
第7章  管理Kafka集群  235
7.1  集群管理  235
7.1.1  启动broker  235
7.1.2  关闭broker  236
7.1.3  设置JMX端口  237
7.1.4  增加broker  238
7.1.5  升级broker版本  238
7.2  topic管理  241
7.2.1  创建topic  241
7.2.2  删除topic  243
7.2.3  查询topic列表  244
7.2.4  查询topic详情  244
7.2.5  修改topic  245
7.3  topic动态配置管理  246
7.3.1  增加topic配置  246
7.3.2  查看topic配置  247
7.3.3  删除topic配置  248
7.4  consumer相关管理  248
7.4.1  查询消费者组  248
7.4.2  重设消费者组位移  251
7.4.3  删除消费者组  256
7.4.4  kafka-consumer-offset-checker  257
7.5  topic分区管理  258
7.5.1  preferred leader选举  258
7.5.2  分区重分配  260
7.5.3  增加副本因子  263
7.6  Kafka常见脚本工具  264
7.6.1  kafka-console-producer脚本  264
7.6.2  kafka-console-consumer脚本  265
7.6.3  kafka-run-class脚本  267
7.6.4  查看消息元数据  268
7.6.5  获取topic当前消息数  270
7.6.6  查询__consumer_offsets  271
7.7  API方式管理集群  273
7.7.1  服务器端API管理topic  273
7.7.2  服务器端API管理位移  275
7.7.3  客户端API管理topic  276
7.7.4  客户端API查看位移  280
7.7.5  0.11.0.0版本客户端API  281
7.8  MirrorMaker  285
7.8.1  概要介绍  285
7.8.2  主要参数  286
7.8.3  使用实例  287
7.9  Kafka安全  288
7.9.1  SASL+ACL  289
7.9.2  SSL加密  297
7.10  常见问题  301
7.11  本章小结  304
第8章  监控Kafka集群  305
8.1  集群健康度检查  305
8.2  MBean监控  306
8.2.1  监控指标  306
8.2.2  指标分类  308
8.2.3  定义和查询JMX端口  309
8.3  broker端JMX监控  310
8.3.1  消息入站/出站速率  310
8.3.2  controller存活JMX指标  311
8.3.3  备份不足的分区数  312
8.3.4  leader分区数  312
8.3.5  ISR变化速率  313
8.3.6  broker I/O工作处理线程空闲率  313
8.3.7  broker网络处理线程空闲率  314
8.3.8  单个topic总字节数  314
8.4  clients端JMX监控  314
8.4.1  producer端JMX监控  314
8.4.2  consumer端JMX监控  316
8.5  JVM监控  317
8.5.1  进程状态  318
8.5.2  GC性能  318
8.6  OS监控  318
8.7  主流监控框架  319
8.7.1  JmxTool  320
8.7.2  kafka-manager  320
8.7.3  Kafka Monitor  325
8.7.4  Kafka Offset Monitor  327
8.7.5  CruiseControl  329
8.8  本章小结  330
第9章  调优Kafka集群  331
9.1  引言  331
9.2  确定调优目标  333
9.3  集群基础调优  334
9.3.1  禁止atime更新  335
9.3.2  文件系统选择  335
9.3.3  设置swapiness  336
9.3.4  JVM设置  337
9.3.5  其他调优  337
9.4  调优吞吐量  338
9.5  调优延时  342
9.6  调优持久性  343
9.7  调优可用性  347
9.8  本章小结  349
第10章  Kafka Connect与Kafka Streams  350
10.1  引言  350
10.2  Kafka Connect  351
10.2.1  概要介绍  351
10.2.2  standalone Connect  353
10.2.3  distributed Connect  356
10.2.4  开发connector  359
10.3  Kafka Streams  362
10.3.1  流处理  362
10.3.2  Kafka Streams核心概念  364
10.3.3  Kafka Streams与其他框架的异同  368
10.3.4  Word Count实例  369
10.3.5  Kafka Streams应用开发  372
10.3.6  Kafka Streams状态查询  382
10.4  本章小结  386
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Apache Kafka实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka入门与实践
内容提要
前言
第1章　Kafka简介
第2章　Kafka安装配置
第3章　Kafka核心组件
第4章　Kafka核心流程分析
第5章　Kafka基本操作实战
第6章　Kafka API编程实战
第7章　Kafka Streams
第8章　Kafka数据采集应用
第9章　Kafka与ELK整合应用
第10章　Kafka与Spark整合应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka入门与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>流式架构：Kafka与MapR Streams数据流处理
第1 章 为什么使用流1
飞机、火车和汽车：车联网和物联网 3
流数据：这才是现实世界 6
什么时候需要流 8
不止是实时：流架构的更多优势11
流架构的最佳实践13
医疗数据流案例 14
流数据：架构设计的核心17
第2 章 流式架构 19
狭义视角：实时应用 20
通用流式架构的关键问题21
消息传递技术的重要性 24
实时分析工具 28
Apache Storm 30
Apache Spark Streaming 31
Apache Flink 32
Apache Apex 33
流分析功能比较33
小结 36
第3 章 流架构：微服务的理想平台 37
为什么需要微服务 38
微服务需要哪些支撑 41
关于微服务的更多详情42
设计流架构：以在线视频服务为例 45
新设计：支持消息传递的基础设施47
通用微架构的重要性 49
命名问题50
为什么使用分布式文件和NoSQL 数据库52
视频服务的新设计 52
小结：综合平台视角 54
第4 章 使用Kafka 进行流传输 57
Kafka 的动机 57
Kafka 的创新 58
Kafka 的基本概念60
排序61
持久化 62
Kafka API 62
KafkaProducer API63
KafkaConsumer API 66
遗留API70
Kafka 实用程序 71
负载均衡 71
镜像 72
Kafka 的陷阱 73
产品环境下的Kafka 73
主题和分区的数目有限 74
手动均衡分区负载 75
没有固有的序列化机制 76
镜像的不足77
小结 78
第5 章 MapR Streams79
MapR Streams 的创新79
MapR 流系统的历史和情境82
MapR Streams 的工作原理 84
配置MapR Streams 86
地理分布式复制 89
MapR Streams 的陷阱 91
第6 章 基于流数据的欺诈检测 93
刷卡速度 94
快速响应决策：“这是欺诈吗”95
多用途流数据98
欺诈检测器的向上扩展 99
小结 101
第7 章 地理分布式数据流 103
利益相关者 104
设计目标 106
设计选择 106
我们的设计 108
数据 108
控制谁能访问流数据109
基于流的地理分布式复制的优势 110
第8 章 总结113
流式架构的优势 115
过渡到流架构116
小结 119
附录A 附加资源121
作者简介125
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>流式架构：Kafka与MapR Streams数据流处理
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka Streams实战
第一部分 开启Kafka Streams之旅
第1章 欢迎来到Kafka Streams 3
1.1 大数据的发展以及它是如何改变程序设计方式的 3
1.1.1 大数据起源 4
1.1.2 MapReduce中的重要概念 5
1.1.3 批处理还不够 7
1.2 流式处理简介 8
1.3 处理购买交易 9
1.3.1 权衡流式处理的选择 9
1.3.2 将需求解构为图表 10
1.4 改变看待购买交易的视角 10
1.4.1 源节点 11
1.4.2 信用卡屏蔽节点 11
1.4.3 模式节点 11
1.4.4 奖励节点 12
1.4.5 存储节点 13
1.5 Kafka Streams在购买处理节点图中的应用 13
1.6 Kafka Streams在购买交易流中的应用 14
1.6.1 定义源 15
1.6.2 第 一个处理器：屏蔽信用卡号码 15
1.6.3 第二个处理器：购买模式 16
1.6.4 第三个处理器：客户奖励 17
1.6.5 第四个处理器：写入购买记录 18
1.7 小结 18
第2章 Kafka快速指南 20
2.1 数据问题 20
2.2 使用Kafka处理数据 21
2.2.1 ZMart原始的数据平台 21
2.2.2 一个Kafka销售交易数据中心 22
2.3 Kafka架构 23
2.3.1 Kafka是一个消息代理 23
2.3.2 Kafka是一个日志 24
2.3.3 Kafka日志工作原理 25
2.3.4 Kafka和分区 25
2.3.5 分区按键对数据进行分组 26
2.3.6 编写自定义分区器 27
2.3.7 指定一个自定义分区器 28
2.3.8 确定恰当的分区数 29
2.3.9 分布式日志 29
2.3.10 ZooKeeper：领导者、追随者和副本 30
2.3.11 Apache ZooKeeper 31
2.3.12 选择一个控制器 31
2.3.13 副本 31
2.3.14 控制器的职责 32
2.3.15 日志管理 33
2.3.16 日志删除 33
2.3.17 日志压缩 35
2.4 生产者发送消息 36
2.4.1 生产者属性 38
2.4.2 指定分区和时间戳 39
2.4.3 指定分区 39
2.4.4 Kafka中的时间戳 40
2.5 消费者读取消息 40
2.5.1 管理偏移量 41
2.5.2 自动提交偏移量 42
2.5.3 手动提交偏移量 42
2.5.4 创建消费者 43
2.5.5 消费者和分区 43
2.5.6 再平衡 43
2.5.7 更细粒度的消费者分配 44
2.5.8 消费者示例 44
2.6 安装和运行Kafka 45
2.6.1 Kafka本地配置 45
2.6.2 运行Kafka 46
2.6.3 发送第 一条消息 47
2.7 小结 49
第二部分 Kafka Streams开发篇
第3章 开发Kafka Streams 53
3.1 流式处理器API 53
3.2 Kafka Streams的Hello World 54
3.2.1 构建“Yelling App”的拓扑 55
3.2.2 Kafka Streams配置 58
3.2.3 Serde的创建 59
3.3 处理客户数据 60
3.3.1 构建一个拓扑 61
3.3.2 创建一个自定义的Serde 67
3.4 交互式开发 69
3.5 下一步 71
3.5.1 新需求 71
3.5.2 将记录写入Kafka之外 76
3.6 小结 78
第4章 流和状态 79
4.1 事件的思考 79
4.2 将状态操作应用到Kafka Stream 81
4.2.1 值转换处理器 82
4.2.2 有状态的客户奖励 82
4.2.3 初始化值转换器 84
4.2.4 使用状态将Purchase对象映射为Reward Accumulator 84
4.2.5 更新奖励处理器 88
4.3 使用状态存储查找和记录以前看到的数据 89
4.3.1 数据本地化 90
4.3.2 故障恢复和容错 91
4.3.3 Kafka Streams使用状态存储 91
4.3.4 其他键/值存储供应者 92
4.3.5 状态存储容错 93
4.3.6 配置变更日志主题 93
4.4 连接流以增加洞察力 94
4.4.1 设置数据 95
4.4.2 生成包含客户ID的键来执行连接 96
4.4.3 构建连接 98
4.4.4 其他连接选项 102
4.5 Kafka Streams中的时间戳 104
4.5.1 自带的时间戳提取器实现类 105
4.5.2 WallclockTimestampExtractor 106
4.5.3 自定义时间戳提取器 106
4.5.4 指定一个时间戳提取器 107
4.6 小结 108
第5章 KTable API 109
5.1 流和表之间的关系 110
5.1.1 记录流 110
5.1.2 更新记录或变更日志 111
5.1.3 事件流与更新流对比 113
5.2 记录更新和KTable配置 115
5.2.1 设置缓存缓冲大小 115
5.2.2 设置提交间隔 116
5.3 聚合和开窗操作 117
5.3.1 按行业汇总股票成交量 118
5.3.2 开窗操作 122
5.3.3 连接KStream和KTable 128
5.3.4 GlobalKTable 130
5.3.5 可查询的状态 133
5.4 小结 133
第6章 处理器API 135
6.1 更高阶抽象与更多控制的权衡 135
6.2 使用源、处理器和接收器创建一个拓扑 136
6.2.1 添加一个源节点 136
6.2.2 添加一个处理器节点 137
6.2.3 增加一个接收器节点 140
6.3 通过股票分析处理器深入研究处理器API 141
6.3.1 股票表现处理器应用程序 142
6.3.2 process()方法 145
6.3.3 punctuator执行 147
6.4 组合处理器 148
6.5 集成处理器API和Kafka Streams API 158
6.6 小结 159
第三部分 管理Kafka Streams
第7章 监控和性能 163
7.1 Kafka基本监控 163
7.1.1 测评消费者和生产者性能 164
7.1.2 检查消费滞后 165
7.1.3 拦截生产者和消费者 166
7.2 应用程序指标 169
7.2.1 指标配置 171
7.2.2 如何连接到收集到的指标 172
7.2.3 使用JMX 172
7.2.4 查看指标 176
7.3 更多Kafka Streams调试技术 177
7.3.1 查看应用程序的表现形式 177
7.3.2 获取应用程序各种状态的通知 178
7.3.3 使用状态监听器 179
7.3.4 状态恢复监听器 181
7.3.5 未捕获的异常处理器 184
7.4 小结 184
第8章 测试Kafka Streams应用程序 185
8.1 测试拓扑 186
8.1.1 构建测试用例 188
8.1.2 测试拓扑中的状态存储 190
8.1.3 测试处理器和转换器 191
8.2 集成测试 193
8.3 小结 199
第四部分 Kafka Streams进阶
第9章 Kafka Streams的高级应用 203
9.1 将Kafka与其他数据源集成 204
9.1.1 使用Kafka Connect集成数据 205
9.1.2 配置Kafka Connect 205
9.1.3 转换数据 207
9.2 替代数据库 211
9.2.1 交互式查询的工作原理 213
9.2.2 分配状态存储 213
9.2.3 创建和查找分布式状态存储 215
9.2.4 编写交互式查询 216
9.2.5 查询服务器内部 218
9.3 KSQL 221
9.3.1 KSQL流和表 222
9.3.2 KSQL架构 222
9.3.3 安装和运行KSQL 224
9.3.4 创建一个KSQL流 224
9.3.5 编写KSQL查询 226
9.3.6 创建一张KSQL表 227
9.3.7 配置KSQL 227
9.4 小结 228
附录A 额外的配置信息 229
附录B 精确一次处理语义 234
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka Streams实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka源码解析与实战
序
前言
第1章　Kafka简介 1
1.1　Kafka诞生的背景 1
1.2　Kafka在LinkedIn内部的应用 3
1.3　Kafka的主要设计目标 4
1.4　为什么使用消息系统 4
1.5　本章小结 5
第2章　Kafka的架构 6
2.1　Kafka的基本组成 6
2.2　Kafka的拓扑结构 8
2.3　Kafka内部的通信协议 9
2.4　本章小结 12
第3章　Broker概述 13
3.1　Broker的启动 13
3.2　Broker内部的模块组成 15
3.3　本章小结 18
第4章　Broker的基本模块 19
4.1　SocketServer 19
4.2　KafkaRequestHandlerPool 25
4.3　KafkaApis 27
4.3.1　LogManager 27
4.3.2　ReplicaManager 37
4.3.3　OffsetManager 47
4.3.4　KafkaScheduler 51
4.3.5　KafkaApis 52
4.4　KafkaHealthcheck 81
4.5　TopicConfigManager 83
4.6　本章小结 85
第5章　Broker的控制管理模块 86
5.1　KafkaController的选举策略 86
5.2　KafkaController的初始化 91
5.2.1　Leader状态下KafkaController的初始化 91
5.2.2　Standby状态下KafkaController的初始化 94
5.3　Topic的分区状态转换机制 95
5.3.1　分区状态的分类 95
5.3.2　分区状态的转换 96
5.3.3　PartitionStateMachine模块的启动 102
5.4　Topic分区的领导者副本选举策略 103
5.4.1　NoOpLeaderSelector 104
5.4.2　Off?linePartitionLeaderSelector 104
5.4.3　ReassignedPartitionLeader-Selector 106
5.4.4　PreferredReplicaPartition-LeaderSelector 107
5.4.5　ControlledShutdownLeader-Selector 108
5.5　Topic分区的副本状态转换机制 109
5.5.1　副本状态的分类 110
5.5.2　副本状态的转换 111
5.5.3　ReplicaStateMachine模块的启动 117
5.6　KafkaController内部的监听器 118
5.6.1　TopicChangeListener 119
5.6.2　AddPartitionsListener 121
5.6.3　PartitionsReassignedListener 122
5.6.4　ReassignedPartitionsIsr-ChangeListener 128
5.6.5　PreferredReplicaElection-Listener 130
5.6.6　BrokerChangeListener 132
5.6.7　DeleteTopicsListener 135
5.7　Kafka集群的负载均衡流程 136
5.8　Kafka集群的Topic删除流程 140
5.9　KafkaController的通信模块 146
5.10　本章小结 150
第6章　Topic的管理工具 151
6.1　kafka-topics.sh 151
6.1.1　createTopic 153
6.1.2　alterTopic 156
6.1.3　listTopics 160
6.1.4　describeTopic 161
6.1.5　deleteTopic 163
6.2　kafka-reassign-partitions.sh 164
6.2.1　generateAssignment 166
6.2.2　executeAssignment 167
6.2.3　verifyAssignment 170
6.3　kafka-preferred-replica-election.sh 172
6.4　本章小结 175
第7章　生产者 176
7.1　设计原则 176
7.2　示例代码 176
7.3　模块组成 180
7.3.1　ProducerSendThread 180
7.3.2　ProducerPool 182
7.3.3　DefaultEventHandler 184
7.4　发送模式 189
7.4.1　同步模式 189
7.4.2　异步模式 189
7.5　本章小结 192
第8章　消费者 193
8.1　简单消费者 193
8.1.1　设计原则 193
8.1.2　消费者流程 194
8.1.3　示例代码 195
8.1.4　原理解析 200
8.2　高级消费者 202
8.2.1　设计原则 202
8.2.2　消费者流程 203
8.2.3　示例代码 204
8.2.4　原理解析 205
8.3　本章小结 227
第9章　Kafka的典型应用 228
9.1　Kafka和Storm的集成 228
9.1.1　Storm简介 228
9.1.2　示例代码 230
9.2　Kafka和ELK的集成 235
9.2.1　ELK简介 235
9.2.2　配置流程 236
9.3　Kafka和Hadoop的集成 237
9.3.1　Hadoop简介 237
9.3.2　示例代码 239
9.4　Kafka和Spark的集成 242
9.4.1　Spark简介 242
9.4.2　示例代码 245
9.5　本章小结 247
第10章　Kafka的综合实例 248
10.1　安防大数据的主要应用 248
10.2　Kafka在安防整体解决方案中的角色 249
10.3　典型业务 250
10.3.1　车辆人脸图片数据的入库 251
10.3.2　视频数据的入库 252
10.3.3　数据延时的监控 254
10.3.4　数据质量的监控 256
10.3.5　布控统计 258
10.3.6　容灾备份 259
10.4　本章小结 260
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka源码解析与实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka并不难学！入门、进阶、商业实战
第1篇 准备
第1章 了解消息队列和Kafka 2
1.1 本章教学视频说明 2
1.2 消息队列 2
∟1.2.1 什么是消息队列 3
∟1.2.2 消息队列主要有哪些作用 3
1.3 为什么需要Kafka 6
1.4 Kafka的基本概念 7
∟1.4.1 代理、生产者、消费者、消费者组 7
∟1.4.2 主题、分区、副本、记录 8
1.5 了解Kafka的工作机制——生产消息/消费消息 9
1.6 Kafka的使用范围 10
∟1.6.1 Kafka的设计初衷 10
∟1.6.2 Kafka的特性 11
∟1.6.3 Kafka适用于哪些场景 13
1.7 小结 14
第2章 安装及配置Kafka 15
2.1 本章教学视频说明 15
2.2 安装与配置基础环境 16
∟2.2.1 安装并配置Linux操作系统 16
∟2.2.2 实例1：安装与配置Java运行环境 18
∟2.2.3 实例2：配置SSH免密码登录 21
∟2.2.4 实例3：安装与配置Zookeeper 23
2.3 实例4：部署Kafka 27
∟2.3.1 单机模式部署 27
∟2.3.2 分布式模式部署 29
2.4 实例5：安装与配置Kafka监控工具 32
∟2.4.1 获取并编译Kafka Eagle源代码 32
∟2.4.2 安装与配置Kafka Eagle 33
2.5 实例6：编译Kafka源代码 37
∟2.5.1 安装与配置Scala运行环境 38
∟2.5.2 安装与配置Gradle 39
∟2.5.3 了解Kafka源代码的编译过程 40
2.6 实例7：将Kafka源代码导入编辑器 42
∟2.6.1 导入IntelliJ IDEA编辑器 42
∟2.6.2 导入Eclipse编辑器 44
2.7 了解元数据的存储分布 46
2.8 了解控制器的选举流程 48
∟2.8.1 了解控制器的启动顺序 48
∟2.8.2 了解主题分区Leader节点的选举过程 52
∟2.8.3 了解注册分区和副本状态机 59
∟2.8.4 了解分区自动均衡和分区重新分配 61
2.9 小结 66
——第2篇 入门
第3章 Kafka的基本操作 68
3.1 本章教学视频说明 68
3.2 操作Zookeeper集群 68
∟3.2.1 Zookeeper的作用及背景 69
∟3.2.2 实例8：单机模式启动Zookeeper系统 70
∟3.2.3 实例9：单机模式关闭Zookeeper系统 72
∟3.2.4 实例10：分布式模式启动Zookeeper集群 74
3.2.5 实例11：分布式模式关闭Zookeeper集群 77
3.3 操作Kafka集群 77
∟3.3.1 实例12：单机模式启动Kafka系统 78
∟3.3.2 实例13：单机模式关闭Kafka系统 79
∟3.3.3 实例14：分布式模式启动Kafka集群 81
∟3.3.4 实例15：分布式模式关闭Kafka集群 84
3.4 管理主题 85
∟3.4.1 什么是主题 86
∟3.4.2 实例16：创建主题 87
∟3.4.3 实例17：查看主题 88
∟3.4.4 实例18：修改主题 92
∟3.4.5 实例19：删除主题 94
3.5 管理分区与副本 95
∟3.5.1 分区和副本的背景及作用 95
∟3.5.2 实例20：修改分区 96
∟3.5.3 实例21：修改副本数 97
3.6 小结 99
第4章 将消息数据写入Kafka系统——生产 100
4.1 本章教学视频说明 100
4.2 了解Kafka生产者 101
4.3 使用脚本操作生产者 101
∟4.3.1 实例22：通过监控工具查看消息 102
∟4.3.2 实例23：启动消费者程序，并查看消息 103
4.4 发送消息到Kafka主题 104
∟4.4.1 了解异步模式 104
∟4.4.2 实例24：生产者用异步模式发送消息 105
∟4.4.3 了解同步模式 105
∟4.4.4 实例25：生产者用同步模式发送消息 106
∟4.4.5 多线程发送消息 107
∟4.4.6 实例26：生产者用单线程发送消息 107
∟4.4.7 实例27：生产者用多线程发送消息 110
4.5 配置生产者的属性 112
4.6 保存对象的各个属性——序列化 115
∟4.6.1 实例28：序列化一个对象 115
∟4.6.2 实例29：在生产者应用程序中实现序列化 117
4.7 自定义主题分区 122
∟4.7.1 实例30：编写自定义主题分区的算法 122
∟4.7.2 实例31：演示自定义分区类的使用 123
4.8 小结 125
第5章 从Kafka系统中读取消息数据——消费 126
5.1 本章教学视频说明 126
5.2 了解Kafka消费者 126
∟5.2.1 为什么需要消费者组 126
∟5.2.1 消费者和消费者组的区别 127
∟5.2.2 消费者和分区的对应关系 127
5.3 使用Kafka系统的脚本操作消费者 130
∟5.3.1 认识消费者新接口 130
∟5.3.2 实例32：用新接口启动消费者程序，并查看消费者信息 131
∟5.3.3 实例33：用旧接口启动消费者程序，并查看消费者元数据的存储结构 134
5.4 消费Kafka集群中的主题消息 136
∟5.4.1 主题如何自动获取分区和手动分配分区 137
∟5.4.2 实例34：主题自动/手动获取分区 137
∟5.4.3 实例35：反序列化主题消息 140
∟5.4.4 如何提交消息的偏移量 145
∟5.4.5 实例36：使用多线程消费多个分区的主题 146
5.5 配置消费者的属性 150
5.6 小结 151
第6章 存储及管理数据 152
6.1 本章教学视频说明 152
6.2 分区存储数据 152
∟6.2.1 熟悉分区存储 153
∟6.2.2 了解消息的格式 154
6.3 清理过期数据的两种方法 155
6.4 网络模型和通信流程 156
∟6.4.1 基本数据类型 156
∟6.4.2 通信模型 157
∟6.4.3 通信过程 157
6.6 小结 159
——第3篇 进阶
第7章 Kafka安全机制 162
7.1 本章教学视频说明 162
7.2 了解Kafka的安全机制 162
∟7.2.1 身份验证 163
∟7.2.2 权限控制 163
7.3 使用SSL协议进行加密和身份验证 164
∟7.3.1 了解SSL协议 164
∟7.3.2 实例37：创建SSL密钥库，并查看密钥库文件 165
∟7.3.3 实例38：创建私有证书 167
∟7.3.4 实例39：导出证书，使用CA对证书进行签名 170
∟7.3.5 实例40：在服务端配置SSL协议，并创建主题 173
∟7.3.6 实例41：在客户端配置SSL协议，并读/写数据 174
7.4 使用SASL协议进行认证 176
∟7.4.1 给客户端配置“Java认证和授权服务”（JAAS） 176
∟7.4.2 给服务端配置SASL 178
∟7.4.3 实例42：开启SASL/Kerberos认证协议 178
∟7.4.4 实例43：开启SASL/PLAIN认证协议 181
∟7.4.5 实例44：开启SASL/SCRAM认证协议 184
7.5 权限控制 187
∟7.5.1 权限控制的基础命令 187
∟7.5.2 配置ACL（访问控制列表） 188
∟7.5.3 实例45：启动集群 189
∟7.5.4 实例46：查看授权、添加授权、删除授权 190
7.6 小结 195
第8章 用Kafka连接器建立数据管道 196
8.1 本章教学视频说明 196
8.2 认识Kafka连接器 196
∟8.2.1 了解连接器的使用场景 197
∟8.2.2 特性及优势 198
∟8.3 操作Kafka连接器 199
8.3.1 配置Kafka连接器的属性 199
∟8.3.2 认识应用接口——REST API 202
∟8.3.3 实例47：单机模式下，将数据导入Kafka主题中 203
∟8.3.4 实例48：单机模式下，将Kafka主题中的数据导出 205
∟8.3.5 实例49：分布式模式下，将数据导入Kafka主题 206
8.4 实例50：开发一个简易的Kafka连接器插件 210
∟8.4.1 编写Source连接器 211
∟8.4.2 编写Sink连接器 217
∟8.4.3 打包与部署 220
8.5 小结 225
第9章 Kafka流处理 226
9.1 本章教学视频说明 226
9.2 初识Kafka流处理 227
∟9.2.1 什么是流处理 227
∟9.2.2 什么是流式计算 227
∟9.2.3 为何要使用流处理 228
9.3 了解流处理的架构 229
∟9.3.1 流分区与任务 230
∟9.3.2 线程模型 232
∟9.3.3 本地状态存储 234
∟9.3.4 容错性（Failover） 235
9.4 操作KStream和KTable 235
∟9.4.1 流处理的核心概念 236
∟9.4.2 窗口操作 237
∟9.4.3 连接操作 241
∟9.4.4 转换操作 246
∟9.4.5 聚合操作 247
9.5 实例51：利用流处理开发一个单词统计程序 248
∟9.5.1 创建Kafka流主题 248
∟9.5.2 统计流主题中单词出现的频率 249
∟9.5.3 预览操作结果 250
9.6 实例52：利用Kafka流开发一个SQL引擎 251
∟9.6.1 构建生产流数据源 251
∟9.6.2 构建Kafka流处理 253
∟9.6.3 构建数据结构和执行SQL逻辑 254
∟9.6.4 观察操作结果 255
9.7 小结 256
第10章 监控与测试 257
10.1 本章教学视频说明 257
10.2 Kafka的监控工具——Kafka Eagle系统 258
∟10.2.1 实例53：管理主题 258
∟10.2.2 实例54：查看消费者组信息 259
∟10.2.3 实例55：查看Kafka与Zookeeper集群的状态和性能 263
10.3 测试生产者性能 264
∟10.3.1 了解测试环境 264
∟10.3.2 认识测试工具 265
∟10.3.3 实例56：利用工具测试生产者性能 266
10.4 测试消费者性能 275
∟10.4.1 了解测试环境 275
∟10.4.2 认识测试工具 276
∟10.4.3 实例57：利用脚本测试消费者的性能 276
10.4 小结 280
——第4篇 商业实战
第11章 Kafka与ELK套件的整合 282
11.1 本章教学视频说明 282
11.2 安装与配置ELK 283
∟11.2.1 安装与配置LogStash 283
∟11.2.2 实例58：LogStash的标准输入与输出 285
∟11.2.3 安装与配置ElasticSearch 287
∟11.2.4 实例59：使用ElasticSearch集群的HTTP接口创建索引 292
∟11.2.5 实例60：使用ElasticSearch集群的HTTP接口查看索引 293
∟11.2.6 实例61：使用ElasticSearch集群的HTTP接口添加数据 294
∟11.2.7 安装与配置Kibana 296
∟11.2.8 实例62：启动并验证Kibana系统 298
11.3 实例63：实现一个游戏日志实时分析系统 299
∟11.3.1 了解系统要实现的功能 300
∟11.3.2 了解平台体系架构 300
∟11.3.3 采集数据 302
∟11.3.4 分流数据 304
∟11.3.5 实现数据可视化 306
11.4 小结 308
第12章 Kafka与Spark实时计算引擎的整合 309
12.1 本章教学视频说明 309
12.2 介绍Spark背景 310
∟12.2.1 Spark SQL——Spark处理结构化数据的模块 310
∟12.2.2 Spark Streaming——Spark核心应用接口的一种扩展 311
∟12.2.3 MLlib——Spark的一个机器学习类库 311
∟12.2.4 GraphX——Spark的一个图计算框架 311
12.3 准备Spark环境 311
∟12.3.1 下载Spark基础安装包 311
∟12.3.2 安装与配置Spark集群 312
12.4 操作Spark 315
∟12.4.1 实例64：使用Spark Shell统计单词出现的频率 315
∟12.4.2 实例65：使用Spark SQL对单词权重进行降序输出 317
∟12.4.3 实例66：使用Spark Submit统计单词出现的频率 319
12.5 实例67：对游戏明细数据做实时统计 322
∟12.5.1 了解项目背景和价值 323
∟12.5.2 设计项目实现架构 323
∟12.5.3 编码步骤一 实现数据采集 325
∟12.5.4 编码步骤二 实现流计算 327
∟12.5.5 编码步骤三 打包应用程序 330
∟12.5.6 编码步骤四 创建表结构 332
∟12.5.7 编码步骤五 执行应用程序 332
∟12.5.8 编码步骤六 预览结果 333
12.6 小结 333
第13章 实例68：从零开始设计一个Kafka监控系统——Kafka Eagle 334
13.1 本章教学视频说明 334
13.2 了解Kafka Eagle监控系统 335
∟13.2.1 设计的背景 335
∟13.2.2 应用场景 336
13.3 从结构上了解Kafka Eagle 337
∟13.3.1 了解Kafka Eagle的整体架构和代码结构 337
∟13.3.2 设计Kafka Eagle的7大功能模块 339
13.4 实现Kafka Eagle的功能模块 347
∟13.4.1 编码步骤一 实现数据面板 347
∟13.4.2 编码步骤二 实现主题管理 348
∟13.4.3 编码步骤三 实现消费者实例详情 350
∟13.4.4 编码步骤四 实现集群监控 350
∟13.4.5 编码步骤五 实现性能监控 351
∟13.4.6 编码步骤六 实现告警功能 351
∟13.4.7 编码步骤七 实现系统功能 352
13.5 安装及使用Kafka Eagle监控系统 353
∟13.5.1 准备环境 353
∟13.5.2 快速部署 354
∟13.5.3 了解Kafka Eagle的基础命令 358
13.6 小结 358
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kafka并不难学！入门、进阶、商业实战
