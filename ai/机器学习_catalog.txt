>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
目录
第1章 1
1.1 引言 1
1.2 基本术 2
1.3 假设空间 4
1.4 归纳偏好 6
1.5 发展历程 10
1.6 应用现状 13
1.7 阅读材料 16
习题 19
参考文献 20
休息一会儿 22
第2章 模型评估与选择 23
2.1 经验误差与过拟合 23
2.2 评估方法 24
2.2.1 留出法 25
2.2.2 交叉验证法 26
2.2.3 自助法 27
2.2.4 调参与最终模型 28
2.3 性能度量 28
2.3.1 错误率与精度 29
2.3.2 查准率、查全率与F1 30
2.3.3 ROC与AUC 33
2.3.4 代价敏感错误率与代价曲线 35
2.4 比较检验 37
2.4.1 假设检验 37
2.4.2 交叉验证t检验 40
2.4.3 McNemar检验 41
2.4.4 Friedman检验与后续检验 42
2.5 偏差与方差 44
2.6 阅读材料 46
习题 48
参考文献 49
休息一会儿 51
第3章 线性模型 53
3.1 基本形式 53
3.2 线性回归 53
3.3 对数几率回归 57
3.4 线性判别分析 60
3.5 多分类学习 63
3.6 类别不平衡问题 66
3.7 阅读材料 67
习题 69
参考文献 70
休息一会儿 72
第4章 决策树 73
4.1 基本流程 73
4.2 划分选择 75
4.2.1 信息增益 75
4.2.2 增益率 77
4.2.3 基尼指数 79
4.3 剪枝处理 79
4.3.1 预剪枝 80
4.3.2 后剪枝 82
4.4 连续与缺失值 83
4.4.1 连续值处理 83
4.4.2 缺失值处理 85
4.5 多变量决策树 88
4.6 阅读材料 92
习题 93
参考文献 94
休息一会儿 95
第5章 神经网络 97
5.1 神经元模型 97
5.2 感知机与多层网络 98
5.3 误差逆传播算法 101
5.4 全局最小与局部极小 106
5.5 其他常见神经网络 108
5.5.1 RBF网络 108
5.5.2 ART网络 108
5.5.3 SOM网络 109
5.5.4 级联相关网络 110
5.5.5 Elman网络 111
5.5.6 Boltzmann机 111
5.6 深度学习 113
5.7 阅读材料 115
习题 116
参考文献 117
休息一会儿 120
第6章 支持向量机 121
6.1 间隔与支持向量 121
6.2 对偶问题 123
6.3 核函数 126
6.4 软间隔与正则化 129
6.5 支持向量回归 133
6.6 核方法 137
6.7 阅读材料 139
习题 141
参考文献 142
休息一会儿 145
第7章 贝叶斯分类器 147
7.1 贝叶斯决策论 147
7.2 极大似然估计 149
7.3 朴素贝叶斯分类器 150
7.4 半朴素贝叶斯分类器 154
7.5 贝叶斯网 156
7.5.1 结构 157
7.5.2 学习 159
7.5.3 推断 161
7.6 EM算法 162
7.7 阅读材料 164
习题 166
参考文献 167
休息一会儿 169
第8章 集成学习 171
8.1 个体与集成 171
8.2 Boosting 173
8.3 Bagging与随机森林 178
8.3.1 Bagging 178
8.3.2 随机森林 179
8.4 结合策略 181
8.4.1 平均法 181
8.4.2 投票法 182
8.4.3 学习法 183
8.5 多样性 185
8.5.1 误差--分歧分解 185
8.5.2 多样性度量 186
8.5.3 多样性增强 188
8.6 阅读材料 190
习题 192
参考文献 193
休息一会儿 196
第9章 聚类 197
9.1 聚类任务 197
9.2 性能度量 197
9.3 距离计算 199
9.4 原型聚类 202
9.4.1 k均值算法 202
9.4.2 学习向量量化 204
9.4.3 高斯混合聚类 206
9.5 密度聚类 211
9.6 层次聚类 214
9.7 阅读材料 217
习题 220
参考文献 221
休息一会儿 224
第10章 降维与度量学习 225
10.1 k近邻学习 225
10.2 低维嵌入 226
10.3 主成分分析 229
10.4 核化线性降维 232
10.5 流形学习 234
10.5.1 等度量映射 234
10.5.2 局部线性嵌入 235
10.6 度量学习 237
10.7 阅读材料 240
习题 242
参考文献 243
休息一会儿 246
第11章 特征选择与稀疏学习 247
11.1 子集搜索与评价 247
11.2 过滤式选择 249
11.3 包裹式选择 250
11.4 嵌入式选择与L$_1$正则化 252
11.5 稀疏表示与字典学习 254
11.6 压缩感知 257
11.7 阅读材料 260
习题 262
参考文献 263
休息一会儿 266
第12章 计算学习理论 267
12.1 基础知识 267
12.2 PAC学习 268
12.3 有限假设空间 270
12.3.1 可分情形 270
12.3.2 不可分情形 272
12.4 VC维 273
12.5 Rademacher复杂度 279
12.6 稳定性 284
12.7 阅读材料 287
习题 289
参考文献 290
休息一会儿 292
第13章 半监督学习 293
13.1 未标记样本 293
13.2 生成式方法 295
13.3 半监督SVM 298
13.4 图半监督学习 300
13.5 基于分歧的方法 304
13.6 半监督聚类 307
13.7 阅读材料 311
习题 313
参考文献 314
休息一会儿 317
第14章 概率图模型 319
14.1 隐马尔可夫模型 319
14.2 马尔可夫随机场 322
14.3 条件随机场 325
14.4 学习与推断 328
14.4.1 变量消去 328
14.4.2 信念传播 330
14.5 近似推断 331
14.5.1 MCMC采样 331
14.5.2 变分推断 334
14.6 话题模型 337
14.7 阅读材料 339
习题 341
参考文献 342
休息一会儿 345
第15章 规则学习 347
15.1 基本概念 347
15.2 序贯覆盖 349
15.3 剪枝优化 352
15.4 一阶规则学习 354
15.5 归纳逻辑程序设计 357
15.5.1 最小一般泛化 358
15.5.2 逆归结 359
15.6 阅读材料 363
习题 365
参考文献 366
休息一会儿 369
第16章 强化学习 371
16.1 任务与奖赏 371
16.2 $K$-摇臂赌博机 373
16.2.1 探索与利用 373
16.2.2 $\epsilon $-贪心 374
16.2.3 Softmax 375
16.3 有模型学习 377
16.3.1 策略评估 377
16.3.2 策略改进 379
16.3.3 策略迭代与值迭代 381
16.4 免模型学习 382
16.4.1 蒙特卡罗强化学习 383
16.4.2 时序差分学习 386
16.5 值函数近似 388
16.6 模仿学习 390
16.6.1 直接模仿学习 391
16.6.2 逆强化学习 391
16.7 阅读材料 393
习题 394
参考文献 395
休息一会儿 397
附录 399
A 矩阵 399
B 优化 403
C 概率分布 409
后记 417
索引 419
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
译者序
前言
第1章 引言
第2章 概念学习和一般到特殊序
第3章 决策树学习
第4章 人工神经网络
第5章 评估假设
第6章 贝叶斯学习
第7章 计算学习理论
第8章 基于实例的学习
第9章 遗传算法
第10章 学习规则集合
第11章 分析学习
第12章 归纳和分析学习的结合
第13章 增强学习
附录 符号约定
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实战
目　录

第一部分　分类
第1章　机器学习基础　　2
1.1 　何谓机器学习　　3
1.1.1 　传感器和海量数据　　4
1.1.2 　机器学习非常重要　　5
1.2 　关键术语　　5
1.3 　机器学习的主要任务　　7
1.4 　如何选择合适的算法　　8
1.5 　开发机器学习应用程序的步骤　　9
1.6 　Python语言的优势　　10
1.6.1 　可执行伪代码　　10
1.6.2 　Python比较流行　　10
1.6.3 　Python语言的特色　　11
1.6.4 　Python语言的缺点　　11
1.7 　NumPy函数库基础　　12
1.8 　本章小结　　13
第2章　k-近邻算法 　　15
2.1 　k-近邻算法概述　　15
2.1.1 　准备：使用Python导入数据　　17
2.1.2 　从文本文件中解析数据　　19
2.1.3 　如何测试分类器　　20
2.2 　示例：使用k-近邻算法改进约会网站的配对效果　　20
2.2.1 　准备数据：从文本文件中解析数据　　21
2.2.2 　分析数据：使用Matplotlib创建散点图　　23
2.2.3 　准备数据：归一化数值　　25
2.2.4 　测试算法：作为完整程序验证分类器　　26
2.2.5 　使用算法：构建完整可用系统　　27
2.3 　示例：手写识别系统　　28
2.3.1 　准备数据：将图像转换为测试向量　　29
2.3.2 　测试算法：使用k-近邻算法识别手写数字　　30
2.4 　本章小结　　31
第3章　决策树 　　32
3.1 　决策树的构造　　33
3.1.1 　信息增益　　35
3.1.2 　划分数据集　　37
3.1.3 　递归构建决策树　　39
3.2 　在Python中使用Matplotlib注解绘制树形图　　42
3.2.1 　Matplotlib注解　　43
3.2.2 　构造注解树　　44
3.3 　测试和存储分类器　　48
3.3.1 　测试算法：使用决策树执行分类　　49
3.3.2 　使用算法：决策树的存储　　50
3.4 　示例：使用决策树预测隐形眼镜类型　　50
3.5 　本章小结　　52
第4章　基于概率论的分类方法：朴素贝叶斯 　　53
4.1 　基于贝叶斯决策理论的分类方法　　53
4.2 　条件概率　　55
4.3 　使用条件概率来分类　　56
4.4 　使用朴素贝叶斯进行文档分类　　57
4.5 　使用Python进行文本分类　　58
4.5.1 　准备数据：从文本中构建词向量　　58
4.5.2 　训练算法：从词向量计算概率　　60
4.5.3 　测试算法：根据现实情况修改分类器　　62
4.5.4 　准备数据：文档词袋模型　　64
4.6 　示例：使用朴素贝叶斯过滤垃圾邮件　　64
4.6.1 　准备数据：切分文本　　65
4.6.2 　测试算法：使用朴素贝叶斯进行交叉验证　　66
4.7 　示例：使用朴素贝叶斯分类器从个人广告中获取区域倾向　　68
4.7.1 　收集数据：导入RSS源　　68
4.7.2 　分析数据：显示地域相关的用词　　71
4.8 　本章小结　　72
第5章　Logistic回归 　　73
5.1 　基于Logistic回归和Sigmoid函数的分类　　74
5.2 　基于最优化方法的最佳回归系数确定　　75
5.2.1 　梯度上升法　　75
5.2.2 　训练算法：使用梯度上升找到最佳参数　　77
5.2.3 　分析数据：画出决策边界　　79
5.2.4 　训练算法：随机梯度上升　　80
5.3 　示例：从疝气病症预测病马的死亡率　　85
5.3.1 　准备数据：处理数据中的缺失值　　85
5.3.2 　测试算法：用Logistic回归进行分类　　86
5.4 　本章小结　　88
第6章　支持向量机　　89
6.1 　基于最大间隔分隔数据　　89
6.2 　寻找最大间隔　　91
6.2.1 　分类器求解的优化问题　　92
6.2.2 　SVM应用的一般框架　　93
6.3 　SMO高效优化算法　　94
6.3.1 　Platt的SMO算法　　94
6.3.2 　应用简化版SMO算法处理小规模数据集　　94
6.4 　利用完整Platt SMO算法加速优化　　99
6.5 　在复杂数据上应用核函数　　105
6.5.1 　利用核函数将数据映射到高维空间　　106
6.5.2 　径向基核函数　　106
6.5.3 　在测试中使用核函数　　108
6.6 　示例：手写识别问题回顾　　111
6.7 　本章小结　　113
第7章　利用AdaBoost元算法提高分类
性能 　　115
7.1 　基于数据集多重抽样的分类器　　115
7.1.1 　bagging：基于数据随机重抽样的分类器构建方法　　116
7.1.2 　boosting　　116
7.2 　训练算法：基于错误提升分类器的性能　　117
7.3 　基于单层决策树构建弱分类器　　118
7.4 　完整AdaBoost算法的实现　　122
7.5 　测试算法：基于AdaBoost的分类　　124
7.6 　示例：在一个难数据集上应用AdaBoost　　125
7.7 　非均衡分类问题　　127
7.7.1 　其他分类性能度量指标：正确率、召回率及ROC曲线　　128
7.7.2 　基于代价函数的分类器决策控制　　131
7.7.3 　处理非均衡问题的数据抽样方法　　132
7.8 　本章小结　　132
第二部分　利用回归预测数值型数据
第8章　预测数值型数据：回归 　　136
8.1 　用线性回归找到最佳拟合直线　　136
8.2 　局部加权线性回归　　141
8.3 　示例：预测鲍鱼的年龄　　145
8.4 　缩减系数来“理解”数据　　146
8.4.1 　岭回归　　146
8.4.2 　lasso　　148
8.4.3 　前向逐步回归　　149
8.5 　权衡偏差与方差　　152
8.6 　示例：预测乐高玩具套装的价格　　153
8.6.1 　收集数据：使用Google购物的API　　153
8.6.2 　训练算法：建立模型　　155
8.7 　本章小结　　158
第9章　树回归　　159
9.1 　复杂数据的局部性建模　　159
9.2 　连续和离散型特征的树的构建　　160
9.3 　将CART算法用于回归　　163
9.3.1 　构建树　　163
9.3.2 　运行代码　　165
9.4 　树剪枝　　167
9.4.1 　预剪枝　　167
9.4.2 　后剪枝　　168
9.5 　模型树　　170
9.6 　示例：树回归与标准回归的比较　　173
9.7 　使用Python的Tkinter库创建GUI　　176
9.7.1 　用Tkinter创建GUI　　177
9.7.2 　集成Matplotlib和Tkinter　　179
9.8 　本章小结　　182
第三部分　无监督学习
第10章　利用K-均值聚类算法对未标注数据分组　　184
10.1 　K-均值聚类算法　　185
10.2 　使用后处理来提高聚类性能　　189
10.3 　二分K-均值算法　　190
10.4 　示例：对地图上的点进行聚类　　193
10.4.1 　Yahoo! PlaceFinder API　　194
10.4.2 　对地理坐标进行聚类　　196
10.5 　本章小结　　198
第11章　使用Apriori算法进行关联分析　　200
11.1 　关联分析　　201
11.2 　Apriori原理　　202
11.3 　使用Apriori算法来发现频繁集　　204
11.3.1 　生成候选项集　　204
11.3.2 　组织完整的Apriori算法　　207
11.4 　从频繁项集中挖掘关联规则　　209
11.5 　示例：发现国会投票中的模式　　212
11.5.1 　收集数据：构建美国国会投票记录的事务数据集　　213
11.5.2 　测试算法：基于美国国会投票记录挖掘关联规则　　219
11.6 　示例：发现毒蘑菇的相似特征　　220
11.7 　本章小结　　221
第12章　使用FP-growth算法来高效发现频繁项集　　223
12.1 　FP树：用于编码数据集的有效方式　　224
12.2 　构建FP树　　225
12.2.1 　创建FP树的数据结构　　226
12.2.2 　构建FP树　　227
12.3 　从一棵FP树中挖掘频繁项集　　231
12.3.1 　抽取条件模式基　　231
12.3.2 　创建条件FP树　　232
12.4 　示例：在Twitter源中发现一些共现词　　235
12.5 　示例：从新闻网站点击流中挖掘　　238
12.6 　本章小结　　239
第四部分　其他工具
第13章　利用PCA来简化数据　　242
13.1 　降维技术　　242
13.2 　PCA　　243
13.2.1 　移动坐标轴　　243
13.2.2 　在NumPy中实现PCA　　246
13.3 　示例：利用PCA对半导体制造数据降维　　248
13.4 　本章小结　　251
第14章　利用SVD简化数据　　252
14.1 　SVD的应用　　252
14.1.1 　隐性语义索引　　253
14.1.2 　推荐系统　　253
14.2 　矩阵分解　　254
14.3 　利用Python实现SVD　　255
14.4 　基于协同过滤的推荐引擎　　257
14.4.1 　相似度计算　　257
14.4.2 　基于物品的相似度还是基于用户的相似度？　　260
14.4.3 　推荐引擎的评价　　260
14.5 　示例：餐馆菜肴推荐引擎　　260
14.5.1 　推荐未尝过的菜肴　　261
14.5.2 　利用SVD提高推荐的效果　　263
14.5.3 　构建推荐引擎面临的挑战　　265
14.6 　基于SVD的图像压缩　　266
14.7 　本章小结　　268
第15章　大数据与MapReduce　　270
15.1 　MapReduce：分布式计算的框架　　271
15.2 　Hadoop流　　273
15.2.1 　分布式计算均值和方差的mapper　　273
15.2.2 　分布式计算均值和方差的reducer　　274
15.3 　在Amazon网络服务上运行Hadoop程序　　275
15.3.1 　AWS上的可用服务　　276
15.3.2 　开启Amazon网络服务之旅　　276
15.3.3 　在EMR上运行Hadoop作业　　278
15.4 　MapReduce上的机器学习　　282
15.5 　在Python中使用mrjob来自动化MapReduce　　283
15.5.1 　mrjob与EMR的无缝集成　　283
15.5.2 　mrjob的一个MapReduce脚本剖析　　284
15.6 　示例：分布式SVM的Pegasos算法　　286
15.6.1 　Pegasos算法　　287
15.6.2 　训练算法：用mrjob实现MapReduce版本的SVM　　288
15.7 　你真的需要MapReduce吗？　　292
15.8 　本章小结　　292
附录A 　Python入门　　294
附录B 　线性代数　　303
附录C 　概率论复习　　309
附录D 　资源　　312
索引　　313
版权声明　　316

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络与机器学习（原书第3版）
出版者的话
译者序
前言
缩写和符号
术语
第0章  导言1
0.1  什么是神经网络1
0.2  人类大脑4
0.3  神经元模型7
0.4  被看作有向图的神经网络10
0.5  反馈11
0.6  网络结构13
0.7  知识表示14
0.8  学习过程20
0.9  学习任务22
0.10  结束语27
注释和参考文献27
第1章  Rosenblatt感知器28
1.1  引言28
1.2  感知器28
1.3  感知器收敛定理29
1.4  高斯环境下感知器与贝叶斯分类器的关系33
1.5  计算机实验：模式分类36
1.6  批量感知器算法38
1.7  小结和讨论39
注释和参考文献39
习题40
第2章  通过回归建立模型28
2.1  引言41
2.2  线性回归模型：初步考虑41
2.3  参数向量的最大后验估计42
2.4  正则最小二乘估计和MAP估计之间的关系46
2.5  计算机实验：模式分类47
2.6  最小描述长度原则48
2.7  固定样本大小考虑50
2.8  工具变量方法53
2.9  小结和讨论54
注释和参考文献54
习题55
第3章  最小均方算法56
3.1  引言56
3.2  LMS算法的滤波结构56
3.3  无约束最优化：回顾58
3.4  维纳滤波器61
3.5  最小均方算法63
3.6  用马尔可夫模型来描画LMS算法和维纳滤波器的偏差64
3.7  朗之万方程：布朗运动的特点65
3.8  Kushner直接平均法66
3.9  小学习率参数下统计LMS学习理论67
3.10  计算机实验Ⅰ：线性预测68
3.11  计算机实验Ⅱ：模式分类69
3.12  LMS算法的优点和局限71
3.13  学习率退火方案72
3.14  小结和讨论73
注释和参考文献74
习题74
第4章  多层感知器77
4.1  引言77
4.2  一些预备知识78
4.3  批量学习和在线学习79
4.4  反向传播算法81
4.5  异或问题89
4.6  改善反向传播算法性能的试探法90
4.7  计算机实验：模式分类94
4.8  反向传播和微分95
4.9  Hessian矩阵及其在在线学习中的规则96
4.10  学习率的最优退火和自适应控制98
4.11  泛化102
4.12  函数逼近104
4.13  交叉验证107
4.14  复杂度正则化和网络修剪109
4.15  反向传播学习的优点和局限113
4.16  作为最优化问题看待的监督学习117
4.17  卷积网络126
4.18  非线性滤波127
4.19  小规模和大规模学习问题131
4.20  小结和讨论136
注释和参考文献137
习题138
第5章  核方法和径向基函数网络144
5.1  引言144
5.2  模式可分性的Cover定理144
5.3  插值问题148
5.4  径向基函数网络150
5.5  K-均值聚类152
5.6  权向量的递归最小二乘估计153
5.7  RBF网络的混合学习过程156
5.8  计算机实验：模式分类157
5.9  高斯隐藏单元的解释158
5.10  核回归及其与RBF网络的关系160
5.11  小结和讨论162
注释和参考文献164
习题165
第6章  支持向量机168
6.1  引言168
6.2  线性可分模式的最优超平面168
6.3  不可分模式的最优超平面173
6.4  使用核方法的支持向量机176
6.5  支持向量机的设计178
6.6  XOR问题179
6.7  计算机实验:模式分类181
6.8  回归：鲁棒性考虑184
6.9  线性回归问题的最优化解184
6.10  表示定理和相关问题187
6.11  小结和讨论191
注释和参考文献192
习题193
第7章  正则化理论197
7.1  引言197
7.2  良态问题的Hadamard条件198
7.3  Tikhonov正则化理论198
7.4  正则化网络205
7.5  广义径向基函数网络206
7.6  再论正则化最小二乘估计209
7.7  对正则化的附加要点211
7.8  正则化参数估计212
7.9  半监督学习215
7.10  流形正则化：初步的考虑216
7.11  可微流形217
7.12  广义正则化理论220
7.13  光谱图理论221
7.14  广义表示定理222
7.15  拉普拉斯正则化最小二乘算法223
7.16  用半监督学习对模式分类的实验225
7.17  小结和讨论227
注释和参考文献228
习题229
第8章  主分量分析232
8.1  引言232
8.2  自组织原则232
8.3  自组织的特征分析235
8.4  主分量分析：扰动理论235
8.5  基于Hebb的最大特征滤波器241
8.6  基于Hebb的主分量分析247
8.7  计算机实验：图像编码251
8.8  核主分量分析252
8.9  自然图像编码中的基本问题256
8.10  核Hebb算法257
8.11  小结和讨论260
注释和参考文献262
习题264
第9章  自组织映射268
9.1  引言268
9.2  两个基本的特征映射模型269
9.3  自组织映射270
9.4  特征映射的性质275
9.5  计算机实验Ⅰ：利用SOM解网格动力学问题280
9.6  上下文映射281
9.7  分层向量量化283
9.8  核自组织映射285
9.9  计算机实验Ⅱ：利用核SOM解点阵动力学问题290
9.10  核SOM和相对熵之间的关系291
9.11  小结和讨论293
注释和参考文献294
习题295
第10章  信息论学习模型299
10.1  引言299
10.2  熵300
10.3  最大熵原则302
10.4  互信息304
10.5  相对熵306
10.6  系词308
10.7  互信息作为最优化的目标函数310
10.8  最大互信息原则311
10.9  最大互信息和冗余减少314
10.10  空间相干特征316
10.11  空间非相干特征318
10.12  独立分量分析320
10.13  自然图像的稀疏编码以及与ICA编码的比较324
10.14  独立分量分析的自然梯度学习326
10.15  独立分量分析的最大似然估计332
10.16  盲源分离的最大熵学习334
10.17  独立分量分析的负熵最大化337
10.18  相关独立分量分析342
10.19  速率失真理论和信息瓶颈347
10.20  数据的最优流形表达350
10.21  计算机实验：模式分类354
10.22  小结和讨论354
注释和参考文献356
习题361
第11章  植根于统计力学的随机方法366
11.1  引言366
11.2  统计力学367
11.3  马尔可夫链368
11.4  Metropolis算法374
11.5  模拟退火375
11.6  Gibbs抽样377
11.7  Boltzmann机378
11.8  logistic信度网络382
11.9  深度信度网络383
11.10  确定性退火385
11.11  和EM算法的类比389
11.12  小结和讨论390
注释和参考文献390
习题392
第12章  动态规划396
12.1  引言396
12.2  马尔可夫决策过程397
12.3  Bellman最优准则399
12.4  策略迭代401
12.5  值迭代402
12.6  逼近动态规划：直接法406
12.7  时序差分学习406
12.8  Q学习410
12.9  逼近动态规划：非直接法412
12.10  最小二乘策略评估414
12.11  逼近策略迭代417
12.12  小结和讨论419
注释和参考文献421
习题422
第13章  神经动力学425
13.1  引言425
13.2  动态系统426
13.3  平衡状态的稳定性428
13.4  吸引子432
13.5  神经动态模型433
13.6  作为递归网络范例的吸引子操作435
13.7  Hopfield模型435
13.8  Cohen-Grossberg定理443
13.9  盒中脑状态模型445
13.10  奇异吸引子和混沌448
13.11  混沌过程的动态重构452
13.12  小结和讨论455
注释和参考文献457
习题458
第14章  动态系统状态估计的贝叶斯滤波461
14.1  引言461
14.2  状态空间模型462
14.3  卡尔曼滤波器464
14.4  发散现象及平方根滤波469
14.5  扩展的卡尔曼滤波器474
14.6  贝叶斯滤波器477
14.7  数值积分卡尔曼滤波器:基于卡尔曼滤波器480
14.8  粒子滤波器484
14.9  计算机实验：扩展的卡尔曼滤波器和粒子滤波器对比评价490
14.10  大脑功能建模中的
卡尔曼滤波493
14.11  小结和讨论494
注释和参考文献496
习题497
第15章  动态驱动递归网络501
15.1  引言501
15.2  递归网络体系结构502
15.3  通用逼近定理505
15.4  可控性和可观测性507
15.5  递归网络的计算能力510
15.6  学习算法511
15.7  通过时间的反向传播512
15.8  实时递归学习515
15.9  递归网络的消失梯度519
15.10  利用非线性逐次状态估计的递归网络监督学习框架521
15.11  计算机实验：Mackay-Glass吸引子的动态重构526
15.12  自适应考虑527
15.13  实例学习：应用于神经控制的模型参考529
15.14  小结和讨论530
注释和参考文献533
习题534
参考文献538
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络与机器学习（原书第3版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>分布式机器学习：算法、理论与实践
序言一
序言二
前　言
作者介绍
第1章　绪论/ 1
1.1　人工智能及其飞速发展/ 2
1.2　大规模、分布式机器学习/ 4
1.3　本书的安排/ 6
参考文献/ 7
第2章　机器学习基础/ 9
2.1　机器学习的基本概念/ 10
2.2　机器学习的基本流程/ 13
2.3　常用的损失函数/ 16
2.3.1　Hinge损失函数/ 16
2.3.2　指数损失函数/ 16
2.3.3　交叉熵损失函数/ 17
2.4　常用的机器学习模型/ 18
2.4.1　线性模型/ 18
2.4.2　核方法与支持向量机/ 18
2.4.3　决策树与Boosting/ 21
2.4.4　神经网络/ 23
2.5　常用的优化方法/ 32
2.6　机器学习理论/ 33
2.6.1　机器学习算法的泛化误差/ 34
2.6.2　泛化误差的分解/ 34
2.6.3　基于容度的估计误差的上界/ 35
2.7　总结/ 36
参考文献/ 36
第3章　分布式机器学习框架/ 41
3.1　大数据与大模型的挑战/ 42
3.2　分布式机器学习的基本流程/ 44
3.3　数据与模型划分模块/ 46
3.4　单机优化模块/ 48
3.5　通信模块/ 48
3.5.1　通信的内容/ 48
3.5.2　通信的拓扑结构/ 49
3.5.3　通信的步调/ 51
3.5.4　通信的频率/ 52
3.6　数据与模型聚合模块/ 53
3.7　分布式机器学习理论/ 54
3.8　分布式机器学习系统/ 55
3.9　总结/ 56
参考文献/ 57
第4章　单机优化之确定性算法/ 61
4.1　基本概述/ 62
4.1.1　机器学习的优化框架/ 62
4.1.2　优化算法的分类和发展历史/ 65
4.2　一阶确定性算法/ 67
4.2.1　梯度下降法/ 67
4.2.2　投影次梯度下降法/ 69
4.2.3　近端梯度下降法/ 70
4.2.4　Frank-Wolfe算法/ 71
4.2.5　Nesterov加速法/ 72
4.2.6　坐标下降法/ 75
4.3　二阶确定性算法/ 75
4.3.1　牛顿法/ 76
4.3.2　拟牛顿法/ 77
4.4　对偶方法/ 78
4.5　总结/ 81
参考文献/ 8
第5章　单机优化之随机算法/ 85
5.1　基本随机优化算法/ 86
5.1.1　随机梯度下降法/ 86
5.1.2　随机坐标下降法/ 88
5.1.3　随机拟牛顿法/ 91
5.1.4　随机对偶坐标上升法/ 93
5.1.5　小结/ 95
5.2　随机优化算法的改进/ 96
5.2.1　方差缩减方法/ 96
5.2.2　算法组合方法/ 100
5.3　非凸随机优化算法/ 101
5.3.1　Ada系列算法/ 102
5.3.2　非凸理论分析/ 104
5.3.3　逃离鞍点问题/ 106
5.3.4　等级优化算法/ 107
5.4　总结/ 109
参考文献/ 109
第6章　数据与模型并行/ 113
6.1　基本概述/ 114
6.2　计算并行模式/ 117
6.3　数据并行模式/ 119
6.3.1　数据样本划分/ 120
6.3.2　数据维度划分/ 123
6.4　模型并行模式/ 123
6.4.1　线性模型/ 123
6.4.2　神经网络/ 127
6.5　总结/ 133
参考文献/ 133
第7章　通信机制/ 135
7.1　基本概述/ 136
7.2　通信的内容/ 137
7.2.1　参数或参数的更新/ 137
7.2.2　计算的中间结果/ 137
7.2.3　讨论/ 138
7.3　通信的拓扑结构/ 139
7.3.1　基于迭代式MapReduce/AllReduce的通信拓扑/ 140
7.3.2　基于参数服务器的通信拓扑/ 142
7.3.3　基于数据流的通信拓扑/ 143
7.3.4　讨论/ 145
7.4　通信的步调/ 145
7.4.1　同步通信/ 146
7.4.2　异步通信/ 147
7.4.3　同步和异步的平衡/ 148
7.4.4　讨论/ 150
7.5　通信的频率/ 150
7.5.1　时域滤波/ 150
7.5.2　空域滤波/ 153
7.5.3　讨论/ 155
7.6　总结/ 156
参考文献/ 156
第8章　数据与模型聚合/ 159
8.1　基本概述/ 160
8.2　基于模型加和的聚合方法/ 160
8.2.1　基于全部模型加和的聚合/ 160
8.2.2　基于部分模型加和的聚合/ 162
8.3　基于模型集成的聚合方法/ 167
8.3.1　基于输出加和的聚合/ 168
8.3.2　基于投票的聚合/ 171
8.4　总结/ 174
参考文献/ 174
第9章　分布式机器学习算法/ 177
9.1　基本概述/ 178
9.2　同步算法/ 179
9.2.1　同步SGD方法/ 179
9.2.2　模型平均方法及其改进/ 182
9.2.3　ADMM算法/ 183
9.2.4　弹性平均SGD算法/ 185
9.2.5　讨论/ 186
9.3　异步算法/ 187
9.3.1　异步SGD/ 187
9.3.2　Hogwild!算法/ 189
9.3.3　Cyclades算法/ 190
9.3.4　带延迟处理的异步算法/ 192
9.3.5　异步方法的进一步加速/ 199
9.3.6　讨论/ 199
9.4　同步和异步的对比与融合/ 199
9.4.1　同步和异步算法的实验对比/ 199
9.4.2　同步和异步的融合/ 201
9.5　模型并行算法/ 203
9.5.1　DistBelief/ 203
9.5.2　AlexNet/ 204
9.6　总结/ 205
参考文献/ 205
第10章　分布式机器学习理论/ 209
10.1　基本概述/ 210
10.2　收敛性分析/ 210
10.2.1　优化目标和算法/ 211
10.2.2　数据和模型并行/ 213
10.2.3　同步和异步/ 215
10.3　加速比分析/ 217
10.3.1　从收敛速率到加速比/ 218
10.3.2　通信量的下界/ 219
10.4　泛化分析/ 221
10.4.1　优化的局限性/ 222
10.4.2　具有更好泛化能力的非凸优化算法/ 224
10.5　总结/ 226
参考文献/ 226
第11章　分布式机器学习系统/ 229
11.1　基本概述/ 230
11.2　基于IMR的分布式机器学习系统/ 231
11.2.1　IMR和Spark/ 231
11.2.2　Spark MLlib/ 234
11.3　基于参数服务器的分布式机器学习系统/ 236
11.3.1　参数服务器/ 236
11.3.2　Multiverso参数服务器/ 237
11.4　基于数据流的分布式机器学习系统/ 241
11.4.1　数据流/ 241
11.4.2　TensorFlow数据流系统/ 243
11.5　实战比较/ 248
11.6　总结/ 252
参考文献/ 252
第12章　结语/ 255
12.1　全书总结/ 256
12.2　未来展望/ 257
索引/ 260
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>分布式机器学习：算法、理论与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
前言	1
第1章 使用R语言	9
R与机器学习	10
第2章 数据分析	36
分析与验证	36
什么是数据	37
推断数据的类型	40
推断数据的含义	42
数值摘要表	43
均值、中位数、众数	44
分位数	46
标准差和方差	47
可视化分析数据	49
列相关的可视化	68
第3章 分类：垃圾过滤	77
非此即彼：二分类	77
漫谈条件概率	81
试写第一个贝叶斯垃圾分类器	82
第4章 排序：智能收件箱	97
次序未知时该如何排序	97
按优先级给邮件排序	98
实现一个智能收件箱	102
第5章 回归模型：预测网页访问量	128
回归模型简介	128
预测网页流量	142
定义相关性	152
第6章 正则化：文本回归	155
数据列之间的非线性关系：超越直线	155
避免过拟合的方法	164
文本回归	174
第7章 优化：密码破译	182
优化简介	182
岭回归	188
密码破译优化问题	193
第8章 PCA：构建股票市场指数	203
无监督学习	203
主成分分析	204
第9章 MDS：可视化地研究参议员相似性	212
基于相似性聚类	212
如何对美国参议员做聚类	219
第10章 kNN：推荐系统	229
k近邻算法	229
R语言程序包安装数据	235
第11章 分析社交图谱	239
社交网络分析	239
用黑客的方法研究Twitter的社交关系图数据	244
分析Twitter社交网络	252
第12章 模型比较	270
SVM：支持向量机	270
算法比较	280
参考文献	287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>图解机器学习
第I部分 绪 论
第1章 什么是机器学习 2
1.1 学习的种类 2
1.2 机器学习任务的例子 4
1.3 机器学习的方法 8
第2章 学习模型 12
2.1 线性模型 12
2.2 核模型 15
2.3 层级模型 17
第II部分 有监督回归
第3章 最小二乘学习法 22
3.1 最小二乘学习法 22
3.2 最小二乘解的性质 25
3.3 大规模数据的学习算法 27
第4章带有约束条件的最小二乘法 31
4.1 部分空间约束的最小二乘学习法 31
4.2 ｌ2 约束的最小二乘学习法 33
4.3 模型选择 37
第5章 稀疏学习 43
5.1 ｌ1 约束的最小二乘学习法 43
5.2 ｌ1 约束的最小二乘学习的求解方法 45
5.3 通过稀疏学习进行特征选择 50
5.4 ｌp约束的最小二乘学习法 51
5.5 ｌ1+ｌ2 约束的最小二乘学习法 52
第6章 鲁棒学习 55
6.1 ｌ1 损失最小化学习 56
6.2 Huber损失最小化学习 58
6.3 图基损失最小化学习 63
6.4 ｌ1 约束的Huber损失最小化学习 65
第III部分 有监督分类
第7章 基于最小二乘法的分类 70
7.1 最小二乘分类 70
7.2 0/1 损失和间隔 73
7.3 多类别的情形 76
第8章 支持向量机分类 80
8.1 间隔最大化分类 80
8.2 支持向量机分类器的求解方法 83
8.3 稀疏性 86
8.4 使用核映射的非线性模型 88
8.5 使用Hinge损失最小化学习来解释 90
8.6 使用Ramp损失的鲁棒学习 93
第9章 集成分类 98
9.1 剪枝分类 98
9.2 Bagging学习法 101
9.3 Boosting 学习法 105
第10章 概率分类法 112
10.1 Logistic回归 112
10.2 最小二乘概率分类 116
第11 章序列数据的分类 121
11.1 序列数据的模型化 122
11.2 条件随机场模型的学习 125
11.3 利用条件随机场模型对标签序列进行预测 128
第IV部分 无监督学习
第12章 异常检测 132
12.1 局部异常因子 132
12.2 支持向量机异常检测 135
12.3 基于密度比的异常检测 137
第13章 无监督降维 143
13.1 线性降维的原理 144
13.2 主成分分析 146
13.3 局部保持投影 148
13.4 核函数主成分分析 152
13.5 拉普拉斯特征映射 155
第14章 聚类 158
14.1 K均值聚类 158
14.2 核K均值聚类 160
14.3 谱聚类 161
14.4 调整参数的自动选取 163
第V部分 新兴机器学习算法
第15章 在线学习 170
15.1 被动攻击学习 170
15.2 适应正则化学习 176
第16章 半监督学习 181
16.1 灵活应用输入数据的流形构造 182
16.2 拉普拉斯正则化最小二乘学习的求解方法 183
16.3 拉普拉斯正则化的解释 186
第17章 监督降维 188
17.1 与分类问题相对应的判别分析 188
17.2 充分降维 195
第18章 迁移学习 197
18.1 协变量移位下的迁移学习 197
18.2 类别平衡变化下的迁移学习 204
第19章 多任务学习 212
19.1 使用最小二乘回归的多任务学习 212
19.2 使用最小二乘概率分类器的多任务学习 215
19.3 多次维输出函数的学习 216
第VI部分 结 语
第20章 总结与展望 222
参考文献 225
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>图解机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>美团机器学习实践
第一部分 通用流程
第　1章 问题建模　2
1.1　评估指标　3
1.1.1　分类指标　4
1.1.2　回归指标　7
1.1.3　排序指标　9
1.2　样本选择　10
1.2.1　数据去噪　11
1.2.2　采样　12
1.2.3　原型选择和训练集选择　13
1.3　交叉验证　14
1.3.1　留出法　14
1.3.2　K折交叉验证　15
1.3.3　自助法　16
参考文献　17
第　2章 特征工程　18
2.1　特征提取　18
2.1.1　探索性数据分析　19
2.1.2　数值特征　20
2.1.3　类别特征　22
2.1.4　时间特征　24
2.1.5　空间特征　25
2.1.6　文本特征　25
2.2　特征选择　27
2.2.1　过滤方法　28
2.2.2　封装方法　31
2.2.3　嵌入方法　31
2.2.4　小结　32
2.2.5　工具介绍　33
参考文献　33
第3章　常用模型　35
3.1　逻辑回归　35
3.1.1　逻辑回归原理　35
3.1.2　逻辑回归应用　38
3.2　场感知因子分解机　39
3.2.1　因子分解机原理　39
3.2.2　场感知因子分解机原理　40
3.2.3　场感知因子分解机的应用　41
3.3　梯度提升树　42
3.3.1　梯度提升树原理　42
3.3.2　梯度提升树的应用　44
参考文献　44
第4章　模型融合　45
4.1　理论分析　46
4.1.1　融合收益　46
4.1.2　模型误差 分歧分解　46
4.1.3　模型多样性度量　48
4.1.4　多样性增强　49
4.2　融合方法　50
4.2.1　平均法　50
4.2.2　投票法　52
4.2.3　Bagging　54
4.2.4　Stacking　55
4.2.5　小结　56
参考文献　57
第二部分　数据挖掘
第5章　用户画像　60
5.1　什么是用户画像　60
5.2　用户画像数据挖掘　63
5.2.1　画像数据挖掘整体架构　63
5.2.2　用户标识　65
5.2.3　特征数据　67
5.2.4　样本数据　68
5.2.5　标签建模　69
5.3　用户画像应用　83
5.3.1　用户画像实时查询系统　83
5.3.2　人群画像分析系统　87
5.3.3　其他系统　90
5.3.4　线上应用效果　91
5.4　小结　91
参考文献　91
第6章　POI实体链接　92
6.1　问题的背景与难点　92
6.2　国内酒店POI实体链接解决方案　94
6.2.1　酒店POI实体链接　94
6.2.2　数据清洗　96
6.2.3　特征生成　97
6.2.4　模型选择与效果评估　100
6.2.5　索引粒度的配置　101
6.3　其他场景的策略调整　101
6.4　小结　103
第7章　评论挖掘　104
7.1　评论挖掘的背景　104
7.1.1　评论挖掘的粒度　105
7.1.2　评论挖掘的维度　105
7.1.3　评论挖掘的整合思考　106
7.2　评论标签提取　106
7.2.1　数据的获取及预处理　107
7.2.2　无监督的标签提取方法　109
7.2.3　基于深度学习的标签提取方法　111
7.3　标签情感分析　113
7.3.1　评论标签情感分析的特殊性　113
7.3.2　基于深度学习的情感分析方法　115
7.3.3　评论标签情感分析的后续优 化与思考　118
7.4　评论挖掘的未来应用及实践　119
7.5　小结　119
参考文献　119
第三部分　搜索和推荐
第8章　O2O场景下的查询理解与 用户引导　122
8.1　现代搜索引擎原理　123
8.2　精确理解查询　124
8.2.1　用户查询意图的定义与识别　125
8.2.2　查询实体识别与结构化　129
8.2.3　召回策略的变迁　130
8.2.4　查询改写　131
8.2.5　词权重与相关性计算　134
8.2.6　类目相关性与人工标注　135
8.2.7　查询理解小结　136
8.3　引导用户完成搜索　137
8.3.1　用户引导的产品定义与衡量 标准　137
8.3.2　搜索前的引导——查询词 推荐　140
8.3.3　搜索中的引导——查询补全　143
8.3.4　搜索后的引导——相关搜索　145
8.3.5　效率提升与效果提升　145
8.3.6　用户引导小结　149
8.4　小结　149
参考文献　150
第9章　O2O场景下排序的特点　152
9.1　系统概述　154
9.2　在线排序服务　154
9.3　多层正交A/B测试　155
9.4　特征获取　155
9.5　离线调研系统　156
9.6　特征工程　156
9.7　排序模型　157
9.8　场景化排序　160
9.9　小结　165
第　10章 推荐在O2O场景的应用　166
10.1　典型的O2O推荐场景　166
10.2　O2O推荐场景特点　167
10.2.1　O2O场景的地理位置因素　168
10.2.2　O2O场景的用户历史行为　168
10.2.3　O2O场景的实时推荐　169
10.3　美团推荐实践——推荐框架　169
10.4　美团推荐实践——推荐召回　170
10.4.1　基于协同过滤的召回　171
10.4.2　基于位置的召回　171
10.4.3　基于搜索查询的召回　172
10.4.4　基于图的召回　172
10.4.5　基于实时用户行为的召回　172
10.4.6　替补策略　172
10.5　美团推荐实践——推荐排序　173
10.5.1　排序特征　173
10.5.2　排序样本　174
10.5.3　排序模型　175
10.6　推荐评价指标　176
参考文献　176
第四部分　计算广告
第　11章 O2O场景下的广告营销　178
11.1　O2O场景下的广告业务特点　178
11.2　商户、用户和平台三者利益平衡　180
11.2.1　商户效果感知　180
11.2.2　用户体验　181
11.2.3　平台收益　182
11.3　O2O广告机制设计　183
11.3.1　广告位设定　183
11.3.2　广告召回机制　183
11.3.3　广告排序机制　184
11.4　O2O推送广告　187
11.5　O2O广告系统工具　190
11.5.1　面向开发人员的系统工具　190
11.5.2　面向广告主和运营人员的 工具　192
11.6　小结　194
参考文献　194
第　12章 用户偏好和损失建模　196
12.1　如何定义用户偏好　196
12.1.1　什么是用户偏好　196
12.1.2　如何衡量用户偏好　196
12.1.3　对不同POI 的偏好　197
12.1.4　用户对 POI 偏好的衡量　197
12.2　广告价值与偏好损失的兑换　198
12.2.1　优化目标　199
12.2.2　模型建模　199
12.3　Pairwise 模型学习　201
12.3.1　GBRank　202
12.3.2　RankNet　204
参考文献　205
第五部分　深度学习
第　13章 深度学习概述　208
13.1　深度学习技术发展历程　209
13.2　深度学习基础结构　211
13.3　深度学习研究热点　216
13.3.1　基于深度学习的生成式模型　216
13.3.2　深度强化学习　218
参考文献　219
第　14章 深度学习在文本领域的应用　220
14.1　基于深度学习的文本匹配　221
14.2　基于深度学习的排序模型　231
14.2.1　排序模型简介　231
14.2.2　深度学习排序模型的演进　232
14.2.3　美团的深度学习排序模型 尝试　235
14.3　小结　237
参考文献　237
第　15章 深度学习在计算机视觉中的 应用　238
15.1　基于深度学习的OCR　238
15.1.1　OCR技术发展历程　239
15.1.2　基于深度学习的文字检测　244
15.1.3　基于序列学习的文字识别　248
15.1.4　小结　251
15.2　基于深度学习的图像智能审核　251
15.2.1　基于深度学习的水印检测　252
15.2.2　明星脸识别　254
15.2.3　色情图片检测　257
15.2.4　场景分类　257
15.3　基于深度学习的图像质量排序　259
15.3.1　图像美学质量评价　260
15.3.2　面向点击预测的图像质量 评价　260
15.4　小结　263
参考文献　264
第六部分　算法工程
第　16章 大规模机器学习　268
16.1　并行计算编程技术　268
16.1.1　向量化　269
16.1.2　多核并行OpenMP　270
16.1.3　GPU编程　272
16.1.4　多机并行MPI　273
16.1.5　并行编程技术小结　276
16.2　并行计算模型　276
16.2.1　BSP　277
16.2.2　SSP　279
16.2.3　ASP　280
16.2.4　参数服务器　281
16.3　并行计算案例　284
16.3.1　XGBoost并行库Rabit　284
16.3.2　MXNet并行库PS-Lite　286
16.4　美团并行计算机器学习平台　287
参考文献　289
第　17章 特征工程和实验平台　290
17.1　特征平台　290
17.1.1　特征生产　290
17.1.2　特征上线　293
17.1.3　在线特征监控　301
17.2　实验管理平台　302
17.2.1　实验平台概述　302
17.2.2　美团实验平台——Gemini　304
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>美团机器学习实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>白话大数据与机器学习
前言
第1章　大数据产业 1
1.1　大数据产业现状 1
1.2　对大数据产业的理解 2
1.3　大数据人才 3
1.3.1　供需失衡 3
1.3.2　人才方向 3
1.3.3　环节和工具 5
1.3.4　门槛障碍 6
1.4　小结 8
第2章　步入数据之门 9
2.1　什么是数据 9
2.2　什么是信息 10
2.3　什么是算法 12
2.4　统计、概率和数据挖掘 13
2.5　什么是商业智能 13
2.6　小结 14
第3章　排列组合与古典概型 15
3.1　排列组合的概念 16
3.1.1　公平的决断——扔硬币 16
3.1.2　非古典概型 17
3.2　排列组合的应用示例 18
3.2.1　双色球彩票 18
3.2.2　购车摇号 20
3.2.3　德州扑克 21
3.3　小结 25
第4章　统计与分布 27
4.1　加和值、平均值和标准差 27
4.1.1　加和值 28
4.1.2　平均值 29
4.1.3　标准差 30
4.2　加权均值 32
4.2.1　混合物定价 32
4.2.2　决策权衡 34
4.3　众数、中位数 35
4.3.1　众数 36
4.3.2　中位数 37
4.4　欧氏距离 37
4.5　曼哈顿距离 39
4.6　同比和环比 41
4.7　抽样 43
4.8　高斯分布 45
4.9　泊松分布 49
4.10　伯努利分布 52
4.11　小结 54
第5章　指标 55
5.1　什么是指标 55
5.2　指标化运营 58
5.2.1　指标的选择 58
5.2.2　指标体系的构建 62
5.3　小结 63
第6章　信息论 64
6.1　信息的定义 64
6.2　信息量 65
6.2.1　信息量的计算 65
6.2.2　信息量的理解 66
6.3　香农公式 68
6.4　熵 70
6.4.1　热力熵 70
6.4.2　信息熵 72
6.5　小结 75
第7章　多维向量空间 76
7.1　向量和维度 76
7.1.1　信息冗余 77
7.1.2　维度 79
7.2　矩阵和矩阵计算 80
7.3　数据立方体 83
7.4　上卷和下钻 85
7.5　小结 86
第8章　回归 87
8.1　线性回归 87
8.2　拟合 88
8.3　残差分析 94
8.4　过拟合 99
8.5　欠拟合 100
8.6　曲线拟合转化为线性拟合 101
8.7　小结 104
第9章　聚类 105
9.1　K-Means算法 106
9.2　有趣模式 109
9.3　孤立点 110
9.4　层次聚类 110
9.5　密度聚类 113
9.6　聚类评估 116
9.6.1　聚类趋势 117
9.6.2　簇数确定 119
9.6.3　测定聚类质量 121
9.7　小结 124
第10章　分类 125
10.1　朴素贝叶斯 126
10.1.1　天气的预测 128
10.1.2　疾病的预测 130
10.1.3　小结 132
10.2　决策树归纳 133
10.2.1　样本收集 135
10.2.2　信息增益 136
10.2.3　连续型变量 137
10.3　随机森林 140
10.4　隐马尔可夫模型 141
10.4.1　维特比算法 144
10.4.2　前向算法 151
10.5　支持向量机SVM 154
10.5.1　年龄和好坏 154
10.5.2　“下刀”不容易 157
10.5.3　距离有多远 158
10.5.4　N维度空间中的距离 159
10.5.5　超平面怎么画 160
10.5.6　分不开怎么办 160
10.5.7　示例 163
10.5.8　小结 164
10.6　遗传算法 164
10.6.1　进化过程 164
10.6.2　算法过程 165
10.6.3　背包问题 165
10.6.4　极大值问题 173
10.7　小结 181
第11章　关联分析 183
11.1　频繁模式和Apriori算法 184
11.1.1　频繁模式 184
11.1.2　支持度和置信度 185
11.1.3　经典的Apriori算法 187
11.1.4　求出所有频繁模式 190
11.2　关联分析与相关性分析 192
11.3　稀有模式和负模式 193
11.4　小结 194
第12章　用户画像 195
12.1　标签 195
12.2　画像的方法 196
12.2.1　结构化标签 196
12.2.2　非结构化标签 198
12.3　利用用户画像 203
12.3.1　割裂型用户画像 203
12.3.2　紧密型用户画像 204
12.3.3　到底“像不像” 204
12.4　小结 205
第13章　推荐算法 206
13.1　推荐思路 206
13.1.1　贝叶斯分类 206
13.1.2　利用搜索记录 207
13.2　User-based CF 209
13.3　Item-based CF 211
13.4　优化问题 215
13.5　小结 217
第14章　文本挖掘 218
14.1　文本挖掘的领域 218
14.2　文本分类 219
14.2.1　Rocchio算法 220
14.2.2　朴素贝叶斯算法 223
14.2.3　K-近邻算法 225
14.2.4　支持向量机SVM算法 226
14.3　小结 227
第15章　人工神经网络 228
15.1　人的神经网络 228
15.1.1　神经网络结构 229
15.1.2　结构模拟 230
15.1.3　训练与工作 231
15.2　FANN库简介 233
15.3　常见的神经网络 235
15.4　BP神经网络 235
15.4.1　结构和原理 236
15.4.2　训练过程 237
15.4.3　过程解释 240
15.4.4　示例 240
15.5　玻尔兹曼机 244
15.5.1　退火模型 244
15.5.2　玻尔兹曼机 245
15.6　卷积神经网络 247
15.6.1　卷积 248
15.6.2　图像识别 249
15.7　深度学习 255
15.8　小结 256
第16章　大数据框架简介 257
16.1　著名的大数据框架 257
16.2　Hadoop框架 258
16.2.1　MapReduce原理 259
16.2.2　安装Hadoop 261
16.2.3　经典的WordCount 264
16.3　Spark 框架 269
16.3.1　安装Spark 270
16.3.2　使用Scala计算WordCount 271
16.4　分布式列存储框架 272
16.5　PrestoDB——神奇的CLI 273
16.5.1　Presto为什么那么快 273
16.5.2　安装Presto 274
16.6　小结 277
第17章　系统架构和调优 278
17.1　速度——资源的配置 278
17.1.1　思路一：逻辑层面的优化 279
17.1.2　思路二：容器层面的优化 279
17.1.3　思路三：存储结构层面的优化 280
17.1.4　思路四：环节层面的优化 280
17.1.5　资源不足 281
17.2　稳定——资源的可用 282
17.2.1　借助云服务 282
17.2.2　锁分散 282
17.2.3　排队 283
17.2.4　谨防“雪崩” 283
17.3　小结 285
第18章　数据解读与数据的价值 286
18.1　运营指标 286
18.1.1　互联网类型公司常用指标 287
18.1.2　注意事项 288
18.2　AB测试 289
18.2.1　网页测试 290
18.2.2　方案测试 290
18.2.3　灰度发布 292
18.2.4　注意事项 293
18.3　数据可视化 295
18.3.1　图表 295
18.3.2　表格 299
18.4　多维度——大数据的灵魂 299
18.4.1　多大算大 299
18.4.2　大数据网络 300
18.4.3　去中心化才能活跃 301
18.4.4　数据会过剩吗 302
18.5　数据变现的场景 303
18.5.1　数据价值的衡量的讨论 303
18.5.2　场景1：征信数据 307
18.5.3　场景2：宏观数据 308
18.5.4　场景3：画像数据 309
18.6　小结 310
附录A　VMware Workstation的安装 311
附录B　CentOS虚拟机的安装方法 314
附录C　Python语言简介 318
附录D　Scikit-learn库简介 323
附录E　FANN for Python安装 324
附录F　群众眼中的大数据 325
写作花絮 327
参考文献 329
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>白话大数据与机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习
第1章　Spark的环境搭建与运行　　1
1.1　Spark的本地安装与配置　　2
1.2　Spark集群　　3
1.3　Spark编程模型　　4
1.3.1　SparkContext类与SparkConf 类　　4
1.3.2　Spark shell　　5
1.3.3　弹性分布式数据集　　6
1.3.4　广播变量和累加器　　10
1.4　Spark Scala编程入门　　11
1.5　Spark Java编程入门　　14
1.6　Spark Python编程入门　　17
1.7　在Amazon EC2上运行Spark　　18
1.8　小结　　23
第2章　设计机器学习系统　　24
2.1　MovieStream介绍　　24
2.2　机器学习系统商业用例　　25
2.2.1　个性化　　26
2.2.2　目标营销和客户细分　　26
2.2.3　预测建模与分析　　26
2.3　机器学习模型的种类　　27
2.4　数据驱动的机器学习系统的组成　　27
2.4.1　数据获取与存储　　28
2.4.2　数据清理与转换　　28
2.4.3　模型训练与测试回路　　29
2.4.4　模型部署与整合　　30
2.4.5　模型监控与反馈　　30
2.4.6　批处理或实时方案的选择　　31
2.5　机器学习系统架构　　31
2.6　小结　　33
第3章　Spark上数据的获取、处理与准备　　34
3.1　获取公开数据集　　35
3.2　探索与可视化数据　　37
3.2.1　探索用户数据　　38
3.2.2　探索电影数据　　41
3.2.3　探索评级数据　　43
3.3　处理与转换数据　　46
3.4　从数据中提取有用特征　　48
3.4.1　数值特征　　48
3.4.2　类别特征　　49
3.4.3　派生特征　　50
3.4.4　文本特征　　51
3.4.5　正则化特征　　55
3.4.6　用软件包提取特征　　56
3.5　小结　　57
第4章　构建基于Spark的推荐引擎　　58
4.1　推荐模型的分类　　59
4.1.1　基于内容的过滤　　59
4.1.2　协同过滤　　59
4.1.3　矩阵分解　　60
4.2　提取有效特征　　64
4.3　训练推荐模型　　67
4.3.1　使用MovieLens 100k数据集训练模型　　67
4.3.2　使用隐式反馈数据训练模型　　68
4.4　使用推荐模型　　69
4.4.1　用户推荐　　69
4.4.2　物品推荐　　72
4.5　推荐模型效果的评估　　75
4.5.1　均方差　　75
4.5.2　K值平均准确率　　77
4.5.3　使用MLlib内置的评估函数　　81
4.6　小结　　82
第5章　Spark构建分类模型　　83
5.1　分类模型的种类　　85
5.1.1　线性模型　　85
5.1.2　朴素贝叶斯模型　　89
5.1.3　决策树　　90
5.2　从数据中抽取合适的特征　　91
5.3　训练分类模型　　93
5.4　使用分类模型　　95
5.5　评估分类模型的性能　　96
5.5.1　预测的正确率和错误率　　96
5.5.2　准确率和召回率　　97
5.5.3　ROC曲线和AUC　　99
5.6　改进模型性能以及参数调优　　101
5.6.1　特征标准化　　101
5.6.2　其他特征　　104
5.6.3　使用正确的数据格式　　106
5.6.4　模型参数调优　　107
5.7　小结　　115
第6章　Spark构建回归模型　　116
6.1　回归模型的种类　　116
6.1.1　最小二乘回归　　117
6.1.2　决策树回归　　117
6.2　从数据中抽取合适的特征　　118
6.3　回归模型的训练和应用　　123
6.4　评估回归模型的性能　　125
6.4.1　均方误差和均方根误差　　125
6.4.2　平均绝对误差　　126
6.4.3　均方根对数误差　　126
6.4.4　R-平方系数　　126
6.4.5　计算不同度量下的性能　　126
6.5　改进模型性能和参数调优　　127
6.5.1　变换目标变量　　128
6.5.2　模型参数调优　　132
6.6　小结　　140
第7章　Spark构建聚类模型　　141
7.1　聚类模型的类型　　142
7.1.1　K-均值聚类　　142
7.1.2　混合模型　　146
7.1.3　层次聚类　　146
7.2　从数据中提取正确的特征　　146
7.3　训练聚类模型　　150
7.4　使用聚类模型进行预测　　151
7.5　评估聚类模型的性能　　155
7.5.1　内部评价指标　　155
7.5.2　外部评价指标　　156
7.5.3　在MovieLens数据集计算性能　　156
7.6　聚类模型参数调优　　156
7.7　小结　　158
第8章　Spark应用于数据降维　　159
8.1　降维方法的种类　　160
8.1.1　主成分分析　　160
8.1.2　奇异值分解　　160
8.1.3　和矩阵分解的关系　　161
8.1.4　聚类作为降维的方法　　161
8.2　从数据中抽取合适的特征　　162
8.3　训练降维模型　　169
8.4　使用降维模型　　172
8.4.1　在LFW数据集上使用PCA投影数据　　172
8.4.2　PCA和SVD模型的关系　　173
8.5　评价降维模型　　174
8.6　小结　　176
第9章　Spark高级文本处理技术　　177
9.1　处理文本数据有什么特别之处　　177
9.2　从数据中抽取合适的特征　　177
9.2.1　短语加权表示　　178
9.2.2　特征哈希　　179
9.2.3　从20新闻组数据集中提取TF-IDF特征　　180
9.3　使用TF-IDF模型　　192
9.3.1　20 Newsgroups数据集的文本相似度和TF-IDF特征　　192
9.3.2　基于20 Newsgroups数据集使用TF-IDF训练文本分类器　　194
9.4　评估文本处理技术的作用　　196
9.5　Word2Vec 模型　　197
9.6　小结　　200
第10章　Spark Streaming在实时机器学习上的应用　　201
10.1　在线学习　　201
10.2　流处理　　202
10.2.1　Spark Streaming介绍　　202
10.2.2　使用Spark Streaming缓存和容错　　205
10.3　创建Spark Streaming应用　　206
10.3.1　消息生成端　　207
10.3.2　创建简单的流处理程序　　209
10.3.3　流式分析　　211
10.3.4　有状态的流计算　　213
10.4　使用Spark Streaming进行在线学习　　215
10.4.1　流回归　　215
10.4.2　一个简单的流回归程序　　216
10.4.3　流K-均值　　220
10.5　在线模型评估　　221
10.6　小结　　224
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与优化
第1章 引言 1
1.1 学习与智能优化：燎原之火 1
1.2 寻找黄金和寻找伴侣 3
1.3 需要的只是数据 5
1.4 超越传统的商业智能 5
1.5 LION方法的实施 6
1.6 “动手”的方法 6
第2章 懒惰学习：最近邻方法 9
第3章 学习需要方法 14
3.1 从已标记的案例中学习：最小化和泛化 16
3.2 学习、验证、测试 18
3.3 不同类型的误差 21
第一部分 监督学习
第4章 线性模型 26
4.1 线性回归 27
4.2 处理非线性函数关系的技巧 28
4.3 用于分类的线性模型 29
4.4 大脑是如何工作的 30
4.5 线性模型为何普遍，为何成功 31
4.6 最小化平方误差和 32
4.7 数值不稳定性和岭回归 34
第5章 广义线性最小二乘法 37
5.1 拟合的优劣和卡方分布 38
5.2 最小二乘法与最大似然估计 42
5.2.1 假设检验 42
5.2.2 交叉验证 44
5.3 置信度的自助法 44
第6章 规则、决策树和森林 50
6.1 构造决策树 52
6.2 民主与决策森林 56
第7章 特征排序及选择 59
7.1 特征选择：情境 60
7.2 相关系数 62
7.3 相关比 63
7.4 卡方检验拒绝统计独立性 64
7.5 熵和互信息 64
第8章 特定非线性模型 67
8.1 logistic 回归 67
8.2 局部加权回归 69
8.3 用LASSO来缩小系数和选择输入值 72
第9章 神经网络：多层感知器 76
9.1 多层感知器 78
9.2 通过反向传播法学习 80
9.2.1 批量和bold driver反向传播法 81
9.2.2 在线或随机反向传播 82
9.2.3 训练多层感知器的高级优化 83
第10章 深度和卷积网络 84
10.1 深度神经网络 85
10.1.1 自动编码器 86
10.1.2 随机噪声、屏蔽和课程 88
10.2 局部感受野和卷积网络 89
第11章 统计学习理论和支持向量机 94
11.1 经验风险最小化 96
11.1.1 线性可分问题 98
11.1.2 不可分问题 100
11.1.3 非线性假设 100
11.1.4 用于回归的支持向量 101
第12章 最小二乘法和健壮内核机器 103
12.1 最小二乘支持向量机分类器 104
12.2 健壮加权最小二乘支持向量机 106
12.3 通过修剪恢复稀疏 107
12.4 算法改进：调谐QP、原始版本、无补偿 108
第13章 机器学习中的民主 110
13.1 堆叠和融合 111
13.2 实例操作带来的多样性：装袋法和提升法 113
13.3 特征操作带来的多样性 114
13.4 输出值操作带来的多样性：纠错码 115
13.5 训练阶段随机性带来的多样性 115
13.6 加性logistic回归 115
13.7 民主有助于准确率－拒绝的折中 118
第14章 递归神经网络和储备池计算 121
14.1 递归神经网络 122
14.2 能量极小化霍普菲尔德网络 124
14.3 递归神经网络和时序反向传播 126
14.4 递归神经网络储备池学习 127
14.5 超限学习机 128
第二部分 无监督学习和聚类
第15章 自顶向下的聚类：K均值 132
15.1 无监督学习的方法 134
15.2 聚类：表示与度量 135
15.3 硬聚类或软聚类的K均值方法 137
第16章 自底向上（凝聚）聚类 142
16.1 合并标准以及树状图 142
16.2 适应点的分布距离：马氏距离 144
16.3 附录：聚类的可视化 146
第17章 自组织映射 149
17.1 将实体映射到原型的人工皮层 150
17.2 使用成熟的自组织映射进行分类 153
第18章 通过线性变换降维（投影） 155
18.1 线性投影 156
18.2 主成分分析 158
18.3 加权主成分分析：结合坐标和关系 160
18.4 通过比值优化进行线性判别 161
18.5 费希尔线性判别分析 163
第19章 通过非线性映射可视化图与网络 165
19.1 最小应力可视化 166
19.2 一维情况：谱图绘制 168
19.3 复杂图形分布标准 170
第20章 半监督学习 174
20.1 用部分无监督数据进行学习 175
20.1.1 低密度区域中的分离 177
20.1.2 基于图的算法 177
20.1.3 学习度量 179
20.1.4 集成约束和度量学习 179
第三部分 优化：力量之源
第21章 自动改进的局部方法 184
21.1 优化和学习 185
21.2 基于导数技术的一维情况 186
21.2.1 导数可以由割线近似 190
21.2.2 一维最小化 191
21.3 求解高维模型（二次正定型） 191
21.3.1 梯度与最速下降法 194
21.3.2 共轭梯度法 196
21.4 高维中的非线性优化 196
21.4.1 通过线性查找的全局收敛 197
21.4.2 解决不定黑塞矩阵 198
21.4.3 与模型信赖域方法的关系 199
21.4.4 割线法 200
21.4.5 缩小差距：二阶方法与线性复杂度 201
21.5 不涉及导数的技术：反馈仿射振荡器 202
21.5.1 RAS：抽样区域的适应性 203
21.5.2 为健壮性和多样化所做的重复 205
第22章 局部搜索和反馈搜索优化 211
22.1 基于扰动的局部搜索 212
22.2 反馈搜索优化：搜索时学习 215
22.3 基于禁忌的反馈搜索优化 217
第23章 合作反馈搜索优化 222
23.1 局部搜索过程的智能协作 223
23.2 CoRSO：一个政治上的类比 224
23.3 CoRSO的例子：RSO与RAS合作 226
第24章 多目标反馈搜索优化 232
24.1 多目标优化和帕累托最优 233
24.2 脑－计算机优化：循环中的用户 235
第四部分 应用精选
第25章 文本和网页挖掘 240
25.1 网页信息检索与组织 241
25.1.1 爬虫 241
25.1.2 索引 242
25.2 信息检索与排名 244
25.2.1 从文档到向量：向量－空间模型 245
25.2.2 相关反馈 247
25.2.3 更复杂的相似性度量 248
25.3 使用超链接来进行网页排名 250
25.4 确定中心和权威：HITS 254
25.5 聚类 256
第26章 协同过滤和推荐 257
26.1 通过相似用户结合评分 258
26.2 基于矩阵分解的模型 260
参考文献 263
索引 269
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与优化
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习导论
出版者的话中文版序译者序前言致谢符号表第1章 绪论  1.1　什么是机器学习  1.2　机器学习的应用实例    1.2.1　学习关联性    1.2.2　分类    1.2.3　回归    1.2.4　非监督学习    1.2.5　增强学习  1.3　注释  1.4　相关资源  1.5　习题  1.6　参考文献第2章 监督学习  2.1　由实例学习类  2.2　VC维  2.3　概率逼近正确学习  2.4　噪声  2.5　学习多类  2.6　回归  2.7　模型选择与泛化  2.8　监督机器学习算法的维  2.9　注释  2.10　习题  2.11　参考文献第3章 贝叶斯决策定理  3.1　引言　  3.2　分类  3.3　损失与风险  3.4　判别式函数  3.5　效用理论  3.6　信息值  3.7　贝叶斯网络  3.8　影响图  3.9　关联规则  3.10　注释  3.11　习题  3.12　参考文献第4章 参数方法  4.1　引言  4.2　最大似然估计    4.2.1　伯努利密度    4.2.2　多项密度    4.2.3　高斯（正态）密度  4.3　评价估计：偏倚和方差  4.4　贝叶斯估计  4.5　参数分类  4.6　回归  4.7　调整模型的复杂度：偏倚／方差两难选择  4.8　模型选择过程  4.9　注释  4.10　习题  4.11　参考文献第5章 多元方法  5.1　多元数据  5.2　参数估计  5.3　缺失值估计  5.4　多元正态分布  5.5　多元分类……第6章　维度旭纳第7章　聚类第8章　非参数方法第9章　决策树第10章　线性判别式第11章　多层感知器第12章　局部模型　第13章　隐马尔可夫模型　第14章　分类算法评估和比较第15章　组合多学习器第16章　增强学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>python机器学习
译者序
推荐序
作者简介
审校者简介
前言
第1章 赋予计算机学习数据的能力1
1.1构建智能机器将数据转化为知识1
1.2 机器学习的三种不同方法1
1.2.1 通过监督学习对未来事件进行预测2
1.2.2 通过强化学习解决交互式问题4
1.2.3 通过无监督学习发现数据本身潜在的结构4
1.2.4 基本术语及符号介绍5
1.3 构建机器学习系统的蓝图6
1.3.1 数据预处理6
1.3.2 选择预测模型类型并进行训练7
1.3.3 模型验证与使用未知数据进行预测8
1.4 Python在机器学习中的应用8
本章小结9
第2章 机器学习分类算法10
2.1 人造神经元—早期机器学习概览10
2.2 使用Python实现感知器学习算法13
2.3 自适应线性神经元及其学习的收敛性19
2.3.1 通过梯度下降最小化代价函数20
2.3.2 使用Python实现自适应线性神经元21
2.3.3 大规模机器学习与随机梯度下降25
本章小结29
第3章 使用scikit-learn实现机器学习分类算法30
3.1 分类算法的选择30
3.2 初涉scikit-learn的使用30
使用scikit-learn训练感知器31
3.3 逻辑斯谛回归中的类别概率34
3.3.1 初识逻辑斯谛回归与条件概率34
3.3.2 通过逻辑斯谛回归模型的代价函数获得权重36
3.3.3 使用scikit-learn训练逻辑斯谛回归模型37
3.3.4 通过正则化解决过拟合问题39
3.4 使用支持向量机最大化分类间隔41
3.4.1 对分类间隔最大化的直观认识41
3.4.2 使用松弛变量解决非线性可分问题42
3.4.3 使用scikit-learn实现SVM44
3.5 使用核SVM解决非线性问题44
3.6 决策树48
3.6.1 最大化信息增益—获知尽可能准确的结果49
3.6.2 构建决策树52
3.6.3 通过随机森林将弱分类器集成为强分类器53
3.7 惰性学习算法—k-近邻算法54
本章小结57
第4章 数据预处理—构建好的训练数据集58
4.1 缺失数据的处理58
4.1.1 将存在缺失值的特征或样本删除59
4.1.2 缺失数据填充60
4.1.3 理解scikit-learn预估器的API60
4.2 处理类别数据61
4.2.1 有序特征的映射61
4.2.2 类标的编码62
4.2.3 标称特征上的独热编码63
4.3 将数据集划分为训练数据集和测试数据集64
4.4 将特征的值缩放到相同的区间65
4.5 选择有意义的特征66
4.5.1 使用L1正则化满足数据稀疏化67
4.5.2 序列特征选择算法70
4.6 通过随机森林判定特征的重要性74
本章小结76
第5章 通过降维压缩数据77
5.1 无监督数据降维技术—主成分分析77
5.1.1 总体方差与贡献方差78
5.1.2 特征转换80
5.1.3 使用scikit-learn进行主成分分析82
5.2 通过线性判别分析压缩无监督数据84
5.2.1 计算散布矩阵85
5.2.2 在新特征子空间上选取线性判别算法87
5.2.3 将样本映射到新的特征空间89
5.2.4 使用scikit-learn进行LDA分析90
5.3 使用核主成分分析进行非线性映射91
5.3.1 核函数与核技巧91
5.3.2 使用Python实现核主成分分析94
5.3.3 映射新的数据点99
5.3.4 scikit-learn中的核主成分分析102
本章小结103
第6章 模型评估与参数调优实战104
6.1 基于流水线的工作流104
6.1.1 加载威斯康星乳腺癌数据集104
6.1.2 在流水线中集成数据转换及评估操作105
6.2 使用k折交叉验证评估模型性能106
6.2.1 holdout方法106
6.2.2 k折交叉验证107
6.3 通过学习及验证曲线来调试算法110
6.3.1 使用学习曲线判定偏差和方差问题110
6.3.2 通过验证曲线来判定过拟合与欠拟合112
6.4 使用网格搜索调优机器学习模型113
6.4.1 使用网络搜索调优超参114
6.4.2 通过嵌套交叉验证选择算法115
6.5 了解不同的性能评价指标116
6.5.1 读取混淆矩阵116
6.5.2 优化分类模型的准确率和召回率117
6.5.3 绘制ROC曲线118
6.5.4 多类别分类的评价标准121
本章小结121
第7章 集成学习—组合不同的模型122
7.1 集成学习122
7.2 实现一个简单的多数投票分类器125
7.3 评估与调优集成分类器131
7.4 bagging —通过bootstrap样本构建集成分类器135
7.5 通过自适应boosting提高弱学习机的性能138
本章小结143
第8章 使用机器学习进行情感分析144
8.1 获取IMDb电影评论数据集144
8.2 词袋模型简介146
8.2.1 将单词转换为特征向量146
8.2.2 通过词频-逆文档频率计算单词关联度147
8.2.3 清洗文本数据148
8.2.4 标记文档149
8.3 训练用于文档分类的逻辑斯谛回归模型151
8.4 使用大数据—在线算法与外存学习152
本章小结155
第9章 在Web应用中嵌入机器学习模型156
9.1 序列化通过scikit-learn拟合的模型156
9.2 使用SQLite数据库存储数据158
9.3 使用Flask开发Web应用160
9.3.1 第一个Flask Web应用160
9.3.2 表单验证及渲染161
9.4 将电影分类器嵌入Web应用164
9.5 在公共服务器上部署Web应用169
本章小结172
第10章 使用回归分析预测连续型目标变量173
10.1 简单线性回归模型初探173
10.2 波士顿房屋数据集174
10.3 基于最小二乘法构建线性回归模型178
10.3.1 通过梯度下降计算回归参数178
10.3.2 使用scikit-learn估计回归模型的系数181
10.4 使用RANSAC拟合高鲁棒性回归模型182
10.5 线性回归模型性能的评估184
10.6 回归中的正则化方法185
10.7 线性回归模型的曲线化-多项式回归186
10.7.1 房屋数据集中的非线性关系建模188
10.7.2 使用随机森林处理非线性关系190
本章小结193
第11章 聚类分析——处理无类标数据194
11.1 使用k-means算法对相似对象进行分组194
11.1.1 k-means++196
11.1.2 硬聚类与软聚类198
11.1.3 使用肘方法确定簇的最佳数量199
11.1.4 通过轮廓图定量分析聚类质量200
11.2 层次聚类203
11.2.1 基于距离矩阵进行层次聚类204
11.2.2 树状图与热度图的关联207
11.2.3 通过scikit-learn进行凝聚聚类208
11.3 使用DBSCAN划分高密度区域209
本章小结212
第12章 使用人工神经网络识别图像213
12.1 使用人工神经网络对复杂函数建模213
12.1.1 单层神经网络回顾214
12.1.2 多层神经网络架构简介215
12.1.3 通过正向传播构造神经网络216
12.2 手写数字的识别218
12.2.1 获取MNIST数据集218
12.2.2 实现一个多层感知器222
12.3 人工神经网络的训练228
12.3.1 计算逻辑斯谛代价函数228
12.3.2 通过反向传播训练神经网络230
12.4 建立对反向传播的直观认识231
12.5 通过梯度检验调试神经网络232
12.6 神经网络的收敛性236
12.7 其他神经网络架构237
12.7.1 卷积神经网络237
12.7.2 循环神经网络238
12.8 关于神经网络的实现239
本章小结240
第13章 使用Theano并行训练神经网络241
13.1 使用Theano构建、编译并运行表达式241
13.1.1 什么是Theano242
13.1.2 初探Theano243
13.1.3 配置Theano244
13.1.4 使用数组结构245
13.1.5 整理思路—线性回归示例247
13.2 为前馈神经网络选择激励函数250
13.2.1 逻辑斯谛函数概述250
13.2.2 通过softmax函数评估多类别分类任务中的类别概率252
13.2.3 通过双曲正切函数增大输出范围252
13.3 使用Keras提高训练神经网络的效率254
本章小结258
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>python机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习基础教程
前言　　ix
第1章　引言　　1
1.1　为何选择机器学习　　1
1.1.1　机器学习能够解决的问题　　2
1.1.2　熟悉任务和数据　　4
1.2　为何选择Python　　4
1.3　scikit-learn　　4
1.4　必要的库和工具　　5
1.4.1　Jupyter Notebook　　6
1.4.2　NumPy　　6
1.4.3　SciPy　　6
1.4.4　matplotlib　　7
1.4.5　pandas　　8
1.4.6　mglearn　　9
1.5　Python 2与Python 3的对比　　9
1.6　本书用到的版本　　10
1.7　第一个应用：鸢尾花分类　　11
1.7.1　初识数据　　12
1.7.2　衡量模型是否成功：训练数据与测试数据　　14
1.7.3　要事第一：观察数据　　15
1.7.4　构建第一个模型：k近邻算法　　16
1.7.5　做出预测　　17
1.7.6　评估模型　　18
1.8　小结与展望　　19
第2章　监督学习　　21
2.1　分类与回归　　21
2.2　泛化、过拟合与欠拟合　　22
2.3　监督学习算法　　24
2.3.1　一些样本数据集　　25
2.3.2　k 近邻　　28
2.3.3　线性模型　　35
2.3.4　朴素贝叶斯分类器　　53
2.3.5　决策树　　54
2.3.6　决策树集成　　64
2.3.7　核支持向量机　　71
2.3.8　神经网络（深度学习）　　80
2.4　分类器的不确定度估计　　91
2.4.1　决策函数　　91
2.4.2　预测概率　　94
2.4.3　多分类问题的不确定度　　96
2.5　小结与展望　　98
第3章　无监督学习与预处理　　100
3.1　无监督学习的类型　　100
3.2　无监督学习的挑战　　101
3.3　预处理与缩放　　101
3.3.1　不同类型的预处理　　102
3.3.2　应用数据变换　　102
3.3.3　对训练数据和测试数据进行相同的缩放　　104
3.3.4　预处理对监督学习的作用　　106
3.4　降维、特征提取与流形学习　　107
3.4.1　主成分分析　　107
3.4.2　非负矩阵分解　　120
3.4.3　用t-SNE进行流形学习　　126
3.5　聚类　　130
3.5.1　k 均值聚类　　130
3.5.2　凝聚聚类　　140
3.5.3　DBSCAN　　143
3.5.4　聚类算法的对比与评估　　147
3.5.5　聚类方法小结　　159
3.6　小结与展望　　159
第4章　数据表示与特征工程　　161
4.1　分类变量　　161
4.1.1　One-Hot编码（虚拟变量）　　162
4.1.2　数字可以编码分类变量　　166
4.2　分箱、离散化、线性模型与树　　168
4.3　交互特征与多项式特征　　171
4.4　单变量非线性变换　　178
4.5　自动化特征选择　　181
4.5.1　单变量统计　　181
4.5.2　基于模型的特征选择　　183
4.5.3　迭代特征选择　　184
4.6　利用专家知识　　185
4.7　小结与展望　　192
第5章　模型评估与改进　　193
5.1　交叉验证　　194
5.1.1　scikit-learn中的交叉验证　　194
5.1.2　交叉验证的优点　　195
5.1.3　分层k 折交叉验证和其他策略　　196
5.2　网格搜索　　200
5.2.1　简单网格搜索　　201
5.2.2　参数过拟合的风险与验证集　　202
5.2.3　带交叉验证的网格搜索　　203
5.3　评估指标与评分　　213
5.3.1　牢记最终目标　　213
5.3.2　二分类指标　　214
5.3.3　多分类指标　　230
5.3.4　回归指标　　232
5.3.5　在模型选择中使用评估指标　　232
5.4　小结与展望　　234
第6章　算法链与管道　　236
6.1　用预处理进行参数选择　　237
6.2　构建管道　　238
6.3　在网格搜索中使用管道　　239
6.4　通用的管道接口　　242
6.4.1　用make_pipeline方便地创建管道　　243
6.4.2　访问步骤属性　　244
6.4.3　访问网格搜索管道中的属性　　244
6.5　网格搜索预处理步骤与模型参数　　246
6.6　网格搜索选择使用哪个模型　　248
6.7　小结与展望　　249
第7章　处理文本数据　　250
7.1　用字符串表示的数据类型　　250
7.2　示例应用：电影评论的情感分析　　252
7.3　将文本数据表示为词袋　　254
7.3.1　将词袋应用于玩具数据集　　255
7.3.2　将词袋应用于电影评论　　256
7.4　停用词　　259
7.5　用tf-idf缩放数据　　260
7.6　研究模型系数　　263
7.7　多个单词的词袋（n元分词）　　263
7.8　高级分词、词干提取与词形还原　　267
7.9　主题建模与文档聚类　　270
7.10　小结与展望　　277
第8章　全书总结　　278
8.1　处理机器学习问题　　278
8.2　从原型到生产　　279
8.3　测试生产系统　　280
8.4　构建你自己的估计器　　280
8.5　下一步怎么走　　281
8.5.1　理论　　281
8.5.2　其他机器学习框架和包　　281
8.5.3　排序、推荐系统与其他学习类型　　282
8.5.4　概率建模、推断与概率编程　　282
8.5.5　神经网络　　283
8.5.6　推广到更大的数据集　　283
8.5.7　磨练你的技术　　284
8.6　总结　　284
关于作者　　285
关于封面　　285
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习基础教程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入理解机器学习：从原理到算法
出版者的话
译者序
前言
致谢
第1章引论1
1.1什么是学习1
1.2什么时候需要机器学习2
1.3学习的种类3
1.4与其他领域的关系4
1.5如何阅读本书4
1.6符号6
第一部分理论基础
第2章简易入门10
2.1一般模型——统计学习理论框架10
2.2经验风险最小化11
2.3考虑归纳偏置的经验风险最小化12
2.4练习15
第3章一般学习模型17
3.1PAC学习理论17
3.2更常见的学习模型18
3.2.1放宽可实现假设——不可知PAC学习18
3.2.2学习问题建模19
3.3小结21
3.4文献评注21
3.5练习21
第4章学习过程的一致收敛性24
4.1一致收敛是可学习的充分条件24
4.2有限类是不可知PAC可学习的25
4.3小结26
4.4文献评注27
4.5练习27
第5章偏差与复杂性权衡28
5.1“没有免费的午餐”定理28
5.2误差分解31
5.3小结31
5.4文献评注32
5.5练习32
第6章VC维33
6.1无限的类也可学习33
6.2VC维概述34
6.3实例35
6.3.1阈值函数35
6.3.2区间35
6.3.3平行于轴的矩形35
6.3.4有限类36
6.3.5VC维与参数个数36
6.4PAC学习的基本定理36
6.5定理6.7的证明37
6.5.1Sauer引理及生长函数37
6.5.2有小的有效规模的类的一致收敛性39
6.6小结40
6.7文献评注41
6.8练习41
第7章不一致可学习44
7.1不一致可学习概述44
7.2结构风险最小化46
7.3最小描述长度和奥卡姆剃刀48
7.4可学习的其他概念——一致收敛性50
7.5探讨不同的可学习概念51
7.6小结53
7.7文献评注53
7.8练习54
第8章学习的运行时间56
8.1机器学习的计算复杂度56
8.2ERM规则的实现58
8.2.1有限集58
8.2.2轴对称矩形59
8.2.3布尔合取式59
8.2.4学习三项析取范式60
8.3高效学习，而不通过合适的ERM60
8.4学习的难度*61
8.5小结62
8.6文献评注62
8.7练习62
第二部分从理论到算法
第9章线性预测66
9.1半空间66
9.1.1半空间类线性规划67
9.1.2半空间感知器68
9.1.3半空间的VC维69
9.2线性回归70
9.2.1最小平方70
9.2.2多项式线性回归71
9.3逻辑斯谛回归72
9.4小结73
9.5文献评注73
9.6练习73
第10章boosting75
10.1弱可学习75
10.2AdaBoost78
10.3基础假设类的线性组合80
10.4AdaBoost用于人脸识别82
10.5小结83
10.6文献评注83
10.7练习84
第11章模型选择与验证85
11.1用结构风险最小化进行模型选择85
11.2验证法86
11.2.1留出的样本集86
11.2.2模型选择的验证法87
11.2.3模型选择曲线88
11.2.4k折交叉验证88
11.2.5训练验证测试拆分89
11.3如果学习失败了应该做什么89
11.4小结92
11.5练习92
第12章凸学习问题93
12.1凸性、利普希茨性和光滑性93
12.1.1凸性93
12.1.2利普希茨性96
12.1.3光滑性97
12.2凸学习问题概述98
12.2.1凸学习问题的可学习性99
12.2.2凸利普希茨/光滑有界学习问题100
12.3替代损失函数101
12.4小结102
12.5文献评注102
12.6练习102
第13章正则化和稳定性104
13.1正则损失最小化104
13.2稳定规则不会过拟合105
13.3Tikhonov正则化作为稳定剂106
13.3.1利普希茨损失108
13.3.2光滑和非负损失108
13.4控制适合与稳定性的权衡109
13.5小结111
13.6文献评注111
13.7练习111
第14章随机梯度下降114
14.1梯度下降法114
14.2次梯度116
14.2.1计算次梯度117
14.2.2利普希茨函数的次梯度118
14.2.3次梯度下降118
14.3随机梯度下降118
14.4SGD的变型120
14.4.1增加一个投影步120
14.4.2变步长121
14.4.3其他平均技巧121
14.4.4强凸函数*121
14.5用SGD进行学习123
14.5.1SGD求解风险极小化123
14.5.2SGD求解凸光滑学习问题的分析124
14.5.3SGD求解正则化损失极小化125
14.6小结125
14.7文献评注125
14.8练习126
第15章支持向量机127
15.1间隔与硬SVM127
15.1.1齐次情况129
15.1.2硬SVM的样本复杂度129
15.2软SVM与范数正则化130
15.2.1软SVM的样本复杂度131
15.2.2间隔、基于范数的界与维度131
15.2.3斜坡损失*132
15.3最优化条件与“支持向量”*133
15.4对偶*133
15.5用随机梯度下降法实现软SVM134
15.6小结135
15.7文献评注135
15.8练习135
第16章核方法136
16.1特征空间映射136
16.2核技巧137
16.2.1核作为表达先验的一种形式140
16.2.2核函数的特征*141
16.3软SVM应用核方法141
16.4小结142
16.5文献评注143
16.6练习143
第17章多分类、排序与复杂预测问题145
17.1一对多和一对一145
17.2线性多分类预测147
17.2.1如何构建Ψ147
17.2.2对损失敏感的分类148
17.2.3经验风险最小化149
17.2.4泛化合页损失149
17.2.5多分类SVM和SGD150
17.3结构化输出预测151
17.4排序153
17.5二分排序以及多变量性能测量157
17.6小结160
17.7文献评注160
17.8练习161
第18章决策树162
18.1采样复杂度162
18.2决策树算法163
18.2.1增益测量的实现方式164
18.2.2剪枝165
18.2.3实值特征基于阈值的拆分规则165
18.3随机森林165
18.4小结166
18.5文献评注166
18.6练习166
第19章最近邻167
19.1k近邻法167
19.2分析168
19.2.11NN准则的泛化界168
19.2.2“维数灾难”170
19.3效率实施*171
19.4小结171
19.5文献评注171
19.6练习171
第20章神经元网络174
20.1前馈神经网络174
20.2神经网络学习175
20.3神经网络的表达力176
20.4神经网络样本复杂度178
20.5学习神经网络的运行时179
20.6SGD和反向传播179
20.7小结182
20.8文献评注183
20.9练习183
第三部分其他学习模型
第21章在线学习186
21.1可实现情况下的在线分类186
21.2不可实现情况下的在线识别191
21.3在线凸优化195
21.4在线感知器算法197
21.5小结199
21.6文献评注199
21.7练习199
第22章聚类201
22.1基于链接的聚类算法203
22.2k均值算法和其他代价最小聚类203
22.3谱聚类206
22.3.1图割206
22.3.2图拉普拉斯与松弛图割算法206
22.3.3非归一化的谱聚类207
22.4信息瓶颈*208
22.5聚类的进阶观点208
22.6小结209
22.7文献评注210
22.8练习210
第23章维度约简212
23.1主成分分析212
23.1.1当dm时一种更加有效的求解方法214
23.1.2应用与说明214
23.2随机投影216
23.3压缩感知217
23.4PCA还是压缩感知223
23.5小结223
23.6文献评注223
23.7练习223
第24章生成模型226
24.1极大似然估计226
24.1.1连续随机变量的极大似然估计227
24.1.2极大似然与经验风险最小化228
24.1.3泛化分析228
24.2朴素贝叶斯229
24.3线性判别分析230
24.4隐变量与EM算法230
24.4.1EM是交替最大化算法232
24.4.2混合高斯模型参数估计的EM算法233
24.5贝叶斯推理233
24.6小结235
24.7文献评注235
24.8练习235
第25章特征选择与特征生成237
25.1特征选择237
25.1.1滤波器238
25.1.2贪婪选择方法239
25.1.3稀疏诱导范数241
25.2特征操作和归一化242
25.3特征学习244
25.4小结246
25.5文献评注246
25.6练习246
第四部分高级理论
第26章拉德马赫复杂度250
26.1拉德马赫复杂度概述250
26.2线性类的拉德马赫复杂度255
26.3SVM的泛化误差界256
26.4低1范数预测器的泛化误差界258
26.5文献评注259
第27章覆盖数260
27.1覆盖260
27.2通过链式反应从覆盖到拉德马赫复杂度261
27.3文献评注262
第28章学习理论基本定理的证明263
28.1不可知情况的上界263
28.2不可知情况的下界264
28.2.1证明m(ε，δ)≥0.5log(1/(4δ))/ε2264
28.2.2证明m(ε，1/8)≥8d/ε2265
28.3可实现情况的上界267
第29章多分类可学习性271
29.1纳塔拉詹维271
29.2多分类基本定理271
29.3计算纳塔拉詹维272
29.3.1基于类的一对多272
29.3.2一般的多分类到二分类约简273
29.3.3线性多分类预测器273
29.4好的与坏的ERM274
29.5文献评注275
29.6练习276
第30章压缩界277
30.1压缩界概述277
30.2例子278
30.2.1平行于轴的矩形278
30.2.2半空间279
30.2.3可分多项式279
30.2.4间隔可分的情况279
30.3文献评注280
第31章PAC贝叶斯281
31.1PAC贝叶斯界281
31.2文献评注282
31.3练习282
附录A技术性引理284
附录B测度集中度287
附录C线性代数294
参考文献297
索引305
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入理解机器学习：从原理到算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实战：基于Scikit-Learn和TensorFlow
前言1
第一部分 机器学习基础
第1章 机器学习概览11
什么是机器学习12
为什么要使用机器学习12
机器学习系统的种类15
监督式/无监督式学习16
批量学习和在线学习21
基于实例与基于模型的学习24
机器学习的主要挑战29
训练数据的数量不足29
训练数据不具代表性30
质量差的数据32
无关特征32
训练数据过度拟合33
训练数据拟合不足34
退后一步35
测试与验证35
练习37
第2章 端到端的机器学习项目39
使用真实数据39
观察大局40
框架问题41
选择性能指标42
检查假设45
获取数据45
创建工作区45
下载数据48
快速查看数据结构49
创建测试集52
从数据探索和可视化中获得洞见56
将地理数据可视化57
寻找相关性59
试验不同属性的组合61
机器学习算法的数据准备62
数据清理63
处理文本和分类属性65
自定义转换器67
特征缩放68
转换流水线68
选择和训练模型70
培训和评估训练集70
使用交叉验证来更好地进行评估72
微调模型74
网格搜索74
随机搜索76
集成方法76
分析最佳模型及其错误76
通过测试集评估系统77
启动、监控和维护系统78
试试看79
练习79
第3章 分类80
MNIST80
训练一个二元分类器82
性能考核83
使用交叉验证测量精度83
混淆矩阵84
精度和召回率86
精度/召回率权衡87
ROC曲线90
多类别分类器93
错误分析95
多标签分类98
多输出分类99
练习100
第4章 训练模型102
线性回归103
标准方程104
计算复杂度106
梯度下降107
批量梯度下降110
随机梯度下降112
小批量梯度下降114
多项式回归115
学习曲线117
正则线性模型121
岭回归121
套索回归123
弹性网络125
早期停止法126
逻辑回归127
概率估算127
训练和成本函数128
决策边界129
Softmax回归131
练习134
第5章 支持向量机136
线性SVM分类136
软间隔分类137
非线性SVM分类139
多项式核140
添加相似特征141
高斯RBF核函数142
计算复杂度143
SVM回归144
工作原理145
决策函数和预测146
训练目标146
二次规划148
对偶问题149
核化SVM149
在线SVM151
练习152
第6章 决策树154
决策树训练和可视化154
做出预测155
估算类别概率157
CART训练算法158
计算复杂度158
基尼不纯度还是信息熵159
正则化超参数159
回归161
不稳定性162
练习163
第7章 集成学习和随机森林165
投票分类器165
bagging和pasting168
Scikit-Learn的bagging和pasting169
包外评估170
Random Patches和随机子空间171
随机森林172
极端随机树173
特征重要性173
提升法174
AdaBoost175
梯度提升177
堆叠法181
练习184
第8章 降维185
维度的诅咒186
数据降维的主要方法187
投影187
流形学习189
PCA190
保留差异性190
主成分191
低维度投影192
使用Scikit-Learn192
方差解释率193
选择正确数量的维度193
PCA压缩194
增量PCA195
随机PCA195
核主成分分析196
选择核函数和调整超参数197
局部线性嵌入199
其他降维技巧200
练习201
第二部分 神经网络和深度学习
第9章 运行TensorFlow205
安装207
创建一个计算图并在会话中执行208
管理图209
节点值的生命周期210
TensorFlow中的线性回归211
实现梯度下降211
手工计算梯度212
使用自动微分212
使用优化器214
给训练算法提供数据214
保存和恢复模型215
用TensorBoard来可视化图和训练曲线216
命名作用域219
模块化220
共享变量222
练习225
第10章 人工神经网络简介227
从生物神经元到人工神经元227
生物神经元228
具有神经元的逻辑计算229
感知器230
多层感知器和反向传播233
用TensorFlow的高级API来训练MLP236
使用纯TensorFlow训练DNN237
构建阶段237
执行阶段240
使用神经网络241
微调神经网络的超参数242
隐藏层的个数242
每个隐藏层中的神经元数243
激活函数243
练习244
第11章 训练深度神经网络245
梯度消失/爆炸问题245
Xavier初始化和He初始化246
非饱和激活函数248
批量归一化250
梯度剪裁254
重用预训练图层255
重用TensorFlow模型255
重用其他框架的模型256
冻结低层257
缓存冻结层257
调整、丢弃或替换高层258
模型动物园258
无监督的预训练259
辅助任务中的预训练260
快速优化器261
Momentum优化261
Nesterov梯度加速262
AdaGrad263
RMSProp265
Adam优化265
学习速率调度267
通过正则化避免过度拟合269
提前停止269
1和2正则化269
dropout270
最大范数正则化273
数据扩充274
实用指南275
练习276
第12章 跨设备和服务器的分布式TensorFlow279
一台机器上的多个运算资源280
安装280
管理GPU RAM282
在设备上操作284
并行执行287
控制依赖288
多设备跨多服务器288
开启一个会话290
master和worker服务290
分配跨任务操作291
跨多参数服务器分片变量291
用资源容器跨会话共享状态292
使用TensorFlow队列进行异步通信294
直接从图中加载数据299
在TensorFlow集群上并行化神经网络305
一台设备一个神经网络305
图内与图间复制306
模型并行化308
数据并行化309
练习314
第13章 卷积神经网络31
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实战：基于Scikit-Learn和TensorFlow
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习
第1章关于预测的两类核心算法
1.1为什么这两类算法如此有用
1.2什么是惩罚回归方法
1.3什么是集成方法
1.4算法的选择
1.5构建预测模型的流程
1.5.1构造一个机器学习问题
1.5.2特征提取和特征工程
1.5.3确定训练后的模型的性能
1.6各章内容及其依赖关系
1.7小结
1.8参考文献
第2章通过理解数据来了解问题
2.1“解剖”一个新问题
2.1.1属性和标签的不同类型决定模型的选择
2.1.2新数据集的注意事项
2.2分类问题：用声纳发现未爆炸的水雷
2.2.1“岩石vs水雷”数据集的物理特性
2.2.2“岩石vs水雷”数据集统计特征
2.2.3用分位数图展示异常点
2.2.4类别属性的统计特征
2.2.5利用PythonPandas对“岩石vs水雷”数据集进行统计分析
2.3对“岩石vs水雷数据集”属性的可视化展示
2.3.1利用平行坐标图进行可视化展示
2.3.2属性和标签的关系可视化
2.3.3用热图（heatmap）展示属性和标签的相关性
2.3.4对“岩石vs
2.4基于因素变量的实数值预测鲍鱼的年龄
2.4.1回归问题的平行坐标图—鲍鱼问题的变量关系可视化
2.4.2回归问题如何使用关联热图—鲍鱼问题的属性对关系的可视化
2.5用实数值属性预测实数值目标：评估红酒口感
2.6多类别分类问题：它属于哪种玻璃
小结
参考文献
第3章预测模型的构建：平衡性能、复杂性以及大数据
3.1基本问题：理解函数逼近
3.1.1使用训练数据
3.1.2评估预测模型的性能
3.2影响算法选择及性能的因素——复杂度以及数据
3.2.1简单问题和复杂问题的对比
3.2.2一个简单模型与复杂模型的对比
3.2.3影响预测算法性能的因素
3.2.4选择一个算法：线性或者非线性
3.3度量预测模型性能
3.3.1不同类型问题的性能评价指标
3.3.2部署模型的性能模拟
3.4模型与数据的均衡
3.4.1通过权衡问题复杂度、模型复杂度以及数据集规模来选择模型
3.4.2使用前向逐步回归来控制过拟合
3.4.3评估并理解你的预测模型
3.4.4通过惩罚回归系数来控制过拟合——岭回归
小结
参考文献
第4章惩罚线性回归模型
4.1为什么惩罚线性回归方法如此有效
4.1.1足够快速地估计系数
4.1.2变量的重要性信息
4.1.3部署时的预测足够快速
4.1.4性能可靠
4.1.5稀疏解
4.1.6问题本身可能需要线性模型
4.1.7什么时候使用集成方法
4.2惩罚线性回归：对线性回归进行正则化以获得最优性能
4.2.1训练线性模型：最小化错误以及更多
4.2.2向OLS公式中添加一个系数惩罚项
4.2.3其他有用的系数惩罚项：Manhattan以及ElasticNet
4.2.4为什么套索惩罚会导致稀疏的系数向量
4.2.5ElasticNet惩罚项包含套索惩罚项以及岭惩罚项
4.3求解惩罚线性回归问题
4.3.1理解最小角度回归与前向逐步回归的关系
4.3.2LARS如何生成数百个不同复杂度的模型
4.3.3从数百个LARS生成结果中选择最佳模型
4.3.4使用Glmnet：非常快速并且通用
4.4基于数值输入的线性回归方法的扩展
4.4.1使用惩罚回归求解分类问题
4.4.2求解超过2种输出的分类问题
4.4.3理解基扩展：使用线性方法来解决非线性问题
4.4.4向线性方法中引入非数值属性
小结
参考文献
第5章使用惩罚线性方法来构建预测模型
5.1惩罚线性回归的Python包
5.2多变量回归：预测红酒口感
5.2.1构建并测试模型以预测红酒口感
5.2.2部署前在整个数据集上进行训练
5.2.3基扩展：基于原始属性扩展新属性来改进性能
5.3二分类：使用惩罚线性回归来检测未爆炸的水雷
5.3.1构建部署用的岩石水雷分类器
5.4多类别分类—分类犯罪现场的玻璃样本
小结
参考文献
第6章集成方法
6.1二元决策树
6.1.1如何利用二元决策树进行预测
6.1.2如何训练一个二元决策树
6.1.3决策树的训练等同于分割点的选择
6.1.4二元决策树的过拟合
6.1.5针对分类问题和类别特征所做的修改
6.2自举集成：Bagging算法
6.2.1Bagging算法是如何工作的
6.2.2Bagging算法小结
6.3梯度提升法（GradientBoosting）
6.3.1梯度提升法的基本原理
6.3.2获取梯度提升法的最佳性能
6.3.3针对多变量问题的梯度提升法
6.3.4梯度提升方法的小结
6.4随机森林
6.4.1随机森林：Bagging加上随机属性子集
6.4.2随机森林的性能
6.4.3随机森林小结
6.5小结
6.6参考文献
第7章用Python构建集成模型
7.1用Python集成方法工具包解决回归问题
7.1.1构建随机森林模型来预测红酒口感
7.1.2用梯度提升预测红酒品质
7.2用Bagging来预测红酒口感
7.3Python集成方法引入非数值属性
7.3.1对鲍鱼性别属性编码引入Python随机森林回归方法
7.3.2评估性能以及变量编码的重要性
7.3.3在梯度提升回归方法中引入鲍鱼性别属性
7.3.4梯度提升法的性能评价以及变量编码的重要性
7.4用Python集成方法解决二分类问题
7.4.1用Python随机森林方法探测未爆炸的水雷
7.4.2构建随机森林模型探测未爆炸水雷
7.4.3随机森林分类器的性能
7.4.4用Python梯度提升法探测未爆炸水雷
7.4.5梯度提升法分类器的性能
7.5用Python集成方法解决多类别分类问题
7.5.1用随机森林对玻璃进行分类
7.5.2处理类不均衡问题
7.5.3用梯度提升法对玻璃进行分类
7.5.4评估在梯度提升法中使用随机森林基学习器的好处
7.6算法比较
小结
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>百面机器学习
推荐序
前言
机器学习算法工程师的自我修养
第1章　特征工程
第1节　特征归一化
第2节　类别型特征
第3节　高维组合特征的处理
第4节　组合特征
第5节　文本表示模型
第6节　Word2Vec
第7节　图像数据不足时的处理方法
第2章　模型评估
第1节　评估指标的局限性
第2节　ROC 曲线
第3节　余弦距离的应用
第4节　A/B 测试的陷阱
第5节　模型评估的方法
第6节　超参数调优
第7节　过拟合与欠拟合
第3章　经典算法
第1节　支持向量机
第2节　逻辑回归
第3节　决策树
第4章　降维
第1节　PCA 最大方差理论
第2节PCA 最小平方误差理论
第3节　线性判别分析
第4节　线性判别分析与主成分分析
第5章　非监督学习
第1节　K均值聚类
第2节　高斯混合模型
第3节　自组织映射神经网络
第4节　非监督学习算法的评估
第6章　概率图模型
第1节　概率图模型的联合概率分布
第2节　概率图表示
第3节　生成式模型与判别式模型
第4节　马尔可夫模型
第5节　主题模型
第7章　优化算法
第1节　有监督学习的损失函数
第2节　机器学习中的优化问题
第3节　经典优化算法
第4节　梯度验证
第5节　随机梯度下降法
第6节　随机梯度下降法的加速
第7节　L1 正则化与稀疏性
第8章　采样
第1节　采样的作用
第2节　均匀分布随机数
第3节　常见的采样方法
第4节　高斯分布的采样
第5节　马尔科夫蒙特卡洛采样法
第6节　贝叶斯网络的采样
第7节　不均衡样本集的重采样
第9章　前向神经网络
第1节　多层感知机与布尔函数
第2节　深度神经网络中的激活函数
第3节　多层感知机的反向传播算法
第4节　神经网络训练技巧
第5节　深度卷积神经网络
第6节　深度残差网络
第10章　循环神经网络
第1节　循环神经网络和卷积神经网络
第2节　循环神经网络的梯度消失问题
第3节　循环神经网络中的激活函数
第4节　长短期记忆网络
第5节　Seq2Seq 模型
第6节　注意力机制
第11章　强化学习
第1节　强化学习基础
第2节　视频游戏里的强化学习
第3节　策略梯度
第4节　探索与利用
第12章　集成学习
第1节　集成学习的种类
第2节　集成学习的步骤和例子
第3节　基分类器
第4节　偏差与方差
第5节　梯度提升决策树的基本原理
第6节　XGBoost与GBDT 的联系和区别
第13章　生成式对抗网络
第1节　初识GANs 的秘密
第2节　WGAN：抓住低维的幽灵
第3节　DCGAN：当GANs 遇上卷积
第4节　ALI：包揽推断业务
第5节　IRGAN：生成离散样本
第6节　SeqGAN：生成文本序列
第14章　人工智能的热门应用
第1节　计算广告
第2节　游戏中的人工智能
第3节　AI 在自动驾驶中的应用
第4节　机器翻译
第5节　人机交互中的智能计算
后记
作者随笔
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>百面机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入理解AutoML和AutoDL：构建自动化机器学习与深度学习平台
目录
赞誉
前言
第1章　人工智能概述1
1.1　全面了解人工智能1
1.1.1　人工智能定义1
1.1.2　弱人工智能、强人工智能与超人工智能2
1.1.3　人工智能三大主义3
1.1.4　机器学习与深度学习4
1.2　人工智能发展历程5
1.3　深度学习的崛起之路7
1.3.1　人脸识别的起源7
1.3.2　自动驾驶的福音7
1.3.3　超越人类的AI智能体8
1.3.4　懂你的AI8
1.3.5　奔跑、飞行以及玩游戏的AI8
1.3.6　人人都可以创造属于自己的AI8
1.4　深度学习的发展9
1.4.1　计算机视觉9
1.4.2　自然语言处理10
1.4.3　语音识别11
1.5　下一代人工智能11
1.6　参考文献13
第2章　自动化人工智能14
2.1　AutoML概述14
2.1.1　什么是自动化14
2.1.2　AutoML的起源与发展15
2.2　AutoML的研究意义17
2.2.1　AutoML的研究动机17
2.2.2　AutoML的意义和作用18
2.3　现有AutoML平台产品21
2.3.1　谷歌Cloud AutoML21
2.3.2　百度EasyDL23
2.3.3　阿里云PAI24
2.3.4　探智立方DarwinML28
2.3.5　第四范式AI ProphetAutoML29
2.3.6　智易科技30
2.4　参考文献31
第3章　机器学习概述32
3.1　机器学习的发展32
3.1.1　“机器学习”名字的由来32
3.1.2　“机器学习”的前世今生33
3.1.3　“机器学习”的理论基础34
3.2　机器学习的实现方法36
3.2.1　分类问题36
3.2.2　回归问题38
3.2.3　聚类问题39
3.3　自动化机器学习40
3.3.1　机器学习面临的问题40
3.3.2　为什么会产生AutoML41
3.4　参考文献41
第4章　自动化特征工程43
4.1　特征工程43
4.1.1　什么是特征43
4.1.2　什么是特征工程44
4.2　特征工程处理方法45
4.2.1　特征选择45
4.2.2　数据预处理47
4.2.3　特征压缩48
4.3　手工特征工程存在的问题49
4.4　自动化特征工程50
4.4.1　什么是自动化特征工程50
4.4.2　机器学习和深度学习的特征工程51
4.5　自动化特征工程生成方法52
4.5.1　深度特征合成算法52
4.5.2　Featuretools自动特征提取52
4.5.3　基于时序数据的自动化特征工程56
4.6　自动化特征工程工具67
4.6.1　自动化特征工程系统67
4.6.2　自动化特征工程平台71
4.7　参考文献75
第5章　自动化模型选择76
5.1　模型选择76
5.2　自动化模型选择77
5.2.1　基于贝叶斯优化的自动化模型选择78
5.2.2　基于进化算法的自动化模型选择84
5.2.3　分布式自动化模型选择86
5.2.4　自动化模型选择的相关平台92
5.3　自动集成学习94
5.3.1　集成学习基础94
5.3.2　集成学习之结合策略97
5.3.3　自动化模型集成98
5.4　参考文献99
第6章　自动化超参优化101
6.1　概述101
6.1.1　问题定义103
6.1.2　搜索空间103
6.1.3　搜索策略103
6.1.4　评价预估104
6.1.5　经验迁移加速105
6.2　基本方法105
6.2.1　网格搜索105
6.2.2　随机搜索105
6.3　基于模型的序列超参优化106
6.3.1　代理模型的选择108
6.3.2　代理模型的更新108
6.3.3　新超参组的选择109
6.3.4　基于高斯过程回归的序列超参优化111
6.3.5　基于随机森林算法代理的序列超参优化112
6.3.6　基于TPE算法的序列超参优化114
6.3.7　SMBO的进阶技巧114
6.4　基于进化算法的自动化超参优化115
6.4.1　基于进化策略的自动化超参优化115
6.4.2　基于粒子群算法的自动化超参优化116
6.5　基于迁移学习的超参优化加速方法117
6.5.1　经验迁移机制117
6.5.2　经验迁移衰退机制117
6.5.3　经验迁移权重机制117
6.5.4　优化过程的试点机制118
6.6　参考文献118
第7章　深度学习基础120
7.1　深度学习简介120
7.1.1　什么是神经元120
7.1.2　人工神经网络的发展历程121
7.1.3　深度学习方法123
7.2　卷积神经网络简介123
7.2.1　卷积层123
7.2.2　池化层125
7.2.3　全连接层126
7.3　CNN经典模型126
7.3.1　LeNet126
7.3.2　AlexNet127
7.3.3　VGGNet128
7.3.4　GoogLeNet129
7.3.5　ResNet130
7.3.6　DenseNet131
7.4　循环神经网络132
7.4.1　基本循环神经模型132
7.4.2　LSTM模型133
7.4.3　GRU模型134
7.5　参考文献134
第8章　自动化深度学习概述136
8.1　深度学习vs自动化深度学习136
8.2　什么是NAS136
8.2.1　问题定义137
8.2.2　搜索策略139
8.2.3　加速方案140
8.3　NAS方法分类140
第9章　基于强化学习的AutoDL142
9.1　强化学习基础142
9.1.1　强化学习简介142
9.1.2　基本要素及问题定义144
9.1.3　发展历史144
9.1.4　基本方法146
9.2　两类基本模型147
9.2.1　TD经典算法148
9.2.2　DQN系列算法149
9.2.3　策略梯度算法152
9.3　强化学习之Actor-Critic系列154
9.3.1　Actor-Critic算法154
9.3.2　确定性策略梯度155
9.3.3　深度确定性策略梯度157
9.3.4　异步优势Actor-Critic算法158
9.3.5　近端策略优化160
9.3.6　分布式近端策略优化164
9.4　基于强化学习的自动搜索166
9.5　基本搜索方法166
9.5.1　基于层的搜索166
9.5.2　基于块的搜索169
9.5.3　基于连接的搜索171
9.6　进阶搜索方法173
9.6.1　逆强化学习173
9.6.2　图超网络174
9.6.3　蒙特卡洛树搜索175
9.6.4　知识提炼（教师网络）177
9.7　参考文献179
第10章　基于进化算法的AutoDL181
10.1　启发式算法181
10.1.1　随机搜索182
10.1.2　近邻搜索183
10.1.3　进化计算187
10.1.4　启发式算法的局限性189
10.2　初代进化算法190
10.2.1　基本术语190
10.2.2　基础算子191
10.2.3　遗传算法196
10.2.4　进化策略198
10.2.5　进化规划199
10.3　其他近代进化算法200
10.3.1　遗传编程算法簇200
10.3.2　群体算法—以PSO为例205
10.3.3　文化基因算法207
10.3.4　差分进化算法208
10.3.5　分布估计算法208
10.4　进化神经网络209
10.4.1　简介209
10.4.2　神经网络编码方式210
10.4.3　竞争约定211
10.4.4　网络结构的创新性212
10.4.5　NAS之进化算法212
10.5　细粒度的神经进化（NEAT算法）213
10.5.1　基因编码214
10.5.2　基因的可追溯性216
10.5.3　通过物种形成保护创新结构216
10.6　粗粒度的神经进化（CoDeep-NEAT算法）218
10.6.1　DeepNEAT算法218
10.6.2　CoDeepNEAT算法219
10.7　block-level的进化220
10.7.1　Genetic CNN算法220
10.7.2　CGP-CNN方法222
10.8　基于node-level的网络架构进化224
10.8.1　思想简介224
10.8.2　基本算法设计225
10.8.3　信息复用与加速226
10.9　基于NAS搜索空间的网络架构进化227
10.9.1　思想简介227
10.9.2　基本算法设计227
10.9.3　信息复用与加速228
10.10　基于层次拓扑表示的网络进化方法228
10.10.1　思想简介228
10.10.2　分级表示229
10.10.3　随机的层次分级进化230
10.11　参考文献230
第11章　AutoDL高阶233
11.1　搜索加速之权值共享法233
11.1.1　ENAS233
11.1.2　基于稀疏优化的NAS235
11.2　基于one-shot模型的架构搜索236
11.2.1　超网络的应用236
11.2.2　基于one-shot的搜索237
11.2.3　实例级架构搜索238
11.2.4　单路径超网络240
11.3　搜索加速之代理评估模型241
11.3.1　代理模型241
11.3.2　PNAS中的LSTM代理242
11.4　基于网络态射法的神经架构搜索244
11.4.1　网络态射的提出244
11.4.2　什么是网络态射244
11.4.3　网络态射+迂回爬山法246
11.5　可微分神经架构搜索247
11.5.1　可微分神经架构搜索的来源247
11.5.2　可微分神经架构搜索的方法248
11.6　参考文献250
第12章　垂直领域的AutoDL252
12.1　AutoCV252
12.1.1　Auto-DeepLab（图像语义分割）252
12.1.2　随机连线神经网络257
12.2　AutoVoice261
12.2.1　关键词定位问题定义261
12.2.2　随机自适应架构搜索原理262
12.2.3　SANAS模型262
12.3　AutoNLP263
12.3.1　什么是自注意力机制263
12.3.2　初识Transformer模型265
12.3.3　Evolved Transformer结构266
12.4　参考文献270
第13章　自动化模型压缩与加速271
13.1　从生物角度看模型压缩的重要性271
13.1.1　人脑神经元的修剪271
13.1.2　大脑的冗余性272
13.1.3　修剪的意义273
13.2　模型压缩发展概述274
13.3　入门级方法：量化技术275
13.3.1　量化技术275
13.3.2　二值化网络276
13.3.3　TensorRT277
13.4　初级方法：修剪法278
13.4.1　修剪法278
13.4.2　修剪与修复279
13.5　中级方法：稀疏化技术281
13.5.1　正则化281
13.5.2　知识精炼281
13.5.3　张量分解281
13.6　高级方法：轻量级模型设计284
13.6.1　简化卷积操作284
13.6.2　深度可分离卷积285
13.6.3　改进的Inception287
13.7　自动化模型压缩技术289
13.7.1　AMC算法289
13.7.2　PocketFlow框架291
13.8　基于AutoDL的轻量级模型292
13.8.1　问题定义292
13.8.2　帕累托最优问题293
13.8.3　进化算法的应用294
13.8.4　强化学习的应用296
13.8.5　可微分架构搜索298
13.9　参考文献300
第14章　元学习302
14.1　什么是元学习302
14.1.1　基本介绍302
14.1.2　经典案例303
14.1.3　深入了解元学习304
14.1.4　元学习应用的发展306
14.2　元学习的通用流程306
14.2.1　基本定义306
14.2.2　流程框架306
14.3　从模型评估中学习307
14.3.1　任务无关推荐308
14.3.2　参数空间设计308
14.3.3　参数转换309
14.3.4　学习曲线310
14.4　从任务属性中学习310
14.4.1　元特征310
14.4.2　学习元特征311
14.4.3　相似任务的热启动优化311
14.4.4　元模型311
14.4.5　管道合成312
14.4.6　是否调整312
14.5　从先前模型中学习312
14.5.1　迁移学习313
14.5.2　神经网络中的元学习313
14.5.3　小样本学习314
14.5.4　监督学习之外的方法315
14.6　基于模型的方法316
14.6.1　记忆增强神经网络316
14.6.2　元网络317
14.6.3　模型无关的元学习方法317
14.6.4　利用注意力机制的方法319
14.6.5　基于时间卷积的方法320
14.6.6　基于损失预测的方法321
14.6.7　元强化学习321
14.7　基于度量的方法322
14.7.1　Siamese网络322
14.7.2　匹配网络324
14.7.3　关系网络324
14.7.4　原型网络325
14.8　基于优化的方法326
14.8.1　基于LSTM网络的元学习者326
14.8.2　未知模型的元学习326
14.8.3　Reptile：可扩展元学习方法327
14.8.4　基于梯度预测的方法327
14.9　参考文献329
结束语332
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入理解AutoML和AutoDL：构建自动化机器学习与深度学习平台
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>终极算法
推荐序
序
第一章 机器学习革命
学习算法入门
为何商业拥护机器学习
给科学方法增压
10 亿个比尔•克林顿
学习算法与国家安全
我们将走向何方
第二章 终极算法
来自神经科学的论证
来自进化论的论证
来自物理学的论证
来自统计学的论证
来自计算机科学的论证
机器学习算法与知识工程师
天鹅咬了机器人
终极算法是狐狸，还是刺猬
我们正面临什么危机
新的万有理论
未达标准的终极算法候选项
机器学习的五大学派
第三章 符号学派：休谟的归纳问题
约不约
“天下没有免费的午餐”定理
对知识泵进行预设
如何征服世界
在无知与幻觉之间
你能信任的准确度
归纳是逆向的演绎
掌握治愈癌症的方法
20 问游戏
符号学派
第四章 联结学派：大脑如何学习
感知器的兴盛与衰亡
物理学家用玻璃制作大脑
世界上最重要的曲线
攀登超空间里的高峰
感知器的复仇
一个完整的细胞模型
大脑的更深处
第五章 进化学派：自然的学习算法
达尔文的算法
探索：利用困境
程序的适者生存法则
性有何用
先天与后天
谁学得最快，谁就会赢
第六章 贝叶斯学派：在贝叶斯教堂里
统治世界的定理
所有模型都是错的，但有些却有用
从《尤金•奥涅金》到Siri
所有东西都有关联，但不是直接关联
推理问题
掌握贝叶斯学派的方法
马尔可夫权衡证据
逻辑与概率：一对不幸的组合
第七章 类推学派：像什么就是什么
完美另一半
维数灾难
空中蛇灾
爬上梯子
起床啦
第八章 无师自通
物以类聚，人以群分
发现数据的形状
拥护享乐主义的机器人
熟能生巧
学会关联
第九章 解开迷惑
万里挑一
终极算法之城
马尔科夫逻辑网络
从休谟到你的家用机器人
行星尺度机器学习
医生马上来看你
第十章 建立在机器学习之上的世界
性、谎言和机器学习
数码镜子
充满模型的社会
分享与否？方式、地点如何？
神经网络抢了我的工作
战争不属于人类
谷歌＋终极算法=天网？
进化的第二部分
后 记
致 谢
延伸阅读
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>终极算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
绪论　机器学习概述　　1
第1章　机器学习的构成要素　　9
1.1　任务：可通过机器学习解决的问题　　9
1.1.1　探寻结构　　11
1.1.2　性能评价　　13
1.2　模型：机器学习的输出　　14
1.2.1　几何模型　　14
1.2.2　概率模型　　17
1.2.3　逻辑模型　　22
1.2.4　分组模型与评分模型　　26
1.3　特征：机器学习的马达　　26
1.3.1　特征的两种用法　　28
1.3.2　特征的构造与变换　　29
1.3.3　特征之间的交互　　32
1.4　总结与展望　　33
第2章　两类分类及相关任务　　37
2.1　分类　　39
2.1.1　分类性能的评价　　40
2.1.2　分类性能的可视化　　43
2.2　评分与排序　　46
2.2.1　排序性能的评价及可视化　　48
2.2.2　将排序器转化为分类器　　52
2.3　类概率估计　　54
2.3.1　类概率估计量　　55
2.3.2　将排序器转化为概率估计子　　57
2.4　小结与延伸阅读　　59
第3章　超越两类分类　　61
3.1　处理多类问题　　61
3.1.1　多类分类　　61
3.1.2　多类得分及概率　　65
3.2　回归　　68
3.3　无监督学习及描述性学习　　70
3.3.1　预测性聚类与描述性聚类　　71
3.2.2　其他描述性模型　　74
3.4　小结与延伸阅读　　76
第4章　概念学习　　77
4.1　假设空间　　78
4.1.1　最小一般性　　79
4.1.2　内部析取　　82
4.2　通过假设空间的路径　　84
4.2.1　最一般相容假设　　86
4.2.2　封闭概念　　87
4.3　超越合取概念　　88
4.4　可学习性　　92
4.5　小结与延伸阅读　　94
第5章　树模型　　97
5.1　决策树　　100
5.2　排序与概率估计树　　103
5.3　作为减小方差的树学习方法　　110
5.3.1　回归树　　110
5.3.2　聚类树　　113
5.4　小结与延伸阅读　　115
第6章　规则模型　　117
6.1　学习有序规则列表　　117
6.2　学习无序规则集　　124
6.2.1　用于排序和概率估计的规则集　　128
6.2.2　深入探究规则重叠　　130
6.3　描述性规则学习　　131
6.3.1　用于子群发现的规则学习　　131
6.3.2　关联规则挖掘　　135
6.4　一阶规则学习　　139
6.5　小结与延伸阅读　　143
第7章　线性模型　　145
7.1　最小二乘法　　146
7.1.1　多元线性回归　　150
7.1.2　正则化回归　　153
7.1.3　利用最小二乘回归实现分类　　153
7.2　感知机　　155
7.3　支持向量机　　158
7.4　从线性分类器导出概率　　164
7.5　超越线性的核方法　　168
7.6　小结与延伸阅读　　170
第8章　基于距离的模型　　173
8.1　距离测度的多样性　　173
8.2　近邻与范例　　178
8.3　最近邻分类器　　182
8.4　基于距离的聚类　　184
8.4.1　K均值算法　　186
8.4.2　K中心点聚类　　187
8.4.3　silhouette　　188
8.5　层次聚类　　190
8.6　从核函数到距离　　194
8.7　小结与延伸阅读　　195
第9章　概率模型　　197
9.1　正态分布及其几何意义　　200
9.2　属性数据的概率模型　　205
9.2.1　利用朴素贝叶斯模型实现分类　　206
9.2.2　训练朴素贝叶斯模型　　209
9.3　通过优化条件似然实现鉴别式学习　　211
9.4　含隐变量的概率模型　　214
9.4.1　期望最大化算法　　215
9.4.2　高斯混合模型　　216
9.5　基于压缩的模型　　218
9.6　小结与延伸阅读　　220
第10章　特征　　223
10.1　特征的类型　　223
10.1.1　特征上的计算　　223
10.1.2　属性特征、有序特征及数量特征　　227
10.1.3　结构化特征　　228
10.2　特征变换　　229
10.2.1　阈值化与离散化　　229
10.2.2　归一化与标定　　234
10.2.3　特征缺失　　239
10.3　特征的构造与选择　　240
10.4　小结与延伸阅读　　243
第11章　模型的集成　　245
11.1　Bagging与随机森林　　246
11.2　Boosting　　247
11.3　集成学习进阶　　250
11.3.1　偏差、方差及裕量　　250
11.3.2　其他集成方法　　251
11.3.3　元学习　　252
11.4　小结与延伸阅读　　252
第12章　机器学习的实验　　255
12.1　度量指标的选择　　256
12.2　量指标的获取　　258
12.3　如何解释度量指标　　260
12.4　小结与延伸阅读　　264
后记　路在何方　　267
记忆要点　　269
参考文献　　271
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习系统设计
第1章　Python机器学习入门　　1
1.1 　梦之队：机器学习与Python　　1
1.2 　这本书将教给你什么（以及不会教什么）　　2
1.3 　遇到困难的时候怎么办　　3
1.4 　开始　　4
1.4.1 　NumPy、SciPy和Matplotlib简介　　4
1.4.2 　安装Python　　5
1.4.3 　使用NumPy和SciPy智能高效地处理数据　　5
1.4.4 　学习NumPy　　5
1.4.5 　学习SciPy　　9
1.5 　我们第一个（极小的）机器学习应用　　10
1.5.1 　读取数据　　10
1.5.2 　预处理和清洗数据　　11
1.5.3 　选择正确的模型和学习算法　　12
1.6 　小结　　20
第2章　如何对真实样本分类　　22
2.1 　Iris数据集　　22
2.1.1 　第一步是可视化　　23
2.1.2 　构建第一个分类模型　　24
2.2 　构建更复杂的分类器　　28
2.3 　更复杂的数据集和更复杂的分类器　　29
2.3.1 　从Seeds数据集中学习　　29
2.3.2 　特征和特征工程　　30
2.3.3 　最邻近分类　　30
2.4 　二分类和多分类　　33
2.5 　小结　　34
第3章　聚类：寻找相关的帖子　　35
3.1 　评估帖子的关联性　　35
3.1.1 　不应该怎样　　36
3.1.2 　应该怎样　　36
3.2 　预处理：用相近的公共词语个数来衡量相似性　　37
3.2.1 　将原始文本转化为词袋　　37
3.2.2 　统计词语　　38
3.2.3 　词语频次向量的归一化　　40
3.2.4 　删除不重要的词语　　41
3.2.5 　词干处理　　42
3.2.6 　停用词兴奋剂　　44
3.2.7 　我们的成果和目标　　45
3.3 　聚类　　46
3.3.1 　K均值　　46
3.3.2 　让测试数据评估我们的想法　　49
3.3.3 　对帖子聚类　　50
3.4 　解决我们最初的难题　　51
3.5 　调整参数　　54
3.6 　小结　　54
第4章　主题模型　　55
4.1 　潜在狄利克雷分配（LDA）　　55
4.2 　在主题空间比较相似度　　59
4.3 　选择主题个数　　64
4.4 　小结　　65
第5章　分类：检测劣质答案　　67
5.1 　路线图概述　　67
5.2 　学习如何区分出优秀的答案　　68
5.2.1 　调整样本　　68
5.2.2 　调整分类器　　68
5.3 　获取数据　　68
5.3.1 　将数据消减到可处理的程度　　69
5.3.2 　对属性进行预选择和处理　　70
5.3.3 　定义什么是优质答案　　71
5.4 　创建第一个分类器　　71
5.4.1 　从k邻近（kNN）算法开始　　71
5.4.2 　特征工程　　72
5.4.3 　训练分类器　　73
5.4.4 　评估分类器的性能　　74
5.4.5 　设计更多的特征　　74
5.5 　决定怎样提升效果　　77
5.5.1 　偏差?方差及其折中　　77
5.5.2 　解决高偏差　　78
5.5.3 　解决高方差　　78
5.5.4 　高偏差或低偏差　　78
5.6 　采用逻辑回归　　81
5.6.1 　一点数学和一个小例子　　81
5.6.2 　在帖子分类问题上应用逻辑回归　　83
5.7 　观察正确率的背后：准确率和召回率　　84
5.8 　为分类器瘦身　　87
5.9 　出货　　88
5.10 　小结　　88
第6章　分类II：情感分析　　89
6.1 　路线图概述　　89
6.2 　获取推特（Twitter）数据　　89
6.3 　朴素贝叶斯分类器介绍　　90
6.3.1 　了解贝叶斯定理　　90
6.3.2 　朴素　　91
6.3.3 　使用朴素贝叶斯进行分类　　92
6.3.4 　考虑未出现的词语和其他古怪情况　　94
6.3.5 　考虑算术下溢　　95
6.4 　创建第一个分类器并调优　　97
6.4.1 　先解决一个简单问题　　97
6.4.2 　使用所有的类　　99
6.4.3 　对分类器的参数进行调优　　101
6.5 　清洗推文　　104
6.6 　将词语类型考虑进去　　106
6.6.1 　确定词语的类型　　106
6.6.2 　用SentiWordNet成功地作弊　　108
6.6.3 　我们第一个估算器　　110
6.6.4 　把所有东西融合在一起　　111
6.7 　小结　　112
第7章　回归：推荐　　113
7.1 　用回归预测房价　　113
7.1.1 　多维回归　　116
7.1.2 　回归里的交叉验证　　116
7.2 　惩罚式回归　　117
7.2.1 　L1和L2惩罚　　117
7.2.2 　在Scikit-learn中使用Lasso或弹性网　　118
7.3 　P大于N的情形　　119
7.3.1 　基于文本的例子　　120
7.3.2 　巧妙地设置超参数（hyperparameter）　　121
7.3.3 　评分预测和推荐　　122
7.4 　小结　　126
第8章　回归：改进的推荐　　127
8.1 　改进的推荐　　127
8.1.1 　使用二值推荐矩阵　　127
8.1.2 　审视电影的近邻　　129
8.1.3 　组合多种方法　　130
8.2 　购物篮分析　　132
8.2.1 　获取有用的预测　　133
8.2.2 　分析超市购物篮　　134
8.2.3 　关联规则挖掘　　136
8.2.4 　更多购物篮分析的高级话题　　137
8.3 　小结　　138
第9章　分类III：音乐体裁分类　　139
9.1 　路线图概述　　139
9.2 　获取音乐数据　　139
9.3 　观察音乐　　140
9.4 　用FFT构建第一个分类器　　143
9.4.1 　增加实验敏捷性　　143
9.4.2 　训练分类器　　144
9.4.3 　在多分类问题中用混淆矩阵评估正确率　　144
9.4.4 　另一种方式评估分类器效果：受试者工作特征曲线（ROC）　　146
9.5 　用梅尔倒频谱系数（MFCC）提升分类效果　　148
9.6 　小结　　152
第10章　计算机视觉：模式识别　　154
10.1 　图像处理简介　　154
10.2 　读取和显示图像　　155
10.2.1 　图像处理基础　　156
10.2.2 　加入椒盐噪声　　161
10.2.3 　模式识别　　163
10.2.4 　计算图像特征　　163
10.2.5 　设计你自己的特征　　164
10.3 　在更难的数据集上分类　　166
10.4 　局部特征表示　　167
10.5 　小结　　170
第11章　降维　　171
11.1 　路线图　　171
11.2 　选择特征　　172
11.2.1 　用筛选器检测冗余特征　　172
11.2.2 　用封装器让模型选择特征　　178
11.3 　其他特征选择方法　　180
11.4 　特征抽取　　181
11.4.1 　主成分分析（PCA）　　181
11.4.2 　PCA的局限性以及LDA会有什么帮助　　183
11.5 　多维标度法（MDS）　　184
11.6 　小结　　187
第12章　大数据　　188
12.1 　了解大数据　　188
12.2 　用Jug程序包把你的处理流程分解成几个任务　　189
12.2.1 　关于任务　　189
12.2.2 　复用部分结果　　191
12.2.3 　幕后的工作原理　　192
12.2.4 　用Jug分析数据　　192
12.3 　使用亚马逊Web服务（AWS）　　194
12.3.1 　构建你的第一台机器　　195
12.3.2 　用starcluster自动创建集群　　199
12.4 　小结　　202
附录A 　更多机器学习知识　　203
A.1 　在线资源　　203
A.2 　参考书　　203
A.2.1 　问答网站　　203
A.2.2 　博客　　204
A.2.3 　数据资源　　205
A.2.4 　竞争日益加剧　　205
A.3 　还剩下什么　　205
A.4 　小结　　206
索引　　207

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习系统设计
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>白话机器学习算法
第1章 基础知识 1
1.1　准备数据 1
1.1.1　数据格式 1
1.1.2　变量类型 2
1.1.3　变量选择 3
1.1.4　特征工程 3
1.1.5　缺失数据 4
1.2　选择算法 4
1.2.1　无监督学习 5
1.2.2　监督学习 6
1.2.3　强化学习 7
1.2.4　注意事项 7
1.3　参数调优 7
1.4　评价模型 9
1.4.1　分类指标 9
1.4.2　回归指标 10
1.4.3　验证 10
1.5　小结 11
第2章　k均值聚类 13
2.1　找出顾客群 13
2.2　示例：影迷的性格特征 13
2.3　定义群组 16
2.3.1　有多少个群组 16
2.3.2　每个群组中有谁 17
2.4　局限性 18
2.5　小结 19
第3章　主成分分析 21
3.1　食物的营养成分 21
3.2　主成分 22
3.3　示例：分析食物种类 24
3.4　局限性 27
3.5　小结 29
第4章　关联规则 31
4.1　发现购买模式 31
4.2　支持度、置信度和提升度 31
4.3　示例：分析杂货店的销售数据 33
4.4　先验原则 35
4.4.1　寻找具有高支持度的项集 36
4.4.2　寻找具有高置信度或高提升度的关联规则 37
4.5　局限性 37
4.6　小结 37
第5章　社会网络分析 39
5.1　展现人际关系 39
5.2　示例：国际贸易 40
5.3　Louvain方法 42
5.4　PageRank算法 43
5.5　局限性 46
5.6　小结 47
第6章　回归分析 49
6.1　趋势线 49
6.2　示例：预测房价 49
6.3　梯度下降法 52
6.4　回归系数 54
6.5　相关系数 55
6.6　局限性 56
6.7　小结 57
第7章　k最近邻算法和异常检测 59
7.1　食品检测 59
7.2　物以类聚，人以群分 60
7.3　示例：区分红白葡萄酒 61
7.4　异常检测 62
7.5　局限性 63
7.6　小结 63
第8章　支持向量机 65
8.1　医学诊断 65
8.2　示例：预测心脏病 65
8.3　勾画最佳分界线 66
8.4　局限性 69
8.5　小结 69
第9章　决策树 71
9.1　预测灾难幸存者 71
9.2　示例：逃离泰坦尼克号 72
9.3　生成决策树 73
9.4　局限性 74
9.5　小结 75
第10章　随机森林 77
10.1　集体智慧 77
10.2　示例：预测犯罪行为 77
10.3　集成模型 81
10.4　自助聚集法 82
10.5　局限性 83
10.6　小结 84
第11章　神经网络 85
11.1　建造人工智能大脑 85
11.2　示例：识别手写数字 86
11.3　神经网络的构成 89
11.4　激活规则 91
11.5　局限性 92
11.6　小结 94
第12章　A/B测试和多臂老虎机 95
12.1　初识A/B测试 95
12.2　A/B测试的局限性 95
12.3　epsilon递减策略 96
12.4　示例：多臂老虎机 97
12.5　胜者为先 99
12.6　epsilon递减策略的局限性 99
12.7　小结 100
附录A　无监督学习算法概览 101
附录B　监督学习算法概览 102
附录C　调节参数列表 103
附录D　更多评价指标 104
术语表 107
关于作者 114
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>白话机器学习算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>漫画机器学习入门
第1 章 一无所知的魔镜
1-1 王后与魔镜的出场 2
1-2 尝试机器学习 6
知识专栏 什么是机器学习 9
1-3 数据是机器学习的条件 10
知识专栏 机器的自己学习 13
第2 章 美丽的秘诀
2-1 魔镜的回答 15
知识专栏 数学的重要性 19
2-2 挑战回归问题 20
知识专栏 机器能和人一样吗？ 26
2-3 描述美丽程度的函数 27
知识专栏 机器学习的老师 36
第3 章 挑战优解
3-1 学习热情高涨的王后 38
知识专栏 要善于学习好的算法 48
3-2 模型的力量 49
知识专栏 训练用数据和测试用数据 53
3-3 寻找新的特征量 54
知识专栏 函数的复杂性 61
3-4 人工神经网络 62
知识专栏 大脑的信息处理机能 65
第4 章 挑战深度学习
4-1 多层神经网络 67
知识专栏 深度学习的提出 75
4-2 防止过度学习 76
知识专栏 要战胜过度学习 80
4-3 批量学习与在线学习 81
知识专栏 概率梯度下降法 91
第5 章 预测未来
5-1 魔镜的识别能力 93
5-2 寻找边界条件 95
知识专栏 支持向量机的通用性 101
5-3 数据可以分割到什么程度？ 102
知识专栏 能够实现空间变形的内核法 106
5-4 填补空数据 107
知识专栏 数据的由来 114
5-5 挖掘数据中的本质 115
知识专栏 简洁性与人的直觉 121
第6 章 无所不能的魔镜
6-1 图像数据的重要性 123
知识专栏 磁铁也能机器学习？ 125
6-2 基于玻尔兹曼机器学习的图像处理方法 126
知识专栏 机器学习和统计力学 141
6-3 获取更加复杂的特征 142
知识专栏 变分原理 147
6-4 多彩世界中的隐含变量 148
知识专栏 数据的采集 154
6-5 寻找复杂数据的本质 155
知识专栏 Hinton的故事 166
第7 章 看脸识美人
7-1的魔镜 168
7-2 原来魔镜是这样工作的 179
魔镜的制作方法（参考书籍） 185
后序 192
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>漫画机器学习入门
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践指南
前　言
第一部分 准备篇
第1章 机器学习发展及应用前景	2
1.1 机器学习概述	2
1.1.1 什么是机器学习	3
1.1.2 机器学习的发展	3
1.1.3 机器学习的未来	4
1.2 机器学习应用前景	5
1.2.1 数据分析与挖掘	5
1.2.2 模式识别	5
1.2.3 更广阔的领域	6
1.3 小结	7
第2章 科学计算平台	8
2.1 科学计算软件平台概述	8
2.1.1 常用的科学计算软件	9
2.1.2 本书使用的工程计算平台	10
2.2 计算平台的配置	11
2.2.1 numpy等python科学计算包的安装与配置	11
2.2.2 opencv 安装与配置	13
2.2.3 mlpy 安装与配置	14
2.2.4 beautifulsoup安装与配置	15
2.2.5 neurolab安装与配置	15
2.2.6 r安装与配置	15
2.3 小结	16
第二部分 基础篇
第3章 机器学习数学基础	18
3.1 数学对我们有用吗	18
3.2 机器学习需要哪些数学知识	20
3.3 小结	25
第4章 计算平台应用实例	26
4.1 python计算平台简介及应用实例	26
4.1.1 python语言基础	26
4.1.2 numpy库	37
4.1.3 pylab、matplotlib绘图	44
4.1.4 图像基础	46
4.1.5 图像融合与图像镜像	55
4.1.6 图像灰度化与图像加噪	57
4.1.7 声音基础	60
4.1.8 声音音量调节	63
4.1.9 图像信息隐藏	68
4.1.10 声音信息隐藏	72
4.2 r语言基础	78
4.2.1 基本操作	78
4.2.2 向量	81
4.2.3 对象集属性	87
4.2.4 因子和有序因子	88
4.2.5 循环语句	89
4.2.6 条件语句	89
4.3 r语言科学计算	90
4.3.1 分类（组）统计	90
4.3.2 数组与矩阵基础	91
4.3.3 数组运算	94
4.3.4 矩阵运算	95
4.4 r语言计算实例	103
4.4.1 学生数据集读写	103
4.4.2 最小二乘法拟合	105
4.4.3 交叉因子频率分析	106
4.4.4 向量模长计算	107
4.4.5 欧氏距离计算	108
4.5 小结	109
思考题	109
第三部分 统计分析实战篇
第5章 统计分析基础	112
5.1 数据分析概述	112
5.2 数学基础	113
5.3 回归分析	118
5.3.1 单变量线性回归	118
5.3.2 多元线性回归	121
5.3.3 非线性回归	121
5.4 数据分析基础	124
5.4.1 区间频率分布	124
5.4.2 数据直方图	126
5.4.3 数据散点图	127
5.4.4 五分位数 129
5.4.5 累积分布函数	130
5.4.6 核密度估计	130
5.5 数据分布分析	132
5.6 小结	134
思考题	135
第6章 统计分析案例	136
6.1 数据图形化案例解析	136
6.1.1 点图	136
6.1.2 饼图和条形图	137
6.1.3 茎叶图和箱线图	138
6.2 数据分布趋势案例解析	140
6.2.1 平均值	140
6.2.2 加权平均值	140
6.2.3 数据排序	141
6.2.4 中位数	142
6.2.5 极差、半极差	142
6.2.6 方差	143
6.2.7 标准差	143
6.2.8 变异系数、样本平方和	143
6.2.9 偏度系数、峰度系数	144
6.3 正态分布案例解析	145
6.3.1 正态分布函数	145
6.3.2 峰度系数分析	146
6.3.3 累积分布概率	146
6.3.4 概率密度函数	147
6.3.5 分位点	148
6.3.6 频率直方图	151
6.3.7 核概率密度与正态概率分布图	151
6.3.8 正太检验与分布拟合	152
6.3.9 其他分布及其拟合	154
6.4 小结	155
思考题	155
第四部分 机器学习实战篇
第7章 机器学习算法	158
7.1 神经网络	158
7.1.1 rosenblatt感知器	159
7.1.2 梯度下降 173
7.1.3 反向传播与多层感知器	180
7.1.4 python神经网络库	199
7.2 统计算法	201
7.2.1 平均值	201
7.2.2 方差与标准差	203
7.2.3 贝叶斯算法	205
7.3 欧氏距离	208
7.4 余弦相似度	209
7.5 svm 210
7.5.1 数学原理	210
7.5.2 smo算法	212
7.5.3 算法应用	212
7.6 回归算法	217
7.6.1 线性代数基础	217
7.6.2 最小二乘法原理	218
7.6.3 线性回归	219
7.6.4 多元非线性回归	221
7.6.5 岭回归方法	223
7.6.6 伪逆方法	224
7.7 pca降维	225
7.8 小结	227
思考题	227
第8章 数据拟合案例	228
8.1 数据拟合	228
8.1.1 图像分析法	228
8.1.2 神经网络拟合法	240
8.2 线性滤波	256
8.2.1 wav声音文件	256
8.2.2 线性滤波算法过程	256
8.2.3 滤波python实现	257
8.3 小结	262
思考题	262
第9章 图像识别案例	264
9.1 图像边缘算法	264
9.1.1 数字图像基础	264
9.1.2 算法描述	265
9.2 图像匹配	266
9.2.1 差分矩阵求和	267
9.2.2 差分矩阵均值	269
9.2.3 欧氏距离匹配	271
9.3 图像分类	277
9.3.1 余弦相似度	277
9.3.2 pca图像特征提取算法	283
9.3.3 基于神经网络的图像分类	284
9.3.4 基于svm的图像分类	289
9.4 人脸辨识	291
9.4.1 人脸定位	291
9.4.2 人脸辨识	293
9.5 手写数字识别	300
9.5.1 手写数字识别算法	300
9.5.2 算法的python实现	301
9.6 小结	303
思考题	304
第10章 文本分类案例	305
10.1 文本分类概述	305
10.2 余弦相似度分类	306
10.2.1 中文分词	306
10.2.2 停用词清理	308
10.2.3 算法实战	310
10.3 朴素贝叶斯分类	315
10.3.1 算法描述	316
10.3.2 先验概率计算	316
10.3.3 最大后验概率	316
10.3.4 算法实现	317
10.4 小结	323
思考题	323
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础教程
出版者的话
译者序
前言
第1章　线性建模：最小二乘法1
1.1　线性建模1
1.1.1　定义模型2
1.1.2　模型假设2
1.1.3　定义什么是好的模型3
1.1.4　最小二乘解：一个有效的例子4
1.1.5　有效的例子7
1.1.6　奥运会数据的最小二乘拟合8
1.1.7　小结9
1.2　预测9
1.2.1　第二个奥运会数据集10
1.2.2　小结12
1.3　向量/矩阵符号12
1.3.1　例子17
1.3.2　数值的例子18
1.3.3　预测19
1.3.4　小结19
1.4　线性模型的非线性响应19
1.5　泛化与过拟合22
1.5.1　验证数据22
1.5.2　交叉验证23
1.5.3　K折交叉验证的计算缩放25
1.6　正则化最小二乘法25
1.7　练习27
其他阅读材料28
第2章　线性建模：最大似然方法29
2.1　误差作为噪声29
2.2　随机变量和概率30
2.2.1　随机变量30
2.2.2　概率和概率分布31
2.2.3　概率的加法32
2.2.4　条件概率32
2.2.5　联合概率33
2.2.6　边缘化34
2.2.7　贝叶斯规则介绍36
2.2.8　期望值37
2.3　常见的离散分布39
2.3.1　伯努利分布39
2.3.2　二项分布39
2.3.3　多项分布40
2.4　连续型随机变量——概率密度函数40
2.5　常见的连续概率密度函数42
2.5.1　均匀密度函数42
2.5.2　β密度函数43
2.5.3　高斯密度函数44
2.5.4　多元高斯44
2.5.5　小结46
2.6　产生式的考虑（续）46
2.7　似然估计47
2.7.1　数据集的似然值48
2.7.2　最大似然49
2.7.3　最大似然解的特点50
2.7.4　最大似然法适用于复杂模型52
2.8　偏差方差平衡问题53
2.9　噪声对参数估计的影响53
2.9.1　参数估计的不确定性54
2.9.2　与实验数据比较57
2.9.3　模型参数的变异性——奥运会数据58
2.10　预测值的变异性59
2.10.1　预测值的变异性——一个例子59
2.10.2　估计值的期望值61
2.10.3　小结63
2.11　练习63
其他阅读材料64
第3章　机器学习的贝叶斯方法66
3.1　硬币游戏66
3.1.1　计算正面朝上的次数67
3.1.2　贝叶斯方法67
3.2　精确的后验70
3.3　三个场景71
3.3.1　没有先验知识71
3.3.2　公平的投币76
3.3.3　有偏的投币78
3.3.4　三个场景——总结80
3.3.5　增加更多的数据80
3.4　边缘似然估计80
3.5　超参数82
3.6　图模型83
3.7　奥运会100米数据的贝叶斯处理实例84
3.7.1　模型84
3.7.2　似然估计85
3.7.3　先验概率85
3.7.4　后验概率85
3.7.5　1阶多项式87
3.7.6　预测89
3.8　边缘似然估计用于多项式模型阶的选择90
3.9　小结91
3.10　练习91
其他阅读材料92
第4章　贝叶斯推理94
4.1　非共轭模型94
4.2　二值响应94
4.3　点估计：最大后验估计方案96
4.4　拉普拉斯近似100
4.4.1　拉普拉斯近似实例：近似γ密度101
4.4.2　二值响应模型的拉普拉斯近似102
4.5　抽样技术103
4.5.1　玩飞镖游戏104
4.5.2　Metropolis-Hastings算法105
4.5.3　抽样的艺术110
4.6　小结111
4.7　练习111
其他阅读材料111
第5章　分类113
5.1　一般问题113
5.2　概率分类器113
5.2.1　贝叶斯分类器114
5.2.2　逻辑回归121
5.3　非概率分类器123
5.3.1　K近邻算法123
5.3.2　支持向量机和其他核方法…125
5.3.3　小结132
5.4　评价分类器的性能133
5.4.1　准确率——0/1损失133
5.4.2　敏感性和特异性133
5.4.3　ROC曲线下的区域134
5.4.4　混淆矩阵135
5.5　判别式和产生式分类器136
5.6　小结136
5.7　练习136
其他阅读材料137
第6章　聚类分析138
6.1　一般问题138
6.2　K均值聚类139
6.2.1　聚类数目的选择141
6.2.2　K均值的不足之处141
6.2.3　核化K均值141
6.2.4　小结144
6.3　混合模型144
6.3.1　生成过程144
6.3.2　混合模型似然函数146
6.3.3　EM算法146
6.3.4　例子151
6.3.5　EM寻找局部最优153
6.3.6　组分数目的选择153
6.3.7　混合组分的其他形式154
6.3.8　用EM估计MAP156
6.3.9　贝叶斯混合模型157
6.4　小结157
6.5　练习157
其他阅读材料158
第7章　主成分分析与隐变量模型159
7.1　一般问题159
7.2　主成分分析161
7.2.1　选择D164
7.2.2　PCA的局限性165
7.3　隐变量模型165
7.3.1　隐变量模型中的混合模型165
7.3.2　小结166
7.4　变分贝叶斯166
7.4.1　选择Q（θ）167
7.4.2　优化边界168
7.5　PCA的概率模型168
7.5.1　Qτ（τ）169
7.5.2　Qxn（xn）170
7.5.3　Qwn（wm）171
7.5.4　期望值要求171
7.5.5　算法172
7.5.6　例子173
7.6　缺失值174
7.6.1　缺失值作为隐变量176
7.6.2　预测缺失值176
7.7　非实值数据177
7.7.1　概率PPCA177
7.7.2　议会数据可视化180
7.8　小结184
7.9　练习184
其他阅读材料184
词汇表185
索引188
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础教程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘：实用机器学习工具与技术（原书第3版）
目　录
Data Mining：Practical Machine Learning Tools and Techniques，Third Edition
出版者的话
译者序
前言
致谢
第一部分　数据挖掘简介
第1章　绪论2
1.1　数据挖掘和机器学习2
1.1.1　描述结构模式3
1.1.2　机器学习5
1.1.3　数据挖掘6
1.2　简单的例子：天气问题和其他问题6
1.2.1　天气问题7
1.2.2　隐形眼镜：一个理想化的问题8
1.2.3　鸢尾花：一个经典的数值型数据集10
1.2.4　CPU性能：介绍数值预测11
1.2.5　劳资协商：一个更真实的例子11
1.2.6　大豆分类：一个经典的机器学习的成功例子13
1.3　应用领域14
1.3.1　Web挖掘15
1.3.2　包含评判的决策15
1.3.3　图像筛选16
1.3.4　负载预测17
1.3.5　诊断17
1.3.6　市场和销售18
1.3.7　其他应用19
1.4　机器学习和统计学20
1.5　将泛化看做搜索21
1.5.1　枚举概念空间22
1.5.2　偏差22
1.6　数据挖掘和道德24
1.6.1　再识别25
1.6.2　使用个人信息25
1.6.3　其他问题26
1.7　补充读物27
第2章　输入：概念、实例和属性29
2.1　概念29
2.2　样本31
2.2.1　关系32
2.2.2　其他实例类型34
2.3　属性35
2.4　输入准备37
2.4.1　数据收集37
2.4.2　ARFF格式38
2.4.3　稀疏数据40
2.4.4　属性类型40
2.4.5　缺失值41
2.4.6　不正确的值42
2.4.7　了解数据43
2.5　补充读物43
第3章　输出：知识表达44
3.1　表44
3.2　线性模型44
3.3　树45
3.4　规则48
3.4.1　分类规则49
3.4.2　关联规则52
3.4.3　包含例外的规则52
3.4.4　表达能力更强的规则54
3.5　基于实例的表达56
3.6　聚类58
3.7　补充读物60
第4章　算法：基本方法61
4.1　推断基本规则61
4.1.1　缺失值和数值属性62
4.1.2　讨论64
4.2　统计建模64
4.2.1　缺失值和数值属性67
4.2.2　用于文档分类的朴素贝叶斯68
4.2.3　讨论70
4.3　分治法：建立决策树70
4.3.1　计算信息量73
4.3.2　高度分支属性74
4.3.3　讨论75
4.4　覆盖算法：建立规则76
4.4.1　规则与树77
4.4.2　一个简单的覆盖算法77
4.4.3　规则与决策列表80
4.5　挖掘关联规则81
4.5.1　项集81
4.5.2　关联规则83
4.5.3　有效地生成规则85
4.5.4　讨论87
4.6　线性模型87
4.6.1　数值预测：线性回归87
4.6.2　线性分类：Logistic回归88
4.6.3　使用感知机的线性分类90
4.6.4　使用Winnow的线性分类91
4.7　基于实例的学习92
4.7.1　距离函数93
4.7.2　有效寻找最近邻93
4.7.3　讨论97
4.8　聚类97
4.8.1　基于距离的迭代聚类98
4.8.2　快速距离计算99
4.8.3　讨论100
4.9　多实例学习100
4.9.1　聚集输入100
4.9.2　聚集输出100
4.9.3　讨论101
4.10　补充读物101
4.11　Weka实现103
第5章　可信度：评估学习结果104
5.1　训练和测试104
5.2　预测性能106
5.3　交叉验证108
5.4　其他评估方法109
5.4.1　留一交叉验证109
5.4.2　自助法109
5.5　数据挖掘方法比较110
5.6　预测概率113
5.6.1　二次损失函数114
5.6.2　信息损失函数115
5.6.3　讨论115
5.7　计算成本116
5.7.1　成本敏感分类117
5.7.2　成本敏感学习118
5.7.3　提升图119
5.7.4　ROC曲线122
5.7.5　召回率-精确率曲线124
5.7.6　讨论124
5.7.7　成本曲线125
5.8　评估数值预测127
5.9　最小描述长度原理129
5.10　在聚类方法中应用MDL原理131
5.11　补充读物132
第二部分　高级数据挖掘
第6章　实现：真正的机器学习方案134
6.1　决策树135
6.1.1　数值属性135
6.1.2　缺失值136
6.1.3　剪枝137
6.1.4　估计误差率138
6.1.5　决策树归纳的复杂度140
6.1.6　从决策树到规则140
6.1.7　C4.5:选择和选项141
6.1.8　成本-复杂度剪枝141
6.1.9　讨论142
6.2　分类规则142
6.2.1　选择测试的标准143
6.2.2　缺失值和数值属性143
6.2.3　生成好的规则144
6.2.4　使用全局优化146
6.2.5　从局部决策树中获得规则146
6.2.6　包含例外的规则149
6.2.7　讨论151
6.3　关联规则152
6.3.1　建立频繁模式树152
6.3.2　寻找大项集157
6.3.3　讨论157
6.4　扩展线性模型158
6.4.1　最大间隔超平面159
6.4.2　非线性类边界160
6.4.3　支持向量回归161
6.4.4　核岭回归163
6.4.5　核感知机164
6.4.6　多层感知机165
6.4.7　径向基函数网络171
6.4.8　随机梯度下降172
6.4.9　讨论173
6.5　基于实例的学习174
6.5.1　减少样本集的数量174
6.5.2　对噪声样本集剪枝174
6.5.3　属性加权175
6.5.4　泛化样本集176
6.5.5　用于泛化样本集的距离函数176
6.5.6　泛化的距离函数177
6.5.7　讨论178
6.6　局部线性模型用于数值预测178
6.6.1　模型树179
6.6.2　构建树179
6.6.3　对树剪枝180
6.6.4　名目属性180
6.6.5　缺失值181
6.6.6　模型树归纳的伪代码181
6.6.7　从模型树到规则184
6.6.8　局部加权线性回归184
6.6.9　讨论185
6.7　贝叶斯网络186
6.7.1　预测186
6.7.2　学习贝叶斯网络189
6.7.3　算法细节190
6.7.4　用于快速学习的数据结构192
6.7.5　讨论194
6.8　聚类194
6.8.1　选择聚类的个数195
6.8.2　层次聚类195
6.8.3　层次聚类的例子196
6.8.4　增量聚类199
6.8.5　分类效用203
6.8.6　基于概率的聚类204
6.8.7　EM算法205
6.8.8　扩展混合模型206
6.8.9　贝叶斯聚类207
6.8.10　讨论209
6.9　半监督学习210
6.9.1　用于分类的聚类210
6.9.2　协同训练212
6.9.3　EM和协同训练212
6.9.4　讨论213
6.10　多实例学习213
6.10.1　转换为单实例学习213
6.10.2　升级学习算法215
6.10.3　专用多实例方法215
6.10.4　讨论216
6.11　Weka实现216
第7章　数据转换218
7.1　属性选择219
7.1.1　独立于方案的选择220
7.1.2　搜索属性空间222
7.1.3　具体方案相关的选择223
7.2　离散化数值属性225
7.2.1　无监督离散化226
7.2.2　基于熵的离散化226
7.2.3　其他离散化方法229
7.2.4　基于熵的离散化与基于误差的离散化229
7.2.5　离散属性转换成数值属性230
7.3　投影230
7.3.1　主成分分析231
7.3.2　随机投影233
7.3.3　偏最小二乘回归233
7.3.4　从文本到属性向量235
7.3.5　时间序列236
7.4　抽样236
7.5　数据清洗237
7.5.1　改进决策树237
7.5.2　稳健回归238
7.5.3　检测异常239
7.5.4　一分类学习239
7.6　多分类问题转换成二分类问题242
7.6.1　简单方法242
7.6.2　误差校正输出编码243
7.6.3　集成嵌套二分法244
7.7　校准类概率246
7.8　补充读物247
7.9　Weka实现249
第8章　集成学习250
8.1　组合多种模型250
8.2　装袋251
8.2.1　偏差-方差分解251
8.2.2　考虑成本的装袋253
8.3　随机化253
8.3.1　随机化与装袋254
8.3.2　旋转森林254
8.4　提升255
8.4.1　AdaBoost算法255
8.4.2　提升算法的威力257
8.5　累加回归258
8.5.1　数值预测258
8.5.2　累加Logistic回归259
8.6　可解释的集成器260
8.6.1　选择树260
8.6.2　Logistic模型树262
8.7　堆栈262
8.8　补充读物264
8.9　Weka实现265
第9章　继续：扩展和应用266
9.1　应用数据挖掘266
9.2　从大型的数据集里学习268
9.3　数据流学习270
9.4　融合领域知识272
9.5　文本挖掘273
9.6　Web挖掘276
9.7　对抗情形278
9.8　无处不在的数据挖掘280
9.9　补充读物281
第三部分　Weka数据挖掘平台
第10章　Weka简介284
10.1　Weka中包含了什么284
10.2　如何使用Weka285
10.3　Weka的其他应用286
10.4　如何得到Weka286
第11章　Explorer界面287
11.1　开始287
11.1.1　准备数据287
11.1.2　将数据载入Explorer288
11.1.3　建立决策树289
11.1.4　查看结果290
11.1.5　重做一遍292
11.1.6　运用模型292
11.1.7　运行错误的处理294
11.2　探索Explorer294
11.2.1　载入及过滤文件294
11.2.2　训练和测试学习方案299
11.2.3　自己动手：用户分类器301
11.2.4　使用元学习器304
11.2.5　聚类和关联规则305
11.2.6　属性选择306
11.2.7　可视化306
11.3　过滤算法307
11.3.1　无监督属性过滤器307
11.3.2　无监督实例过滤器312
11.3.3　有监督过滤器314
11.4　学习算法316
11.4.1　贝叶斯分类器317
11.4.2　树320
11.4.3　规则322
11.4.4　函数325
11.4.5　神经网络331
11.4.6　懒惰分类器334
11.4.7　多实例分类器335
11.4.8　杂项分类器336
11.5　元学习算法336
11.5.1　装袋和随机化337
11.5.2　提升338
11.5.3　组合分类器338
11.5.4　成本敏感学习339
11.5.5　优化性能339
11.5.6　针对不同任务重新调整分类器340
11.6　聚类算法340
11.7　关联规则学习器345
11.8　属性选择346
11.8.1　属性子集评估器347
11.8.2　单一属性评估器347
11.8.3　搜索方法348
第12章　Knowledge Flow界面351
12.1　开始351
12.2　Knowledge Flow组件353
12.3　配置及连接组件354
12.4　增量学习356
第13章　Experimenter界面358
13.1　开始358
13.1.1　运行一个实验358
13.1.2　分析结果359
13.2　简单设置362
13.3　高级设置363
13.4　分析面板365
13.5　将运行负荷分布到多个机器上366
第14章　命令行界面368
14.1　开始368
14.2　Weka的结构368
14.2.1　类、实例和包368
14.2.2　weka.core包370
14.2.3　weka.classifiers包371
14.2.4　其他包372
14.2.5　Javadoc索引373
14.3　命令行选项373
14.3.1　通用选项374
14.3.2　与具体方案相关的选项375
第15章　嵌入式机器学习376
15.1　一个简单的数据挖掘应用376
15.1.1　MessageClassifier（）380
15.1.2　updateData（）380
15.1.3　classifyMessage（）381
第16章　编写新的学习方案382
16.1　一个分类器范例382
16.1.1　buildClassifier（）389
16.1.2　makeTree（）389
16.1.3　computeInfoGain（）390
16.1.4　classifyInstance（）390
16.1.5　toSource（）391
16.1.6　main（）394
16.2　与实现分类器有关的惯例395
第17章　Weka Explorer的辅导练习397
17.1　Explorer界面简介397
17.1.1　导入数据集397
17.1.2　数据集编辑器397
17.1.3　应用过滤器398
17.1.4　可视化面板399
17.1.5　分类器面板399
17.2　最近邻学习和决策树402
17.2.1　玻璃数据集402
17.2.2　属性选择403
17.2.3　类噪声以及最近邻学习403
17.2.4　改变训练数据的数量404
17.2.5　交互式建立决策树405
17.3　分类边界406
17.3.1　可视化1R406
17.3.2　可视化最近邻学习407
17.3.3　可视化朴素贝叶斯407
17.3.4　可视化决策树和规则集407
17.3.5　弄乱数据408
17.4　预处理以及参数调整408
17.4.1　离散化408
17.4.2　离散化的更多方面408
17.4.3　自动属性选择409
17.4.4　自动属性选择的更多方面410
17.4.5　自动参数调整410
17.5　文档分类411
17.5.1　包含字符串属性的数据411
17.5.2　实际文档文类412
17.5.3　探索StringToWordVector过滤器413
17.6　挖掘关联规则413
17.6.1　关联规则挖掘413
17.6.2　挖掘一个真实的数据集415
17.6.3　购物篮分析415
参考文献416
索引431
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘：实用机器学习工具与技术（原书第3版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>面向机器学习的自然语言标注
前言1
第1章基础知识7
1.1语言标注的重要性7
1.1.1语言学描述的层次8
1.1.2什么是自然语言处理9
1.2语料库语言学简史10
1.2.1什么是语料库13
1.2.2语料库的早期应用15
1.2.3当今的语料库17
1.2.4标注类型18
1.3语言数据和机器学习24
1.3.1分类25
1.3.2聚类25
1.3.3结构化模式归纳26
1.4标注开发循环26
1.4.1现象建模27
1.4.2按照规格说明进行标注30
1.4.3在语料库上训练和测试算法31
1.4.4对结果进行评价32
1.4.5修改模型和算法33
总结34
第2章确定目标与选择数据36
2.1定义目标36
2.1.1目标陈述37
2.1.2提炼目标：信息量与正确性38
2.2背景研究43
2.2.1语言资源44
2.2.2机构与会议44
2.2.3自然语言处理竞赛45
2.3整合数据集46
2.3.1理想的语料库：代表性与平衡性47
2.3.2从因特网上收集数据47
2.3.3从人群中获取数据48
2.4语料库的规模49
2.4.1现有语料库50
2.4.2语料库内部的分布51
总结53
第3章语料库分析54
3.1语料库分析中的基本概率知识55
3.1.1联合概率分布56
3.1.2贝叶斯定理58
3.2计算出现次数58
3.2.1齐普夫定律（Zip'sLaw）61
3.2.2n元语法62
3.3语言模型63
总结65
第4章建立模型与规格说明66
4.1模型和规格说明示例66
4.1.1电影题材分类69
4.1.2添加命名实体70
4.1.3语义角色71
4.2采用（或不采用）现有模型73
4.2.1创建模型和规格说明：一般性与特殊性74
4.2.2使用现有模型和规格说明76
4.2.3使用没有规格说明的模型78
4.3各种标准78
4.3.1ISO标准78
4.3.2社区驱动型标准81
4.3.3影响标注的其他标准81
总结82
第5章选择并应用标注标准84
5.1元数据标注：文档分类85
5.1.1单标签标注：电影评论85
5.1.2多标签标注：电影题材87
5.2文本范围标注：命名实体90
5.2.1内嵌式标注90
5.2.2基于词例的分离式标注92
5.2.3基于字符位置的分离式标注95
5.3链接范围标注：语义角色96
5.4ISO标准和你97
总结97
第6章标注与审核99
6.1标注项目的基本结构99
6.2标注规格说明与标注指南101
6.3准备修改102
6.4准备用于标注的数据103
6.4.1元数据103
6.4.2数据预处理104
6.4.3为标注工作分割文件104
6.5撰写标注指南105
6.5.1例1：单标签标注——电影评论106
6.5.2例2：多标签标注——电影题材108
6.5.3例3：范围标注——命名实体111
6.5.4例4：链接范围标注——语义角色112
6.6标注人员114
6.7选择标注环境116
6.8评价标注结果117
6.8.1Cohen的Kappa（κ）算法118
6.8.2Fleiss的Kappa（κ）算法119
6.8.3解释Kappa系数122
6.8.4在其他上下文中计算κ值123
6.9创建黄金标准（审核）125
总结126
第7章训练：机器学习129
7.1何谓学习130
7.2定义学习任务132
7.3分类算法133
7.3.1决策树学习135
7.3.2朴素贝叶斯学习140
7.3.3最大熵分类器145
7.3.4其他需要了解的分类器147
7.4序列归纳算法148
7.5聚类和无监督学习150
7.6半监督学习150
7.7匹配标注与算法153
总结154
第8章测试与评价156
8.1测试算法157
8.2评价算法157
8.2.1混淆矩阵157
8.2.2计算评价得分159
8.2.3解释评价得分163
8.3可能影响算法评价的问题164
8.3.1数据集太小164
8.3.2算法过于适合开发数据166
8.3.3标注中的信息过多166
8.4最后测试得分167
总结167
……
第9章修改与报告169
第10章标注：TimeML179
第11章自动标注：生成TimeML199
第12章后记：标注的未来发展趋势217
附录A可利用的语料库与标注规格说明列表227
附录B软件资源列表249
附录CMAE用户指南269
附录DMAI用户指南276
附录E参考文献282
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>面向机器学习的自然语言标注
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习实践指南
第1章Python机器学习的生态系统1
1.1数据科学／机器学习的工作流程2
1.1.1获取2
1.1.2检查和探索2
1.1.3清理和准备3
1.1.4建模3
1.1.5评估3
1.1.6部署3
1.2Python库和功能3
1.2.1获取4
1.2.2检查4
1.2.3准备20
1.2.4建模和评估26
1.2.5部署34
1.3设置机器学习的环境34
1.4小结34
第2章构建应用程序，发现低价的公寓35
2.1获取公寓房源数据36
使用import.io抓取房源数据36
2.2检查和准备数据38
2.2.1分析数据46
2.2.2可视化数据50
2.3对数据建模51
2.3.1预测54
2.3.2扩展模型57
2.4小结57
第3章构建应用程序，发现低价的机票58
3.1获取机票价格数据59
3.2使用高级的网络爬虫技术检索票价数据60
3.3解析DOM以提取定价数据62
通过聚类技术识别异常的票价66
3.4使用IFTTT发送实时提醒75
3.5整合在一起78
3.6小结82
第4章使用逻辑回归预测IPO市场83
4.1IPO市场84
4.1.1什么是IPO84
4.1.2近期IPO市场表现84
4.1.3基本的IPO策略93
4.2特征工程94
4.3二元分类103
4.4特征的重要性108
4.5小结111
第5章创建自定义的新闻源112
5.1使用Pocket应用程序，创建一个监督训练的集合112
5.1.1安装Pocket的Chrome扩展程序113
5.1.2使用PocketAPI来检索故事114
5.2使用embed.lyAPI下载故事的内容119
5.3自然语言处理基础120
5.4支持向量机123
5.5IFTTT与文章源、Google表单和电子邮件的集成125
通过IFTTT设置新闻源和Google表单125
5.6设置你的每日个性化新闻简报133
5.7小结137
第6章预测你的内容是否会广为流传138
6.1关于病毒性，研究告诉我们了些什么139
6.2获取分享的数量和内容140
6.3探索传播性的特征149
6.3.1探索图像数据149
6.3.2探索标题152
6.3.3探索故事的内容156
6.4构建内容评分的预测模型157
6.5小结162
第7章使用机器学习预测股票市场163
7.1市场分析的类型164
7.2关于股票市场，研究告诉我们些什么165
7.3如何开发一个交易策略166
7.3.1延长我们的分析周期172
7.3.2使用支持向量回归，构建我们的模型175
7.3.3建模与动态时间扭曲182
7.4小结186
第8章建立图像相似度的引擎187
8.1图像的机器学习188
8.2处理图像189
8.3查找相似的图像191
8.4了解深度学习195
8.5构建图像相似度的引擎198
8.6小结206
第9章打造聊天机器人207
9.1图灵测试207
9.2聊天机器人的历史208
9.3聊天机器人的设计212
9.4打造一个聊天机器人217
9.5小结227
第10章构建推荐引擎228
10.1协同过滤229
10.1.1基于用户的过滤230
10.1.2基于项目的过滤233
10.2基于内容的过滤236
10.3混合系统237
10.4构建推荐引擎238
10.5小结251
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习实践指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python大战机器学习
第一篇机器学习基础篇 1
第 1章线性模型 .................................................. 2
1.1概述 2
1.2算法笔记精华 2
1.2.1普通线性回归 2
1.2.2广义线性模型 5
1.2.3逻辑回归 5
1.2.4线性判别分析 7
1.3 Python实战 10
1.3.1线性回归模型 11
1.3.2线性回归模型的正则化 12
1.3.3逻辑回归 22
1.3.4线性判别分析 26
第 2章决策树 .................................................... 30
2.1概述 30
2.2算法笔记精华 30
2.1决策树原理 30
2.2构建决策树的 3个步骤 31
CART算法 37
2.4连续值和缺失值的处理 42
2.3 Python实战 43
2.3.1回归决策树（DecisionTreeRegressor） 43
2.3.2分类决策树（DecisionTreeClassiﬁr） 49
2.3.3决策图 54
第 3章贝叶斯分类器.............................................. 55
3.1概述 55
3.2 算法笔记精华55
3.2.1 贝叶斯定理55
3.2.2 朴素贝叶斯法56
3.3 Python 实战59
3.3.1 高斯贝叶斯分类器（GaussianNB） 61
3.3.2 多项式贝叶斯分类器（MultinomialNB） 62
3.3.3 伯努利贝叶斯分类器（BernoulliNB） 65
3.3.4 递增式学习partial_fit 方法69
第4 章k 近邻法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
4.1 概述70
4.2 算法笔记精华70
4.2.1 kNN 三要素70
4.2.2 k 近邻算法72
4.2.3 kd 树73
4.3 Python 实践74
第5 章数据降维. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
5.1 概述83
5.2 算法笔记精华83
5.2.1 维度灾难与降维83
5.2.2 主成分分析（PCA） 84
5.2.3 SVD 降维91
5.2.4 核化线性（KPCA）降维91
5.2.5 流形学习降维93
5.2.6 多维缩放（MDS）降维93
5.2.7 等度量映射（Isomap）降维96
5.2.8 局部线性嵌入（LLE） 97
5.3 Python 实战99
5.4 小结118
第6 章聚类和EM 算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
6.1 概述119
6.2 算法笔记精华120
6.2.1 聚类的有效性指标120
6.2.2 距离度量122
6.2.3 原型聚类123
6.2.4 密度聚类126
6.2.5层次聚类 127
6.2.6 EM算法 128
6.2.7实际中的聚类要求 136
6.3 Python实战 137
K均值聚类（KMeans） 138
3.2密度聚类（DBSCAN） 143
3.3层次聚类（AgglomerativeClustering） 146
3.4混合高斯（GaussianMixture）模型 149
6.4小结 153
第二篇机器学习高级篇 155
第 7章支持向量机 ................................................ 156
7.1概述 156
7.2算法笔记精华 157
2.1线性可分支持向量机 157
2.2线性支持向量机 162
2.3非线性支持向量机 166
2.4支持向量回归 167
SVM的优缺点 170
7.3 Python实战 170
7.3.1线性分类 SVM 171
7.3.2非线性分类 SVM 175
7.3.3线性回归 SVR 182
7.3.4非线性回归 SVR 186
第 8章人工神经网络.............................................. 192
8.1概述 192
8.2算法笔记精华 192
8.2.1感知机模型 192
8.2.2感知机学习算法 194
8.2.3神经网络 197
8.3 Python实战 205
3.1感知机学习算法的原始形式 205
3.2感知机学习算法的对偶形式 209
3.3学习率与收敛速度 212
3.4感知机与线性不可分数据集 213
3.5多层神经网络 215
8.3.6多层神经网络与线性不可分数据集 216
8.3.7多层神经网络的应用 219
第 9章半监督学习 ................................................ 225
9.1概述 225
9.2算法笔记精华 226
2.1生成式半监督学习方法 226
2.2图半监督学习 228
9.3 Python实战 234
9.4小结 243
第 10章集成学习 ................................................. 244
10.1概述 244
10.2算法笔记精华 244
10.2.1集成学习的原理及误差 244
10.2.2 Boosting算法 246
10.2.3 AdaBoost算法 246
10.2.4 AdaBoost与加法模型 252
10.2.5提升树 253
10.2.6 Bagging算法 256
10.2.7误差-分歧分解 257
10.2.8多样性增强 259
10.3 Python实战 260
10.3.1 AdaBoost 261
10.3.2 GradientTreeBoosting 272
10.3.3 RandomForest 288
10.4小结 298
第三篇机器学习工程篇 299
第 11章数据预处理............................................... 300
11.1概述 300
11.2算法笔记精华 300
11.2.1去除唯一属性 300
11.2.2处理缺失值的三种方法 301
11.2.3常见的缺失值补全方法 302
11.2.4特征编码 307
2.5数据标准化、正则化 308
2.6特征选择 310
2.7稀疏表示和字典学习 313
11.3 Python实践 316
11.3.1二元化 316
11.3.2独热码 317
11.3.3标准化 321
11.3.4正则化 325
11.3.5过滤式特征选取 326
11.3.6包裹式特征选取 330
11.3.7嵌入式特征选取 334
11.3.8学习器流水线（Pipeline） 339
11.3.9字典学习 340
第 12章模型评估、选择与验证 .................................... 345
12.1概述 345
12.2算法笔记精华 346
2.1损失函数和风险函数 346
2.2模型评估方法 348
2.3模型评估 349
2.4性能度量 350
2.5偏差方差分解 356
12.3 Python实践 357
3.1损失函数 357
3.2数据集切分 359
3.3性能度量 370
3.4参数优化 387
第四篇 Kaggle实战篇 401
第 13章 Kaggle牛刀小试 .......................................... 402
13.1 Kaggle简介 402
13.2清洗数据 403
2.1加载数据 403
2.2合并数据 406
2.3拆分数据 407
2.4去除唯一值 408
2.5数据类型转换 410
13.2.6 Data_Cleaner类 412
13.3数据预处理 415
13.3.1独热码编码 415
13.3.2归一化处理 419
13.3.3 Data_Preprocesser类 421
13.4学习曲线和验证曲线 424
13.4.1程序说明 424
13.4.2运行结果 430
13.5参数优化 433
13.6小结 435
全书符号 ........................................................... 436
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python大战机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习导论（原书第2版）
Introduction to Machine Learning,Second Edition
出版者的话
中文版序
译者序
前言
致谢
关于第2版
符号表
第1章　绪论1
1.1　什么是机器学习1
1.2　机器学习的应用实例3
1.2.1　学习关联性3
1.2.2　分类3
1.2.3　回归6
1.2.4　非监督学习7
1.2.5　增强学习8
1.3　注释8
1.4　相关资源10
1.5　习题11
1.6　参考文献12
第2章　监督学习13
2.1　由实例学习类13
2.2　VC维15
2.3　概率逼近正确学习16
2.4　噪声17
2.5　学习多类18
2.6　回归19
2.7　模型选择与泛化21
2.8　监督机器学习算法的维23
2.9　注释24
2.10　习题25
2.11　参考文献25
第3章　贝叶斯决策定理27
3.1　引言27
3.2　分类28
3.3　损失与风险29
3.4　判别式函数31
3.5　效用理论31
3.6　关联规则32
3.7　注释33
3.8　习题33
3.9　参考文献34
第4章　参数方法35
4.1　引言35
4.2　最大似然估计35
4.2.1　伯努利密度36
4.2.2　多项密度36
4.2.3　高斯(正态)密度37
4.3　评价估计：偏倚和方差37
4.4　贝叶斯估计38
4.5　参数分类40
4.6　回归43
4.7　调整模型的复杂度：偏倚/方差两难选择45
4.8　模型选择过程47
4.9　注释50
4.10　习题50
4.11　参考文献51
第5章　多元方法52
5.1　多元数据52
5.2　参数估计52
5.3　缺失值估计53
5.4　多元正态分布54
5.5　多元分类56
5.6　调整复杂度59
5.7　离散特征61
5.8　多元回归62
5.9　注释63
5.10　习题63
5.11　参考文献64
第6章　维度归约65
6.1　引言65
6.2　子集选择65
6.3　主成分分析67
6.4　因子分析71
6.5　多维定标75
6.6　线性判别分析77
6.7　等距特征映射80
6.8　局部线性嵌入81
6.9　注释83
6.10　习题84
6.11　参考文献85
第7章　聚类86
7.1　引言86
7.2　混合密度86
7.3　k-均值聚类87
7.4　期望最大化算法90
7.5　潜在变量混合模型93
7.6　聚类后的监督学习94
7.7　层次聚类95
7.8　选择簇个数96
7.9　注释96
7.10　习题97
7.11　参考文献97
第8章　非参数方法99
8.1　引言99
8.2　非参数密度估计99
8.2.1　直方图估计100
8.2.2　核估计101
8.2.3　k最近邻估计102
8.3　到多元数据的推广103
8.4　非参数分类104
8.5　精简的最近邻105
8.6　非参数回归：光滑模型106
8.6.1　移动均值光滑106
8.6.2　核光滑108
8.6.3　移动线光滑108
8.7　如何选择光滑参数109
8.8　注释110
8.9　习题111
8.10　参考文献112
第9章　决策树113
9.1　引言113
9.2　单变量树114
9.2.1　分类树114
9.2.2　回归树118
9.3　剪枝119
9.4　由决策树提取规则120
9.5　由数据学习规则121
9.6　多变量树124
9.7　注释125
9.8　习题126
9.9　参考文献127
第10章　线性判别式129
10.1　引言129
10.2　推广线性模型130
10.3　线性判别式的几何意义131
10.3.1　两类问题131
10.3.2　多类问题132
10.4　逐对分离132
10.5　参数判别式的进一步讨论133
10.6　梯度下降135
10.7　逻辑斯谛判别式135
10.7.1　两类问题135
10.7.2　多类问题138
10.8　回归判别式141
10.9　注释142
10.10　习题143
10.11　参考文献143
第11章　多层感知器144
11.1　引言144
11.1.1　理解人脑144
11.1.2　神经网络作为并行处理的典范145
11.2　感知器146
11.3　训练感知器148
11.4　学习布尔函数150
11.5　多层感知器151
11.6　作为普适近似的MLP153
11.7　后向传播算法154
11.7.1　非线性回归154
11.7.2　两类判别式157
11.7.3　多类判别式158
11.7.4　多个隐藏层158
11.8　训练过程158
11.8.1　改善收敛性158
11.8.2　过分训练159
11.8.3　构造网络161
11.8.4　线索162
11.9　调整网络规模163
11.10　学习的贝叶斯观点164
11.11　维度归约165
11.12　学习时间167
11.12.1　时间延迟神经网络167
11.12.2　递归网络168
11.13　注释169
11.14　习题170
11.15　参考文献170
第12章　局部模型173
12.1　引言173
12.2　竞争学习173
12.2.1　在线k-均值173
12.2.2　自适应共鸣理论176
12.2.3　自组织映射177
12.3　径向基函数178
12.4　结合基于规则的知识182
12.5　规范化基函数182
12.6　竞争的基函数184
12.7　学习向量量化186
12.8　混合专家模型186
12.8.1　协同专家模型188
12.8.2　竞争专家模型188
12.9　层次混合专家模型189
12.10　注释189
12.11　习题190
12.12　参考文献190
第13章　核机器192
13.1　引言192
13.2　最佳分离超平面193
13.3　不可分情况：软边缘超平面195
13.4　v-SVM197
13.5　核技巧198
13.6　向量核199
13.7　定义核200
13.8　多核学习201
13.9　多类核机器202
13.10　用于回归的核机器203
13.11　一类核机器206
13.12　核维度归约208
13.13　注释209
13.14　习题209
13.15　参考文献210
第14章　贝叶斯估计212
14.1　引言212
14.2　分布参数的估计213
14.2.1　离散变量213
14.2.2　连续变量215
14.3　函数参数的贝叶斯估计216
14.3.1　回归216
14.3.2　基函数或核函数的使用218
14.3.3　贝叶斯分类219
14.4　高斯过程221
14.5　注释223
14.6　习题224
14.7　参考文献224
第15章　隐马尔可夫模型225
15.1　引言225
15.2　离散马尔可夫过程225
15.3　隐马尔可夫模型227
15.4　HMM的三个基本问题229
15.5　估值问题229
15.6　寻找状态序列231
15.7　学习模型参数233
15.8　连续观测235
15.9　带输入的HMM236
15.10　HMM中的模型选择236
15.11　注释237
15.12　习题238
15.13　参考文献239
第16章　图方法240
16.1　引言240
16.2　条件独立的典型情况241
16.3　图模型实例245
16.3.1　朴素贝叶斯分类245
16.3.2　隐马尔可夫模型246
16.3.3　线性回归248
16.4　d-分离248
16.5　信念传播249
16.5.1　链249
16.5.2　树250
16.5.3　多树251
16.5.4　结树252
16.6　无向图：马尔可夫随机场253
16.7　学习图模型的结构254
16.8　影响图255
16.9　注释255
16.10　习题256
16.11　参考文献256
第17章　组合多学习器258
17.1　基本原理258
17.2　产生有差异的学习器258
17.3　模型组合方案260
17.4　投票法261
17.5　纠错输出码263
17.6　装袋265
17.7　提升265
17.8　重温混合专家模型267
17.9　层叠泛化268
17.10　调整系综268
17.11　级联269
17.12　注释270
17.13　习题271
17.14　参考文献272
第18章　增强学习275
18.1　引言275
18.2　单状态情况：K臂赌博机问题276
18.3　增强学习基础277
18.4　基于模型的学习278
18.4.1　价值迭代279
18.4.2　策略迭代279
18.5　时间差分学习280
18.5.1　探索策略280
18.5.2　确定性奖励和动作280
18.5.3　非确定性奖励和动作282
18.5.4　资格迹283
18.6　推广285
18.7　部分可观测状态286
18.7.1　场景286
18.7.2　例子：老虎问题287
18.8　注释290
18.9　习题291
18.10　参考文献292
第19章　机器学习实验的设计与分析294
19.1　引言294
19.2　因素、响应和实验策略296
19.3　响应面设计297
19.4　随机化、重复和阻止298
19.5　机器学习实验指南298
19.6　交叉验证和再抽样方法300
19.6.1　K-折交叉验证300
19.6.2　5×2交叉验证301
19.6.3　自助法302
19.7　度量分类器的性能302
19.8　区间估计304
19.9　假设检验307
19.10　评估分类算法的性能308
19.10.1　二项检验308
19.10.2　近似正态检验309
19.10.3　t检验309
19.11　比较两个分类算法309
19.11.1　McNemar检验310
19.11.2　K-折交叉验证配对t检验310
19.11.3　5×2交叉验证配对t检验311
19.11.4　5×2交叉验证配对F检验311
19.12　比较多个算法：方差分析312
19.13　在多个数据集上比较315
19.13.1　比较两个算法315
19.13.2　比较多个算法317
19.14　注释317
19.15　习题318
19.16　参考文献319
附录A　概率论320
索引328
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习导论（原书第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与数据挖掘:方法和应用
第1部分&nbsp;&nbsp;基&nbsp;本&nbsp;概&nbsp;念
&nbsp;第1章&nbsp;&nbsp;机器学习方法概述
&nbsp;&nbsp;1.1&nbsp;&nbsp;导论
&nbsp;&nbsp;1.2&nbsp;&nbsp;机器学习任务
&nbsp;&nbsp;&nbsp;1.2.1&nbsp;&nbsp;认知观点
&nbsp;&

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与数据挖掘:方法和应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习在量化投资中的应用研究
第1章  绪论	1
1.1  背景与意义	1
1.2  国内外研究现状	3
1.2.1  金融时间序列方法	3
1.2.2  机器学习方法	6
1.2.3  小波与流形方法	10
1.3  本书主要内容与逻辑结构	15
1.3.1  内容安排	15
1.3.2  逻辑结构	17
第2章  统计学习与机器学习	19
2.1  计算学习理论	19
2.1.1  学习问题表述	19
2.1.2  统计学习理论	21
2.1.3  可能近似正确学习模型	22
2.2  神经网络模型	23
2.2.1  多层感知器神经网络模型	23
2.2.2  广义回归神经网络模型	26
2.3  支持向量机理论	28
2.3.1  线性支持向量分类机	29
2.3.2  非线性支持向量分类机	31
2.3.3  支持向量回归机	33
2.4  本章小结	34
第3章  基于模糊神经网络的股票预测模型分析	35
3.1  引言	35
3.2  模糊神经网络模型研究	36
3.2.1  模糊逻辑推理系统结构	36
3.2.2  模糊神经网络分类器	37
3.2.3  模糊神经网络回归机	38
3.3  基于模糊神经网络的股票预测	40
3.3.1  模糊神经网络设计	40
3.3.2  实验结果与分析	42
3.4  本章小结	43
第4章  基于高斯核支持向量机的股票预测模型分析	44
4.1  引言	44
4.2  核函数研究	45
4.2.1  核的构造条件	45
4.2.2  核的构造原则	46
4.2.3  核的主要类型	49
4.3  基于高斯核支持向量机的股票预测	52
4.3.1  数据处理与性能指标	52
4.3.2  实验结果与分析	53
4.4  本章小结	57
第5章  基于小波支持向量机的股票收益模型分析	58
5.1  引言	58
5.2  股票收益的理论研究	59
5.2.1  有效市场假说与布朗运动模型	59
5.2.2  分形市场假说与分数布朗运动模型	61
5.2.3  Hurst指数与重标极差分析	62
5.2.4  混沌动力学模型与Lyapunov指数	64
5.3  基于小波支持向量机的收益模型	65
5.3.1  小波变换与多分辨分析	66
5.3.2  小波核构造与证明	68
5.3.3  实验结果与分析	70
5.4  本章小结	77
第6章  基于小波支持向量机的波动模型分析	79
6.1  引言	79
6.2  波动率模型研究	79
6.2.1  ARCH模型	80
6.2.2  GARCH模型	81
6.2.3  随机波动SV模型	82
6.3  基于小波支持向量机的GARCH模型	84
6.3.1  仿真实验	84
6.3.2  真实数据集实验	86
6.4  本章小结	95
第7章  基于流形小波核的收益序列分析	96
7.1  引言	96
7.2  微分几何基本理论	96
7.3  核函数的几何解释	100
7.4  构造融合先验知识的流形小波核	101
7.5  实验结果与分析	102
7.6  本章小结	107
第8章  基于样条小波核的波动序列分析	108
8.1  引言	108
8.2  样条小波模型研究	108
8.3  样条空间与函数	110
8.3.1  样条函数空间	110
8.3.2  B样条函数定义与性质	112
8.4  样条小波核构造与证明	113
8.5  实验结果与分析	115
8.6  本章小结	119
第9章  结论与展望	120
9.1  本书主要贡献	120
9.2  后续研究展望	122
附录A  微积分	124
A.1  基本定义	124
A.2  梯度和Hesse矩阵	126
A.3  方向导数	126
A.4  Taylor展开式	128
A.5  分离定理	129
附录B  Hilbert空间	131
B.1  向量空间	131
B.2  内积空间	134
B.3  Hilbert空间	136
B.4  算子、特征值和特征向量	138
附录C  专题研究期间学术论文与科研项目	140
后记	143
参考文献	144
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习在量化投资中的应用研究
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习算法原理与编程实践
第1章  机器学习的基础    1
1.1  编程语言与开发环境    2
1.1.1  搭建Python开发环境    2
1.1.2  安装Python算法库    4
1.1.3  IDE配置及其安装测试    5
1.2  对象、矩阵与矢量化编程    8
1.2.1  对象与维度    8
1.2.2  初识矩阵    10
1.2.3  矢量化编程与GPU运算    13
1.2.4  理解数学公式与NumPy矩阵运算    14
1.2.5  Linalg线性代数库    18
1.3  机器学习的数学基础    20
1.3.1  相似性的度量    21
1.3.2  各类距离的意义与Python实现    22
1.3.3  理解随机性    29
1.3.4  回顾概率论    30
1.3.5  多元统计基础    32
1.3.6  特征间的相关性    33
1.3.7  再谈矩阵——空间的变换    35
1.3.8  数据归一化    40
1.4  数据处理与可视化    42
1.4.1  数据的导入和内存管理    42
1.4.2  表与线性结构的可视化    45
1.4.3  树与分类结构的可视化    46
1.4.4  图与网络结构的可视化    47
1.5  Linux操作系统下部署Python机器学习开发环境    48
1.5.1  Linux发行版的选择    48
1.5.2  CentOS部署多版本Python实例    49
1.5.3  安装NumPy、SciPy、Matplotlib开发包    52
1.5.4  安装Scikit-Learn开发包    54
1.6  结语    55
第2章  中文文本分类    56
2.1  文本挖掘与文本分类的概念    56
2.2  文本分类项目    58
2.2.1  文本预处理    58
2.2.2  中文分词介绍    61
2.2.3  Scikit-Learn库简介    66
2.2.4  向量空间模型    70
2.2.5  权重策略：TF-IDF方法    71
2.2.6  使用朴素贝叶斯分类模块    74
2.2.7  分类结果评估    76
2.3  分类算法：朴素贝叶斯    78
2.3.1  贝叶斯公式推导    78
2.3.2  朴素贝叶斯算法实现    79
2.3.3  算法的改进    82
2.3.4  评估分类结果    82
2.4  分类算法：kNN    83
2.4.1  kNN算法原理    83
2.4.2  kNN算法的Python实现    86
2.4.3  评估分类结果    88
2.5  结语    88
第3章  决策树的发展    89
3.1  决策树的基本思想    89
3.1.1  从一个实例开始    90
3.1.2  决策树的算法框架    95
3.1.3  信息熵测度    96
3.2  ID3决策树    98
3.2.1  ID3算法    98
3.2.2  ID3的实现    101
3.2.3  决策树主方法    101
3.2.4  训练决策树    103
3.2.5  持久化决策树    104
3.2.6  决策树分类    105
3.2.7  算法评估    106
3.3  C4.5算法    106
3.3.1  信息增益率    106
3.3.2  C4.5的实现    108
3.3.3  训练决策树    108
3.3.4  分类数据    109
3.4  Scikit-Learn与回归树    110
3.4.1  回归算法原理    110
3.4.2  最小剩余方差法    111
3.4.3  模型树    113
3.4.4  剪枝策略    113
3.4.5  Scikit-Learn实现    115
3.5  结语    117
第4章  推荐系统原理    118
4.1  推荐系统概述    119
4.1.1  从亚马逊网站认识推荐系统    119
4.1.2  推荐系统的架构    122
4.1.3  开源推荐系统    125
4.2  协同过滤及其算法    126
4.2.1  协同过滤    126
4.2.2  数据预处理    127
4.2.3  使用Scikit-Learn的KMeans聚类    127
4.2.4  User CF原理    129
4.2.5  Item CF原理    131
4.2.6  SVD原理与计算    132
4.3  KMeans算法详解    135
4.3.1  KMeans算法流程    135
4.3.2  辅助函数    136
4.3.3  聚类主函数    137
4.3.4  评估分类结果    139
4.4  聚类的改进：二分KMeans算法    141
4.4.1  二分聚类主函数    141
4.4.2  评估分类结果    142
4.5  SVD算法详解    143
4.5.1  SVD算法回顾    143
4.5.2  常用距离函数    146
4.5.3  SVD数据集    146
4.5.4  SVD算法主函数    147
4.5.5  评估结果    147
4.6  结语    148
第5章  梯度寻优    149
5.1  最优化与计算复杂性    149
5.1.1  最优化理论    149
5.1.2  最优化的数学描述    150
5.1.3  凸集与分离定理    151
5.1.4  凸函数及其性质    153
5.1.5  局部最优与全局最优    155
5.1.6  计算复杂性与NP问题    156
5.1.7  逐次逼近法    159
5.2  Logistic梯度下降法    163
5.2.1  梯度下降法    164
5.2.2  线性分类器    166
5.2.3  Logistic函数——世界不是非黑即白    169
5.2.4  算法流程    171
5.2.5  对测试集进行分类    175
5.3  算法分析    175
5.3.1  超平面的变化趋势    176
5.3.2  超平面的收敛评估    177
5.3.3  权重向量的收敛评估    179
5.3.4  算法总体评价    180
5.4  随机梯度下降法：算法改进与评估    180
5.4.1  主函数    181
5.4.2  程序输出    182
5.4.3  步长变化率    183
5.4.4  权重收敛评估    184
5.4.5  权重分量的变化趋势    185
5.4.6  算法总体评价    187
5.5  结语    187
第6章  神经网络初步    189
6.1  神经网络简史    189
6.1.1  起源与早期发展    189
6.1.2  中期发展    190
6.1.3  当前的发展与反思    192
6.2  BP神经网络理论    192
6.2.1  线性不可分问题    192
6.2.2  BP网络构成    193
6.2.3  BP网络的训练过程    196
6.3  BP网络的实现和评估    199
6.3.1  BP网络类与主要方法    199
6.3.2  设计BP网络    199
6.3.3  辅助函数    202
6.3.4  主函数    203
6.3.5  分类器    204
6.3.6  执行分类并输出结果    205
6.3.7  BP网络评估    207
6.4  自组织特征映射神经网络    208
6.4.1  SOM网络框架    208
6.4.2  SOM类    211
6.4.3  功能函数    212
6.4.4  SOM网络的实现    212
6.4.5  聚类结果    213
6.5  Boltzmann机算法    215
6.5.1  问题的提出    215
6.5.2  模拟退火原理    216
6.5.3  Boltzmann分布与退火过程    217
6.5.4  Boltzmann机类与功能函数    219
6.5.5  最短路径的实现    222
6.5.6  执行算法    223
6.5.7  评估结果    224
6.6  结语    225
第7章  预测的技术与哲学    226
7.1  线性系统的预测    226
7.1.1  回归与现代预测学    226
7.1.2  最小二乘法    227
7.1.3  代码实现    229
7.1.4  正规方程组法    231
7.1.5  正规方程组的代码实现    232
7.1.6  算法评估    232
7.2  径向基网络    233
7.2.1  RBF网络    233
7.2.2  辅助函数    236
7.2.3  使用RBF预测    236
7.2.4  评估预测结果    238
7.3  岭回归    238
7.3.1  验证多重共线性    239
7.3.2  岭回归理论    240
7.3.3  岭际分析    240
7.3.4  k值的判定    242
7.3.5  辅助函数    243
7.3.6  岭回归的实现与k值计算    243
7.3.7  算法评估    244
7.4  预测的哲学    245
7.4.1  从《周易》谈起    246
7.4.2  两仪生四象    249
7.4.3  周期三与混沌    251
7.4.4  Logistic中的吸引子    254
7.4.5  三生万物    258
7.4.6  八卦图及其推演    261
7.5  结语    263
第8章  万能分类器——支持向量机    265
8.1  支持向量机的理论基础    266
8.1.1  经验风险最优    266
8.1.2  关键定理与VC维    267
8.1.3  结构风险最优    270
8.2  SVM的数学推导    272
8.2.1  最大间隔超平面    272
8.2.2  拉格朗日乘子法    275
8.2.3  KKT条件与对偶变换    276
8.2.4  分类器函数    277
8.2.5  映射到高维空间    278
8.2.6  核函数法    280
8.2.7  离群点的松弛变量    281
8.3  SMO算法    284
8.3.1  SMO求解SVM    284
8.3.2  构造SMO类    288
8.3.3  主函数    290
8.3.4  训练数据    291
8.3.5  分类并评估算法    293
8.4  SVM中文文本分类    293
8.4.1  回顾中文文本分类    294
8.4.2  Scikit-Learn SVM分类    294
8.4.3  评估结果    295
8.5  结语    296
第9章  人脸识别中的机器学习    297
9.1  模式识别概述    297
9.1.1  认知与模式    297
9.1.2  机器视觉与OpenCV    300
9.1.3  OpenCV的文件与基本操作    301
9.2  人脸检测    305
9.2.1  人脸识别的历史与架构    305
9.2.2  人脸识别系统    307
9.2.3  人脸检测原理与Haar级联检测    308
9.2.4  人脸检测特征文件    311
9.2.5  Haar cascade的实现    314
9.2.6  LBP cascade的实现    315
9.3  AdaBoost算法概述    316
9.3.1  算法原理与步骤    316
9.3.2  辅助函数    317
9.3.3  AdaBoost分类器    318
9.3.4  单层决策树分类子算法    319
9.3.5  训练数据集    321
9.3.6  执行分类    322
9.4  人脸识别    323
9.4.1  人脸数据库    324
9.4.2  PCA原理    325
9.4.3  特征脸识别类    327
9.4.4  生成特征脸    328
9.4.5  执行人脸识别    330
9.5  结语    330
第10章  认知计算与深度学习    332
10.1  认知计算    332
10.1.1  认知层次论    333
10.1.2  从具体到抽象    336
10.1.3  Theano库与基本操作    338
10.2  多层感知器    343
10.2.1  MNIST数据集    343
10.2.2  Softmax回归类    345
10.2.3  正则化方法    347
10.2.4  执行SoftMax学习    350
10.2.5  多层感知器    353
10.2.6  多层感知器的实现    355
10.2.7  MLP的训练过程    358
10.3  卷积神经网络    358
10.3.1  理论基础    358
10.3.2  卷积类    363
10.3.3  LeNet5函数    364
10.3.4  CNN的训练过程    369
10.4  Theano安装与GPU运算    370
10.4.1  Anaconda安装    370
10.4.2  实现CPU运算    372
10.4.3  安装VS2013    374
10.4.4  安装CUDA    375
10.4.5  实现支持GPU运算    378
10.5  结语    378
第11章  概率图模型与词性标注    380
11.1  马尔科夫过程    381
11.1.1  随机过程与状态图    381
11.1.2  马尔科夫链及其概念    382
11.1.3  马尔科夫链的实现    384
11.2  概率图模型和贝叶斯网    385
11.2.1  概述    385
11.2.2  条件独立性    386
11.2.3  贝叶斯网简介    390
11.2.4  贝叶斯网的构造    392
11.2.5  贝叶斯网的推理简介    394
11.3  隐马尔科夫模型    396
11.3.1  概述    396
11.3.2  HMM推理与前向算法    399
11.3.3  Vertibi算法原理    403
11.3.4  Vertibi算法实现    405
11.3.5  执行并输出结果    406
11.4  词性标注系统    406
11.4.1  语料库与词性资源    407
11.4.2  手工计算    409
11.4.3  结果验证    413
11.5  结语    414
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习算法原理与编程实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践：测试驱动的开发方法
前言　　xi
第1章　测试驱动的机器学习　　1
1.1　TDD的历史　　2
1.2　TDD与科学方法　　2
1.2.1　TDD可构建有效的逻辑命题　　3
1.2.2　TDD要求你将假设以文字或代码的形式记录下来　　5
1.2.3　TDD和科学方法的闭环反馈机制　　5
1.3　机器学习中的风险　　5
1.3.1　数据的不稳定性　　6
1.3.2　欠拟合　　6
1.3.3　过拟合　　7
1.3.4　未来的不可预测性　　8
1.4　为降低风险应采用的测试　　8
1.4.1　利用接缝测试减少数据中的不稳定因素　　8
1.4.2　通过交叉验证检验拟合效果　　9
1.4.3　通过测试训练速度降低过拟合风险　　10
1.4.4　检测未来的精度和查全率漂移情况　　11
1.5　小结　　11
第2章　机器学习概述　　13
2.1　什么是机器学习　　13
2.1.1　有监督学习　　13
2.1.2　无监督学习　　14
2.1.3　强化学习　　15
2.2　机器学习可完成的任务　　15
2.3　本书采用的数学符号　　16
2.4　小结　　16
第3章　K近邻分类　　17
3.1　K近邻分类的历史　　18
3.2　基于邻居的居住幸福度　　18
3.3　如何选择K　　21
3.3.1　猜测K的值　　21
3.3.2　选择K的启发式策略　　21
3.3.3　K的选择算法　　24
3.4　何谓“近”　　24
3.4.1　Minkowski距离　　25
3.4.2　Mahalanobis距离　　26
3.5　各类别的确定　　27
3.6　利用KNN算法和OpenCV实现胡须和眼镜的检测　　29
3.6.1　类图　　29
3.6.2　从原始图像到人脸图像　　30
3.6.3　Face类　　33
3.6.4　Neighborhood类　　36
3.7　小结　　43
第4章　朴素贝叶斯分类　　45
4.1　利用贝叶斯定理找出欺诈性订单　　45
4.1.1　条件概率　　46
4.1.2　逆条件概率　　47
4.2　朴素贝叶斯分类器　　48
4.2.1　链式法则　　48
4.2.2　贝叶斯推理中的朴素性　　49
4.2.3　伪计数　　50
4.3　垃圾邮件过滤器　　51
4.3.1　类图　　51
4.3.2　数据源　　52
4.3.3　Email类　　52
4.3.4　符号化与上下文　　55
4.3.5　SpamTrainer类　　56
4.3.6　通过交叉验证将错误率最小化　　63
4.4　小结　　66
第5章　隐马尔可夫模型　　67
5.1　利用状态机跟踪用户行为　　67
5.1.1　隐含状态的输出和观测　　69
5.1.2　利用马尔可夫假设简化问题　　70
5.1.3　利用马尔可夫链而非有限状态机　　71
5.1.4　隐马尔可夫模型　　71
5.2　评估：前向-后向算法　　72
5.3　利用维特比算法求解解码问题　　75
5.4　学习问题　　76
5.5　利用布朗语料库进行词性标注　　76
5.5.1　词性标注器的首要问题：CorpusParser　　77
5.5.2　编写词性标注器　　79
5.5.3　通过交叉验证获取模型的置信度　　86
5.5.4　模型的改进方案　　88
5.6　小结　　88
第6章　支持向量机　　89
6.1　求解忠诚度映射问题　　89
6.2　SVM的推导过程　　91
6.3　非线性数据　　92
6.3.1　核技巧　　92
6.3.2　软间隔　　96
6.4　利用SVM进行情绪分析　　97
6.4.1　类图　　98
6.4.2　Corpus类　　99
6.4.3　从语料库返回一个无重复元素的单词集　　102
6.4.4　CorpusSet类　　103
6.4.5　SentimentClassifier类　　107
6.4.6　随时间提升结果　　111
6.5　小结　　111
第7章　神经网络　　113
7.1　神经网络的历史　　113
7.2　何为人工神经网络　　114
7.2.1　输入层　　115
7.2.2　隐含层　　116
7.2.3　神经元　　117
7.2.4　输出层　　122
7.2.5　训练算法　　122
7.3　构建神经网络　　125
7.3.1　隐含层数目的选择　　126
7.3.2　每层中神经元数目的选择　　126
7.3.3　误差容限和最大epoch的选择　　126
7.4　利用神经网络对语言分类　　127
7.4.1　为语言编写接缝测试　　129
7.4.2　网络类的交叉验证　　132
7.4.3　神经网络的参数调校　　135
7.4.4　收敛性测试　　136
7.4.5　神经网络的精度和查全率　　136
7.4.6　案例总结　　136
7.5　小结　　136
第8章　聚类　　137
8.1　用户组　　138
8.2　K均值聚类　　139
8.2.1　K均值算法　　139
8.2.2　K均值聚类的缺陷　　140
8.3　EM聚类算法　　141
8.4　不可能性定理　　142
8.5　音乐归类　　142
8.5.1　数据收集　　143
8.5.2　用K均值聚类分析数据　　144
8.5.3　EM聚类　　146
8.5.4　爵士乐的EM聚类结果　　149
8.6　小结　　151
第9章　核岭回归　　153
9.1　协同过滤　　153
9.2　应用于协同过滤的线性回归　　154
9.3　正则化技术与岭回归　　157
9.4　核岭回归　　158
9.5　理论总结　　158
9.6　用协同过滤推荐啤酒风格　　159
9.6.1　数据集　　159
9.6.2　我们所需的工具　　159
9.6.3　评论者　　162
9.6.4　编写代码确定某人的偏好　　164
9.6.5　利用用户偏好实现协同过滤　　166
9.7　小结　　167
第10章　模型改进与数据提取　　169
10.1　维数灾难问题　　169
10.2　特征选择　　171
10.3　特征变换　　173
10.4　主分量分析　　175
10.5　独立分量分析　　177
10.6　监测机器学习算法　　179
10.6.1　精度与查全率：垃圾邮件过滤　　179
10.6.2　混淆矩阵　　181
10.7　均方误差　　182
10.8　产品环境的复杂性　　183
10.9　小结　　183
第11章　结语　　185
11.1　机器学习算法回顾　　185
11.2　如何利用这些信息来求解问题　　186
11.3　未来的学习路线　　187
作者介绍　　188
封面介绍　　188
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践：测试驱动的开发方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>实用机器学习
推荐序
作者序
致谢
译者序
关于本书
作者简介
关于封面插图
第1部分机器学习工作流程
第1章什么是机器学习
1.1理解机器学习
1.2使用数据进行决策
1.2.1传统方法
1.2.2机器学习方法
1.2.3机器学习的五大优势
1.2.4面临的挑战
1.3跟踪机器学习流程：从数据到部署
1.3.1数据集合和预处理
1.3.2数据构建模型
1.3.3模型性能评估
1.3.4模型性能优化
1.4提高模型性能的高级技巧
1.4.1数据预处理和特征工程
1.4.2用在线算法持续改进模型
1.4.3具有数据量和速度的规模化模型
1.5总结
1.6本章术语
第2章实用数据处理
2.1起步：数据收集
2.1.1应包含哪些特征
2.1.2如何获得目标变量的真实值
2.1.3需要多少训练数据
2.1.4训练集是否有足够的代表性
2.2数据预处理
2.2.1分类特征
2.2.2缺失数据处理
2.2.3简单特征工程
2.2.4数据规范化
2.3数据可视化
2.3.1马赛克图
2.3.2盒图
2.3.3密度图
2.3.4散点图
2.4总结
2.5本章术语
第3章建模和预测
3.1基础机器学习建模
3.1.1寻找输入和目标间的关系
3.1.2寻求好模型的目的
3.1.3建模方法类型
3.1.4有监督和无监督学习
3.2分类：把数据预测到桶中
3.2.1构建分类器并预测
3.2.2非线性数据与复杂分类
3.2.3多类别分类
3.3回归：预测数值型数据
3.3.1构建回归器并预测
3.3.2对复杂的非线性数据进行回归
3.4总结
3.5本章术语
第4章模型评估与优化
4.1模型泛化：评估新数据的预测准确性
4.1.1问题：过度拟合与乐观模型
4.1.2解决方案：交叉验证
4.1.3交叉验证的注意事项
4.2分类模型评估
4.2.1分类精度和混淆矩阵
4.2.2准确度权衡与ROC曲线
4.2.3多类别分类
4.3回归模型评估
4.3.1使用简单回归性能指标
4.3.2检验残差
4.4参数调整优化模型
4.4.1机器学习算法和它们的调整参数
4.4.2网格搜索
4.5总结
4.6本章术语
第5章基础特征工程
5.1动机：为什么特征工程很有用
5.1.1什么是特征工程
5.1.2使用特征工程的5个原因
5.1.3特征工程与领域专业知识
5.2基本特征工程过程
5.2.1实例：事件推荐
5.2.2处理日期和时间特征
5.2.3处理简单文本特征
5.3特征选择
5.3.1前向选择和反向消除
5.3.2数据探索的特征选择
5.3.3实用特征选择实例
5.4总结
5.5本章术语
第2部分实 际 应 用
第6章案例：NYC出租车数据
6.1数据：NYC出租车旅程和收费信息
6.1.1数据可视化
6.1.2定义问题并准备数据
6.2建模
6.2.1基本线性模型
6.2.2非线性分类器
6.2.3包含分类特征
6.2.4包含日期-时间特征
6.2.5模型的启示
6.3总结
6.4本章术语
第7章高级特征工程
7.1高级文本特征
7.1.1词袋模型
7.1.2主题建模
7.1.3内容拓展
7.2图像特征
7.2.1简单图像特征
7.2.2提取物体和形状
7.3时间序列特征
7.3.1时间序列数据的类型
7.3.2时间序列数据的预测
7.3.3经典时间序列特征
7.3.4事件流的特征工程
7.4总结
7.5本章术语
第8章NLP高级案例：电影评论情感预测
8.1研究数据和应用场景
8.1.1数据集初探
8.1.2检查数据
8.1.3应用场景有哪些
8.2提取基本NLP特征并构建初始模型
8.2.1词袋特征
8.2.2用朴素贝叶斯算法构建模型
8.2.3tf-idf算法规范词袋特征
8.2.4优化模型参数
8.3高级算法和模型部署的考虑
8.3.1word2vec特征
8.3.2随机森林模型
8.4总结
8.5本章术语
第9章扩展机器学习流程
9.1扩展前需考虑的问题
9.1.1识别关键点
9.1.2选取训练数据子样本代替扩展性
9.1.3可扩展的数据管理系统
9.2机器学习建模流程扩展
9.3预测扩展
9.3.1预测容量扩展
9.3.2预测速度扩展
9.4总结
9.5本章术语
第10章案例：数字显示广告
10.1显示广告
10.2数字广告数据
10.3特征工程和建模策略
10.4数据大小和形状
10.5奇异值分解
10.6资源估计和优化
10.7建模
10.8K近邻算法
10.9随机森林算法
10.10其他实用考虑
10.11总结
10.12本章术语
10.13摘要和结论
附录常用机器学习算法
名词术语中英文对照
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>实用机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据时代的算法：机器学习、人工智能及其典型实例
第1章　算法基础	1
1.1　基础算法分析类型	1
1.1.1　分治法	1
1.1.2　动态规划法	2
1.1.3　回溯法	3
1.1.4　分支限界法	4
1.1.5　贪心法	4
1.2　算法性能分析	5
1.3　概率论与数理统计基础	6
1.4　距离计算	8
1.4.1  欧氏距离	8
1.4.2  马氏距离	9
1.4.3  曼哈顿距离	9
1.4.4  切比雪夫距离	9
1.4.5  闵氏距离	9
1.4.6  海明距离	10
1.5　排序算法	10
1.5.1　快速排序	11
1.5.2　归并排序	11
1.5.3　堆排序	13
1.5.4　基数排序	15
1.5.5　外排序	16
1.6　字符压缩编码	17
1.6.1　哈夫曼编码	17
1.6.2　香农-范诺编码	21
1.7　本章小结	24
第2章　数据查找与资源分配算法	25
2.1　数值查找算法	25
2.1.1　二分搜索算法	25
2.1.2　分块查找算法	27
2.1.3　哈希查找算法	28
2.2　字符串查找算法	30
2.2.1　Knuth-Morris-Pratt算法	31
2.2.2　Boyer-Moore算法	34
2.2.3　Sunday算法	37
2.3　海量数据中的查找	39
2.3.1　基于布隆过滤器查找	39
2.3.2　倒排索引查找	41
2.4　银行家算法	43
2.5　背包问题	44
2.5.1　0-1背包问题	45
2.5.2　部分背包问题	46
2.6　本章小结	47
第3章　路径分析算法	49
3.1　基于Dijkstra算法的路径分析	49
3.1.1　应用示例：极地探险	49
3.1.2　基于Dijkstra的最短路径规划	50
3.2　基于Floyd算法的路径分析	53
3.2.1　应用示例：任意两个城市之间的最短路径	53
3.2.2　Floyd原理	54
3.2.3　基于Floyd算法计算两个城市最短距离	56
3.3　基于A*算法的路径搜索	58
3.3.1　应用实例：绕过障碍区到达目的地	58
3.3.2　A*算法与最短距离计算	59
3.4　基于维特比算法的概率路径	61
3.4.1　应用实例：推断天气状态	61
3.4.2　维特比算法思想	62
3.4.3　计算天气状态	62
3.5　最长公共子序列问题	64
3.5.1　概要	64
3.5.2　最长公共子串	64
3.5.3　最长公共子序列原理	66
3.5.4　实例：求两字符串的最长公共子序列	66
3.6　本章小结	68
第4章　相似度分析算法	69
4.1　应用实例：海量网页相似度分析	69
4.2　基于Jaccard相似系数的相似度计算	70
4.2.1　计算流程	70
4.2.2　狭义Jaccard相似系数	71
4.2.3　广义Jaccard相似系数	71
4.3　基于MinHash的相似性算法	71
4.3.1　与Jaccard相似性关系	71
4.3.2　计算网页文本相似性过程	72
4.4　向量空间模型	73
4.4.1　词袋模型	73
4.4.2　TF-IDF算法	74
4.5　基于余弦相似性算法的相似度分析	76
4.5.1　原理基础	76
4.5.2　公式解析	77
4.5.3　计算网页文本相似性过程	77
4.6　基于语义主题模型的相似度算法	78
4.7　基于SimHash算法的指纹码	80
4.7.1　SimHash引入	81
4.7.2　SimHash的计算流程	81
4.7.3　计算重复信息	83
4.8　相似度算法的差异性	84
4.9　本章小结	85
第5章　数据分类算法	86
5.1　基于朴素贝叶斯分类器	86
5.1.1　有监督分类与无监督分类	87
5.1.2　应用实例：识别车厘子与樱桃	88
5.1.3　分类流程归纳	91
5.1.4　应用扩展：垃圾邮件识别	92
5.1.5　常用评价指标	96
5.2　基于AdaBoost分类器	100
5.2.1　AdaBoost概述	100
5.2.2　AdaBoost算法具体流程	101
5.2.3　AdaBoost算法的应用实例	102
5.2.4　AdaBoost算法的优点	105
5.3　基于支持向量机的分类器	105
5.3.1　线性可分与线性不可分	106
5.3.2　感知器	107
5.3.3　支持向量机	108
5.4　基于K邻近算法的分类器	109
5.4.1　应用实例：电影观众兴趣发现	109
5.4.2　核心思想	109
5.4.3　电影观众兴趣发现	110
5.5　本章小结	113
第6章　数据聚类算法	115
6.1　基于系统聚类法	115
6.1.1　概述	116
6.1.2　最短距离法	117
6.1.3　重心聚类法	119
6.1.4　动态聚类法	120
6.2　基于K-Means聚类算法	122
6.2.1　应用实例：新闻聚类	122
6.2.2　逻辑流程	123
6.2.3　实现新闻聚类分析	124
6.2.4　K-Means++	128
6.2.5　K-中心点聚类算法	129
6.2.6　ISODATA聚类算法	130
6.3　基于密度的DBSCAN算法	131
6.4　基于BIRCH算法的聚类分析	133
6.4.1　聚类特征	133
6.4.2　聚类特征树	134
6.5　聚类与分类差异	135
6.6　本章小结	136
第7章　数据预测与估算算法	137
7.1　产生式模型与判别式模型	137
7.2　基于最大似然估计的预测	138
7.3　基于线性回归的估算	140
7.3.1　概要	140
7.3.2　最小二乘法	141
7.4　基于最大期望算法分析	143
7.5　基于隐马尔科夫模型预测	144
7.5.1　应用实例：高温天气与行为概率	144
7.5.2　原理分析	145
7.5.3　高温天气与行为概率	147
7.6　基于条件随机场的序列预测	151
7.6.1　应用实例	151
7.6.2　原理分析	151
7.6.3　条件随机场的优缺点	153
7.7　本章小结	154
第8章　数据决策分析算法	155
8.1　基于ID3算法的决策分析	156
8.1.1　信息量	156
8.1.2　信息熵	156
8.1.3　信息增益	157
8.1.4　ID3算法流程	157
8.1.5　ID3算法的应用	157
8.2　基于C4.5算法的分类决策树	159
8.2.1　概要	159
8.2.2　应用实例	159
8.3　基于分类回归树的决策划分	161
8.3.1　概要	162
8.3.2　应用实例：决策划分	163
8.3.3　剪枝	164
8.4　基于随机森林的决策分类	168
8.4.1　随机森林的特点	169
8.4.2　随机森林的构造方法	169
8.4.3　应用实例：决定车厘子的售价层次	170
8.5　本章小结	172
第9章　数据关联规则分析算法	174
9.1　基于Apriori算法的关联项分析	174
9.1.1　应用实例：超市的货架摆放问题	175
9.1.2　基本概要	175
9.1.3　算法原理	176
9.1.4　有效摆放货架	176
9.2　基于FP-Growth算法的关联性分析	179
9.2.1　构建FP树	179
9.2.2　频繁项分析	181
9.2.3　与Apripri算法比较	184
9.3　基于Eclat算法的频繁项集挖掘	184
9.4　本章小结	185
第10章　数据推荐算法	187
10.1　概要	187
10.1.1　推荐算法发展	188
10.1.2　协同过滤推荐	189
10.2　基于Item-Based协同过滤推荐	190
10.2.1　Item-Based基本思想	190
10.2.2　Slope One实例：基于评分推荐	190
10.3　基于User-Based协同过滤推荐	193
10.3.1　应用实例：根据人群的推荐	194
10.3.2　User-Based与Item-Based对比	197
10.4　基于潜在因子算法的推荐	198
10.4.1　应用实例：新闻推荐	198
10.4.2　流行度与推荐	200
10.5　推荐算法与效果评价	201
10.6　本章小结	203
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据时代的算法：机器学习、人工智能及其典型实例
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>视觉机器学习20讲
绪论 1 第1讲 K-means 11 1.1 基本原理 11 1.2 算法改进 13 1.3 仿真实验 16 1.4 算法特点 18 第 2 讲 KNN学习 20 2.1 基本原理 20 2.2 算法改进 23 2.3 仿真实验 24 2.4 算法特点 26 第 3 讲 回归学习 28 3.1 基本原理 28 3.1.1 参数回归 29 3.1.2 非参数回归 30 3.1.3 半参数回归 30 3.2 算法改进 30 3.2.1 线性回归模型 30 3.2.2 多项式回归模型 31 3.2.3 主成分回归模型 32 3.2.4 自回归模型 33 3.2.5 核回归模型 33 3.3 仿真实验 37 3.3.1 回归学习流程 37 3.3.2 基于回归学习的直线边缘提取 37 3.3.3 基于回归学习的图像插值 39 3.4 算法特点 41 第 4 讲 决策树学习 42 4.1 基本原理 42 4.1.1 分类与聚类 42 4.1.2 决策树 43 4.1.3 信息增益的度量标准 43 4.1.4 信息增益度量期望的熵降低 44 4.1.5 悲观错误剪枝PEP 46 4.1.6 基本决策树算法 47 4.2 算法改进 47 4.2.1 ID3算法 47 4.2.2 C4.5算法 48 4.2.3 SLIQ算法 49 4.2.4 SPRINT算法 49 4.3 仿真实验 50 4.3.1 用于学习布尔函数的ID3算法伪代码 50 4.3.2 C4.5算法构造决策树的伪代码 51 4.4 算法特点 53 第 5 讲 Random Forest学习 54 5.1 基本原理 54 5.1.1 决策树 55 5.1.2 Bagging集成学习 55 5.1.3 Random Forest方法 56 5.2 算法改进 57 5.3 仿真实验 58 5.3.1 Random Forest分类与回归流程 58 5.3.2 Forest-RI和Forest-RC 59 5.3.3 基于Random Forest的头部姿态估计 59 5.4 算法特点 60 第 6 讲 贝叶斯学习 62 6.1 基本原理 62 6.2 算法改进 63 6.2.1 朴素贝叶斯模型 63 6.2.2 层级贝叶斯模型 65 6.2.3 增广贝叶斯学习模型 66 6.2.4 基于Boosting技术的朴素贝叶斯模型 66 6.2.5 贝叶斯神经网络模型 66 6.3 仿真实验 66 6.3.1 Learn_Bayse(X,V) 67 6.3.2 Classify_Bayse(X) 67 6.4 算法特点 68 第 7 讲 EM算法 70 7.1 基本原理 70 7.2 算法改进 71 7.2.1 EM算法的快速计算 71 7.2.2 未知分布函数的选取 74 7.2.3 EM算法收敛性的改进 75 7.3 仿真实验 77 7.3.1 EM算法流程 77 7.3.2 EM算法的伪代码 77 7.3.3 EM算法应用——高斯混合模型 77 7.4 算法特点 79 第 8 讲 Adaboost 81 8.1 基本原理 81 8.1.1 Boosting方法 81 8.1.2 Adaboost方法 82 8.2 算法改进 83 8.2.1 权值更新方法的改进 83 8.2.2 Adaboost并行算法 83 8.3 仿真实验 83 8.3.1 Adaboost算法实现流程 83 8.3.2 Adaboost算法示例 84 8.4 算法特点 86 8.4.1 Adaboost算法的优点 86 8.4.2 Adaboost算法的缺点 87 第 9 讲 SVM方法 88 9.1 基本原理 88 9.2 算法改进 90 9.3 仿真实验 94 9.4 算法特点 100 第 10 讲 增强学习 102 10.1 基本原理 102 10.2 算法改进 105 10.2.1 部分感知模型 105 10.2.2 增强学习中的函数估计 105 10.2.3 分层增强学习 106 10.2.4 多Agent增强学习 107 10.3 仿真实验 107 10.4 算法特点 109 第 11 讲 流形学习 111 11.1 算法原理 111 11.1.1 ISOMAP 112 11.1.2 LLE 113 11.1.3 LE 113 11.1.4 HE 115 11.2 算法改进 115 11.2.1 LPP 116 11.2.2 MFA 117 11.3 算法仿真 119 11.4 算法特点 123 第 12 讲 RBF学习 126 12.1 基本原理 126 12.1.1 基于RBF函数的内插方法 126 12.1.2 RBF神经网络 129 12.1.3 数据中心的计算方法 130 12.2 算法改进 132 12.2.1 针对完全内插问题的改进方法 132 12.2.2 针对不适定问题的改进方法 133 12.2.3 广义RBF神经网络 134 12.3 仿真实验 134 12.3.1 基于高斯函数的RBF学习 134 12.3.2 RBF学习算法流程 135 12.4 算法特点 136 第 13 讲 稀疏表示 138 13.1 基本原理 138 13.1.1 信号稀疏表示 138 13.1.2 贪婪求解算法 140 13.1.3 凸优化求解算法 141 13.2 算法改进 142 13.2.1 组合Lasso（Group Lasso） 142 13.2.2 混合Lasso（Fused Lasso） 143 13.2.3 弹性网络（Elastic net） 143 13.3 仿真实验 143 13.3.1 OMP算法 143 13.3.2 APG算法 144 13.3.3 基于稀疏表示的人脸识别 145 13.4 算法特点 147 13.4.1 算法优点 147 13.4.2 算法缺点 147 第 14 讲 字典学习 149 14.1 基本原理 149 14.2 算法改进 151 14.2.1 最优方向法（MOD） 151 14.2.2 K-SVD法 151 14.2.3 在线字典学习法 151 14.3 仿真实验 152 14.3 基于字典学习的视频图像降噪方法 153 14.4 算法特点 154 14.4.1 算法优点 154 14.4.2 算法缺点 155 第 15 讲 BP学习 156 15.1 基本原理 156 15.1.1 人工神经网络 156 15.1.2 BP学习原理 157 15.2 算法改进 162 15.2.1 改进学习速率 163 15.2.2 改进训练样本 164 15.2.3 改进损失函数 164 15.2.4 改进连接方式 165 15.3 仿真实验 165 15.4 算法特点 167 第 16 讲 CNN学习 170 16.1 基本原理 170 16.1.1 神经认知机模型 170 16.1.2 CNN算法思想 171 16.1.3 CNN网络结构 171 16.1.4 CNN网络学习 174 16.2 算法改进 178 16.2.1 设计新的卷积神经网络训练策略 178 16.2.2 使用GPU加速卷积运算过程 178 16.2.3 使用并行计算提高网络训练和测试速度 179 16.2.4 采用分布式计算提高网络训练和测试速度 179 16.2.5 硬件化卷积神经网络 179 16.3 仿真实验 179 16.3.1 卷积神经网络训练算法仿真 179 16.3.2 卷积神经网络实际应用实例 181 16.4 算法特点 183 16.4.1 算法优点 183 16.4.2 算法缺点 183 第 17 讲 RBM学习 185 17.1 基本原理 185 17.1.1 RBM学习思想 185 17.1.2 RBM模型基础 186 17.1.3 RBM模型学习 189 17.2 算法改进 195 17.2.1 方差RBM 195 17.2.2 均值方差RBM 196 17.2.3 稀疏RBM 196 17.2.4 稀疏组RBM 197 17.2.5 分类RBM 197 17.3 仿真实验 198 17.4 算法特点 199 17.4.1 算法优点 199 17.4.2 算法缺点 200 第 18 讲 深度学习 203 18.1 基本原理 203 18.2 算法改进 212 18.3 仿真实验 214 18.4 算法特点 215 第 19 讲 遗传算法 218 19.1 算法原理 218 19.2 算法改进 220 19.2.1 适应度函数设计 220 19.2.2 初始群体的选取 221 19.3 算法仿真 221 19.3.1 图像预处理 222 19.3.2 车牌特征选取 222 19.3.3 基于遗传算法的车牌定位 223 19.4 算法特点 225 19.4.1 遗传算法的优点 226 19.4.2 遗传算法的不足 226 第 20 讲 蚁群方法 228 20.1 基本原理 228 20.1.1 群智能 228 20.1.2 蚂蚁寻找食物源方法 229 20.1.3 蚁群算法的规则 230 20.1.4 蚁群算法的实现 231 20.2 算法改进 232 20.2.1 基于遗传学的改进蚁群算法 232 20.2.2 蚁群系统 232 20.2.3 精英蚁群系统 233 20.2.4 最大最小蚁群系统 233 20.2.5 排序蚁群系统 234 20.2.6 最优-最差蚂蚁系统 235 20.3 仿真实验 235 20.3.1 蚁群算法实例 235 20.3.2 蚁群算法实现流程 236 20.3.3 蚁群算法伪代码 237 20.4 算法特点 238
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>视觉机器学习20讲
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python与机器学习实战
第1章　Python与机器学习入门	1
1.1  机器学习绪论	1
1.1.1  什么是机器学习	2
1.1.2  机器学习常用术语	3
1.1.3  机器学习的重要性	6
1.2  人生苦短，我用Python	7
1.2.1  为何选择Python	7
1.2.2  Python 在机器学习领域的优势	8
1.2.3  Anaconda的安装与使用	8
1.3  第一个机器学习样例	12
1.3.1  获取与处理数据	13
1.3.2  选择与训练模型	14
1.3.3  评估与可视化结果	15
1.4  本章小结	17
第2章　贝叶斯分类器	18
2.1  贝叶斯学派	18
2.1.1  贝叶斯学派与频率学派	19
2.1.2  贝叶斯决策论	19
2.2  参数估计	20
2.2.1  极大似然估计（ML估计）	21
2.2.2  极大后验概率估计（MAP估计）	22
2.3  朴素贝叶斯	23
2.3.1  算法陈述与基本架构的搭建	23
2.3.2  MultinomialNB的实现与评估	31
2.3.3  GaussianNB的实现与评估	40
2.3.4  MergedNB的实现与评估	43
2.3.5  算法的向量化	50
2.4  半朴素贝叶斯与贝叶斯网	53
2.4.1  半朴素贝叶斯	53
2.4.2  贝叶斯网	54
2.5  相关数学理论	55
2.5.1  贝叶斯公式与后验概率	55
2.5.2  离散型朴素贝叶斯算法	56
2.5.3  朴素贝叶斯和贝叶斯决策	58
2.6  本章小结	59
第3章　决策树	60
3.1  数据的信息	60
3.1.1  信息论简介	61
3.1.2  不确定性	61
3.1.3  信息的增益	65
3.1.4  决策树的生成	68
3.1.5  相关的实现	77
3.2  过拟合与剪枝	92
3.2.1  ID3、C4.5的剪枝算法	93
3.2.2  CART剪枝	100
3.3  评估与可视化	103
3.4  相关数学理论	111
3.5  本章小结	113
第4章　集成学习	114
4.1  “集成”的思想	114
4.1.1  众擎易举	115
4.1.2  Bagging与随机森林	115
4.1.3  PAC框架与Boosting	119
4.2  随机森林算法	120
4.3  AdaBoost算法	124
4.3.1  AdaBoost算法陈述	124
4.3.2  弱模型的选择	126
4.3.3  AdaBoost的实现	127
4.4  集成模型的性能分析	129
4.4.1  随机数据集上的表现	130
4.4.2  异或数据集上的表现	131
4.4.3  螺旋数据集上的表现	134
4.4.4  蘑菇数据集上的表现	136
4.5  AdaBoost算法的解释	138
4.6  相关数学理论	139
4.6.1  经验分布函数	139
4.6.2  AdaBoost与前向分步加法模型	140
4.7  本章小结	142
第5章　支持向量机	144
5.1  感知机模型	145
5.1.1  线性可分性与感知机策略	145
5.1.2  感知机算法	148
5.1.3  感知机算法的对偶形式	151
5.2  从感知机到支持向量机	153
5.2.1  间隔最大化与线性SVM	154
5.2.2  SVM算法的对偶形式	158
5.2.3  SVM的训练	161
5.3  从线性到非线性	163
5.3.1  核技巧简述	163
5.3.2  核技巧的应用	166
5.4  多分类与支持向量回归	180
5.4.1  一对多方法（One-vs-Rest）	180
5.4.2  一对一方法（One-vs-One）	181
5.4.3  有向无环图方法（Directed Acyclic Graph Method）	181
5.4.4  支持向量回归（Support Vector Regression）	182
5.5  相关数学理论	183
5.5.1  梯度下降法	183
5.5.2  拉格朗日对偶性	185
5.6  本章小结	187
第6章　神经网络	188
6.1  从感知机到多层感知机	189
6.2  前向传导算法	192
6.2.1  算法概述	193
6.2.2  激活函数（Activation Function）	195
6.2.3  损失函数（Cost Function）	199
6.3  反向传播算法	200
6.3.1  算法概述	200
6.3.2  损失函数的选择	202
6.3.3  相关实现	205
6.4  特殊的层结构	211
6.5  参数的更新	214
6.5.1  Vanilla Update	217
6.5.2  Momentum Update	217
6.5.3  Nesterov Momentum Update	219
6.5.4  RMSProp	220
6.5.5  Adam	221
6.5.6  Factory	222
6.6  朴素的网络结构	223
6.7  “大数据”下的网络结构	227
6.7.1  分批（Batch）的思想	228
6.7.2  交叉验证	230
6.7.3  进度条	231
6.7.4  计时器	233
6.8  相关数学理论	235
6.8.1  BP算法的推导	235
6.8.2  Softmax + log-likelihood组合	238
6.9  本章小结	240
第7章　卷积神经网络	241
7.1  从NN到CNN	242
7.1.1  “视野”的共享	242
7.1.2  前向传导算法	243
7.1.3  全连接层（Fully Connected Layer）	250
7.1.4  池化（Pooling）	251
7.2  利用TensorFlow重写NN	252
7.2.1  反向传播算法	252
7.2.2  重写Layer结构	253
7.2.3  实现SubLayer结构	255
7.2.4  重写CostLayer结构	261
7.2.5  重写网络结构	262
7.3  将NN扩展为CNN	263
7.3.1  实现卷积层	263
7.3.2  实现池化层	266
7.3.3  实现CNN中的特殊层结构	267
7.3.4  实现LayerFactory	268
7.3.5  扩展网络结构	270
7.4  CNN的性能	272
7.4.1  问题描述	272
7.4.2  搭建CNN模型	273
7.4.3  模型分析	280
7.4.4  应用CNN的方法	283
7.4.5  Inception	286
7.5  本章小结	289
附录A　Python入门	290
附录B　Numpy入门	303
附录C　TensorFlow入门	310
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python与机器学习实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习导论（原书第3版）
出版者的话
译者序
前言
符号说明
第1章引言1
1.1什么是机器学习1
1.2机器学习的应用实例2
1.2.1学习关联性2
1.2.2分类3
1.2.3回归5
1.2.4非监督学习6
1.2.5增强学习7
1.3注释8
1.4相关资源10
1.5习题11
1.6参考文献12
第2章监督学习13
2.1由实例学习类13
2.2VC维16
2.3概率近似正确学习16
2.4噪声17
2.5学习多类18
2.6回归19
2.7模型选择与泛化21
2.8监督机器学习算法的维23
2.9注释24
2.10习题25
2.11参考文献26
第3章贝叶斯决策理论27
3.1引言27
3.2分类28
3.3损失与风险29
3.4判别式函数30
3.5关联规则31
3.6注释33
3.7习题33
3.8参考文献36
第4章参数方法37
4.1引言37
4.2最大似然估计37
4.2.1伯努利密度38
4.2.2多项式密度38
4.2.3高斯（正态）密度39
4.3评价估计：偏倚和方差39
4.4贝叶斯估计40
4.5参数分类42
4.6回归44
4.7调整模型的复杂度：偏倚/方差两难选择46
4.8模型选择过程49
4.9注释51
4.10习题51
4.11参考文献53
第5章多元方法54
5.1多元数据54
5.2参数估计54
5.3缺失值估计55
5.4多元正态分布56
5.5多元分类57
5.6调整复杂度61
5.7离散特征62
5.8多元回归63
5.9注释64
5.10习题64
5.11参考文献66
第6章维度归约67
6.1引言67
6.2子集选择67
6.3主成分分析70
6.4特征嵌入74
6.5因子分析75
6.6奇异值分解与矩阵分解78
6.7多维定标79
6.8线性判别分析82
6.9典范相关分析85
6.10等距特征映射86
6.11局部线性嵌入87
6.12拉普拉斯特征映射89
6.13注释90
6.14习题91
6.15参考文献92
第7章聚类94
7.1引言94
7.2混合密度94
7.3k均值聚类95
7.4期望最大化算法98
7.5潜在变量混合模型100
7.6聚类后的监督学习101
7.7谱聚类102
7.8层次聚类103
7.9选择簇个数104
7.10注释104
7.11习题105
7.12参考文献106
第8章非参数方法107
8.1引言107
8.2非参数密度估计108
8.2.1直方图估计108
8.2.2核估计109
8.2.3k最近邻估计110
8.3推广到多变元数据111
8.4非参数分类112
8.5精简的最近邻112
8.6基于距离的分类113
8.7离群点检测115
8.8非参数回归：光滑模型116
8.8.1移动均值光滑116
8.8.2核光滑117
8.8.3移动线光滑119
8.9如何选择光滑参数119
8.10注释120
8.11习题121
8.12参考文献122
第9章决策树124
9.1引言124
9.2单变量树125
9.2.1分类树125
9.2.2回归树128
9.3剪枝130
9.4由决策树提取规则131
9.5由数据学习规则132
9.6多变量树134
9.7注释135
9.8习题137
9.9参考文献138
第10章线性判别式139
10.1引言139
10.2推广线性模型140
10.3线性判别式的几何意义140
10.3.1两类问题140
10.3.2多类问题141
10.4逐对分离142
10.5参数判别式的进一步讨论143
10.6梯度下降144
10.7逻辑斯谛判别式145
10.7.1两类问题145
10.7.2多类问题147
10.8回归判别式150
10.9学习排名151
10.10注释152
10.11习题152
10.12参考文献154
第11章多层感知器155
11.1引言155
11.1.1理解人脑155
11.1.2神经网络作为并行处理的典范156
11.2感知器157
11.3训练感知器159
11.4学习布尔函数160
11.5多层感知器161
11.6作为普适近似的MLP162
11.7向后传播算法163
11.7.1非线性回归163
11.7.2两类判别式166
11.7.3多类判别式166
11.7.4多个隐藏层167
11.8训练过程167
11.8.1改善收敛性167
11.8.2过分训练168
11.8.3构造网络169
11.8.4线索169
11.9调整网络规模170
11.10学习的贝叶斯观点172
11.11维度归约173
11.12学习时间174
11.12.1时间延迟神经网络175
11.12.2递归网络175
11.13深度学习176
11.14注释177
11.15习题178
11.16参考文献180
第12章局部模型182
12.1引言182
12.2竞争学习182
12.2.1在线k均值182
12.2.2自适应共鸣理论184
12.2.3自组织映射185
12.3径向基函数186
12.4结合基于规则的知识189
12.5规范化基函数190
12.6竞争的基函数191
12.7学习向量量化193
12.8混合专家模型193
12.8.1协同专家模型194
12.8.2竞争专家模型195
12.9层次混合专家模型195
12.10注释196
12.11习题196
12.12参考文献198
第13章核机器200
13.1引言200
13.2最佳分离超平面201
13.3不可分情况：软边缘超平面203
13.4vSVM205
13.5核技巧205
13.6向量核206
13.7定义核207
13.8多核学习208
13.9多类核机器209
13.10用于回归的核机器210
13.11用于排名的核机器212
13.12一类核机器213
13.13大边缘最近邻分类215
13.14核维度归约216
13.15注释217
13.16习题217
13.17参考文献218
第14章图方法221
14.1引言221
14.2条件独立的典型情况222
14.3生成模型226
14.4d分离227
14.5信念传播228
14.5.1链228
14.5.2树229
14.5.3多树230
14.5.4结树232
14.6无向图：马尔科夫随机场232
14.7学习图模型的结构234
14.8影响图234
14.9注释234
14.10习题235
14.11参考文献237
第15章隐马尔科夫模型238
15.1引言238
15.2离散马尔科夫过程238
15.3隐马尔科夫模型240
15.4HMM的三个基本问题241
15.5估值问题241
15.6寻找状态序列244
15.7学习模型参数245
15.8连续观测247
15.9HMM作为图模型248
15.10HMM中的模型选择250
15.11注释251
15.12习题252
15.13参考文献254
第16章贝叶斯估计255
16.1引言255
16.2离散分布的参数的贝叶斯估计257
16.2.1K>2个状态：狄利克雷分布257
16.2.2K=2个状态:贝塔分布258
16.3高斯分布的参数的贝叶斯估计258
16.3.1一元情况：未知均值，已知方差258
16.3.2一元情况:未知均值,未知方差259
16.3.3多元情况:未知均值,未知协方差260
16.4函数的参数的贝叶斯估计261
16.4.1回归261
16.4.2具有噪声精度先验的回归264
16.4.3基或核函数的使用265
16.4.4贝叶斯分类266
16.5选择先验268
16.6贝叶斯模型比较268
16.7混合模型的贝叶斯估计270
16.8非参数贝叶斯建模272
16.9高斯过程272
16.10狄利克雷过程和中国餐馆275
16.11本征狄利克雷分配276
16.12贝塔过程和印度自助餐277
16.13注释278
16.14习题278
16.15参考文献279
第17章组合多学习器280
17.1基本原理280
17.2产生有差异的学习器280
17.3模型组合方案282
17.4投票法282
17.5纠错输出码285
17.6装袋286
17.7提升287
17.8重温混合专家模型288
17.9层叠泛化289
17.10调整系综290
17.10.1选择系综的子集290
17.10.2构建元学习器290
17.11级联291
17.12注释292
17.13习题293
17.14参考文献294
第18章增强学习297
18.1引言297
18.2单状态情况：K臂赌博机问题298
18.3增强学习的要素299
18.4基于模型的学习300
18.4.1价值迭代300
18.4.2策略迭代301
18.5时间差分学习301
18.5.1探索策略301
18.5.2确定性奖励和动作302
18.5.3非确定性奖励和动作303
18.5.4资格迹304
18.6推广305
18.7部分可观测状态306
18.7.1场景306
18.7.2例子：老虎问题307
18.8注释310
18.9习题311
18.10参考文献312
第19章机器学习实验的设计与分析314
19.1引言314
19.2因素、响应和实验策略315
19.3响应面设计317
19.4随机化、重复和阻止317
19.5机器学习实验指南318
19.6交叉验证和再抽样方法320
19.6.1K折交叉验证320
19.6.25×2交叉验证320
19.6.3自助法321
19.7度量分类器的性能321
19.8区间估计324
19.9假设检验326
19.10评估分类算法的性能327
19.10.1二项检验327
19.10.2近似正态检验328
19.10.3t检验328
19.11比较两个分类算法329
19.11.1McNemar检验329
19.11.2K折交叉验证配对t检验329
19.11.35×2交叉验证配对t检验330
19.11.45×2交叉验证配对F检验330
19.12比较多个算法：方差分析331
19.13在多个数据集上比较333
19.13.1比较两个算法334
19.13.2比较多个算法335
19.14多元检验336
19.14.1比较两个算法336
19.14.2比较多个算法337
19.15注释338
19.16习题339
19.17参考文献340
附录A概率论341
索引348
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习导论（原书第3版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark MLlib机器学习
第一部分　Spark MLlib基础
第1章　Spark机器学习简介	2
1.1　机器学习介绍	2
1.2　Spark介绍	3
1.3　Spark MLlib介绍	4
第2章　Spark数据操作	6
2.1　Spark RDD操作	6
2.1.1　Spark RDD创建操作	6
2.1.2　Spark RDD转换操作	7
2.1.3　Spark RDD行动操作	14
2.2　MLlib Statistics统计操作	15
2.2.1　列统计汇总	15
2.2.2　相关系数	16
2.2.3　假设检验	18
2.3　MLlib数据格式	18
2.3.1　数据处理	18
2.3.2　生成样本	22
第3章　Spark MLlib矩阵向量	26
3.1　Breeze介绍	26
3.1.1　Breeze创建函数	27
3.1.2　Breeze元素访问及操作函数	29
3.1.3　Breeze数值计算函数	34
3.1.4　Breeze求和函数	35
3.1.5　Breeze布尔函数	36
3.1.6　Breeze线性代数函数	37
3.1.7　Breeze取整函数	39
3.1.8　Breeze常量函数	40
3.1.9　Breeze复数函数	40
3.1.10　Breeze三角函数	40
3.1.11　Breeze对数和指数函数	40
3.2　BLAS介绍	41
3.2.1　BLAS向量-向量运算	42
3.2.2　BLAS矩阵-向量运算	42
3.2.3　BLAS矩阵-矩阵运算	43
3.3　MLlib向量	43
3.3.1　MLlib向量介绍	43
3.3.2　MLlib Vector接口	44
3.3.3　MLlib DenseVector类	46
3.3.4　MLlib SparseVector类	49
3.3.5　MLlib Vectors伴生对象	50
3.4　MLlib矩阵	57
3.4.1　MLlib矩阵介绍	57
3.4.2　MLlib Matrix接口	57
3.4.3　MLlib DenseMatrix类	59
3.4.4　MLlib SparseMatrix类	64
3.4.5　MLlib Matrix伴生对象	71
3.5　MLlib BLAS	77
3.6　MLlib分布式矩阵	93
3.6.1　MLlib分布式矩阵介绍	93
3.6.2　行矩阵（RowMatrix）	94
3.6.3　行索引矩阵（IndexedRowMatrix）	96
3.6.4　坐标矩阵（CoordinateMatrix）	97
3.6.5　分块矩阵（BlockMatrix）	98
第二部分　Spark MLlib回归算法
第4章　Spark MLlib线性回归算法	102
4.1　线性回归算法	102
4.1.1　数学模型	102
4.1.2　最小二乘法	105
4.1.3　梯度下降算法	105
4.2　源码分析	106
4.2.1　建立线性回归	108
4.2.2　模型训练run方法	111
4.2.3　权重优化计算	114
4.2.4　线性回归模型	121
4.3　实例	123
4.3.1　训练数据	123
4.3.2　实例代码	123
第5章　Spark MLlib逻辑回归算法	126
5.1　逻辑回归算法	126
5.1.1　数学模型	126
5.1.2  梯度下降算法	128
5.1.3　正则化	129
5.2　源码分析	132
5.2.1　建立逻辑回归	134
5.2.2　模型训练run方法	137
5.2.3　权重优化计算	137
5.2.4　逻辑回归模型	144
5.3　实例	148
5.3.1　训练数据	148
5.3.2　实例代码	148
第6章　Spark MLlib保序回归算法	151
6.1　保序回归算法	151
6.1.1　数学模型	151
6.1.2　L2保序回归算法	153
6.2　源码分析	153
6.2.1　建立保序回归	154
6.2.2　模型训练run方法	156
6.2.3　并行PAV计算	156
6.2.4　PAV计算	157
6.2.5　保序回归模型	159
6.3　实例	164
6.3.1　训练数据	164
6.3.2　实例代码	164
第三部分　Spark MLlib分类算法
第7章　Spark MLlib贝叶斯分类算法	170
7.1　贝叶斯分类算法	170
7.1.1　贝叶斯定理	170
7.1.2　朴素贝叶斯分类	171
7.2　源码分析	173
7.2.1　建立贝叶斯分类	173
7.2.2　模型训练run方法	176
7.2.3　贝叶斯分类模型	179
7.3　实例	181
7.3.1　训练数据	181
7.3.2　实例代码	182
第8章　Spark MLlib SVM支持向量机算法	184
8.1　SVM支持向量机算法	184
8.1.1　数学模型	184
8.1.2　拉格朗日	186
8.2　源码分析	189
8.2.1　建立线性SVM分类	191
8.2.2　模型训练run方法	194
8.2.3　权重优化计算	194
8.2.4　线性SVM分类模型	196
8.3　实例	199
8.3.1　训练数据	199
8.3.2　实例代码	199
第9章　Spark MLlib决策树算法	202
9.1　决策树算法	202
9.1.1　决策树	202
9.1.2　特征选择	203
9.1.3　决策树生成	205
9.1.4　决策树生成实例	206
9.1.5　决策树的剪枝	208
9.2　源码分析	209
9.2.1　建立决策树	211
9.2.2　建立随机森林	216
9.2.3　建立元数据	220
9.2.4　查找特征的分裂及划分	223
9.2.5　查找最好的分裂顺序	228
9.2.6　决策树模型	231
9.3　实例	234
9.3.1　训练数据	234
9.3.2　实例代码	234
第四部分　Spark MLlib聚类算法
第10章　Spark MLlib KMeans聚类算法	238
10.1　KMeans聚类算法	238
10.1.1　KMeans算法	238
10.1.2　演示KMeans算法	239
10.1.3　初始化聚类中心点	239
10.2　源码分析	240
10.2.1　建立KMeans聚类	242
10.2.2　模型训练run方法	247
10.2.3　聚类中心点计算	248
10.2.4　中心点初始化	251
10.2.5　快速距离计算	254
10.2.6　KMeans聚类模型	255
10.3　实例	258
10.3.1　训练数据	258
10.3.2　实例代码	259
第11章　Spark MLlib LDA主题模型算法	261
11.1　LDA主题模型算法	261
11.1.1　LDA概述	261
11.1.2　LDA概率统计基础	262
11.1.3　LDA数学模型	264
11.2　GraphX基础	267
11.3　源码分析	270
11.3.1　建立LDA主题模型	272
11.3.2　优化计算	279
11.3.3　LDA模型	283
11.4　实例	288
11.4.1　训练数据	288
11.4.2　实例代码	288
第五部分　Spark MLlib关联规则挖掘算法
第12章　Spark MLlib FPGrowth关联规则算法	292
12.1　FPGrowth关联规则算法	292
12.1.1　基本概念	292
12.1.2　FPGrowth算法	293
12.1.3　演示FP树构建	294
12.1.4　演示FP树挖掘	296
12.2　源码分析	298
12.2.1　FPGrowth类	298
12.2.2　关联规则挖掘	300
12.2.3　FPTree类	303
12.2.4　FPGrowthModel类	306
12.3　实例	306
12.3.1　训练数据	306
12.3.2　实例代码	306
第六部分　Spark MLlib推荐算法
第13章　Spark MLlib ALS交替最小二乘算法	310
13.1　ALS交替最小二乘算法	310
13.2　源码分析	312
13.2.1　建立ALS	314
13.2.2　矩阵分解计算	322
13.2.3　ALS模型	329
13.3　实例	334
13.3.1　训练数据	334
13.3.2　实例代码	334
第14章　Spark MLlib协同过滤推荐算法	337
14.1　协同过滤推荐算法	337
14.1.1　协同过滤推荐概述	337
14.1.2　用户评分	338
14.1.3　相似度计算	338
14.1.4　推荐计算	340
14.2　协同推荐算法实现	341
14.2.1　相似度计算	344
14.2.2　协同推荐计算	348
14.3　实例	350
14.3.1　训练数据	350
14.3.2　实例代码	350
第七部分　Spark MLlib神经网络算法
第15章　Spark MLlib神经网络算法综述	354
15.1　人工神经网络算法	354
15.1.1　神经元	354
15.1.2　神经网络模型	355
15.1.3  信号前向传播	356
15.1.4　误差反向传播	357
15.1.5　其他参数	360
15.2　神经网络算法实现	361
15.2.1　神经网络类	363
15.2.2　训练准备	370
15.2.3　前向传播	375
15.2.4　误差反向传播	377
15.2.5　权重更新	381
15.2.6　ANN模型	382
15.3　实例	384
15.3.1　测试数据	384
15.3.2　测试函数代码	387
15.3.3　实例代码	388
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark MLlib机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习——Python实践
第一部分 初始
1 初识机器学习 2
1.1 学习机器学习的误区 2
1.2 什么是机器学习 3
1.3 Python 中的机器学习 3
1.4 学习机器学习的原则 5
1.5 学习机器学习的技巧 5
1.6 这本书不涵盖以下内容 6
1.7 代码说明 6
1.8 总结 6
2 Python 机器学习的生态圈 7
2.1 Python 7
2.2 SciPy 9
2.3 scikit-learn 9
2.4 环境安装 10
2.5 总结 12
3 第一个机器学习项目 13
3.1 机器学习中的 Hello World 项目 13
3.2 导入数据 14
3.3 概述数据 15
3.4 数据可视化 18
3.5 评估算法 20
3.6 实施预测 23
3.7 总结 24
4 Python 和 SciPy 速成 25
4.1 Python 速成 25
4.2 NumPy 速成 34
4.3 Matplotlib 速成 36
4.4 Pandas 速成 39
4.5 总结 41
第二部分 数据理解
5 数据导入 44
5.1 CSV 文件 44
5.2 Pima Indians 数据集 45
5.3 采用标准 Python 类库导入数据 46
5.4 采用 NumPy 导入数据 46
5.5 采用 Pandas 导入数据 47
5.6 总结 47
6 数据理解 48
6.1 简单地查看数据 48
6.2 数据的维度 49
6.3 数据属性和类型 50
6.4 描述性统计 50
6.5 数据分组分布（适用于分类算法） 51
6.6 数据属性的相关性 52
6.7 数据的分布分析 53
6.8 总结 54
7 数据可视化 55
7.1 单一图表 55
7.2 多重图表 58
7.3 总结 61
第三部分 数据准备
8 数据预处理 64
8.1 为什么需要数据预处理 64
8.2 格式化数据 65
8.3 调整数据尺度 65
8.4 正态化数据 67
8.5 标准化数据 68
8.6 二值数据 69
8.7 总结 70
9 数据特征选定 71
9.1 特征选定 72
9.2 单变量特征选定 72
9.3 递归特征消除 73
9.4 主要成分分析 75
9.5 特征重要性 76
9.6 总结 76
第四部分 选择模型
10 评估算法 78
10.1 评估算法的方法 78
10.2 分离训练数据集和评估数据集 79
10.3 K 折交叉验证分离 80
10.4 弃一交叉验证分离 81
10.5 重复随机分离评估数据集与训练数据集 82
10.6 总结 83
11 算法评估矩阵 85
11.1 算法评估矩阵 85
11.2 分类算法矩阵 86
11.3 回归算法矩阵 93
11.4 总结 96
12 审查分类算法 97
12.1 算法审查 97
12.2 算法概述 98
12.3 线性算法 98
12.4 非线性算法 101
12.5 总结 105
13 审查回归算法 106
13.1 算法概述 106
13.2 线性算法 107
13.3 非线性算法 111
13.4 总结 113
14 算法比较 115
14.1 选择最佳的机器学习算法 115
14.2 机器学习算法的比较 116
14.3 总结 118
15 自动流程 119
15.1 机器学习的自动流程 119
15.2 数据准备和生成模型的 Pipeline 120
15.3 特征选择和生成模型的 Pipeline 121
15.4 总结 122
第五部分 优化模型
16 集成算法 124
16.1 集成的方法 124
16.2 装袋算法 125
16.3 提升算法 129
16.4 投票算法 131
16.5 总结 132
17 算法调参 133
17.1 机器学习算法调参 133
17.2 网格搜索优化参数 134
17.3 随机搜索优化参数 135
17.4 总结 136
第六部分 结果部署
18 持久化加载模型 138
18.1 通过 pickle 序列化和反序列化机器学习的模型 138
18.2 通过 joblib 序列化和反序列化机器学习的模型 140
18.3 生成模型的技巧 141
18.4 总结 141
第七部分 项目实践
19 预测模型项目模板 144
19.1 在项目中实践机器学习 145
19.2 机器学习项目的 Python 模板 145
19.3 各步骤的详细说明 146
19.4 使用模板的小技巧 148
19.5 总结 149
20 回归项目实例 150
20.1 定义问题 150
20.2 导入数据 151
20.3 理解数据 152
20.4 数据可视化 155
20.5 分离评估数据集 159
20.6 评估算法 160
20.7 调参改善算法 164
20.8 集成算法 165
20.9 集成算法调参 167
20.10 确定最终模型 168
20.11 总结 169
21 二分类实例 170
21.1 问题定义 170
21.2 导入数据 171
21.3 分析数据 172
21.4 分离评估数据集 180
21.5 评估算法 180
21.6 算法调参 184
21.7 集成算法 187
21.8 确定最终模型 190
21.9 总结 190
22 文本分类实例 192
22.1 问题定义 192
22.2 导入数据 193
22.3 文本特征提取 195
22.4 评估算法 196
22.5 算法调参 198
22.6 集成算法 200
22.7 集成算法调参 201
22.8 确定最终模型 202
22.9 总结 203
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习——Python实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习系统设计：python语言实现
CONTENTS
目录
译者序
前言
第1章　机器学习的思维1
1.1　人机界面1
1.2　设计原理4
1.2.1　问题的类型6
1.2.2　问题是否正确7
1.2.3　任务8
1.2.4　统一建模语言27
1.3　总结31
第2章　工具和技术32
2.1　Python与机器学习33
2.2　IPython控制台33
2.3　安装SciPy栈34
2.4　NumPy35
2.4.1　构造和变换数组38
2.4.2　数学运算39
2.5　Matplotlib41
2.6　Pandas45
2.7　SciPy47
2.8　Scikit-learn50
2.9　总结57
第3章　将数据变为信息58
3.1　什么是数据58
3.2　大数据59
3.2.1　大数据的挑战60
3.2.2　数据模型62
3.2.3　数据分布63
3.2.4　来自数据库的数据67
3.2.5　来自互联网的数据68
3.2.6　来自自然语言的数据70
3.2.7　来自图像的数据72
3.2.8　来自应用编程接口的数据72
3.3　信号74
3.4　数据清洗76
3.5　数据可视化78
3.6　总结80
第4章　模型—从信息中学习81
4.1　逻辑模型81
4.1.1　一般性排序83
4.1.2　解释空间84
4.1.3　覆盖空间86
4.1.4　PAC学习和计算复杂性87
4.2　树状模型88
4.3　规则模型92
4.3.1　有序列表方法94
4.3.2　基于集合的规则模型95
4.4　总结98
第5章　线性模型100
5.1　最小二乘法101
5.1.1　梯度下降102
5.1.2　正规方程法107
5.2　logistic回归109
5.3　多分类113
5.4　正则化115
5.5　总结117
第6章　神经网络119
6.1　神经网络入门119
6.2　logistic单元121
6.3　代价函数126
6.4　神经网络的实现128
6.5　梯度检验133
6.6　其他神经网络架构134
6.7　总结135
第7章　特征—算法眼中的世界136
7.1　特征的类型137
7.1.1　定量特征137
7.1.2　有序特征138
7.1.3　分类特征138
7.2　运算和统计139
7.3　结构化特征141
7.4　特征变换141
7.4.1　离散化143
7.4.2　归一化144
7.4.3　校准145
7.5　主成分分析149
7.6　总结151
第8章　集成学习152
8.1　集成学习的类型152
8.2　Bagging方法153
8.2.1　随机森林154
8.2.2　极端随机树155
8.3　Boosting方法159
8.3.1　AdaBoost161
8.3.2　梯度Boosting163
8.4　集成学习的策略165
8.5　总结168
第9章　设计策略和案例研究169
9.1　评价模型的表现169
9.2　模型的选择174
9.3　学习曲线176
9.4　现实世界中的案例研究178
9.4.1　建立一个推荐系统178
9.4.2　温室虫害探测185
9.5　机器学习一瞥188
9.6　总结190
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习系统设计：python语言实现
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>scikit learn机器学习
前言
第1章 机器学习介绍	1
1.1 什么是机器学习	1
1.2 机器学习有什么用	2
1.3 机器学习的分类	3
1.4 机器学习应用开发的典型步骤	4
1.4.1 数据采集和标记	4
1.4.2 数据清洗	5
1.4.3 特征选择	5
1.4.4 模型选择	5
1.4.5 模型训练和测试	5
1.4.6 模型性能评估和优化	5
1.4.7 模型使用	6
1.5 复习题	6
第2章 Python机器学习软件包	7
2.1 开发环境搭建	7
2.2 IPython简介	8
2.2.1 IPython基础	8
2.2.2 IPython图形界面	13
2.3 Numpy简介	15
2.3.1 Numpy数组	15
2.3.2 Numpy运算	19
2.4 Pandas简介	32
2.4.1 基本数据结构	32
2.4.2 数据排序	34
2.4.3 数据访问	34
2.4.4 时间序列	36
2.4.5 数据可视化	36
2.4.6 文件读写	38
2.5 Matplotlib简介	38
2.5.1 图形样式	38
2.5.2 图形对象	40
2.5.3 画图操作	46
2.6 scikit-learn简介	51
2.6.1 scikit-learn示例	51
2.6.2 scikit-learn一般性原理和通用规则	55
2.7 复习题	56
2.8 拓展学习资源	57
第3章 机器学习理论基础	58
3.1 过拟合和欠拟合	58
3.2 成本函数	59
3.3 模型准确性	60
3.3.1 模型性能的不同表述方式	61
3.3.2 交叉验证数据集	61
3.4 学习曲线	62
3.4.1 实例：画出学习曲线	62
3.4.2 过拟合和欠拟合的特征	65
3.5 算法模型性能优化	65
3.6 查准率和召回率	66
3.7 F1 Score	67
3.8 复习题	67
第4章 k-近邻算法	69
4.1 算法原理	69
4.1.1 算法优缺点	69
4.1.2 算法参数	70
4.1.3 算法的变种	70
4.2 示例：使用k-近邻算法进行分类	70
4.3 示例：使用k-近邻算法进行回归拟合	72
4.4 实例：糖尿病预测	74
4.4.1 加载数据	74
4.4.2 模型比较	75
4.4.3 模型训练及分析	77
4.4.4 特征选择及数据可视化	78
4.5 拓展阅读	80
4.5.1 如何提高k-近邻算法的运算效率	80
4.5.2 相关性测试	80
4.6 复习题	81
第5章 线性回归算法	83
5.1 算法原理	83
5.1.1 预测函数	83
5.1.2 成本函数	84
5.1.3 梯度下降算法	84
5.2 多变量线性回归算法	86
5.2.1 预测函数	86
5.2.2 成本函数	87
5.2.3 梯度下降算法	88
5.3 模型优化	89
5.3.1 多项式与线性回归	89
5.3.2 数据归一化	89
5.4 示例：使用线性回归算法拟合正弦函数	90
5.5 示例：测算房价	92
5.5.1 输入特征	92
5.5.2 模型训练	93
5.5.3 模型优化	94
5.5.4 学习曲线	95
5.6 拓展阅读	96
5.6.1 梯度下降迭代公式推导	96
5.6.2 随机梯度下降算法	96
5.6.3 标准方程	97
5.7 复习题	97
第6章 逻辑回归算法	98
6.1 算法原理	98
6.1.1 预测函数	98
6.1.2 判定边界	99
6.1.3 成本函数	100
6.1.4 梯度下降算法	102
6.2 多元分类	102
6.3 正则化	103
6.3.1 线性回归模型正则化	103
6.3.2 逻辑回归模型正则化	104
6.4 算法参数	104
6.5 实例：乳腺癌检测	106
6.5.1 数据采集及特征提取	106
6.5.2 模型训练	108
6.5.3 模型优化	110
6.5.4 学习曲线	111
6.6 拓展阅读	113
6.7 复习题	114
第7章 决策树	115
7.1 算法原理	115
7.1.1 信息增益	116
7.1.2 决策树的创建	119
7.1.3 剪枝算法	120
7.2 算法参数	121
7.3 实例：预测泰坦尼克号幸存者	122
7.3.1 数据分析	122
7.3.2 模型训练	123
7.3.3 优化模型参数	124
7.3.4 模型参数选择工具包	127
7.4 拓展阅读	130
7.4.1 熵和条件熵	130
7.4.2 决策树的构建算法	130
7.5 集合算法	131
7.5.1 自助聚合算法Bagging	131
7.5.2 正向激励算法boosting	131
7.5.3 随机森林	132
7.5.4 ExtraTrees算法	133
7.6 复习题	133
第8章 支持向量机	134
8.1 算法原理	134
8.1.1 大间距分类算法	134
8.1.2 松弛系数	136
8.2 核函数	138
8.2.1 最简单的核函数	138
8.2.2 相似性函数	140
8.2.3 常用的核函数	141
8.2.4 核函数的对比	142
8.3 scikit-learn里的SVM	144
8.4 实例：乳腺癌检测	146
8.5 复习题	149
第9章 朴素贝叶斯算法	151
9.1 算法原理	151
9.1.1 贝叶斯定理	151
9.1.2 朴素贝叶斯分类法	152
9.2 一个简单的例子	153
9.3 概率分布	154
9.3.1 概率统计的基本概念	154
9.3.2 多项式分布	155
9.3.3 高斯分布	158
9.4 连续值的处理	159
9.5 实例：文档分类	160
9.5.1 获取数据集	160
9.5.2 文档的数学表达	161
9.5.3 模型训练	163
9.5.4 模型评价	165
9.6 复习题	167
第10章 PCA算法	168
10.1 算法原理	168
10.1.1 数据归一化和缩放	169
10.1.2 计算协方差矩阵的特征向量	169
10.1.3 数据降维和恢复	170
10.2 PCA 算法示例	171
10.2.1 使用Numpy模拟PCA计算过程	171
10.2.2 使用sklearn进行PCA降维运算	173
10.2.3 PCA的物理含义	174
10.3 PCA 的数据还原率及应用	175
10.3.1 数据还原率	175
10.3.2 加快监督机器学习算法的运算速度	176
10.4 实例：人脸识别	176
10.4.1 加载数据集	176
10.4.2 一次失败的尝试	179
10.4.3 使用PCA来处理数据集	182
10.4.4 最终结果	185
10.5 拓展阅读	189
10.6 复习题	189
第11章 k-均值算法	190
11.1 算法原理	190
11.1.1 k-均值算法成本函数	191
11.1.2 随机初始化聚类中心点	191
11.1.3 选择聚类的个数	192
11.2 scikit-learn里的k-均值算法	192
11.3 使用k-均值对文档进行聚类分析	195
11.3.1 准备数据集	195
11.3.2 加载数据集	196
11.3.3 文本聚类分析	197
11.4 聚类算法性能评估	200
11.4.1 Adjust Rand Index	200
11.4.2 齐次性和完整性	201
11.4.3 轮廓系数	203
11.5 复习题	204
后记	205
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>scikit learn机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能时代
目　录
引　言　制造出像大脑一样工作的机器 001
第一章　人工智能 009
第二章　神经网络 025
第三章　人脑 043
第四章　记忆 067
第五章　智能理论的新框架 087
第六章　大脑皮层是如何工作的 109
第七章　意识与创造力 177
第八章　智能的未来 205
附录　可检验的11个预测 235
参考书目 245
致　谢 253
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能时代
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>NLTK基础教程(用NLTK和Python库构建机器学习应用)
第1章自然语言处理简介1
1.1为什么要学习NLP2
1.2先从Python开始吧5
1.2.1列表5
1.2.2自助功能6
1.2.3正则表达式8
1.2.4字典9
1.2.5编写函数10
1.3向NLTK迈进11
1.4练习16
1.5小结17
第2章文本的歧义及其清理18
2.1何谓文本歧义18
2.2文本清理20
2.3语句分离器21
2.4标识化处理22
2.5词干提取23
2.6词形还原24
2.7停用词移除25
2.8罕见词移除26
2.9拼写纠错26
2.10练习27
2.11小结28
第3章词性标注29
3.1何谓词性标注29
3.1.1Stanford标注器32
3.1.2深入了解标注器33
3.1.3顺序性标注器35
3.1.4Brill标注器37
3.1.5基于机器学习的标注器37
3.2命名实体识别（NER）38
3.3练习40
3.4小结41
第4章文本结构解析43
4.1浅解析与深解析43
4.2两种解析方法44
4.3为什么需要进行解析44
4.4不同的解析器类型46
4.4.1递归下降解析器46
4.4.2移位—归约解析器46
4.4.3图表解析器46
4.4.4正则表达式解析器47
4.5依存性文本解析48
4.6语块分解50
4.7信息提取53
4.7.1命名实体识别（NER）53
4.7.2关系提取54
4.8小结55
第5章NLP应用56
5.1构建第一个NLP应用57
5.2其他NLP应用60
5.2.1机器翻译60
5.2.2统计型机器翻译61
5.2.3信息检索62
5.2.4语音识别64
5.2.5文本分类65
5.2.6信息提取66
5.2.7问答系统67
5.2.8对话系统67
5.2.9词义消歧67
5.2.10主题建模68
5.2.11语言检测68
5.2.12光符识别68
5.3小结68
第6章文本分类70
6.1机器学习71
6.2文本分类72
6.3取样操作74
6.3.1朴素贝叶斯法76
6.3.2决策树79
6.3.3随机梯度下降法80
6.3.4逻辑回归81
6.3.5支持向量机81
6.4随机森林算法83
6.5文本聚类83
6.6文本中的主题建模84
6.7参考资料87
6.8小结87
第7章Web爬虫88
7.1Web爬虫88
7.2编写第一个爬虫程序89
7.3Scrapy库中的数据流92
7.3.1Scrapy库的shell93
7.3.2目标项98
7.4生成网站地图的蜘蛛程序99
7.5目标项管道100
7.6参考资料102
7.7小结102
第8章NLTK与其他Python库的搭配运用104
8.1NumPy104
8.1.1多维数组105
8.1.2基本运算106
8.1.3从数组中提取数据107
8.1.4复杂矩阵运算108
8.2SciPy112
8.2.1线性代数113
8.2.2特征值与特征向量113
8.2.3稀疏矩阵114
8.2.4优化措施115
8.3pandas117
8.3.1读取数据117
8.3.2数列119
8.3.3列转换121
8.3.4噪声数据121
8.4matplotlib123
8.4.1子图绘制123
8.4.2添加坐标轴124
8.4.3散点图绘制125
8.4.4条形图绘制126
8.4.53D绘图126
8.5参考资料126
8.6小结127
第9章Python中的社交媒体挖掘128
9.1数据收集128
9.2数据提取132
9.3地理可视化134
9.3.1影响力检测135
9.3.2Facebook135
9.3.3有影响力的朋友139
9.4小结141
第10章大规模文本挖掘142
10.1在Hadoop上使用Python的不同方式142
10.1.1Python的流操作143
10.1.2Hive／Pig下的UDF143
10.1.3流封装器143
10.2Hadoop上的NLTK144
10.2.1用户定义函数（UDF）144
10.2.2Python的流操作146
10.3Hadoop上的Scikit—learn147
10.4PySpark150
10.5小结153
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>NLTK基础教程(用NLTK和Python库构建机器学习应用)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习及其应用2007
1 图象空间中的距离   1.1 引言   1.2 两副图象间的距离   1.3 两组图象间的距离   1.4 结束语   参考文献 2　平均奖赏强化学习研究   2.1 引言   2.2 MDP与SMDP    2.2.1 单链策略迭代算法    2.2.2 值迭代算法    2.2.3 异步值迭代算法   2.3 平均奖赏动态规划算法   2.4 平均奖赏强化学习算法   2.5 基于参考状态的平均奖赏强化学习法   2.6 仿真实验   2.7 结束语 3　离阶异构数据挖掘   3.1 引言  3.2 同构数据挖掘    3.2.1 谱聚类算法    3.2.2 Page Rank算法  3.3 两类异构对象的数据挖掘    3.3.1 二部图的谱分解    3.3.2 基于信息论的协同聚类  3.4 高阶异构数据挖掘    3.4.1 高阶异构对象的建模    3.4.2 基于统一关系矩阵的方法    3.4.3 基于张量的方法    3.4.4 基于相容二部图的方法  3.5 结束语  参考文献4 求解SVM的几何方法研究  4.1 引言  4.2 求解SVM几何方法的理论基础    4.2.1 线性可分SVM与最近点问题    4.2.2 L2范数SVM及其几何解释    4.2.3 软凸包与V—SVM的几何解释  4.3 求解线性可分SVM问题的几何算法    4.3.1 Gilbert算法与最小范数问题    4.3.2 可分情形下的SK算法    4.3.3 可分情形下的MDM算法  4.4　求解L1范数SVM问题的几何算法    4.4.1 软SK算法    4.4.2 软MDM算法  4.5 软SK算法和软MDM算法的一些实验结果    4.5.1 实验方法、实验环境与数据库    4.5.2 软SK算法实验    4.5.3 软MDM算法实验  4.6 SVM的最小球覆盖解释与近似最小球覆盖算法求解  4.7 SMO与几何算法之间的联系  4.8 结束语  参考文献5　典型相关分析研究进展  5.1 引言  5.2 问题的数学刻画    5.2.1 CCA数学描述    5.2.2 相关性与互信息之间的关系    5.2.3 CCA其他多元分析方法之间的关系    5.2.4 核CCA  5.3 CCA研究进展    5.3.1 CCA的应用    5.3.2 CCA计算方法的改进    5.3.3 基于CCA的扩展模型  5.4 结束语  参考文献6  Rashomon特征选择  6.1 引言    6.1.1 Rashomon    6.1.2 模型多样性问题    6.1.3 最简单的Rashomon问题——特征选择  6.2 特征选择    6.2.1 经典特征选择的类型    6.2.2 Filter类型特征选择    6.2.3 Relief算法  6.3  基于Reduct的特征选择    6.3.1 BNA(D)与误差    6.3.2 Reduct作为特征选择的解答  6.4R ashomon特征选择    6.4.1 基于全序的Reduct算法    6.4.2 Rashomon特征选择  6.5 次属性原理    6.5.1 次属性    6.5.2 次属性原理  6.6 Rashomon特征选择的计算    6.6.1 优化规则    6.6.2 算法  6.7 总结与问题  参考文献7  复杂网络上的学习  7.1 引言  7.2 分类器网络及Boosting学习    7.2.1 NetWork Boosting算法    7.2.2 算法收敛性    7.2.3 UCI数据集上的实验结果  7.3 网络拓扑结构对于NetWork Boosting算法性能的影响    7.3.1 Bias－Variance－Covariance    7.3.2 连接度数变化对于样本权重分布之间相关性的影响    7.3.3 不同连接概率的随机图上的对比实验结果  7.4 分布式环境中的分类器网络    7.4.1 分布式NetworkBoosting算法    7.4.2 分布式环境中监督学习实验结果    7.4.3 总结  参考文献8  聚类分析的新进展——谱聚类综述  8.1 谱聚类算法的由来  8.2 无向图的拉普拉斯矩阵性质  8.3 基于图划分的谱聚类算法  8.4 谱聚类算法诱导的异质聚类  8.5 谱聚类算法的进一步讨论  参考文献9 机器学习与自然语言处理  9.1 引言  9.2 自然语言处理的主攻方向  9.3 文学语言对机器学习提出的挑战    9.3.1 隐喻和影射    9.3.2 引用典故    9.3.3 遣词造句的形象化    9.3.4 夸张    9.3.5 双关    9.3.6 拟人化  9.4 服务于机器学习的语言资源建设  9.5 机器学习方法的实践    9.5.1 词义消歧研究    9.5.2 情感倾向分析    9.5.3 隐喻识别    9.5.4 小结  9.6 结束语  参考文献10 监督流形学习  10.1 引言  10.2 基础    10.2.1 流形    10.2.2 嵌入  10.3 流形学习简介及LLE算法    lO.3.1 流形学习的目的和基本思路    10.3.2 算法有效性分析    10.3.3 LLE算法介绍  10.4 监督流形学习    10.4.1 相关研究介绍    10.4.2 监督流形学习中面临的问题  10.5 基于Gabor基的监督流形学习    10.5.1 Gabor特征表示    10.5.2 ULLELDA算法    10.5.3 基于Gabor基的监督流形学习实验    10.5.4 En—ULLELDA算法    10.5.5 基于集成流形学习的实验  10.6 MUSNACAL算法和En—MUSNACAL算法    10.6.1 覆盖算法    10.6.2 双向RBF映射模型    10.6.3 分类    10.6.4 En—MUSNACAL算法    10.6.5 基于MUSNAcAL算法和En—MUSNACAL算法的实验    10.6.6 小结  10.7 讨论与总结  参考文献11 超完备拓扑独立分量分析  11.1 引言  11.2 超完备表示模型与算法  11.3 超完备表示实验仿真  11.4 结束语  参考文献12 商空间框架下的机器学习方法  12.1 人类智能的主要特征    12.1.1 人类全局分析问题的能力    12.1.2 人类局部分析问题的能力  12.2 智能的数学模型    12.2.1 全局分析能力的数学模型——粒度分析(计算)的    商空间模型    12.2.2 局部分析能力的数学模型——构造性学习方法(覆盖算法)    12.2.3 两者的综合  12.3 商空间粒度计算    12.3.1 粒度与模糊关系  12.4 商空间粒度分析的方法    12.4.1 对论域取粒度    12.4.2 对属性取粒度    12.4.3 对结构取粒度    12.4.4 商空间粒度计算的基本原理  12.5 构造性机器学习方法    12.5.1 覆盖算法    12.5.2 具有粒度结构知识的获取    12.5.3 基于商空间的覆盖算法  12.6 小结  参考文献13  半监督学习中的协同训练风范  13.1 引言  13.2 半监督学习  13.3 协同训练算法  13.4 协同训练理论分析  13.5 协同训练的应用  13.6 结束语  参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习及其应用2007
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>多智能体机器学习--强化学习方法
目 录
译者序
原书前言
第1章监督式学习概述
1 1 LS算法
1 2 RLS算法
1 3 LMS算法
1 4随机逼近法
参考文献
第2章单智能体强化学习
2 1简介
2 2 n臂赌博机问题
2 3学习结构
2 4值函数
2 5最优值函数
2 5.1网格示例
2 6 MDP
2 7学习值函数
2 8策略迭代
2 9 时间差分学习
2 10状态一行为函数的时间差分学习
2 11 Q学习
2 12资格迹
参考文献
第3章双人矩阵博弈学习
3 1矩阵博弈
3 2双人矩阵博弈中的纳什均衡
3 3双人零和矩阵博弈中的线性规划
3 4学习算法
3 5梯度上升算法
3 6 WoLF - IGA算法
3 7 PHC算法
3 8 WoLF - PHC算法
3 9矩阵博弈中的分散式学习
3 10学习自动机
3 11线性回报一无为算法
3 12线性回报一惩罚算法
3 13滞后锚算法
3 14 LR．滞后锚算法
3 14.1仿真
参考文献
第4章多人随机博弈学习
4 1简介
4 2多人随机博弈
4 3极大极小Q学习算法
4 3.1 2 x2网格博弈
4 4纳什Q学习算法
4 4.1学习过程
4 5单纯形算法
4 6 Lemke - Howson算法
4 7纳什Q学习算法实现
4 8朋友或敌人Q学习算法
4 9无限梯度上升算法
4 10 PHC算法
4 11 WoLF - PHC算法
4 12 网格世界中的疆土防御问题
4 12.1仿真和结果
4 13 LR．滞后锚算法在随机博弈中的扩展
4 14 EMA Q学习算法
4 15 EMA Q学习与其他方法的仿真与结果比较
4 15.1矩阵博弈
4 15 2随机博弈
参考文献
第5章微分博弈
5 1简介
5 2模糊系统简述
5 2.1模糊集和模糊规则
5 2 2模糊推理机
5 2 3模糊化与去模糊化
5 2 4模糊系统及其示例
5 3模糊Q学习
5 4 FACL
5 5疯狂司机微分博弈
5 6模糊控制器结构
5.7 Q(A)学习模糊推理系统
5 8疯狂司机博弈的仿真结果
5 9双车追捕者一逃跑者博弈中的学习算法
5 10双车博弈仿真
5 11 疆土防御微分博弈
5 12疆土防御微分博弈中的形成回报
5 13仿真结果
5 13.1 -个防御者对一个人侵者
5 13 2两个防御者对一个人侵者
参考文献
第6章群智能与性格特征的进化
6 1简介
6 2群智能的进化
6 3环境表征
6 4群机器人的性格特征
6 5性格特征的进化
6 6仿真结构框架
6 7零和博弈示例
6 7.1收敛性
6 7 2仿真结果
6 8后续仿真实现
6 9机器人走出房间
6 10机器人跟踪目标
6 11小结
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>多智能体机器学习--强化学习方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习经典实例
第1章　监督学习　　1
1.1　简介　　1
1.2　数据预处理技术　　2
1.2.1　准备工作　　2
1.2.2　详细步骤　　2
1.3　标记编码方法　　4
1.4　创建线性回归器　　6
1.4.1　准备工作　　6
1.4.2　详细步骤　　7
1.5　计算回归准确性　　9
1.5.1　准备工作　　9
1.5.2　详细步骤　　10
1.6　保存模型数据　　10
1.7　创建岭回归器　　11
1.7.1　准备工作　　11
1.7.2　详细步骤　　12
1.8　创建多项式回归器　　13
1.8.1　准备工作　　13
1.8.2　详细步骤　　14
1.9　估算房屋价格　　15
1.9.1　准备工作　　15
1.9.2　详细步骤　　16
1.10　计算特征的相对重要性　　17
1.11　评估共享单车的需求分布　　19
1.11.1　准备工作　　19
1.11.2　详细步骤　　19
1.11.3　更多内容　　21
第2章　创建分类器　　24
2.1　简介　　24
2.2　建立简单分类器　　25
2.2.1　详细步骤　　25
2.2.2　更多内容　　27
2.3　建立逻辑回归分类器　　27
2.4　建立朴素贝叶斯分类器　　31
2.5　将数据集分割成训练集和测试集　　32
2.6　用交叉验证检验模型准确性　　33
2.6.1　准备工作　　34
2.6.2　详细步骤　　34
2.7　混淆矩阵可视化　　35
2.8　提取性能报告　　37
2.9　根据汽车特征评估质量　　38
2.9.1　准备工作　　38
2.9.2　详细步骤　　38
2.10　生成验证曲线　　40
2.11　生成学习曲线　　43
2.12　估算收入阶层　　45
第3章　预测建模　　48
3.1　简介　　48
3.2　用SVM建立线性分类器　　49
3.2.1　准备工作　　49
3.2.2　详细步骤　　50
3.3　用SVM建立非线性分类器　　53
3.4　解决类型数量不平衡问题　　55
3.5　提取置信度　　58
3.6　寻找最优超参数　　60
3.7　建立事件预测器　　62
3.7.1　准备工作　　62
3.7.2　详细步骤　　62
3.8　估算交通流量　　64
3.8.1　准备工作　　64
3.8.2　详细步骤　　64
第4章　无监督学习——聚类　　67
4.1　简介　　67
4.2　用k-means算法聚类数据　　67
4.3　用矢量量化压缩图片　　70
4.4　建立均值漂移聚类模型　　74
4.5　用凝聚层次聚类进行数据分组　　76
4.6　评价聚类算法的聚类效果　　79
4.7　用DBSCAN算法自动估算集群数量　　82
4.8　探索股票数据的模式　　86
4.9　建立客户细分模型　　88
第5章　构建推荐引擎　　91
5.1　简介　　91
5.2　为数据处理构建函数组合　　92
5.3　构建机器学习流水线　　93
5.3.1　详细步骤　　93
5.3.2　工作原理　　95
5.4　寻找最近邻　　95
5.5　构建一个KNN分类器　　98
5.5.1　详细步骤　　98
5.5.2　工作原理　　102
5.6　构建一个KNN回归器　　102
5.6.1　详细步骤　　102
5.6.2　工作原理　　104
5.7　计算欧氏距离分数　　105
5.8　计算皮尔逊相关系数　　106
5.9　寻找数据集中的相似用户　　108
5.10　生成电影推荐　　109
第6章　分析文本数据　　112
6.1　简介　　112
6.2　用标记解析的方法预处理数据　　113
6.3　提取文本数据的词干　　114
6.3.1　详细步骤　　114
6.3.2　工作原理　　115
6.4　用词形还原的方法还原文本的基本形式　　116
6.5　用分块的方法划分文本　　117
6.6　创建词袋模型　　118
6.6.1　详细步骤　　118
6.6.2　工作原理　　120
6.7　创建文本分类器　　121
6.7.1　详细步骤　　121
6.7.2　工作原理　　123
6.8　识别性别　　124
6.9　分析句子的情感　　125
6.9.1　详细步骤　　126
6.9.2　工作原理　　128
6.10　用主题建模识别文本的模式　　128
6.10.1　详细步骤　　128
6.10.2　工作原理　　131
第7章　语音识别　　132
7.1　简介　　132
7.2　读取和绘制音频数据　　132
7.3　将音频信号转换为频域　　134
7.4　自定义参数生成音频信号　　136
7.5　合成音乐　　138
7.6　提取频域特征　　140
7.7　创建隐马尔科夫模型　　142
7.8　创建一个语音识别器　　143
第8章　解剖时间序列和时序数据　　147
8.1　简介　　147
8.2　将数据转换为时间序列格式　　148
8.3　切分时间序列数据　　150
8.4　操作时间序列数据　　152
8.5　从时间序列数据中提取统计数字　　154
8.6　针对序列数据创建隐马尔科夫模型　　157
8.6.1　准备工作　　158
8.6.2　详细步骤　　158
8.7　针对序列文本数据创建条件随机场　　161
8.7.1　准备工作　　161
8.7.2　详细步骤　　161
8.8　用隐马尔科夫模型分析股票市场数据　　164
第9章　图像内容分析　　166
9.1　简介　　166
9.2　用OpenCV-Pyhon操作图像　　167
9.3　检测边　　170
9.4　直方图均衡化　　174
9.5　检测棱角　　176
9.6　检测SIFT特征点　　178
9.7　创建Star特征检测器　　180
9.8　利用视觉码本和向量量化创建特征　　182
9.9　用极端随机森林训练图像分类器　　185
9.10　创建一个对象识别器　　187
第10章　人脸识别　　189
10.1　简介　　189
10.2　从网络摄像头采集和处理视频信息　　189
10.3　用Haar级联创建一个人脸识别器　　191
10.4　创建一个眼睛和鼻子检测器　　193
10.5　做主成分分析　　196
10.6　做核主成分分析　　197
10.7　做盲源分离　　201
10.8　用局部二值模式直方图创建一个人脸识别器　　205
第11章　深度神经网络　　210
11.1　简介　　210
11.2　创建一个感知器　　211
11.3　创建一个单层神经网络　　213
11.4　创建一个深度神经网络　　216
11.5　创建一个向量量化器　　219
11.6　为序列数据分析创建一个递归神经网络　　221
11.7　在光学字符识别数据库中将字符可视化　　225
11.8　用神经网络创建一个光学字符识别器　　226
第12章　可视化数据　　230
12.1　简介　　230
12.2　画3D散点图　　230
12.3　画气泡图　　232
12.4　画动态气泡图　　233
12.5　画饼图　　235
12.6　画日期格式的时间序列数据　　237
12.7　画直方图　　239
12.8　可视化热力图　　241
12.9　动态信号的可视化模拟　　242

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习经典实例
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Web安全之机器学习入门
对本书的赞誉
序一
序二
序三
前言
第1章　通向智能安全的旅程 1
1.1　人工智能、机器学习与深度学习 1
1.2　人工智能的发展 2
1.3　国内外网络安全形势 3
1.4　人工智能在安全领域的应用 5
1.5　算法和数据的辩证关系 9
1.6　本章小结 9
参考资源 10
第2章　打造机器学习工具箱 11
2.1　Python在机器学习领域的优势 11
2.1.1　NumPy 11
2.1.2　SciPy 15
2.1.3　NLTK 16
2.1.4　Scikit-Learn 17
2.2　TensorFlow简介与环境搭建 18
2.3　本章小结 19
参考资源 20
第3章　机器学习概述 21
3.1　机器学习基本概念 21
3.2　数据集 22
3.2.1　KDD 99数据 22
3.2.2　HTTP DATASET CSIC 2010 26
3.2.3　SEA数据集 26
3.2.4　ADFA-LD数据集 27
3.2.5　Alexa域名数据 29
3.2.6　Scikit-Learn数据集 29
3.2.7　MNIST数据集 30
3.2.8　Movie Review Data 31
3.2.9　SpamBase数据集 32
3.2.10　Enron数据集 33
3.3　特征提取 35
3.3.1　数字型特征提取 35
3.3.2　文本型特征提取 36
3.3.3　数据读取 37
3.4　效果验证 38
3.5　本章小结 40
参考资源 40
第4章　Web安全基础 41
4.1　XSS攻击概述 41
4.1.1　XSS的分类 43
4.1.2　XSS特殊攻击方式 48
4.1.3　XSS平台简介 50
4.1.4　近年典型XSS攻击事件分析 51
4.2　SQL注入概述 53
4.2.1　常见SQL注入攻击 54
4.2.2　常见SQL注入攻击载荷 55
4.2.3　SQL常见工具 56
4.2.4　近年典型SQL注入事件分析 60
4.3　WebShell概述 63
4.3.1　WebShell功能 64
4.3.2　常见WebShell 64
4.4　僵尸网络概述 67
4.4.1　僵尸网络的危害 68
4.4.2　近年典型僵尸网络攻击事件分析 69
4.5　本章小结 72
参考资源 72
第5章　K近邻算法 74
5.1　K近邻算法概述 74
5.2　示例：hello world！K近邻 75
5.3　示例：使用K近邻算法检测异常操作（一） 76
5.4　示例：使用K近邻算法检测异常操作（二） 80
5.5　示例：使用K近邻算法检测Rootkit 81
5.6　示例：使用K近邻算法检测WebShell 83
5.7　本章小结 85
参考资源 86
第6章　决策树与随机森林算法 87
6.1　决策树算法概述 87
6.2　示例：hello world！决策树 88
6.3　示例：使用决策树算法检测POP3暴力破解 89
6.4　示例：使用决策树算法检测FTP暴力破解 91
6.5　随机森林算法概述 93
6.6　示例：hello world！随机森林 93
6.7　示例：使用随机森林算法检测FTP暴力破解 95
6.8　本章小结 96
参考资源 96
第7章　朴素贝叶斯算法 97
7.1　朴素贝叶斯算法概述 97
7.2　示例：hello world！朴素贝叶斯 98
7.3　示例：检测异常操作 99
7.4　示例：检测WebShell（一） 100
7.5　示例：检测WebShell（二） 102
7.6　示例：检测DGA域名 103
7.7　示例：检测针对Apache的DDoS攻击 104
7.8　示例：识别验证码 107
7.9　本章小结 108
参考资源 108
第8章　逻辑回归算法 109
8.1　逻辑回归算法概述 109
8.2　示例：hello world！逻辑回归 110
8.3　示例：使用逻辑回归算法检测Java溢出攻击 111
8.4　示例：识别验证码 113
8.5　本章小结 114
参考资源 114
第9章　支持向量机算法 115
9.1　支持向量机算法概述 115
9.2　示例：hello world！支持向量机 118
9.3　示例：使用支持向量机算法识别XSS 120
9.4　示例：使用支持向量机算法区分僵尸网络DGA家族 124
9.4.1　数据搜集和数据清洗 124
9.4.2　特征化 125
9.4.3　模型验证 129
9.5　本章小结 130
参考资源 130
第10章　K-Means与DBSCAN算法 131
10.1　K-Means算法概述 131
10.2　示例：hello world！K-Means 132
10.3　示例：使用K-Means算法检测DGA域名 133
10.4　DBSCAN算法概述 135
10.5　示例：hello world！DBSCAN 135
10.6　本章小结 137
参考资源 137
第11章　Apriori与FP-growth算法 138
11.1　Apriori算法概述 138
11.2　示例：hello world！Apriori 140
11.3　示例：使用Apriori算法挖掘XSS相关参数 141
11.4　FP-growth算法概述 143
11.5　示例：hello world！FP-growth 144
11.6　示例：使用FP-growth算法挖掘疑似僵尸主机 145
11.7　本章小结 146
参考资源 146
第12章　隐式马尔可夫算法 147
12.1　隐式马尔可夫算法概述 147
12.2　hello world! 隐式马尔可夫 148
12.3　示例：使用隐式马尔可夫算法识别XSS攻击（一） 150
12.4　示例：使用隐式马尔可夫算法识别XSS攻击（二） 153
12.5　示例：使用隐式马尔可夫算法识别DGA域名 159
12.6　本章小结 162
参考资源 162
第13章　图算法与知识图谱 163
13.1　图算法概述 163
13.2　示例：hello world！有向图 164
13.3　示例：使用有向图识别WebShell 169
13.4　示例：使用有向图识别僵尸网络 173
13.5　知识图谱概述 176
13.6　示例：知识图谱在风控领域的应用 177
13.6.1　检测疑似账号被盗 178
13.6.2　检测疑似撞库攻击 179
13.6.3　检测疑似刷单 181
13.7　示例：知识图谱在威胁情报领域的应用 183
13.7.1　挖掘后门文件潜在联系 184
13.7.2　挖掘域名潜在联系 185
13.8　本章小结 187
参考资源 187
第14章　神经网络算法 188
14.1　神经网络算法概述 188
14.2　示例：hello world！神经网络 190
14.3　示例：使用神经网络算法识别验证码 190
14.4　示例：使用神经网络算法检测Java溢出攻击 191
14.5　本章小结 193
参考资源 194
第15章　多层感知机与DNN算法 195
15.1　神经网络与深度学习 195
15.2　TensorFlow编程模型 196
15.2.1　操作 197
15.2.2　张量 197
15.2.3　变量 198
15.2.4　会话 198
15.3　TensorFlow的运行模式 198
15.4　示例：在TensorFlow下识别验证码（一） 199
15.5　示例：在TensorFlow下识别验证码（二） 202
15.6　示例：在TensorFlow下识别验证码（三） 205
15.7　示例：在TensorFlow下识别垃圾邮件（一） 207
15.8　示例：在TensorFlow下识别垃圾邮件（二） 209
15.9　本章小结 210
参考资源 210
第16章　循环神经网络算法 212
16.1　循环神经网络算法概述 212
16.2　示例：识别验证码 213
16.3　示例：识别恶意评论 216
16.4　示例：生成城市名称 220
16.5　示例：识别WebShell 222
16.6　示例：生成常用密码 225
16.7　示例：识别异常操作 227
16.8　本章小结 230
参考资源 230
第17章　卷积神经网络算法 231
17.1　卷积神经网络算法概述 231
17.2　示例：hello world！卷积神经网络 234
17.3　示例：识别恶意评论 235
17.4　示例：识别垃圾邮件 237
17.5　本章小结 240
参考资源 242
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Web安全之机器学习入门
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据挖掘与机器学习
1 概述
大数据大事年表
为何这个主题现在很重要
大数据是否只是一时的狂热？
在何处应用大数据会产生重大影响？
21　第Ⅰ部分 计算环境
23　第1章 硬件
1．1　存储器（磁盘）
1．2　中央处理器
1．3　内存
1．4　网络
31　第2章 分布式系统
2．1　数据库计算
2．2　文件系统计算
2．3　考虑因素
37　第3章 分析工具
3．1　Weka
3．2　Java和JVM语音
3．3　R语言
3．4　Python
3．5　SAS
47　第Ⅱ部分 将数据转化为商业价值
49　第4章 预测建模
4．1　一个建模方法
4．2　sEMMA
4．3　二元分类法
4．4　多层分类法
4．5　区间预测
4．6　预测模型评估
63　第5章 一般预测建模技术
5．1　RFM
5．2　回归
5．3　广义线性模型
5．4　神经网络
5．5　决策树和回归树
5．6　支持向量机
5．7　贝叶斯网络分类方法
5．8　组合方法
117　第6章 细分
6．1　聚类分析
6．2　距离测度（指标）
6．3　聚类评估
6．4　聚类数量
6．5　K-means算法
6．6　分层聚类法
6．7　群特征刻画
129　第7章 增量响应建模
7．1　建立响应模型
7．2　评估增量响应
137　第8章 时间序列数据挖掘
8．1　降维
8．2　探查模式
8．3　时间序列数据挖掘的应用：Nike+Fuelband智能手环
149　第9章 推荐系统
9．1　何为推荐系统？
9．2　应用于何处？
9．3　如何起作用？
9．4　推荐质量评估
9．5　推荐系统的应用：SAS 图书馆
161　第10章 文本分析
10．1　信息检索
10．2　内容分类
10．3　文本挖掘
10．4　文本分析应用：让我们来玩《危险边缘》（Jeopardy！）
177　第Ⅲ部分 将其全都结合起来的成功案例
179　第11章 基于某大型美国金融服务公司的案例研究
11．1　传统市场营销活动流程
11．2　高效的营销解决方案
11．3　变革的价值主张
187　第12章 主要卫生保健提供者的案例研究
12．1　CAHPS
12．2　HEDIS
12．3　HOS
12．4　IRE
197　第13章 技术制造商案例研究
13．1　发现设备缺陷
13．2　如何降低成本
201　第14章 在线品牌管理的案例研究
205　第15章 移动应用推荐的案例研究
209　第16章 高科技产品制造商的案例研究
16．1　处理缺失数据
16．2　超越生产的应用
213　第17章 展望未来
17．1　重复性研究
17．2　隐私与公共数据集
17．3　物联网
17．4　未来的软件开发
17．5　未来算法开发
17．6　总结
221　关于作者
223　附录
225　参考文献
231　译者后记
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据挖掘与机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然计算、机器学习与图像理解前沿
第1章  进化计算  1.1  从人工智能到计算智能  1.2  从进化论到进化计算    1.2.1  现代进化论    1.2.2  生物进化与优化  1.3  进化计算基础知识    1.3.1  进化计算的主要分支    1.3.2  进化计算的数学基础    1.3.3  进化算法的收敛理论    1.3.4  进化计算的应用  1.4  协同进化计算    1.4.1  协同进化的生物学基础    1.4.2  协同进化的动力学描述    1.4.3  协同进化算法的发展现状  1.5  非达尔文进化理论与密母计算    1.5.1  非达尔文进化的主要理论    1.5.2  密母计算的研究进展  参考文献第2章  人工免疫系统  2.1  从免疫系统到人工免疫系统  2.2  人工免疫系统的研究领域    2.2.1  人工免疫系统模型的研究    2.2.2  人工免疫系统算法的研究    2.2.3  人工免疫系统方法的应用研究  2.3  人工免疫系统与其它方法的比较    2.3.1  人工免疫系统与进化计算    2.3.2  人工免疫系统与人工神经网络    2.3.3  人工免疫系统与一般的确定性优化算法  2.4  免疫优化计算研究的新进展    2.4.1  免疫优化算法研究的主要进展    2.4.2  免疫优化计算理论分析的主要进展  2.5  问题与展望  参考文献第3章  量子计算智能  3.1  量子计算原理    3.1.1  状态的叠加    3.1.2  状态的相干    3.1.3  状态的纠缠    3.1.4  量子并行性  3.2  量子计算智能的几种模型    3.2.1  量子人工神经网络    3.2.2  基于量子染色体的进化算法    3.2.3  基于量子特性的优化算法    3.2.4  量子聚类算法    3.2.5  量子模式识别算法    3.2.6  量子小波与小波包算法    3.2.7  量子退火算法    3.2.8  其它  3.3  量子进化算法    3.3.1  量子进化算法的提出    3.3.2  量子进化操作    3.3.3  量子进化算法的结构框架  3.4  问题与展望  参考文献第4章  多智能体系统  4.1  复杂适应系统    4.1.1  复杂适应系统概述    4.1.2  复杂适应系统的适应性与生物进化过程    4.1.3  生物进化过程的数学模型  4.2  多智能体系统    4.2.1  智能体的基本概念    4.2.2  智能体形式化描述    4.2.3  多智能体系统的主要研究内容    4.2.4  面向问题解决的多智能体系统研究现状    4.2.5  多智能体系统与分布式人工智能    4.2.6  多智能体系统与人工生命    4.2.7  多智能体系统与进化计算  参考文献第5章  进化多目标优化  5.1  多目标优化问题的数学描述  5.2  进化多目标优化的主要算法    5.2.1  第一代进化多目标优化算法    5.2.2  第二代进化多目标优化算法  5.3  当代进化多目标优化算法及研究趋势    5.3.1  基于粒子群优化的多目标优化    5.3.2  基于人工免疫系统的多目标优化    5.3.3  基于分布估计算法的多目标优化    5.3.4  新型占优机制研究    5.3.5  高维多目标优化研究  5.4  几种典型进化多目标优化算法的性能比较    5.4.1  实验设置    5.4.2  NSGA-Ⅱ、SPEA2、PESA-Ⅱ和NNIA的性能比较  5.5  总结与展望  参考文献第6章  核机器学习  6.1  Mercer核  6.2  核机器学习的主要方法    6.2.1  支撑矢量机及统计学习理论    6.2.2  支持矢量新颖发现    6.2.3  核匹配追踪学习机    6.2.4  Mercer聚类方法    6.2.5  Mercer核主分量分析    6.2.6  Mercer核Fisher判别分析    6.2.7  SVMs用于排序学习    6.2.8  学习    6.2.9  用于结构化数据识别的核方法  6.3  核机器学习方法的优势与不足    6.3.1  Mercer核技术的优势    6.3.2  Mercer核技术的不足  6.4  推广Mercer核函数的主要研究方向  参考文献第7章  流形学习与谱图学习  7.1  流形学习的基本概念  7.2  流形学习的降维方法分类    7.2.1  构建关系矩阵的方法    7.2.2  基于局部模型的全局坐标对齐方法    7.2.3  十二种流形降维方法的比较  7.3  谱聚类    7.3.1  谱图划分算法    7.3.2  谱聚类算法  参考文献第8章  集成学习  8.1  集成学习系统的结构    8.1.1  集成学习中多样性个体的构造    8.1.2  集成方法的系统结构    8.1.3  集成学习算法中的合并方法  8.2  集成核匹配追踪学习机    8.2.1  集成核匹配追踪学习机的理论分析    8.2.2  集成核匹配追踪学习机的建立  8.3  谱聚类集成    8.3.1  无监督集成问题    8.3.2  具有多样性的个体谱聚类的构造    8.3.3  多个谱聚类结果的合并    8.3.4  谱聚类集成的流程  参考文献第9章  非线性逼近理论  9.1  函数逼近简述  9.2  非线性逼近    9.2.1  基本概念    9.2.2  希尔伯特空间中的非线性逼近    9.2.3  小波逼近  9.3  高度非线性逼近    9.3.1  研究背景及其意义    9.3.2  正交基库中最优基的选择    9.3.3  函数字典中最优原子的选择  9.4  问题与展望    9.4.1  关于数据的多尺度几何表示    9.4.2  关于基的学习问题  参考文献第10章  多尺度几何分析  10.1  概念的产生  10.2  从傅立叶分析到小波分析  10.3  小波图像逼近  10.4  人类视觉模型  10.5  图像的多尺度几何分析    10.5.1  自适应几何逼近    10.5.2  Bandelet变换    10.5.3  脊波及单尺度脊波变换    10.5.4  Curvelet变换    10.5.5  Contourlet变换  10.6  问题与展望  参考文献第11章  多尺度变换域图像感知与识别  11.1  小波变换的三级统计特性及其机理分析  11.2  小波域隐马尔可夫模型    11.2.1  隐马尔可夫模型    11.2.2  小波域隐马尔可夫模型概述  11.3  变换域的十种统计模型    11.3.1  小波域的八种模型    11.3.2  复小波域模型    11.3.3  Contourlet变换域模型  11.4  基于变换域统计模型的图像感知与识别    11.4.1  图像恢复和重建    11.4.2  图像分割    11.4.3  边缘检测  11.5  问题与展望    11.5.1  面向应用的模型设计和算法构造    11.5.2  变换域的拓展    11.5.3  应用领域的推广  参考文献第12章  图像的高维奇异性检测、学习与理解  12.1  图像识别与理解中存在的主要问题    12.1.1  高维奇异性特征提取问题    12.1.2  多元特征选择问题    12.1.3  特征学习中的“维数灾难”问题    12.1.4  相对小样本问题    12.1.5  计算复杂度问题    12.1.6  特征提取与相似性测度定义和学习问题    12.1.7  无监督和半监督学习问题  12.2  解决高维数据奇异性检测、学习与理解的关键技术    12.2.1  高维数据奇异性检测、学习与理解概述    12.2.2  多尺度几何分析与高维奇异性稀疏逼近及方向信息检测    12.2.3  非线性映射技术    12.2.4  假设空间容量控制    12.2.5  无监督和半监督学习  参考文献第13章  图像去噪的阈值方法  13.1  基本概念    13.1.1  空间滤波    13.1.2  小波去噪    13.1.3  噪声估计  13.2  阈值函数  13.3  阈值规则    13.3.1  塔形分解中的尺度内相关法则    13.3.2  小波分解中的尺度内相关法则    13.3.3  尺度间相关法则    13.3.4  高维数据处理法则  13.4  阈值方案    13.4.1  全局阈值    13.4.2  SURE规则    13.4.3  假设检验    13.4.4  Bayes阈值  13.5  问题与展望    13.5.1  图像的恢复和重构    13.5.2  系数独立性假设    13.5.3  系数建模    13.5.4  变换域的拓展  参考文献第14章  sAR图像理解与解译  14.1  SAR图像自动理解与解译的系统组成  14.2  相干斑抑制    14.2.1  空域滤波技术    14.2.2  频域滤波技术  14.3  SAR图像分割    14.3.1  阈值分割方法    14.3.2  基于像素特征的分割方法    14.3.3  统计分割方法  14.4  图像融合    14.4.1  SAR图像和TM图像的融合    14.4.2  SAR图像不同波段和不同极化图像的融合    14.4.3  极化SAR图像和超光谱图像的融合  14.5  特征提取    14.5.1  边缘特征提取    14.5.2  纹理特征提取    14.5.3  形状特征提取    14.5.4  方向特征提取  14.6  识别与分类    14.6.1  最近邻和k近邻    14.6.2  决策树    14.6.3  贝叶斯分类器    14.6.4  神经网络    14.6.5  支撑矢量机    14.6.6  Boosting和Bagging  14.7  SAR图像特殊目标检测    14.7.1  舰船检测    14.7.2  路网检测    14.7.3  其它目标检测  14.8  问题与展望  参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然计算、机器学习与图像理解前沿
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践应用
第1部分 背景知识
第1章 机器学习概述 3
1.1 背景 3
1.2 发展现状 6
1.2.1 数据现状 6
1.2.2 机器学习算法现状 8
1.3 机器学习基本概念 12
1.3.1 机器学习流程 12
1.3.2 数据源结构 14
1.3.3 算法分类 16
1.3.4 过拟合问题 18
1.3.5 结果评估 20
1.4 本章小结 22
第2部分 算法流程
第2章 场景解析 25
2.1 数据探查 25
2.2 场景抽象 27
2.3 算法选择 29
2.4 本章小结 31
第3章 数据预处理 32
3.1 采样 32
3.1.1 随机采样 32
3.1.2 系统采样 34
3.1.3 分层采样 35
3.2 归一化 36
3.3 去除噪声 39
3.4 数据过滤 42
3.5 本章小结 43
第4章 特征工程 44
4.1 特征抽象 44
4.2 特征重要性评估 49
4.3 特征衍生 53
4.4 特征降维 57
4.4.1 特征降维的基本概念 57
4.4.2 主成分分析 59
4.5 本章小结 62
第5章 机器学习算法——常规算法 63
5.1 分类算法 63
5.1.1 K近邻 63
5.1.2 朴素贝叶斯 68
5.1.3 逻辑回归 74
5.1.4 支持向量机 81
5.1.5 随机森林 87
5.2 聚类算法 94
5.2.1 K-means 97
5.2.2 DBSCAN 103
5.3 回归算法 109
5.4 文本分析算法 112
5.4.1 分词算法——Hmm 112
5.4.2 TF-IDF 118
5.4.3 LDA 122
5.5 推荐类算法 127
5.6 关系图算法 133
5.6.1 标签传播 134
5.6.2 Dijkstra最短路径 138
5.7 本章小结 145
第6章 机器学习算法——深度学习 146
6.1 深度学习概述 146
6.1.1 深度学习的发展 147
6.1.2 深度学习算法与传统
算法的比较 148
6.2 深度学习的常见结构 152
6.2.1 深度神经网络 152
6.2.2 卷积神经网络 153
6.2.3 循环神经网络 156
6.3 本章小结 157
第3部分 工具介绍
第7章 常见机器学习工具介绍 161
7.1 概述 161
7.2 单机版机器学习工具 163
7.2.1 SPSS 163
7.2.2 R语言 167
7.2.3 工具对比 172
7.3 开源分布式机器学习工具 172
7.3.1 Spark MLib 172
7.3.2 TensorFlow 179
7.4 企业级云机器学习工具 190
7.4.1 亚马逊AWS ML 191
7.4.2 阿里云机器学习PAI 196
7.5 本章小结 205
第4部分 实战应用
第8章 业务解决方案 209
8.1 心脏病预测 209
8.1.1 场景解析 209
8.1.2 实验搭建 211
8.1.3 小结 216
8.2 商品推荐系统 216
8.2.1 场景解析 217
8.2.2 实验搭建 218
8.2.3 小结 220
8.3 金融风控案例 220
8.3.1 场景解析 221
8.3.2 实验搭建 222
8.3.3 小结 225
8.4 新闻文本分析 225
8.4.1 场景解析 225
8.4.2 实验搭建 226
8.4.3 小结 230
8.5 农业贷款发放预测 230
8.5.1 场景解析 230
8.5.2 实验搭建 232
8.5.3 小结 236
8.6 雾霾天气成因分析 236
8.6.1 场景解析 237
8.6.2 实验搭建 238
8.6.3 小结 243
8.7 图片识别 243
8.7.1 场景解析 243
8.7.2 实验搭建 245
8.7.3 小结 253
8.8 本章小结 253
第5部分 知识图谱
第9章 知识图谱 257
9.1 未来数据采集 257
9.2 知识图谱的概述 259
9.3 知识图谱开源
工具 261
9.4 本章小结 264
参考文献 265
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>构建实时机器学习系统
前　言
第1部分　实时机器学习方法论
第1章　实时机器学习综述 2
1.1　什么是机器学习 2
1.2　机器学习发展的前世今生 3
1.2.1　历史上机器学习无法调和的难题 3
1.2.2　现代机器学习的新融合 4
1.3　机器学习领域分类 5
1.4　实时是个“万灵丹” 6
1.5　实时机器学习的分类 7
1.5.1　硬实时机器学习 7
1.5.2　软实时机器学习 7
1.5.3　批实时机器学习 8
1.6　实时应用对机器学习的要求 8
1.7　案例：Netflix在机器学习竞赛中学到的经验 9
1.7.1　Netflix 用户信息被逆向工程 9
1.7.2　Netflix 最终胜出者模型无法在生产环境中使用 9
1.8　实时机器学习模型的生存期 10
第2章　实时监督式机器学习 12
2.1　什么是监督式机器学习 12
2.1.1　“江湖门派”对预测模型的
不同看法 13
2.1.2　工业界的学术门派 14
2.1.3　实时机器学习实战的思路 15
2.2　怎样衡量监督式机器学习模型 16
2.2.1　统计量的优秀 16
2.2.2　应用业绩的优秀 20
2.3　实时线性分类器介绍 20
2.3.1　广义线性模型的定义 20
2.3.2　训练线性模型 21
2.3.3　冷启动问题 22
第3章　数据分析工具 Pandas 23
3.1　颠覆 R 的 Pandas 23
3.2　Pandas 的安装 24
3.3　利用 Pandas 分析实时股票报价数据 24
3.3.1　外部数据导入 25
3.3.2　数据分析基本操作 25
3.3.3　可视化操作 26
3.3.4　秒级收盘价变化率初探 28
3.4　数据分析的三个要点 30
3.4.1　不断验证假设 30
3.4.2　全面可视化，全面监控化 30
第4章　机器学习工具 Scikit-learn 31
4.1　如何站在风口上？向Scikit-learn 学习 31
4.1.1　传统的线下统计软件 R 31
4.1.2　底层软件黑盒子 Weka 32
4.1.3　跨界产品 Scikit-learn 33
4.1.4　Scikit-learn的优势 33
4.2　Scikit-learn 的安装 34
4.3　Scikit-learn 的主要模块 35
4.3.1　监督式、非监督式机器学习 35
4.3.2　建模函数fit和predict 36
4.3.3　数据预处理 38
4.3.4　自动化建模预测 Pipeline 39
4.4　利用 Scikit-learn 进行股票价格波动预测 40
4.4.1　数据导入和预处理 41
4.4.2　编写专有时间序列数据预处理模块 41
4.4.3　利用 Pipeline 进行建模 43
4.4.4　评价建模效果 43
4.4.5　引入成交量和高维交叉项进行建模 44
4.4.6　本书没有告诉你的 45
第2部分　实时机器学习架构
第5章　实时机器学习架构设计 48
5.1　设计实时机器学习架构的
四个要点 48
5.2　Lambda 架构和主要成员 49
5.2.1　实时响应层 49
5.2.2　快速处理层 50
5.2.3　批处理层 50
5.3　常用的实时机器学习架构 50
5.3.1　瀑布流架构 50
5.3.2　并行响应架构 51
5.3.3　实时更新模型混合架构 52
5.4　小结 53
第6章　集群部署工具 Docker 55
6.1　Docker 的前世今生 55
6.2　容器虚拟机的基本组成部分 56
6.3　Docker 引擎命令行工具 57
6.3.1　Docker 引擎的安装 57
6.3.2　Docker 引擎命令行的基本操作 58
6.4　通过 Dockerfile 配置容器虚拟机 61
6.4.1　利用 Dockerfile 配置基本容器虚拟机 62
6.4.2　利用 Dockerfile 进行虚拟机和宿主机之间的文件传输 62
6.5　服务器集群配置工具Docker Compose 64
6.5.1　Docker Compose 的安装 64
6.5.2　Docker Compose 的基本操作 64
6.5.3　利用 Docker Compose 创建网页计数器集群 65
6.6　远端服务器配置工具Docker Machine 68
6.6.1　Docker Machine 的安装 68
6.6.2　安装 Oracle VirtualBox 69
6.6.3　创建和管理 VirtualBox中的虚拟机 69
6.6.4　在 Docker Machine 和 VirtualBox的环境中运行集群 70
6.6.5　利用 Docker Machine 在 Digital Ocean 上配置运行集群 71
6.7　其他有潜力的 Docker 工具 73
第7章　实时消息队列和RabbitMQ 74
7.1　实时消息队列 74
7.2　AMQP 和 RabbitMQ 简介 76
7.3　RabbitMQ的主要构成部分 76
7.4　常用交换中心模式 78
7.4.1　直连结构 78
7.4.2　扇形结构 78
7.4.3　话题结构 79
7.4.4　报头结构 79
7.5　消息传导设计模式 79
7.5.1　任务队列 80
7.5.2　Pub/Sub 发布/监听 80
7.5.3　远程命令 81
7.6　利用 Docker 快速部署RabbitMQ 82
7.7　利用 RabbitMQ 开发队列服务 85
7.7.1　准备案例材料 86
7.7.2　实时报价存储服务 86
7.7.3　实时走势预测服务 89
7.7.4　整合运行实验 93
7.7.5　总结和改进 95
第8章　实战数据库综述 98
8.1　SQL 与 NoSQL，主流数据库分类 98
8.1.1　关系型数据库 99
8.1.2　非关系型数据库 NoSQL 99
8.2　数据库的性能 100
8.2.1　耐分割 100
8.2.2　 一致性 101
8.2.3　可用性 101
8.2.4　CAP 定理 101
8.3　SQL和NoSQL对比 102
8.3.1　数据存储、读取方式 102
8.3.2　数据库的扩展方式 103
8.3.3　性能比较 103
8.4　数据库的发展趋势 103
8.4.1　不同数据库之间自动化同步更为方便 103
8.4.2　云数据库的兴起 104
8.4.3　底层和应用层多层化 104
8.5　MySQL 简介 105
8.6　Cassandra简介 105
8.6.1　Cassandra交互方式简介 105
8.6.2　利用Docker安装Cassandra 106
8.6.3　使用Cassandra存储数据 106
第9章　实时数据监控 ELK 集群 107
9.1　Elasticsearch、LogStash和Kibana 的前世今生 107
9.1.1　Elasticsearch 的平凡起家 108
9.1.2　LogStash 卑微的起源 108
9.1.3　Kibana 惊艳登场 109
9.1.4　ELK 协同作战 109
9.2　Elasticsearch 基本架构 109
9.2.1　文档 110
9.2.2　索引和文档类型 111
9.2.3　分片和冗余 112
9.2.4　Elasticsearch 和数据库进行比较 113
9.3　Elasticsearch 快速入门 113
9.3.1　用 Docker 运行 Elasticsearch 容器虚拟机 113
9.3.2　创建存储文档、文档类型和索引 114
9.3.3　搜索文档 117
9.3.4　对偶搜索 120
9.4　Kibana 快速入门 124
9.4.1　利用 Docker 搭建ELK 集群 125
9.4.2　配置索引格式 127
9.4.3　交互式搜索 128
9.4.4　可视化操作 129
9.4.5　实时检测面板 132
第10章　机器学习系统设计模式 134
10.1　 设计模式的前世今生 134
10.1.1　单机设计模式逐渐式微 134
10.1.2　微服务取代设计模式的示例 135
10.1.3　微服务设计模式的兴起 137
10.2　读：高速键值模式 137
10.2.1　问题场景 137
10.2.2　解决方案 138
10.2.3　其他使用场景 139
10.3　读：缓存高速查询模式 139
10.3.1　问题场景 139
10.3.2　解决方案 139
10.3.3　适用场景 141
10.4　更新：异步数据库更新模式 141
10.4.1　问题场景 141
10.4.2　解决方案 141
10.4.3　使用场景案例 142
10.5　更新：请求重定向模式 144
10.5.1　问题场景 144
10.5.2　解决方案 144
10.5.3　更新流程 145
10.5.4　使用场景案例 146
10.6　处理：硬实时并行模式 146
10.6.1　问题场景 146
10.6.2　解决方案 147
10.6.3　使用场景案例 147
10.7　处理：分布式任务队列模式 148
10.7.1　问题场景 148
10.7.2　解决方案 149
10.7.3　Storm 作为分布式任务队列 150
10.7.4　适用场景 151
10.7.5　结构的演进 152
10.8　处理：批实时处理模式 152
10.8.1　问题场景 152
10.8.2　解决方案 152
10.8.3　适用场景 153
第3部分　未来展望
第11章　Serverless 架构 156
11.1　Serverless 架构的前世今生 156
11.2　Serverless 架构对实时
机器学习的影响 157
第12章　深度学习的风口 159
12.1　深度学习的前世今生 159
12.2　深度学习的难点 161
12.3　如何选择深度学习工具 161
12.3.1　与现有编程平台、技能整合的难易程度 162
12.3.2　此平台除做深度学习之外，还能做什么 163
12.3.3　深度学习平台的成熟程度 164
12.4　未来发展方向 165
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>构建实时机器学习系统
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践指南 第2版
推荐序
前言
第一部分　准备篇
第1章	机器学习发展及应用前景 2
1.1	机器学习概述 2
1.1.1	什么是机器学习 3
1.1.2	机器学习的发展 3
1.1.3	机器学习的未来 4
1.2	机器学习应用前景 5
1.2.1	数据分析与挖掘 5
1.2.2	模式识别 6
1.2.3	更广阔的领域 6
1.3	小结 7
第2章	科学计算平台 8
2.1	科学计算软件平台概述 9
2.1.1	常用的科学计算软件 9
2.1.2	本书使用的工程计算平台 10
2.2	计算平台的配置 11
2.2.1	Numpy等Python科学计算包的安装与配置 11
2.2.2	OpenCV 安装与配置 14
2.2.3	mlpy 安装与配置 14
2.2.4	BeautifulSoup安装与配置 15
2.2.5	Neurolab安装与配置 15
2.2.6	R安装与配置 16
2.3	小结 16
第二部分　基础篇
第3章	计算平台应用实例 18
3.1	Python计算平台简介及应用实例 18
3.1.1	Python语言基础 18
3.1.2	Numpy库 29
3.1.3	pylab、matplotlib绘图 36
3.1.4	图像基础 38
3.1.5	图像融合与图像镜像 46
3.1.6	图像灰度化与图像加噪 48
3.1.7	声音基础 51
3.1.8	声音音量调节 53
3.1.9	图像信息隐藏 58
3.1.10	声音信息隐藏 62
3.2	R语言基础 68
3.2.1	基本操作 69
3.2.2	向量 71
3.2.3	对象集属性 77
3.2.4	因子和有序因子 78
3.2.5	循环语句 79
3.2.6	条件语句 79
3.3	R语言科学计算 80
3.3.1	分类（组）统计 80
3.3.2	数组与矩阵基础 81
3.3.3	数组运算 84
3.3.4	矩阵运算 85
3.4	R语言计算实例 93
3.4.1	学生数据集读写 93
3.4.2	最小二乘法拟合 94
3.4.3	交叉因子频率分析 96
3.4.4	向量模长计算 97
3.4.5	欧氏距离计算 98
3.5	小结 99
思考题 99
第4章	生产环境基础 100
4.1	Windows Server 2008基础 100
4.1.1	Windows Server 2008 R2概述 101
4.1.2	Windows PowerShell 102
4.2	Linux基础 103
4.2.1	Linux命令 104
4.2.2	Shell基础 114
4.3	Vim编辑器 122
4.3.1	Vim编辑器概述 122
4.3.2	Vim常用命令 123
4.4	虚拟化平台 124
4.4.1	Citrix Xenserver概述 125
4.4.2	Citrix Xenserver部署 126
4.4.3	基于XenCenter的虚拟服务器管理 126
4.5	Linux环境下的NumPy安装 135
4.6	Linux环境下的R运行环境 136
4.7	PyPy编译器 136
4.7.1	PyPy概述 136
4.7.2	PyPy安装与配置 137
4.7.3	PyPy性能 137
4.7.4	PyPy实践之Lempel-Ziv压缩 138
4.8	小结 145
思考题 146
第三部分　统计分析实战篇
第5章	统计分析基础 148
5.1	数据分析概述 148
5.2	数学基础 149
5.3	回归分析 154
5.3.1	单变量线性回归 154
5.3.2	多元线性回归 156
5.3.3	非线性回归 157
5.4	数据分析基础 159
5.4.1	区间频率分布 159
5.4.2	数据直方图 161
5.4.3	数据散点图 162
5.4.4	五分位数 164
5.4.5	累积分布函数 165
5.4.6	核密度估计 166
5.5	数据分布分析 167
5.6	小结 169
思考题 170
第6章	描述性分析案例 171
6.1	数据图形化案例解析 171
6.1.1	点图 171
6.1.2	饼图和条形图 172
6.1.3	茎叶图和箱线图 173
6.2	数据分布趋势案例解析 175
6.2.1	平均值 175
6.2.2	加权平均值 175
6.2.3	数据排序 176
6.2.4	中位数 177
6.2.5	极差、半极差 177
6.2.6	方差 178
6.2.7	标准差 178
6.2.8	变异系数、样本平方和 178
6.2.9	偏度系数、峰度系数 179
6.3	正态分布案例解析 180
6.3.1	正态分布函数 180
6.3.2	峰度系数分析 181
6.3.3	累积分布概率 181
6.3.4	概率密度函数 182
6.3.5	分位点 183
6.3.6	频率直方图 185
6.3.7	核概率密度与正态概率分布图 185
6.3.8	正态检验与分布拟合 186
6.3.9	其他分布及其拟合 188
6.4	多变量分析 189
6.4.1	多变量数据分析 189
6.4.2	多元数据相关性分析 197
6.5	小结 201
思考题 201
第7章	假设检验与回归模型案例 202
7.1	假设检验 202
7.1.1	二项分布假设检验 202
7.1.2	数据分布检验 204
7.1.3	正态总体均值检验 205
7.1.4	列联表 206
7.1.5	符号检测 207
7.1.6	秩相关检验 210
7.1.7	Kendall相关检验 213
7.2	回归模型 214
7.2.1	回归预测与显著性检验 214
7.2.2	回归诊断 216
7.2.3	回归优化 217
7.2.4	主成分回归 219
7.2.5	广义线性模型 221
7.3	小结 226
思考题 226
第四部分　机器学习实战篇
第8章	机器学习算法 230
8.1	神经网络 230
8.1.1	Rosenblatt感知器 232
8.1.2	梯度下降 245
8.1.3	反向传播与多层感知器 251
8.1.4	Python神经网络库 270
8.2	统计算法 272
8.2.1	平均值 272
8.2.2	方差与标准差 274
8.2.3	贝叶斯算法 276
8.3	欧氏距离 279
8.4	余弦相似度 280
8.5	SVM 281
8.5.1	数学原理 281
8.5.2	SMO算法 283
8.5.3	算法应用 283
8.6	回归算法 287
8.6.1	线性代数基础 288
8.6.2	最小二乘法原理 289
8.6.3	线性回归 290
8.6.4	多元非线性回归 292
8.6.5	岭回归方法 294
8.6.6	伪逆方法 295
8.7	PCA降维 296
8.8	关联规则 297
8.8.1	关联规则概述 297
8.8.2	频繁项集算法 298
8.8.3	关联规则生成 301
8.8.4	实例分析 302
8.9	自动分类 306
8.9.1	聚类算法 306
8.9.2	决策树 313
8.9.3	AdaBoost 316
8.9.4	竞争型神经网络 317
8.9.5	Hamming神经网络 323
8.10	小结 325
思考题 325
第9章	数据拟合案例 327
9.1	数据拟合 327
9.1.1	图像分析法 327
9.1.2	神经网络拟合法 338
9.2	线性滤波 352
9.2.1	WAV声音文件 352
9.2.2	线性滤波算法过程 352
9.2.3	滤波Python实现 353
9.3	数据或曲线平滑 358
9.3.1	平滑概述 358
9.3.2	移动平均 359
9.3.3	递归线性过滤 362
9.3.4	指数平滑 364
9.4	小结 368
思考题 368
第10章	图像算法案例 370
10.1	图像边缘算法 370
10.1.1	数字图像基础 370
10.1.2	算法描述 371
10.2	图像匹配 372
10.2.1	差分矩阵求和 373
10.2.2	差分矩阵均值 375
10.2.3	欧氏距离匹配 376
10.3	图像分类 382
10.3.1	余弦相似度 382
10.3.2	PCA图像特征提取算法 388
10.3.3	基于神经网络的图像分类 389
10.3.4	基于SVM的图像分类 394
10.4	高斯噪声生成 397
10.5	二值化 401
10.5.1	threshold 401
10.5.2	adaptiveThreshold 402
10.6	插值与缩放 404
10.7	仿射 405
10.7.1	仿射原理 405
10.7.2	仿射变换实例 405
10.8	透视投影与透视变换 406
10.8.1	透视投影原理 406
10.8.2	透视投影实例 407
10.9	灰度变换与图像增强 409
10.9.1	灰度变换概述 409
10.9.2	对数变换 409
10.9.3	分段线性变换 410
10.9.4	指数变换 411
10.9.5	直方图均衡化 412
10.10　图像滤波与除噪 415
10.10.1　均一化块滤波 415
10.10.2　邻域平均法 420
10.10.3　中值滤波 423
10.10.4　高斯滤波 427
10.10.5　双边滤波 429
10.10.6　卷积滤波 431
10.10.7　边缘检测 433
10.11　小结 435
思考题 435
第11章	机器视觉案例 437
11.1	人脸辨识 437
11.1.1	人脸定位 437
11.1.2	人脸辨识 439
11.2	手写数字识别 446
11.2.1	手写数字识别算法 446
11.2.2	算法的Python实现 447
11.3	运动侦测 449
11.3.1	视频采集 450
11.3.2	差分算法 452
11.3.3	光流法 456
11.4	形状检测 458
11.4.1	KNN算法概述 458
11.4.2	形状特征提取 459
11.4.3	形状分类 459
11.5	小结 462
思考题 462
第12章	文本分类案例 463
12.1	文本分类概述 463
12.2	余弦相似度分类 464
12.2.1	中文分词 465
12.2.2	停用词清理 467
12.2.3	算法实战 468
12.3	朴素贝叶斯分类 473
12.3.1	算法描述 473
12.3.2	先验概率计算 474
12.3.3	最大后验概率 474
12.3.4	算法实现 474
12.4	自然语言处理 480
12.4.1	NLTK简介 480
12.4.2	NLTK与jieba的配置 481
12.4.3	中文分词并标注词性 483
12.4.4	词特征指标分析 484
12.4.5	Web文档分析 499
12.4.6	Web文档的朴素贝叶斯分类 503
12.4.7	语法结构分析 515
12.4.8	Web文档聚类 518
12.5	小结 526
思考题 526
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践指南 第2版
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与R语言实战
目录
译者序
前言
作者简介
审校者简介
第1章基于R实践机器学习
1.1简介
1.2下载和安装R
1.3下载和安装R Studio
1.4包的安装和加载
1.5数据读写
1.6使用R实现数据操作
1.7应用简单统计
1.8数据可视化
1.9获取用于机器学习的数据集
第2章挖掘RMSTitanic数据集
2.1简介
2.2从CSV文件中读取Titanic数据集
2.3根据数据类型进行转换
2.4检测缺失值
2.5插补缺失值
2.6识别和可视化数据
2.7基于决策树预测获救乘客
2.8基于混淆矩阵验证预测结果的准确性
2.9使用ROC曲线评估性能
第3章R和统计
3.1简介
3.2理解R中的数据采样
3.3在R中控制概率分布
3.4在R中进行一元描述统计
3.5在R中进行多元相关分析
3.6进行多元线性回归分析
3.7执行二项分布检验
3.8执行t检验
3.9执行Kolmogorov—Smirnov检验
3.10理解Wilcoxon秩和检验及Wilcoxon符号秩检验
3.11实施皮尔森卡方检验
3.12进行单因素方差分析
3.13进行双因素方差分析
第4章理解回归分析
4.1简介
4.2调用1m函数构建线性回归模型
4.3输出线性模型的特征信息
4.4使用线性回归模型预测未知值
4.5生成模型的诊断图
4.6利用1m函数生成多项式回归模型
4.7调用rlm函数生成稳健线性回归模型
4.8在SLID数据集上研究线性回归案例
4.9基于高斯模型的广义线性回归
4.10基于泊松模型的广义线性回归
4.11基于二项模型的广义线性回归
4.12利用广义加性模型处理数据
4.13可视化广义加性模型
4.14诊断广义加性模型
第5章分类Ⅰ——树、延迟和概率
5.1简介
5.2准备训练和测试数据集
5.3使用递归分割树建立分类模型
5.4递归分割树可视化
5.5评测递归分割树的预测能力
5.6递归分割树剪枝
5.7使用条件推理树建立分类模型
5.8条件推理树可视化
5.9评测条件推理树的预测能力
5，10使用k近邻分类算法
5.11使用逻辑回归分类算法
5.12使用朴素贝叶斯分类算法
第6章分类Ⅱ——神经网络和SVM
6.1简介
6.2使用支持向量机完成数据分类
6_3选择支持向量机的惩罚因子
6.4实现SVM模型的可视化
6.5基于支持向量机训练模型实现类预测
6.6调整支持向量机
6.7利用neuralnet包训练神经网络模型
6.8可视化由neuralnet包得到的神经网络模型
6.9基于neuralnet包得到的模型实现类标号预测
6.10利用nnet包训练神经网络模型
6.11基于nnet包得到的模型实现类标号预测
第7章模型评估
7.1简介
7.2基于k折交叉验证方法评测模型性能
7.3利用e1071包完成交叉验证
7.4利用caret包完成交叉检验
7.5利用caret包对变量重要程度排序
7.6利用rmlner包对变量重要程度排序
7.7利用caret包找到高度关联的特征
7.8利用caret包选择特征
7.9评测回归模型的性能
7.10利用混淆矩阵评测模型的预测能力
7.11利用ROCR评测模型的预测能力
7.12利用caret包比较ROC曲线
7.13利用caret包比较模型性能差异
第8章集成学习
8.1简介
8.2使用bagging方法对数据分类
8.3基于bagging方法进行交叉验证
8.4使用boosting方法对数据分类
8.5基于boosting方法进行交叉验证
8.6使用gradientboosting方法对数据分类
8.7计算分类器边缘
8.8计算集成分类算法的误差演变
8.9使用随机森林方法对数据分类
8.10估算不同分类器的预测误差
第9章聚类
9.1简介
9.2使用层次聚类处理数据
9.3将树分成簇
9.4使用k均值方法处理数据
9.5绘制二元聚类图
9.6聚类算法比较
9.7从簇中抽取轮廓信息
9.8获得优化的k均值聚类
9.9使用密度聚类方法处理数据
9.10使用基于模型的聚类方法处理数据
9.11相异度矩阵的可视化
9.12使用外部验证评估聚类效果
第10章关联分析和序列挖掘
10.1简介
10.2将数据转换成事务数据
10.3展示事务及关联
10.4使用Apriori规则完成关联挖掘
10.5去掉冗余规则
10.6关联规则的可视化
10.7使用Eclat挖掘频繁项集
10.8生成时态事务数据
10.9使用cSPADE挖掘频繁时序模式
第11章降维
11.1简介
11.2使用FSelector完成特征筛选
11.3使用PCA进行降维
11.4使用scree测试确定主成分数
11.5使用Kaiser方法确定主成分数
11.6使用主成分分析散点图可视化多元变量
11.7使用MDS进行降维
11.8使用SVD进行降维
11.9使用SVD进行图像压缩
11.10使用ISOMAP进行非线性降维
11.11使用局部线性嵌入法进行非线性降维
第12章大数据分析（R和Hadoop）
12.1简介
12.2准备RHadoop环境
12.3安装rmr2
12.4安装rhdfs
12.5在thdfs中操作HDFS
12.6在RHadoop中解决单词计数问题
12.7比较RMapReduce程序和标准R程序的性能差别
12.8测试和调试rmr2程序
12.9安装plymlr
12.10使用plyrmr处理数据
12.11在RHadoop中实施机器学习
12.12在AmazonEMR环境中配置RHadoop机群
附录AR和机器学习的资源
附录BTitanic幸存者的数据集
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与R语言实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>零起点Python机器学习快速入门
第 1 章从阿尔法狗开始说起  1
1.1 阿尔法狗的前世今生 1
1.2 机器学习是什么  2
1.3 机器学习大史记  3
1.4 机器学习经典案例  11
第2 章开发环境  13
2.1 数据分析首选Python  13
2.2 用户运行平台  18
2.3 程序目录结构  19
2.4 Spyder 编辑器界面设置  20
2.5 Python 命令行模式  26
2.6 Notebook 模式 27
2.7 模块库控制面板  29
2.8 使用pip 更新模块库 33
第3 章 Python 入门案例  39
3.1 案例3-1：第一次编程“hello,ziwang” 39
3.2 案例3-2：增强版“hello,zwiang” 42
3.3 案例3-3：列举系统模块库清单 44
3.4	案例 3-4：常用绘图风格 45
3.5	案例 3-5：Pandas常用绘图风格 47
3.6	案例 3-6：常用颜色表 cors  49
3.7	案例源码  50
第4 章 Python 基本语法 58
4.1 数据类型 58
案例4-1：基本运算 59
4.2 字符串 61
案例4-2：字符串入门. 61
案例4-3：字符串常用方法 63
4.3 List 列表 64
案例4-4：列表操作 65
4.4 Tuple 元组 66
案例4-5：元组操作 67
4.5 Dictionary 字典. 68
案例4-6：字典操作 68
4.6 数据类型转换 70
案例4-7：控制语句 71
案例4-8：函数定义 73
4.7 案例源码 75
第5 章 Python 人工智能入门与实践 85
5.1 从忘却开始. 85
5.2 Iris 经典爱丽丝. 89
案例5-1：Iris 爱丽丝 90
案例5-2：爱丽丝进化与文本矢量化. 92
5.3 AI 操作流程 95
5.4 数据切割函数 98
案例5-3：Iris 爱丽丝分解 99
案例5-4：线性回归算法. 103
5.5 案例源码 109
第6 章机器学习经典算法案例（上）  116
6.1 线性回归 116
6.2 逻辑回归算法. 124
案例6-1：逻辑回归算法. 125
6.3 朴素贝叶斯算法 127
案例6-2：贝叶斯算法 129
6.4 KNN 近邻算法 130
案例6-3：KNN 近邻算法 133
6.5 随机森林算法. 135
案例6-4：随机森林算法. 139
6.6 案例源码 140
第7 章机器学习经典算法案例（下）  149
7.1 决策树算法 149
案例7-1：决策树算法 151
7.2 GBDT 迭代决策树算法 153
案例7-2：GBDT 迭代决策树算法 154
7.3 SVM 向量机 156
案例7-3：SVM 向量机算法. 157
7.4 SVM-cross 向量机交叉算法 159
案例7-4：SVM-cross 向量机交叉算法 160
7.5 神经网络算法. 161
案例7-5：MLP 神经网络算法. 165
案例7-6：MLP_reg 神经网络回归算法. 168
7.6 案例源码 170
第8 章机器学习组合算法  183
8.1 CCPP 数据集 183
案例8-1：CCPP 数据集 184
案例8-2：CCPP 数据切割. 186
案例8-3：读取CCPP 数据集 189
8.2 机器学习统一接口函数 192
案例8-4：机器学习统一接口 193
案例8-5：批量调用机器学习算法 201
案例8-6：一体化调用 205
8.3 模型预制与保存 208
案例8-7：储存算法模型. 210
案例8-8：批量储存算法模型 213
案例8-9：批量加载算法模型 215
案例8-10：机器学习组合算法 219
8.4 案例源码 224
附录A Sklearn 常用模块和函数. 242
附录B 极宽量化系统模块图 266
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>零起点Python机器学习快速入门
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>高效机器学习
译者序
作者简介
技术评审简介
致谢
第1章　机器学习1
1.1　关键术语2
1.2　机器学习的步骤4
1.3　机器学习算法6
1.4　流行的机器学习算法9
1.4.1　C4.59
1.4.2　k均值9
1.4.3　支持向量机10
1.4.4　Apriori算法10
1.4.5　估计最大化11
1.4.6　PageRank算法11
1.4.7　AdaBoost12
1.4.8　k近邻算法13
1.4.9　朴素贝叶斯14
1.4.10　分类回归树14
1.5　数据挖掘研究中的挑战性问题14
1.5.1　针对高维数据和高速数据流的扩展15
1.5.2　挖掘序列数据和时间序列数据15
1.5.3　从复杂数据中挖掘复杂知识15
1.5.4　分布式数据挖掘与挖掘多代理数据15
1.5.5　数据挖掘过程的相关问题16
1.5.6　安全性、隐私性和数据完整性16
1.5.7　处理非静态、不平衡和代价敏感的数据16
1.6　总结16
参考文献16
第2章　机器学习与知识发现18
2.1　知识发现20
2.1.1　分类20
2.1.2　聚类20
2.1.3　降维21
2.1.4　协同过滤21
2.2　机器学习：分类算法21
2.2.1　逻辑回归21
2.2.2　随机森林22
2.2.3　隐马尔可夫模型23
2.2.4　多层感知机24
2.3　机器学习：聚类算法26
2.3.1　k均值聚类26
2.3.2　模糊k均值(模糊c均值)26
2.3.3　流k均值算法27
2.4　机器学习：降维28
2.4.1　奇异值分解28
2.4.2　主成分分析29
2.4.3　Lanczos算法31
2.5　机器学习：协同过滤32
2.5.1　基于用户的协同过滤32
2.5.2　基于项目的协同过滤32
2.5.3　权值-λ-正规化的交替最小二乘法33
2.6　机器学习：相似矩阵34
2.6.1　Pearson相关系数34
2.6.2　Spearman等级相关系数34
2.6.3　欧氏距离35
2.6.4　Jaccard相似系数35
2.7　总结35
参考文献36
第3章　支持向量机分类37
3.1　从几何角度看待SVM37
3.2　SVM的主要性能38
3.3　硬间隔SVM41
3.4　软间隔SVM43
3.5　核SVM44
3.6　多分类SVM47
3.7　SVM用于非平衡数据集49
3.8　提升SVM计算需求51
3.9　案例研究：SVM用于手写识别53
3.9.1　预处理54
3.9.2　特征提取54
3.9.3　分层的、三级SVM55
3.9.4　实验结果56
3.9.5　复杂度分析57
参考文献59
第4章　支持向量回归63
4.1　SVR概述63
4.2　SVR：概念、数学模型和图形表示64
4.3　核SVR和不同的损失函数:数学模型和图形表示68
4.4　贝叶斯线性回归69
4.5　案例研究：非对称SVR电源预测72
参考文献75
第5章　隐马尔可夫模型76
5.1　离散的马尔可夫过程76
5.1.1　定义178
5.1.2　定义278
5.1.3　定义378
5.2　HMM简介78
5.2.1　HMM的要点80
5.2.2　HMM的三种基本问题80
5.2.3　HMM基本问题的解决81
5.3　连续观测HMM86
5.3.1　多元高斯混合模型88
5.3.2　示例：工作负载相位识别88
5.3.3　监视和观测89
5.3.4　工作负载和相位89
5.3.5　相位探测的混合模型91
参考文献98
第6章　仿生计算：群体智能100
6.1　应用101
6.1.1　演化硬件101
6.1.2　仿生网络103
6.1.3　数据中心优化105
6.2　仿生计算算法106
6.3　群体智能106
6.3.1　蚁群优化算法107
6.3.2　粒子群优化算法109
6.3.3　人工蜂群算法111
6.4　细菌觅食优化算法113
6.5　人工免疫系统114
6.6　数据中心的分布式管理116
6.6.1　工作负载特征116
6.6.2　热度优化117
6.6.3　负载均衡117
6.6.4　算法模型118
参考文献120
第7章　深度神经网络122
7.1　ANN简介122
7.1.1　早期的ANN结构123
7.1.2　经典的ANN124
7.1.3　ANN训练和反向传播算法127
7.2　DBN概述128
7.3　受限玻尔兹曼机130
7.4　DNN训练算法131
7.5　DNN相关研究133
7.5.1　DNN应用134
7.5.2　利用并行实现加快DNN训练135
7.5.3　类似于DBN的深度网络135
参考文献136
第8章　皮质算法141
8.1　皮质算法入门141
8.1.1　皮质算法的结构141
8.1.2　皮质算法的训练143
8.2　权重更新145
8.3　案例研究：改进的皮质算法在阿拉伯语口语数字化中的应用149
8.3.1　基于熵的权重更新规则149
8.3.2　实验验证150
参考文献153
第9章　深度学习156
9.1　层级时序存储概述156
9.2　层级时序存储的演化157
9.2.1　稀疏分布表征160
9.2.2　算法实现160
9.2.3　空间池160
9.2.4　时间池162
9.3　相关工作163
9.4　脉冲神经网络概述164
9.4.1　Hodgkin-Huxley模型165
9.4.2　integrate-and-fire模型165
9.4.3　leaky integrate-and-fire模型165
9.4.4　Izhikevich模型166
9.4.5　Thorpe’s模型166
9.4.6　SNN的信息编码167
9.4.7　SNN的学习168
9.4.8　SNN的变体与扩展169
9.5　总结170
参考文献170
第10章　多目标优化173
10.1　形式定义174
10.1.1　帕累托优化175
10.1.2　支配关系175
10.1.3　性能度量175
10.2　机器学习：进化算法176
10.2.1　遗传算法177
10.2.2　遗传编程178
10.3　多目标优化：一种进化的方法179
10.3.1　加权和方法180
10.3.2　向量评估遗传算法180
10.3.3　多目标遗传算法180
10.3.4　小生境帕累托遗传算法182
10.3.5　非支配排序遗传算法182
10.3.6　强帕累托进化算法183
10.3.7　强帕累托进化算法Ⅱ185
10.3.8　帕累托档案进化策略186
10.3.9　基于帕累托包络的选择算法187
10.3.10　基于帕累托包络的选择算法Ⅱ188
10.3.11　带精英策略的非支配排序遗传算法188
10.4　示例：多目标优化190
10.5　目标函数192
参考文献193
第11章　机器学习实战示例195
11.1　可行的系统建模196
11.2　实例1：计算节点上的工作负载指纹198
11.2.1　相位测定199
11.2.2　指纹202
11.2.3　预测206
11.3　实例2：动态能量分配206
11.3.1　学习过程：特征选取207
11.3.2　学习过程：最优规划208
11.3.3　学习过程：监控209
11.4　模型训练：过程与评价212
11.5　实例3：入侵检测的系统方法214
11.5.1　建模策略215
11.5.2　入侵检测系统架构217
11.6　关于配置文件和系统的思考220
11.7　传感器数据测量221
11.8　总结222
参考文献223
索引224
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>高效机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow机器学习项目实战
第1章　探索和转换数据 1
1.1　TensorFlow的主要数据结构—
张量 1
1.1.1　张量的属性—阶、形状和
类型 1
1.1.2　创建新的张量 3
1.1.3　动手工作—与TensorFlow
交互 4
1.2　处理计算工作流—TensorFlow
的数据流图 5
1.2.1　建立计算图 5
1.2.2　数据供给 6
1.2.3　变量 6
1.2.4　保存数据流图 6
1.3　运行我们的程序—会话 8
1.4　基本张量方法 8
1.4.1　简单矩阵运算 8
1.4.2　序列 11
1.4.3　张量形状变换 12
1.4.4　数据流结构和结果可视化—
TensorBoard 14
1.5　从磁盘读取信息 18
1.5.1　列表格式—CSV 18
1.5.2　读取图像数据 19
1.5.3　加载和处理图像 20
1.5.4　读取标准TensorFlow格式 21
1.6　小结 21
第2章　聚类 22
2.1　从数据中学习—无监督学习 22
2.2　聚类的概念 22
2.3　k均值 23
2.3.1　k均值的机制 23
2.3.2　算法迭代判据 23
2.3.3　k均值算法拆解 24
2.3.4　k均值的优缺点 25
2.4　k最近邻 25
2.4.1　k最近邻算法的机制 26
2.4.2　k-nn的优点和缺点 26
2.5　有用的库和使用示例 27
2.5.1　matplotlib绘图库 27
2.5.2　scikit-learn数据集模块 28
2.5.3　人工数据集类型 28
2.6　例1—对人工数据集的k均值
聚类 29
2.6.1　数据集描述和加载 29
2.6.2　模型架构 30
2.6.3　损失函数描述和优化循环 31
2.6.4　停止条件 31
2.6.5　结果描述 31
2.6.6　每次迭代中的质心变化 32
2.6.7　完整源代码 32
2.6.8　k均值用于环状数据集 34
2.7　例2—对人工数据集使用最近
邻算法 36
2.7.1　数据集生成 36
2.7.2　模型结构 36
2.7.3　损失函数描述 37
2.7.4　停止条件 37
2.7.5　结果描述 37
2.7.6　完整源代码 37
2.8　小结 39
第3章　线性回归 40
3.1　单变量线性模型方程 40
3.2　选择损失函数 41
3.3　最小化损失函数 42
3.3.1　最小方差的全局最小值 42
3.3.2　迭代方法：梯度下降 42
3.4　示例部分 43
3.4.1　TensorFlow中的优化方法—
训练模块 43
3.4.2　tf.train.Optimizer类 43
3.4.3　其他Optimizer实例类型 44
3.5　例1—单变量线性回归 44
3.5.1　数据集描述 45
3.5.2　模型结构 45
3.5.3　损失函数描述和Optimizer 46
3.5.4　停止条件 48
3.5.5　结果描述 48
3.5.6　完整源代码 49
3.6　例2—多变量线性回归 51
3.6.1　有用的库和方法 51
3.6.2　Pandas库 51
3.6.3　数据集描述 51
3.6.4　模型结构 53
3.6.5　损失函数和Optimizer 54
3.6.6　停止条件 55
3.6.7　结果描述 55
3.6.8　完整源代码 56
3.7　小结 57
第4章　逻辑回归 58
4.1　问题描述 58
4.2　Logistic函数的逆函数—Logit
函数 59
4.2.1　伯努利分布 59
4.2.2　联系函数 60
4.2.3　Logit函数 60
4.2.4　对数几率函数的逆函数—
Logistic函数 60
4.2.5　多类分类应用—Softmax
回归 62
4.3　例1—单变量逻辑回归 64
4.3.1　有用的库和方法 64
4.3.2　数据集描述和加载 65
4.3.3　模型结构 67
4.3.4　损失函数描述和优化器
循环 67
4.3.5　停止条件 68
4.3.6　结果描述 68
4.3.7　完整源代码 69
4.3.8　图像化表示 71
4.4　例2—基于skflow单变量逻辑
回归 72
4.4.1　有用的库和方法 72
4.4.2　数据集描述 72
4.4.3　模型结构 72
4.4.4　结果描述 73
4.4.5　完整源代码 74
4.5　小结 74
第5章　简单的前向神经网络 75
5.1　基本概念 75
5.1.1　人工神经元 75
5.1.2　神经网络层 76
5.1.3　有用的库和方法 78
5.2　例1—非线性模拟数据
回归 79
5.2.1　数据集描述和加载 79
5.2.2　数据集预处理 80
5.2.3　模型结构—损失函数
描述 80
5.2.4　损失函数优化器 80
5.2.5　准确度和收敛测试 80
5.2.6　完整源代码 80
5.2.7　结果描述 81
5.3　例2—通过非线性回归，对
汽车燃料效率建模 82
5.3.1　数据集描述和加载 82
5.3.2　数据预处理 83
5.3.3　模型架构 83
5.3.4　准确度测试 84
5.3.5　结果描述 84
5.3.6　完整源代码 84
5.4　例3—多类分类：葡萄酒
分类 86
5.4.1　数据集描述和
加载 86
5.4.2　数据集预处理 86
5.4.3　模型架构 87
5.4.4　损失函数描述 87
5.4.5　损失函数优化器 87
5.4.6　收敛性测试 88
5.4.7　结果描述 88
5.4.8　完整源代码 88
5.5　小结 89
第6章　卷积神经网络 90
6.1　卷积神经网络的起源 90
6.1.1　卷积初探 90
6.1.2　降采样操作—池化 95
6.1.3　提高效率—dropout
操作 98
6.1.4　卷积类型层构建办法 99
6.2　例1—MNIST数字分类 100
6.2.1　数据集描述和加载 100
6.2.2　数据预处理 102
6.2.3　模型结构 102
6.2.4　损失函数描述 103
6.2.5　损失函数优化器 103
6.2.6　准确性测试 103
6.2.7　结果描述 103
6.2.8　完整源代码 104
6.3　例2—CIFAR10数据集的图像
分类 106
6.3.1　数据集描述和加载 107
6.3.2　数据集预处理 107
6.3.3　模型结构 108
6.3.4　损失函数描述和
优化器 108
6.3.5　训练和准确性测试 108
6.3.6　结果描述 108
6.3.7　完整源代码 109
6.4　小结 110
第7章　循环神经网络和LSTM 111
7.1　循环神经网络 111
7.1.1　梯度爆炸和梯度消失 112
7.1.2　LSTM神经网络 112
7.1.3　其他RNN结构 116
7.1.4　TensorFlow LSTM有用的类和
方法 116
7.2　例1—能量消耗、单变量时间序
列数据预测 117
7.2.1　数据集描述和加载 117
7.2.2　数据预处理 118
7.2.3　模型结构 119
7.2.4　损失函数描述 121
7.2.5　收敛检测 121
7.2.6　结果描述 122
7.2.7　完整源代码 122
7.3　例2—创作巴赫风格的
曲目 125
7.3.1　字符级模型 125
7.3.2　字符串序列和概率表示 126
7.3.3　使用字符对音乐编码—
ABC音乐格式 126
7.3.4　有用的库和方法 128
7.3.5　数据集描述和加载 129
7.3.6　网络训练 129
7.3.7　数据集预处理 130
7.3.8　损失函数描述 131
7.3.9　停止条件 131
7.3.10　结果描述 131
7.3.11　完整源代码 132
7.4　小结 137
第8章　深度神经网络 138
8.1　深度神经网络的定义 138
8.2　深度网络结构的历史变迁 138
8.2.1　LeNet 5 138
8.2.2　Alexnet 139
8.2.3　VGG模型 139
8.2.4　第一代Inception模型 140
8.2.5　第二代Inception模型 141
8.2.6　第三代Inception模型 141
8.2.7　残差网络（ResNet） 142
8.2.8　其他的深度神经网络
结构 143
8.3　例子—VGG艺术风格转移 143
8.3.1　有用的库和方法 143
8.3.2　数据集描述和加载 143
8.3.3　数据集预处理 144
8.3.4　模型结构 144
8.3.5　损失函数 144
8.3.6　收敛性测试 145
8.3.7　程序执行 145
8.3.8　完整源代码 146
8.4　小结 153
第9章　规模化运行模型—GPU和
服务 154
9.1　TensorFlow中的GPU支持 154
9.2　打印可用资源和设备参数 155
9.2.1　计算能力查询 155
9.2.2　选择CPU用于计算 156
9.2.3　设备名称 156
9.3　例1—将一个操作指派给
GPU 156
9.4　例2—并行计算Pi的数值 157
9.4.1　实现方法 158
9.4.2　源代码 158
9.5　分布式TensorFlow 159
9.5.1　分布式计算组件 159
9.5.2　创建TensorFlow集群 160
9.5.3　集群操作—发送计算方法
到任务 161
9.5.4　分布式编码结构示例 162
9.6　例3—分布式Pi计算 163
9.6.1　服务器端脚本 163
9.6.2　客户端脚本 164
9.7　例4—在集群上运行分布式
模型 165
9.8　小结 168
第10章　库的安装和其他技巧 169
10.1　Linux安装 169
10.1.1　安装要求 170
10.1.2　Ubuntu安装准备（安装操作的
前期操作） 170
10.1.3　Linux下通过pip安装
TensorFlow 170
10.1.4　Linux下从源码安装
TensorFlow 175
10.2　Windows安装 179
10.2.1　经典的Docker工具箱
方法 180
10.2.2　安装步骤 180
10.3　MacOS X安装 183
10.4　小结 185

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow机器学习项目实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习(从公理到算法)/中国计算机学会学术著作丛书
自序
前言
目录
第1章 引言
第2章 归类理论
第3章 密度估计
第4章 回归
第5章 单类数据降维
第6章 聚类理论
第7章 聚类算法
第8章 分类理论
第9章 基于单类的分类算法：神经网络
第10章 K近邻分类模型
第11章 线性分类模型
第12章 对数线性分类模型
第13章 贝叶斯决策
第14章 决策树
第15章 多类数据降维
第16章 多类数据升维：核方法
第17章 多源数据学习
后记
索引
彩插
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习(从公理到算法)/中国计算机学会学术著作丛书
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习理论与算法
序前言第1章  绪论  1.1 什么是机器学习    1.1.1 信息爆炸    1.1.2 学习的定义    1.1.3 机器学习定义  1.2 机器学习的发展史  1.3 机器学习的发展现状  1.4 机器学习的策略与模型    1.4.1 机器学习策略    1.4.2 机器学习系统的基本模型  1.5 机器学习的相关方法    1.5.1 算法类型    1.5.2 具体方法  1.6 本书的内容安排  参考文献第2章  统计学习理论与支持向量机算法  2.1 引言  2.2 统计学习理论    2.2.1 统计学习理论的形成与发展    2.2.2 统计学习理论的主要内容    2.2.3 学习过程的一致性及收敛速度    2.2.4 函数集的vC维    2.2.5 结构风险最小化归纳原则  2.3 支持向量机    2.3.1 支持向量机的形成与发展    2.3.2 支持向量机的主要内容    2.3.3 基本的支持向量机算法    2.3.4 变形的支持向量机算法    2.3.5 优化的支持向量机算法    2.3.6 多分类的支持向量机算法    2.3.7 支持向量机聚类算法  2.4 本章小结  参考文献  附录第3章  构造性机器学习理论与覆盖算法  3.1 引言    3.1.1 传统的神经网络存在的问题    3.1.2 构造性机器学习方法的提出    3.1.3 构造性机器学习覆盖算法与支持向量机的区别  3.2 覆盖问题的描述及理论基础    3.2.1 覆盖问题的描述    3.2.2 覆盖算法的理论基础  3.3 覆盖模型及其算法的分析    3.3.1 领域覆盖算法    3.3.2 交叉覆盖算法    3.3.3 覆盖算法的改进措施    3.3.4 多侧面递进算法    3.3.5 核覆盖算法    3.3.6 概率模型覆盖算法  3.4 本章小结  参考文献  附录第4章  集成学习与弱可学习理论  4.1 引言  4.2 集成学习的发展和现状  4.3 集成学习的产生背景和主要作用  4.4 集成学习的主要内容    4.4.1 PAC理论    4.4.2 强可学习与弱可学习理论    4.4.3 集成学习的基本概念    4.4.4 集成学习的算法框架  4.5 AdaBoost    4.5.1 AdaBoost算法训练误差的上界    4.5.2 训练轮数T的确定    4.5.3 基于泛化误差上界的分析    4.5.4 基于优化理论的分析  4.6 AdaBoost-M1  4.7 Ada：Boost-M2  4.8 Bagging  4.9 Stacking  4.10 选择性集成    4.10.1 选择性集成的提出    4.10.2 选择性集成的理论基础    4.10.3 GASE：N    4.10.4 选择性集成的发展  4.11 集成学习的应用  4.12 本章小结  参考文献  附录第5章  数据流的概念获取与增量学习  5.1 引言  5.2 数据流    5.2.1 数据流与流形学习的概念    5.2.2 数据流的性质    5.2.3 数据流的特征    5.2.4 数据流处理模型    5.2.5 数据流的基本技术    5.2.6 数据流上的应用  5.3 数据流分类    5.3.1 数据流的分类问题    5.3.2 现有数据流上的分类算法  5.4 数据流的概念漂移    5.4.1 概念漂移定义    5.4.2 概念漂移类型    5.4.3 概念漂移检测    5.4.4 概念漂移与数据流分类的关系    5.4.5 概念漂移的处理方法  5.5 增量学习    5.5.1 支持向量机增量学习算法    5.5.2 基于覆盖的增量学习  5.6 本章小结  参考文献  附录第6章  人工神经网络之遗传算法  6.1 引言  6.2 遗传算法的仿生学基础    6.2.1 生物遗传及其变异    6.2.2 进化  6.3 遗传算法简介    6.3.1 发展史    6.3.2 遗传算法  6.4 基本遗传算法    6.4.1 基本遗传算法描述    6.4.2 基本遗传操作    6.4.3 基本遗传算法的形式化定义    6.4.4 基本遗传算法的应用举例  6.5 遗传算法的理论基础    6.5.1 模式    6.5.2 选择操作对模式的影响    6.5.3 交叉操作对模式的影响    6.5.4 变异操作对模式的影响  6.6 本章小结  参考文献  附录第7章  决策树与贝叶斯网络  7.1 决策树的形成与发展    7.1.1 决策树的定义    7.1.2 决策树的优缺点  7.2 决策树的基本原理：统计学角度  7.3 决策树经典算法介绍    7.3.1 ID3算法    7.3.2 C4.5 算法    7.3.3 EC4.5 算法    7.3.4 CART算法    7.3.5 SuQ算法    7.3.6 SPRINT算法    7.3.7 PUBLIC算法  7.4 决策树的应用    7.4.1 决策树的适用范围    7.4.2 决策树的应用前景    7.4.3 决策树的应用举例  7.5 贝叶斯网络的形成与发展    7.5.1 贝叶斯网络的发展历史    7.5.2 贝叶斯方法的基本观点    7.5.3 贝叶斯网络的特点  7.6 贝叶斯网络原理及应用    7.6.1 贝叶斯网络    7.6.2 贝叶斯网络构造  7.7 典型贝叶斯网络学习方法及其变形    7.7.1 完整数据条件下贝叶斯网络的参数学习    7.7.2 完整数据条件下贝叶斯网络的结构学习    7.7.3 不完整数据条件下贝叶斯网络的参数学习    7.7.4 不完整数据条件下贝叶斯网络的结构学习  7.8 贝叶斯网络推理    7.8.1 贝叶斯网络精确推理算法    7.8.2 贝叶斯网络近似推理算法    7.8.3 贝叶斯网络推理算法的比较分析  7.9 贝叶斯网络的应用    7.9.1 贝叶斯网络用于分类和回归分析    7.9.2 贝叶斯网络用于不确定知识表达和推理    7.9.3 贝叶斯网络在因果数据挖掘上的应用及展望    7.9.4 贝叶斯网络用于聚类模式发现    7.9.5 基于贝叶斯网络的遗传算法    7.9.6 基于贝叶斯网络的多目标优化问题  7.10 本章小结  参考文献  附录
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习理论与算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>决策用强化与系统性机器学习
译者序
原书前言
原书致谢
关于作者
第1章强化与系统性机器学习1
11简介1
12监督学习、无监督学习、半监督学习和强化学习1
13传统机器学习方法和机器学习发展历史3
14什么是机器学习？6
15机器学习问题6
151学习的目标6
16学习模式7
17机器学习技术和范例9
18什么是强化学习？11
19强化函数和环境函数12
110强化学习的需求13
111强化学习和机器智能14
112什么是系统学习？14
113什么是系统性机器学习？15
114系统性机器学习的重点15
115强化性机器学习和系统性机器学习16
116车辆检测问题的案例研究16
117小结16
参考文献17
第2章全系统原理、系统性和多视角的机器学习18
21简介18
211什么是系统性学习？19
212历史20
22什么是系统性机器学习？21
221基于事件的学习21
23广义系统性机器学习框架23
231系统定义24
24多视角决策和多视角学习26
241基于完整信息的表示32
242基于部分信息的表示32
243单视角决策方案图32
244双重视角决策方案图32
245多视角决策方案图32
246定性信念网络和影响图33
25动态和交互式决策33
251交互决策图33
252决策图和影响图中时间的角色34
253系统性视角的建立34
254信息整合35
255建立典型决策方案图35
256受限信息35
257多决策者系统在系统性学习中的角色35
26系统性学习框架39
261数学模型39
262系统性学习的方法39
263自适应系统性学习40
264系统性学习框架41
27系统分析41
28案例学习：在酒店行业中需要系统性学习43
29小结44
参考文献44
第3章强化学习45
31简介45
32学习决策者48
33回报和奖励的计算50
331方案和连续任务50
34强化学习和自适应控制51
35动态系统54
351离散事件动态系统54
36强化学习和控制55
37马尔科夫性质和决策过程55
38价值函数56
381行动和价值56
39学习最优策略（有模型和无模型法）57
310动态规划57
3101动态系统性质57
311自适应动态规则58
3111时间差分学习59
3112Q学习60
3113统一的视图60
312范例——拳击训练器的强化学习61
313小结61
参考文献61
第4章系统性机器学习和模型62
41简介62
42系统学习的框架63
421影响空间64
422交互作用为中心的模型69
423以结果为中心的模型69
43捕捉系统视图70
44系统交互的数学表达73
45影响函数74
46决策影响分析74
461时空界限75
47小结80
第5章推理和信息集成82
51简介82
52推理机制和需要83
521情景推理85
522推理确定影响85
53情景和推理的集成88
54统计推理和归纳91
541直接推理91
542间接推理91
543信息推理91
544归纳92
55纯似然方法92
56贝叶斯范例推理93
561贝叶斯定理93
57基于时域推理93
58推理建立系统观点94
581信息集成94
59小结96
参考文献97
第6章自适应学习98
61简介98
62自适应学习和自适应系统98
63什么是自适应机器学习101
64基于方案的适应性和学习方法101
641动态适应性和情景感知的学习102
65系统学习和自适应学习104
651多学习器的使用105
652系统自适应机器学习108
653自适应应用的设计110
654自适应学习的需要和适应的原因111
655适应类型112
656自适应框架114
66竞争学习和自适应学习115
661适应性函数116
662决策网络118
663自适应学习方案119
67范例120
671案例研究：基于自适应学习的文本120
672自适应学习的文档挖掘121
68小结122
参考文献122
第7章多视角和全局系统性的学习123
71简介123
72多视角方案构建124
73多视角决策和多视角学习126
731视角结合126
732影响图和部分方案决策表示图127
733表示决策方案图（RDSD）130
734范例：部分方案决策表示图（PDSRD）表示的不同视角获取的城市信息131
74全局系统性学习和多视角途径134
741分散信息整合135
742多视角和全局系统知识表示135
743什么是多视角方案？135
744特定方案136
75基于多视角途径的案例研究136
751交通控制器用多视角途径137
752情感检测用多视角途径模型138
76多视角方法的局限性143
77小结143
参考文献144
第8章增量学习和知识表示145
81简介145
82为什么增量学习？146
83学习已经学会的147
831绝对增量学习148
832选择增量学习149
84监督增量学习157
85增量无监督学习和增量聚类158
851增量聚类：任务160
852增量聚类：方法161
853阈值161
86半监督增量学习162
87增量与系统性学习163
88增量接近值和学习方法164
881增量学习方法1165
882增量学习方法2166
883计算C值增量166
89学习与决策模型169
810增量分类技术169
811案例分析：增量文档分类170
812小结171
第9章知识增长：机器学习的视角173
91简介173
92短暂的历史和相关工作174
93知识增长和知识启发178
931策略使用进行知识启发178
932基于目标的知识启发179
933基于过程的知识启发179
94生命周期180
941知识水平181
942直接知识181
943间接知识182
944程序知识182
945问题182
946决策182
947知识生命周期183
95增量知识表达184
96案例学习和遗忘学习186
97知识的扩充：技术和方法187
971知识增量技术187
972知识增量方法188
973提取知识的机制189
98启发式学习190
99系统性机器学习和知识获取190
991全方位知识获取191
992系统知识管理和先进的机器学习192
910在复杂环境下的知识增量193
911案例研究193
9111银行案例研究193
9112软件开发公司194
9113杂货集市/零售集市195
912小结195
参考文献196
第10章构建学习系统197
101简介197
102系统性学习系统197
1021学习单元199
1022知识库200
1023性能单元200
1024反馈单元200
1025允许测量的系统200
103算法选择201
1031k近邻（kNN）201
1032支持向量机（SVM）202
1033质心法202
104知识表示203
1041实用方案和案例研究203
105学习系统的设计204
106让系统表现得更智能204
107案例学习205
108整体知识框架和强化学习的应用205
1081智能算法的选择207
109智能决策——部署和知识采集以及重用208
1010基于案例的学习：人体情感检测系统209
1011复杂决策问题的整体视角211
1012知识表示和资源查找213
1013组件215
10131范例215
1014学习系统和智能系统的未来216
1015小结217
附录218
附录A统计学习方法218
A1概率218
A11互斥事件218
A12独立事件218
A2贝叶斯分类219
A21朴素贝叶斯分类220
A22贝叶斯分类器的优点和缺点221
A3回归221
A31线性222
A32非线性222
A33回归的其他方法222
A4粗糙集223
A41不可分辨关系223
A42集近似224
A43边界区域224
A44粗糙集和清晰集224
A45约简224
A46可有可无和不可缺少的属性224
A5支持向量机224
参考文献225
附录B马尔科夫过程225
B1马尔科夫过程225
B11案例226
B12解决步骤226
B13长期227
B14马尔科夫过程示例228
B2半马尔科夫过程231
B21建议231
B22验证232
B23推论232
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>决策用强化与系统性机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习及其应用2009
机器学习与人工智能  1 引言  2 机器学习与人工智能的不同理念  3 统计机器学习的特点  4 集群学习(ensemble learning)  5 人工智能对机器学习的补充  6 重采样方法——自助法  7 变量稀疏化  8 知识的集群  9 讨论和总结  参考文献关系强化学习研究  1 引言  2 Tetris和强化学习解法    2.1 Tetris    2.2 Tetris的抽象和建模    2.3 Tetris的强化学习解法    2.4 状态空间抽象  3 关系强化学习    3.1 关系强化学习及其抽象    3.2 逻辑决策树方法    3.3 马尔可夫逻辑网方法  4 结束语  参考文献因果挖掘的若干统计方法  1 引言  2 井底之蛙：因果作用与混杂因素  3 替罪羔羊：利用替代指标评价因果作用    3.1 几种替代指标准则    3.2 替代指标悖论    3.3 一致替代指标，严格一致替代指标  4 盲人摸象：贝叶斯网络的结构学习    4.1 贝叶斯网络结构的分解学习方法    4.2 贝叶斯网络结构的递归学习方法    4.3 贝叶斯网络结构的聚类学习方法  5 纲举目张：确定因果网络方向的主动学习方法    5.1 各种干预方法    5.2 各种算法的模拟比较  6 寻根问底+顺藤摸瓜：寻摸结果变量的原因    6.1 外部干预下的预测问题    6.2 局部因果挖掘的方法  7 讨论  参考文献基于学习的图像超分辨率算法  1 引言  2 基于学习的超分辨率算法综述    2.1 间接最大后验算法    2.2 直接最大后验算法    2.3 基于学习的超分辨率算法的优缺点  3 基于学习的超分辨率算法的性能极限    3.1 什么是基于学习的超分辨率算法的极限    3.2 期望风险的下界    3.3 基于学习的超分辨率算法的极限    3.4 下界的计算与阈值的选取    3.5 讨论  4 结语  参考文献分类学习的正则化技术  1 引言  2 经典的正则化技术    2.1 Tikhonov正则化    2.2 正则化网络    2.3 支持向量机    2.4 正则化最小二乘分类器    2.5 流形正则化  3 最新研究进展    3.1 正则化分类器的泛化误差界    3.2 正则化项的构造    3.3 正则化参数的选择  4 结束语参考文献Transfer Learning and Its Application for WiFi Localization ProblemsSinno Jialin Pan, Vincent Wenchen Zheng and Qiang Yang  1 Introduction  2 An Overview of Transfer Learning    2.1 Instance Based Transfer Learning    2.2 Transfer Learning Through Dimensionality Reduction    2.3 Transfer Learning Through Selftaught Clustering  3 WiFi Localization in Indoor Environments  4 Transfer Learning for WILP    4.1 Transferring Localization Models over Time    4.2 Transferring Localization Models across Space    4.3 Transferring Localization Models across Devices  5 Experiments and Discussion    5.1 ICDM 2007 Data Mining Contest Dataset    5.2 Experimental Results    6 Conclusion and Future Work  References关于boosting算法的margin解释  1 引言  2 背景与相关工作  3 主要结果  4 对Emargin上界的解释  5 证明    5.1 定理3的证明    5.2 命题1的证明    5.3 定理4的证明    5.4 定理5的证明    5.5 定理6的证明  6 实验  7 结论  参考文献最大间隔聚类快速算法研究  1 引言    1.1 支持向量机    1.2 最大间隔聚类    1.3 国内外研究现状  2 两类问题的最大间隔聚类算法    2.1 优化问题的等价转化    2.2 切平面算法  3 多类问题的最大间隔聚类算法    3.1 切平面算法  4 实验分析    4.1 实验数据集    4.2 评价标准    4.3 对比算法以及参数选择    4.4 聚类精度比较    4.5 聚类速度比较    4.6 约束凹凸规划平均迭代次数    4.7 切平面算法计算时间与数据集规模的关系    4.8 参数ε对切平面算法精度以及速度的影响    4.9 参数C对切平面算法精度以及速度的影响  5 总结  参考文献自适应K段主曲线  1 引言  2 主曲线综述    2.1 主曲线初步    2.2 主曲线发展历史  3 自适应K段主曲线    3.1 引入先验知识    3.2 顶点移除    3.3 自适应K段主曲线实现  4 实验  5 应用：高精度GPS学习  6 讨论  7 总结  附录  A.1 投影步骤细节  A.2 优化步骤细节  A.3 GPS精度的改进  参考文献MIML：多示例多标记学习  1 引言  2 MIML框架  3 MIML学习算法  3.1 基于退化策略的MIML学习算法  3.2 基于正则化的MIML学习算法  4 利用MIML学习单示例样本  5 利用MIML学习复杂高层概念  6 结束语  参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习及其应用2009
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据科学与机器学习
第 1 章 入门 1
1.1　安装Enthought Canopy　1
1.2　使用并理解IPython/Jupyter Notebook　6
1.3　Python基础——第 一部分　9
1.4　理解Python代码　11
1.5　导入模块　13
1.5.1　数据结构　13
1.5.2　使用列表　14
1.5.3　元组　17
1.5.4　字典　18
1.6　Python基础——第二部分　20
1.6.1　Python中的函数　20
1.6.2　循环　23
1.6.3　探索活动　24
1.7　运行Python脚本　24
1.7.1　运行Python代码的其他方式　25
1.7.2　在命令行中运行Python脚本　25
1.7.3　使用Canopy IDE　26
1.8　小结　28
第　2 章 统计与概率复习以及Python实现　29
2.1　数据类型　29
2.1.1　数值型数据　30
2.1.2　分类数据　30
2.1.3　定序数据　31
2.2　均值、中位数和众数　32
2.2.1　均值　32
2.2.2　中位数　33
2.2.3　众数　34
2.3　在Python中使用均值、中位数和众数　35
2.3.1　使用NumPy包计算均值　35
2.3.2　使用NumPy包计算中位数　36
2.3.3　使用SciPy包计算众数　37
2.4　标准差和方差　40
2.4.1　方差　40
2.4.2　标准差　42
2.4.3　总体方差与样本方差　42
2.4.4　在直方图上分析标准差和方差　44
2.4.5　使用Python计算标准差和方差　44
2.4.6　自己动手　45
2.5　概率密度函数和概率质量函数　45
2.5.1　概率密度函数　45
2.5.2　概率质量函数　46
2.6　各种类型的数据分布　47
2.6.1　均匀分布　47
2.6.2　正态分布或高斯分布　48
2.6.3　指数概率分布与指数定律　50
2.6.4　二项式概率质量函数　50
2.6.5　泊松概率质量函数　51
2.7　百分位数和矩　52
2.7.1　百分位数　53
2.7.2　矩　56
2.8　小结　60
第　3 章 Matplotlib与概率高级概念　61
3.1　Matplotlib快速学习　61
3.1.1　在一张图形上进行多次绘图　62
3.1.2　将图形保存为文件　63
3.1.3　调整坐标轴　64
3.1.4　添加网格　65
3.1.5　修改线型和颜色　65
3.1.6　标记坐标轴并添加图例　68
3.1.7　一个有趣的例子　69
3.1.8　生成饼图　70
3.1.9　生成条形图　71
3.1.10　生成散点图　72
3.1.11　生成直方图　72
3.1.12　生成箱线图　73
3.1.13　自己动手　74
3.2　协方差与相关系数　74
3.2.1　概念定义　75
3.2.2　相关系数　76
3.2.3　在Python中计算协方差和相关系数　76
3.2.4　相关系数练习　80
3.3　条件概率　80
3.3.1　Python中的条件概率练习　81
3.3.2　条件概率作业　84
3.3.3　作业答案　85
3.4　贝叶斯定理　86
3.5　小结　88
第　4 章 预测模型　89
4.1　线性回归　89
4.1.1　普通最小二乘法　90
4.1.2　梯度下降法　91
4.1.3　判定系数或r方　91
4.1.4　使用Python进行线性回归并计算r方　92
4.1.5　线性回归练习　94
4.2　多项式回归　95
4.2.1　使用NumPy实现多项式回归　96
4.2.2　计算r方误差　98
4.2.3　多项式回归练习　98
4.3　多元回归和汽车价格预测　99
4.3.1　使用Python进行多元回归　100
4.3.2　多元回归练习　102
4.4　多水平模型　102
4.5　小结　104
第　5 章 使用Python进行机器学习　105
5.1　机器学习及训练/测试法　105
5.1.1　非监督式学习　106
5.1.2　监督式学习　107
5.2　使用训练/测试法防止多项式回归中的过拟合　109
5.3　贝叶斯方法——概念　113
5.4　使用朴素贝叶斯实现垃圾邮件分类器　115
5.5　k均值聚类　118
5.6　基于收入与年龄进行人群聚类　121
5.7　熵的度量　123
5.8　决策树——概念　124
5.8.1　决策树实例　126
5.8.2　生成决策树　127
5.8.3　随机森林　127
5.9　决策树——使用Python预测录用决策　128
5.9.1　集成学习——使用随机森林　132
5.9.2　练习　133
5.10　集成学习　133
5.11　支持向量机简介　135
5.12　使用scikit-learn通过SVM进行人员聚集　137
5.13　小结　140
第　6 章 推荐系统　141
6.1　什么是推荐系统　141
6.2　基于项目的协同过滤　145
6.3　基于项目的协同过滤是如何工作的　146
6.4　找出电影相似度　149
6.5　改善电影相似度结果　155
6.6　向人们推荐电影　159
6.7　改善推荐结果　165
6.8　小结　167
第　7 章 更多数据挖掘和机器学习技术　168
7.1　k最近邻的概念　168
7.2　使用KNN预测电影评分　170
7.3　数据降维与主成分分析　176
7.3.1　数据降维　176
7.3.2　主成分分析　177
7.4　对鸢尾花数据集的PCA示例　178
7.5　数据仓库简介　182
7.6　强化学习　184
7.6.1　Q-learning　185
7.6.2　探索问题　186
7.6.3　时髦名词　186
7.7　小结　188
第　8 章 处理真实数据　189
8.1　偏差-方差权衡　189
8.2　使用k折交叉验证避免过拟合　192
8.3　数据清理和标准化　196
8.4　清理Web日志数据　198
8.4.1　对Web日志应用正则表达式　198
8.4.2　修改1——筛选请求字段　200
8.4.3　修改2——筛选post请求　201
8.4.4　修改3——检查用户代理　203
8.4.5　筛选爬虫与机器人　204
8.4.6　修改4——使用网站专用筛选器　205
8.4.7　Web日志数据练习　206
8.5　数值型数据的标准化　207
8.6　检测异常值　208
8.6.1　处理异常值　209
8.6.2　异常值练习　211
8.7　小结211
第　9 章 Apache Spark——大数据上的机器学习　212
9.1　安装Spark　212
9.1.1　在Windows系统中安装Spark　213
9.1.2　在其他操作系统上安装Spark　214
9.1.3　安装Java Development Kit　214
9.1.4　安装Spark　217
9.2　Spark简介　227
9.2.1　可伸缩　227
9.2.2　速度快　228
9.2.3　充满活力　229
9.2.4　易于使用　229
9.2.5　Spark组件　229
9.2.6　在Spark中使用Python还是Scala　230
9.3　Spark和弹性分布式数据集　231
9.3.1　SparkContext对象　231
9.3.2　创建RDD　232
9.3.3　更多创建RDD的方法　233
9.3.4　RDD操作　233
9.4　MLlib简介　235
9.4.1　MLlib功能　235
9.4.2　MLlib特殊数据类型　236
9.5　在Spark中使用MLlib实现决策树　236
9.6　在Spark中实现k均值聚类　245
9.7　TF-IDF　250
9.7.1　TF-IDF实战　250
9.7.2　使用TF-IDF　251
9.8　使用Spark MLlib搜索维基百科　251
9.8.1　导入语句　252
9.8.2　创建初始RDD　252
9.8.3　创建并转换HashingTF对象　253
9.8.4　计算TF-IDF得分　254
9.8.5　使用维基百科搜索引擎算法　254
9.8.6　运行算法　255
9.9　使用Spark 2.0中的MLlib数据框API　255
9.10　小结　259
第　10 章 测试与实验设计　260
10.1　A/B测试的概念　260
10.1.1　A/B测试　260
10.1.2　A/B测试的转化效果测量　262
10.1.3　小心方差　263
10.2　t检验与p值　263
10.2.1　t统计量或t检验　264
10.2.2　p值　264
10.3　使用Python计算t统计量和p值　265
10.3.1　使用实验数据进行A/B测试　265
10.3.2　样本量有关系吗　267
10.4　确定实验持续时间　268
10.5　A/B测试中的陷阱　269
10.5.1　新奇性效应　270
10.5.2　季节性效应　271
10.5.3　选择性偏差　271
10.5.4　数据污染　272
10.5.5　归因错误　272
10.6　小结　273
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据科学与机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习算法
0  绪论	1
0.1  机器学习基础	1
0.1.1  机器学习的概念	1
0.1.2  机器学习算法的分类	2
0.2  监督学习	3
0.2.1  监督学习	3
0.2.2  监督学习的流程	3
0.2.3  监督学习算法	4
0.3  无监督学习	4
0.3.1  无监督学习	4
0.3.2  无监督学习的流程	4
0.3.3  无监督学习算法	5
0.4  推荐系统和深度学习	6
0.4.1  推荐系统	6
0.4.2  深度学习	6
0.5  Python和机器学习算法实践	6
参考文献	7
第一部分  分类算法
1  Logistic Regression	10
1.1  Logistic Regression模型	10
1.1.1  线性可分VS线性不可分	10
1.1.2  Logistic Regression模型	11
1.1.3  损失函数	13
1.2  梯度下降法	14
1.2.1  梯度下降法的流程	14
1.2.2  凸优化与非凸优化	15
1.2.3  利用梯度下降法训练Logistic Regression模型	17
1.3  梯度下降法的若干问题	18
1.3.1  选择下降的方向	18
1.3.2  步长的选择	19
1.4  Logistic Regression算法实践	20
1.4.1  利用训练样本训练Logistic Regression模型	20
1.4.2  最终的训练效果	22
1.4.3  对新数据进行预测	23
参考文献	26
2  Softmax Regression	27
2.1  多分类问题	27
2.2  Softmax Regression算法模型	28
2.2.1  Softmax Regression模型	28
2.2.2  Softmax Regression算法的代价函数	28
2.3  Softmax Regression算法的求解	29
2.4  Softmax Regression与Logistic Regression的关系	31
2.4.1  Softmax Regression中的参数特点	31
2.4.2  由Softmax Regression到Logistic Regression	31
2.5  Softmax Regression算法实践	32
2.5.1  对Softmax Regression算法的模型进行训练	33
2.5.2  最终的模型	34
2.5.3  对新的数据的预测	35
参考文献	39
3  Factorization Machine	40
3.1  Logistic Regression算法的不足	40
3.2  因子分解机FM的模型	42
3.2.1  因子分解机FM模型	42
3.2.2  因子分解机FM可以处理的问题	43
3.2.3  二分类因子分解机FM算法的损失函数	43
3.3  FM算法中交叉项的处理	43
3.3.1  交叉项系数	43
3.3.2  模型的求解	44
3.4  FM算法的求解	45
3.4.1  随机梯度下降（Stochastic Gradient Descent）	45
3.4.2  基于随机梯度的方式求解	45
3.4.3  FM算法流程	46
3.5  因子分解机FM算法实践	49
3.5.1  训练FM模型	50
3.5.2  最终的训练效果	53
3.5.3  对新的数据进行预测	55
参考文献	57
4  支持向量机	58
4.1  二分类问题	58
4.1.1  二分类的分隔超平面	58
4.1.2  感知机算法	59
4.1.3  感知机算法存在的问题	61
4.2  函数间隔和几何间隔	61
4.2.1  函数间隔	62
4.2.2  几何间隔	62
4.3  支持向量机	63
4.3.1  间隔最大化	63
4.3.2  支持向量和间隔边界	64
4.3.3  线性支持向量机	65
4.4  支持向量机的训练	66
4.4.1  学习的对偶算法	66
4.4.2  由线性支持向量机到非线性支持向量机	68
4.4.3  序列最小最优化算法SMO	69
4.5  支持向量机SVM算法实践	74
4.5.1  训练SVM模型	74
4.5.2  利用训练样本训练SVM模型	81
4.5.3  利用训练好的SVM模型对新数据进行预测	85
参考文献	88
5  随机森林	89
5.1  决策树分类器	89
5.1.1  决策树的基本概念	89
5.1.2  选择最佳划分的标准	91
5.1.3  停止划分的标准	94
5.2  CART分类树算法	95
5.2.1  CART分类树算法的基本原理	95
5.2.2  CART分类树的构建	95
5.2.3  利用构建好的分类树进行预测	98
5.3  集成学习（Ensemble Learning）	99
5.3.1  集成学习的思想	99
5.3.2  集成学习中的典型方法	99
5.4  随机森林（Random Forests）	101
5.4.1  随机森林算法模型	101
5.4.2  随机森林算法流程	102
5.5  随机森林RF算法实践	104
5.5.1  训练随机森林模型	105
5.5.2  最终的训练结果	109
5.5.3  对新数据的预测	110
参考文献	113
6  BP神经网络	114
6.1  神经元概述	114
6.1.1  神经元的基本结构	114
6.1.2  激活函数	115
6.2  神经网络模型	116
6.2.1  神经网络的结构	116
6.2.2  神经网络中的参数说明	117
6.2.3  神经网络的计算	117
6.3  神经网络中参数的求解	118
6.3.1  神经网络损失函数	118
6.3.2  损失函数的求解	119
6.3.3  BP神经网络的学习过程	120
6.4  BP神经网络中参数的设置	126
6.4.1  非线性变换	126
6.4.2  权重向量的初始化	126
6.4.3  学习率	127
6.4.4  隐含层节点的个数	127
6.5  BP神经网络算法实践	127
6.5.1  训练BP神经网络模型	128
6.5.2  最终的训练效果	132
6.5.3  对新数据的预测	133
参考文献	136
第二部分  回归算法
7  线性回归	138
7.1  基本线性回归	138
7.1.1  线性回归的模型	138
7.1.2  线性回归模型的损失函数	139
7.2  线性回归的最小二乘解法	140
7.2.1  线性回归的最小二乘解法	140
7.2.2  广义逆的概念	141
7.3  牛顿法	141
7.3.1  基本牛顿法的原理	141
7.3.2  基本牛顿法的流程	142
7.3.3  全局牛顿法	142
7.3.4  Armijo搜索	144
7.3.5  利用全局牛顿法求解线性回归模型	145
7.4  利用线性回归进行预测	146
7.4.1  训练线性回归模型	147
7.4.2  最终的训练结果	149
7.4.3  对新数据的预测	150
7.5  局部加权线性回归	152
7.5.1 局部加权线性回归模型	152
7.5.2  局部加权线性回归的最终结果	153
参考文献	154
8  岭回归和Lasso回归	155
8.1  线性回归存在的问题	155
8.2  岭回归模型	156
8.2.1  岭回归模型	156
8.2.2  岭回归模型的求解	156
8.3  Lasso回归模型	157
8.4  拟牛顿法	158
8.4.1  拟牛顿法	158
8.4.2  BFGS校正公式的推导	158
8.4.3  BFGS校正的算法流程	159
8.5  L-BFGS求解岭回归模型	162
8.5.1  BGFS算法存在的问题	162
8.5.2  L-BFGS算法思路	162
8.6  岭回归对数据的预测	165
8.6.1  训练岭回归模型	166
8.6.2  最终的训练结果	168
8.6.3  利用岭回归模型预测新的数据	168
参考文献	171
9  CART树回归	172
9.1  复杂的回归问题	172
9.1.1  线性回归模型	172
9.1.2  局部加权线性回归	173
9.1.3  CART算法	174
9.2  CART回归树生成	175
9.2.1  CART回归树的划分	175
9.2.2  CART回归树的构建	177
9.3  CART回归树剪枝	179
9.3.1  前剪枝	179
9.3.2  后剪枝	180
9.4  CART回归树对数据预测	180
9.4.1  利用训练数据训练CART回归树模型	180
9.4.2  最终的训练结果	182
9.4.3  利用训练好的CART回归树模型对新的数据预测	185
参考文献	187
第三部分  聚类算法
10  K-Means	190
10.1  相似性的度量	190
10.1.1  闵可夫斯基距离	191
10.1.2  曼哈顿距离	191
10.1.3  欧氏距离	191
10.2  K-Means算法原理	192
10.2.1  K-Means算法的基本原理	192
10.2.2  K-Means算法步骤	193
10.2.3  K-Means算法与矩阵分解	193
10.3  K-Means算法实践	195
10.3.1  导入数据	196
10.3.2  初始化聚类中心	197
10.3.3  聚类过程	198
10.3.4  最终的聚类结果	199
10.4  K-Means++算法	200
10.4.1  K-Means算法存在的问题	200
10.4.2  K-Means++算法的基本思路	202
10.4.3  K-Means++算法的过程和最终效果	204
参考文献	205
11  Mean Shift	206
11.1  Mean Shift向量	206
11.2  核函数	207
11.3  Mean Shift算法原理	209
11.3.1  引入核函数的Mean Shift向量	209
11.3.2  Mean Shift算法的基本原理	210
11.4  Mean Shift算法的解释	212
11.4.1  概率密度梯度	212
11.4.2  Mean Shift向量的修正	213
11.4.3  Mean Shift算法流程	213
11.5  Mean Shift算法实践	217
11.5.1  Mean Shift的主过程	218
11.5.2  Mean Shift的最终聚类结果	219
参考文献	221
12  DBSCAN	222
12.1  基于密度的聚类	222
12.1.1  基于距离的聚类算法存在的问题	222
12.1.2  基于密度的聚类算法	225
12.2  DBSCAN算法原理	225
12.2.1  DBSCAN算法的基本概念	225
12.2.2  DBSCAN算法原理	227
12.2.3  DBSCAN算法流程	228
12.3  DBSCAN算法实践	231
12.3.1  DBSCAN算法的主要过程	232
12.3.2  Mean Shift的最终聚类结果	234
参考文献	236
13  Label Propagation	237
13.1  社区划分	237
13.1.1  社区以及社区划分	237
13.1.2  社区划分的算法	238
13.1.3  社区划分的评价标准	239
13.2  Label Propagation算法原理	239
13.2.1  Label Propagation算法的基本原理	239
13.2.2  标签传播	240
13.2.3  迭代的终止条件	242
13.3  Label Propagation算法过程	244
13.4  Label Propagation算法实践	244
13.4.1  导入数据	245
13.4.2  社区的划分	246
13.4.3  最终的结果	247
参考文献	248
第四部分  推荐算法
14  协同过滤算法	250
14.1  推荐系统的概述	250
14.1.1  推荐系统	250
14.1.2  推荐问题的描述	251
14.1.3  推荐的常用方法	251
14.2  基于协同过滤的推荐	252
14.2.1  协同过滤算法概述	252
14.2.2  协同过滤算法的分类	252
14.3  相似度的度量方法	253
14.3.1  欧氏距离	254
14.3.2  皮尔逊相关系数（Pearson Correlation）	254
14.3.3  余弦相似度	254
14.4  基于协同过滤的推荐算法	256
14.4.1  基于用户的协同过滤算法	256
14.4.2  基于项的协同过滤算法	258
14.5  利用协同过滤算法进行推荐	260
14.5.1  导入用户-商品数据	260
14.5.2  利用基于用户的协同过滤算法进行推荐	261
14.5.3  利用基于项的协同过滤算法进行推荐	262
参考文献	264
15  基于矩阵分解的推荐算法	265
15.1  矩阵分解	265
15.2  基于矩阵分解的推荐算法	266
15.2.1  损失函数	266
15.2.2  损失函数的求解	266
15.2.3  加入正则项的损失函数即求解方法	267
15.2.4  预测	269
15.3  利用矩阵分解进行推荐	270
15.3.1  利用梯度下降对用户商品矩阵分解和预测	270
15.3.2  最终的结果	272
15.4  非负矩阵分解	273
15.4.1  非负矩阵分解的形式化定义	274
15.4.2  损失函数	274
15.4.3  优化问题的求解	274
15.5  利用非负矩阵分解进行推荐	277
15.5.1  利用乘法规则进行分解和预测	277
15.5.2  最终的结果	278
参考文献	279
16  基于图的推荐算法	280
16.1  二部图与推荐算法	280
16.1.1  二部图	280
16.1.2  由用户商品矩阵到二部图	281
16.2  PageRank算法	282
16.2.1  PageRank算法的概念	282
16.2.2  PageRank的两个假设	283
16.2.3  PageRank的计算方法	283
16.3  PersonalRank算法	285
16.3.1  PersonalRank算法原理	285
16.3.2  PersonalRank算法的流程	286
16.4  利用PersonalRank算法进行推荐	288
16.4.1  利用PersonalRank算法进行推荐	288
16.4.2  最终的结果	291
参考文献	291
第五部分  深度学习
17  AutoEncoder	294
17.1  多层神经网络	294
17.1.1  三层神经网络模型	294
17.1.2  由三层神经网络到多层神经网络	295
17.2  AutoEncoder模型	296
17.2.1  AutoEncoder模型结构	296
17.2.2  AutoEncoder的损失函数	297
17.3  降噪自编码器Denoising AutoEncoder	298
17.3.1  Denoising AutoEncoder原理	298
17.3.2  Denoising AutoEncoder实现	299
17.4  利用Denoising AutoEncoders构建深度网络	302
17.4.1  无监督的逐层训练	302
17.4.2  有监督的微调	303
17.5  利用TensorFlow实现Stacked Denoising AutoEncoders	306
17.5.1  训练Stacked Denoising AutoEncoders模型	306
17.5.2  训练的过程	307
参考文献	308
18  卷积神经网络	309
18.1  传统神经网络模型存在的问题	309
18.2  卷积神经网络	311
18.2.1  卷积神经网络中的核心概念	311
18.2.2  卷积神经网络模型	312
18.3  卷积神经网络的求解	313
18.3.1  卷积层（Convolution Layer）	313
18.3.2  下采样层（Sub-Sampling Layer）	316
18.3.3  全连接层（Fully-Connected Layer）	316
18.4  利用TensorFlow实现CNN	316
18.4.1  CNN的实现	316
18.4.2  训练CNN模型	320
18.4.3  训练的过程	321
参考文献	321
第六部分  项目实践
19  微博精准推荐	324
19.1  精准推荐	324
19.1.1  精准推荐的项目背景	324
19.1.2  精准推荐的技术架构	325
19.1.3  离线数据挖掘	326
19.2  基于用户行为的挖掘	327
19.2.1  基于互动内容的兴趣挖掘	327
19.2.2  基于与博主互动的兴趣挖掘	328
19.3  基于相似用户的挖掘	329
19.3.1  基于“@”人的相似用户挖掘	329
19.3.2  基于社区的相似用户挖掘	329
19.3.3  基于协同过滤的相似用户挖掘	331
19.4  点击率预估	332
19.4.1  点击率预估的概念	332
19.4.2  点击率预估的方法	332
19.5  各种数据技术的效果	334
参考文献	335
附录A	336
附录B	341
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础：从入门到求职
第1章  机器学习概述
1.1  机器学习介绍
1.1.1  机器学习的特点
1.1.2  机器学习的对象
1.1.3  机器学习的应用
1.2  机器学习分类
1.2.1  按任务类型分类
1.2.2  按学习方式分类
1.2.3  生成模型与判别模型
1.3  机器学习方法三要素
1.3.1  模型
1.3.2  策略
1.3.3  算法
1.3.4  小结
第2章  机器学习工程实践
2.1  模型评估指标
2.1.1  回归模型的评估指标
2.1.2  分类模型的评估指标
2.1.3  聚类模型的评估指标
2.1.4  常用距离公式
2.2  模型复杂度度量
2.2.1  偏差与方差
2.2.2  过拟合与正则化
2.3  特征工程与模型调优
2.3.1  数据挖掘项目流程
2.3.2  特征工程
2.3.3  模型选择与模型调优
第3章  线性回归
3.1  问题引入
3.2  线性回归模型
3.2.1  模型建立
3.2.2  策略确定
3.2.3  算法求解
3.2.4  线性回归模型流程
3.3  线性回归的scikit-learn实现
3.3.1  普通线性回归
3.3.2  Lasso回归
3.3.3  岭回归
3.3.4  ElasticNet回归
3.4  线性回归实例
3.5  小结
第4章  朴素贝叶斯
4.1  概述
4.2  相关原理
4.2.1  朴素贝叶斯基本原理
4.2.2  原理的进一步阐述
4.2.3  后验概率最大化的含义
4.2.4  拉普拉斯平滑
4.3  朴素贝叶斯的三种形式及scikit-learn实现
4.3.1  高斯型
4.3.2  多项式型
4.3.3  伯努利型
4.4  中文文本分类项目
4.4.1  项目简介
4.4.2  项目过程
4.4.3  完整程序实现
4.5  小结
第5章  K近邻
5.1  概述
5.2  K近邻分类原理
5.2.1  K值的选择
5.2.2  距离度量
5.2.3  分类决策规则
5.2.4  K近邻分类算法过程
5.3  K近邻回归原理
5.3.1  回归决策规则
5.3.2  K近邻回归算法过程
5.4  搜索优化——KD树
5.4.1  构造KD树
5.4.2  搜索KD树
5.5  K近邻的scikit-learn实现
5.5.1  K近邻分类
5.5.2  K近邻回归
5.6  K近邻应用实例
5.7  小结
第6章  决策树
6.1  概述
6.2  特征选择
6.2.1  信息增益
6.2.2  信息增益比
6.2.3  基尼指数
6.3  决策树生成
6.3.1  ID3决策树
6.3.2  C4.5决策树
6.3.3  CART决策树
6.4  决策树剪枝
6.5  决策树的scikit-learn实现
6.6  决策树应用于文本分类
6.7  小结
第7章  Logistic回归
7.1  Logistic回归概述
7.2  Logistic回归原理
7.2.1  Logistic回归模型
7.2.2  Logistic回归学习策略
7.2.3  Logistic回归优化算法
7.3  多项Logistic回归
7.4  Logistic回归的scikit-learn实现
7.5  Logistic回归实例
7.6  小结
第8章  支持向量机
8.1  感知机
8.1.1  感知机模型
8.1.2  感知机学习策略
8.1.3  感知机优化算法
8.1.4  感知机模型整体流程
8.1.5  小结
8.2  硬间隔支持向量机
8.2.1  引入
8.2.2  推导
8.3  软间隔支持向量机
8.4  合页损失函数
8.5  非线性支持向量机
8.6  SVM的scikit-learn实现
8.6.1  线性SVM
8.6.2  非线性SVM
8.7  SVM实例
8.8  小结
第9章  随机森林
9.1  Bagging
9.2  随机森林概念
9.3  RF的推广——extra trees
9.4  RF的scikit-learn实现
9.5  RF的scikit-learn使用实例
9.5.1  程序
9.5.2  结果及分析
9.5.3  扩展
9.6  小结
第10章  AdaBoost
10.1  AdaBoost的结构
10.1.1  AdaBoost的工作过程
10.1.2  AdaBoost多分类问题
10.1.3  AdaBoost回归问题
10.2  AdaBoost的原理
10.3  AdaBoost的scikit-learn实现
10.4  AdaBoost应用实例
10.5  AdaBoost模型的优缺点
第11章  提升树
11.1  提升树的定义
11.2  梯度提升树
11.2.1  梯度提升树的原理推导
11.2.2  GBDT和GBRT模型的处理过程
11.2.3  梯度提升模型的scikit-learn实现
11.2.4  梯度提升模型的scikit-learn使用实例
11.2.5  GBDT模型的优缺点
11.3  XGBoost
11.3.1  XGBoost的原理
11.3.2  XGBoost调参
11.3.3  XGBoost与GBDT的比较
第12章  聚类
12.1  聚类问题介绍
12.2  K-Means聚类
12.2.1  K-Means聚类过程和原理
12.2.2  K-Means算法优化
12.2.3  小结
12.2.4  K-Means应用实例
12.3  层次聚类
12.3.1  层次聚类的过程和原理
12.3.2  小结
12.3.3  层次聚类应用实例
12.4  密度聚类算法
12.4.1  密度聚类算法过程和原理
12.4.2  密度聚类小结
12.4.3  密度聚类应用实例
12.5  谱聚类
12.5.1  谱聚类的过程和原理
12.5.2  谱聚类小结
12.5.3  谱聚类应用实例
12.6  高斯混合模型
12.6.1  高斯混合聚类过程和原理
12.6.2  EM算法
12.6.3  小结
12.6.4  GMM应用实例
第13章  降维
13.1  奇异值分解
13.1.1  矩阵的特征分解
13.1.2  奇异值分解
13.2  主成分分析
13.2.1  PCA原理推导
13.2.2  核化PCA
13.2.3  PCA/KPCA的scikit-learn实现
13.3  线性判别分析
13.3.1  LDA原理推导
13.3.2  LDA与PCA的比较
13.3.3  LDA应用实例
13.4  局部线性嵌入
13.4.1  局部线性嵌入介绍
13.4.2  局部线性嵌入过程和原理
13.4.3  LLE应用实例
第14章  Word2Vec和Doc2Vec词向量模型
14.1  Word2Vec
14.1.1  Word2Vec概述
14.1.2  基于Hierarchical Softmax方法的CBOW模型
14.1.3  基于Hierarchical Softmax方法的Skip-Gram模型
14.1.4  基于Negative Sampling方法的CBOW模型
14.1.5  基于Negative Sampling方法的Skip-Gram模型
14.1.6  Word2Vec应用实例
14.2  Doc2Vec模型
14.2.1  Doc2Vec模型原理
14.2.2  Doc2Vec应用实例
第15章  深度神经网络
15.1  深度学习
15.1.1  概述
15.1.2  深度学习发展历史
15.2  神经网络原理
15.2.1  前向传播
15.2.2  反向传播
15.2.3  实例
15.2.4  几种常用激活函数
15.2.5  梯度消失与梯度爆炸
15.2.6  几种常用的优化算法
15.3  神经网络应用实例
15.4  小结
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础：从入门到求职
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据与机器学习
绪论争论中的大数据、机器学习与未来政治()
上篇数据主义
第一章数据军团：权力政治的算法角逐()
第一节复杂社会的演进：决策的相互扰动()
第二节同意的社会计算：传统民调的罪与罚()
第三节数据较量:美国大选幕后的算法操盘手()
第二章高频统计：选举中的政治预测()
第一节贝叶斯定理：纳特·西尔弗和他的538网站()
第二节预测偏差：538网站的数据陷阱()
第三节另类统计：最高频争议即为最大影响力()
第三章数据外交：一场即将到来的外交革命()
第一节从数字外交到数据外交：数据力量的崛起()
第二节从技术变革到当前争议：外交决策的数据冲击()
第三节从理论假说到案例实践：数据驱动的外交创新()
第四节未来前景与关键障碍：数据外交的拓展空间()
下篇数据原理
第四章文本分析:情感与意图的自动识别()
第一节分词原理：非结构化数据的结构化处理()
第二节情感分析：挖掘文本叙述中的情绪波动()
第三节主题模型：探索政治文本的隐含语义结构()
第五章社会网络:圈子里的政治文化()
第一节社会网络：以关系为中心的政治度量()
第二节强联系与弱联系：政治系统中的信息传递()
第三节中心性分析：发掘政治网络中的关键节点()
第六章机器学习：暴力冲突的社会感知()
第一节谢林模型：从计算机模拟到机器学习()
第二节学习原理：从有监督学习到无监督学习()
第三节神经网络:仿生人脑与社会情景的模式识别()
第四节预警未来：冲突预测的当前障碍()
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据与机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习在线：解析阿里云机器学习平台
第1章  阿里云机器学习	1
1.1  产品特点	1
1.2  名词解释	2
1.3  构建机器学习实验	3
1.3.1  新建实验	3
1.3.2  使用组件搭建工作流	4
1.3.3  运行实验、查看结果	5
1.3.4  模型部署、在线预测	6
第2章  商家作弊行为检测	7
2.1  数据探索	8
2.2  建模、预测和评估	15
2.3  尝试其他分类模型	19
2.4  判断商家作弊	24
第3章  生存预测	27
3.1  数据集一	27
3.1.1  特征分析	28
3.1.2  生存预测	33
3.2  数据集二	36
3.2.1  随机森林模型	39
3.2.2  朴素贝叶斯模型	47
第4章  信用风险预测	50
4.1  整体流程	53
4.1.1  特征哑元化	54
4.1.2  特征重要性	57
4.2  模型效果评估	61
4.3  减少模型特征的个数	62
第5章  用户购买行为预测	65
5.1  数据探索	66
5.2  思路	68
5.2.1  用户和品牌的各种特征	69
5.2.2  二分类模型训练	71
5.3  计算训练数据集	71
5.3.1  原始数据划分	72
5.3.2  计算特征	74
5.3.3  计算标签	89
5.4  二分类模型训练	90
5.4.1  正负样本配比	90
5.4.2  逻辑回归算法	92
5.4.3  随机森林算法	94
第6章  聚类与分类	96
6.1  数据可视化	97
6.2  K-Means聚类	98
6.2.1  聚类、评估流程	100
6.2.2  聚成两类	101
6.2.3  聚成三类	103
6.3  K最近邻算法	104
6.3.1  使用KNN算法进行分类	105
6.3.2  算法比较	108
6.4  多分类模型	109
6.4.1  使用朴素贝叶斯算法	109
6.4.2  使用逻辑回归多分类算法	112
6.4.3  使用随机森林算法	115
6.4.4  各多分类模型效果对比	118
第7章  葡萄酒品质预测	119
7.1  数据探索	120
7.2  线性回归	123
7.3  GBDT回归	125
第8章  文本分析	127
8.1  分词	128
8.2  词频统计	130
8.3  单词的区分度	131
8.4  字符串比较	133
8.5  抽取关键词、关键句	139
8.5.1  原理简介	139
8.5.2  完整流程	141
8.6  主题模型	146
8.6.1  LDA模型	147
8.6.2  新闻的主题模型	149
8.6.3  数据预处理	150
8.6.4  主题与原始分类的关系	153
8.7  单词映射为向量	160
8.7.1  相近单词	162
8.7.2  单词聚类	165
8.8  组件使用小结	168
第9章  基于用户退货描述的赔付预测	170
9.1  思路	171
9.2  训练集的特征生成	173
9.3  测试集的特征生成	180
9.4  模型训练、预测、评估	181
9.5  提高召回率	185
第10章  情感分析	189
10.1  词袋模型	190
10.1.1  训练集的特征生成	192
10.1.2  测试集的特征生成	196
10.1.3  模型训练、预测、评估	197
10.2  词向量模型	200
10.2.1  特征生成	201
10.2.2  模型训练	206
第11章  影片推荐	211
11.1  协同过滤	212
11.2  整体流程	213
11.3  预处理，过滤出好评信息	215
11.4  计算影片间的相似度	215
11.5  计算用户可能喜欢的影片	221
11.6  查看推荐效果	224
第12章  支持深度学习框架	227
12.1  TensorFlow组件简介	227
12.2  Softmax模型	231
12.3  深度神经网络	234
附录A	237
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习在线：解析阿里云机器学习平台
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
译者序
序
前言
审校者简介
第1章 品味机器学习 1
1.1 初步了解机器学习 1
1.2 机器学习可以解决的事情 3
1.3 初步了解 Python 4
1.4 初步了解 OpenCV 4
1.5 安装 5
1.5.1 获取本书最新的代码 5
1.5.2 掌握 Python Anaconda 6
1.5.3 在 conda 环境中安装OpenCV 8
1.5.4 验证安装结果 9
1.5.5 一睹 OpenCV ML 模块 11
1.6 总结 11
第2章 使用 OpenCV 和 Python处理数据 12
2.1 理解机器学习流程 12
2.2 使用 OpenCV 和 Python 处理数据 14
2.2.1 创建一个新的 IPython 或 Jupyter 会话 15
2.2.2 使用 Python 的 NumPy包处理数据 16
2.2.3 在 Python 中载入外部数据集 20
2.2.4 使用 Matplotlib 进行数据可视化 21
2.2.5 使用C++ 中 OpenCV 的 TrainData 容器处理数据 26
2.3 总结 27
第3章 监督学习的第一步 28
3.1 理解监督学习 28
3.1.1 了解 OpenCV 中的监督学习 29
3.1.2 使用评分函数评估模型性能 30
3.2 使用分类模型预测类别 35
3.2.1 理解 k-NN 算法 37
3.2.2 使用 OpenCV实现 k-NN 37
3.3 使用回归模型预测连续结果 43
3.3.1 理解线性回归 43
3.3.2 使用线性回归预测波士顿房价 44
3.3.3 应用 Lasso 回归和ridge 回归 48
3.4 使用逻辑回归对鸢尾花种类进行分类 48
3.5 总结 53
第4 数据表示与特征工程 54
4.1 理解特征工程 54
4.2 数据预处理 55
4.2.1 特征标准化 56
4.2.2 特征归一化 57
4.2.3 特征缩放到一定的范围 57
4.2.4 特征二值化 58
4.2.5 缺失数据处理 58
4.3 理解降维 59
4.3.1 在OpenCV 中实现主成分分析 61
4.3.2 实现独立成分分析 64
4.3.3 实现非负矩阵分解 65
4.4 类别变量表示 66
4.5 文本特征表示 68
4.6 图像表示 69
4.6.1 使用色彩空间 69
4.6.2 图像角点检测 71
4.6.3 使用尺度不变特征变换 72
4.6.4 使用加速健壮特征 74
4.7 总结 75
第5章 使用决策树进行医疗诊断 76
5.1 理解决策树 76
5.1.1 构建第一个决策树 79
5.1.2 可视化训练得到的决策树 85
5.1.3 深入了解决策树的内部工作机制 87
5.1.4 特征重要性评分 88
5.1.5 理解决策规则 89
5.1.6 控制决策树的复杂度 90
5.2 使用决策树进行乳腺癌的诊断 90
5.2.1 载入数据集 91
5.2.2 构建决策树 92
5.3 使用决策树进行回归 96
5.4 总结 99
第6章 使用支持向量机检测行人 100
6.1 理解线性支持向量机 100
6.1.1 学习最优决策边界 101
6.1.2 实现我们的第一个支持向量机 102
6.2 处理非线性决策边界 107
6.2.1 理解核机制 108
6.2.2 认识我们的核 109
6.2.3 实现非线性支持向量机 109
6.3 自然环境下的行人检测 110
6.3.1 获取数据集 111
6.3.2 初窥方向梯度直方图 113
6.3.3 生成负样本 114
6.3.4 实现支持向量机 116
6.3.5 模型自举 116
6.3.6 在更大的图像中检测行人 118
6.3.7 进一步优化模型 120
6.4 总结 121
第7章 使用贝叶斯学习实现垃圾邮件过滤 122
7.1 理解贝叶斯推断 122
7.1.1 概率论的短暂之旅 123
7.1.2 理解贝叶斯定理 124
7.1.3 理解朴素贝叶斯分类器 126
7.2 实现第一个贝叶斯分类器 127
7.2.1 创建一个练习数据集 127
7.2.2 使用一个正态贝叶斯分类器对数据分类 128
7.2.3 使用一个朴素贝叶斯分类器对数据分类 131
7.2.4 条件概率的可视化 132
7.3 使用朴素贝叶斯分类器对邮件分类 134
7.3.1 载入数据集 134
7.3.2 使用Pandas构建数据矩阵 136
7.3.3 数据预处理 137
7.3.4 训练正态贝叶斯分类器 138
7.3.5 使用完整的数据集进行训练 139
7.3.6 使用n-gram提升结果 139
7.3.7 使用TD-IDF提升结果 140
7.4 总结 141
第8章 使用非监督学习发现隐藏结构 142
8.1 理解非监督学习 142
8.2 理解k均值聚类 143
8.3 理解期望最大化 145
8.3.1 实现期望最大化解决方案 146
8.3.2 了解期望最大化的局限 148
8.4 使用k均值压缩色彩空间 154
8.4.1 真彩色调色板的可视化 154
8.4.2 使用k均值减少调色板 157
8.5 使用k均值对手写数字分类 159
8.5.1 载入数据集 159
8.5.2 运行k均值 159
8.6 把聚类组织成层次树 161
8.6.1 理解层次聚类 161
8.6.2 实现凝聚层次聚类 162
8.7 总结 163
第9章 使用深度学习对手写数字分类 164
9.1 理解McCulloch-Pitts神经元 164
9.2 理解感知器 167
9.3 实现第一个感知器 169
9.3.1 生成练习数据集 170
9.3.2 使用数据拟合感知器 171
9.3.3 评估感知器分类器 171
9.3.4 把感知器应用到线性不可分的数据上 173
9.4 理解多层感知器 174
9.4.1 理解梯度下降 175
9.4.2 使用反向传播训练多层感知器 178
9.4.3 在OpenCV中实现多层感知器 179
9.5 了解深度学习 183
9.6 手写数字分类 186
9.6.1 载入MNIST数据集 187
9.6.2 MNIST数据集预处理 188
9.6.3 使用OpenCV训练一个MLP 189
9.6.4 使用Keras训练一个深度神经网络 190
9.7 总结 192
第10章 组合不同算法为一个整体 193
10.1 理解集成方法 193
10.1.1 理解平均集成 195
10.1.2 理解提升集成 197
10.1.3 理解堆叠集成 200
10.2 组合决策树为随机森林 200
10.2.1 理解决策树的不足 200
10.2.2 实现第一个随机森林 204
10.2.3 使用scikit-learn实现一个随机森林 205
10.2.4 实现极端随机树 206
10.3 使用随机森林进行人脸识别 208
10.3.1 载入数据集 208
10.3.2 预处理数据集 209
10.3.3 训练和测试随机森林 210
10.4 实现AdaBoost 212
10.4.1 使用OpenCV实现AdaBoost 212
10.4.2 使用scikit-learn实现AdaBoost 213
10.5 组合不同模型为一个投票分类器 214
10.5.1 理解不同的投票机制 214
10.5.2 实现一个投票分类器 215
10.6 总结 217
第11章 通过超参数调优选择合适的模型 218
11.1 评估一个模型 218
11.1.1 评估模型错误的方法 219
11.1.2 评估模型正确的方法 220
11.1.3 选择最好的模型 221
11.2 理解交叉验证 223
11.2.1 使用OpenCV手动实现交叉验证 225
11.2.2 使用scikit-learn进行k折交叉验证 226
11.2.3 实现留一法交叉验证 227
11.3 使用自举评估鲁棒性 228
11.4 评估结果的重要性 230
11.4.1 实现T检验 230
11.4.2 实现配对卡方检验 232
11.5 使用网格搜索进行超参数调优 233
11.5.1 实现一个简单的网格搜索 234
11.5.2 理解验证集的价值 235
11.5.3 网格搜索结合交叉验证 236
11.5.4 网格搜索结合嵌套交叉验证 238
11.6 使用不同评估指标来对模型评分 239
11.6.1 选择正确的分类指标 239
11.6.2 选择正确的回归指标 240
11.7 链接算法形成一个管道 240
11.7.1 用 scikit-learn 实现管道 241
11.7.2 在网格搜索中使用管道 242
11.8 总结 243
第12章 综合 244
12.1 着手处理一个机器学习问题 244
12.2 构建自己的估计器 245
12.2.1 使用C++编写自己的基于OpenCV的分类器 245
12.2.2 使用Python 编写自己的基于scikit-learn的分类器 247
12.3 今后的方向 249
12.4 总结 251
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与数据科学(基于R的统计学习方法)
版权
版权声明
内容提要
前言
第1章　机器学习综述
第2章　连接数据
第3章　数据处理
第4章　探索性数据分析
第5章　回归
第6章　分类
第7章　评估模型性能
第8章　非监督学习
术语表
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习与数据科学(基于R的统计学习方法)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习理论及应用
总序前言第1章 引言第1篇 李群机器学习第2章 李群机器学习模型  2.1 引言  2.2 李群机器学习的概念  2.3 李群机器学习的代数模型  2.4 李群机器学习的几何模型  2.5 李群机器学习公理假设  2.6 李群机器学习Dynkin图的几何学习算法  2.7 李群机器学习的线形分类器设计  2.8 本章小结  参考文献  第3章 李群机器学习(LML)子空间轨道生成算法  3.1 LML中偏序集及格的基本概念  3.2 LML子空间轨道生成格学习算法  3.3 LML中一般线性群GLn(Fn)作用下学习子空间轨道生成格学习算法  3 4 本章小结  参考文献  第4章 李群机器学习的辛群学习算法  4.1 问题提出  4.2 李群机器学习中的辛群分类器设计  4.3 李群机器学与中的辛群分类器算法  4.4 应用实例  4.5 本章小结  参考文献  第5章 李群机器学习的量子群学习算法  5.1 问题提出  5.2 李群机器学习中的最干群分类器构造方法  5.3 世子群学爿算法存分子对接巾的应用  5.4 本章小结  参考文献  第6章 李群机器学习的纤堆丛学习算法  6.1 问题提出  6.2 纤维丛学习模型  6.3 纤维丛学习算法  6.4 本章小结  参考文献  第2篇 动态模糊机器学习第7章 动态模糊机器掌习模型  7.1 问题提出  7.2 动态模糊机器学习模型  7.3 动态模糊机器学习系统的相关算法  7.4 动态模糊机器学习系统的过程控制模型  7.5 动态模糊关系学习算法  7.6 本章小结  参考文献  第8章 动态模糊自主学习子空间学习算法  8.1 自主学习研究现状分析  8.2 基于DFL的自主学习子空间的理论体系  8.3 基于DFL的自主学习子空间学习算法  8.4 本章小结  参考文献  第9章 动态模糊决策树学习  9.1 决策树学习的研究现状  9.2 动态模糊格的决策树方法  9.3 动态模糊决策树特殊属性处理技术  9.4 动态模糊决策树的剪枝策略  9.5 应用  9.6 本章小结  参考文献  第10章 基于FDL的多Agent学习模型  10.1 引言  10.2 基于DFL的Agent心智模型  10.3 基于DFL的单Agent学习算法  10.4 基于DFL的多Agent学习模型   10.5 本章小结  参考文献  第3篇 其他学习方法第11章 Agent普适机器学习  11.1 引言  11.2 Agent普适机器学习  11.3 一种Agent普适机器学习分类器设计  11.4 本章小结  参考文献  第12章 贝叶斯量子随机学习算法  12.1 问题提出  12.2 相关基本理论  12.3 贝叶斯量子随机学习模型  12.4 网络结构的贝叶斯量子随机学习算法设计  12.5 网络参数的贝叶斯量子随机学习算法设计  12.6 面向缺失数据的贝叶斯量子随机学习算法设计  12.7 本章小结  参考文献   附录  附录1 拓扑群  附录2 微分几何概念  附录3 流形学习算法  附录4 辛群的基本概念和性质  附录5 量子群的基本概念  附录6 纤维丛  附录7 动态模糊集(DFS)  附录8 动态模糊(DF)关系  附录9 动态模糊逻辑  附录10 动态模糊格及其性质中英文名词对照
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习理论及应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习理论、方法及应用
《智能科学技术著作丛书》序序前言第1章  机器学习概述  1.1  机器学习的概念  1.2  机器学习的发展历史  1.3  机器学习的分类    1.3.1  基于学习策略的分类    1.3.2  基于学习方法的分类    1.3.3  基于学习方式的分类    1.3.4  基于数据形式的分类    1.3.5  基于学习目标的分类  1.4  机器学习的主要策略    1.4.1  基于神经网络的学习    1.4.2  进化学习    1.4.3  强化学习  1.5  本书主要内容及安排  1.6  本章小结  参考文献第2章  基于时间差分的神经网络预测控制  2.1  方法的提出  2.2  基于时间差分的Elman网络预测控制    2.2.1  Elman网络预测模型    2.2.2  反馈校正模型    2.2.3  参考轨迹    2.2.4  滚动优化算法  2.3  仿真研究    2.3.1  预测仿真    2.3.2  跟踪仿真  2.4  本章小结  参考文献第3章  基于径向基函数网络的机械手迭代学习控制  3.1  机械手迭代学习控制  3.2  基于RBF网络的迭代学习控制    3.2.1  选取查询点的k个最接近样例    3.2.2  利用RBF网络拟合k个数据点    3.2.3  预测查询点的控制输入  3.3  仿真研究  3.4  本章小结  参考文献第4章  自适应T-S型模糊径向基函数网络  4.1  RBF网络和模糊推理系统的功能等价性  4.2  自适应T-S型FRBF网络结构  4.3  自适应T-S型FRBF网络学习    4.3.1  网络学习动态    4.3.2  网络结构学习    4.3.3  网络参数学习    4.3.4  算法步骤  4.4  仿真研究  4.5  本章小结  参考文献第5章  基于强化学习的自适应PID控制  5.1  Actor-Critic学习  5.2  基于强化学习的自适应PID控制    5.2.1  基于强化学习的自适应PID控制结构    5.2.2  基于RBF网络的Actor-Critic学习  5.3  控制器设计步骤  5.4  仿真研究  5.5  本章小结  参考文献第6章  基于动态回归网络的强化学习控制  6.1  Q学习  6.2  基于Elman网络的强化学习控制    6.2.1  基于Elman网络的Q学习    6.2.2  Elman网络学习算法    6.2.3  基于Elman网络的Q学习方法步骤  6.3  仿真研究  6.4  本章小结  参考文献第7章  基于自适应FRBF网络的强化学习  7.1  基于自适应FRBF网络的Actor-Qitic学习    7.1.1  基于自适应FRBF网络的Actorcritic学习结构    7.1.2  自适应FRBF网络的学习    7.1.3  算法步骤    7.1.4  仿真研究  7.2  基于自适应FRBF网络的Q学习    7.2.1  基于自适应FRBF网络的Q学习结构    7.2.2  自适应FRBF网络的学习    7.2.3  算法步骤    7.2.4  仿真研究  7.3  本章小结  参考文献第8章  基于支持向量机的强化学习  8.1  SVM    8.1.1  机器学习    8.1.2  核学习    8.1.3  SVM的思想    8.1.4  SVM的重要概念  8.2  基于SVM的强化学习    8.2.1  基于SVM的Q学习结构    8.2.2  基于滚动时间窗机制的SVM    8.2.3  算法步骤    8.2.4  仿真研究  8.3  基于协同最小二乘SVM的强化学习    8.3.1  基于协同最小二乘SVM的Q学习    8.3.2  LS-SVRM逼近状态一动作对到值函数的映射关系    8.3.3  LS-SVCM逼近状态空间到动作空间的映射关系    8.3.4  仿真研究  8.4  本章小结  参考文献第9章  基于高斯过程分类器的强化学习  9.1  基于高斯过程分类器的强化学习  9.2  在线高斯过程分类器学习  9.3  算法步骤  9.4  仿真研究  9.5  本章小结  参考文献第10章  基于图上测地高斯基函数的策略迭代强化学习  10.1  环境的图论描述  10.2  测地高斯基函数  10.3  递归最小二乘策略迭代  10.4  算法步骤  10.5  仿真研究  10.6  本章小结  参考文献第11章  多目标优化问题的差分进化一分布估计算法  11.1  多目标优化  11.2  多目标优化的差分进化一分布估计算法    11.2.1  多目标优化的DE-EDA混合算法步骤    11.2.2  多目标优化的DE子代生成策略    11.2.3  多目标优化的EDA子代生成策略  11.3  实例研究  11.4  本章小结  参考文献第12章  基于细菌觅食行为的分布估计算法在预测控制中的应用  12.1  方法的提出  12.2  基于改进分布估汁算法的预测控制    12.2.1  预测模型    12.2.2  反馈校正模型    12.2.3  基于改进分布估计算法的滚动优化  12.3  实验分析    12.3.1  Benchmark函数实验    12.3.2  预测控制的曲线跟踪实验  12.4  本章小结  参考文献第13章  一种多样性保持的分布估计算法  13.1  混沌模型  13.2  多样性保持分布估计算法  13.3  Benchmark函数实验  13.4  在支持向量机参数选择中的应用    13.4.1  算法步骤    13.4.2  Chebyshev混沌时间序列预测  13.5  本章小结  参考文献附录  部分机器学习算法MATLAB源程序  程序1  第11章  多目标差分进化-分布估计算法MATLAB源程序  程序2  第12章  基于细菌觅食行为的分布估计算法部分MATLAB源程序  程序3  第13章  一种多样性保持的分布估计算法部分MATLAB程序
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习理论、方法及应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习之路——Caffe、Keras、scikit-learn实战
第一篇 机器学习篇
第1 章 初识机器学习  2
1.1 机器学习——赋予机器“学习”的灵魂  2
1.1.1 小红帽识别毒蘑菇  2
1.1.2 三种机器学习问题 6
1.1.3 常用符号  6
1.1.4 回顾  7
1.2 KNN——相似的邻居请投票 7
1.2.1 模型原理  7
1.2.2 鸢尾花卉数据集（IRIS） 9
1.2.3 训练模型  9
1.2.4 评估模型 12
1.2.5 关于KNN 14
1.2.6 运用KNN 模型 15
1.2.7 回顾  16
1.3 逻辑分类I：线性分类模型 16
1.3.1 参数化的模型  16
1.3.2 逻辑分类：预测 18
1.3.3 逻辑分类：评估 22
1.3.4 逻辑分类：训练 23
1.3.5 回顾  24
1.4 逻辑分类II：线性分类模型  24
1.4.1 寻找模型的权重 24
1.4.2 去均值和归一化 31
1.4.3 实现  33
1.4.4 回顾  34
第2 章 机器学习进阶 35
2.1 特征工程 35
2.1.1 泰坦尼克号生存预测 35
2.1.2 两类特征 38
2.1.3 构造非线性特征 41
2.1.4 回顾  45
2.2 调试模型 46
2.2.1 模型调试的目标 46
2.2.2 调试模型 49
2.2.3 回顾  52
2.3 分类模型评估指标  53
2.3.1 混淆矩阵系指标 53
2.3.2 评估曲线 58
2.3.3 回顾  61
2.4 回归模型 61
2.4.1 回归与分类 61
2.4.2 线性回归 62
2.4.3 波士顿房价预测 66
2.4.4 泰坦尼克号生存预测：回归预测特征年龄Age  69
2.4.5 线性模型与非线性模型  72
2.4.6 回顾  73
2.5 决策树模型  73
2.5.1 信息与编码 74
2.5.2 决策树  76
2.5.3 对比线性模型和决策树模型的表现 77
2.5.4 回顾  79
2.6 模型融合 80
2.6.1 融合成群体（Ensamble）  80
2.6.2 Bagging：随机森林（Random Forest） 82
2.6.3 Boosting：GBDT 83
2.6.4 Stacking  86
2.6.5 泰坦尼克号生存预测：小结 93
2.6.6 回顾  94
第3 章 实战：股票量化  95
3.1 第一步：构造童话世界 95
3.1.1 股票是什么 95
3.1.2 当机器学习与量化交易走在一起  96
3.1.3 构造一个童话世界  96
3.1.4 回顾 100
3.2 第二步：应用机器学习  100
3.2.1 构建特征数据 100
3.2.2 回归预测股票价格  103
3.2.3 分类预测股票涨跌  108
3.2.4 通过决策树分类，绘制决策图 112
3.2.5 回顾 114
3.3 第三步：在真实世界应用机器学习  114
3.3.1 回测 115
3.3.2 基于特征的交易预测  119
3.3.3 破灭的童话——真实世界的机器学习 122
第二篇 深度学习篇
第4 章 深度学习：背景和工具  126
4.1 背景 126
4.1.1 人工智能——为机器赋予人的智能  126
4.1.2 图灵测试  126
4.1.3 强人工智能 vs 弱人工智能  127
4.1.4 机器学习和深度学习  128
4.1.5 过度的幻想  128
4.1.6 回顾 129
4.2 深度学习框架简介 129
4.2.1 评测方式  130
4.2.2 评测对象  131
4.2.3 深度学习框架评测  131
4.2.4 小结 135
4.3 深度学习框架快速上手  135
4.3.1 符号主义  135
4.3.2 MNIST  136
4.3.3 Keras 完成逻辑分类  138
4.3.4 回顾 141
4.4 Caffe 实现逻辑分类模型 141
4.4.1 Caffe 训练MNIST 概览  142
4.4.2 Caffe 简介  144
4.4.3 准备数据集  145
4.4.4 准备模型  146
4.4.5 模型训练流程 149
4.4.6 使用模型  149
4.4.7 Caffe 的Python 接口  150
4.4.8 回顾 151
第5 章 深层学习模型  152
5.1 解密生物智能  154
5.1.1 实验一：大脑的材料  154
5.1.2 实验二：探索脑皮层的功能区域  156
5.1.3 实验三：不同的皮层组织——区别在于函数算法  158
5.1.4 实验四：可替换的皮层模块——神经元组成的学习模型  161
5.1.5 模拟神经元  162
5.1.6 生物结构带来的启发  163
5.1.7 回顾 164
5.2 DNN 神经网络模型  164
5.2.1 线性内核和非线性激活 164
5.2.2 DNN、CNN、RNN 165
5.2.3 逻辑分类：一层神经网络  166
5.2.4 更多的神经元 167
5.2.5 增加Hidden Layer（隐层）  168
5.2.6 ReLu 激活函数  170
5.2.7 理解隐层  171
5.2.8 回顾 172
5.3 神经元的深层网络结构  172
5.3.1 问题：更宽 or 更深  172
5.3.2 链式法则：深层模型训练更快 173
5.3.3 生物：深层模型匹配生物的层级识别模式  175
5.3.4 深层网络结构 177
5.3.5 回顾 178
5.4 典型的DNN 深层网络模型：MLP  178
5.4.1 优化梯度下降 179
5.4.2 处理过拟合：Dropout  181
5.4.3 MLP 模型  182
5.4.4 回顾 185
5.5 Caffe 实现MLP  185
5.5.1 搭建MLP  185
5.5.2 训练模型  189
5.5.3 回顾 190
第6 章 学习空间特征  191
6.1 预处理空间数据  192
6.1.1 像素排列展开的特征向量带来的问题 192
6.1.2 过滤冗余  194
6.1.3 生成数据  195
6.1.4 回顾 198
6.2 描述图片的空间特征：特征图  199
6.2.1 图片的卷积运算. 199
6.2.2 卷积指令和特征图  201
6.2.3 回顾 206
6.3 CNN 模型I：卷积神经网络原理  206
6.3.1 卷积神经元  207
6.3.2 卷积层  208
6.3.3 多层卷积  211
6.3.4 回顾 216
6.4 CNN 模型II：图片识别 216
6.4.1 连接分类模型 216
6.4.2 猫狗分类  217
6.4.3 反思CNN 与DNN 的结合：融合训练  221
6.4.4 深度学习与生物视觉  222
6.4.5 回顾 224
6.5 CNN 的实现模型 224
6.5.1 ImageNet 简介 224
6.5.2 Googlenet 模型和Inception 结构 226
6.5.3 VGG 模型  228
6.5.4 其他模型  231
6.5.5 回顾 232
6.6 微训练模型（fine-tuning）  232
6.6.1 二次训练一个成熟的模型  232
6.6.2 微训练在ImageNet 训练好的模型 233
6.6.3 回顾 239
第7 章 Caffe 实例：狗狗品种辨别  240
7.1 准备图片数据  240
7.1.1 搜集狗狗图片 240
7.1.2 清洗数据  241
7.1.3 标准化数据  242
7.1.4 回顾 243
7.2 训练模型  243
7.2.1 生成样本集  244
7.2.2 生成训练、测试数据集 245
7.2.3 生成lmdb  246
7.2.4 生成去均值文件. 247
7.2.5 更改prototxt 文件 247
7.2.6 训练模型  249
7.2.7 回顾 249
7.3 使用生成的模型进行分类 249
7.3.1 更改deploy.prototxt 249
7.3.2 加载模型  250
7.3.3 回顾 257
第8 章 漫谈时间序列模型 258
8.1 Embedding  259
8.1.1 简单的文本识别. 260
8.1.2 深度学习从读懂词义开始  261
8.1.3 游戏：词义运算. 264
8.1.4 回顾 264
8.2 输出序列的模型  265
8.2.1 RNN 265
8.2.2 LSTM  266
8.2.3 并用人工特征和深度学习特征——一个NLP 模型的优化历程  268
8.2.4 反思：让模型拥有不同的能力 270
8.2.5 回顾 273
8.3 深度学习：原理篇总结  273
8.3.1 原理小结  273
8.3.2 使用建议  275
第9 章 用深度学习做个艺术画家——模仿实现PRISMA  277
9.1 机器学习初探艺术作画  278
9.1.1 艺术作画概念基础  278
9.1.2 直观感受一下机器艺术家  279
9.1.3 一个有意思的实验  280
9.1.4 机器艺术作画的愿景  281
9.1.5 回顾 282
9.2 实现秒级艺术作画 282
9.2.1 主要实现思路分解讲解 283
9.2.2 使用统计参数期望与标准差寻找mask  290
9.2.3 工程代码封装结构及使用示例 299
9.2.4 回顾和后记  302
附录A 机器学习环境部署 303
附录B 深度学习环境部署 307
附录C 随书代码运行环境部署  312
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习之路——Caffe、Keras、scikit-learn实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习及其应用2013
Learning Sparse Topical Representations
1  Introduction
2  Related Work
2.1  Probabilistic LDA
2.2  Non-negative Matrix Faetorization
3  Sparse Topical Coding
3.1  A Probabilistic Generative Process
3.2  STC for MAP Estimation
3.3  Optimization with Coordinate Descent
4  Extensions
4.1  Collapsed STC
4.2  Supervised Sparse Topical Coding
5  Experiments
5.1  Sparse Word Code
5.2  Prediction Accuracy
5.3  Time Efficiency
6  Conclusion
References
多视图在利用未标记数据学习中的效用
1  引言
2  多视图在半监督学习中的效用
3  多视图在主动学习中的效用
4  多视图在主动半监督学习中的效用
5  视图分割
6  结束语
参考文献
知识挖掘与用户建模
1  引言
2  技术综述
3  本体知识体系构建
3.1  知识挖掘
3.2  知识加工
3.3  语义计算
3.4  实验结果
3.5  基于本体知识的需求主题体系构建
4  跨产品用户日志挖掘
4.1  技术框架
4.2  跨产品用户数据scssion分割
4.3  跨产品用户数据关注点挖掘
5  用户建模
5.1  用户属性建模
5.2  用户兴趣建模
5.3  用户状态建模
5.4  多维度用户行为分析模型
5.5  用户兴趣模型的地域性关联分析
6  结语
参考文献
异质人脸图像合成
1  引言
2  基于子空间学习的图像合成方法
2.1  基于线性子空间学习的方法
2.2  基于流形学习的方法
3  基于贝叶斯推理的合成方法
3.1  基于嵌入式隐马尔科夫模型的方法
3.2  基于马尔科夫随机场的方法
4  基于人脸幻像思想的合成方法
5  实验结果
6  结束语
参考文献
面向高维多视图数据的广义相关分析
1  引言
1.1  多视图数据
1.2  数据降维的意义与方法
2  基于相关分析的降维方法所面临的问题与解决方案
2.1  忽视多视图数据的监督信息
2.2  要求不同视图间的数据全配对
2.3  现有解决方案
3  我们的研究工作
3.1  半配对局部相关分析
3.2  半监督半配对广义相关分析
3.3  邻域相关分析
4  小结
参考文献
基于向量场的流形学习和排序
1  引言
2  平行向量场和线性函数
2.1  流形上半监督学习问题
2.2  平行向量场和线性函数
2.3  目标函数
3  离散化和优化
3.1  切空间和向量场离散化
3.2  梯度场计算
3.3  平行向量场计算
3.4  离散形式的目标函数
3.5  目标函数优化
4  基于平行向量场正则化的排序
4.1  向量场正则化
4.2  尺1和及2的离散化
4.3  目标函数离散化
4.4  目标函数优化
4.5  实验
5  结束语与展望
参考文献
秩极小化：理论、算法与应用
1  引言
2  主要数学模型
3  理论分析
4  算法
4.1  加速近邻梯度法及其推广
4.2  交错方向法及其线性化
4.3  奇异值分解的计算
5  应用
5.1  背景建模
5.2  图像批量对齐
5.3  变换不变低秩纹理
5.4  运动分割
5.5  图像分割
5.6  图像显著区域检测
6  结束语
参考文献
实值多变量维数约简
1  引言
2  实值多变量维数约简
2.1  切片逆回归法
2.2  切片逆回归的推广
2.3  主Hessian方向
2.4  子空间简介
2.5  稀疏充分维数约简
2.6  核维数约简
2.7  最小平方维数约简
3  树形结构的核维数约简
3.1  动机
3.2  树形算法的介绍
3.3  (残差)树形核维数约简
3.4  实验部分
3.5  结论
4  核维数约简在人群计数中的应用
4.1  核维数约简
4.2  多核学习
5  结论
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习及其应用2013
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习精讲
译者序
前言
第1章引言
1.1教计算机区分猫和狗
1.2预测学习问题
1.2.1回归
1.2.2分类
1.3特征设计
1.4数值优化
1.5小结
第一部分基本工具及概念
第2章数值优化基础
2.1微积分定义的最优性
2.1.1泰勒级数逼近
2.1.2最优性的一阶条件
2.1.3凸性的便利
2.2优化数值方法
2.2.1概览
2.2.2停止条件
2.2.3梯度下降
2.2.4牛顿法
2.3小结
2.4习题
第3章回归
3.1线性回归基础
3.1.1符号和建模
3.1.2用于线性回归的最小二乘代价函数
3.1.3最小二乘代价函数的最小化
3.1.4所学模型的效力
3.1.5预测新输入数据的值
3.2知识驱动的回归特征设计
3.3非线性回归和l2正则化
3.3.1逻辑回归
3.3.2非凸代价函数和l2正则化
3.4小结
3.5习题
第4章分类
4.1感知机代价函数
4.1.1基本感知机模型
4.1.2softmax代价函数
4.1.3间隔感知机
4.1.4间隔感知机的可微近似
4.1.5所学分类器的精度
4.1.6预测新输入数据的标签
4.1.7哪个代价函数会产生最好的结果
4.1.8感知机和计数代价的关联
4.2逻辑回归视角下的softmax代价
4.2.1阶梯函数和分类
4.2.2凸逻辑回归
4.3支持向量机视角下的间隔感知机
4.3.1寻找最大间隔超平面
4.3.2硬间隔支持向量机问题
4.3.3软间隔支持向量机问题
4.3.4支持向量机和逻辑回归
4.4多分类
4.4.1一对多的多分类
4.4.2多分类softmax分类
4.4.3所学多分类器的精度
4.4.4哪种多分类方法表现最好
4.5面向分类的知识驱动特征设计
4.6面向真实数据类型的直方图特征
4.6.1文本数据的直方图特征
4.6.2图像数据的直方图特征
4.6.3音频数据的直方图特征
4.7小结
4.8习题
第二部分完全数据驱动的机器学习工具
第5章回归的自动特征设计
5.1理想回归场景中的自动特征设计
5.1.1向量逼近
5.1.2从向量到连续函数
5.1.3连续函数逼近
5.1.4连续函数逼近的常见基
5.1.5获取权重
5.1.6神经网络的图表示
5.2真实回归场景中的自动特征设计
5.2.1离散化的连续函数逼近
5.2.2真实回归场景
5.3回归交叉验证
5.3.1诊断过拟合与欠拟合问题
5.3.2留出交叉验证
5.3.3留出交叉验证的计算
5.3.4k折交叉验证
5.4哪个基最好
5.4.1理解数据背后的现象
5.4.2实践方面的考虑
5.4.3什么时候可任意选择基
5.5小结
5.6习题
5.7关于连续函数逼近的注释
第6章分类中的自动特征设计
6.1理想分类场景中的自动特征设计
6.1.1分段连续函数逼近
6.1.2指示函数的形式化定义
6.1.3指示函数逼近
6.1.4获取权重
6.2真实分类场景中的自动特征设计
6.2.1离散化的指示函数逼近
6.2.2真实的分类场景
6.2.3分类器精度和边界定义
6.3多分类
6.3.1一对多的多分类
6.3.2多分类softmax分类
6.4分类交叉验证
6.4.1留出交叉验证
6.4.2留出交叉验证的计算
6.4.3k折交叉验证
6.4.4一对多多分类的k折交叉验证
6.5哪个基最好
6.6小结
6.7习题
第7章核、反向传播和正则化交叉验证
7.1固定特征核
7.1.1线性代数基本定理
7.1.2核化代价函数
7.1.3核化的价值
7.1.4核的例子
7.1.5核作为相似矩阵
7.2反向传播算法
7.2.1计算两层网络代价函数的梯度
7.2.2计算三层神经网络的梯度
7.2.3动量梯度下降
7.3l2正则化交叉验证
7.3.1l2正则化和交叉验证
7.3.2回归的k折正则化交叉验证
7.3.3分类的正则化交叉验证
7.4小结
7.5更多的核计算
7.5.1核化不同的代价函数
7.5.2傅里叶核——标量输入
7.5.3傅里叶核——向量输入
第三部分大规模数据机器学习方法
第8章高级梯度算法
8.1梯度下降法的固定步长规则
8.1.1梯度下降法和简单的二次代理
8.1.2有界曲率函数和最优保守步长规则
8.1.3如何使用保守固定步长规则
8.2梯度下降的自适应步长规则
8.2.1回溯线性搜索的自适应步长规则
8.2.2如何使用自适应步长规则
8.3随机梯度下降
8.3.1梯度分解
8.3.2随机梯度下降迭代
8.3.3随机梯度下降的价值
8.3.4随机梯度下降的步长规则
8.3.5在实践中如何使用随机梯度下降法
8.4梯度下降方案的收敛性证明
8.4.1利普希茨常数固定步长梯度下降的收敛性
8.4.2回溯线性搜索梯度下降的收敛性
8.4.3随机梯度法的收敛性
8.4.4面向凸函数的固定步长梯度下降的收敛速度
8.5计算利普希茨常数
8.6小结
8.7习题
第9章降维技术
9.1数据的降维技术
9.1.1随机子采样
9.1.2K均值聚类
9.1.3K均值问题的优化
9.2主成分分析
9.3推荐系统
9.3.1矩阵填充模型
9.3.2矩阵填充模型的优化
9.4小结
9.5习题
第四部分附录
附录A基本的向量和矩阵运算
附录B向量微积分基础
附录C基本的矩阵分解及伪逆
附录D凸几何
参考文献
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习精讲
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
第1章　机器学习理论简述　　1
1.1 经验误差最小化 　　2
1.1.1 假设与定义　　2
1.1.2 原理陈述 　　4
1.2 经验风险最小化原理的一致性　　4
1.2.1 在测试集上估计泛化误差　　6
1.2.2 泛化误差的一致边界　　7
1.2.3 结构风险最小化　　15
1.3 依赖于数据的泛化误差界　　17
1.3.1 Rademacher 复杂度　　17
1.3.2 Rademacher 复杂度和VC 维的联系　　17
1.3.3 利用Rademacher 复杂度获取泛化界的步骤　　19
1.3.4 Rademacher 复杂度的性质　　23
第2章　无约束凸优化算法　　26
2.1 梯度法　　29
2.1.1 批处理模式　　29
2.1.2 在线模式　　31
2.2 拟牛顿法　　32
2.2.1 牛顿方向　　32
2.2.2 Broyden-Fletcher-Goldfarb-Shanno 公式　　33
2.3 线搜索　　36
2.3.1 Wolfe 条件　　37
2.3.2 基于回溯策略的线搜索　　41
2.4 共轭梯度法　　43
2.4.1 共轭方向　　43
2.4.2 共轭梯度算法　　46
第3章　二类分类　　48
3.1 感知机　　48
3.1.1 感知机的收敛性定理　　51
3.1.2 带间隔感知机及其与经验风险最小化原理的联系　　53
3.2 Adaline　　54
3.2.1 与线性回归和经验风险最小化原理的联系　　54
3.3 Logistic 回归  　　56
3.3.1 与经验风险最小化原理的联系　　57
3.4 支持向量机　　58
3.4.1 硬间隔　　58
3.4.2 软间隔　　63
3.4.3 基于间隔的泛化误差界　　66
3.5 AdaBoost　　68
3.5.1 与经验风险最小化原理的联系　　70
3.5.2 拒绝法抽样　　72
3.5.3 理论研究　　73
第4章　多类分类　　76
4.1 形式表述　　76
4.1.1 分类误差　　77
4.1.2 泛化误差界　　77
4.2 单一法　　80
4.2.1 多类支持向量机　　80
4.2.2 多类AdaBoost　　84
4.2.3 多层感知机　　87
4.3 组合二类分类算法的模型　　91
4.3.1 一对全　　91
4.3.2 一对一　　92
4.3.3 纠错码　　93
第5章　半监督学习　　95
5.1 无监督框架和基本假设　　95
5.1.1 混合密度模型　　96
5.1.2 估计混合参数　　96
5.1.3 半监督学习的基本假设　　102
5.2 生成法　　104
5.2.1 似然准则在半监督学习情形的推广　　104
5.2.2 半监督CEM 算法　　105
5.2.3 应用：朴素贝叶斯分类器的半监督学习　　106
5.3 判别法　　108
5.3.1 自训练算法 　　109
5.3.2 转导支持向量机　　111
5.3.3 贝叶斯分类器误差的转导界　　113
5.3.4 基于伪标注的多视角学习　　116
5.4 图法　　118
5.4.1 标注的传播 　　119
5.4.2 马尔可夫随机游动　　121
第6章　排序学习　　123
6.1 形式表述　　123
6.1.1 排序误差函数　　124
6.1.2 样例排序　　127
6.1.3 备择排序　　128
6.2 方法　　130
6.2.1 单点法 　　130
6.2.2 成对法 　　135
6.3 互相关数据的学习 　　144
6.3.1 测试界 　　146
6.3.2 泛化界 　　146
6.3.3 一些具体例子中的界的估计　　151
附录　回顾和补充　　155
附录A　概率论回顾　　156
A.1 概率测度　　156
A.1.1 可概率化空间　　156
A.1.2 概率空间　　157
A.2 条件概率　　158
A.2.1 贝叶斯公式　　158
A.2.2 独立性　　159
A.3 实随机变量  　　159
A.3.1 分布函数　　160
A.3.2 随机变量的期望和方差　　161
A.3.3 集中不等式　　162
附录B　程序代码　　166
B.1 数据结构　　166
B.1.1 数据集　　166
B.1.2 超参数结构　　167
B.2 稀疏表示　　168
B.3 程序运行　　170
B.4 代码　　172
B.4.1 BGFS 算法（2.2.2 节）　　172
B.4.2 线搜索（2.3 节）  　　175
B.4.3 共轭梯度法（2.4 节）　　178
B.4.4 感知机（3.1 节）  　　180
B.4.5 Adaline 算法（3.2 节）　　181
B.4.6 Logistic 回归（3.3 节）　　182
B.4.7 AdaBoost 算法（3.5 节）　　184
B.4.8 AdaBoost M2 算法（4.2.2 节）　　188
B.4.9 多层感知机（4.2.3 节）　　192
B.4.10 K-均值算法（5.1.2 节）　　195
B.4.11 半监督朴素贝叶斯（5.2.3 节）  　　197
B.4.12 自学习（5.3.1 节） 　　201
B.4.13 一次性自学习（5.3.1 节） 　　204
B.4.14 PRank 算法（6.2.1 节）　　205
B.4.15 RankBoost 算法（6.2.2 节）　　207
参考文献　　211
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
序言
第 一章 机器学习概述 1
1．1 机器学习简介 1
1．1．1 机器学习简史 1
1．1．2 机器学习主要流派 2
1．2 机器学习、人工智能和数据挖掘 4
1．2．1 什么是人工智能 4
1．2．2 机器学习、人工智能与数据挖掘 5
1．3 典型机器学习应用领域 5
1．4 机器学习算法 12
1．5 机器学习的一般流程 20
第 二章 机器学习基本方法 23
2．1 统计分析 23
2．1．1 统计基础 23
2．1．2 常见概率分布 29
2．1．3 参数估计 31
2．1．4 假设检验 33
2．1．5 线性回归 33
2．1．6 Logistics回归 37
2．1．7 判别分析 38
2．1．8 非线性模型 39
2．2 高维数据降维 40
2．2．1 主成分分析 40
2．2．2 线性判别分析 43
2．2．3 局部线性嵌入 47
2．3 特征工程 48
2．3．1 特征构造 48
2．3．2 特征选择 49
2．3．3 特征提取 50
2．4 模型训练 50
2．4．1 模型训练常见术语 50
2．4．2 训练数据收集 51
2．5 可视化分析 52
2．5．1 可视化分析的作用 52
2．5．2 可视化分析方法 53
2．5．3 可视化分析常用工具 54
2．5．4 常见的可视化图表 56
2．5．5 可视化分析面临的挑战 62
第三章 决策树与分类算法 64
3．1 决策树算法 64
3．1．1 分支处理 66
3．1．2 连续属性离散化 72
3．1．3 过拟合问题 74
3．1．4 分类效果评价 78
3．2 集成学习 83
3．2．1 装袋法 83
3．2．2 提升法 84
3．2．3 GBDT 86
3．2．4 随机森林 87
3．3 决策树应用 89
第四章 聚类分析 95
4．1 聚类分析概念 95
4．1．1 聚类方法分类 95
4．1．2 良好聚类算法的特征 97
4．2 聚类分析的度量 97
4．2．1 外部指标 98
4．2．2 内部指标 99
4．3 基于划分的方法 101
4．3．1 k-均值算法 101
4．3．2 k-medoids算法 106
4．3．3 k-prototype算法 107
4．4 基于密度聚类 107
4．4．1 DBSCAN算法 108
4．4．2 OPTICS算法 110
4．4．3 DENCLUE算法 111
4．5 基于层次的聚类 116
4．5．1 BIRCH聚类 117
4．5．2 CURE算法 120
4．6 基于网格的聚类 122
4．7 基于模型的聚类 123
4．7．1 概率模型聚类 123
4．7．2 模糊聚类 129
4．7．3 Kohonen神经网络聚类 129
第五章 文本分析 137
5．1 文本分析介绍 137
5．2 文本特征提取及表示 138
5．2．1 TF-IDF 138
5．2．2 信息增益 139
5．2．3 互信息 139
5．2．4 卡方统计量 140
5．2．5 词嵌入 141
5．2．6 语言模型 142
5．2．7 向量空间模型 144
5．3 知识图谱 146
5．3．1 知识图谱相关概念 147
5．3．2 知识图谱的存储 147
5．3．3 知识图谱挖掘与计算 148
5．3．4 知识图谱的构建过程 150
5．4 词法分析 155
5．4．1 文本分词 156
5．4．2 命名实体识别 159
5．4．3 词义消歧 160
5．5 句法分析 161
5．6 语义分析 163
5．7 文本分析应用 164
5．7．1 文本分类 164
5．7．2 信息抽取 167
5．7．3 问答系统 168
5．7．4 情感分析 169
5．7．5 自动摘要 171
第六章 神经网络 173
6．1 神经网络介绍 173
6．1．1 前馈神经网络 173
6．1．2 反馈神经网络 176
6．1．3 自组织神经网络 179
6．2 神经网络相关概念 180
6．2．1 激活函数 180
6．2．2 损失函数 184
6．2．3 学习率 185
6．2．4 过拟合 188
6．2．5 模型训练中的问题 189
6．2．6 神经网络效果评价 192
6．3 神经网络应用 192
第七章 贝叶斯网络 197
7．1 贝叶斯理论概述 197
7．1．1 贝叶斯方法的基本观点 197
7．1．2 贝叶斯网络的应用 198
7．2 贝叶斯概率基础 198
7．2．1 概率论 198
7．2．2 贝叶斯概率 199
7．3 朴素贝叶斯分类模型 200
7．4 贝叶斯网络 203
7．5 贝叶斯网络的应用 209
7．5．1 中文分词 210
7．5．2 机器翻译 210
7．5．3 故障诊断 211
7．5．4 疾病诊断 211
第八章 支持向量机 215
8．1 支持向量机模型 215
8．1．1 核函数 215
8．1．2 模型原理分析 216
8．2 支持向量机应用 219
第九章 进化计算 226
9．1 遗传算法的基础 226
9．1．1 基因重组（交叉）与基因突变 227
9．1．2 遗传算法实现技术 228
9．1．3 遗传算法案例 234
9．2 蚁群算法 237
9．2．1 蚁群算法应用案例 238
9．3 蜂群算法简介 239
9．3．1 蜂群算法应用案例 241
第十章 分布式机器学习 245
10．1 分布式机器学习基础 245
10．1．1 参数服务器 245
10．1．2 分布式并行计算类型 246
10．2 分布式机器学习框架 247
10．3 并行决策树 254
10．4 并行k-均值算法 255
第十一章 深度学习 258
11．1 卷积神经网络 258
11．1．1 卷积神经网络的整体结构 259
11．1．2 常见卷积神经网络 262
11．2 循环神经网络 271
11．2．1 RNN基本原理 271
11．2．2 长短期记忆网络 274
11．2．3 门限循环单元 277
11．3 深度学习流行框架 278
第十二章 高等级深度学习 281
12．1 高等级卷积神经网络 281
12．1．1 目标检测与追踪 281
12．1．2 目标分割 295
12．2 高等级循环神经网络应用 301
12．2．1 Encoder-Decoder模型 301
12．2．2 注意力模型 301
12．2．3 LSTM高等级应用 302
12．3 无监督式深度学习 307
12．3．1 深度信念网络 307
12．3．2 自动编码器网络 309
12．3．3 生成对抗网络模型 312
12．4 强化学习 316
12．4．1 增强学习基础 316
12．4．2 深度增强学习 318
12．5 迁移学习 321
12．6 对偶学习 324
第十三章 推荐系统 327
13．1 推荐系统介绍 327
13．1．1 推荐系统的应用场景 327
13．2 推荐系统通用模型 329
13．2．1 推荐系统结构 329
13．2．2 基于内容的推荐 330
13．2．3 基于协同过滤的推荐算法 331
13．2．4 基于图的模型 334
13．2．5 基于关联规则的推荐 335
13．2．6 基于知识的推荐 341
13．2．7 基于标签的推荐 342
13．3 推荐系统评测 343
13．3．1 评测方法 343
13．3．2 评测指标 345
13．4 推荐系统常见问题 349
13．4．1 冷启动问题 349
13．4．2 推荐系统注意事项 351
13．5 推荐系统实例 352
第十四章 实验 364
14．1 华为FusionInsight产品平台介绍 364
14．2 银行定期存款业务预测 365
14．2．1 上传银行客户及存贷款数据 366
14．2．2 准备存款业务分析工作区 367
14．2．3 创建数据挖掘流程 368
14．2．4 定期存款业务模型保存和应用 375
14．3 客户分群 378
14．3．1 分析业务需求 379
14．3．2 上传客户信息数据 381
14．3．3 准备客户分群工作区 382
14．3．4 创建数据挖掘流程 383
14．3．5 客户分群模型保存和应用 392
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Java机器学习
第1章　机器学习应用快速入门　　1
1.1　机器学习与数据科学　　1
1.1.1　机器学习能够解决的问题　　2
1.1.2　机器学习应用流程　　3
1.2　数据与问题定义　　4
1.3　数据收集　　5
1.3.1　发现或观察数据　　5
1.3.2　生成数据　　6
1.3.3　采样陷阱　　7
1.4　数据预处理　　7
1.4.1　数据清洗　　8
1.4.2　填充缺失值　　8
1.4.3　剔除异常值　　8
1.4.4　数据转换　　9
1.4.5　数据归约　　10
1.5　无监督学习　　10
1.5.1　查找相似项目　　10
1.5.2　聚类　　12
1.6　监督学习　　13
1.6.1　分类　　14
1.6.2　回归　　16
1.7　泛化与评估　　18
1.8　小结　　21
第2章　面向机器学习的Java库与平台　　22
2.1　Java环境　　22
2.2　机器学习库　　23
2.2.1　Weka　　23
2.2.2　Java机器学习　　25
2.2.3　Apache Mahout　　26
2.2.4　Apache Spark　　27
2.2.5　Deeplearning4j　　28
2.2.6　MALLET　　29
2.2.7　比较各个库　　30
2.3　创建机器学习应用　　31
2.4　处理大数据　　31
2.5　小结　　33
第3章　基本算法——分类、回归和聚类　　34
3.1　开始之前　　34
3.2　分类　　35
3.2.1　数据　　35
3.2.2　加载数据　　36
3.2.3　特征选择　　37
3.2.4　学习算法　　38
3.2.5　对新数据分类　　40
3.2.6　评估与预测误差度量　　41
3.2.7　混淆矩阵　　41
3.2.8　选择分类算法　　42
3.3　回归　　43
3.3.1　加载数据　　43
3.3.2　分析属性　　44
3.3.3　创建与评估回归模型　　45
3.3.4　避免常见回归问题的小技巧　　48
3.4　聚类　　49
3.4.1　聚类算法　　49
3.4.2　评估　　50
3.5　小结　　51
第4章　利用集成方法预测客户关系　　52
4.1　客户关系数据库　　52
4.1.1　挑战　　53
4.1.2　数据集　　53
4.1.3　评估　　54
4.2　最基本的朴素贝叶斯分类器基准　　55
4.2.1　获取数据　　55
4.2.2　加载数据　　56
4.3　基准模型　　58
4.3.1　评估模型　　58
4.3.2　实现朴素贝叶斯基准线　　59
4.4　使用集成方法进行高级建模　　60
4.4.1　开始之前　　60
4.4.2　数据预处理　　61
4.4.3　属性选择　　62
4.4.4　模型选择　　63
4.4.5　性能评估　　66
4.5　小结　　66
第5章　关联分析　　67
5.1　购物篮分析　　67
5.2　关联规则学习　　69
5.2.1　基本概念　　69
5.2.2　Apriori算法　　71
5.2.3　FP-增长算法　　71
5.2.4　超市数据集　　72
5.3　发现模式　　73
5.3.1　Apriori算法　　73
5.3.2　FP-增长算法　　74
5.4　在其他领域中的应用　　75
5.4.1　医疗诊断　　75
5.4.2　蛋白质序列　　75
5.4.3　人口普查数据　　76
5.4.4　客户关系管理　　76
5.4.5　IT运营分析　　76
5.5　小结　　77
第6章　使用Apache Mahout制作推荐引擎　　78
6.1　基本概念　　78
6.1.1　关键概念　　79
6.1.2　基于用户与基于项目的分析　　79
6.1.3　计算相似度的方法　　80
6.1.4　利用与探索　　81
6.2　获取Apache Mahout　　81
6.3　创建一个推荐引擎　　84
6.3.1　图书评分数据集　　84
6.3.2　加载数据　　84
6.3.3　协同过滤　　89
6.4　基于内容的过滤　　97
6.5　小结　　97
第7章　欺诈与异常检测　　98
7.1　可疑与异常行为检测　　98
7.2　可疑模式检测　　99
7.3　异常模式检测　　100
7.3.1　分析类型　　100
7.3.2　事务分析　　101
7.3.3　规划识别　　101
7.4　保险理赔欺诈检测　　101
7.4.1　数据集　　102
7.4.2　为可疑模式建模　　103
7.5　网站流量异常检测　　107
7.5.1　数据集　　107
7.5.2　时序数据中的异常检测　　108
7.6　小结　　113
第8章　利用Deeplearning4j进行图像识别　　114
8.1　图像识别简介　　114
8.2　图像分类　　120
8.2.1　Deeplearning4j　　120
8.2.2　MNIST数据集　　121
8.2.3　加载数据　　121
8.2.4　创建模型　　122
8.3　小结　　128
第9章　利用手机传感器进行行为识别　　129
9.1　行为识别简介　　129
9.1.1　手机传感器　　130
9.1.2　行为识别流水线　　131
9.1.3　计划　　132
9.2　从手机收集数据　　133
9.2.1　安装Android Studio　　133
9.2.2　加载数据采集器　　133
9.2.3　收集训练数据　　136
9.3　创建分类器　　138
9.3.1　减少假性转换　　140
9.3.2　将分类器嵌入移动应用　　142
9.4　小结　　143
第10章　利用Mallet进行文本挖掘——主题模型与垃圾邮件检测　　144
10.1　文本挖掘简介　　144
10.1.1　主题模型　　145
10.1.2　文本分类　　145
10.2　安装Mallet　　146
10.3　使用文本数据　　147
10.3.1　导入数据　　149
10.3.2　对文本数据做预处理　　150
10.4　为BBC新闻做主题模型　　152
10.4.1　BBC数据集　　152
10.4.2　建模　　153
10.4.3　评估模型　　155
10.4.4　重用模型　　156
10.5　垃圾邮件检测　　157
10.5.1　垃圾邮件数据集　　158
10.5.2　特征生成　　159
10.5.3　训练与测试模型　　160
10.6　小结　　161
第11章　机器学习进阶　　162
11.1　现实生活中的机器学习　　162
11.1.1　噪声数据　　162
11.1.2　类不平衡　　162
11.1.3　特征选择困难　　163
11.1.4　模型链　　163
11.1.5　评价的重要性　　163
11.1.6　从模型到产品　　164
11.1.7　模型维护　　164
11.2　标准与标记语言　　165
11.2.1　CRISP-DM　　165
11.2.2　SEMMA方法　　166
11.2.3　预测模型标记语言　　166
11.3　云端机器学习　　167
11.4　Web资源与比赛　　168
11.4.1　数据集　　168
11.4.2　在线课程　　169
11.4.3　比赛　　170
11.4.4　网站与博客　　170
11.4.5　场馆与会议　　171
11.5　小结　　171
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Java机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘(实用机器学习工具与技术原书第4版)/智能科学与技术丛书
译者序
前言
致谢
第一部分　数据挖掘基础
第1章　绪论 2
1.1　数据挖掘和机器学习 2
1.1.1　描述结构模式 3
1.1.2　机器学习 5
1.1.3　数据挖掘 6
1.2　简单的例子：天气问题和其他问题 6
1.2.1　天气问题 6
1.2.2　隐形眼镜：一个理想化的问题 8
1.2.3　鸢尾花：一个经典的数值型数据集 9
1.2.4　CPU性能：引入数值预测 10
1.2.5　劳资协商：一个更真实的例子 11
1.2.6　大豆分类：一个经典的机器学习的成功例子 12
1.3　应用领域 14
1.3.1　Web挖掘 14
1.3.2　包含判断的决策 15
1.3.3　图像筛选 15
1.3.4　负载预测 16
1.3.5　诊断 17
1.3.6　市场和销售 17
1.3.7　其他应用 18
1.4　数据挖掘过程 19
1.5　机器学习和统计学 20
1.6　将泛化看作搜索 21
1.6.1　枚举概念空间 22
1.6.2　偏差 22
1.7　数据挖掘和道德问题 24
1.7.1　再识别 24
1.7.2　使用个人信息 25
1.7.3　其他问题 26
1.8　拓展阅读及参考文献 26
第2章　输入：概念、实例和属性 29
2.1　概念 29
2.2　实例 31
2.2.1　关系 31
2.2.2　其他实例类型 34
2.3　属性 35
2.4　输入准备 36
2.4.1　数据收集 37
2.4.2　ARFF格式 37
2.4.3　稀疏数据 39
2.4.4　属性类型 40
2.4.5　缺失值 41
2.4.6　不正确的值 42
2.4.7　非均衡数据 42
2.4.8　了解数据 43
2.5　拓展阅读及参考文献 43
第3章　输出：知识表达 44
3.1　表 44
3.2　线性模型 44
3.3　树 46
3.4　规则 49
3.4.1　分类规则 49
3.4.2　关联规则 52
3.4.3　包含例外的规则 53
3.4.4　表达能力更强的规则 54
3.5　基于实例的表达 56
3.6　聚类 58
3.7　拓展阅读及参考文献 59
第4章　算法：基本方法 60
4.1　推断基本规则 60
4.2　简单概率模型 63
4.2.1　缺失值和数值属性 65
4.2.2　用于文档分类的朴素贝叶斯 67
4.2.3　讨论 68
4.3　分治法：创建决策树 69
4.3.1　计算信息量 71
4.3.2　高度分支属性 73
4.4　覆盖算法：建立规则 74
4.4.1　规则与树 75
4.4.2　一个简单的覆盖算法 76
4.4.3　规则与决策列表 79
4.5　关联规则挖掘 79
4.5.1　项集 80
4.5.2　关联规则 81
4.5.3　高效地生成规则 84
4.6　线性模型 86
4.6.1　数值预测：线性回归 86
4.6.2　线性分类：logistic回归 87
4.6.3　使用感知机的线性分类 89
4.6.4　使用Winnow的线性分类 90
4.7　基于实例的学习 91
4.7.1　距离函数 92
4.7.2　高效寻找最近邻 92
4.7.3　讨论 96
4.8　聚类 96
4.8.1　基于距离的迭代聚类 97
4.8.2　更快的距离计算 98
4.8.3　选择簇的个数 99
4.8.4　层次聚类 100
4.8.5　层次聚类示例 101
4.8.6　增量聚类 102
4.8.7　分类效用 104
4.8.8　讨论 106
4.9　多实例学习 107
4.9.1　聚集输入 107
4.9.2　聚集输出 107
4.10　拓展阅读及参考文献 108
4.11　Weka实现 109
第5章　可信度：评估学习结果 111
5.1　训练和测试 111
5.2　预测性能 113
5.3　交叉验证 115
5.4　其他评估方法 116
5.4.1　留一交叉验证法 116
5.4.2　自助法 116
5.5　超参数选择 117
5.6　数据挖掘方法比较 118
5.7　预测概率 121
5.7.1　二次损失函数 121
5.7.2　信息损失函数 122
5.7.3　讨论 123
5.8　计算成本 123
5.8.1　成本敏感分类 125
5.8.2　成本敏感学习 126
5.8.3　提升图 126
5.8.4　ROC曲线 129
5.8.5　召回率–精确率曲线 130
5.8.6　讨论 131
5.8.7　成本曲线 132
5.9　评估数值预测 134
5.10　最小描述长度原理 136
5.11　将MDL原理应用于聚类 138
5.12　使用验证集进行模型选择 138
5.13　拓展阅读及参考文献 139
第二部分　高级机器学习方案
第6章　树和规则 144
6.1　决策树 144
6.1.1　数值属性 144
6.1.2　缺失值 145
6.1.3　剪枝 146
6.1.4　估计误差率 147
6.1.5　决策树归纳法的复杂度 149
6.1.6　从决策树到规则 150
6.1.7　C4.5：选择和选项 150
6.1.8　成本–复杂度剪枝 151
6.1.9　讨论 151
6.2　分类规则 152
6.2.1　选择测试的标准 152
6.2.2　缺失值和数值属性 153
6.2.3　生成好的规则 153
6.2.4　使用全局优化 155
6.2.5　从局部决策树中获得规则 157
6.2.6　包含例外的规则 158
6.2.7　讨论 160
6.3　关联规则 161
6.3.1　建立频繁模式树 161
6.3.2　寻找大项集 163
6.3.3　讨论 166
6.4　Weka 实现 167
第7章　基于实例的学习和线性模型的扩展 168
7.1　基于实例的学习 168
7.1.1　减少样本集的数量 168
7.1.2　对噪声样本集剪枝 169
7.1.3　属性加权 170
7.1.4　泛化样本集 170
7.1.5　用于泛化样本集的距离函数 171
7.1.6　泛化的距离函数 172
7.1.7　讨论 172
7.2　扩展线性模型 173
7.2.1　最大间隔超平面 173
7.2.2　非线性类边界
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘(实用机器学习工具与技术原书第4版)/智能科学与技术丛书
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch 机器学习从入门到实战
前言
第 1 章 深度学习介绍......................................................................................... 1
1.1 人工智能、机器学习与深度学习 .................................................................. 2
1.2 深度学习工具介绍 .......................................................................................... 5
1.3 PyTorch 介绍.................................................................................................... 7
1.4 你能从本书中学到什么 .................................................................................. 9
第 2 章 PyTorch 安装和快速上手 ...................................................................... 11
2.1 PyTorch 安装.................................................................................................. 12
2.1.1 Anaconda 安装.................................................................................... 12
2.1.2 PyTorch 安装....................................................................................... 19
2.2 Jupyter Notebook 使用................................................................................... 19
2.3 NumPy 基础知识........................................................................................... 22
2.3.1 基本概念 ............................................................................................. 23
2.3.2 创建数组 ............................................................................................. 24
2.3.3 基本运算 ............................................................................................. 26
2.3.4 索引、切片和迭代 ............................................................................. 27
2.3.5 数组赋值 ............................................................................................. 32
2.3.6 更改数组的形状 ................................................................................. 33
2.3.7 组合、拆分数组 ................................................................................. 34
2.3.8 广播 ..................................................................................................... 35
2.4 PyTorch 基础知识.......................................................................................... 37
2.4.1 Tensor 简介 ......................................................................................... 37
2.4.2 Variable 简介....................................................................................... 37VIII
PyTorch 机器学习从入门到实战
2.4.3 CUDA 简介......................................................................................... 38
2.4.4 模型的保存与加载 ............................................................................. 39
2.4.5 第一个 PyTorch 程序.......................................................................... 39
第 3 章 神经网络 .............................................................................................. 42
3.1 神经元与神经网络 ........................................................................................ 43
3.2 激活函数 ........................................................................................................ 45
3.2.1 Sigmoid ................................................................................................ 46
3.2.2 Tanh ..................................................................................................... 47
3.2.3 Hard Tanh ............................................................................................ 48
3.2.4 ReLU ................................................................................................... 49
3.2.5 ReLU 的扩展 ...................................................................................... 50
3.2.6 Softmax ................................................................................................ 53
3.2.7 LogSoftmax ......................................................................................... 54
3.3 前向算法 ........................................................................................................ 54
3.4 损失函数 ........................................................................................................ 56
3.4.1 损失函数的概念 ................................................................................. 56
3.4.2 回归问题 ............................................................................................. 56
3.4.3 分类问题 ............................................................................................. 57
3.4.4 PyTorch 中常用的损失函数............................................................... 58
3.5 后向算法 ........................................................................................................ 61
3.6 数据的准备 .................................................................................................... 64
3.7 实例：单层神经网络 .................................................................................... 65
第 4 章 深层神经网络及训练............................................................................ 69
4.1 深层神经网络 ................................................................................................ 71
4.1.1 神经网络为何难以训练 ..................................................................... 71
4.1.2 改进策略 ............................................................................................. 73
4.2 梯度下降 ........................................................................................................ 73
4.2.1 随机梯度下降 ..................................................................................... 73
4.2.2 Mini-Batch 梯度下降.......................................................................... 74
4.3 优化器 ............................................................................................................ 75
4.3.1 SGD ..................................................................................................... 76
4.3.2 Momentum .......................................................................................... 76
4.3.3 AdaGrad .............................................................................................. 77
4.3.4 RMSProp ............................................................................................. 78IX
目 录
4.3.5 Adam ................................................................................................... 79
4.3.6 选择正确的优化算法 ......................................................................... 79
4.3.7 优化器的使用实例 ............................................................................. 80
4.4 正则化 ............................................................................................................ 83
4.4.1 参数规范惩罚 ..................................................................................... 84
4.4.2 Batch Normalization ............................................................................ 84
4.4.3 Dropout ................................................................................................ 85
4.5 实例：MNIST 深层神经网络....................................................................... 87
第 5 章 卷积神经网络....................................................................................... 91
5.1 计算机视觉 .................................................................................................... 93
5.1.1 人类视觉和计算机视觉 ..................................................................... 93
5.1.2 特征提取 ............................................................................................. 93
5.1.3 数据集 ................................................................................................. 95
5.2 卷积神经网络 ................................................................................................ 98
5.2.1 卷积层 ............................................................................................... 100
5.2.2 池化层 ............................................................................................... 102
5.2.3 经典卷积神经网络 ........................................................................... 103
5.3 MNIST 数据集上卷积神经网络的实现..................................................... 108
第 6 章 嵌入与表征学习 .................................................................................. 112
6.1 PCA .............................................................................................................. 113
6.1.1 PCA 原理 .......................................................................................... 113
6.1.2 PCA 的 PyTorch 实现....................................................................... 114
6.2 自动编码器 .................................................................................................. 115
6.2.1 自动编码器原理 ............................................................................... 116
6.2.2 自动解码器的 PyTorch 实现............................................................ 116
6.2.3 实例：图像去噪 ............................................................................... 120
6.3 词嵌入 .......................................................................................................... 123
6.3.1 词嵌入原理 ....................................................................................... 123
6.3.2 实例：基于词向量的语言模型实现 ............................................... 126
第 7 章 序列预测模型..................................................................................... 130
7.1 序列数据处理 .............................................................................................. 131
7.2 循环神经网络 .............................................................................................. 132
7.3 LSTM 和 GRU ............................................................................................. 136X
PyTorch 机器学习从入门到实战
7.4 LSTM 在自然语言处理中的应用............................................................... 140
7.4.1 词性标注 ........................................................................................... 140
7.4.2 情感分析 ........................................................................................... 142
7.5 串到串网络 .................................................................................................. 143
7.5.1 串到串网络原理 ............................................................................... 143
7.5.2 注意力机制 ....................................................................................... 144
7.6 实例：基于 GRU 和 Attention 的机器翻译............................................... 145
7.6.1 公共模块 ........................................................................................... 145
7.6.2 数据处理 ........................................................................................... 145
7.6.3 模型定义 ........................................................................................... 149
7.6.4 训练模块定义 ................................................................................... 153
7.6.5 训练和模型保存 ............................................................................... 159
7.6.6 评估过程 ........................................................................................... 161
第 8 章 PyTorch 项目实战 .............................................................................. 163
8.1 图像识别和迁移学习——猫狗大战 .......................................................... 164
8.1.1 迁移学习介绍 ................................................................................... 164
8.1.2 计算机视觉工具包 ........................................................................... 164
8.1.3 猫狗大战的 PyTorch 实现................................................................ 165
8.2 文本分类 ...................................................................................................... 170
8.2.1 文本分类的介绍 ............................................................................... 171
8.2.2 计算机文本工具包 ........................................................................... 172
8.2.3 基于 CNN 的文本分类的 PyTorch 实现 ......................................... 172
8.3 语音识别系统介绍 ...................................................................................... 180
8.3.1 语音识别介绍 ................................................................................... 181
8.3.2 命令词识别的 PyTorch 实现............................................................ 181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch 机器学习从入门到实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言实战——机器学习与数据分析
第1章  初识R语言	1
1.1  R语言简介	1
1.2  安装与运行	3
1.3  开始使用R	5
1.4  包的使用	7
1.5  使用帮助	8
第2章  探索R数据	10
2.1  向量的创建	10
2.2  向量的运算	13
2.3  向量的筛选	15
2.4  矩阵的创建	17
2.5  矩阵的使用	20
2.5.1  矩阵的代数运算	20
2.5.2  修改矩阵的行列	22
2.5.3  对行列调用函数	23
2.6  矩阵的筛选	25
第3章  编写R程序	28
3.1  流程的控制	28
3.1.1  条件选择结构的概念	28
3.1.2  条件选择结构的语法	29
3.1.3  循环结构的基本概念	30
3.1.4  循环结构的基本语法	31
3.2  算术与逻辑	33
3.3  使用函数	34
3.3.1  函数式语言	34
3.3.2  默认参数值	35
3.3.3  自定义函数	36
3.3.4  递归的实现	38
3.4  编写代码	40
第4章  概率统计基础	42
4.1  概率论的基本概念	42
4.2  随机变量数字特征	45
4.2.1  期望	45
4.2.2  方差	46
4.3  基本概率分布模型	48
4.3.1  离散概率分布	48
4.3.2  连续概率分布	52
4.3.3  使用内嵌分布	55
4.4  大数定理及其意义	59
4.5  中央极限定理	62
4.6  随机采样分布	65
第5章  实用统计图形	71
5.1  饼状图	71
5.2  直方图	74
5.3  核密图	78
5.4  箱线图	81
5.4.1  箱线图与分位数	81
5.4.2  使用并列箱线图	84
5.5  条形图	87
5.5.1  基本条形图及调整	87
5.5.2  堆砌与分组条形图	88
5.6  分位数与QQ图	91
第6章  数据输入/输出	99
6.1  数据的载入	99
6.1.1  基本的数据导入方法	99
6.1.2  处理其他软件的格式	103
6.1.3  读取来自网页的数据	104
6.1.4  从数据库中读取数据	106
6.2  数据的保存	108
6.3  数据预处理	109
6.3.1  常用数学函数	110
6.3.2  修改数据标签	113
6.3.3  缺失值的处理	114
第7章  高级数据结构	118
7.1  列表	118
7.1.1  列表的创建	118
7.1.2  列表元素的访问	120
7.1.3  增删列表元素	121
7.1.4  拼接列表	123
7.1.5  列表转化为向量	123
7.1.6  列表上的运算	124
7.1.7  列表的递归	125
7.2  数据框	126
7.2.1  数据框的创建	126
7.2.2  数据框元素的访问	128
7.2.3  提取子数据框	129
7.2.4  数据框行列的添加	130
7.2.5  数据框的合并	132
7.2.6  数据框的其他操作	134
7.3  因子	135
7.3.1  因子的创建	136
7.3.2  因子中插入水平	137
7.3.3  因子和常用函数	138
7.4  表	140
7.4.1  表的创建	141
7.4.2  表中元素的访问	143
7.4.3  表中变量的边际值	143
第8章  统计推断	146
8.1  参数估计	146
8.1.1  参数估计的基本原理	146
8.1.2  单总体参数区间估计	149
8.1.3  双总体均值差的估计	155
8.1.4  双总体比例差的估计	161
8.2  假设检验	162
8.2.1  基本概念	162
8.2.2  两类错误	166
8.2.3  均值检验	167
8.3  极大似然估计	172
8.3.1  极大似然法的基本原理	172
8.3.2  求极大似然估计的方法	174
8.3.3  极大似然估计应用举例	176
第9章  非参数检验方法	181
9.1  列联分析	181
9.1.1  类别数据与列联表	181
9.1.2  皮尔逊（Pearson）的卡方检验	182
9.1.3  列联分析应用条件	186
9.1.4  费希尔（Fisher）的确切检验	188
9.2  符号检验	190
9.3  威尔科克森（Wilcoxon）符号秩检验	195
9.4  威尔科克森（Wilcoxon）的秩和检验	199
9.5  克鲁斯卡尔-沃利斯（Kruskal-Wallis）检验	204
第10章  一元线性回归	208
10.1  回归分析的性质	208
10.2  回归的基本概念	210
10.2.1  总体的回归函数	210
10.2.2  随机干扰的意义	211
10.2.3  样本的回归函数	213
10.3  回归模型的估计	214
10.3.1  普通最小二乘法原理	214
10.3.2  一元线性回归的应用	216
10.3.3  经典模型的基本假定	218
10.3.4  总体方差的无偏估计	222
10.3.5  估计参数的概率分布	225
10.4  正态条件下的模型检验	227
10.4.1  拟合优度的检验	227
10.4.2  整体性假定检验	231
10.4.3  单个参数的检验	233
10.5  一元线性回归模型预测	234
10.5.1  点预测	234
10.5.2  区间预测	235
第11章  线性回归进阶	239
11.1  多元线性回归模型	239
11.2  多元回归模型估计	241
11.2.1  最小二乘估计量	241
11.2.2  多元回归的实例	242
11.2.3  总体参数估计量	245
11.3  多元回归模型检验	247
11.3.1  线性回归的显著性	247
11.3.2  回归系数的显著性	249
11.4  多元线性回归模型预测	250
11.5  其他回归模型函数形式	253
11.5.1  双对数模型以及生产函数	253
11.5.2  倒数模型与菲利普斯曲线	255
11.5.3  多项式回归模型及其分析	258
11.6  回归模型的评估与选择	260
11.6.1  嵌套模型选择	261
11.6.2  赤池信息准则	262
11.6.3  逐步回归方法	265
11.7  现代回归方法的新进展	269
11.7.1  多重共线性	269
11.7.2  岭回归	270
11.7.3  从岭回归到Lasso	271
第12章  方差分析方法	275
12.1  方差分析的基本概念	275
12.2  单因素方差分析方法	278
12.2.1  基本原理	278
12.2.2  分析步骤	279
12.2.3  强度测量	280
12.3  双因素方差分析方法	281
12.3.1  无交互作用的分析	281
12.3.2  有交互作用的分析	286
12.4  多重比较	289
12.4.1  多重t检验	290
12.4.2  Dunnett检验	291
12.4.3  Tukey的HSD检验	294
12.4.4  Newman-Keuls检验	298
12.5  方差齐性的检验方法	301
12.5.1  Bartlett检验法	301
12.5.2  Levene检验法	303
第13章  聚类分析	307
13.1  聚类的概念	307
13.2  K均值算法	308
13.2.1  距离度量	309
13.2.2  算法描述	310
13.2.3  应用实例	312
13.3  最大期望算法	314
13.3.1  算法原理	314
13.3.2  收敛探讨	319
13.4  高斯混合模型	320
13.4.1  模型推导	320
13.4.2  应用实例	323
第14章  支持向量机	326
14.1  从逻辑回归到线性分类	326
14.2  线性可分的支持向量机	330
14.2.1  函数距离与几何距离	330
14.2.2  最大间隔分类器	332
14.2.3  拉格朗日乘数法	334
14.2.4  对偶问题的求解	339
14.3  松弛因子与软间隔模型	343
14.4  非线性支持向量机方法	345
14.4.1  从更高维度上分类	345
14.4.2  非线性核函数方法	347
14.4.3  默瑟定理与核函数	350
14.5  对数据进行分类的实践	350
14.5.1  基本建模函数	351
14.5.2  分析建模结果	355
第15章  人工神经网络	358
15.1  从感知机开始	358
15.1.1  感知机模型	358
15.1.2  感知机学习	360
15.1.3  多层感知机	362
15.2  基本神经网络	365
15.2.1  神经网络结构	365
15.2.2  符号标记说明	366
15.2.3  后向传播算法	368
15.3  神经网络实践	370
15.3.1  核心函数介绍	370
15.3.2  应用分析实践	372
参考文献	375
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言实战——机器学习与数据分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习即服务：将Python机器学习创意快速转变为云端Web应用程序
译者序1
译者序2
译者序3
关于作者
关于技术审校者
前言
第1章　无服务器计算介绍1
1.1　一个简单的本地Flask应用程序1
1.2　在微软Azure上使用无服务器计算4
1.2.1　操作步骤5
1.2.2　结论和附加信息12
1.3　在谷歌云上使用无服务器计算12
1.3.1　操作步骤13
1.3.2　结论和附加信息18
1.4　在Amazon AWS上使用无服务器计算19
1.4.1　操作步骤19
1.4.2　结论和附加信息24
1.5　在PythonAnywhere上托管应用程序24
1.5.1　操作步骤25
1.5.2　结论和附加信息26
1.6　本章小结26
第2章　在Azure上进行共享单车回归模型智能预测27
2.1　共享单车租赁需求回归系数分析28
2.2　探索共享单车原始数据集28
2.2.1　下载UCI机器学习库数据集29
2.2.2　Jupyter Notebook配置使用29
2.2.3　数据集探索31
2.2.4　预测结果变量分析33
2.2.5　量化特征与租赁统计34
2.2.6　分类特征研究35
2.3　数据建模准备工作36
2.3.1　回归建模37
2.3.2　简单线性回归37
2.3.3　简单线性回归模型37
2.4　特征工程试验39
2.4.1　多项式建模39
2.4.2　创建分类数据虚拟特征40
2.4.3　非线性模型试验41
2.4.4　使用时间序列复杂特征42
2.5　简约模型44
2.5.1　简单模型中的回归系数提取44
2.5.2　R-Squared44
2.5.3　基于回归系数的新数据预测46
2.6　共享单车租赁需求交互式Web应用设计48
2.6.1　代码可读性与扩展性摘要48
2.6.2　构建本地Flask应用49
2.6.3　下载运行GitHub共享单车代码50
2.6.4　Web应用程序调试最佳实践51
2.7　在微软Azure上运行Web应用程序54
2.7.1　使用Git托管项目代码54
2.7.2　微软Azure命令行接口工具使用56
2.7.3　资源清理59
2.7.4　故障排查60
2.7.5　步骤回顾62
2.8　Web应用程序脚本及技术分析62
2.8.1　main.py文件分析63
2.8.2　/static/文件夹分析64
2.8.3　/templates/index.html文件及脚本分析64
2.9　本章小结66
2.10　附加资源66
第3章　在GCP上基于逻辑回归实现实时智能67
3.1　规划Web应用68
3.2　数据处理68
3.2.1　处理分类型数据71
3.2.2　从分类型数据创建虚拟特征75
3.3　建模75
3.3.1　训练和测试数据集拆分76
3.3.2　逻辑回归77
3.3.3　预测幸存率78
3.4　准备上云78
3.4.1　函数startup()79
3.4.2　函数submit_new_profile()79
3.4.3　使用HTML表单实现交互79
3.4.4　创建动态图像80
3.4.5　下载Titanic代码81
3.5　部署到谷歌云上82
3.5.1　Google App Engine82
3.5.2　在Google App Engine上进行部署83
3.5.3　问题排查86
3.5.4　收尾工作87
3.6　代码回顾87
3.6.1　main.py87
3.6.2　app.yaml88
3.6.3　appengine_config.py文件与lib文件夹89
3.6.4　requirements.txt89
3.7　步骤回顾90
3.8　本章小结90
第4章　在AWS上使用Gradient Boosting Machine进行预训练91
4.1　Web应用程序规划92
4.2　探索葡萄酒品质数据集92
4.3　处理不平衡的类别95
4.4　使用Gradient Boosting Classifier97
4.4.1　评估模型98
4.4.2　持久化模型101
4.4.3　新数据预测101
4.5　设计Web应用程序以交互评估葡萄酒品质103
4.6　Ajax—服务器端动态Web渲染104
4.7　在虚拟环境中工作：一个方便实验、更加安全和纯净的沙箱104
4.8　AWS Elastic Beanstalk105
4.8.1　为Elastic Beanstalk创建一个访问账户106
4.8.2　Elastic Beanstalk108
4.8.3　EB Command Line Interface108
4.8.4　修复WSGIApplication-Group110
4.8.5　创建EB应用程序111
4.8.6　查看应用程序111
4.9　资源清理112
4.10　步骤回顾114
4.11　故障排查115
4.11.1　查看日志115
4.11.2　SSH登录到实例115
4.12　本章小结116
第5章　案例研究1：在Web和移动浏览器上预测股票市场117
5.1　配对交易策略118
5.2　下载和准备数据119
5.2.1　准备数据120
5.2.2　股票代码透视121
5.3　价格市场数据扩展121
5.4　绘制价差122
5.5　交易理念123
5.5.1　寻找极端案例123
5.5.2　提供交易建议124
5.6　计算交易股数125
5.7　设计一个移动友好的Web应用程序提供交易建议127
5.8　运行本地Flask应用程序128
5.9　表单验证130
5.10　在PythonAnywhere上运行应用程序130
5.11　修复WSGI文件133
5.11.1　源代码133
5.11.2　WSGI配置133
5.11.3　重新加载网站134
5.12　PythonAnywhere故障排查135
5.13　本章小结136
第6章　基于Azure和Google地图的犯罪行为预测137
6.1　Web应用程序规划138
6.2　探索旧金山犯罪热图数据集138
6.2.1　数据清洗139
6.2.2　数据重分布140
6.2.3　周数据探索142
6.3　数据特征工程142
6.3.1　创建年度月份汇总数据特征143
6.3.2　创建时段数据特征144
6.3.3　时段特征数据集探索145
6.4　地理数据可视化146
6.4.1　地理坐标位置绘制146
6.4.2　地理坐标近似值区块创建147
6.5　基于历史数据的犯罪预测149
6.6　Google地图152
6.7　热力图层153
6.8　犯罪数据在Google地图上的应用154
6.9　犯罪预测数据自定义提取155
6.10　设计Web应用程序156
6.10.1　添加Google API密钥157
6.10.2　本地运行Web应用程序157
6.10.3　Azure公有云Git准备157
6.10.4　Azure命令行接口工具160
6.10.5　故障排查164
6.10.6　资源清理166
6.11　本章小结166
第7章　在AWS上使用朴素贝叶斯和OpenWeather进行预测167
7.1　探索数据集167
7.2　朴素贝叶斯169
7.3　Sklearn中的GaussianNB170
7.4　实时天气预报OpenWeatherMap171
7.4.1　使用天气预测服务173
7.4.2　数据转换174
7.5　设计Web应用程序177
7.6　在AWS Elastic Beanstalk上运行应用程序179
7.6.1　修复WSGIApplication-Group180
7.6.2　查看应用程序181
7.6.3　记得终止实例182
7.7　本章小结184
7.7.1　访问OpenWeatherMap数据184
7.7.2　捕获异常184
7.7.3　处理用户输入的数据185
第8章　在GCP上基于TensorFlow实现交互式绘画和数字预测186
8.1　MNIST数据集186
8.2　TensorFlow189
8.3　使用TensorFlow和卷积网络建模189
8.3.1　构建建模层190
8.3.2　损益函数191
8.3.3　实例化会话191
8.3.4　训练191
8.3.5　准确度191
8.3.6　运行脚本192
8.4　准备上云193
8.4.1　运行一个保存的TensorFlow模型193
8.4.2　保存模型194
8.4.3　画布194
8.4.4　从画布到TensorFlow195
8.4.5　测试新的手写数字195
8.4.6　设计Web应用程序196
8.4.7　下载Web应用程序197
8.5　部署到谷歌云上198
8.5.1　谷歌云Flexible App Engine198
8.5.2　在Google App Engine上部署199
8.5.3　问题排查201
8.5.4　收尾工作202
8.6　本章小结203
8.6.1　HTML5
8.6.2　TensorFlow203
8.6.3　设计203
第9章 　案例研究2：动态股票图表显示205
9.1　使用Matplotlib创建股票图表205
9.2　探索配对交易图表207
9.3　设计Web应用程序210
9.4　具有移动友好性的表格211
9.5　上传Web应用程序到PythonAnywhere213
9.6　本章小结215
第10章　在GCP上使用奇异值分解实现推荐系统216
10.1　规划Web应用216
10.2　推荐系统简介217
10.3　探索MovieLens数据集217
10.3.1　MovieLens数据集概况218
10.3.2　探索ratings.csv和movies.csv219
10.3.3　理解评级和评级文化221
10.3.4　给出推荐224
10.4　协同过滤226
10.4.1　相似性和距离测量工具227
10.4.2　欧几里得距离227
10.4.3　余弦相似距离228
10.5　奇异值分解228
10.5.1　将电影评级集中到零周围229
10.5.2　观察SVD的行为229
10.6　准备上云232
10.6.1　下载并在本地运行“下一部电影看什么？”232
10.6.2　代码解释234
10.7　部署到谷歌云上236
10.7.1　在Google App Engine上部署236
10.7.2　问题排查240
10.7.3　收尾工作240
10.8　本章小结241
第11章　在Azure上使用NLP和可视化技术简化复杂概念242
11.1　Web应用规划242
11.2　数据探索243
11.3　文本清理244
11.4　基于文本的特征工程245
11.5　TFIDF文本数据清理247
11.6　NLP与正则表达式247
11.7　使用外部垃圾邮件关键字列表248
11.8　使用Sklearn库TfidfVectorizer提取特征250
11.9　输出变量准备250
11.10　使用Sklearn库随机森林分类器建模251
11.10.1　模型性能测量252
11.10.2　模型阈值交互255
11.11　Web图形化交互256
11.12　构建本地Flask Web应用257
11.13　将应用程序部署到Azure公有云259
11.13.1　在Azure上部署Git259
11.13.2　Azure命令行接口工具262
11.13.3　资源清理265
11.13.4　故障排查266
11.14　本章小结与附加资源268
第12章　案例研究3：使用基础财务信息使内容更丰富269
12.1　访问股票上市公司名单269
12.2　使用维基百科API获取公司信息271
12.3　构建动态FinViz链接272
12.4　基础消息探索273
12.5　设计Web应用程序274
12.6　上传Web应用程序到PythonAnywhere276
12.7　本章小结281
第13章　使用Google Analytics282
13.1　创建Google Analytics账户282
13.2　JavaScript跟踪器283
13.3　阅读分析报告284
13.4　流量来源286
13.5　页面286
13.6　本章小结与附加资源287
第14章　在PythonAnywhere上使用A/B测试和MySQL数据库288
14.1　A/B测试289
14.1.1　用户跟踪290
14.1.2　通用唯一标识符290
14.2　MySQL290
14.2.1　使用命令行启动和停止服务292
14.2.2　MySQL命令行监视器293
14.2.3　创建数据库293
14.2.4　创建数据表294
14.2.5　创建数据库用户295
14.3　Python库：mysql.connector295
14.3.1　SELECT SQL语句296
14.3.2　INSERT SQL语句296
14.3.3　UPDATE SQL语句297
14.4　将代码抽象为函数298
14.5　设计Web应用程序300
14.6　在PythonAnywhere上设置MySQL300
14.7　在PythonAnywhere上进行A/B测试302
14.8　A/B测试结果304
14.9　本章小结304
第15章　从访问者到订阅者306
15.1　基于文本的身份验证306
15.1.1　Flask-HTTPAuth硬编码账户307
15.1.2　摘要式身份验证示例308
15.1.3　使用外部文本文件的摘要式身份验证示例309
15.2　简单订阅插件系统311
15.2.1　用Memberful进行销售311
15.2.2　用PayPal进行捐赠315
15.2.3　用Stripe进行购买317
15.3　本章小结321
第16章　案例研究4：使用Memberful构建订阅付费墙322
16.1　升级Memberful和Python-Anywhere支付账户323
16.1.1　升级Memberful323
16.1.2　升级PythonAnywhere326
16.1.3　使用pip安装Flask-SSLify326
16.2　Memberful用户验证327
16.2.1　两步流程和Flask会话机制327
16.2.2　身份验证第1步328
16.2.3　身份验证第2步328
16.2.4　调用Memberful函数330
16.3　设计Web应用程序331
16.3.1　在Memberful.com上设计一个订阅计划331
16.3.2　将Web应用程序上传到PythonAnywhere333
16.3.3　在Memberful和MySQL中替换你自己的凭据335
16.4　代码解释336
16.4.1　main.py336
16.4.2　welcome.html336
16.4.3　index.html337
16.5　本章小结338
第17章　关闭所有资源339
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习即服务：将Python机器学习创意快速转变为云端Web应用程序
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习实践
前言 1
第1章 5
可能近似正确的软件 5
正确地编写软件 6
编写正确的软件 10
本书计划 16
第2章 快速介绍机器学习 18
什么是机器学习 18
有监督学习 18
无监督学习 19
强化学习 20
机器学习能完成什么 20
本书中使用的数学符号 21
结论 22
第3章 K最近邻算法 23
如何确定是否想购买一栋房子 23
房子的价格究竟几何 24
愉悦回归 24
什么是邻域 25
K最近邻算法简介 26
K先生最近的邻居 26
距离 27
维度灾难 33
如何选择K 34
给西雅图的房子估价 37
结论 43
第4章 朴素贝叶斯分类 44
通过贝叶斯定理来发现欺诈订单 44
条件概率 45
概率符号 45
反向条件概率（又名贝叶斯定理） 47
朴素贝叶斯分类器 47
贝叶斯推理之朴素 48
伪计数 49
垃圾邮件过滤器 50
标记化和上下文 55
结论 67
第5章 决策树和随机森林 68
蘑菇的细微差别 69
使用民间定理实现蘑菇分类 70
找到最佳切换点 71
修剪树 74
结论 83
第6章 隐马尔可夫模型 84
使用状态机来跟踪用户行为 84
输出/观测隐含状态 86
使用马尔可夫假设化简 87
隐马尔可夫模型 88
评估: 前向-后向算法 89
通过维特比算法解码 93
学习问题 94
词性标注与布朗语库 94
结论 105
第7章 支持向量机 106
客户满意度作为语言的函数 107
SVM背后的理论 108
情绪分析器 113
聚合情绪 124
将情绪映射到底线 126
结论 127
第8章 神经网络 128
什么是神经网络 129
神经网络史 129
布尔逻辑 129
感知器 130
如何构建前馈神经网络 130
构建神经网络 144
使用神经网络来对语言分类 145
结论 154
第9章 聚类 155
无任何偏差的研究数据 155
用户群组 156
测试群集映射 157
K均值聚类 159
最大期望（EM）聚类 161
不可能性定理 163
案例：音乐归类 164
结论 174
第10章 模型改进与数据提取 175
辩论俱乐部 175
选择更好的数据 176
最小冗余最大相关性的特征选择 181
特征变换与矩阵分解 183
结论 189
第11章 将这些方法融合在一起：结论 191
机器学习算法回顾 191
如何使用这些信息来解决问题 193
下一步做什么 193
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习Web应用
第1章　Python机器学习实践入门 1
1.1　机器学习常用概念 1
1.2　数据的准备、处理和可视化
—NumPy、pandas和matplotlib教程 6
1.2.1　NumPy的用法 6
1.2.2　理解pandas模块 23
1.2.3　matplotlib教程 32
1.3　本书使用的科学计算库 35
1.4　机器学习的应用场景 36
1.5　小结 36
第2章　无监督机器学习 37
2.1　聚类算法 37
2.1.1　分布方法 38
2.1.2　质心点方法 40
2.1.3　密度方法 41
2.1.4　层次方法 44
2.2　降维 52
2.3　奇异值分解（SVD） 57
2.4　小结 58
第3章　有监督机器学习 59
3.1　模型错误评估 59
3.2　广义线性模型 60
3.2.1　广义线性模型的概率
解释 63
3.2.2　k近邻 63
3.3　朴素贝叶斯 64
3.3.1　多项式朴素贝叶斯 65
3.3.2　高斯朴素贝叶斯 66
3.4　决策树 67
3.5　支持向量机 70
3.6　有监督学习方法的对比 75
3.6.1　回归问题 75
3.6.2　分类问题 80
3.7　隐马尔可夫模型 84
3.8　小结 93
第4章　Web挖掘技术 94
4.1　Web结构挖掘 95
4.1.1　Web爬虫 95
4.1.2　索引器 95
4.1.3　排序—PageRank
算法 96
4.2　Web内容挖掘 97
句法解析 97
4.3　自然语言处理 98
4.4　信息的后处理 108
4.4.1　潜在狄利克雷分配 108
4.4.2　观点挖掘（情感
分析） 113
4.5　小结 117
第5章　推荐系统 118
5.1　效用矩阵 118
5.2　相似度度量方法 120
5.3　协同过滤方法 120
5.3.1　基于记忆的协同
过滤 121
5.3.2　基于模型的协同
过滤 126
5.4　CBF方法 130
5.4.1　商品特征平均得分
方法 131
5.4.2　正则化线性回归
方法 132
5.5　用关联规则学习，构建推荐
系统 133
5.6　对数似然比推荐方法 135
5.7　混合推荐系统 137
5.8　推荐系统评估 139
5.8.1　均方根误差（RMSE）
评估 140
5.8.2　分类效果的度量方法 143
5.9　小结 144
第6章　开始Django之旅 145
6.1　HTTP—GET和POST方法的
基础 145
6.1.1　Django的安装和
服务器的搭建 146
6.1.2　配置 147
6.2　编写应用—Django
最重要的功能 150
6.2.1　model 150
6.2.2　HTML网页背后的
URL和view 151
6.2.3　URL声明和view 154
6.3　管理后台 157
6.3.1　shell接口 158
6.3.2　命令 159
6.3.3　RESTful应用编程
接口（API） 160
6.4　小结 162
第7章　电影推荐系统Web应用 163
7.1　让应用跑起来 163
7.2　model 165
7.3　命令 166
7.4　实现用户的注册、登录和
登出功能 172
7.5　信息检索系统（电影查询） 175
7.6　打分系统 178
7.7　推荐系统 180
7.8　管理界面和API 182
7.9　小结 184
第8章　影评情感分析应用 185
8.1　影评情感分析应用用法
简介 185
8.2　搜索引擎的选取和应用的
代码 187
8.3　Scrapy的配置和情感分析
应用代码 189
8.3.1　Scrapy的设置 190
8.3.2　Scraper 190
8.3.3　Pipeline 193
8.3.4　爬虫 194
8.4　Django model 196
8.5　整合Django和Scrapy 197
8.5.1　命令（情感分析模型和
删除查询结果） 198
8.5.2　情感分析模型加载器 198
8.5.3　删除已执行过的查询 201
8.5.4　影评情感分析器—
Django view和HTML
代码 202
8.6　PageRank：Django view和
算法实现 206
8.7　管理后台和API 210
8.8　小结 212
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习Web应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度实践spark机器学习
前言
第1章　了解机器学习 1
1.1　机器学习的定义 1
1.2　大数据与机器学习 2
1.3　机器学习、人工智能及深度学习 2
1.4　机器学习的基本任务 3
1.5　如何选择合适算法 4
1.6　Spark在机器学习方面的优势 5
1.7　小结 5
第2章　构建Spark机器学习系统 6
2.1　机器学习系统架构 6
2.2　启动集群 7
2.3　加载数据 9
2.4　探索数据 10
2.4.1　数据统计信息 10
2.4.2　数据质量分析 11
2.4.3　数据特征分析 12
2.4.4　数据的可视化 17
2.5　数据预处理 19
2.5.1　数据清理 20
2.5.2　数据变换 21
2.5.3　数据集成 22
2.5.4　数据归约 23
2.6　构建模型 25
2.7　模型评估 26
2.8　组装 30
2.9　模型选择或调优 30
2.9.1　交叉验证 31
2.9.2　训练–验证切分 32
2.10　保存模型 32
2.11　小结 33
第3章　ML Pipeline原理与实战 34
3.1　Pipeline简介 34
3.2　DataFrame 35
3.3　Pipeline组件 36
3.4　Pipeline原理 37
3.5　Pipeline实例 38
3.5.1　使用Estimator、Transformer和Param的实例 38
3.5.2　ML使用Pipeline的实例 40
3.6　小结 41
第4章　特征提取、转换和选择 42
4.1　特征提取 42
4.1.1　词频—逆向文件
频率（TF-IDF） 42
4.1.2　Word2Vec 43
4.1.3　计数向量器 44
4.2　特征转换 45
4.2.1　分词器 45
4.2.2　移除停用词 46
4.2.3　n-gram 47
4.2.4　二值化 48
4.2.5　主成分分析 48
4.2.6　多项式展开 50
4.2.7　离散余弦变换 50
4.2.8　字符串—索引变换 51
4.2.9　 索引—字符串变换 53
4.2.10　独热编码 54
4.2.11　向量—索引变换 57
4.2.12　交互式 58
4.2.13　正则化 59
4.2.14　规范化 60
4.2.15　最大值—最小值缩放 60
4.2.16　最大值—绝对值缩放 61
4.2.17　离散化重组 62
4.2.18　元素乘积 63
4.2.19　SQL转换器 64
4.2.20　向量汇编 65
4.2.21　分位数离散化 66
4.3　特征选择 67
4.3.1　向量机 67
4.3.2　R公式 69
4.3.3　卡方特征选择 70
4.4　小结 71
第5章　模型选择和优化 72
5.1　模型选择 72
5.2　交叉验证 73
5.3　训练验证拆分法 75
5.4　自定义模型选择 76
5.5　小结 78
第6章　Spark MLlib基础 79
6.1　Spark MLlib简介 80
6.2　Spark MLlib架构 81
6.3　数据类型 82
6.4　基础统计 84
6.4.1　摘要统计 84
6.4.2　相关性 84
6.4.3　假设检验 85
6.4.4　随机数据生成 85
6.5　RDD、Dataframe和Dataset 86
6.5.1　RDD 86
6.5.2　DatasetDataFrame 87
6.5.3　相互转换 88
6.6　小结 89
第7章　构建Spark ML推荐模型 90
7.1　推荐模型简介 91
7.2　数据加载 92
7.3　数据探索 94
7.4　训练模型 94
7.5　组装 95
7.6　评估模型 96
7.7　模型优化 96
7.8　小结 98
第8章　构建Spark ML分类模型 99
8.1　分类模型简介 99
8.1.1　线性模型 100
8.1.2　决策树模型 101
8.1.3　朴素贝叶斯模型 102
8.2　数据加载 102
8.3　数据探索 103
8.4　数据预处理 104
8.5　组装 109
8.6　模型优化 110
8.7　小结 113
第9章　构建Spark ML回归模型 114
9.1　回归模型简介 115
9.2　数据加载 115
9.3　探索特征分布 117
9.4　数据预处理 120
9.4.1　特征选择 121
9.4.2　特征转换 121
9.5　组装 122
9.6　模型优化 124
9.7　小结 126
第10章　构建Spark ML聚类模型 127
10.1　K-means模型简介 128
10.2　数据加载 129
10.3　探索特征的相关性 129
10.4　数据预处理 131
10.5　组装 132
10.6　模型优化 134
10.7　小结 136
第11章　PySpark 决策树模型 137
11.1　PySpark 简介 138
11.2　决策树简介 139
11.3　数据加载 140
11.3.1　原数据集初探 140
11.3.2　PySpark的启动 142
11.3.3　基本函数 142
11.4　数据探索 143
11.5　数据预处理 143
11.6　创建决策树模型 145
11.7　训练模型进行预测 146
11.8　模型优化 149
11.8.1　特征值的优化 149
11.8.2　交叉验证和网格参数 152
11.9　脚本方式运行 154
11.9.1　在脚本中添加配置信息 154
11.9.2　运行脚本程序 154
11.10　小结 154
第12章　SparkR朴素贝叶斯模型 155
12.1　SparkR简介 156
12.2　获取数据 157
12.2.1　SparkDataFrame数据结构
说明 157
12.2.2　创建SparkDataFrame 157
12.2.3　SparkDataFrame的常用操作 160
12.3　朴素贝叶斯分类器 162
12.3.1　数据探查 162
12.3.2　对原始数据集进行转换 163
12.3.3　查看不同船舱的生还率差异 163
12.3.4　转换成SparkDataFrame格式的数据 165
12.3.5　模型概要 165
12.3.6　预测 165
12.3.7　评估模型 166
12.4　小结 167
第13章　使用Spark Streaming构建在线学习模型 168
13.1　Spark Streaming简介 168
13.1.1　Spark Streaming常用术语 169
13.1.2　Spark Streaming处理流程 169
13.2　Dstream操作
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度实践spark机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习系统设计
译者序
前言
第1章机器学习的思维1
1.1人机界面1
1.2设计原理4
1.2.1问题的类型6
1.2.2问题是否正确7
1.2.3任务8
1.2.4统一建模语言27
1.3总结31
第2章工具和技术32
2.1Python与机器学习33
2.2IPython控制台33
2.3安装SciPy栈34
2.4NumPy35
2.4.1构造和变换数组38
2.4.2数学运算39
2.5Matplotlib41
2.6Pandas45
2.7SciPy47
2.8Scikit—learn50
2.9总结57
第3章将数据变为信息58
3.1什么是数据58
3.2大数据59
3.2.1大数据的挑战60
3.2.2数据模型62
3.2.3数据分布63
3.2.4来自数据库的数据67
3.2.5来自互联网的数据68
3.2.6来自自然语言的数据70
3.2.7来自图像的数据72
3.2.8来自应用编程接口的数据72
3.3信号74
3.4数据清洗76
3.5数据可视化78
3.6总结80
第4章模型—从信息中学习81
4.1逻辑模型81
4.1.1一般性排序83
4.1.2解释空间84
4.1.3覆盖空间86
4.1.4PAC学习和计算复杂性87
4.2树状模型88
4.3规则模型92
4.3.1有序列表方法94
4.3.2基于集合的规则模型95
4.4总结98
第5章线性模型100
5.1最小二乘法101
5.1.1梯度下降102
5.1.2正规方程法107
5.2logistic回归109
5.3多分类113
5.4正则化115
5.5总结117
第6章神经网络119
6.1神经网络入门119
6.2logistic单元121
6.3代价函数126
6.4神经网络的实现128
6.5梯度检验133
6.6其他神经网络架构134
6.7总结135
第7章特征—算法眼中的世界136
7.1特征的类型137
7.1.1定量特征137
7.1.2有序特征138
7.1.3分类特征138
7.2运算和统计139
7.3结构化特征141
7.4特征变换141
7.4.1离散化143
7.4.2归一化144
7.4.3校准145
7.5主成分分析149
7.6总结151
第8章集成学习152
8.1集成学习的类型152
8.2Bagging方法153
8.2.1随机森林154
8.2.2极端随机树155
8.3Boosting方法159
8.3.1AdaBoost161
8.3.2梯度Boosting163
8.4集成学习的策略165
8.5总结168
第9章设计策略和案例研究169
9.1评价模型的表现169
9.2模型的选择174
9.3学习曲线176
9.4现实世界中的案例研究178
9.4.1建立一个推荐系统178
9.4.2温室虫害探测185
9.5机器学习一瞥188
9.6总结190
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习系统设计
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>零起点Python足彩大数据与机器学习实盘分析
第1章 足彩与数据分析 1
1.1 “阿尔法狗”与足彩 1
1.2 案例1-1：可怕的英国足球 3
1.3 关于足彩的几个误区 7
1.4 足彩·大事件 8
1.5 大数据图灵（足彩）原则 10
1.6 主要在线彩票资源 11
1.7 主要在线足彩数据源 15
1.8 足彩基础知识 17
1.9 学习路线图 18
第2章 开发环境 19
2.1 数据分析首选Python 19
2.1.1 大数据，why Python 19
2.1.2 入门简单，功能强大 21
2.1.3 难度降低90%，性能提高10倍 23
2.1.4 “零对象”编程模式 24
2.2 用户运行平台 25
2.3 程序目录结构 26
2.4 tfbDat足彩数据包 27
2.5 Spyder编辑器界面设置 28
2.5.1 开发环境界面设置 28
2.5.2 代码配色技巧 29
2.5.3 图像显示配置 31
2.5.4 重剑无锋 32
2.6 Notebook模式 34
2.7 模块库控制面板 36
2.7.1 模块库资源 37
2.7.2 模块库维护更新 37
2.7.3 系统关联 38
2.8 使用pip命令更新模块库 39
2.8.1 pip常用命令 39
2.8.2 进入Python命令行模式 41
2.8.3 pip安装模板 41
2.8.4 pip参数解释 42
2.8.5 pip-install参数选项 43
第3章 入门案例套餐 45
3.1 案例3-1：第一次编程，“hello,ziwang” 45
3.1.1 简单调试 46
3.1.2 控制台复位 47
3.2 案例3-2：增强版“hello,ziwang” 47
3.3 案例3-3：列举系统模块库清单 49
3.4 案例3-4：常用绘图风格 50
3.5 案例3-5：Pandas常用绘图风格 52
3.6 案例3-6：常用颜色表cors 53
第4章 足彩量化分析系统 55
4.1 功能简介 55
4.1.1 目录结构 56
4.1.2 TFB安装与更新 56
4.2 TFB主体框架 57
4.2.1 模块构成 57
4.2.2 Top-Base极宽基础模块库 57
4.2.3 Top-Football极宽足彩专业模块库 58
4.2.4 tfbDat极宽足彩数据包 59
4.2.5 量化系统模块构成 60
4.2.6 案例4-1：赔率文件切割 61
4.2.7 案例4-2：批量切割数据文件 64
4.3 tfbDat数据结构 66
4.3.1 案例4-3：tfb数据格式 67
4.3.2 gid基本比赛数据格式 67
4.3.3 xdat赔率数据格式 69
4.4 足彩基本数据分析 73
4.4.1 案例4-4：比赛数据基本图表分析 73
4.4.2 案例4-5：比赛数据进阶图表分析 77
4.4.3 案例4-6：比赛数据年度图表分析 80
4.4.4 案例4-7：比赛数据时间细分图表分析 81
4.5 胜、平、负数据分析 88
4.5.1 案例4-8：胜、平、负数据分析 88
4.5.2 @修饰符 88
4.5.3 胜、平、负分析 90
4.6 赔率数据分析 91
4.6.1 案例4-9：赔率分析 91
4.6.2 扩充dr_gid_top10绘图函数 92
4.6.3 赔率对比 93
第5章 常用数据分析工具 96
5.1 Pandas数据分析软件 96
5.1.1 Pandas简介 96
5.1.2 案例5-1：Pandas常用统计功能 99
5.2 科学计算 104
5.3 人工智能 105
5.4 NLTK语义分析 107
5.5 数据清洗统计分析 109
5.6 数据可视化 109
第6章 辅助工具 114
6.1 性能优化 114
6.1.1 Numexpr矢量加速库 115
6.1.2 Numba支持GPU的加速模块库 115
6.1.3 Blaze大数据优化模块库 115
6.1.4 Pyston加速模块 116
6.1.5 PyPy加速模块 116
6.1.6 Cython 116
6.1.7 其他优化技巧 117
6.2 网页信息抓取 117
6.2.1 Requests人性化的网络模块 118
6.2.2 Scrapy网页爬虫框架 118
6.2.3 Beautiful Soup 4 119
6.3 其他工具模块 120
6.3.1 Logging日志模块 120
6.3.2 Debug调试工具 121
6.3.3 re正则表达式 121
6.3.4 并行编程 122
6.4 网络辅助资源 123
6.5 arrow优雅简捷的时间模块库 125
6.5.1 案例6-1：arrow入门案例 126
6.5.2 创建arrow时间对象 128
6.5.3 创建时间戳 128
6.5.4 arrow属性 129
6.5.5 replace替换和shift位移 130
6.5.6 format格式化参数 130
6.5.7 时间转换 131
6.5.8 短命令 131
6.5.9 人性化 131
6.5.10 范围和跨度 132
6.5.11 工厂模式 133
6.5.12 Token特殊字符 133
第7章 网络足彩数据抓取 135
7.1 500彩票网站数据接口的优势 135
7.1.1 案例7-1：抓取赔率数据网页 136
7.1.2 网页数据实战操作技巧 139
7.2 网页解析的心灵鸡汤 141
7.2.1 BS4四大要素三缺一 142
7.2.2 Tag标签对象 142
7.2.3 案例7-2：Tag标签对象 142
7.2.4 案例7-3：Tag标签对象数据类型 145
7.2.5 NavigableString导航字符串 149
7.2.6 BeautifulSoup复合对象 149
7.2.7 Comment注释对象 150
7.2.8 案例7-4：BS4查找匹配功能 150
7.2.9 BS4节点遍历功能 154
7.3 足彩基本数据抓取 155
7.3.1 案例7-5：分析网页比赛数据 155
7.3.2 案例7-6：提取网页比赛数据 157
7.3.3 gid比赛基本数据结构 159
7.3.4 案例7-7：提取比赛得分 161
7.3.5 案例7-8：提取球队id编码 164
7.3.6 案例7-9：抓取历年比赛数据 167
7.3.7 案例7-10：流程图工具与Python 171
7.3.8 实盘技巧 172
7.3.9 案例7-11：进程池并发运行 174
7.4 批量抓取足彩网页数据实盘教程 177
7.4.1 案例7-12：批量抓取赔率数据 177
7.4.2 fb_gid_getExt扩展网页下载函数 178
7.4.3 bars节点数据包与pools彩票池 178
7.4.4 抓取扩展网页 180
7.5 足彩赔率数据抓取 181
7.5.1 gid与赔率数据网页 181
7.5.2 案例7-13：提取赔率数据 184
7.5.3 赔率数据与结构化数据 186
7.5.4 瀑布流数据网页与小数据理论 189
第8章 足彩数据回溯测试 191
8.1 TFB系统构成 192
8.1.1 TFB系统模块结构 192
8.1.2 Top-Base极宽基础模块库 192
8.1.3 Top-Football极宽足彩专业模块库 193
8.2 实盘数据更新 194
8.2.1 案例8-1：实盘数据更新 194
8.2.2 实盘要点：冗余 195
8.2.3 实盘要点：耐心 196
8.2.4 实盘要点：数据文件 197
8.2.5 main_get函数 197
8.3 变量初始化 199
8.3.1 全局变量与类定义 201
8.3.2 彩票池内存数据库 202
8.3.3 案例8-2：内存数据库&数据包 204
8.4 回溯测试 205
8.4.1 案例8-3：回溯 206
8.4.2 main_bt回溯主入口 207
8.4.3 案例8-4：实盘回溯 209
8.4.4 彩票池与统计池 211
8.4.5 poolTrd下单交易数据 212
8.4.6 poolRet回报记录数据 213
8.4.7 实盘足彩推荐分析 214
8.4.8 实盘回报分析 214
8.4.9 全数据分析与足彩数据集 215
8.5 bt_main回溯主函数 216
8.5.1 bt_1dayMain单日回溯函数 218
8.5.2 赔率数据合并函数 219
8.5.3 单日回报分析函数 220
8.5.4 单日回报分析 221
8.5.5 单场比赛回报分析 223
8.6 sta01策略的大数据分析 224
8.6.1 一号策略函数 226
8.6.2 超过100%的盈利策略与秘诀 227
8.6.3 统计分析 228
8.6.4 回溯时间测试 229
8.6.5 bt_main_ret总回报分析 230
第9章 参数智能寻优 232
9.1 一元参数寻优 233
9.1.1 案例9-1：一号策略参数寻优 233
9.1.2 一元测试函数 234
9.1.3 测试结果数据格式 236
9.1.4 案例9-2：一元参数图表分析 237
9.2 策略函数扩展 241
9.2.1 扩展一号策略函数 241
9.2.2 案例9-3：一号扩展策略 242
9.2.3 案例9-4：sta10策略 244
9.3 二元参数寻优 246
9.3.1 案例9-5：sta10参数寻优 246
9.3.2 案例9-6：二元参数图表分析 248
9.4 策略310准多因子策略 252
9.4.1 案例9-7：数据预处理 254
9.4.2 案例9-8：策略310参数寻优 257
9.4.3 案例9-9：策略310图表分析 259
9.4.4 案例9-10：策略310 264
第10章 Python人工智能入门与实践 266
10.1 从忘却开始 266
10.2 Iris经典爱丽丝 269
10.2.1 案例10-1：经典爱丽丝 270
10.2.2 案例10-2：爱丽丝进化与矢量化文本 272
10.3 AI操作流程 273
10.3.1 机器学习与测试数据集合 274
10.3.2 机器学习运行流程 274
10.3.3 经典机器学习算法 275
10.3.4 黑箱大法 275
10.3.5 数据切割函数 276
10.3.6 案例10-3：爱丽丝分解 277
10.3.7 案例10-4：线性回归算法 281
第11章 机器学习经典算法案例（上） 286
11.1 线性回归 286
11.2 逻辑回归算法 293
11.2.1 案例11-1：逻辑回归算法 294
11.3 朴素贝叶斯算法 296
11.3.1 案例11-2：贝叶斯算法 297
11.4 KNN近邻算法 299
11.4.1 案例11-3：KNN近邻算法 301
11.5 随机森林算法 302
11.5.1 案例11-4：随机森林算法 306
第12章 机器学习经典算法案例（下） 308
12.1 决策树算法 308
12.1.1 案例12-1：决策树算法 310
12.2 GBDT迭代决策树算法 311
12.2.1 案例12-2：GBDT迭代决策树算法 312
12.3 SVM向量机 313
12.3.1 案例12-3：SVM向量机算法 315
12.4 SVM-cross向量机交叉算法 316
12.4.1 案例12-4：SVM-cross向量机交叉算法 317
12.5 神经网络算法 318
12.5.1 经典神经网络算法 319
12.5.2 Sklearn神经网络算法 320
12.5.3 人工智能学习路线图 320
12.5.4 案例12-5：MLP神经网络算法 321
12.5.5 案例12-6：MLP_reg神经网络回归算法 323
第13章 机器学习组合算法 326
13.1 CCPP数据集 326
13.1.1 案例13-1：CCPP数据集 327
13.1.2 案例13-2：CCPP数据切割 328
13.1.3 数据切割函数 330
13.1.4 案例13-3：读取CCPP数据集 331
13.1.5 数据读取函数 333
13.2 机器学习统一接口函数 334
13.2.1 案例13-4：机器学习统一接口 334
13.2.2 统一接口函数 336
13.2.3 机器学习算法代码 338
13.2.4 效果评估函数 339
13.2.5 常用评测指标 340
13.3 批量调用机器学习算法 341
13.3.1 案例13-5：批量调用 341
13.3.2 批量调用算法模型 344
13.4 一体化调用 345
13.4.1 案例13-6：一体化调用 345
13.4.2 一体化调用函数 346
13.5 模型预制与保存 348
13.5.1 案例13-7：储存算法模型 348
13.5.2 模型保存函数 350
13.5.3 模型预测函数 350
13.5.4 案例13-8：批量储存算法模型 351
13.5.5 批量模型储存函数 353
13.5.6 案例13-9：批量加载算法模型 353
13.6 机器学习组合算法 357
13.6.1 案例13-10：机器学习组合算法 357
13.6.2 机器学习组合算法函数 359
第14章 足彩机器学习模型构建 361
14.1 数据整理 361
14.1.1 案例14-1：赔率数据合成 362
14.1.2 案例14-2：按年切割赔率数据 365
14.1.3 案例14-3：累计切割赔率数据 365
14.2 年度足彩赔率模型 366
14.2.1 案例14-4：2016年度足彩赔率模型组 367
14.2.2 案例14-5：年度多字段足彩赔率模型组 370
14.3 累计足彩赔率模型 373
14.3.1 案例14-6：累计2016足彩赔率模型组 373
14.3.2 案例14-7：累计多字段足彩赔率模型组 376
14.3.3 足彩算法模型文件 379
第15章 足彩机器学习模型验证 381
15.1 年度赔率模型验证 381
15.1.1 案例15-1：年度赔率模型验证 381
15.1.2 案例15-2：多字段年度赔率模型验证 383
15.2 累计赔率模型验证 385
15.2.1 案例15-3：累计赔率模型验证 385
15.2.2 案例15-4：多字段累计赔率模型验证 386
15.3 年度组合模型验证 388
15.3.1 案例15-5：年度组合模型验证 388
15.3.2 案例15-6：多字段年度组合模型验证 391
15.3.3 案例15-7：全字段年度组合模型验证 391
15.3.4 年度组合模型测试数据对比分析 392
15.4 累计组合模型验证 393
15.4.1 案例15-8：年度组合模型验证 393
15.4.2 案例15-9：多字段年度组合模型验证 394
15.4.3 累计组合模型测试数据对比分析 394
第16章 结果数据分析 397
16.1 神秘的df9 397
16.1.1 案例16-1：调试模式 397
16.1.2 神秘的df9结果数据变量 400
16.2 盈利率分析 402
16.2.1 案例16-2：盈利率计算 402
第17章 机器学习足彩实盘分析 407
17.1 回溯主入口 408
17.1.1 案例17-1：策略sta01 409
17.1.2 结果文件解读 409
17.1.3 数据字段分析 411
17.2 机器学习与回溯分析 412
17.2.1 案例17-2：Log回归策略足彩分析 414
17.2.2 Log回归策略函数 415
17.2.3 案例17-3：30天Log回归策略足彩分析 418
17.2.4 数据文件分析 420
17.2.5 足彩推荐 421
17.3 进一步深入 421
附录A Sklearn常用模块和函数 423
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>零起点Python足彩大数据与机器学习实盘分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>实用机器学习
版权
内容提要
序一
序二
前言
第1章　引论
第2章　R语言
第3章　数学基础
第4章　数据探索和预处理
第5章　回归分析
第6章　分类算法
第7章　推荐算法
第8章　排序学习
第9章　集成学习
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>实用机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习进阶实战/大数据技术丛书
前　言
第一篇　基础篇
第1章　机器学习概述 2
1.1　机器学习概述 2
1.1.1　理解大数据 2
1.1.2　机器学习发展过程 4
1.1.3　大数据生态环境 5
1.2　机器学习算法 6
1.2.1　传统机器学习 6
1.2.2　深度学习 8
1.2.3　其他机器学习 8
1.3　机器学习分类 9
1.3.1　监督学习 9
1.3.2　无监督学习 10
1.3.3　半监督学习 10
1.3.4　强化学习 10
1.4　机器学习综合应用 11
1.4.1　异常检测 12
1.4.2　用户画像 12
1.4.3　广告点击率预估 12
1.4.4　企业征信大数据应用 12
1.4.5　智慧交通大数据应用 13
1.5　本章小结 13
第2章　数据分析流程和方法 14
2.1　数据分析概述 14
2.2　数据分析流程 15
2.2.1　业务调研 16
2.2.2　明确目标 16
2.2.3　数据准备 16
2.2.4　特征处理 17
2.2.5　模型训练与评估 21
2.2.6　输出结论 23
2.3　数据分析的基本方法 24
2.3.1　汇总统计 24
2.3.2　相关性分析 25
2.3.3　分层抽样 26
2.3.4　假设检验 26
2.4　简单的数据分析实践 27
2.4.1　环境准备 27
2.4.2　准备数据 28
2.4.3　数据分析 29
2.5　本章小结 30
第二篇　算法篇
第3章　构建分类模型 32
3.1　分类模型概述 32
3.2　分类模型算法 34
3.2.1　逻辑回归 34
3.2.2　朴素贝叶斯模型 36
3.2.3　SVM模型 37
3.2.4　决策树模型 39
3.2.5　K-近邻 40
3.3　分类效果评估 40
3.3.1　正确率 41
3.3.2　准确率、召回率和F1值 41
3.3.3　ROC和AUC 42
3.4　App数据的分类实现 44
3.4.1　选择分类器 44
3.4.2　准备数据 45
3.4.3　训练模型 46
3.4.4　模型性能评估 48
3.4.5　模型参数调优 49
3.5　其他分类模型 50
3.5.1　随机森林 50
3.5.2　梯度提升树 51
3.5.3　因式分解机模型 51
3.6　本章小结 52
第4章　构建聚类模型 53
4.1　聚类概述 53
4.2　聚类模型 54
4.2.1　KMeans聚类 54
4.2.2　DBSCAN聚类 55
4.2.3　主题聚类 56
4.3　聚类效果评价 58
4.3.1　集中平方误差和 58
4.3.2　Purity评价法 59
4.4　使用KMeans对鸢尾花卉数据集聚类 59
4.4.1　准备数据 59
4.4.2　特征处理 60
4.4.3　聚类分析 60
4.4.4　模型性能评估 62
4.5　使用DBSCAN对GPS数据进行聚类 62
4.5.1　准备数据 63
4.5.2　特征处理 64
4.5.3　聚类分析 64
4.5.4　模型参数调优 65
4.6　其他模型 66
4.6.1　层次聚类 66
4.6.2　基于图的聚类 67
4.6.3　混合聚类模型 67
4.7　本章小结 68
第5章　构建回归模型 69
5.1　常用回归模型 69
5.1.1　线性回归模型 70
5.1.2　回归树模型 70
5.1.3　其他回归模型 71
5.2　评估指标 73
5.3　回归模型优化 74
5.3.1　特征选择 74
5.3.2　特征变换 74
5.4　构建UCI裙子销售数据回归模型 75
5.4.1　准备数据 75
5.4.2　训练模型 78
5.4.3　评估效果 79
5.4.4　模型优化 79
5.5　其他回归模型案例 80
5.5.1　GDP影响因素分析 81
5.5.2　大气污染分析 81
5.5.3　大数据比赛中的回归问题 81
5.6　本章小结 82
第6章　构建关联规则模型 83
6.1　关联规则概述 83
6.2　常用关联规则算法 84
6.2.1　Apriori算法 84
6.2.2　FP-Growth算法 85
6.3　效果评估和优化 86
6.3.1　效果评估 86
6.3.2　效果优化 87
6.4　使用FP-Growth对豆瓣评分数据进行挖掘 88
6.4.1　准备数据 89
6.4.2　训练模型 89
6.4.3　观察规则 91
6.4.4　参数调优 91
6.4.5　使用算法 92
6.5　其他应用场景 94
6.6　本章小结 96
第7章　协同过滤 97
7.1　协同过滤概述 97
7.2　常用的协同过滤算法 98
7.2.1　基于用户的协同过滤 99
7.2.2　基于物品的协同过滤 100
7.2.3　矩阵分解技术 101
7.2.4　推荐算法的选择 102
7.3　评估标准 103
7.3.1　准确率 103
7.3.2　覆盖率 103
7.3.3　多样性 104
7.3.4　其他指标 104
7.4　使用电影评分数据进行协同过滤实践 104
7.4.1　准备数据 105
7.4.2　训练模型 106
7.4.3　测试模型 109
7.4.4　使用ALS结果 111
7.5　本章小结 112
第8章　数据降维 113
8.1　降维概述 113
8.2　常用降维算法 114
8.2.1　主成分分析 114
8.2.2　奇异值分解 116
8.2.3　广义降维 117
8.2.4　文本降维 118
8.3　降维评估标准 121
8.4　使用PCA对Digits数据集进行降维 122
8.4.1　准备数据 122
8.4.2　训练模型 123
8.4.3　分析降维结果 124
8.5　其他降维方法 124
8.5.1　线性判别分析 124
8.5.2　局部线性嵌入 125
8.5.3　拉普拉斯特征映射 125
8.6　本章小结 126
第三篇　综合应用篇
第9章　异常检测 128
9.1　异常概述 128
9.1.1　异常的产生 129
9.1.2　异常检测的分类 129
9.2　异常检测方法 130
9.2.1　基于模型的方法 130
9.2.2　基于邻近度的方法 131
9.2.3　基于密度的方法 132
9.2.4　基于聚类的方法 133
9.3　异常检测系统 133
9.3.1　异常检测过程 133
9.
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习进阶实战/大数据技术丛书
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>scikit-learn机器学习（第2版）
第 1章　机器学习基础　1
1.1　定义机器学习　1
1.2　从经验中学习　2
1.3　机器学习任务　3
1.4　训练数据、测试数据和验证数据　4
1.5　偏差和方差　6
1.6　scikit-learn简介　8
1.7　安装scikit-learn　8
1.7.1　使用pip安装　9
1.7.2　在Windows系统下安装　9
1.7.3　在Ubuntu 16.04系统下安装　10
1.7.4　在Mac OS系统下安装　10
1.7.5　安装Anaconda　10
1.7.6　验证安装　10
1.8　安装pandas、Pillow、NLTK和matplotlib　11
1.9　小结　11
第 2章　简单线性回归　12
2.1　简单线性回归　12
2.1.1　用代价函数评价模型的拟合性　15
2.1.2　求解简单线性回归的OLS　17
2.2　评价模型　19
2.3　小结　21
第3章　用K-近邻算法分类和回归　22
3.1　K-近邻模型　22
3.2　惰性学习和非参数模型　23
3.3　KNN模型分类　23
3.4　KNN模型回归　31
3.5　小结　36
第4章　特征提取　37
4.1　从类别变量中提取特征　37
4.2　特征标准化　38
4.3　从文本中提取特征　39
4.3.1　词袋模型　39
4.3.2　停用词过滤　42
4.3.3　词干提取和词形还原　43
4.3.4　tf-idf权重扩展词包　45
4.3.5　空间有效特征向量化与哈希技巧　48
4.3.6　词向量　49
4.4　从图像中提取特征　52
4.4.1　从像素强度中提取特征　53
4.4.2　使用卷积神经网络激活项作为特征　54
4.5　小结　56
第5章　从简单线性回归到多元线性回归　58
5.1　多元线性回归　58
5.2　多项式回归　62
5.3　正则化　66
5.4　应用线性回归　67
5.4.1　探索数据　67
5.4.2　拟合和评估模型　69
5.5　梯度下降法　72
5.6　小结　76
第6章　从线性回归到逻辑回归　77
6.1　使用逻辑回归进行二元分类　77
6.2　垃圾邮件过滤　79
6.2.1　二元分类性能指标　81
6.2.2　准确率　82
6.2.3　精准率和召回率　83
6.2.4　计算F1值　84
6.2.5　ROC AUC　84
6.3　使用网格搜索微调模型　86
6.4　多类别分类　88
6.5　多标签分类和问题转换　93
6.6　小结　97
第7章　朴素贝叶斯　98
7.1　贝叶斯定理　98
7.2　生成模型和判别模型　100
7.3　朴素贝叶斯　100
7.4　在scikit-learn中使用朴素贝叶斯　102
7.5　小结　106
第8章　非线性分类和决策树回归　107
8.1　决策树　107
8.2　训练决策树　108
8.2.1　选择问题　109
8.2.2　基尼不纯度　116
8.3　使用scikit-learn类库创建决策树　117
8.4　小结　120
第9章　集成方法：从决策树到随机森林　121
9.1　套袋法　121
9.2　推进法　124
9.3　堆叠法　126
9.4　小结　128
第 10章　感知机　129
10.1　感知机　129
10.1.1　激活函数　130
10.1.2　感知机学习算法　131
10.1.3　使用感知机进行二元分类　132
10.1.4　使用感知机进行文档分类　138
10.2　感知机的局限性　139
10.3　小结　140
第 11章　从感知机到支持向量机　141
11.1　核与核技巧　141
11.2　最大间隔分类和支持向量　145
11.3　用scikit-learn分类字符　147
11.3.1　手写数字分类　147
11.3.2　自然图片字符分类　150
11.4　小结　152
第 12章　从感知机到人工神经网络　153
12.1　非线性决策边界　154
12.2　前馈人工神经网络和反馈人工神经网络　155
12.3　多层感知机　155
12.4　训练多层感知机　157
12.4.1　反向传播　158
12.4.2　训练一个多层感知机逼近XOR函数　162
12.4.3　训练一个多层感知机分类手写数字　164
12.5　小结　165
第 13章　K-均值算法　166
13.1　聚类　166
13.2　K-均值算法　168
13.2.1　局部最优值　172
13.2.2　用肘部法选择K值　173
13.3　评估聚类　176
13.4　图像量化　178
13.5　通过聚类学习特征　180
13.6　小结　184
第 14章　使用主成分分析降维　185
14.1　主成分分析　185
14.1.1　方差、协方差和协方差矩阵　188
14.1.2　特征向量和特征值　190
14.1.3　进行主成分分析　192
14.2　使用PCA对高维数据可视化　194
14.3　使用PCA进行面部识别　196
14.4　小结　199
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>scikit-learn机器学习（第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>套路！机器学习：北美数据科学家的私房课
第1章  白话数据科学  1
1.1  什么是数据科学  3
1.2  什么是数据科学家  5
1.2.1  数据科学家需要的技能  6
1.2.2  数据科学算法总结  10
1.3  数据科学可以解决什么问题  20
1.3.1  前提要求  20
1.3.2  问题种类  22
1.4  小结  25
第2章  数据集  26
2.1  服装消费者数据  26
2.2  航空公司满意度调查  33
2.3  生猪疫情风险预测数据  37
第3章  数据分析流程  41
3.1  从问题到数据  42
3.2  从数据到信息  44
3.3  从信息到行动  46
第4章  数据预处理  47
4.1  介绍  47
4.2  数据清理  50
4.3  缺失值填补  52
4.3.1  中位数或众数填补  53
4.3.2  K-近邻填补  54
4.3.3  装袋树填补  56
4.4  中心化和标量化  56
4.5  有偏分布  59
4.6  处理离群点  63
4.7  共线性  66
4.8  稀疏变量  70
4.9  编码名义变量  71
4.10  小结  73
第5章  数据操作  75
5.1  数据读写  76
5.1.1  取代传统数据框的tibble对象  76
5.1.2  高效数据读写：readr包  80
5.1.3  数据表对象读取  83
5.2  数据整合  91
5.2.1  base包：apply()  91
5.2.2  plyr包：ddply()函数  93
5.2.3  dplyr包  96
5.3  数据整形  102
5.3.1  reshape2包  102
5.3.2  tidyr包  105
5.4  小结  107
第6章  基础建模技术  109
6.1  有监督和无监督  109
6.2  误差及其来源  111
6.2.1  系统误差和随机误差  111
6.2.2  因变量误差  117
6.2.3  自变量误差  121
6.3  数据划分和再抽样  122
6.3.1  划分训练集和测试集  123
6.3.2  重抽样  131
6.4  小结  135
第7章  模型评估度量  136
7.1  回归模型评估度量  136
7.2  分类模型评估度量  139
7.2.1  Kappa统计量  141
7.2.2  ROC曲线  143
7.2.3  提升图  145
7.3  小结  146
第8章  特征工程  148
8.1  特征构建  149
8.2  特征提取  152
8.2.1  初步探索特征  153
8.2.2  主成分分析  158
8.2.3  探索性因子分析  163
8.2.4  高维标度化  167
8.2.5  知识扩展：3种降维特征提取方法的理论  171
8.3  特征选择  177
8.3.1  过滤法  178
8.3.2  绕封法  188
8.4  小结  195
第9章  线性回归及其衍生  196
9.1  普通线性回归  197
9.1.1  最小二乘线性模型  197
9.1.2  回归诊断  201
9.1.3  离群点、高杠杆点和强影响点  204
9.2  收缩方法  205
9.2.1  岭回归  205
9.2.2  Lasso  209
9.2.3  弹性网络  212
9.3  知识扩展：LASSO的变量选择功能  213
9.4  主成分和偏最小二乘回归  215
9.5  小结  221
第10章  广义线性模型压缩方法  222
10.1  初识GLMNET  223
10.2  收缩线性回归  227
10.3  逻辑回归  235
10.3.1  普通逻辑回归  235
10.3.2  收缩逻辑回归  236
10.3.3  知识扩展：群组lasso逻辑回归  239
10.4  收缩多项回归  243
10.5  泊松收缩回归  246
10.6  小结  249
第11章  树模型  250
11.1  分裂准则  252
11.2  树的修剪  256
11.3  回归树和决策树  260
11.4  装袋树  268
11.5  随机森林  273
11.6  助推法  277
11.7  知识扩展：助推法的可加模型框架  283
11.8  知识扩展：助推树的数学框架  286
11.8.1  数学表达  286
11.8.2  梯度助推数值优化  289
11.9  小结  290
第12章  神经网络  292
12.1  投影寻踪回归（PROJECTION PURSUIT REGRESSION）  293
12.2  神经网络（NEURAL NETWORKS）  296
12.3  神经网络拟合  299
12.4  训练神经网络  300
12.5  用CARET包训练神经网络  302
12.6  小结  311
参考文献  312
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>套路！机器学习：北美数据科学家的私房课
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于机器学习算法的分类知识发现及其在文本分析中的应用
第1章概述
1.1分类知识发现
1.1.1知识发现的概念和过程
1.1.2数据挖掘中的知识表示模式
1.1.3分类知识发现主要算法
1.1.4不完整数据分类知识发现
1.2文本挖掘
1.3本书内容组织
第2章不完整数据分类算法研究
2.1不完整数据分类知识发现
2.1.1不完整数据的类型
2.1.2不完整数据的处理
2.1.3不完整数据分类算法
2.1.4健壮贝叶斯分类
2.1.5朴素信念分类
2.2对现有方法的思考
2.2.1朴素信念分类算法的权重假设简单
2.2.2缺乏属性数据和类标记同时缺失情况下分类知识发现的研究
2.2.3半监督算法的效率问题
2.3不完整数据加权朴素信念分类算法
2.3.1相关分析及相关系数
2.3.2加权保守推理规则
2.3.3加权朴素信念算法分类过程
2.4标准数据集UCI上的对比实验
2.4.1实验数据集及实验设计
2.4.2实验结果分析
2.5本章小结
第3章两阶段半监督加权朴素信念分类算法研究
3.1半监督分类知识发现研究现状
3.2问题分析
3.2.1未标记样本在分类学习中的作用
3.2.2现有半监督分类方法分析
3.3两阶段分类方法相关思路
3.3.1基于规则模型的两阶段分类
3.3.2两阶段半监督文本分类
3.4两阶段半监督加权朴素信念分类
3.4.1TSS—WNC分类主要过程
3.4.2时间复杂度分析
3.5在标准数据集UCI上的实验
3.5.1分类对比实验
3.5.2实验结果及分析
3.5本章小结
第4章放松区间优势的朴素信念分类算法研究
4.1问题分析
4.2区间优势比较
4.3基于放松区间优势推理规则的不完整数据分类
4.3.1放松的区间优势
4.3.2放松的区间优势推理规则
4.3.3基于放松区间优势推理规则的分类过程
4.4在标准数据集UCI上的实验
4.4.1RCIR—NCC分类对比实验
4.4.2实验结果分析
4.5本章小结
第5章典籍英译文体风格识别研究
5.1文体风格特征
5.2文体风格识别算法
5.3典籍英译文体风格向量空间模型
5.3.1典籍英译语料特点
5.3.2典籍英译多层面文体风格模型
5.4文体风格特征选择
5.4.1信息增益
5.4.2X2统计量
5.4.3典籍英译文体风格识别特征选择
5.5特征数据项缺失文体识别实验
5.5.1加权朴素信念文体风格识别实验
5.5.2两阶段半监督文体风格识别实验
5.5.3放松区间优势朴素信念文体风格识别实验
5.5.4类别不平衡文体识别实验
5.6本章小结
第6章基于特征缺失补偿最大熵模型的文本分类
6.1最大熵模型
6.2基于Gaussian先验平滑特征补偿的最大熵模型
6.3混合特征选择算法
6.4基于特征缺失补偿最大熵模型的文本分类
6.5本章小结
第7章基于文本分析的网络舆情研究
7.1基于微博客的网络舆情指标体系
7.1.1网络舆情指标体系
7.1.2基于微博客的网络舆情指标体系
7.1.3微博客舆情预警对策
7.2基于关键字的微博客舆情传播规律
7.2.1网络舆情传播规律
7.2.2微博客网络舆情传播规律和对策
7.3基于关键字的网络舆情个案研究
7.3.1个案研究环境及实验数据
7.3.2大连地区抢盐潮个案分析
7.4微博客舆情的跨语言特征
7.4.1跨语言微博客特征表示
7.4.2跨语言微博客舆情预警研究框架
7.5网络文本情感倾向
7.5.1网络文本情感分析粒度
7.5.2网络文本情感分析基本问题
7.5.3网络文本情感分析前沿问题
7.5.4网络文本情感分析研究框架
7.6本章小结
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于机器学习算法的分类知识发现及其在文本分析中的应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于H2O的机器学习实用方法
译者序
原书前言
第 1章 安装和快速启动 1
1.1 安装准备 1
1.1.1 安装 R 1
1.1.2 安装 Python 2
1.1.3 隐私保护 2
1.1.4 安装 Java 2
1.2 利用 R（CRAN）安装 H2O 3
1.3 利用 Python（pip）安装 H2O 4
1.4 diyi个学习示例 5
1.4.1 利用 Python进行训练和预测 8
1.4.2 利用 R进行训练和预测 10
1.4.3 性能与预测 12
1.4.4 运气不佳 13
1.5 Flow 13
1.5.1 数据 14
1.5.2 模型 16
1.5.3 预测 17
1.5.4 Flow中的其他注意事项 18
1.6 小结 18
第2章 数据导入/数据导出19
2.1 存储空间要求 19
2.2 数据准备 20
2.3 数据导入到 H2O 21
2.3.1 加载 csv文件 21
2.3.2 加载其他格式文件 23
2.3.3 从 R中直接加载 23
2.3.4 从 Python中直接加载 25
2.4 数据操作 26
2.4.1 懒操作、命名和删除 26
2.4.2 数据汇总 27
2.4.3 列操作 28
2.4.4 行聚合 29
2.4.5 索引 30
2.4.6 H2O中的数据拆分 31
2.4.7 行和列 35
2.5 数据从 H2O中导出 38
2.5.1 导出数据帧 38
2.5.2 POJO 39
2.5.3 模型文件 40
2.5.4 保存所有模型 40
2.6 小结 41
第３章 数据集 42
3.1 数据集：建筑节能 42
3.1.1 设置和加载 43
3.1.2 数据列 44
3.1.3 拆分数据 45
3.1.4 观察 46
3.1.5 关于数据集 50
3.2 数据集：手写体 50
3.2.1 设置和加载 51
3.2.2 观察 52
3.2.3 帮助建模 54
3.2.4 关于数据集 55 5.4 建筑节能：默认的随机森林 91
3.3 数据集：足球比分 56
3.3.1 相关性 59
3.3.2 缺失数据.更多列 62
3.3.3 如何训练和测试？ 63
3.3.4 设置和加载 63
3.3.5 其他第三方 64
3.3.6 缺失数据（再次） 67
3.3.7 设置和加载（再次） 67
3.3.8 关于数据集 70
3.4 小结 70
第 4章 常用模型参数 71
4.1 支持测度 71
4.1.1 回归指数 72
4.1.2 分类指数 72
4.1.3 二项式分类 73
4.2 要素 75
4.3 努力 76
4.4 评分和验证 76
4.5 提前终止 77
4.6 检查点 79
4.7 交叉验证（又名 k-folds） 81
4.8 数据加权 82
4.9 抽样、归纳 84
4.10 回归 85
4.11 输出控制 87
4.12 小结 87
第5章 随机森林88
5.1 决策树 88
5.2 随机森林 89
5.3 参数 89 5.5 网格搜索 93
5.5.1 笛卡尔 94
5.5.2 随机离散 96
5.5.3 高层策略 98
5.6 建筑节能：改进的随机森林 99
5.7 MNIST：默认的随机森林 101
5.8 MNIST：改进的随机森林 102
5.8.1 增强数据 105
5.9 足球比赛：默认的随机森林 106
5.10 足球比赛：改进的随机森林 108
5.11 小结 110
第 6章 梯度推进机 // 111
6.1 推进 // 111
6.2 好处、坏处和…神秘之处 // 112
6.3 参数 // 113
6.4 建筑节能：默认 GBM // 114
6.5 建筑节能：改进 GBM // 115
6.6 MNIST：默认 GBM // 119
6.7 MNIST：改进 GBM // 120
6.8 足球比赛：默认 GBM // 122
6.9 足球比赛：改进 GBM // 123
6.10 小结 // 125
第 7章 线性模型 // 126
7.1 GLM参数 // 126
7.2 建筑节能：默认 GLM // 130
7.3 建筑节能：改进 GLM // 132
7.4 MNIST：默认 GLM // 136
7.5 MNIST：改进 GLM // 137
7.6 足球比赛：默认 GLM // 139
7.7 足球比赛：改进 GLM // 141
7.8 小结 // 142
第 8章 深度学习（神经网络）// 143
8.1 什么是神经网络？ // 143
8.1.1 数值与分类 // 145
8.1.2 神经网络层 // 146
8.1.3 激活函数 // 147
8.2 参数 // 148
8.2.1 深度学习正则化 // 148
8.2.2 深度学习评分 // 149
8.3 建筑节能：默认的深度学习 // 152
8.4 建筑节能：改进的深度学习 // 153
8.5 MNIST：默认的深度学习 // 157
8.6 MNIST：改进的深度学习 // 159
8.7 足球比赛：默认的深度学习 // 163
8.8 足球比赛：改进的深度学习 // 164
8.9 小结 // 168
8.10 附录：更多的深度学习参数 // 169
第 9章 无监督学习 // 171
9.1 k均值聚类 // 172
9.2 深度学习自动编码器 // 174
9.2.1 层叠自动编码器 // 177
9.3 主成分分析 // 178
9.4 GLRM // 179
9.5 缺失数据 // 180
9.5.1 GLRM // 183
9.5.2 失去 R // 183
9.6 小结 // 187
第 10章 其他内容 // 188
10.1 重要且需要分析的内容 // 188
10.2 安装zui新版本的 H2O // 188
10.2.1 由源代码构建 // 189
10.3 命令行运行 // 189
10.4 聚类 // 189
10.4.1 EC2 // 190
10.4.2 其他云提供商 // 191
10.4.3 Hadoop // 191
10.5 Spark/Sparkling Water // 191
10.6 朴素贝叶斯 // 192
10.7 集成 // 192
10.7.1 层叠： h2o.ensemble // 193
10.7.2 分类集成 // 195
10.8 小结 // 195
第 11章 后记：一切运行良好！ // 196
11.1 建筑节能结果 // 196
11.2 MNIST结果 // 197
11.3 足球比赛结果 // 199
11.4 究竟有多差？ // 200
11.4.1 越多越好 // 201
11.4.2 仍渴望更多 // 202
11.4.3 困难排除 // 202
11.4.4 自动编码器 // 203
11.4.5 卷积和收缩 // 204
11.4.6 集成 // 205
11.4.7 这就是可能zui差的情况. // 206
11.5 小结 // 206
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于H2O的机器学习实用方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于R语言的机器学习
前言 1
第1章 什么是模型？ 5
算法与模型有什么不同？ 10
术语说明 12
模型的局限性 13
建模中的统计与计算 15
数据训练 16
交叉验证 17
为什么使用R语言？ 18
优点 19
缺点 22
小结 23
第2章 监督学习与无监督机器学习 25
监督模型 26
回归 26
训练数据与测试数据 28
分类 30
混合方法 37
无监督学习 47
无监督聚类方法 48
小结 50
第3章 R语言中的采样统计和模型训练 52
偏差 53
R语言中的采样 58
训练与测试 61
交叉验证 74
小结 76
第4章 全面解析回归 78
线性回归 79
多项式回归 88
拟合数据的优点——过度拟合的风险 95
逻辑回归 98
小结 112
第5章 全面解析神经网络 115
单层神经网络 115
用R语言建立一个简单的神经网络 116
多层神经网络 125
回归神经网络 131
神经网络分类 136
使用caret的神经网络 137
小结 139
第6章 基于树的方法 141
简单的树模型 141
决定树的分割方式 143
决策树的优点和缺点 147
条件推理树 158
随机森林 161
小结 164
第7章 其他高级方法 165
朴素贝叶斯分类 165
主成分分析 169
支持向量机 179
k最近邻算法 185
小结 191
第8章 使用caret包实现机器学习 192
泰坦尼克号数据集 193
使用caret 196
小结 207
附录A caret机器学习模型大全 209
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于R语言的机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础
第1章绪论
1.1从两个问题谈起
1.2模型评估与模型参数选择
1.2.1验证
1.2.2正则化
1.3机器学习算法分类
1.3.1监督学习
1.3.2非监督学习
习题
第2章回归
2.1线性回归
2.2Logistic回归
习题
第3章LDA主题模型
3.1LDA简介
3.2数学基础
3.2.1多项分布
3.2.2Dirichlet分布
3.2.3共轭先验分布
3.3LDA主题模型
3.3.1基础模型
3.3.2PLSA模型
3.3.3LDA模型
3.4LDA模型应用实例
3.4.1配置安装
3.4.2文本预处理
3.4.3使用Gensim
习题
第4章决策树
4.1决策树简介
4.1.1一个小例子
4.1.2几个重要的术语及决策树构造思路
4.2离散型决策树的构造
4.3连续性数值的处理
4.4决策树剪枝
习题
第5章支持向量机
5.1分离超平面与最大间隔
5.2线性支持向量机
5.2.1硬间隔
5.2.2软间隔
5.3非线性支持向量机
5.3.1核方法
5.3.2常用的核函数
5.4操作实例： 应用MATLAB多分类SVM、二分类SVM、决策树
算法进行分类
5.4.1数据集选择
5.4.2数据预处理
5.4.3模型表现
5.4.4经验总结
习题
第6章提升方法
6.1随机森林
6.1.1随机森林介绍
6.1.2Bootstrap Aggregation
6.1.3随机森林训练过程
6.1.4随机森林的优点与缺点
6.2Adaboost
6.2.1引入
6.2.2Adaboost实现过程
6.2.3Adaboost总结
6.3随机森林算法应用举例
6.3.1MATLAB中随机森林算法
6.3.2操作实例1： 基于集成方法的IRIS数据集分类
6.3.3操作实例2： 基于ensemble方法的人脸识别
习题
第7章神经网络基础
7.1基础概念
7.2感知机
7.2.1单层感知机
7.2.2多层感知机
7.3BP神经网络
7.3.1梯度下降
7.3.2后向传播
7.4径向基函数网络
7.4.1精确插值与径向基函数
7.4.2径向基函数网络
7.5Hopfield网络
7.5.1Hopfield网络的结构
7.5.2Hopfield网络的训练
7.5.3Hopfield网络状态转移
7.6Boltzmann机
7.7自组织映射网络
7.7.1网络结构
7.7.2训练算法
7.8实例： 使用MATLAB进行Batch Normalization
7.8.1浅识Batch Normalization
7.8.2MATLAB nntool使用简介
习题
第8章深度神经网络
8.1什么是深度神经网络
8.2卷积神经网络
8.2.1卷积神经网络的基本思想
8.2.2卷积操作
8.2.3池化层
8.2.4卷积神经网络
8.3循环神经网络
8.3.1循环单元
8.3.2通过时间后向传播
8.3.3带有门限的循环单元
8.4MATLAB深度学习工具箱简介
8.5利用Theano搭建和训练神经网络
8.5.1Theano简介
8.5.2Theano的基本使用
8.5.3搭建训练神经网络的项目
习题
第9章聚类算法
9.1简介
9.1.1聚类任务
9.1.2基本表示
9.2KMeans算法
9.2.1算法简介
9.2.2算法流程
9.2.3KMeans的一些改进
9.2.4选择合适的K
9.2.5XMeans
9.3层次聚类
9.4聚类算法拓展
9.4.1聚类在信号处理领域的应用
9.4.2以语义聚类的形式展示网络图像搜索结果
习题
第10章寻优算法之遗传算法
10.1简介
10.1.1算法起源
10.1.2基本过程
10.1.3基本表示
10.1.4输入输出
10.1.5优缺点及应用
10.2算法原型
10.2.1初始化
10.2.2评估
10.2.3选择优秀个体
10.2.4交叉
10.2.5变异
10.2.6迭代
10.3算法拓展
10.3.1精英主义思想
10.3.2灾变
习题
第11章项目实践： 基于机器学习的监控视频行人检测与追踪系统
11.1引言
11.2相关算法与指标
11.2.1方向梯度直方图
11.2.2支持向量机
11.2.3结构相似性
11.2.4HaarLike特征
11.2.5级联分类器
11.2.6特征脸
11.3系统设计与实现
11.3.1视频处理模块
11.3.2图像识别模块
11.3.3目标追踪模块
11.4系统测试
11.4.1测试环境
11.4.2系统单元测试与集成测试
11.4.3性能测试
11.4.4系统识别准确率测试
11.5结语
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习线性代数基础
第1章 坐标与变换：高楼平地起
1.1 描述空间的工具：向量 2
1.2 基底构建一切，基底决定坐标 13
1.3 矩阵，让向量动起来 18
1.4 矩阵乘向量的新视角：变换基底 27
第2章 空间与映射：矩阵的灵魂
2.1 矩阵：描述空间中的映射 34
2.2 追因溯源：逆矩阵和逆映射 42
2.3 向量空间和子空间 50
2.4 老树开新花，道破方程组的解 55
第3章 近似与拟合：真相最近处
3.1 投影，寻找距离最近的向量 62
3.2 深入剖析最小二乘法的本质 69
3.3 施密特正交化：寻找最佳投影基 74
第4章 相似与特征：最佳观察角
4.1 相似变换：不同的视角，同一个变换 80
4.2 对角化：寻找最简明的相似矩阵 85
4.3 关键要素：特征向量与特征值 89
第5章 降维与压缩：抓住主成分
5.1 最重要的矩阵：对称矩阵 96
5.2 数据分布的度量 100
5.3 利用特征值分解（EVD）进行主成分分析（PCA） 103
5.4 更通用的利器：奇异值分解（SVD） 111
5.5 利用奇异值分解进行数据降维 116
第6章 实践与应用：线代用起来
6.1 SVD在推荐系统中的应用 124
6.2 利用SVD进行彩色图片压缩 133
第7章 函数与复数域：概念的延伸
7.1 傅里叶级数：从向量的角度看函数 145
7.2 复数域中的向量和矩阵 151
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习线性代数基础
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB与机器学习
第一部分 机器学习概论
第1章 机器学习概述
1.1 引言
1.2 机器学习基础
1.2.1 数据
1.2.2 模型
1.2.3 训练
1.3 学习机
1.4 机器学习分类
1.5 自主学习方法
1.5.1 回归
1.5.2 神经网络
1.5.3 支持向量机
1.5.4 决策树
1.5.5 专家系统
第2章 自主学习的历史
2.1引言
2.2 人工智能
2.3 学习控制
2.4 机器学习
2.5 未来
第3章 机器学习软件
3.1 自主学习软件
3.2 商业化MATLAB软件
3.2.1 MathWorks公司产品
3.2.2 普林斯顿卫星系统产品
3.3 MATLAB开源资源
3.3.1 深度学习工具箱
3.3.2 深度神经网络
3.3.3 MatConvNet
3.4 机器学习工具
3.4.1 R语言
3.4.2 Scikit learn
3.4.3 LIBSVM
3.5 优化工具
3.5.1 LOQO
3.5.2 SNOPT
3.5.3 GLPK
3.5.4 CVX
3.5.5 SeDuMi
3.5.6 YALMIP
第二部分 机器学习的MATLAB实现
第4章 用于机器学习的MATLAB数据类型
4.1 MATLAB数据类型概述
4.1.1 矩阵
4.1.2 元胞数组
4.1.3 数据结构
4.1.4 数值类型
4.1.5 图像
4.1.6 数据存储
4.1.7 Tall数组
4.1.8 稀疏矩阵
4.1.9 表与分类数组
4.1.10 大型MAT文件
4.2 使用参数初始化数据结构
4.2.1 问题
4.2.2 方法
4.2.3 步骤
4.3 在图像数据存储上执行mapReduce
4.3.1 问题
4.3.2 方法
4.3.3 步骤
总结
第5章MATLAB图形
5.1 二维线图
5.1.1 问题
5.1.2 方法
5.1.3 步骤
5.2二维图形
5.2.1 问题
5.2.2 方法
5.2.3 步骤
5.3 定制二维图
5.3.1 问题
5.3.2 方法
5.3.3 步骤
5.4 三维盒子
5.4.1 问题
5.4.2 方法
5.4.3 步骤
5.5 用纹理绘制三维对象
5.5.1 问题
5.5.2 方法
5.5.3 步骤
5.6 三维图形
5.6.1 问题
5.6.2 方法
5.6.3 步骤
5.7 构建图形用户界面
5.7.1 问题
5.7.2 方法
5.7.3 步骤
总结
第6章 MATLAB机器学习示例
6.1引言
6.2 机器学习
6.2.1 神经网络
6.2.2 面部识别
6.2.3 数据分类
6.3 控制
6.3.1卡尔曼滤波器
6.3.2自适应控制
6.4人工智能
第7章 基于深度学习的面部识别
7.1在线获取数据：用于训练神经网络
7.1.1 问题
7.1.2 方法
7.1.3 步骤
7.2 生成神经网络的训练数据
7.2.1 问题
7.2.2 方法
7.2.3 步骤
7.3 卷积
7.3.1 问题
7.3.2 方法
7.3.3 步骤
7.4卷积层
7.4.1 问题
7.4.2 方法
7.4.3 步骤
7.5 池化
7.5.1 问题
7.5.2 方法
7.5.3 步骤
7.6 全连接层
7.6.1 问题
7.6.2 方法
7.6.3 步骤
7.7 确定输出概率
7.7.1 问题
7.7.2 方法
7.7.3 步骤
7.8 测试神经网络
7.8.1 问题
7.8.2 方法
7.8.3 步骤
7.9 识别图像
7.9.1 问题
7.9.2 方法
7.9.3 步骤
总结
第8章 数据分类
8.1 生成分类测试数据
8.1.1 问题
8.1.2 方法
8.1.3 步骤
8.2 绘制决策树
8.2.1 问题
8.2.2 方法
8.2.3 步骤
8.3 决策树的算法实现
8.3.1 问题
8.3.2 方法
8.3.3 步骤
8.4 生成决策树
8.4.1 问题
8.4.2 方法
8.4.3 步骤
8.5 手工创建决策树
8.5.1 问题
8.5.2 方法
8.5.3 步骤
8.6 训练和测试决策树
8.6.1 问题
8.6.2 方法
8.6.3 步骤
总结
第9章 基于神经网络的数字分类
9.1 生成带噪声的测试图像
9.1.1 问题
9.1.2 方法
9.1.3 步骤
9.2创建神经网络工具箱
9.2.1 问题
9.2.2 方法
9.2.3 步骤
9.3 训练单一输出节点的神经网络
9.3.1 问题
9.3.2 方法
9.3.3 步骤
9.4 测试神经网络
9.4.1 问题
9.4.2 方法
9.4.3 步骤
9.5 训练多输出节点的神经网络
9.5.1 问题
9.5.2 方法
9.5.3 步骤
总结
第10章 卡尔曼滤波器
10.1 状态估计器
10.1.1 问题
10.1.2 方法
10.1.3 步骤
10.1.4 传统卡尔曼滤波器
10.2 使用UKF进行状态估计
10.2.1 问题
10.2.2 方法
10.2.3 步骤
10.3 使用UKF进行参数估计
10.3.1 问题
10.3.2 方法
10.3.3 步骤
总结
第11章 自适应控制
11.1 自调谐：求振荡器频率
11.1.1 问题
11.1.2 方法
11.1.3 步骤
11.2 模型参考自适应控制
11.2.1 创建方波输入
11.2.2 实现模型参考自适应控制
11.2.3 转子的MRAC系统实现
11.3 飞机的纵向控制
11.3.1 编写飞机纵向运动的微分方程
11.3.2 利用数值方法寻找平衡状态
11.3.3 飞机的数值仿真
11.3.4 神经网络中对取值范围的限定和缩放
11.3.5 寻找学习控制的神经网络
11.3.6 枚举输入集合
11.3.7 编写通用神经网络函数
11.3.8 实现PID控制
11.3.9 飞机俯仰角PID控制演示
11.3.10 创建俯仰动力学的神经网络
11.3.11 非线性仿真中的控制器演示
11.4 轮船驾驶：实现轮船驾驶控制的增益调度
11.4.1 问题
11.4.2 方法
11.4.3 步骤
总结
第12章 自动驾驶
12.1 汽车雷达建模
12.1.1 问题
12.1.2 步骤
12.1.3 方法
12.2 汽车的自主传递控制
12.2.1 问题
12.2.2 方法
12.2.3 步骤
12.3 汽车动力学
12.3.1 问题
12.3.2 步骤
12.3.3 方法
12.4 汽车仿真与卡尔曼滤波器
12.4.1 问题
12.4.2 方法
12.4.3 步骤
12.5 雷达数据的MHT实现
12.5.1问题
12.5.2 方法
12.5.3 步骤
12.5.4 假设形成
12.5.5 轨道剪枝
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB与机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习、大数据分析和可视化
模块1 机器学习的概念
第1讲 理解机器学习技术 3
1．1 什么是机器学习 4
1．1．1 数据挖掘与机器学习之间的差异 5
1．1．2 SpamAssassin特性 6
1．2 机器学习的应用 8
1．2．1 图像识别 8
1．2．2 语音识别 10
1．2．3 医疗诊断 10
1．2．4 统计套利 11
1．2．5 关联学习 11
1．2．6 分类 11
1．2．7 预测 12
1．2．8 提取 13
1．2．9 回归 13
1．2．10 概率 13
1．3 机器学习的类型 14
1．3．1 有监督学习 14
1．3．2 无监督学习 15
1．3．3 强化学习 15
1．4 机器学习方法 16
1．4．1 决策树学习 16
1．4．2 关联规则学习 16
1．4．3 人工神经网络 17
1．4．4 归纳逻辑编程 17
1．4．5 支持向量机 17
1．4．6 聚类 18
1．4．7 贝叶斯网络 18
1．4．8 强化学习 18
1．4．9 表示学习 18
1．4．10 相似性和度量学习 18
1．4．11 稀疏字典学习 19
1．5 机器学习算法列表 19
练习 22
备忘单 24
第2讲 R上的图模型和贝叶斯网络 25
2．1 图模型简介 26
2．1．1 图模型的类型 30
2．1．2 图中的条件独立性 32
2．1．3 图中的条件独立性与分割 33
2．1．4 图的分解或者因子化 35
2．1．5 图模型的应用 36
2．2 案例研究——图模型在大众公司的应用 37
2．2．1 背景 37
2．2．2 问题 37
2．2．3 解决方案 38
2．3 贝叶斯统计简介 38
2．3．1 贝叶斯定理 39
2．3．2 贝叶斯网络 39
2．4 贝叶斯网络特性 43
2．5 贝叶斯网络中的概率推理 49
2．5．1 推断未观测变量 49
2．5．2 参数学习 49
2．5．3 结构学习 49
2．6 贝叶斯方法 51
2．6．1 变量消除 51
2．6．2 动态编程 52
2．6．3 逼近算法 52
2．7 贝叶斯网络的应用 54
练习 57
备忘单 59
第3讲 人工神经网络 60
3．1 神经网络简介 62
3．2 神经网络的应用 65
3．3 神经网络的结构 66
3．4 人工神经网络模型 68
3．4．1 多层感知器 68
3．4．2 径向基函数网络 69
3．4．3 Kohonen网络 70
3．5 学习规则 72
3．5．1 Hebbian学习规则 73
3．5．2 感知器学习规则 73
3．5．3 Delta学习规则（Windrow-Hoff学习规则） 74
3．5．4 相关学习规则 74
3．5．5 外向星学习规则 74
3．6 神经网络训练算法 75
3．6．1 梯度下降 76
3．6．2 演化算法 77
3．6．3 遗传算法 78
3．7 在R中实现神经网络 80
练习 84
备忘单 87
第4讲 在R中使用PCA和因子分析降维 88
4．1 降维简介 90
4．2 降维的应用 91
4．2．1 文档分类 91
4．2．2 基因表达微阵列分析 92
4．2．3 面部识别 93
4．3 因子分析 94
4．4 因子分析的应用 96
4．4．1 心理测验学中的因子分析 96
4．4．2 营销中的因子分析 97
4．5 因子分析方法 98
4．5．1 EFA和CFA的相似之处 98
4．5．2 EFA和CFA之间的差异 98
4．6 作为数据归约方法的因子分析 99
4．6．1 确定因子数量的标准 101
4．6．2 公因子方差 102
4．6．3 因子载荷 103
4．6．4 因子结构的旋转 104
4．6．5 旋转策略 104
4．6．6 因子结构的解读 105
4．6．7 层次化因子分析 106
4．6．8 因子得分 107
4．7 主成分分析 107
4．7．1 主成分分析的显著性 108
4．7．2 主成分的提取 108
4．7．3 主成分的特性 108
4．7．4 主成分分析的特性 109
4．8 主成分分析中的数据归约和解读 109
4．8．1 投影于一个轴上的惯性 110
4．8．2 距离 110
4．8．3 逆方差 110
4．8．4 协方差 111
4．8．5 变量的范数 112
4．8．6 因子轴 112
4．8．7 因子平面 112
4．8．8 主成分分析的目标 113
4．8．9 相关矩阵的特征值 113
4．8．10 变量的表示 113
4．8．11 个体的表示 114
4．8．12 主成分分析过程 114
4．8．13 选择主成分数量 116
4．8．14 主成分分析的变种 118
4．9 在R上实现主成分分析 120
4．9．1 示例1：欧洲人的蛋白质消耗 120
4．9．2 示例2：美国月度失业率 122
练习 123
备忘单 125
第5讲 支持向量机 127
5．1 支持向量机简介 128
5．2 支持向量机的应用领域 129
5．3 SVM算法 131
5．3．1 可分情况 132
5．3．2 不可分情况 133
5．4 线性支持向量机 135
5．4．1 原型 135
5．4．2 对偶形式 136
5．4．3 有偏和无偏超平面 137
5．5 核函数 137
5．5．1 核规则 137
5．5．2 支持向量机核示例 139
5．6 在R中训练和测试SVM模型 139
5．7 用SVM模型预测的实例 143
5．7．1 数据集 143
5．7．2 准备数据集 144
5．7．3 选择参数 144
5．7．4 训练模型 145
5．7．5 测试模型 146
练习 147
备忘单 149
模块2 社交媒体、移动分析和可视化
第1讲 大数据解决方案工程 153
1．1 大数据展望过程 154
1．1．1 步骤1：研究和面谈以理解业务活动 155
1．1．2 步骤2：获取和分析数据 157
1．1．3 步骤3：对新思路展开头脑风暴 158
1．1．4 步骤4：排定大数据集用例的优先级 159
1．1．5 步骤5：文档 160
1．2 大数据用例的优先级排定 160
1．2．1 优先顺序矩阵过程 161
1．2．2 优先顺序矩阵的陷阱 162
1．3 解决方案工程过程 164
1．3．1 第1步：理解组织是如何赚钱的 164
1．3．2 第2步：识别组织的关键业务活动 167
1．3．3 第3步：进行头脑风暴，确定大数据在业务上的作用 167
1．3．4 第4步：将业务活动分解为用例 168
1．3．5 第5步：证明用例 168
1．3．6 第6步：设计和实施大数据解决方案 169
1．4 解决方案工程示例 170
1．4．1 客户行为分析 171
1．4．2 减少欺诈行为 172
1．5 大数据解决方案的挑战 172
练习 174
备忘单 176
第2讲 社交媒体分析和文本分析 177
2．1 什么是社交媒体 178
2．2 社交分析、指标和计量 181
2．2．1 社交媒体分析工具 181
2．2．2 社交媒体分析与业务决策 182
2．2．3 社交媒体分析与其他分析类型的对比 184
2．3 社交媒体分析的关键要素 184
2．3．1 目标受众 184
2．3．2 预期行动 185
2．3．3 内容 185
2．3．4 内容机制 185
2．3．5 社交媒体分析中使用的技术 186
2．3．6 在线社交媒体分析工具 187
2．3．7 社交媒体分析所用的桌面应用程序 187
2．4 文本挖掘简介 188
2．4．1 文本挖掘工作方式 189
2．4．2 文本挖掘的应用 190
2．5 文本分析过程 190
2．6 情绪分析 192
2．6．1 情绪分析使用的方法 193
2．6．2 在线情绪分析 193
2．7 在R上实施Twitter情绪分析 194
练习 203
备忘单 205
第3讲 执行移动分析 207
3．1 移动分析简介 208
3．1．1 什么是移动分析 209
3．1．2 移动分析和Web分析 209
3．1．3 移动分析和商业价值 210
3．1．4 移动分析结果类型 210
3．1．5 移动分析应用类型 211
3．1．6 使用移动分析的领域 212
3．2 移动分析工具 212
3．2．1 基于位置的跟踪工具 213
3．2．2 实时分析工具 213
3．2．3 用户行为跟踪工具 214
3．3 执行移动分析 216
3．3．1 通过移动应用收集数据 216
3．3．2 将数据收集到服务器 217
3．4 应用分析报告 218
3．5 移动分析的挑战 219
3．5．1 网络问题 219
3．5．2 安全性问题和政府协议 220
练习 221
备忘单 223
第4讲 大数据可视化 225
4．1 什么是可视化 226
4．1．1 为什么对数据进行可视化 226
4．1．2 可视化技术 227
4．1．3 可视化类型 227
4．1．4 可视化的应用 228
4．2 大数据可视化的重要性 229
4．2．1 传统信息可视化的不足 229
4．2．2 大数据可视化的商业价值 229
4．2．3 用可视化将数据变成信息 230
4．2．4 使用不同工具的可视化示例 231
4．2．5 大数据可视化中的障碍 233
4．3 大数据可视化工具 233
4．3．1 大数据可视化专属服务 234
4．3．2 开源可视化程序库 234
4．3．3 用于大数据可视化的技术 235
4．4 Tableau产品 235
4．4．1 用Tableau Desktop创建可视化 236
4．4．2 Tableau Desktop工作区简介 239
4．4．3 多个工作表页面 240
4．4．4 Tableau工作区 240
4．5 使用数据源 246
4．5．1 用Tableau联合数据库表 246
4．5．2 连接到SQL 247
4．6 数据运算（排序、聚合、联接） 248
4．6．1 地图和地理单元 249
4．6．2 创建交互式可视化 251
练习 254
备忘单 256
第5讲 招聘准备 258
5．1 大数据分析师所需要的关键技能 260
5．2 大数据分析岗位职责 262
5．2．1 初级分析师 262
5．2．2 中级分析师 263
5．2．3 高级分析师 263
5．3 大数据工作机会领域 264
模块3 大数据分析的行业应用
第1讲 大数据业务问题和解决方案—保险欺诈分析 273
1．1 背景 274
1．1．1 保险合同 275
1．1．2 保单类型 275
1．2 保险欺诈及其影响 276
1．3 场景 277
1．4 数据的解释 277
1．5 方法论 278
1．6 具体做法 279
1．7 结论 280
第2讲 大数据业务问题和解决方案—信用风险 281
2．1 背景 282
2．2 场景 283
2．3 数据的解释 284
2．4 方法论和具体做法 285
2．5 结论 287
第3讲 大数据业务问题和解决方案—典型行业 288
3．1 背景 289
3．1．1 客户流失 289
3．1．2 缺乏最优营销策略 289
3．1．3 呼叫数据记录（CDR）分析的需求 290
3．2 为增加利润而进行数据分析 290
3．2．1 避免客户流失 290
3．2．2 采用最优的营销策略 290
3．2．3 分析呼叫详细记录 291
3．3 场景 291
3．4 数据的解释 291
3．5 方法论 294
3．6 具体做法 295
3．6．1 高管视图 295
3．6．2 中层管理视图 296
3．6．3 代理人视图 296
3．7 结论 298
第4讲 大数据业务问题和解决方案—在线客户细分 299
4．1 背景 300
4．2 为客户细分进行数据分析 301
4．3 场景 302
4．4 数据的解释 302
4．5 方法论 302
4．6 具体做法 303
4．7 结论 305
第5讲 大数据业务问题和解决方案—在电子商务中使用可视化工具 306
5．1 背景 307
5．2 场景 310
5．3 数据的解释 310
5．4 方法论 311
5．5 具体做法 311
5．6 结论 317
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习、大数据分析和可视化
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python+Spark 2.0+Hadoop机器学习与大数据实战
目   录


第1章  Python Spark机器学习与Hadoop大数据     1
1.1  机器学习的介绍   2
1.2 Spark的介绍 5
1.3 Spark数据处理 RDD、DataFrame、Spark SQL  7
1.4  使用Python开发 Spark机器学习与大数据应用       8
1.5 Python Spark 机器学习         9
1.6 Spark ML Pipeline机器学习流程介绍  10
1.7 Spark 2.0的介绍    12
1.8  大数据定义   13
1.9 Hadoop 简介          14
1.10 Hadoop HDFS分布式文件系统  14
1.11 Hadoop MapReduce的介绍        17
1.12 结论      18
第2章  VirtualBox虚拟机软件的安装        19
2.1 VirtualBox的下载和安装      20
2.2  设置VirtualBox存储文件夹          23
2.3  在VirtualBox创建虚拟机     25
2.4  结论        29
第3章  Ubuntu Linux 操作系统的安装      30
3.1 Ubuntu Linux 操作系统的安装    31
3.2  在Virtual设置Ubuntu虚拟光盘文件 33
3.3  开始安装Ubuntu  35
3.4  启动Ubuntu  40
3.5  安装增强功能        41
3.6  设置默认输入法   45
3.7  设置“终端”程序        48
3.8  设置“终端”程序为白底黑字   49
3.9  设置共享剪贴板   50
3.10 设置最佳下载服务器 52
3.11 结论      56
第4章  Hadoop Single Node Cluster的安装        57
4.1  安装JDK         58
4.2  设置SSH无密码登录    61
4.3  下载安装Hadoop  64
4.4  设置Hadoop环境变量 67
4.5  修改Hadoop配置设置文件 69
4.6  创建并格式化HDFS目录     73
4.7  启动Hadoop  74
4.8  打开HadoopResource-Manager Web界面 76
4.9 NameNode HDFS Web界面   78
4.10 结论      79
第5章  Hadoop Multi Node Cluster的安装         80
5.1  把Single NodeCluster复制到data1    83
5.2  设置VirtualBox网卡     84
5.3  设置data1服务器         87
5.4  复制data1服务器到data2、data3、master     94
5.5  设置data2服务器         97
5.6  设置data3服务器         100
5.7  设置master服务器      102
5.8 master连接到data1、data2、data3 创建HDFS目录      107
5.9  创建并格式化NameNodeHDFS目录  110
5.10 启动Hadoop Multi Node Cluster         112
5.11 打开Hadoop ResourceManager Web界面         114
5.12 打开NameNode Web界面 115
5.13 停止Hadoop Multi Node Cluster         116
5.14 结论      116
第 6 章  Hadoop HDFS命令        117
6.1  启动HadoopMulti-Node Cluster  118
6.2  创建与查看HDFS目录 120
6.3  从本地计算机复制文件到HDFS  122
6.4  将HDFS上的文件复制到本地计算机 127
6.5  复制与删除HDFS文件 129
6.6  在Hadoop HDFSWeb用户界面浏览HDFS  131
6.7  结论        134
第7章  Hadoop MapReduce         135
7.1  简单介绍WordCount.java     136
7.2  编辑WordCount.java     137
7.3  编译WordCount.java     141
7.4  创建测试文本文件        143
7.5  运行WordCount.java     145
7.6  查看运行结果        146
7.7  结论        147
第8章  Python Spark的介绍与安装   148
8.1 Scala的介绍与安装       150
8.2  安装Spark      153
8.3  启动pyspark交互式界面     156
8.4  设置pyspark显示信息 157
8.5  创建测试用的文本文件        159
8.6  本地运行pyspark程序 161
8.7  在Hadoop YARN运行pyspark      163
8.8  构建SparkStandalone Cluster运行环境      165
8.9  在SparkStandalone运行pyspark         171
8.10 Spark Web UI界面        173
8.11 结论      175
第9章  在 IPythonNotebook 运行 Python Spark 程序   176
9.1  安装Anaconda       177
9.2  在IPythonNotebook使用Spark   180
9.3  打开IPythonNotebook笔记本     184
9.4  插入程序单元格   185
9.5  加入注释与设置程序代码说明标题   186
9.6  关闭IPythonNotebook 188
9.7  使用IPythonNotebook在Hadoop YARN-client模式运行   189
9.8  使用IPythonNotebook在Spark Stand Alone模式运行       192
9.9  整理在不同的模式运行IPythonNotebook的命令     194
9.9.1 在 Local 启动 IPython Notebook     195
9.9.2 在Hadoop YARN-client 模式启动 IPython Notebook       195
9.9.3 在Spark Stand Alone 模式启动 IPython Notebook 195
9.10 结论      196
第10章  Python Spark RDD 197
10.1 RDD的特性 198
10.2 开启IPython Notebook        199
10.3 基本RDD“转换”运算     201
10.4 多个RDD“转换”运算     206
10.5 基本“动作”运算      208
10.6 RDD Key-Value 基本“转换”运算   209
10.7 多个RDD Key-Value“转换”运算     212
10.8 Key-Value“动作”运算      215
10.9 Broadcast 广播变量   217
10.10 accumulator累加器  220
10.11 RDD Persistence持久化   221
10.12 使用Spark创建WordCount      223
10.13 Spark WordCount详细解说       226
10.14 结论   228
第11章  Python Spark的集成开发环境     229
11.1 下载与安装eclipse Scala IDE      232
11.2 安装PyDev  235
11.3 设置字符串替代变量 240
11.4 PyDev 设置 Python 链接库       243
11.5 PyDev设置anaconda2链接库路径   245
11.6 PyDev设置Spark Python链接库         247
11.7 PyDev设置环境变量  248
11.8 新建PyDev项目 251
11.9 加入WordCount.py程序     253
11.10 输入WordCount.py程序  254
11.11 创建测试文件并上传至HDFS目录 257
11.12 使用spark-submit执行WordCount程序         259
11.13 在Hadoop YARN-client上运行WordCount程序      261
11.14 在Spark Standalone Cluster上运行WordCount程序      264
11.15 在eclipse外部工具运行Python Spark程序    267
11.16 在eclipse运行spark-submit YARN-client          273
11.17 在eclipse运行spark-submit Standalone 277
11.18 结论   280
第12章  Python Spark创建推荐引擎 281
12.1 推荐算法介绍      282
12.2 “推荐引擎”大数据分析使用场景 282
12.3 ALS推荐算法的介绍   283
12.4 如何搜索数据      285
12.5 启动IPython Notebook        289
12.6 如何准备数据      290
12.7 如何训练模型      294
12.8 如何使用模型进行推荐      295
12.9 显示推荐的电影名称 297
12.10 创建Recommend项目      299
12.11 运行RecommendTrain.py 推荐程序代码        302
12.12 创建Recommend.py推荐程序代码         304
12.13 在eclipse运行Recommend.py         307
12.14 结论   310
第13章  Python Spark MLlib决策树二元分类   311
13.1 决策树介绍 312
13.2 “StumbleUpon Evergreen”大数据问题  313
13.2.1 Kaggle网站介绍       313
13.2.2 “StumbleUpon Evergreen”大数据问题场景分析        313
13.3 决策树二元分类机器学习 314
13.4 如何搜集数据      315
13.4.1 StumbleUpon数据内容    315
13.4.2 下载 StumbleUpon 数据         316
13.4.3 用LibreOffice Calc 电子表格查看train.tsv    319
13.4.4 复制到项目目录       322
13.5  使用IPython Notebook示范       323
13.6 如何进行数据准备      324
13.6.1 导入并转换数据       324
13.6.2 提取 feature 特征字段  327
13.6.3 提取分类特征字段  328
13.6.4 提取数值特征字段  331
13.6.5 返回特征字段  331
13.6.6 提取 label 标签字段       331
13.6.7 建立训练评估所需的数据       332
13.6.8 以随机方式将数据分为 3 部分并返回         333
13.6.9 编写 PrepareData(sc) 函数    333
13.7 如何训练模型      334
13.8 如何使用模型进行预测      335
13.9 如何评估模型的准确率      338
13.9.1 使用 AUC 评估二元分类模型        338
13.9.2 计算 AUC 339
13.10 模型的训练参数如何影响准确率   341
13.10.1 建立 trainEvaluateModel       341
13.10.2 评估impurity参数 343
13.10.3 训练评估的结果以图表显示         344
13.10.4 编写 evalParameter       347
13.10.5 使用 evalParameter 评估 maxDepth 参数        347
13.10.6 使用 evalParameter 评估 maxBins 参数  348
13.11 如何找出准确率最高的参数组合   349
13.12 如何确认是否过度训练   352
13.13 编写RunDecisionTreeBinary.py程序        352
13.14 开始输入RunDecisionTreeBinary.py程序        353
13.15 运行RunDecisionTreeBinary.py         355
13.15.1 执行参数评估         355
13.15.2 所有参数训练评估找出最好的参数组合    355
13.15.3 运行 RunDecisionTreeBinary.py 不要输入参数  357
13.16 查看DecisionTree的分类规则          358
13.17 结论   360
第14章  Python Spark MLlib 逻辑回归二元分类       361
14.1 逻辑回归分析介绍      362
14.2 RunLogisticRegression WithSGDBinary.py程序说明 363
14.3 运行RunLogisticRegression WithSGDBinary.py进行参数评估          367
14.4 找出最佳参数组合      370
14.5 修改程序使用参数进行预测      370
14.6 结论      372
第15章  Python Spark MLlib支持向量机SVM二元分类  373
15.1 支持向量机SVM算法的基本概念    374
15.2 运行SVMWithSGD.py进行参数评估          376
15.3 运行SVMWithSGD.py 训练评估参数并找出最佳参数组合    378
15.4 运行SVMWithSGD.py 使用最佳参数进行预测        379
15.5 结论      381
第16章  Python Spark MLlib朴素贝叶斯二元分类   382
16.1 朴素贝叶斯分析原理的介绍      383
16.2 RunNaiveBayesBinary.py程序说明     384
16.3 运行NaiveBayes.py进行参数评估    386
16.4 运行训练评估并找出最好的参数组合      387
16.5 修改RunNaiveBayesBinary.py 直接使用最佳参数进行预测  388
16.6 结论      390
第17章  Python Spark MLlib决策树多元分类   391
17.1 “森林覆盖植被”大数据问题分析场景 392
17.2 UCI Covertype数据集介绍 393
17.3 下载与查看数据 394
17.4 修改PrepareData() 数据准备   396
17.5 修改trainModel 训练模型程序         398
17.6 使用训练完成的模型预测数据 399
17.7 运行RunDecisionTreeMulti.py 进行参数评估  401
17.8 运行RunDecisionTreeMulti.py 训练评估参数并找出最好的参数组合  403
17.9 运行RunDecisionTreeMulti.py 不进行训练评估      404
17.10 结论   406
第18章  Python Spark MLlib决策树回归分析   407
18.1 Bike Sharing大数据问题分析     408
18.2 Bike Sharing数据集     409
18.3 下载与查看数据 409
18.4 修改 PrepareData() 数据准备  412
18.5 修改DecisionTree.trainRegressor训练模型      415
18.6 以 RMSE 评估模型准确率         416
18.7 训练评估找出最好的参数组合 417
18.8 使用训练完成的模型预测数据 417
18.9 运行RunDecisionTreeMulti.py进行参数评估   419
18.10 运行RunDecisionTreeMulti.py训练评估参数并找出最好的参数组合 421
18.11 运行RunDecisionTreeMulti.py 不进行训练评估    422
18.12 结论   424
第19章  Python Spark SQL、DataFrame、RDD数据统计与可视化         425
19.1 RDD、DataFrame、Spark SQL 比较  426
19.2 创建RDD、DataFrame与Spark SQL 427
19.2.1 在 local 模式运行 IPython Notebook    427
19.2.2 创建RDD  427
19.2.3 创建DataFrame        428
19.2.4 设置 IPython Notebook 字体 430
19.2.5 为DataFrame 创建别名 431
19.2.6 开始使用 Spark SQL         431
19.3 SELECT显示部分字段          434
19.3.1 使用 RDD 选取显示部分字段       434
19.3.2 使用 DataFrames 选取显示字段  434
19.3.3 使用 Spark SQL 选取显示字段       435
19.4 增加计算字段      436
19.4.1 使用 RDD 增加计算字段       436
19.4.2 使用 DataFrames 增加计算字段  436
19.4.3 使用 Spark SQL 增加计算字段       437
19.5 筛选数据      438
19.5.1 使用 RDD 筛选数据       438
19.5.2 使用 DataFrames 筛选数据  438
19.5.3 使用 Spark SQL 筛选数据       439
19.6 按单个字段给数据排序      439
19.6.1 RDD 按单个字段给数据排序          439
19.6.2 使用 Spark SQL排序        440
19.6.3 使用 DataFrames按升序给数据排序   441
19.6.4 使用 DataFrames按降序给数据排序   442
19.7 按多个字段给数据排序      442
19.7.1 RDD 按多个字段给数据排序          442
19.7.2 Spark SQL 按多个字段给数据排序         443
19.7.3 DataFrames 按多个字段给数据排序    443
19.8 显示不重复的数据      444
19.8.1 RDD 显示不重复的数据          444
19.8.2 Spark SQL 显示不重复的数据         445
19.8.3 Dataframes显示不重复的数据      445
19.9 分组统计数据      446
19.9.1 RDD 分组统计数据          446
19.9.2 Spark SQL分组统计数据 447
19.9.3 Dataframes分组统计数据      448
19.10 Join 联接数据   450
19.10.1 创建 ZipCode 450
19.10.2 创建 zipcode_tab  452
19.10.3 Spark SQL 联接 zipcode_table 数据表         454
19.10.4 DataFrame user_df 联接 zipcode_df   455
19.11 使用 Pandas DataFrames 绘图       457
19.11.1 按照不同的州统计并以直方图显示    457
19.11.2 按照不同的职业统计人数并以圆饼图显示         459
19.12 结论   461
第20章  Spark ML Pipeline 机器学习流程二元分类         462
20.1 数据准备      464
20.1.1 在 local 模式执行 IPython Notebook    464
20.1.2 编写 DataFrames UDF 用户自定义函数       466
20.1.3 将数据分成 train_df 与 test_df    468
20.2 机器学习pipeline流程的组件   468
20.2.1 StringIndexer     468
20.2.2 OneHotEncoder         470
20.2.3 VectorAssembler       472
20.2.4 使用 DecisionTreeClassi?er 二元分类  474
20.3 建立机器学习pipeline流程        475
20.4 使用pipeline进行数据处理与训练   476
20.5 使用pipelineModel 进行预测    477
20.6 评估模型的准确率      478
20.7 使用TrainValidation进行训练验证找出最佳模型    479
20.8 使用crossValidation交叉验证找出最佳模型   481
20.9 使用随机森林 RandomForestClassi?er分类器         483
20.10 结论   485
第21章  Spark ML Pipeline 机器学习流程多元分类         486
21.1 数据准备      487
21.1.1 读取文本文件  488
21.1.2  创建 DataFrame      489
21.1.3 转换为 double 490
21.2 建立机器学习pipeline流程        492
21.3 使用dt_pipeline进行数据处理与训练      493
21.4 使用pipelineModel 进行预测    493
21.5 评估模型的准确率      495
21.4 使用TrainValidation进行训练验证找出最佳模型    496
21.7 结论      498
第22章  Spark ML Pipeline 机器学习流程回归分析         499
22.1 数据准备      501
22.1.1 在local 模式执行 IPython Notebook     501
22.1.2 将数据分成 train_df 与 test_df    504
22.2 建立机器学习pipeline流程        504
22.3 使用dt_pipeline进行数据处理与训练      506
22.4 使用pipelineModel 进行预测    506
22.5 评估模型的准确率      507
22.6 使用TrainValidation进行训练验证找出最佳模型    508
22.7 使用crossValidation进行交叉验证找出最佳模型   510
22.8 使用GBT Regression   511
22.9 结论      513
附录A  本书范例程序下载与安装说明      514
A.1  下载范例程序        515
A.2  打开本书IPythonNotebook范例程序         516
A.3  打开 eclipsePythonProject 范例程序         518
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python+Spark 2.0+Hadoop机器学习与大数据实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础
译者序
前言
第1章　引言1
1.1　应用与问题1
1.2　定义与术语2
1.3　交叉验证4
1.4　学习情境5
1.5　本书概览6
第2章　PAC学习框架8
2.1　PAC学习模型8
2.2　对有限假设集的学习保证——一致的情况12
2.3　对有限假设集的学习保证——不一致的情况16
2.4　泛化性18
2.4.1　确定性与随机性情境18
2.4.2　贝叶斯误差与噪声19
2.4.3　估计误差与近似误差19
2.4.4　模型选择20
2.5　文献评注21
2.6　习题22
第3章　Rademacher复杂度和VC-维25
3.1　Rademacher复杂度25
3.2　生长函数29
3.3　VC-维31
3.4　下界36
3.5　文献评注41
3.6　习题42
第4章　支持向量机47
4.1　线性分类47
4.2　可分情况下的支持向量机48
4.2.1　原始优化问题48
4.2.2　支持向量49
4.2.3　对偶优化问题50
4.2.4　留一法51
4.3　不可分情况下的支持向量机52
4.3.1　原始优化问题53
4.3.2　支持向量54
4.3.3　对偶优化问题55
4.4　间隔理论56
4.5　文献评注62
4.6　习题62
第5章　核方法65
5.1　引言65
5.2　正定对称核67
5.2.1　定义67
5.2.2　再生核希尔伯特空间69
5.2.3　性质70
5.3　基于核的算法73
5.3.1　具有PDS核的SVM73
5.3.2　表示定理74
5.3.3　学习保证75
5.4　负定对称核76
5.5　序列核78
5.5.1　加权转换器79
5.5.2　有理核82
5.6　文献评注85
5.7　习题85
第6章　boosting89
6.1　引言89
6.2　AdaBoost算法90
6.2.1　经验误差的界92
6.2.2　与坐标下降的关系93
6.2.3　与逻辑回归的关系94
6.2.4　实践中的标准使用方式95
6.3　理论结果95
6.3.1　基于VC-维的分析96
6.3.2　基于间隔的分析96
6.3.3　间隔最大化100
6.3.4　博弈论解释101
6.4　讨论103
6.5　文献评注104
6.6　习题105
第7章　在线学习108
7.1　引言108
7.2　有专家建议的预测109
7.2.1　错误界和折半算法109
7.2.2　加权多数算法110
7.2.3　随机加权多数算法111
7.2.4　指数加权平均算法114
7.3　线性分类117
7.3.1　感知机算法117
7.3.2　Winnow算法122
7.4　在线到批处理的转换124
7.5　与博弈论的联系127
7.6　文献评注127
7.7　习题128
第8章　多分类133
8.1　多分类问题133
8.2　泛化界134
8.3　直接型多分类算法139
8.3.1　多分类SVM139
8.3.2　多分类boosting算法140
8.3.3　决策树141
8.4　类别分解型多分类算法144
8.4.1　一对多144
8.4.2　一对一145
8.4.3　纠错编码146
8.5　结构化预测算法148
8.6　文献评注149
8.7　习题150
第9章　排序152
9.1　排序问题152
9.2　泛化界153
9.3　使用SVM进行排序155
9.4　RankBoost156
9.4.1　经验误差界158
9.4.2　与坐标下降的关系159
9.4.3　排序问题集成算法的间隔界160
9.5　二部排序161
9.5.1　二部排序中的boosting算法162
9.5.2　ROC曲线下面积164
9.6　基于偏好的情境165
9.6.1　两阶段排序问题166
9.6.2　确定性算法167
9.6.3　随机性算法168
9.6.4　关于其他损失函数的扩展168
9.7　讨论169
9.8　文献评注170
9.9　习题171
第10章　回归172
10.1　回归问题172
10.2　泛化界173
10.2.1　有限假设集173
10.2.2　Rademacher复杂度界174
10.2.3　伪维度界175
10.3　回归算法177
10.3.1　线性回归178
10.3.2　核岭回归179
10.3.3　支持向量回归182
10.3.4　Lasso186
10.3.5　组范数回归算法188
10.3.6　在线回归算法189
10.4　文献评注190
10.5　习题190
第11章　算法稳定性193
11.1　定义193
11.2　基于稳定性的泛化保证194
11.3　基于核的正则化算法的稳定性196
11.3.1　应用于回归算法：SVR和KRR198
11.3.2　应用于分类算法：SVM200
11.3.3　讨论200
11.4　文献评述201
11.5　习题201
第12章　降维203
12.1　主成分分析204
12.2　核主成分分析205
12.3　KPCA和流形学习206
12.3.1　等距映射206
12.3.2　拉普拉斯特征映射207
12.3.3　局部线性嵌入207
12.4　Johnson-Lindenstrauss引理208
12.5　文献评注210
12.6　习题210
第13章　学习自动机和语言212
13.1　引言212
13.2　有限自动机213
13.3　高效精确学习214
13.3.1　被动学习214
13.3.2　通过查询学习215
13.3.3　通过查询学习自动机216
13.4　极限下的识别220
13.5　文献评注224
13.6　习题225
第14章　强化学习227
14.1　学习情境227
14.2　马尔可夫决策过程模型228
14.3　策略229
14.3.1　定义229
14.3.2　策略值229
14.3.3　策略评估230
14.3.4　最优策略230
14.4　规划算法231
14.4.1　值迭代231
14.4.2　策略迭代233
14.4.3　线性规划235
14.5　学习算法235
14.5.1　随机逼近236
14.5.2　TD（0）算法239
14.5.3　Q-学习算法240
14.5.4　SARSA242
14.5.5　TD（λ）算法242
14.5.6　大状态空间243
14.6　文献评注244
结束语245
附录A　线性代数回顾246
附录B　凸优化251
附录C　概率论回顾257
附录D　集中不等式264
附录E　符号273
索引274
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习基础
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言机器学习
译者序
前言
关于作者
关于审稿人
第1章　开始使用R语言和机器学习 1
1.1　探究R的基本内容 2
1.1.1　使用R作为科学计算器 2
1.1.2　向量运算 3
1.1.3　特殊值 5
1.2　R的数据结构 5
1.2.1　向量 6
1.2.2　数组和矩阵 8
1.2.3　列表 13
1.2.4　数据框 16
1.3　使用函数 20
1.3.1　内置函数 20
1.3.2　用户自定义函数 20
1.3.3　以参数形式传递函数 21
1.4　控制代码流 22
1.4.1　使用if、if-else和ifelse语句 22
1.4.2　使用switch语句 23
1.4.3　循环 23
1.5　高级结构 24
1.5.1　lapply和sapply函数 25
1.5.2　apply函数 26
1.5.3　tapply函数 27
1.5.4　mapply函数 28
1.6　进一步使用R 29
1.6.1　获得帮助 29
1.6.2　处理添加包 30
1.7　机器学习基础 30
1.7.1　机器学习——真正的含义是什么 30
1.7.2　机器学习——如何应用于现实世界 31
1.7.3　机器学习算法的类型 32
1.8　总结 33
第2章　让我们进行机器学习 34
2.1　理解机器学习 35
2.2　机器学习算法 35
2.3　算法家族 40
2.3.1　有监督学习算法 41
2.3.2　无监督学习算法 52
2.4　总结 57
第3章　应用市场购物篮分析预测顾客购买趋势 58
3.1　检测和预测趋势 59
3.2　市场购物篮分析 60
3.2.1　市场购物篮分析的真正含义 60
3.2.2　核心概念和定义 60
3.2.3　用于分析的技术 62
3.2.4　制定数据驱动的决策 63
3.3　评估产品列联矩阵 63
3.3.1　获取数据 64
3.3.2　分析和可视化数据 65
3.3.3　整体推荐 66
3.3.4　高级列联矩阵 67
3.4　频繁项集的生成 69
3.4.1　开始 69
3.4.2　数据检索和转换 69
3.4.3　建立项集关联矩阵 70
3.4.4　建立频繁项集生成工作流 72
3.4.5　检测购物趋势 74
3.5　关联规则挖掘 75
3.5.1　加载添加包和数据 76
3.5.2　探索性分析 76
3.5.3　检测和预测购物趋势 77
3.5.4　关联规则可视化 80
3.6　总结 80
第4章　建立产品推荐系统 82
4.1　理解推荐系统 83
4.2　推荐系统存在的问题 83
4.3　协同过滤器 84
4.3.1　核心概念和定义 84
4.3.2　协同过滤算法 85
4.4　建立推荐引擎 87
4.4.1　矩阵分解 88
4.4.2　算法实现 90
4.4.3　解释结果 94
4.5　产品推荐引擎实战 95
4.5.1　提取、转换并分析数据 96
4.5.2　模型准备和预测 99
4.5.3　模型评价 100
4.6　总结 102
第5章　信用风险检测和预测——描述分析 103
5.1　分析的类型 104
5.2　我们将要面临的挑战 104
5.3　什么是信用风险 105
5.4　获取数据 105
5.5　数据处理 107
5.5.1　处理缺失值 107
5.5.2　数据类型转换 108
5.6　数据分析和变换 109
5.6.1　建立分析实用函数 110
5.6.2　分析数据集 113
5.6.3　保存变换后的数据集 130
5.7　接下来的步骤 130
5.7.1　建立特征集 130
5.7.2　选择机器学习算法 131
5.8　总结 131
第6章　信用风险检测和预测——预测分析 133
6.1　预测分析 134
6.2　如何预测信用风险 135
6.3　预测模型中的重要概念 137
6.3.1　准备数据 137
6.3.2　建立预测模型 137
6.3.3　评估预测模型 138
6.4　获取数据 140
6.5　数据处理 141
6.6　特征选择 142
6.7　应用逻辑回归建立模型 144
6.8　应用支持向量机建立模型 148
6.9　应用决策树建立模型 156
6.10　应用随机森林建立模型 161
6.11　应用神经网络建立模型 165
6.12　模型比较和选择 169
6.13　总结 171
第7章　社交媒体分析：分析Twitter数据 172
7.1　社交网络（Twitter） 172
7.2　数据挖掘与社交网络 174
7.2.1　挖掘社交网络数据 175
7.2.2　数据和可视化 176
7.3　从Twitter API开始 179
7.3.1　概览 179
7.3.2　注册应用 180
7.3.3　链接/认证 181
7.3.4　提取推文示例 182
7.4　Twitter数据挖掘 183
7.4.1　常用词汇和关联 186
7.4.2　广泛使用的设备 191
7.4.3　层次聚类 192
7.4.4　主题建模 194
7.5　社交网络数据挖掘带来的挑战 197
7.6　参考文献 198
7.7　总结 198
第8章　Twitter数据的情感分析 200
8.1　理解情感分析 201
8.1.1　情感分析的关键概念 201
8.1.2　方法 204
8.1.3　应用 205
8.1.4　挑战 206
8.2　推文中的情感分析 206
8.2.1　极性分析 208
8.2.2　基于分类的算法 212
8.3　总结 223
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow机器学习实战指南
目　　录
译者序
作者简介
审校者简介
前言
第1章 TensorFlow基础 1
1.1 TensorFlow介绍 1
1.2 TensorFlow如何工作 1
1.3 声明张量 3
1.4 使用占位符和变量 6
1.5 操作（计算）矩阵 7
1.6 声明操作 10
1.7 实现激励函数 12
1.8 读取数据源 14
1.9 学习资料 19
第2章 TensorFlow进阶 20
2.1 本章概要 20
2.2 计算图中的操作 20
2.3 TensorFlow的嵌入Layer 21
2.4 TensorFlow的多层Layer 23
2.5 TensorFlow实现损失函数 26
2.6 TensorFlow实现反向传播 30
2.7 TensorFlow实现随机训练和批量训练 34
2.8 TensorFlow实现创建分类器 37
2.9 TensorFlow实现模型评估 40
第3章 基于TensorFlow的线性回归 45
3.1 线性回归介绍 45
3.2 用TensorFlow求逆矩阵 45
3.3 用TensorFlow实现矩阵分解 47
3.4 用TensorFlow实现线性回归算法 49
3.5 理解线性回归中的损失函数 52
3.6 用TensorFlow实现戴明回归算法 55
3.7 用TensorFlow实现lasso回归和岭回归算法 58
3.8 用TensorFlow实现弹性网络回归算法 60
3.9 用TensorFlow实现逻辑回归算法 62
第4章 基于TensorFlow的支持向量机 66
4.1 支持向量机简介 66
4.2 线性支持向量机的使用 67
4.3 弱化为线性回归 72
4.4 TensorFlow上核函数的使用 77
4.5 用TensorFlow实现非线性支持向量机 82
4.6 用TensorFlow实现多类支持向量机 85
第5章 最近邻域法 90
5.1 最近邻域法介绍 90
5.2 最近邻域法的使用 91
5.3 如何度量文本距离 95
5.4 用TensorFlow实现混合距离计算 98
5.5 用TensorFlow实现地址匹配 101
5.6 用TensorFlow实现图像识别 105
第6章 神经网络算法 109
6.1 神经网络算法基础 109
6.2 用TensorFlow实现门函数 110
6.3 使用门函数和激励函数 113
6.4 用TensorFlow实现单层神经网络 117
6.5 用TensorFlow实现神经网络常见层 120
6.6 用TensorFlow实现多层神经网络 126
6.7 线性预测模型的优化 131
6.8 用TensorFlow基于神经网络实现井字棋 136
第7章 自然语言处理 143
7.1 文本处理介绍 143
7.2 词袋的使用 144
7.3 用TensorFlow实现TF-IDF算法 149
7.4 用TensorFlow实现skip-gram模型 155
7.5 用TensorFlow实现CBOW词嵌入模型 162
7.6 使用TensorFlow的Word2Vec预测 167
7.7 用TensorFlow实现基于Doc2Vec的情感分析 172
第8章 卷积神经网络 181
8.1 卷积神经网络介绍 181
8.2 用TensorFlow实现简单的CNN 182
8.3 用TensorFlow实现进阶的CNN 188
8.4 再训练已有的CNN模型 196
8.5 用TensorFlow实现模仿大师绘画 199
8.6 用TensorFlow实现DeepDream 205
第9章 递归神经网络 211
9.1 递归神经网络介绍 211
9.2 用TensorFlow实现RNN模型进行垃圾短信预测 212
9.3 用TensorFlow实现LSTM模型 218
9.4 Stacking多个LSTM Layer 226
9.5 用TensorFlow实现Seq2Seq翻译模型 229
9.6 TensorFlow实现孪生RNN预测相似度 235
第10章 TensorFlow产品化 243
10.1 简介 243
10.2 TensorFlow的单元测试 243
10.3 TensorFlow的并发执行 247
10.4 分布式TensorFlow实践 250
10.5 TensorFlow产品化开发提示 252
10.6 TensorFlow产品化的实例 254
第11章 TensorFlow的进阶应用 257
11.1 简介 257
11.2 TensorFlow可视化：Tensorboard 257
11.3 Tensorboard的进阶 260
11.4 用TensorFlow实现遗传算法 262
11.5 TensorFlow实现k-means算法 266
11.6 用TensorFlow求解常微分方程问题 270
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow机器学习实战指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践指南
* 1章 简明学习问题… ……………………………………………………1
1.1 归纳推理和演绎推理的基础……………………………………………………2
1.2 你曾遇到这些事情吗？…………………………………………………………3
1.3 释放归纳的力量…………………………………………………………………3
1.4 推断的阴阳之道…………………………………………………………………4
1.5 学习问题的三大要素……………………………………………………………4
1.6 从数据中学习的目标……………………………………………………………6
1.7 阐明选择标准……………………………………………………………………7
1.8 学习任务的选择…………………………………………………………………8
附注………………………………………………………………………………………9
* 2章 监督学习………………………………………………………13
2.1 有效分类的基本要素……………………………………………………………13
2.2 如何确定假设类别的答案………………………………………………………15
2.3 监督学习的两个核心方法………………………………………………………16
2.3.1 生成算法的关键…………………………………………………………16
2.3.2 理解判别算法……………………………………………………………17
2.4 什么是贝叶斯分类器……………………………………………………………17
误差下界…………………………………………………………………………19
2.5 评估贝叶斯误差的两种简单技巧………………………………………………19
2.5.1 Mahalanobis技巧……………………………………………………19
2.5.2 Bhattacharyya技巧…………………………………………………20
2.6 如何释放朴素贝叶斯分类器的力量……………………………………………21
一个建立直觉的例子……………………………………………………………22
2.7 朴素贝叶斯分类器的R极简建立方法…………………………………………24
2.7.1 一个模拟的例子… …………………………………………………………24
2.7.2 甲状腺数据的分析………………………………………………………28
2.8 如何利用k-近邻算法的价值…………………………………………………33
2.8.1 深化理解的例子…………………………………………………………34
2.8.2 k近邻的R直接方法……………………………………………………37
2.8.3 如何决定k的* 优值……………………………………………………42
2.9 线性判别分析的关键……………………………………………………………42
2.9.1 求解广义特征值问题…………………………………………………44
2.9.2 R判别分析的基本要素…………………………………………………45
2.9.3 检查你想要的模型类型………………………………………………49
2.9.4 不要止步于线性判别分析………………………………………………50
2.10 逻辑回归分类的秘密……………………………………………………………51
建立R逻辑回归分类器的简便方法……………………………………………53
2.11 激励创意和激情的超级好主意…………………………………………………57
附注………………………………………………………………………………………59
第3章 无监督学习……………………………………………………68
3.1 无监督学习简介…………………………………………………………………68
3.2 两种核心方法及其工作原理……………………………………………………69
3.3 无监督学习的应用技术及R实现………………………………………………70
3.4 无监督学习的典型例子，你可以模仿学习……………………………………85
3.4.1 数据（图像）预处理……………………………………………………86
3.4.2 处理图像中的噪声………………………………………………………86
3.4.3 颅骨“剥离”……………………………………………………………87
3.4.4 完 美组合…………………………………………………………………87
附注……………………………………………………………………………………89
第4章 半监督学习……………………………………………………91
4.1 未标记数据的作用………………………………………………………………92
4.2 一致性假设……………………………………………………………………94
4.3 尝试半监督学习的极简方法…………………………………………………94
4.4 自学习算法………………………………………………………………………95
4.5 基于半监督模型的R学习……………………………………………………98
4.6 使用土地分类掌握这种实践说明… ……………………………………………102
附注……………………………………………………………………………………105
第5章 统计学习理论…………………………………………………108
5.1 Vapnik-Chervonenkis泛化界……………………………………………109
5.2 什么是Vapnik-Chervonenkis维…………………………………………110
5.3 结构风险* 小化的关键………………………………………………………113
5.4 实践中使用统计学习理论的* 佳建议………………………………………114
5.5 如何精通支持向量机…………………………………………………………115
5.6 支持向量机的本质……………………………………………………………116
松弛的处理……………………………………………………………………117
5.7 如何建立R支持向量机………………………………………………………118
附注……………………………………………………………………………………120
第6章 模型选择………………………………………………………122
6.1 模型的快速改进………………………………………………………………122
6.2 一个价值500万美元的小错误………………………………………………124
6.3 “天下没有免费午餐”定理之三大关键教训…………………………………125
6.4 什么是偏差和方差权衡………………………………………………………127
6.4.1 可约误差………………………………………………………………128
6.4.2 偏差……………………………………………………………………129
6.4.3 方差……………………………………………………………………130
6.5 你的模型犯过这种错吗？……………………………………………………131
6.6 留出技术的秘密………………………………………………………………132
6.7 有效交叉验证的艺术…………………………………………………………134
6.7.1 k-折交叉验证………………………………………………………134
6.7.2 一个R案例……………………………………………………………135
6.7.3 留一验证………………………………………………………………138
附注……………………………………………………………………………………140
恭喜你！……………………………………………………………………142
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习实践指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Scala机器学习
译者序
前言
第1章探索数据分析1
1.1Scala入门2
1.2去除分类字段的重复值2
1.3数值字段概述4
1.4基本抽样、分层抽样和一致抽样5
1.5使用Scala和Spark的Note—book工作8
1.6相关性的基础12
1.7总结14
第2章数据管道和建模15
2.1影响图16
2.2序贯试验和风险处理17
2.3探索与利用问题21
2.4不知之不知23
2.5数据驱动系统的基本组件23
2.5.1数据收集24
2.5.2数据转换层25
2.5.3数据分析与机器学习26
2.5.4UI组件26
2.5.5动作引擎28
2.5.6关联引擎28
2.5.7监控28
2.6优化和交互28
2.7总结29
第3章使用Spark和MLlib30
3.1安装Spark31
3.2理解Spark的架构32
3.2.1任务调度32
3.2.2Spark的组件35
3.2.3MQTT、ZeroMQ、Flume和Kafka36
3.2.4HDFS、Cassandra、S3和Tachyon37
3.2.5Mesos、YARN和Standa—lone38
3.3应用38
3.3.1单词计数38
3.3.2基于流的单词计数41
3.3.3SparkSQL和数据框45
3.4机器学习库46
3.4.1SparkR47
3.4.2图算法：Graphx和Graph—Frames48
3.5Spark的性能调整48
3.6运行Hadoop的HDFS49
3.7总结54
第4章监督学习和无监督学习55
4.1记录和监督学习55
4.1.1Iirs数据集56
4.1.2类标签点57
4.1.3SVMWithSGD58
4.1.4logistic回归60
4.1.5决策树62
4.1.6bagging和boosting：集成学习方法66
4.2无监督学习66
4.3数据维度71
4.4总结73
第5章回归和分类74
5.1回归是什么74
5.2连续空间和度量75
5.3线性回归77
5.4logistic回归81
5.5正则化83
5.6多元回归84
5.7异方差84
5.8回归树85
5.9分类的度量87
5.10多分类问题87
5.11感知机87
5.12泛化误差和过拟合90
5.13总结90
第6章使用非结构化数据91
6.1嵌套数据92
6.2其他序列化格式100
6.3Hive和Impala102
6.4会话化104
6.5使用特质109
6.6使用模式匹配110
6.7非结构化数据的其他用途113
6.8概率结构113
6.9投影113
6.10总结113
第7章使用图算法115
7.1图简介115
7.2SBT116
7.3Scala的图项目119
7.3.1增加节点和边121
7.3.2图约束123
7.3.3JSON124
7.4GraphX126
7.4.1谁收到电子邮件130
7.4.2连通分量131
7.4.3三角形计数132
7.4.4强连通分量132
7.4.5PageRank133
7.4.6SVD++134
7.5总结138
第8章Scala与R和Python的集成139
8.1R的集成140
8.1.1R和SparkR的相关配置140
8.1.2数据框144
8.1.3线性模型150
8.1.4广义线性模型152
8.1.5在SparkR中读取JSON文件156
8.1.6在SparkR中写入Parquet文件157
8.1.7从R调用Scala158
8.2Python的集成161
8.2.1安装Python161
8.2.2PySpark162
8.2.3从Java／Scala调用Python163
8.3总结167
第9章Scala中的NLP169
9.1文本分析流程170
9.2Spark的MLlib库177
9.2.1TF—IDF177
9.2.2LDA178
9.3分词、标注和分块185
9.4POS标记186
9.5使用word2vec寻找词关系189
9.6总结192
第10章高级模型监控193
10.1系统监控194
10.2进程监控195
10.3模型监控201
10.3.1随时间变化的性能202
10.3.2模型停用标准202
10.3.3A／B测试202
10.4总结202
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Scala机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PYTHON3:数据分析与机器学习实战
第0章  本书的技术体系
0.1  Python的发展趋势
0.2  人工智能时代学习python的重要性
0.3  本书的技术体系
0.4  学习本书需要注意的事项
第1章  Python基础知识
1.1  Python简介
1.1.1  了解Python的起源与发展历史
1.1.2  Python的特色
1.1.3  学习Python的原因
1.2  Python的当前版本
1.3  Python的优缺点
1.4  Python与其他语言的区别
1.5  Python的应用领域
第2章  Python的安装、配置与卸载
2.1  Python的安装
2.1.1  Python的下载
2.1.2  Python的安装
2.2  Python的配置
2.2.1  Python环境变量的设置
2.2.2  Python的启动
2.3  Python的卸载
第3章  Python 3 基础语法
3.1  第一个Python程序
3.2  Python的输入和输出
3.2.1  Python的输出语句
3.2.2  Python的输入语句
3.3  Python的基本数据类型
3.3.1  数字
3.3.2  字符串
3.3.3  列表
3.3.4  元组
3.3.5  集合
3.3.6  字典
3.4  Python库的导入
3.5  Python的集成开发环境
3.6  自测练习
第4章  Python 3的编程
4.1  条件语句
4.2  循环语句
4.2.1  while循环
4.2.2  for循环
4.3  函数
4.4  模块
4.5  自测练习
第5章  机器学习基础
5.1  机器学习概述
5.2  监督学习简介
5.3  非监督学习简介
5.4  增强学习简介
5.5  深度学习简介
5.6  机器学习常用术语
第6章  Python 机器学习及分析工具
6.1  矩阵操作函数库（Numpy）
6.1.1  Numpy的安装
6.1.2  Numpy的基本使用
6.2  科学计算的核心包（Scipy）
6.2.1  科学计算的核心包的安装
6.2.2  科学计算的核心包的基本使用
6.3  Python的绘图库（Matplotlib）
6.3.1  Matplotlib简介及安装
6.3.2  Matplotlib的基本使用
6.4  数据分析包（Pandas）
6.4.1  Pandas简介和安装
6.4.2  Pandas的基本使用方法
6.5  机器学习函数库（scikit-learn）
6.6  统计建模工具包（StatsModels）
6.7  深度学习框架（TensorFlow）
第7章  数据预处理
7.1  数据预处理概述
7.2  数据清理
7.2.1  异常数据处理
7.2.2  缺失值处理
7.2.3  噪声数据处理
7.3  数据集成
7.4  数据变换
7.5  数据归约
7.6  Python的主要数据预处理函数
7.6.1  Python的数据结构
7.6.2  数据缺失处理函数
第8章  分类问题
8.1  分类概述
8.2  常用方法
8.2.1  k-近邻算法
8.2.2  朴素贝叶斯
8.2.3  支持向量机
8.2.4  AdaBoost算法
8.2.5  决策树
8.2.6  Multi-layer Perceptron 多层感知机
8.3  项目实战
8.3.1  实例1：使用k-近邻算法实现约会网站的配对效果
8.3.2  实例2：使用朴素贝叶斯过滤垃圾邮件
8.3.3  实例3：SVM实现手写识别系统
8.3.4  实例4：基于单层决策树构建分类算法
8.3.5  实例5：使用决策树对iris数据集分类
8.3.6  实例6：使用决策树对身高体重数据进行分类
8.3.7  实例7：使用k-近邻算法对鸢尾花数据进行交叉验证
8.3.8  使用多层感知器分析，根据葡萄酒的各项化学特征来
判断葡萄酒的优劣
8.4  自测练习
第9章  预测分析
9.1  预测概述
9.2  常用方法
9.2.1  时间序列分析预测法
9.2.2  BP神经网络模型
9.3  项目实战
9.3.1  实例1：根据一年的历史数据预测后十年的数据趋势
9.3.2  实例2：使用神经网络预测公路运量
9.4  自测练习
第10章  关联分析
10.1  关联分析概述
10.2  基本方法
10.2.1  Apriori算法
10.2.2  FP-growth算法
10.3  项目实战（解决目前流行的实际问题）
10.3.1  用Apriori进行关联分析的实例
10.3.2  使用FP-growth算法提取频繁项集
10.4  自测练习
第11章  网络爬虫
11.1  网络爬虫概述
11.1.1  网络爬虫原理
11.1.2  爬虫分类
11.2  网页抓取策略和方法
11.2.1  网页抓取策略
11.2.2  网页抓取的方法
11.3  项目实战
11.3.1  用python抓取指定的网页
11.3.2  用python抓取包含关键词的网页
11.3.3  下载贴吧中的图片
11.3.4  股票数据抓取
11.4  自测练习
第12章  集成学习
12.1  集成学习概述
12.2  常用方法
12.2.1  Bagging和随机森林
12.2.2  boosting和AdaBoost
12.3  项目实战
12.3.1  使用随机森林方法预测乘员的存活概率
12.3.2  使用Adaboost方法进行二元分类
12.4  自测练习
第13章  深度学习
13.1  深度学习概述
13.2  常用方法
13.2.1  监督学习的深度学习网络结构
13.2.2  非监督学习的深度学习网络结构
13.3  项目实战
13.3.1  使用TensorFlow框架进行MNIST数据集生成
13.3.2  使用Theano框架进行MNIST数字识别
13.4  自测练习
第14章  数据降维及压缩
14.1  数据降维及压缩概述
14.1.1  数据降维
14.1.2  图像压缩
14.2  基本方法
14.2.1  主成分分析
14.2.2  奇异值分解
14.3  项目实战
14.3.1  主成分分析PCA实例
14.3.2  使用奇异值分解进行图像压缩
14.4  自测练习
第15章  聚类分析
15.1  聚类分析概述
15.2  K-means算法
15.2.1  K-means算法与步骤
15.2.2  K-means算法涉及的问题
15.2.3  实际聚类问题的处理流程
15.3  项目实战
15.3.1  K-means算法实现二维数据聚类
15.3.2  使用scikit-learn中的方法进行聚类分析
15.4  自测练习
第16章  回归分析问题
16.1  回归分析概述
16.2  基本方法
16.2.1  一元回归分析
16.2.2  多元线性回归
16.2.3  回归的计算方法
16.2.4  逻辑回归分析
16.3  项目实战
16.3.1  身高与体重的回归分析
16.3.2  房价预测
16.3.3  产品销量与广告的多元回归分析
16.3.4  鸢尾花数据的逻辑回归分析
16.4  自测练习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PYTHON3:数据分析与机器学习实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于机器学习的行为识别技术研究
第１章 绪论
１.１ 研究背景与意义
１.２ 国内外研究现状
１.３ 研究内容与论文组织
第２章 人体关键点跟踪及轨迹恢复
２.１ 引言
２.２ 人体结构模型
２.３ 基于马尔科夫链蒙特卡罗原理的改进粒子滤波算法
２.４ 实验与结果
２.５ 本章小结
第３章 基于词包的人体行为特征表示
３.１ 引言
３.２ 时空兴趣点特征
３.３ 人体轨迹相空间重建及特征
３.４ 基于视觉词的人体行为特征表示
３.５ 实验与结果
３.６ 本章小结
第４章 基于改进ＰＬＳＡ和案例推理算法的简单歧义行为识别
４.１ 引言
４.２ ＰＬＳＡ模型的基本原理
４.３ 案例推理
４.４ 改进ＰＬＳＡ＋ＣＢＲ歧义行为识别算法
４.５ 实验与结果
４.６ 本章小结
第５章 基于马尔科夫逻辑网络的复杂行为识别
５.１ 引言
５.２ 马尔科夫逻辑网简介
５.３ 基于马尔科夫逻辑网的复杂行为识别
５.４ 实验与结果
５.５ 本章小结
第６章 结束语
６.１ 本文工作总结
６.２ 进一步研究工作
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于机器学习的行为识别技术研究
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习经典算法剖析
第 1章　正态贝叶斯分类器 1
1.1　原理分析 1
1.2　源码解析 8
1.3　应用实例 13
第 2章　K近邻算法 15
2.1　原理分析 15
2.2　源码解析 16
2.3　应用实例 22
第3章　支持向量机 25
3.1　原理分析 25
3.2　源码解析 50
3.3　应用实例 71
第4章　决策树 73
4.1　原理分析 73
4.2　源码解析 81
4.3　应用实例 117
第5章　AdaBoost 120
5.1　原理分析 120
5.2　源码解析 123
5.3　应用实例 140
第6章　梯度提升树 142
6.1　原理分析 142
6.2　源码解析 147
6.3　应用实例 158
第7章　随机森林 161
7.1　原理分析 161
7.2　源码解析 163
7.3　应用实例 171
第8章　极端随机树 173
8.1　原理分析 173
8.2　源码解析 173
8.3　应用实例 187
第9章　期望极大值 189
9.1　原理分析 189
9.2　源码解析 202
9.3　应用实例 212
第 10章　神经网络 214
10.1　原理分析 214
10.2　源码解析 220
10.3　应用实例 241
附录A　Win7系统下OpenCV 2.4.9与
Visual Studio 2012
编译环境的配置 244
附录B　Win7系统下QT 5.3.1与
OpenCV 2.4.9 编译环境的
配置 248
附录C　级联分类器 252
参考文献 287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习经典算法剖析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Microsoft Azure机器学习和预测分析
第1部分数据科学和Microsoft Azure Machine Learning导论
第1章数据科学导论3
1.1数据科学是什么3
1.2分析频谱4
1.2.1描述性分析4
1.2.2诊断性分析5
1.2.3预测性分析5
1.2.4规定性分析5
1.3为何重要，为何现在6
1.3.1把数据看作竞争资产6
1.3.2客户需求的增长6
1.3.3对数据挖掘技术认识的提高7
1.3.4访问更多数据7
1.3.5更快、更廉价的处理能力7
1.3.6数据科学流程8
1.4常见数据科学技术10
1.4.1分类算法10
1.4.2聚类算法11
1.4.3回归算法12
1.4.4模拟12
1.4.5内容分析12
1.4.6推荐引擎13
1.5数据科学的前沿13
1.6小结14
第2章Microsoft Azure Machine Learning导论15
2.1你好，Machine Learning Studio15
2.2实验的组件16
2.3Gallery简介17
2.4创建训练实验的5个简单步骤18
2.4.1第1步：获取数据19
2.4.2第2步：预处理数据20
2.4.3第3步：定义特征22
2.4.4第4步：选择和应用学习算法23
2.4.5第5步：在新数据之上做预测24
2.5在生产环境里部署你的模型26
2.5.1创建预测实验26
2.5.2把你的实验发布成Web服务28
2.5.3访问Azure Machine Learning的Web服务28
2.6小结30
第3章数据准备31
3.1数据清理和处理31
3.1.1了解你的数据32
3.1.2缺失值和空值37
3.1.3处理重复记录38
3.1.4识别并移除离群值39
3.1.5特征归一化40
3.1.6处理类别不均41
3.2特征选择43
3.3特征工程46
3.3.1分装数据48
3.3.2维度灾难50
3.4小结53
第4章整合R54
4.1R概览54
4.2构建和部署你的首个R脚本56
4.3使用R进行数据预处理59
4.4使用脚本包（ZIP）61
4.5使用R构建和部署决策树64
4.6小结68
第5章整合Python69
5.1概览69
5.2Python快速上手70
5.3在AzureML实验里使用Python71
5.4使用Python进行数据预处理76
5.4.1使用Python合并数据76
5.4.2使用Python处理缺失值79
5.4.3使用Python进行特征选择80
5.4.4在AzureML实验里运行Python代码82
5.5小结86
第2部分统计学和机器学习算法
第6章统计学和机器学习算法概览89
6.1回归算法89
6.1.1线性回归89
6.1.2神经网络90
6.1.3决策树92
6.1.4提升决策树93
6.2分类算法94
6.2.1支持向量机95
6.2.2贝叶斯点机96
6.3聚类算法97
6.4小结99
第3部分实用应用程序
第7章构建客户倾向模型103
7.1业务问题103
7.2数据获取和准备104
7.3训练模型109
7.4模型测试和验证111
7.5模型的性能112
7.6确定评估指标的优先级115
7.7小结116
第8章使用PowerBI可视化你的模型117
8.1概览117
8.2PowerBI简介117
8.3使用PowerBI可视化的三种方案119
8.4在Azure Machine Learning里给你的数据评分，并在Excel里可视化120
8.5在Excel里评分并可视化你的数据123
8.6在Azure Machine Learning里给你的数据评分，并在powerbi.com里可视化124
8.6.1加载数据125
8.6.2构建你的仪表板125
8.7小结127
第9章构建流失模型128
9.1流失模型概览128
9.2构建和部署客户流失模型129
9.2.1准备和了解数据129
9.2.2数据预处理和特征选择132
9.2.3用于预测流失的分类模型135
9.2.4评估客户流失模型的性能137
9.3小结138
第10章客户细分模型139
10.1客户细分模型概览139
10.2构建和部署你的第一个K均值聚类模型140
10.2.1特征散列142
10.2.2找出合适的特征142
10.2.3K均值聚类算法的属性144
10.3批发客户的客户细分145
10.3.1从UCI机器学习库加载数据145
10.3.2使用K均值聚类算法进行批发客户细分146
10.3.3新数据的聚类分配147
10.4小结148
第11章构建预见性维护模型149
11.1概览149
11.2预见性维护场景150
11.3业务问题150
11.4数据获取和准备151
11.4.1数据集151
11.4.2数据加载151
11.4.3数据分析151
11.5训练模型154
11.6模型测试和验证155
11.7模型性能156
11.8改善模型的技术158
11.9模型部署161
11.9.1创建预测实验161
11.9.2把你的实验部署成Web服务162
11.10小结163
第12章推荐系统164
12.1概览164
12.2推荐系统的方案和场景164
12.3业务问题165
12.4数据获取和准备166
12.5训练模型170
12.6模型测试和验证171
12.7小结175
第13章使用和发布Azure Marketplace上的模型176
13.1什么是机器学习API176
13.2如何使用Azure Marketplace的API178
13.3在Azure Marketplace里发布你自己的模型182
13.4为你的机器学习模型创建和发布Web服务182
13.4.1创建评分实验183
13.4.2把你的实验发布成Web服务183
13.5获取API密钥和OData端点信息184
13.6把你的模型发布为Azure Marketplace里的API184
13.7小结186
第14章Cortana分析187
14.1Cortana分析套件是什么187
14.2Cortana分析套件的功能187
14.3示例场景189
14.4小结190
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Microsoft Azure机器学习和预测分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习视角的结构健康监测
第1章绪论
1.1工程师与科学家如何研究损伤
1.2发展SHM技术的原因
1.3损伤定义
1.4SHM统计模式识别范例
1.4.1运营评估
1.4.2数据采集
1.4.3数据归一化
1.4.4数据净化
1.4.5数据压缩
1.4.6数据融合
1.4.7特征提取
1.4.8特征判别的统计建模
1.5局部与整体损伤诊断
1.6结构健康监测的基本公理
1.7本书采用的方法
参考文献
第2章研究历史回顾
2.1旋转机械应用
2.1.1旋转机械的运营评估
2.1.2旋转机械的数据采集
2.1.3旋转机械特征值的提取
2.1.4旋转机械损伤诊断的统计建模
2.1.5旋转机械状态监测的结论意见
2.2海洋石油平台
2.2.1海洋平台运营评估
2.2.2海洋平台数据采集
2.2.3海洋平台特征值提取
2.2.4海洋平台统计学建模
2.2.5海洋石油平台结构健康监测研究的经验教训
2.3航空航天结构
2.3.1航空航天结构的运营评估
2.3.2航空航天结构的数据采集
2.3.3航空航天结构的特征提取和统计建模
2.3.4用于航空航天SHM应用的统计模型
2.3.5关于航空航天SHM应用的结论性意见
2.4土木工程基础设施
2.4.1桥梁结构的运营评价
2.4.2桥梁结构的数据采集
2.4.3以模态属性为基础的特征
2.4.4土木工程基础设施的特征统计分类
2.4.5桥梁结构应用
2.5小结
参考文献
第3章运营评估
3.1结构健康监测的经济和寿命安全理由
3.2定义待检测的损伤
3.3运营和环境条件
3.4数据采集限制
3.5运营评估实例：桥梁监测
3.6运营评估实例：风力发电机
3.7运营评估总结
参考文献
第4章传感与数据采集
4.1简介
4.2SHM的传感与数据采集系统策略
4.2.1策略Ⅰ
4.2.2策略Ⅱ
4.3传感和数据采集的概念挑战
4.4应采集什么类型的数据？
4.4.1动态输入和响应量
4.4.2其他损伤敏感物理量
4.4.3环境量
4.4.4运营量
4.5目前的SHM传感系统
4.5.1有线系统
4.5.2无线系统
4.6传感器网络范例
4.6.1直接连接到中央处理设备的传感器阵列
4.6.2跳频连接的分布式处理
4.6.3混合连接的分布式处理
4.7未来的传感网络范例
4.8定义传感器系统特性
4.8.1所需灵敏度及量程
4.8.2所需带宽及频率分辨率
4.8.3传感器数量和位置
4.8.4传感器标定、稳定性和可靠性
4.9定义数据采样参数
4.10定义数据采集系统
4.11主动与被动传感
4.12多尺度传感
4.13传感器系统的供电
4.14信号调理
4.15传感器和作动器优化
4.16传感器融合
4.17结构健康监测传感和数据采集问题的总结
参考文献
第5章案例研究
5.1Ⅰ—40桥
5.1.1初步测试和数据采集
5.1.2完好状态环境振动测试
5.1.3强迫振动测试
5.2混凝土柱
5.2.1拟静力加载
5.2.2动态激励
5.2.3数据采集
5.3自由度系统
5.3.1物理参数
5.3.2数据采集
5.4模拟房屋结构
5.4.1试验过程与数据采集
5.4.2测试数据
5.5Alamosa峡谷大桥
5.5.1试验过程和数据采集
5.5.2环境测量
5.5.3研究模态特性变异所进行的振动试验
5.6Gnat飞机
5.6.1用改造的检查面板模拟损伤
5.6.2用拆除检测板模拟损伤
参考文献
第6章概率统计导论
6.1简介
6.2概率：基本定义
6.3随机变量及其分布
6.4期望值
6.5高斯分布（及其他分布）
6.6多元统计
6.7多元高斯分布
6.8条件概率和贝叶斯定理
6.9置信限与累积分布函数
6.10孤立点分析
6.10.1单变量数据中的异常值
6.10.2多元数据中的异常值
6.10.3不一致性临界值或阈值计算
6.11密度估计
6.12极值统计
6.12.1极值统计简介
6.12.2基本理论
6.12.3极限分布的确定
6.13降维——主成分分析
6.13.1简单投影
6.13.2主成分分析
6.14结论
参考文献
……
第7章损伤敏感特征
第8章基于线性响应偏差的特征
第9章机器学习与统计模式识别
第10章无监督学习——异常诊断
第11章监督学习——分类与回归
第12章数据归一化
第13章结构健康监测的基本公理
第14章损伤预后
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习视角的结构健康监测
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>终身机器学习
译者序
前 言
致 谢
第1章 引言1
1.1 传统机器学习范式1
1.2 案例3
1.3 终身学习简史7
1.4 终身学习的定义9
1.5 知识类型和关键挑战14
1.6 评估方法和大数据的角色17
1.7 本书大纲18
第2章 相关学习范式20
2.1 迁移学习20
2.1.1 结构对应学习21
2.1.2 朴素贝叶斯迁移分类器22
2.1.3 迁移学习中的深度学习23
2.1.4 迁移学习与终身学习的区别24
2.2 多任务学习25
2.2.1 多任务学习中的任务相关性25
2.2.2 GO-MTL：使用潜在基础任务的多任务学习26
2.2.3 多任务学习中的深度学习28
2.2.4 多任务学习与终身学习的区别30
2.3 在线学习30
2.4 强化学习31
2.5 元学习32
2.6 小结34
第3章 终身监督学习35
3.1 定义和概述36
3.2 基于记忆的终身学习37
3.2.1 两个基于记忆的学习方法37
3.2.2 终身学习的新表达37
3.3 终身神经网络39
3.3.1 MTL网络39
3.3.2 终身EBNN40
3.4 ELLA：高效终身学习算法41
3.4.1 问题设定41
3.4.2 目标函数42
3.4.3 解决一个低效问题43
3.4.4 解决第二个低效问题45
3.4.5 主动的任务选择46
3.5 终身朴素贝叶斯分类47
3.5.1 朴素贝叶斯文本分类47
3.5.2 LSC的基本思想49
3.5.3 LSC技术50
3.5.4 讨论52
3.6 基于元学习的领域词嵌入52
3.7 小结和评估数据集54
第4章 持续学习与灾难性遗忘56
4.1 灾难性遗忘56
4.2 神经网络中的持续学习58
4.3 无遗忘学习61
4.4 渐进式神经网络62
4.5 弹性权重合并63
4.6 iCaRL：增量分类器与表示学习65
4.6.1 增量训练66
4.6.2 更新特征表示67
4.6.3 为新类构建范例集68
4.6.4 在iCaRL中完成分类68
4.7 专家网关69
4.7.1 自动编码网关69
4.7.2 测量训练的任务相关性70
4.7.3 为测试选择相关的专家71
4.7.4 基于编码器的终身学习71
4.8 生成式重放的持续学习72
4.8.1 生成式对抗网络72
4.8.2 生成式重放73
评估灾难性遗忘74
4.10 小结和评估数据集75
第5章 开放式学习79
5.1 问题定义和应用80
5.2 基于中心的相似空间学习81
5.2.1 逐步更新CBS学习模型82
5.2.2 测试CBS学习模型84
5.2.3 用于未知类检测的CBS学习84
5.3 DOC：深度开放式分类87
5.3.1 前馈层和一对其余层87
5.3.2 降低开放空间89
5.3.3 DOC用于图像分类90
5.3.4 发现未知类90
5.4 小结和评估数据集91
第6章 终身主题建模93
6.1 终身主题建模的主要思想93
6.2 LTM：终身主题模型97
6.2.1 LTM模型97
6.2.2 主题知识挖掘99
6.2.3 融合过去的知识100
6.2.4 Gibbs采样器的条件分布102
6.3 AMC：少量数据的终身主题模型102
6.3.1 AMC整体算法103
6.3.2 挖掘must-link知识104
6.3.3 挖掘cannot-link知识107
6.3.4 扩展的Pólya瓮模型108
6.3.5 Gibbs采样器的采样分布110
6.4 小结和评估数据集112
第7章 终身信息提取114
7.1 NELL：停止语言学习器114
7.1.1 NELL结构117
7.1.2 NELL中的提取器与学习118
7.1.3 NELL中的耦合约束120
7.2 终身评价目标提取121
7.2.1 基于的终身学习122
7.2.2 AER算法123
7.2.3 知识学习124
7.2.4 使用过去知识125
7.3 在工作中学习126
7.3.1 条件随机场127
7.3.2 一般依赖特征128
7.3.3 L-CRF算法130
7.4 Lifelong-RL：终身松弛标记法131
7.4.1 松弛标记法132
7.4.2 终身松弛标记法133
7.5 小结和评估数据集133
第8章 聊天机器人的持续知识学习135
8.1 LiLi：终身交互学习与推理136
8.2 LiLi的基本思想139
8.3 LiLi的组件141
8.4 运行示例142
8.5 小结和评估数据集142
第9章 终身强化学习144
9.1 基于多环境的终身强化学习146
9.2 层次贝叶斯终身强化学习147
9.2.1 动机147
9.2.2 层次贝叶斯方法148
9.2.3 MTRL算法149
9.2.4 更新层次模型参数150
9.2.5 对MDP进行采样151
9.3 PG-ELLA：终身策略梯度强化学习152
9.3.1 策略梯度强化学习152
9.3.2 策略梯度终身学习设置154
9.3.3 目标函数和优化154
9.3.4 终身学习的安全策略搜索156
9.3.5 跨领域终身强化学习156
9.4 小结和评估数据集157
第10章 结论及未来方向159
参考文献164
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>终身机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习算法实践
第一篇基 础 理 论
第1章理论入门
1．1引言
1．2推荐系统的形式化定义
1．3基于近邻的协同过滤推荐算法
1．3．1余弦相似度
1．3．2修正余弦相似度
1．3．3Pearson相似度
1．3．4Jaccard相似度
1．4基于用户兴趣的推荐算法
1．5基于模型的协同过滤推荐算法
1．5．1矩阵分解模型
1．5．2交替最小二乘
1．5．3概率矩阵分解
1．5．4非负矩阵分解
1．6基于信任的协同过滤推荐算法
1．7推荐系统现存问题
1．7．1冷启动
1．7．2数据稀疏性
1．7．3可扩展性
1．7．4用户兴趣漂移
1．8评测指标
本章小结
参考文献第二篇基于时序的协同过滤推荐算法
第2章基于巴式系数改进相似度的协同过滤推荐算法
2．1引言
2．2相关工作
2．2．1余弦相似度
2．2．2调整余弦相似度
2．2．3Pearson相关系数
2．2．4Jaccard相似度
2．3一种巴氏系数改进相似度的协同过滤推荐算法
2．3．1巴氏系数
2．3．2巴氏系数相似度
2．3．3BCCF算法描述
2．4实验与分析
2．4．1数据集
2．4．2评价标准
2．4．3实验结果与分析
本章小结
参考文献
第3章基于用户兴趣和项目属性的协同过滤推荐算法
3．1引言
3．2相关工作
3．3基于用户兴趣和项目属性的协同过滤推荐算法
3．3．1基于时间的用户兴趣度权重
3．3．2改进相似度计算
3．3．3加权预测评分
3．3．4算法步骤
3．4实验结果与分析
3．4．1数据集
3．4．2评价标准
3．4．3结果分析
本章小结
参考文献第三篇基于矩阵分解的协同过滤推荐算法
第4章SVD和信任因子相结合的协同过滤推荐算法
4．1引言
4．2标注和相关工作
4．2．1标注
4．2．2奇异值分解
4．2．3计算相似度
4．3SVD和信任因子相结合的协同过滤推荐算法
4．3．1项目特征空间
4．3．2两阶段k近邻选择
4．3．3信任因子
4．3．4预测评分
4．3．5算法
4．4实验结果与分析
4．4．1数据集和实验环境
4．4．2评价标准
4．4．3实验结果分析
本章小结
参考文献
第5章相似度填充的概率矩阵分解的协同过滤推荐算法
5．1引言
5．2相关工作
5．2．1协同过滤推荐算法
5．2．2概率矩阵分解技术
5．3CFPFCF算法
5．3．1算法设计思想
5．3．2CFPFCF算法的描述
5．4实验分析
5．4．1数据集与误差标准
5．4．2实验结果与性能比较
本章小结
参考文献
第6章基于偏置信息的改进概率矩阵分解算法研究
6．1引言
6．2相关工作
6．2．1矩阵分解模型
6．2．2Baseline预测
6．3算法流程
6．4实验分析
6．4．1实验所用数据集
6．4．2实验环境配置
6．4．3实验评价标准
6．4．4实验结果及分析
本章小结
参考文献
第7章基于项目属性改进概率矩阵分解算法
7．1引言
7．2IARBP算法
7．2．1相似度度量
7．2．2算法描述
7．2．3算法复杂度分析
7．3实验结果对比分析
7．3．1实验数据集
7．3．2实验评价标准
7．3．3对比实验配置及说明
7．3．4实验参数分析
7．3．5实验对比
本章小结
参考文献
第8章基于交替最小二乘的改进概率矩阵分解算法
8．1引言
8．2交替最小二乘
8．3Baseline预测
8．4IPMF算法
8．4．1算法改进思想
8．4．2算法流程
8．4．3复杂度分析
8．5实验结果分析
8．5．1对比实验设定
8．5．2实验分析
本章小结
参考文献
第9章基于社交网络的改进概率矩阵分解算法研究
9．1引言
9．2相关工作
9．2．1推荐系统的形式化
9．2．2矩阵分解与推荐系统
9．3概率矩阵分解
9．4主要研究内容
9．4．1基于社交网络的改进概率矩阵分解
9．4．2算法流程
9．4．3算法复杂度分析
9．5实验分析
9．5．1实验数据集
9．5．2实验评价标准
9．5．3对比算法
9．5．4潜在因子维度的影响
9．5．5偏置的影响
9．5．6信任因子的影响
9．5．7对比实验分析
本章小结
参考文献
第10章带偏置的非负矩阵分解推荐算法
10．1引言
10．2相关工作
10．2．1矩阵分解
10．2．2奇异值矩阵
10．2．3Baseline预测
10．2．4NMF算法
10．3RBNMF算法
10．3．1理论分析
10．3．2RBNMF算法流程
10．4实验分析
10．4．1数据集
10．4．2评价标准
10．4．3实验结果及分析
本章小结
参考文献
第11章基于项目热度的协同过滤推荐算法
11.1引言
11.2非负矩阵分解
11.3两阶段近邻选择
11.3.1两阶段k近邻选择
11.3.2项目“热度”和局部信任
11.3.3预测评分
11.4算法描述
11.5实验结果分析
11.5.1不同策略下相似度的分布
11.5.2两种因素的分布与分析
11.5.3实验结果及分析
本章小结
参考文献
第四篇基于信任的协同过滤推荐算法
第12章带偏置的专家信任推荐算法
12.1引言
12.2相关工作
12.2.1专家算法
12.2.2生成推荐值
12.2.3Baseline预测
12.3改进专家算法
12.3.1改进专家信任
12.3.2评分形成
12.3.3算法描述
12.4实验结果与分析
12.4.1数据集
12.4.2评估标准
12.4.3实验结果及分析
本章小结
参考文献
第13章一种改进专家信任的协同过滤推荐算法
13.1引言
13.2标注与相关工作
13.2.1标注
13.2.2近邻模型
13.2.3专家算法
13.3改进专家算法
13.3.1重要概念
13.3.2评分形成
13.3.3算法描述
13.4实验结果与分析
13.4.1数据集
13.4.2评估标准
13.4.3实验结果与分析
本章小结
参考文献
第五篇原型系统开发
第14章电影推荐原型系统
14.1引言
14.2主要功能
14.3关键技术
14.3.1概率矩阵分解模型
14.3.2社交网络正则化
14.4集群搭建
14.4.1集群软硬件环境
14.4.2Spark集群
14.4.3HBase集群
14.5系统特点
14.6用户使用说明
14.6.1系统简介界面
14.6.2建模一和建模二界面
14.6.3集群界面
14.6.4看过的电影界面
14.6.5推荐电影界面
14.6.6统计分析界面
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习算法实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习实战
第一部分Python开发实战
第一章开发环境选择与比较：张目清
第二章Anaconda使用介绍：裔隽
第三章开发规范与方法：张目清
第四章单元测试与代码覆盖率：张怿檬
第二部分Python编程技巧
第五章列表生成式：裔隽
第六章Collections库：裔隽
第七章迭代器：裔隽
第八章Python多线程与多进程浅析：裔隽
第九章Python程序性能分析初步：裔隽
第十章机器学习基础：张怿檬
第十一章主要算法概览：张怿檬
第十二章K近邻算法：张怿檬
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python大规模机器学习
译者序
前言
作者简介
审校者简介
第1章迈向可扩展性的第一步1
1.1详细解释可扩展性1
1.1.1大规模实例3
1.1.2介绍Python4
1.1.3使用Python进行向上扩展4
1.1.4使用Python进行向外扩展5
1.2Python用于大规模机器学习6
1.2.1选择Python 2还是Python 36
1.2.2安装Python7
1.2.3逐步安装7
1.2.4安装软件包8
1.2.5软件包升级9
1.2.6科学计算发行版10
1.2.7Jupyter/IPython介绍11
1.3Python包13
1.3.1NumPy14
1.3.2SciPy14
1.3.3pandas14
1.3.4Scikitlearn15
1.3.5小结21
第2章Scikitlearn中的可扩展学习22
2.1非核心学习22
2.1.1选择子采样23
2.1.2一次优化一个实例24
2.1.3构建非核心学习系统25
2.2流化源数据25
2.2.1处理真实数据集26
2.2.2第一个示例——流化共享单车数据集28
2.2.3使用pandas I/O工具30
2.2.4使用数据库31
2.2.5关注实例排序35
2.3随机学习37
2.3.1批处理梯度下降37
2.3.2随机梯度下降40
2.3.3Scikitlearn的SGD实现40
2.3.4定义SGD学习参数42
2.4数据流的特征管理43
2.4.1描述目标46
2.4.2哈希技巧49
2.4.3其他基本变换51
2.4.4流测试和验证52
2.4.5使用SGD52
2.5小结56
第3章实现快速SVM57
3.1测试数据集58
3.1.1共享单车数据集58
3.1.2森林覆盖类型数据集58
3.2支持向量机59
3.2.1hinge loss及其变形64
3.2.2Scikitlearn的SVM实现65
3.2.3探究通过子采样改善非线性SVM68
3.2.4使用SGD实现大规模SVM70
3.3正则化特征选择77
3.4SGD中的非线性78
3.5超参数调整82
3.6小结96
第4章神经网络与深度学习97
4.1神经网络架构98
4.1.1神经网络如何学习106
4.1.2选择正确的架构110
4.1.3使用神经网络111
4.1.4sknn并行化111
4.2神经网络和正则化113
4.3神经网络和超参数优化115
4.4神经网络和决策边界117
4.5用H2O进行规模化深度学习120
4.5.1用H2O进行大规模深度学习121
4.5.2H2O上的网格搜索124
4.6深度学习和无监督预训练126
4.7使用theanets进行深度学习126
4.8自动编码器和无监督学习128
4.9小结131
第5章用TensorFlow进行深度学习132
5.1TensorFlow安装134
5.2在TensorFlow上使用SkFlow进行机器学习140
5.3安装Keras和TensorFlow148
5.4在TensorFlow中通过Keras实现卷积神经网络152
5.4.1卷积层153
5.4.2池化层153
5.4.3全连接层154
5.5增量CNN方法156
5.6GPU计算156
5.7小结159
第6章大规模分类和回归树160
6.1bootstrap聚合162
6.2随机森林和极端随机森林163
6.3随机搜索实现快速参数优化167
6.4CART和boosting172
6.5XGBoost179
6.5.1XGBoost回归181
6.5.2XGBoost流化大型数据集184
6.5.3XGBoost模型存储185
6.6用H2O实现非核心CART185
6.6.1H2O上的随机森林和网格搜索186
6.6.2H2O上的随机梯度增强和网格搜索188
6.7小结191
第7章大规模无监督学习192
7.1无监督方法192
7.2特征分解：PCA193
7.2.1随机化PCA199
7.2.2增量PCA200
7.2.3稀疏PCA201
7.3使用H2O的PCA202
7.4K-均值聚类算法203
7.4.1初始化方法206
7.4.2K-均值假设206
7.4.3选择最佳K209
7.4.4扩展K-均值算法：小批量212
7.5用H2O实现K-均值216
7.6LDA218
7.7小结226
第8章分布式环境——Hadoop和Spark227
8.1从单机到集群227
8.2设置VM230
8.2.1VirtualBox230
8.2.2Vagrant232
8.2.3使用VM232
8.3Hadoop生态系统234
8.3.1架构234
8.3.2HDFS235
8.3.3MapReduce242
8.3.4YARN250
8.4Spark250
8.5小结260
第9章Spark机器学习实践261
9.1为本章设置虚拟机261
9.2跨集群节点共享变量262
9.2.1广播只读变量262
9.2.2累加器只写变量264
9.2.3广播和累加器的示例265
9.3Spark的数据预处理267
9.3.1JSON文件和Spark DataFrame268
9.3.2处理缺失数据270
9.3.3在内存中分组和创建表271
9.3.4将预处理的DataFrame或RDD写入磁盘273
9.3.5使用Spark DataFrame274
9.4Spark机器学习276
9.4.1Spark处理KDD99数据集277
9.4.2读取数据集277
9.4.3特征工程280
9.4.4训练学习器284
9.4.5评估学习器的表现286
9.4.6机器学习管道的威力286
9.4.7手动优化288
9.4.8交叉验证291
9.5小结293
附录介绍GPU和Theano294
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python大规模机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB深度学习 机器学习、神经网络与人工智能
目    录
第1章　机器学习  1
1.1  什么是机器学习  2
1.2  机器学习面临的挑战  4
1.2.1  过拟合  5
1.2.2  克服过拟合  7
1.3  机器学习的类型  9
1.4  本章小结  13
第2章　神经网络  15
2.1  神经网络的节点  15
2.2  神经网络的层  17
2.3  神经网络的监督学习  21
2.4  训练单层神经网络：delta规则  22
2.5  广义delta规则  25
2.6  SGD、Batch和Mini Batch  26
2.6.1  SGD  26
2.6.2  Batch  27
2.6.3  Mini Batch  27
2.7  delta规则示例  29
2.8  SGD方法的实现  30
2.9  Batch方法的实现  32
2.10  SGD与Batch的比较  34
2.11  单层神经网络的局限性  36
2.12  究竟发生了什么？  38
2.13  本章小结  40
第3章　多层神经网络的训练  41
3.1  反向传播算法  42
3.2  反向传播示例  46
3.2.1  XOR问题  48
3.2.2  动量  50
3.3  代价函数与学习规则  53
3.4  交叉熵函数示例  57
3.5  交叉熵函数  58
3.6  代价函数比较  60
3.7  本章小结  62
第4章　神经网络与分类问题  63
4.1  二元分类  63
4.2  多元分类  66
4.3  多元分类示例  71
4.4  本章小结  78
第5章　深度学习  79
5.1  深度神经网络的改进  80
5.1.1  梯度消失  81
5.1.2  过拟合  82
5.1.3  计算负载  83
5.2  ReLU与Dropout的实例  84
5.2.1  ReLU函数  85
5.2.2  Dropout  88
5.3  本章小结  93
第6章　卷积神经网络  95
6.1  卷积神经网络架构  95
6.2  卷积层  97
6.3  池化层  101
6.4  MNIST示例  102
6.5  本章小结  116
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB深度学习 机器学习、神经网络与人工智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>从机器学习到深度学习
第1章  机器学习基础  1
1.1  引言  1
1.1.1  为什么使用机器学习  2
1.1.2  机器学习与数据挖掘  4
1.1.3  机器学习与人工智能  5
1.2  机器学习的一般流程  7
1.2.1  定义问题  7
1.2.2  收集数据  8
1.2.3  比较算法与模型  9
1.2.4  应用模型  10
1.3  学习策略  10
1.3.1  有监督学习  11
1.3.2  无监督学习  14
1.3.3  强化学习  16
1.3.4  综合模型与工具  18
1.4  评估理论  19
1.4.1  划分数据集  19
1.4.2  交叉验证  21
1.4.3  评估指标  22
1.4.4  拟合不足与过度拟合  25
1.5  本章内容回顾  26
第2章  Python基础工具  27
2.1  Numpy  28
2.1.1  Numpy与Scipy的分工  28
2.1.2  ndarray构造  29
2.1.3  数据类型  32
2.1.4  访问与修改  33
2.1.5  轴  35
2.1.6  维度操作  38
2.1.7  合并与拆分  40
2.1.8  增与删  41
2.1.9  全函数  42
2.1.10  广播  42
2.2  Matplot  43
2.2.1  点线图  44
2.2.2  子视图  50
2.2.3  图像  53
2.2.4  等值图  57
2.2.5  三维绘图  58
2.2.6  从官网学习  59
2.3  Scipy  60
2.3.1  数学与物理常数  61
2.3.2  特殊函数库  62
2.3.3  积分  64
2.3.4  优化  65
2.3.5  插值  67
2.3.6  离散傅里叶  68
2.3.7  卷积  70
2.3.8  线性分析  71
2.3.9  概率统计  73
2.4  本章内容回顾  77
第3章  有监督学习：分类与回归  79
3.1  线性回归  80
3.1.1  何谓线性模型  80
3.1.2  最小二乘法  81
3.1.3  最小二乘法的不足  82
3.1.4  岭回归  85
3.1.5  Lasso回归  87
3.2  梯度下降  90
3.2.1  假设函数与损失函数  90
3.2.2  随机梯度下降  92
3.2.3  实战：SGDRegressor和SGDClassifier  93
3.2.4  增量学习  94
3.3  支持向量机  95
3.3.1  最优超平面  95
3.3.2  软间隔  97
3.3.3  线性不可分问题  98
3.3.4  核函数  99
3.3.5  实战：scikit-learn中的SVM  100
3.4  朴素贝叶斯分类  101
3.4.1  基础概率  102
3.4.2  贝叶斯分类原理  103
3.4.3  高斯朴素贝叶斯  105
3.4.4  多项式朴素贝叶斯  106
3.4.5  伯努利朴素贝叶斯  107
3.5  高斯过程  107
3.5.1  随机过程  108
3.5.2  无限维高斯分布  109
3.5.3  实战：gaussian_process工具包  111
3.6  决策树  114
3.6.1  最易于理解的模型  114
3.6.2  熵的作用  115
3.6.3  实战：DecisionTreeClassifier与DecisionTreeRegressor  117
3.6.4  树的可视化  118
3.7  集成学习  119
3.7.1  偏差与方差  120
3.7.2  随机森林  121
3.7.3  自适应增强  124
3.8  综合话题  126
3.8.1  参数与非参数学习  127
3.8.2  One-Vs-All与One-Vs-One  127
3.8.3  评估工具  129
3.8.4  超参数调试  131
3.8.5  多路输出  134
3.9  本章内容回顾  134
第4章  无监督学习：聚类  136
4.1  动机  137
4.2  K-means  138
4.2.1  算法  139
4.2.2  实战：scikit-learn聚类调用  141
4.2.3  如何选择K值  144
4.3  近邻算法  145
4.3.1  生活化的理解  145
4.3.2  有趣的迭代  146
4.3.3  实战：AffinityPropagation类  147
4.4  高斯混合模型  149
4.4.1  中心极限定理  150
4.4.2  最大似然估计  151
4.4.3  几种协方差矩阵类型  152
4.4.4  实战：GaussianMixture类  154
4.5  密度聚类  156
4.5.1  凸数据集  157
4.5.2  密度算法  158
4.5.3  实战：DBSCAN类  159
4.6  BIRCH  160
4.6.1  层次模型综述  161
4.6.2  聚类特征树  162
4.6.3  实战：BIRCH相关调用  164
4.7  距离计算  166
4.7.1  闵氏距离  166
4.7.2  马氏距离  167
4.7.3  余弦相似度  168
4.7.4  时间序列比较  169
4.7.5  杰卡德相似度  169
4.8  聚类评估  170
4.9  本章内容回顾  172
第5章  无监督学习：数据降维  173
5.1  主成分分析  174
5.1.1  寻找方差最大维度  174
5.1.2  用PCA降维  177
5.1.3  实战：用PCA寻找主成分  178
5.2  线性判别分析  181
5.2.1  双重标准  181
5.2.2  实战：使用LinearDiscriminantAnalysis  183
5.3  多维标度法  185
5.3.1  保留距离信息的线性变换  185
5.3.2  MDS的重要变形  187
5.3.3  实战：使用MDS类  188
5.4  流形学习之Isomap  189
5.4.1  什么是流形  190
5.4.2  测地线距离  192
5.4.3  实战：使用Isomap类  193
5.5  流形学习之局部嵌入  195
5.5.1  局部线性嵌入  195
5.5.2  拉普拉斯特征映射（LE）  198
5.5.3  调用介绍  200
5.5.4  谱聚类  201
5.6  流形学习之t-SNE  203
5.6.1  用Kullback-Leiber衡量分布相似度  203
5.6.2  为什么是t-分布  205
5.6.3  实战：使用TSNE类  206
5.7  实战：降维模型之比较  207
5.8  本章内容回顾  210
第6章  隐马尔可夫模型  212
6.1  场景建模  213
6.1.1  两种状态链  213
6.1.2  两种概率  215
6.1.3  三种问题  217
6.1.4  hmmLearn介绍  218
6.2  离散型分布算法与应用  222
6.2.1  前向算法与后向算法  222
6.2.2  MultinomialNB求估计问题  226
6.2.3  Viterbi算法  227
6.2.4  MultinomialNB求解码问题  229
6.2.5  EM算法  232
6.2.6  Baum-Welch算法  233
6.2.7  用hmmLearn训练数据  235
6.3  连续型概率分布  236
6.3.1  多元高斯分布  237
6.3.2  GaussianHMM  239
6.3.3  GMMHMM  240
6.4  实战：股票预测模型  241
6.4.1  数据模型  241
6.4.2  目标  243
6.4.3  训练模型  243
6.4.4  分析模型参数  245
6.4.5  可视化短线预测  247
6.5  本章内容回顾  250
第7章  贝叶斯网络  251
7.1  什么是贝叶斯网络  252
7.1.1  典型贝叶斯问题  252
7.1.2  静态结构  253
7.1.3  联合/边缘/条件概率换算  256
7.1.4  链式法则与变量消元  258
7.2  网络构建  259
7.2.1  网络参数估计  260
7.2.2  启发式搜索  261
7.2.3  Chow-Liu Tree算法  262
7.3  近似推理  263
7.3.1  蒙特卡洛方法  264
7.3.2  马尔可夫链收敛定理  265
7.3.3  MCMC推理框架  267
7.3.4  Gibbs采样  268
7.3.5  变分贝叶斯  268
7.4  利用共轭建模  270
7.4.1  共轭分布  270
7.4.2  隐含变量与显式变量  272
7.5  实战：胸科疾病诊断  274
7.5.1  诊断需求  274
7.5.2  Python概率工具包  275
7.5.3  建立模型  276
7.5.4  MCMC采样分析  278
7.5.5  近似推理  281
7.6  本章内容回顾  282
第8章  自然语言处理  284
8.1  文本建模  285
8.1.1  聊天机器人原理  285
8.1.2  词袋模型  286
8.1.3  访问新闻资源库  287
8.1.4  TF-IDF  290
8.1.5  实战：关键词推举  290
8.2  词汇处理  294
8.2.1  中文分词  294
8.2.2  Word2vec  296
8.2.3  实战：寻找近似词  298
8.3  主题模型  303
8.3.1  三层模型  303
8.3.2  非负矩阵分解  304
8.3.3  潜在语意分析  305
8.3.4  隐含狄利克雷分配  307
8.3.5  实战：使用工具包  309
8.4  实战：用LDA分析新闻库  311
8.4.1  文本预处理  311
8.4.2  训练与显示  313
8.4.3  困惑度调参  315
8.5  本章内容回顾  317
第9章  深度学习  319
9.1  神经网络基础  320
9.1.1  人工神经网络  320
9.1.2  神经元与激活函数  321
9.1.3  反向传播  323
9.1.4  万能网络  325
9.2  TensorFlow核心应用  328
9.2.1  张量  329
9.2.2  开发架构  331
9.2.3  数据管理  332
9.2.4  评估器  335
9.2.5  图与会话  338
9.2.6  逐代（epoch）训练  341
9.2.7  图与统计可视化  343
9.3  卷积神经网络  349
9.3.1  给深度学习一个理由  349
9.3.2  CNN结构发展  351
9.3.3  卷积层  354
9.3.4  池化层  356
9.3.5  ReLU与Softmax  357
9.3.6  Inception与ResNet  359
9.4  优化  362
9.4.1  批次规范化  362
9.4.2  剪枝  364
9.4.3  算法选择  366
9.5  循环神经网络与递归神经网络  367
9.5.1  循环神经网络  368
9.5.2  长短期记忆（LSTM）  371
9.5.3  递归神经网络  374
9.6  前沿精选  377
9.6.1  物件检测模型  377
9.6.2  密连卷积网络  381
9.6.3  胶囊网络  382
9.7  CNN实战：图像识别  385
9.7.1  开源图像库CIFAR  385
9.7.2  项目介绍  388
9.7.3  构建Graph  389
9.7.4  优化与训练  392
9.7.5  运行  394
9.8  RNN实战：写诗机器人  397
9.8.1  语言模型  397
9.8.2  LSTM开发步骤1：网络架构  401
9.8.3  LSTM开发步骤2：数据加载  402
9.8.4  LSTM开发步骤3：搭建TensorFlow Graph  403
9.8.5  LSTM开发步骤4：解析LSTM RNN  404
9.8.6  LSTM开发步骤5：LSTM中的参数  406
9.8.7  LSTM开发步骤6：用sequence_loss计算RNN损失值  406
9.8.8  LSTM开发步骤7：学习速度可调优化器  407
9.8.9  LSTM开发步骤8：训练  408
9.8.10  开始写唐诗  410
9.8.11  写唐诗步骤1：用唐诗语料训练语言模型  410
9.8.12  写唐诗步骤2：作诗  412
9.8.13  写唐诗步骤3：作品举例  414
9.9  本章内容回顾  415
第10章  强化学习  418
10.1  场景与原理  419
10.1.1  借AlphaGo谈人工智能  419
10.1.2  基于价值的算法Q-Learning与Sarsa  421
10.1.3  基于策略的算法  424
10.1.4  基于模型的算法  426
10.2  OpenAI Gym  427
10.2.1  环境调用  428
10.2.2  实战：用Q-Learning开发走迷宫机器人  432
10.3  深度强化学习  435
10.3.1  DQN及改进  435
10.3.2  DPN、DDPG及A3C  436
10.3.3  实战：用DPN训练月球定点登陆  439
10.4  博弈原理  444
10.4.1  深度搜索与广度搜索  444
10.4.2  完美决策  446
10.4.3  蒙特卡洛搜索树  448
10.5  实战：中国象棋版AlphaGo Zero  449
10.5.1  开源版本AlphaGo Zero  450
10.5.2  盘面建模  452
10.5.3  左右互搏  457
10.5.4  MCTS详解  464
10.5.5  DDPG详解  468
10.5.6  运行展示：训练  473
10.5.7  运行展示：查看统计  475
10.5.8  运行展示：当头炮、把马跳  475
10.5.9  运行展示：人机博弈  476
10.6  本章内容回顾  477
第11章  模型迁移  478
11.1  走向移动端  478
11.1.1  Android上的TensorFlow  479
11.1.2  iOS上的CoreML  480
11.2  迁移学习  483
11.2.1  动机  483
11.2.2  训练流程  484
11.3  案例实战：基于TensorFlow Hub的迁移学习开发  485
11.3.1  下载并训练  485
11.3.2  检验学习成果  486
11.3.3  迁移学习开发  487
11.4  本章内容回顾  488
后记  489
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>从机器学习到深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习手册：从数据预处理到深度学习
第1 章　向量、矩阵和数组 ..................................................................... 1
1.0　简介 .....................................................................................................1
1.1　创建一个向量 ......................................................................................1
1.2　创建一个矩阵 ......................................................................................2
1.3　创建一个稀疏矩阵 ...............................................................................3
1.4　选择元素 ..............................................................................................5
1.5　展示一个矩阵的属性 ...........................................................................6
1.6　对多个元素同时应用某个操作 ............................................................7
1.7　找到最大值和最小值 ...........................................................................8
1.8　计算平均值、方差和标准差 ................................................................9
1.9　矩阵变形 ............................................................................................10
1.10 转置向量或矩阵 ............................................................... 11
1.11 展开一个矩阵 ....................................................................................12
1.12 计算矩阵的秩 ....................................................................................13
1.13 计算行列式 ........................................................................................14
1.14 获取矩阵的对角线元素 .....................................................................14
1.15 计算矩阵的迹 ....................................................................................15
1.16 计算特征值和特征向量 .....................................................................16
1.17 计算点积 ...........................................................................................17
1.18 矩阵的相加或相减 ............................................................................18
1.19 矩阵的乘法 ........................................................................................19
1.20 计算矩阵的逆 ....................................................................................20
1.21 生成随机数 ........................................................................................21
第2 章　加载数据 ................................................................................ 23
2.0　简介 ...................................................................................................23
2.1　加载样本数据集 ................................................................................23
2.2　创建仿真数据集 ................................................................................25
2.3　加载CSV 文件 ..................................................................................28
2.4　加载Excel 文件 .................................................................................29
2.5　加载JSON 文件 .................................................................................29
2.6　查询SQL 数据库 ...............................................................................31
第3 章　数据整理 ................................................................................ 33
3.0　简介 ...................................................................................................33
3.1　创建一个数据帧 ................................................................................34
3.2　描述数据 ............................................................................................35
3.3　浏览数据帧 ........................................................................................37
3.4　根据条件语句来选择行 .....................................................................39
3.5　替换值 ...............................................................................................40
3.6　重命名列 ............................................................................................41
3.7　计算最小值、最大值、总和、平均值与计数值 ................................43
3.8　查找唯一值 ........................................................................................44
3.9　处理缺失值 ........................................................................................45
3.10 删除一列 ...........................................................................................47
3.11 删除一行 ............................................................................................48
3.12 删除重复行 ........................................................................................49
3.13 根据值对行分组 ................................................................................51
3.14 按时间段对行分组 ............................................................................52
3.15 遍历一个列的数据 ............................................................................54
3.16 对一列的所有元素应用某个函数 ......................................................55
3.17 对所有分组应用一个函数 .................................................................56
3.18 连接多个数据帧 ................................................................................57
3.19 合并两个数据帧 ................................................................................59
第4 章　处理数值型数据 ...................................................................... 63
4.0　简介 ...................................................................................................63
4.1　特征的缩放 ........................................................................................63
4.2　特征的标准化 ....................................................................................65
4.3　归一化观察值 ....................................................................................66
4.4　生成多项式和交互特征 .....................................................................69
4.5　转换特征 ............................................................................................70
4.6　识别异常值 ........................................................................................71
4.7　处理异常值 ........................................................................................73
4.8　将特征离散化 ....................................................................................75
4.9　使用聚类的方式将观察值分组 ..........................................................77
4.10 删除带有缺失值的观察值 .................................................................79
4.11 填充缺失值 ........................................................................................81
第5 章　处理分类数据 ......................................................................... 83
5.0　简介 ...................................................................................................83
5.1　对nominal 型分类特征编码 ..............................................................84
5.2　对ordinal 分类特征编码 ....................................................................86
5.3　对特征字典编码 ................................................................................88
5.4　填充缺失的分类值 .............................................................................91
5.5　处理不均衡分类 ................................................................................93
第6 章　处理文本 ................................................................................ 97
6.0　简介 ...................................................................................................97
6.1　清洗文本 ............................................................................................97
6.2　解析并清洗HTML ............................................................................99
6.3　移除标点 .......................................................................................... 100
6.4　文本分词 .......................................................................................... 101
6.5　删除停止词（stop word）......................................... 102
6.6　提取词干 .......................................................................................... 103
6.7　标注词性 .......................................................................................... 104
6.8　将文本编码成词袋（Bag of Words）................................................ 107
6.9　按单词的重要性加权 ....................................... 109
第7 章　处理日期和时间 .................................................................... 113
7.0　简介 ................................................................................................. 113
7.1　把字符串转换成日期 ......................................................... 113
7.2　处理时区 .......................................................................................... 115
7.3　选择日期和时间 .............................................................................. 116
7.4　将日期数据切分成多个特征 ............................................................ 117
7.5　计算两个日期之间的时间差 ............................................................ 118
7.6　对一周内的各天进行编码 ............................................................... 119
7.7　创建一个滞后的特征 ....................................................... 120
7.8　使用滚动时间窗口 ........................................................................... 121
7.9　处理时间序列中的缺失值 ............................................................... 123
第8 章　图像处理 .............................................................................. 127
8.0　简介 ................................................................................................. 127
8.1　加载图像 .......................................................................................... 128
8.2　保存图像 .......................................................................................... 130
8.3　调整图像大小 .................................................................................. 131
8.4　裁剪图像 .......................................................................................... 132
8.5　平滑处理图像 .................................................................................. 133
8.6　图像锐化 .......................................................................................... 136
8.7　提升对比度 .................................................................. 138
8.8　颜色分离 .......................................................................................... 140
8.9　图像二值化 .......................................... 142
8.10 移除背景............................................. 144
8.11 边缘检测 .......................................................................................... 148
8.12 角点检测 ................................. 150
8.13 为机器学习创建特征 ................................................. 153
8.14 将颜色平均值编码成特征 ............................................................... 156
8.15 将色彩直方图编码成特征 ............................................................... 157
第9 章　利用特征提取进行特征降维 ................................................... 161
9.0　简介 ................................................................................................. 161
9.1　使用主成分进行特征降维 ............................................................... 161
9.2　对线性不可分数据进行特征降维 .................................................... 164
9.3　通过最大化类间可分性进行特征降维 ............................................. 166
9.4　使用矩阵分解法进行特征降维...................................... 169
9.5　对稀疏数据进行特征降维 ............................................................... 170
第10 章　使用特征选择进行降维 ........................................................ 173
10.0　简介........................................................... 173
10.1　数值型特征方差的阈值化...................................... 173
10.2　二值特征的方差阈值化............................................ 175
10.3　处理高度相关性的特征 .......................................... 176
10.4　删除与分类任务不相关的特征 ...................................................... 178
10.5　递归式特征消除 ............................................................................ 180
第11 章　模型评估 ............................................................................ 183
11.0　简介 ...................................................................... 183
11.1　交叉验证模型 .......................................... 183
11.2　创建一个基准回归模型........................................ 187
11.3　创建一个基准分类模型 .................................. 188
11.4　评估二元分类器 ................................................ 190
11.5　评估二元分类器的阈值 ..................................... 193
11.6　评估多元分类器 .......................................................... 197
11.7　分类器性能的可视化 ..................................................................... 198
11.8　评估回归模型 ............................................. 201
11.9　评估聚类模型 ............................................................ 203
11.10 创建自定义评估指标 ..................................................................... 204
11.11 可视化训练集规模的影响 ............................................................. 206
11.12 生成对评估指标的报告 .................................................... 208
11.13 可视化超参数值的效果 ................................................. 209
第12 章　模型选择 ............................................................................ 213
12.0　简介 .................................................... 213
12.1　使用穷举搜索选择最佳模型 .......................................................... 213
12.2　使用随机搜索选择最佳模型 .......................................................... 216
12.3　从多种学习算法中选择最佳模型.................. 218
12.4　将数据预处理加入模型选择过程 .............................. 220
12.5　用并行化加速模型选择 ................................. 221
12.6　使用针对特定算法的方法加速模型选择 ....................................... 223
12.7　模型选择后的性能评估 ............................ 224
第13 章　线性回归 ............................................................................ 227
13.0　简介 ........................................ 227
13.1　拟合一条直线 .......................................... 227
13.2　处理特征之间的影响 ..................................................................... 229
13.3　拟合非线性关系 ............................................................................ 231
13.4　通过正则化减少方差 ..................................................................... 233
13.5　使用套索回归减少特征 .............................................. 235
第14 章　树和森林 ............................................................................ 237
14.0　简介 ............................... 237
14.1　训练决策树分类器 ......................................................................... 237
14.2　训练决策树回归模型 ..................................................................... 239
14.3　可视化决策树模型 ......................................................................... 240
14.4　训练随机森林分类器 ..................................................................... 243
14.5　训练随机森林回归模型 ............................ 244
14.6　识别随机森林中的重要特征 .......................................................... 245
14.7　选择随机森林中的重要特征 .......................................................... 248
14.8　处理不均衡的分类 ......................................................................... 249
14.9　控制决策树的规模 ......................................................................... 250
14.10 通过boosting 提高性能 ................................................................ 252
14.11 使用袋外误差（Out-of-Bag Error）评估随机森林模型 ................ 253
第15 章　KNN ................................................................................... 255
15.0　简介 ................................................................... 255
15.1　找到一个观察值的最近邻 ................................................. 255
15.2　创建一个KNN 分类器................................................................... 258
15.3　确定最佳的邻域点集的大小 .......................................................... 260
15.4　创建一个基于半径的最近邻分类器 ......................... 261
第16 章　逻辑回归 ............................................................................ 263
16.0　简介 ............................................................... 263
16.1　训练二元分类器 ............................................................................ 263
16.2　训练多元分类器 ............................................................................ 265
16.3　通过正则化来减小方差 ............................................. 266
16.4　在超大数据集上训练分类器 .......................................................... 267
16.5　处理不均衡的分类 ......................................................................... 269
第17 章　支持向量机 ......................................................................... 271
17.0　简介 ..................................................................... 271
17.1　训练一个线性分类器 ..................................................................... 271
17.2　使用核函数处理线性不可分的数据 ..................................... 274
17.3　计算预测分类的概率 ..................................................................... 278
17.4　识别支持向量 ....................................................... 279
17.5　处理不均衡的分类 ......................................................................... 281
第18 章　朴素贝叶斯 ......................................................................... 283
18.0　简介 ............................................................. 283
18.1　为连续的数据训练分类器 ............................................. 284
18.2　为离散数据和计数数据训练分类器 ............................... 286
18.3　为具有二元特征的数据训练朴素贝叶斯分类器 ............................ 287
18.4　校准预测概率 ........................................ 288
第19 章　聚类 ................................................................................... 291
19.0　简介 ................................................................ 291
19.1　使用K-Means 聚类算法 ................................................................ 291
19.2　加速K-Means 聚类 ........................................................................ 294
19.3　使用Meanshift 聚类算法 ............................................................... 295
19.4　使用DBSCAN 聚类算法 ............................................................... 296
19.5　使用层次合并聚类算法 .......................................... 298
第20 章　神经网络 ............................................................................ 301
20.0　简介 ...................................................................... 301
20.1　为神经网络预处理数据 .................................................... 302
20.2　设计一个神经网络 ......................................................................... 304
20.3　训练一个二元分类器 ..................................................................... 307
20.4　训练一个多元分类器 ..................................................................... 309
20.5　训练一个回归模型 ......................................................................... 311
20.6　做预测 ........................................................................................... 313
20.7　可视化训练历史 ............................................................................ 315
20.8　通过权重调节减少过拟合 ..................................... 318
20.9　通过提前结束减少过拟合 ........................................ 320
20.10 通过Dropout 减少过拟合 ............................................................. 322
20.11 保存模型训练过程 ......................................................................... 324
20.12 使用k 折交叉验证评估神经网络 ................................................ 326
20.13 调校神经网络 ........................................................................ 328
20.14 可视化神经网络 ............................................................................ 331
20.15 图像分类 ....................................................................................... 333
20.16 通过图像增强来改善卷积神经网络的性能 .............................. 337
20.17 文本分类 ....................................................................................... 339
第21 章　保存和加载训练后的模型 ..................................................... 343
21.0　简介 ....................................................................................... 343
21.1　保存和加载scikit-learn 模型 ......................................................... 343
21.2　保存和加载Keras 模型 .................................................................. 345
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习手册：从数据预处理到深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于机器学习的遥感影像分类方法研究
第1章 绪论
1．1 基本概念
1．1．1 土地覆盖
1．1．2 遥感技术
1．1．3 机器学习
1．2 研究意义
1．2．1 丰富土地覆盖遥感分类的理论与方法
1．2．2 为土地利用／覆盖的动态监测、保护和管理提供技术支持
1．2．3 一种新的自适应半监督支持向量机遥感分类模型的提出
1．2．4 半监督学习思想和集成学习思想的融合
1．3 本书研究方法及结构安排
1．3．1 研究方法
1．3．2 结构安排
参考文献
第2章 关键技术国内外研究现状
2．1 遥感影像信息提取方法
2．2 SVM遥感分类研究进展
2．2．1 SVM在遥感分类中的优点
2．2．2 SVM在遥感影像分类中的不足
2．2．3 SVM在遥感影像分类中的应用领域
2．3 半监督学习理论及研究进展
2．4 半监督分类中的聚类算法
2．5 集成学习理论及研究进展
参考文献
第3章 遥感图像数字化
3．1 研究区位置及遥感影像集
3．1．1 研究区位置
3．1．2 研究区影像集
3．1．3 分类体系的建立
3．2 遥感影像数字集
3．2．1 样本采集
3．2．2 特征选取
3．3 本章小结
参考文献
第4章 SVM参数优化方法研究
4．1 SVM理论及参数优化算法研究进展
4．1．1 SVM的核心思想
4．1．2 SVMN论
4．1．3 SVM参数优化方法研究进展
4．2 基于自适应变异粒子群参数优化的土地覆盖分类模型
4．2．1 传统粒子群算法(PSO)
4．2．2 自适应变异粒子群优化算法(AMPSO)
4．2．3 土地覆盖分类模型构建
4．3 实验结果与分析
4．3．1 实验影像选取
4．3．2 特征选取及样本集表示
4．3．3 核函数的选取
4．3．4 实验参数及精度评价指标
4．3．5 实验结果与比较
4．4 本章小结
参考文献
第5章 基于模糊聚类的半监督支持向量机土地覆盖分类方法研究
5．1 概述
5．2 自训练半监督学习
5．2．1 无标签样本的重要性
5．2．2 自训练半监督算法
5．3 模糊聚类理论
5．3．1 聚类的概念
5．3．2 常用聚类算法
5．3．3 聚类有效性验证
5．4 一种新的自训练半监督支持向量机分类模型构建
5．4．1 未标记样本的选择依据
5．4．2 基于GKclust的自训练半监督支持向量机设计流程
5．4．3 基于GKclust的自训练半监督支持向量机算法
5．5 实验结果与分析
5．5．1 遥感影像数字化
5．5．2 参数设置
5．5．3 模糊聚类算法的比较
5．5．4 无标签样本的参与比例
5．5．5 土地覆盖遥感图像分类
5．6 本章小结
参考文献
第6章 基于半监督集成支持向量机的土地覆盖分类研究
6．1 概述
6．2 集成学习框架
6．2．1 个体生成方法
6．2．2 结论生成方法
6．3 半监督集成支持向量机的土地覆盖分类模型构建
6．3．1 个体生成算法
6．3．2 结论生成算法
6．4 实验结果与分析
6．4．1 实验数据
6．4．2 结果与精度分析
6．5 本章小结
参考文献
第7章 总结与展望
7．1 研究结论
7．2 本书不足之处
7．3 研究展望
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于机器学习的遥感影像分类方法研究
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Apache Spark机器学习
译者序
前　言
第1章　Spark机器学习简介 1
1.1　Spark概述和技术优势 2
1.1.1　Spark概述 2
1.1.2　Spark优势 3
1.2　在机器学习中应用Spark计算 4
1.3　机器学习算法 5
1.4　MLlib 6
1.5　Spark RDD和DataFrame 8
1.5.1　Spark RDD 8
1.5.2　Spark DataFrame 9
1.5.3　R语言DataFrame API 10
1.5.4　机器学习框架、RM4E和Spark计算 11
1.5.5　机器学习框架 12
1.5.6　RM4E 13
1.5.7　Spark计算框架 13
1.6　机器学习工作流和Spark pipeline 14
1.7　机器学习工作流示例 16
1.8　Spark notebook简介 19
1.8.1　面向机器学习的notebook方法 19
1.8.2　Spark notebook 21
1.9　小结 22
第2章　Spark机器学习的数据准备 24
2.1　访问和加载数据集 25
2.1.1　访问公开可用的数据集 25
2.1.2　加载数据集到Spark 26
2.1.3　数据集探索和可视化 27
2.2　数据清洗 29
2.2.1　处理数据不完备性 30
2.2.2　在Spark中进行数据清洗 31
2.2.3　更简便的数据清洗 32
2.3　一致性匹配 33
2.3.1　一致性问题 33
2.3.2　基于Spark的一致性匹配 34
2.3.3　实体解析 34
2.3.4　更好的一致性匹配 35
2.4　数据集重组 36
2.4.1　数据集重组任务 36
2.4.2　使用Spark SQL进行数据集重组 37
2.4.3　在Spark上使用R语言进行数据集重组 38
2.5　数据集连接 39
2.5.1　数据连接及其工具——Spark SQL 39
2.5.2　Spark中的数据集连接 40
2.5.3　使用R语言数据表程序包进行数据连接 40
2.6　特征提取 42
2.6.1　特征开发的挑战 42
2.6.2　基于Spark MLlib的特征开发 43
2.6.3　基于R语言的特征开发 45
2.7　复用性和自动化 45
2.7.1　数据集预处理工作流 46
2.7.2　基于Spark pipeline的数据集预处理 47
2.7.3　数据集预处理自动化 47
2.8　小结 49
第3章　基于Spark的整体视图 51
3.1　Spark整体视图 51
3.1.1　例子 52
3.1.2　简洁快速的计算 54
3.2　整体视图的方法 55
3.2.1　回归模型 56
3.2.2　SEM方法 57
3.2.3　决策树 57
3.3　特征准备 58
3.3.1　PCA 59
3.3.2　使用专业知识进行分类分组 59
3.3.3　特征选择 60
3.4　模型估计 61
3.4.1　MLlib实现 62
3.4.2　R notebook实现 62
3.5　模型评估 63
3.5.1　快速评价 63
3.5.2　RMSE 64
3.5.3　ROC曲线 65
3.6　结果解释 66
3.7　部署 66
3.7.1　仪表盘 67
3.7.2　规则 68
3.8　小结 68
第4章　基于Spark的欺诈检测 69
4.1　Spark欺诈检测 70
4.1.1　例子 70
4.1.2　分布式计算 71
4.2　欺诈检测方法 72
4.2.1　随机森林 73
4.2.2　决策树 74
4.3　特征提取 74
4.3.1　从日志文件提取特征 75
4.3.2　数据合并 75
4.4　模型估计 76
4.4.1　MLlib实现 77
4.4.2　R notebook实现 77
4.5　模型评价 77
4.5.1　快速评价 78
4.5.2　混淆矩阵和误报率 78
4.6　结果解释 79
4.7　部署欺诈检测 80
4.7.1　规则 81
4.7.2　评分 81
4.8　小结 82
第5章　基于Spark的风险评分 83
5.1　Spark用于风险评分 84
5.1.1　例子 84
5.1.2　Apache Spark notebook 85
5.2　风险评分方法 87
5.2.1　逻辑回归 87
5.2.2　随机森林和决策树 88
5.3　数据和特征准备 89
5.4　模型估计 91
5.4.1　在Data Scientist Workbench上应用R notebook 91
5.4.2　实现R notebook 92
5.5　模型评价 93
5.5.1　混淆矩阵 93
5.5.2　ROC分析 93
5.5.3　Kolmogorov-Smirnov检验 94
5.6　结果解释 95
5.7　部署 96
5.8　小结 97
第6章　基于Spark的流失预测 99
6.1　Spark流失预测 99
6.1.1　例子 100
6.1.2　Spark计算 100
6.2　流失预测的方法 101
6.2.1　回归模型 102
6.2.2　决策树和随机森林 103
6.3　特征准备 104
6.3.1　特征提取 104
6.3.2　特征选择 105
6.4　模型估计 105
6.5　模型评估 107
6.6　结果解释 109
6.7　部署 110
6.7.1　评分 111
6.7.2　干预措施推荐 111
6.8　小结 111
第7章　基于Spark的产品推荐 112
7.1　基于Apache Spark 的产品推荐引擎 112
7.1.1　例子 113
7.1.2　基于Spark平台的SPSS 114
7.2　产品推荐方法 117
7.2.1　协同过滤 117
7.2.2　编程准备 118
7.3　基于SPSS的数据治理 119
7.4　模型估计 120
7.5　模型评价 121
7.6　产品推荐部署 122
7.7　小结 125
第8章　基于Spark的学习分析 126
8.1　Spark流失预测 127
8.1.1　例子 127
8.1.2　Spark计算 128
8.2　流失预测方法 130
8.2.1　回归模型 130
8.2.2　决策树 131
8.3　特征准备 131
8.3.1　特征开发 133
8.3.2　特征选择 133
8.4　模型估计 135
8.5　模型评价 137
8.5.1　快速评价 138
8.5.2　混淆矩阵和错误率 138
8.6　结果解释 139
8.6.1　计算干预影响 140
8.6.2　计算主因子影响 140
8.7　部署 141
8.7.1　规则 141
8.7.2　评分 142
8.8　小结
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Apache Spark机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>精通机器学习
第1章　成功之路　　1
1.1　流程　　1
1.2　业务理解　　2
1.2.1　确定业务目标　　3
1.2.2　现状评估　　4
1.2.3　确定分析目标　　4
1.2.4　建立项目计划　　4
1.3　数据理解　　4
1.4　数据准备　　5
1.5　建模　　5
1.6　评价　　6
1.7　部署　　6
1.8　算法流程图　　7
1.9　小结　　10
第2章　线性回归：机器学习基础技术　　11
2.1　单变量回归　　11
2.2　多变量线性回归　　18
2.2.1　业务理解　　18
2.2.2　数据理解和数据准备　　18
2.2.3　模型构建与模型评价　　21
2.3　线性模型中的其他问题　　30
2.3.1　定性特征　　30
2.3.2　交互项　　32
2.4　小结　　34
第3章　逻辑斯蒂回归与判别分析　　35
3.1　分类方法与线性回归　　35
3.2　逻辑斯蒂回归　　36
3.2.1　业务理解　　36
3.2.2　数据理解和数据准备　　37
3.2.3　模型构建与模型评价　　41
3.3　判别分析概述　　46
3.4　多元自适应回归样条方法　　50
3.5　模型选择　　54
3.6　小结　　57
第4章　线性模型中的高级特征选择技术　　58
4.1　正则化简介　　58
4.1.1　岭回归　　59
4.1.2　LASSO　　59
4.1.3　弹性网络　　60
4.2　商业案例　　60
4.2.1　业务理解　　60
4.2.2　数据理解和数据准备　　60
4.3　模型构建与模型评价　　65
4.3.1　最优子集　　65
4.3.2　岭回归　　68
4.3.3　LASSO　　71
4.3.4　弹性网络　　73
4.3.5　使用glmnet进行交叉验证　　76
4.4　模型选择　　78
4.5　正则化与分类问题　　78
4.6　小结　　81
第5章　更多分类技术：K最近邻与
支持向量机　　82
5.1　K最近邻　　82
5.2　支持向量机　　84
5.3　商业案例　　86
5.3.1　业务理解　　86
5.3.2　数据理解和数据准备　　87
5.3.3　模型构建与模型评价　　92
5.3.4　模型选择　　98
5.4　SVM中的特征选择　　100
5.5　小结　　101
第6章　分类回归树　　103
6.1　本章技术概述　　103
6.1.1　回归树　　104
6.1.2　分类树　　104
6.1.3　随机森林　　105
6.1.4　梯度提升　　106
6.2　商业案例　　106
6.2.1　模型构建与模型评价　　107
6.2.2　模型选择　　121
6.2.3　使用随机森林进行特征选择　　121
6.3　小结　　123
第7章　神经网络与深度学习　　124
7.1　神经网络介绍　　124
7.2　深度学习简介　　128
7.3　业务理解　　131
7.4　数据理解和数据准备　　132
7.5　模型构建与模型评价　　136
7.6　深度学习示例　　139
7.6.1　H2O背景介绍　　139
7.6.2　将数据上载到H2O平台　　140
7.6.3　建立训练数据集和测试
数据集　　141
7.6.4　模型构建　　142
7.7　小结　　146
第8章　聚类分析　　147
8.1　层次聚类　　148
8.2　K均值聚类　　149
8.3　果瓦系数与围绕中心的划分　　150
8.3.1　果瓦系数　　150
8.3.2　PAM　　151
8.4　随机森林　　151
8.5　业务理解　　152
8.6　数据理解与数据准备　　152
8.7　模型构建与模型评价　　155
8.7.1　层次聚类　　155
8.7.2　K均值聚类　　162
8.7.3　果瓦系数和PAM　　165
8.7.4　随机森林与PAM　　167
8.8　小结　　168
第9章　主成分分析　　169
9.1　主成分简介　　170
9.2　业务理解　　173
9.3　模型构建与模型评价　　176
9.3.1　主成分抽取　　176
9.3.2　正交旋转与解释　　177
9.3.3　根据主成分建立因子得分　　178
9.3.4　回归分析　　178
9.4　小结　　184
第10章　购物篮分析、推荐引擎与
序列分析　　185
10.1　购物篮分析简介　　186
10.2　业务理解　　187
10.3　数据理解和数据准备　　187
10.4　模型构建与模型评价　　189
10.5　推荐引擎简介　　192
10.5.1　基于用户的协同过滤　　193
10.5.2　基于项目的协同过滤　　194
10.5.3　奇异值分解和主成分分析　　194
10.6　推荐系统的业务理解　　198
10.7　推荐系统的数据理解与数据准备　　198
10.8　推荐系统的建模与评价　　200
10.9　序列数据分析　　208
10.10　小结　　214
第11章　创建集成多类分类　　215
11.1　集成模型　　215
11.2　业务理解与数据理解　　216
11.3　模型评价与模型选择　　217
11.4　多类分类　　219
11.5　业务理解与数据理解　　220
11.6　模型评价与模型选择　　223
11.6.1　随机森林　　224
11.6.2　岭回归　　225
11.7　MLR集成模型　　226
11.8　小结　　228
第12章　时间序列与因果关系　　229
12.1　单变量时间序列分析　　229
12.2　业务理解　　235
12.3　模型构建与模型评价　　240
12.3.1　单变量时间序列预测　　240
12.3.2　检查因果关系　　243
12.4　小结　　249
第13章　文本挖掘　　250
13.1　文本挖掘框架与方法　　250
13.2　主题模型　　252
13.3　业务理解　　254
13.4　模型构建与模型评价　　257
13.4.1　词频分析与主题模型　　257
13.4.2　其他定量分析　　261
13.5　小结　　267
第14章　在云上使用R语言　　268
14.1　创建AWS账户　　269
14.1.1　启动虚拟机　　270
14.1.2　启动Rstudio　　272
14.2　小结　　274
附录　R语言基础　　275
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>精通机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习入门之道
第1章 数据科学和机器学习 1
1.1 数据科学在商业领域中的作用 2
1.2 机器学习算法的分类 8
1.2.1 分类：产生类判定的算法 8
1.2.2 回归分析：预测数值的算法 9
1.2.3 聚类分析：对数据进行无监督群组化的算法 10
1.2.4 其他算法 12
1.3 本书使用的例题 13
1.3.1 基于回归分析的观测值推断 13
1.3.2 基于线性判别的新数据分类 17
1.3.3 图像文件的褪色处理（提取代表色） 18
1.3.4 识别手写文字 19
1.4 分析工具的准备 20
1.4.1 本书使用的数据分析工具 21
1.4.2 运行环境设置步骤（以CentOS 6为例） 22
1.4.3 运行环境设置步骤（以Mac OS X为例） 25
1.4.4 运行环境设置步骤（以Windows 7/8.1为例） 27
1.4.5 IPython的使用方法 30
第2章 最小二乘法：机器学习理论第一步 35
2.1 基于近似多项式和最小二乘法的推断 36
2.1.1 训练集的特征变量和目标变量 36
2.1.2 近似多项式和误差函数的设置 38
2.1.3 误差函数最小化条件 39
2.1.4 示例代码的确认 42
2.1.5 统计模型的最小二乘法 46
2.2 过度拟合检出 49
2.2.1 训练集和测试集 49
2.2.2 测试集的验证结果 50
2.2.3 基于交叉检查的泛化能力验证 52
2.2.4 基于数据的过度拟合变化 54
2.3 附录：Hessian矩阵的特性 56
第3章 最优推断法：使用概率的推断理论 59
3.1 概率模型的利用 60
3.1.1 “数据的产生概率”设置 60
3.1.2 基于似然函数的参数评价 65
3.1.3 示例代码的确认 69
3.2 使用简化示例的解释说明 73
3.2.1 正态分布的参数模型 74
3.2.2 示例代码的确认 76
3.2.3 推断量的评价方法（一致性和无偏性） 78
3.3 附录：样本均值及样本方差一致性和无偏性的证明 80
3.3.1 样本均值及样本方差一致性和无偏性的证明 81
3.3.2 示例代码的确认 85
第4章 感知器：分类算法的基础 89
4.1 概率梯度下降法的算法 91
4.1.1 分割平面的直线方程 91
4.1.2 基于误差函数的分类结果评价 93
4.1.3 基于梯度的参数修正 95
4.1.4 示例代码的确认 99
4.2 感知器的几何学解释 100
4.2.1 对角项的任意性和算法的收敛速度 101
4.2.2 感知器的几何学解释 103
4.2.3 对角项的几何学意义 104
第5章 Logistic回归和ROC曲线：学习模型的评价方法 107
5.1 对分类问题应用最优推断法 108
5.1.1 数据发生概率的设置 108
5.1.2 基于最优推断法的参数确定 112
5.1.3 示例代码的确认 114
5.2 基于ROC曲线的学习模型评价 117
5.2.1 Logistic回归在实际问题中的应用 118
5.2.2 基于ROC曲线的性能评价 120
5.2.3 示例代码的确认 123
5.3 附录：IRLS法的推导 126
第6章 K均值算法：无监督学习模型的基础 133
6.1 基于K均值算法的聚类分析和应用实例 134
6.1.1 无监督学习模型类聚类分析 134
6.1.2 基于K均值算法的聚类分析 135
6.1.3 在图像数据方面的应用 138
6.1.4 示例代码的确认 141
6.1.5 K均值算法的数学依据 143
6.2 “懒惰”学习模型K近邻法 146
6.2.1 基于K近邻法的分类 146
6.2.2 K近邻法的问题 148
第7章 EM算法：基于最优推断法的监督学习 151
7.1 使用伯努利分布的最优推断法 152
7.1.1 手写文字的合成方法 153
7.1.2 基于图像生成器的最优推断法应用 154
7.2 使用混合分布的最优推断法 157
7.2.1 基于混合分布的概率计算 157
7.2.2 EM算法的过程 158
7.2.3 示例代码的确认 161
7.2.4 基于聚类分析的探索性数据解析 165
7.3 附录：手写文字数据的采集方法 167
第8章 贝叶斯推断：以数据为基础提高置信度的手法 169
8.1 贝叶斯推断模型和贝叶斯定理 170
8.1.1 贝叶斯推断的思路 171
8.1.2 贝叶斯定理入门 172
8.1.3 使用贝叶斯推断确定正态分布：推断参数 178
8.1.4 使用贝叶斯推断确定正态分布：推断观测值分布 185
8.1.5 示例代码的确认 188
8.2 贝叶斯推断回归分析的应用 190
8.2.1 参数后期分布的计算 190
8.2.2 观测值分布的推断 194
8.2.3 示例代码的确认 195
8.3 附录：最优推断法和贝叶斯推断的关系 198
后记 201
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习入门之道
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>小白学数据挖掘与机器学习
第 1 章 数据挖掘那些事儿 \ 1
1.1 当我们在谈数据挖掘时，其实在讨论什么 \ 2
1.2 从 CRISP-DM 开启数据挖掘实践 \ 7
第 2 章 数据挖掘之利器：SPSS Modeler \ 17
2.1 SPSS Modeler 简介 \ 18
2.2 SPSS Modeler 的下载与安装 \ 21
2.3 SPSS Modeler 的主界面及基本操作 \ 23
2.3.1 SPSS Modeler 主界面介绍 \ 23
2.3.2 鼠标基本操作 \ 31
2.4 将 SPSS Modeler 连接到服务器端 \ 31
第 3 章 巧妇难为无米之炊：数据，数据！ \ 34
3.1 数据的身份 \ 35
3.1.1 变量的测量级别 \ 35
3.1.2 变量的角色 \ 36
3.2 数据的读取 \ 37
3.2.1 读取 Excel 文件数据 \ 37
3.2.2 读取变量文件数据 \ 38
3.2.3 读取 SPSS Statistics（.sav）文件数据 \ 40
3.2.4 读取数据库数据 \ 42
3.3 数据的基本设定 \ 45
3.3.1 变量角色的设定 \ 45
3.3.2 字段的筛选及命名 \ 46
3.4 数据的集成 \ 47
3.4.1 数据的变量集成：合并节点 \ 47
3.4.2 数据的记录集成：追加节点 \ 50
第 4 章 一点都不简单的描述性统计分析 \ 53
4.1 分类变量的基本分析： “矩阵”节点 \ 54
4.2 连续变量的基本分析：数据审核节点 \ 57
4.2.1 连续变量基本分析指标介绍 \ 57
4.2.2 “数据审核”节点 \ 63
第 5 章 何为足够大的差异：常用的统计检验 \ 67
5.1 假设检验 \ 68
5.1.1 假设检验的基本原理 \ 68
5.1.2 假设检验的一般步骤 \ 69
5.2 连续变量与分类变量之间的关系： t 检验 \ 70
5.2.1 两组独立样本均值比较 \ 71
5.2.2 两组配对样本均值比较 \ 72
5.2.3 使用 t 检验的前提条件 \ 73
5.2.4 案例：使用均值比较分析电信客户的流失情况 \ 73
5.3 两个连续变量之间的关系：相关分析 \ 75
5.3.1 相关分析理论 \ 76
5.3.2 案例：使用相关分析研究居民消费水平与国内生产总值的相关关系 \ 77
5.4 两个分类变量之间的关系：卡方检验 \ 80
5.4.1 卡方检验的原理 \ 80
5.4.2 卡方检验的前提条件 \ 82
5.4.3 案例：使用卡方检验研究两个分类字段之间的关系 \ 82
第 6 章 从身高和体重的关系谈起：回归分析 \ 84
6.1 一元线性回归分析 \ 85
6.1.1 分析因变量与自变量的关系，构建回归模型 \ 85
6.1.2 估计模型系数，求解回归模型 \ 87
6.1.3 对模型系数进行检验，确认模型有效性 \ 88
6.1.4 拟合优度检验，判断模型解释能力 \ 89
6.1.5 借助回归模型进行预测 \ 90
6.2 多元线性回归分析 \ 90
6.2.1 估计模型系数，求解回归模型 \ 91
6.2.2 对模型参数进行检验，确认模型有效性 \ 92
6.2.3 拟合优度检验，判断模型解释能力 \ 94
6.2.4 模型的变量选择 \ 95
6.3 使用线性回归分析的注意事项 \ 97
6.4 案例：使用回归分析研究影响房屋价格的重要因素 \ 98
第 7 章 回归岂止这么简单：回归模型的进一步扩展 \ 102
7.1 曲线回归 \ 103
7.2 Logistic 回归 \ 110
7.2.1 Logistic 回归理论 \ 110
7.2.2 案例：使用 Logistic 回归模型分析个人收入水平影响因素 \ 112
第 8 章 模型评估那些事儿：过拟合与欠拟合 \ 117
8.1 过拟合与欠拟合 \ 118
8.2 留出法与交叉验证 \ 122
8.2.1 留出法与分层抽样 \ 122
8.2.2 交叉验证 \ 124
第 9 章 从看电影的思考到决策树的生成 \ 126
9.1 决策树概述 \ 127
9.2 决策树生成 \ 129
9.2.1 从 ID3 算法到 C5.0 算法 \ 131
9.2.2 CART 算法 \ 134
9.3 决策树的剪枝 \ 136
9.3.1 预剪枝策略 \ 137
9.3.2 后剪枝策略 \ 137
9.3.3 代价敏感学习 \ 138
9.4 案例：用决策树分析客户违约情况 \ 140
9.5 关于信息熵的扩展 \ 147
第 10 章 人工神经网络：从人脑神经元开始 \ 151
10.1 从人脑神经元到人工神经网络 \ 152
10.2 感知机 \ 154
10.3 人工神经网络 \ 159
10.3.1 隐藏层的作用 \ 159
10.3.2 人工神经网络算法 \ 160
10.4 案例：利用人工神经网络分析某电信运营商的客户流失情况 \ 164
第 11 章 物以类聚，人以群分：聚类分析 \ 172
11.1 聚类思想的概述 \ 173
11.2 聚类方法的关键：距离 \ 175
11.3 K-Means 算法 \ 176
11.3.1 K-Means 算法原理 \ 176
11.3.2 轮廓系数（Silhouette coefficient） \ 177
11.4 案例：利用 K-Means 算法对不同型号汽车的属性进行聚类分群研究 \ 179
第 12 章 啤酒+尿布=关联分析？ \ 186
12.1 一个关于关联分析的传说 \ 187
12.2 关联分析的基本概念 \ 188
12.3 关联规则的有效性指标 \ 190
12.4 Apriori 算法 \ 192
12.4.1 生成频繁项集 \ 193
12.4.2 生成关联规则 \ 195
12.5 案例：利用 Apriori 算法对顾客的个人信息及购买记录进行关联分析 \ 195
第 13 章 三个臭皮匠，赛过诸葛亮：集成学习算法 \ 199
13.1 集成学习算法概述 \ 200
13.2 3 种不同的集成学习算法 \ 201
13.2.1 Bagging 算法 \ 201
13.2.2 Boosting 算法 \ 203
13.2.3 随机森林 \ 204
13.3 集成学习算法实践 \ 205
13.3.1 Bagging 算法和 Boosting 算法 \ 205
13.3.2 随机森林 \ 211
13.3.3 集成学习算法结果比较 \ 214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>小白学数据挖掘与机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark 2.x 大數據分析與機器學習實戰
01 初嘗 Apache Spark V2
02 Apache Spark SQL
03 Catalyst 優化器
04 Project Tungsten
05 Apache Spark Streaming
06 結構化串流處理 (Structured Streaming)
07 Apache Spark MLlib
08 Apache SparkML
09 Apache SystemML
10 使用 DeepLearning4j 和 H2O 在 Apache Spark 上做深度學習
11 Apache Spark GraphX
12 Apache Spark GraphFrames
13 在 IBM DataScience Experience 上透過 Jupyter Notebooks 使用 Apache Spark
14 在 Kubernetes 之上運行 Apache Spark
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark 2.x 大數據分析與機器學習實戰
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习：Go语言实现
译者序
前言
第1章　数据的收集和组织 1
1.1　数据处理-Gopher方式 2
1.2　Go语言收集和组织数据的最佳实践 4
1.3　CSV文件 5
1.3.1　从文件中读取CSV数据 5
1.3.2　处理非预期的域 6
1.3.3　处理非预期的类型 7
1.3.4　用数据帧操作CSV数据 9
1.4　JSON 11
1.4.1　JSON的解析 11
1.4.2　JSON的输出 14
1.5　SQL-like数据库 14
1.5.1　连接到一个SQL数据库 15
1.5.2　查询数据库 15
1.5.3　修改数据库 17
1.6　缓存 17
1.6.1　在内存中缓存数据 17
1.6.2　在本地磁盘中缓存数据 18
1.7　数据版本控制 19
1.7.1　Pachyderm术语 20
1.7.2　部署/安装Pachyderm 20
1.7.3　创建用于数据版本控制的数据仓库 21
1.7.4　把数据存储到数据仓库中 21
1.7.5　从版本化的数据仓库中获取数据 22
1.8　参考书目 22
1.9　小结 23
第2章　矩阵、概率论和统计学 24
2.1　矩阵和向量 24
2.1.1　向量 24
2.1.2　向量操作 25
2.1.3　矩阵 26
2.1.4　矩阵操作 27
2.2　统计学 29
2.2.1　分布 29
2.2.2　统计方法 30
2.2.3　分布可视化 34
2.3　概率论 39
2.3.1　随机变量 40
2.3.2　概率测量 40
2.3.3　独立和条件概率 40
2.3.4　假设检验 41
2.4　参考书目 43
2.5　小结 44
第3章　评估和验证 45
3.1　评估 45
3.1.1　连续指标 46
3.1.2　分类指标 49
3.2　验证 55
3.2.1　训练和测试集 56
3.2.2　保留集 59
3.2.3　交叉验证 60
3.3　参考书目 61
3.4　小结 62
第4章　回归 63
4.1　理解回归模型的术语 63
4.2　线性回归 64
4.2.1　线性回归概述 64
4.2.2　线性回归假设和陷阱 66
4.2.3　线性回归示例 66
4.3　多元线性回归 78
4.4　非线性和其他类型的回归 81
4.5　参考书目 85
4.6　小结 86
第5章　分类 87
5.1　理解分类模型的术语 87
5.2　逻辑回归 88
5.2.1　逻辑回归概述 88
5.2.2　逻辑回归的假设和陷阱 91
5.2.3　逻辑回归示例 92
5.3　k-最近邻 103
5.3.1　kNN概述 103
5.3.2　kNN假设和陷阱 104
5.3.3　kNN示例 105
5.4　决策树和随机森林 106
5.4.1　决策树和随机森林概述 107
5.4.2　决策树和随机森林的假设及陷阱 107
5.4.3　决策树示例 108
5.4.4　随机森林的例子 109
5.5　朴素贝叶斯 109
5.5.1　朴素贝叶斯概念及其重要假设 110
5.5.2　朴素贝叶斯例子 110
5.6　参考书目 111
5.7　小结 112
第6章　集群 113
6.1　理解集群模型术语 113
6.2　距离或相似度的度量 114
6.3　集群技术的评估 115
6.3.1　内部集群评估 115
6.3.2　外部集群评估 120
6.4　k-均值集群 120
6.4.1　k-均值集群综述 120
6.4.2　k-均值的假设和陷阱 122
6.4.3　k-均值集群的例子 123
6.5　其他集群技术 129
6.6　参考书目 130
6.7　小结 130
第7章　时间序列和异常检测 131
7.1　在Go中表示时序数据 131
7.2　理解时间序列的术语 134
7.3　与时间序列有关的统计 135
7.3.1　自相关 135
7.3.2　偏自相关 139
7.4　预测的自回归模型 141
7.4.1　自回归模型概述 141
7.4.2　自回归模型假设和陷阱 142
7.4.3　自回归模型示例 142
7.5　自回归移动平均和其他时间序列模型 151
7.6　异常检测 151
7.7　参考书目 153
7.8　小结 154
第8章　神经网络和深度学习 155
8.1　理解神经网络术语 155
8.2　构建一个简单的神经网络 157
8.2.1　网络中的节点 157
8.2.2　网络架构 158
8.2.3　为什么期望这种架构有作用 159
8.2.4　训练神经网络 160
8.3　使用简单的神经网络 165
8.3.1　在实际数据上训练神经网络 166
8.3.2　评估神经网络 168
8.4　引入深度学习 169
8.4.1　什么是深度学习模型 170
8.4.2　基于Go语言的深度学习 171
8.5　参考书目 177
8.6　小结 178
第9章　部署、分布分析和模型 179
9.1　在远程机器上可靠地运行模型 179
9.1.1　Docker和Docker术语简介 180
9.1.2　Docker化机器学习的应用 181
9.2　构建可拓展和可重现的机器学习流水线 191
9.2.1　搭建Pachyderm和Kubernetes集群 192
9.2.2　构建一个Pachyderm机器学习流水线 193
9.2.3　更新流水线并检查出处 202
9.2.4　缩放流水线阶段 204
9.3　参考书目 206
9.4　小结 206
附录　与机器学习相关的算法/技术 207
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习：Go语言实现
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习
译者序
关于作者
前言
第1章　大规模机器学习和Spark入门 1
1.1　数据科学 2
1.2　数据科学家：21世纪最炫酷的职业 2
1.2.1　数据科学家的一天 3
1.2.2　大数据处理 4
1.2.3　分布式环境下的机器学习算法 4
1.2.4　将数据拆分到多台机器 6
1.2.5　从Hadoop MapReduce到Spark 6
1.2.6　什么是Databricks 7
1.2.7　Spark包含的内容 8
1.3　H2O.ai简介 8
1.4　H2O和Spark MLlib的区别 10
1.5　数据整理 10
1.6　数据科学：一个迭代过程 11
1.7　小结 11
第2章　探索暗物质：希格斯玻色子 12
2.1　Ⅰ型错误与Ⅱ型错误 12
2.1.1　寻找希格斯玻色子 13
2.1.2　LHC和数据的创建 13
2.1.3　希格斯玻色子背后的理论 14
2.1.4　测量希格斯玻色子 14
2.1.5　数据集 14
2.2　启动Spark与加载数据 15
2.2.1　标记点向量 22
2.2.2　创建训练和测试集合 24
2.2.3　第一个模型：决策树 26
2.2.4　下一个模型：集合树 32
2.2.5　最后一个模型：H2O深度学习 37
2.2.6　构建一个3层DNN 39
2.3　小结 45
第3章　多元分类的集成方法 46
3.1　数据 47
3.2　模型目标 48
3.2.1　挑战 48
3.2.2　机器学习工作流程 48
3.2.3　使用随机森林建模 61
3.3　小结 78
第4章　使用NLP和Spark Streaming预测电影评论 80
4.1　NLP简介 81
4.2　数据集 82
4.3　特征提取 85
4.3.1　特征提取方法：词袋模型 85
4.3.2　文本标记 86
4.4　特征化——特征哈希 89
4.5　我们来做一些模型训练吧 92
4.5.1　Spark决策树模型 93
4.5.2　Spark朴素贝叶斯模型 94
4.5.3　Spark随机森林模型 95
4.5.4　Spark GBM模型 96
4.5.5　超级学习器模型 97
4.6　超级学习器 97
4.6.1　集合所有的转换 101
4.6.2　使用超级学习器模型 105
4.7　小结 105
第5章　word2vec预测和聚类 107
5.1　词向量的动机 108
5.2　word2vec解释 108
5.2.1　什么是单词向量 108
5.2.2　CBOW模型 110
5.2.3　skip-gram模型 111
5.2.4　玩转词汇向量 112
5.2.5　余弦相似性 113
5.3　doc2vec解释 113
5.3.1　分布式内存模型 113
5.3.2　分布式词袋模型 114
5.4　应用word2vec并用向量探索数据 116
5.5　创建文档向量 118
5.6　监督学习任务 119
5.7　小结 123
第6章　从点击流数据中抽取模式 125
6.1　频繁模式挖掘 126
6.2　使用Spark MLlib进行模式挖掘 130
6.2.1　使用FP-growth进行频繁模式挖掘 131
6.2.2　关联规则挖掘 136
6.2.3　使用prefix span进行序列模式挖掘 138
6.2.4　在MSNBC点击流数据上进行模式挖掘 141
6.3　部署模式挖掘应用 147
6.4　小结 154
第7章　使用GraphX进行图分析 155
7.1　基本的图理论 156
7.1.1　图 156
7.1.2　有向和无向图 156
7.1.3　阶和度 157
7.1.4　有向无环图 158
7.1.5　连通分量 159
7.1.6　树 160
7.1.7　多重图 160
7.1.8　属性图 161
7.2　GraphX分布式图计算引擎 162
7.2.1　GraphX中图的表示 163
7.2.2　图的特性和操作 165
7.2.3　构建和加载图 170
7.2.4　使用Gephi可视化图结构 172
7.2.5　图计算进阶 178
7.2.6　GraphFrame 181
7.3　图算法及其应用 183
7.3.1　聚类 183
7.3.2　顶点重要性 185
7.4　GraphX在上下文中 188
7.5　小结 189
第8章　Lending Club借贷预测 190
8.1　动机 190
8.1.1　目标 191
8.1.2　数据 192
8.1.3　数据字典 192
8.2　环境准备 193
8.3　数据加载 193
8.4　探索——数据分析 194
8.4.1　基本清理 194
8.4.2　预测目标 200
8.4.3　使用模型评分 221
8.4.4　模型部署 224
8.5　小结 229
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计机器学习导论
目录
译者序
前言
作者简介
第一部分绪论
第1章统计机器学习
1.1学习的类型
1.2机器学习任务举例
1.2.1监督学习
1.2.2非监督学习
1.2.3进一步的主题
1.3本书结构
第二部分概率与统计
第2章随机变量与概率分布
2.1数学基础
2.2概率
2.3随机变量和概率分布
2.4概率分布的性质
2.4.1期望、中位数和众数
2.4.2方差和标准差
2.4.3偏度、峰度和矩
2.5随便变量的变换
第3章离散概率分布的实例
3.1离散均匀分布
3.2二项分布
3.3超几何分布
3.4泊松分布
3.5负二项分布
3.6几何分布
第4章连续概率分布的实例
4.1连续均匀分布
4.2正态分布
4.3伽马分布、指数分布和卡方分布
4.4Beta分布
4.5柯西分布和拉普拉斯分布
4.6t分布和F分布
第5章多维概率分布
5.1联合概率分布
5.2条件概率分布
5.3列联表
5.4贝叶斯定理
5.5协方差与相关性
5.6独立性
第6章多维概率分布的实例
6.1多项分布
6.2多元正态分布
6.3狄利克雷分布
6.4威沙特分布
第7章独立随机变量之和
7.1卷积
7.2再生性
7.3大数定律
7.4中心极限定理
第8章概率不等式
8.1联合界
8.2概率不等式
8.2.1马尔可夫不等式和切尔诺夫不等式
8.2.2坎泰利不等式和切比雪夫不等式
8.3期望不等式
8.3.1琴生不等式
8.3.2赫尔德不等式和施瓦茨不等式
8.3.3闵可夫斯基不等式
8.3.4康托洛维奇不等式
8.4独立随机变量和的不等式
8.4.1切比雪夫不等式和切尔诺夫不等式
8.4.2霍夫丁不等式和伯恩斯坦不等式
8.4.3贝内特不等式
第9章统计估计
9.1统计估计基础
9.2点估计
9.2.1参数密度估计
9.2.2非参数密度估计
9.2.3回归和分类
9.2.4模型选择
9.3区间估计
9.3.1基于正态样本期望的区间估计
9.3.2bootstrap置信区间
9.3.3贝叶斯置信区间
第10章假设检验
10.1假设检验基础
10.2正态样本期望的检验
10.3尼曼皮尔森引理
10.4列联表检验
10.5正态样本期望差值检验
10.5.1无对应关系的两组样本
10.5.2有对应关系的两组样本
10.6秩的无参检验
10.6.1无对应关系的两组样本
10.6.2有对应关系的两组样本
10.7蒙特卡罗检验
第三部分统计模式识别的生成式方法
第11章通过生成模型估计的模式识别
11.1模式识别的公式化
11.2统计模式识别
11.3分类器训练的准则
11.3.1最大后验概率规则
11.3.2最小错误分类率准则
11.3.3贝叶斯决策规则
11.3.4讨论
11.4生成式方法和判别式方法
第12章极大似然估计
12.1定义
12.2高斯模型
12.3类后验概率的计算
12.4Fisher线性判别分析
12.5手写数字识别
12.5.1预备知识
12.5.2线性判别分析的实现
12.5.3多分类器方法
第13章极大似然估计的性质
13.1一致性
13.2渐近无偏性
13.3渐近有效性
13.3.1一维的情况
13.3.2多维的情况
13.4渐近正态性
13.5总结
第14章极大似然估计的模型选择
14.1模型选择
14.2KL散度
14.3AIC信息论准则
14.4交叉检验
14.5讨论
第15章高斯混合模型的极大似然估计
15.1高斯混合模型
15.2极大似然估计
15.3梯度上升算法
15.4EM算法
第16章非参数估计
16.1直方图方法
16.2问题描述
16.3核密度估计
16.3.1Parzen 窗法
16.3.2利用核的平滑
16.3.3带宽的选择
16.4最近邻密度估计
16.4.1最近邻距离
16.4.2最近邻分类器
第17章贝叶斯推理
17.1贝叶斯预测分布
17.1.1定义
17.1.2与极大似然估计的比较
17.1.3计算问题
17.2共轭先验
17.3最大后验估计
17.4贝叶斯模型选择
第18章边缘相似的解析近似
18.1拉普拉斯近似
18.1.1高斯密度估计
18.1.2例证
18.1.3应用于边际似然逼近
18.1.4贝叶斯信息准则
18.2变分近似
18.2.1变分贝叶斯最大期望算法
18.2.2与一般最大期望法的关系
第19章预测分布的数值近似
19.1蒙特卡罗积分
19.2重要性采样
19.3采样算法
19.3.1逆变换采样
19.3.2拒绝采样
19.3.3马尔可夫链蒙特卡罗方法
第20章贝叶斯混合模型
20.1高斯混合模型
20.1.1贝叶斯公式化
20.1.2变分推断
20.1.3吉布斯采样
20.2隐狄利克雷分配模型
20.2.1主题模型
20.2.2贝叶斯公式化
20.2.3吉布斯采样
第四部分统计机器学习的判别式方法
第21章学习模型
21.1线性参数模型
21.2核模型
21.3层次模型
第22章最小二乘回归
22.1最小二乘法
22.2线性参数模型的解决方案
22.3最小二乘法的特性
22.4大规模数据的学习算法
22.5层次模型的学习算法
第23章具有约束的最小二乘回归
23.1子空间约束的最小二乘
23.22约束的最小二乘
23.3模型选择
第24章稀疏回归
24.11约束的最小二乘
24.2解决1约束的最小二乘
24.3稀疏学习的特征选择
24.4若干扩展
24.4.1广义1约束最小二乘
24.4.2p约束最小二乘
24.4.31+2约束最小二乘
24.4.41,2约束最小二乘
24.4.5迹范数约束最小二乘
第25章稳健回归
25.12损失最小化的非稳健性
25.21损失最小化
25.3Huber损失最小化
25.3.1定义
25.3.2随机梯度算法
25.3.3迭代加权最小二乘
25.3.41约束Huber损失最小化
25.4Tukey 损失最小化
第26章最小二乘分类器
26.1基于最小二乘回归的分类器
26.20/1损失和间隔
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计机器学习导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习与量化投资
第1章  Python与机器学习  1
1.1  scikit-learn模块库  2
1.1.1  scikit-learn的缺点  3
1.1.2  scikit-learn算法模块  4
1.1.3  scikit-learn六大功能  5
1.2  开发环境搭建  8
1.2.1  AI领域的标准编程语言：Python  8
1.2.2  zwPython：难度降低90%，性能提高10倍  9
1.2.3 “零对象”编程模式  11
1.2.4  开发平台搭建  12
1.2.5  程序目录结构  12
案例1-1：重点模块版本测试  13
1.3  机器学习：从忘却开始  17
1.4  学习路线图  20
第2章  机器学习编程入门  21
2.1  经典机器学习算法  21
2.2  经典爱丽丝  22
案例2-1：经典爱丽丝  24
案例2-2：爱丽丝进化与文本矢量化  26
2.3  机器学习算法流程  28
2.4  机器学习数据集  28
案例2-3：爱丽丝分解  29
2.5  数据切割函数  33
2.6  线性回归算法  34
案例2-4：爱丽丝回归  35
第3章  金融数据的预处理  40
3.1  至简归一法  40
案例3-1：麻烦的外汇数据  41
案例3-2：尴尬的日元  45
案例3-3：凶残的比特币  49
3.2  股票池与Rebase  51
3.2.1  股票池  51
3.2.2  Rebase与归一化  52
案例3-4：股票池Rebase归一化  53
3.3  金融数据切割  57
案例3-5：当上证遇到机器学习  58
3.4  preprocessing模块  63
案例3-6：比特币与标准化  65
案例3-7：比特币与归一化  69
第4章  机器学习快速入门  72
4.1  回归算法  72
4.2  LR线性回归模型  73
案例4-1：上证指数之LR回归事件  76
4.3  常用评测指标  81
4.4  多项式回归  83
案例4-2：上证指数的多项式故事  83
案例4-3：预测比特币价格  86
4.5  逻辑回归算法模型  87
案例4-4：上证指数预测逻辑回归版  88
第5章  模型验证优化  96
5.1  交叉验证评估器  96
案例5-1：交叉验证  98
5.2  交叉验证评分  101
案例5-2：交叉验证评分  101
第6章  决策树  103
6.1  决策树算法  103
6.1.1  ID3算法与C4.5算法  105
6.1.2  常用决策树算法  106
6.1.3  sklearn内置决策树算法  107
6.2  决策树回归函数  109
案例6-1：决策树回归算法  110
6.3  决策树分类函数  115
案例6-2：决策树分类算法  116
6.4  GBDT算法  121
6.5  迭代决策树函数  122
案例6-3：GBDT回归算法  123
案例6-4：GBDT分类算法  128
第7章  随机森林算法和极端随机树算法  133
7.1  随机森林函数  135
7.2  决策树测试框架  137
案例7-1：RF回归算法大测试  138
7.3  决策树测试函数  140
案例7-2：上证的RF回归频道  142
案例7-3：当比特币碰到RF回归算法  146
案例7-4：上证和RF分类算法  147
7.4  极端随机树算法  150
7.5  极端随机树函数  151
案例7-5：极端随机树回归算法  152
案例7-6：上证指数案例应用  154
案例7-7：ET、比特币，谁更极端  155
第8章  机器学习算法模式  159
8.1  学习模式  161
8.2  机器学习五大流派  164
8.3  经典机器学习算法  165
8.4  小结  166
第9章  概率编程  167
9.1  朴素贝叶斯的上证之旅  168
案例9-1：上证朴素贝叶斯算法  170
9.2  隐马尔可夫模型  175
案例9-2：HMM模型与模型保存  176
案例9-3：HMM算法与模型读取  180
第10章  实例算法  185
K最近邻算法  186
案例10-1：第一次惊喜——KNN算法  187
案例10-2：KNN分类  190
第11章  正则化算法  192
11.1  岭回归算法  193
案例11-1：新高度——岭回归算法  195
11.2  套索回归算法  197
案例11-2：套索回归算法应用  199
11.3  弹性网络算法  201
案例11-3：弹性网络算法应用  202
11.4  最小角回归算法  204
案例11-4：LARS算法应用  204
第12章  聚类分析  206
12.1  K均值算法  207
案例12-1：K均值算法应用  208
12.2  BIRCH算法  210
案例12-2：BIRCH算法应用  211
12.3  小结  213
第13章  降维算法  215
13.1  主成分分析  216
案例13-1：主成分分析的应用  218
案例13-2：PCA算法的上证戏法  223
13.2  奇异值分解算法  227
案例13-3：奇异果传说：SVD  228
第14章  集成算法  229
14.1  sklearn内置集成算法  231
14.2  装袋算法  232
案例14-1：装袋回归算法  232
案例14-2：装袋分类算法  234
14.3  AdaBoost迭代算法  236
案例14-3：AdaBoost迭代回归算法  237
案例14-4：AdaBoost迭代分类算法  239
第15章  支持向量机  242
15.1  支持向量机算法  242
15.2  SVM函数接口  244
案例15-1：SVM回归算法  245
案例15-2：SVM分类算法  247
第16章  人工神经网络算法  250
多层感知器  252
案例16-1：多层感知器回归算法  253
案例16-2：多层感知器分类算法  256
附录A  sklearn常用模块和函数  259
附录B  量化分析常用指标  284
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习与量化投资
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习（第2版）
第1章　Spark的环境搭建与运行　　1
1.1　Spark的本地安装与配置　　2
1.2　Spark集群　　3
1.3　Spark编程模型　　4
1.3.1　SparkContext类与SparkConf类　　4
1.3.2　SparkSession　　5
1.3.3　Spark shell　　6
1.3.4　弹性分布式数据集　　8
1.3.5　广播变量和累加器　　12
1.4　SchemaRDD　　13
1.5　Spark data frame　　13
1.6　Spark Scala编程入门　　14
1.7　Spark Java编程入门　　17
1.8　Spark Python编程入门　　19
1.9　Spark R编程入门　　21
1.10　在Amazon EC2上运行Spark　　23
1.11　在Amazon Elastic Map Reduce上配置并运行Spark　　28
1.12　Spark用户界面　　31
1.13　Spark所支持的机器学习算法　　32
1.14　Spark ML的优势　　36
1.15　在Google Compute Engine上用Dataproc构建Spark集群　　38
1.15.1　Hadoop和Spark版本　　38
1.15.2　创建集群　　38
1.15.3　提交任务　　41
1.16　小结　　43
第2章　机器学习的数学基础　　44
2.1　线性代数　　45
2.1.1　配置IntelliJ Scala环境　　45
2.1.2　配置命令行Scala环境　　47
2.1.3　域　　48
2.1.4　矩阵　　54
2.1.5　函数　　64
2.2　梯度下降　　68
2.3　先验概率、似然和后验概率　　69
2.4　微积分　　69
2.4.1　可微微分　　69
2.4.2　积分　　70
2.4.3　拉格朗日乘子　　70
2.5　可视化　　71
2.6　小结　　72
第3章　机器学习系统设计　　73
3.1　机器学习是什么　　73
3.2　MovieStream介绍　　74
3.3　机器学习系统商业用例　　75
3.3.1　个性化　　75
3.3.2　目标营销和客户细分　　76
3.3.3　预测建模与分析　　76
3.4　机器学习模型的种类　　76
3.5　数据驱动的机器学习系统的组成　　77
3.5.1　数据获取与存储　　77
3.5.2　数据清理与转换　　78
3.5.3　模型训练与测试循环　　79
3.5.4　模型部署与整合　　79
3.5.5　模型监控与反馈　　80
3.5.6　批处理或实时方案的选择　　80
3.5.7　Spark数据管道　　81
3.6　机器学习系统架构　　82
3.7　Spark MLlib　　83
3.8　Spark ML的性能提升　　83
3.9　MLlib支持算法的比较　　85
3.9.1　分类　　85
3.9.2　聚类　　85
3.9.3　回归　　85
3.10　MLlib支持的函数和开发者API　　86
3.11　MLlib愿景　　87
3.12　MLlib版本的变迁　　87
3.13　小结　　88
第4章　Spark上数据的获取、处理与准备　　89
4.1　获取公开数据集　　90
4.2　探索与可视化数据　　92
4.2.1　探索用户数据　　94
4.2.2　探索电影数据　　102
4.2.3　探索评级数据　　104
4.3　数据的处理与转换　　109
4.4　从数据中提取有用特征　　112
4.4.1　数值特征　　112
4.4.2　类别特征　　113
4.4.3　派生特征　　114
4.4.4　文本特征　　116
4.4.5　正则化特征　　121
4.4.6　用软件包提取特征　　123
4.5　小结　　126
第5章　Spark构建推荐引擎　　127
5.1　推荐模型的分类　　128
5.1.1　基于内容的过滤　　128
5.1.2　协同过滤　　128
5.1.3　矩阵分解　　130
5.2　提取有效特征　　139
5.3　训练推荐模型　　140
5.3.1　使用MovieLens 100k数据集训练模型　　141
5.3.2　使用隐式反馈数据训练模型　　143
5.4　使用推荐模型　　143
5.4.1　ALS模型推荐　　144
5.4.2　用户推荐　　145
5.4.3　物品推荐　　148
5.5　推荐模型效果的评估　　152
5.5.1　ALS模型评估　　152
5.5.2　均方差　　154
5.5.3　K值平均准确率　　156
5.5.4　使用MLlib内置的评估函数　　159
5.6　 FP-Growth 算法　　161
5.6.1　FP-Growth的基本例子　　161
5.6.2　FP-Growth在MovieLens数据集上的实践　　163
5.7　小结　　164
第6章　Spark构建分类模型　　165
6.1　分类模型的种类　　167
6.1.1　线性模型　　167
6.1.2　朴素贝叶斯模型　　177
6.1.3　决策树　　180
6.1.4　树集成模型　　183
6.2　从数据中抽取合适的特征　　188
6.3　训练分类模型　　189
6.4　使用分类模型　　190
6.4.1　在Kaggle/StumbleUpon evergreen数据集上进行预测　　191
6.4.2　评估分类模型的性能　　191
6.4.3　预测的正确率和错误率　　191
6.4.4　准确率和召回率　　193
6.4.5　ROC曲线和AUC　　194
6.5　改进模型性能以及参数调优　　196
6.5.1　特征标准化　　197
6.5.2　其他特征　　199
6.5.3　使用正确的数据格式　　202
6.5.4　模型参数调优　　203
6.6　小结　　211
第7章　Spark构建回归模型　　212
7.1　回归模型的种类　　212
7.1.1　最小二乘回归　　213
7.1.2　决策树回归　　214
7.2　评估回归模型的性能　　215
7.2.1　均方误差和均方根误差　　215
7.2.2　平均绝对误差　　215
7.2.3　均方根对数误差　　216
7.2.4　R-平方系数　　216
7.3　从数据中抽取合适的特征　　216
7.4　回归模型的训练和应用　　220
7.4.1　BikeSharingExecutor　　220
7.4.2　在bike sharing数据集上训练回归模型　　221
7.4.3　决策树集成　　229
7.5　改进模型性能和参数调优　　235
7.5.1　变换目标变量　　235
7.5.2　模型参数调优　　242
7.6　小结　　256
第8章　Spark构建聚类模型　　257
8.1　聚类模型的类型　　258
8.1.1　K-均值聚类　　258
8.1.2　混合模型　　262
8.1.3　层次聚类　　262
8.2　从数据中提取正确的特征　　262
8.3　K-均值训练聚类模型　　265
8.3.1　训练K-均值聚类模型　　266
8.3.2　用聚类模型来预测　　267
8.3.3　解读预测结果　　267
8.4　评估聚类模型的性能　　271
8.4.1　内部评估指标　　271
8.4.2　外部评估指标　　272
8.4.3　在MovieLens数据集上计算性能指标　　272
8.4.4　迭代次数对WSSSE的影响　　272
8.5　二分K-均值　　275
8.5.1　二分K-均值——训练一个聚类模型　　276
8.5.2　WSSSE和迭代次数　　280
8.6　高斯混合模型　　283
8.6.1　GMM聚类分析　　283
8.6.2　可视化GMM类簇分布　　285
8.6.3　迭代次数对类簇边界的影响　　286
8.7　小结　　287
第9章　Spark应用于数据降维　　288
9.1　降维方法的种类　　289
9.1.1　主成分分析　　289
9.1.2　奇异值分解　　289
9.1.3　和矩阵分解的关系　　290
9.1.4　聚类作为降维的方法　　290
9.2　从数据中抽取合适的特征　　291
9.3　训练降维模型　　299
9.4　使用降维模型　　302
9.4.1　在LFW数据集上使用PCA投影数据　　302
9.4.2　PCA和SVD模型的关系　　303
9.5　评价降维模型　　304
9.6　小结　　307
第10章　Spark高级文本处理技术　　308
10.1　文本数据处理的特别之处　　308
10.2　从数据中抽取合适的特征　　309
10.2.1　词加权表示　　309
10.2.2　特征散列　　310
10.2.3　从20 Newsgroups数据集中提取TF-IDF特征　　311
10.3　使用TF-IDF模型　　324
10.3.1　20 Newsgroups数据集的文本相似度和TF-IDF特征　　324
10.3.2　基于20 Newsgroups数据集使用TF-IDF训练文本分类器　　326
10.4　评估文本处理技术的作用　　328
10.5　Spark 2.0上的文本分类　　329
10.6　Word2Vec模型　　331
10.6.1　借助Spark MLlib训练Word2Vec模型　　331
10.6.2　借助Spark ML训练Word2Vec模型　　332
10.7　小结　　334
第11章　Spark Streaming实时机器学习　　335
11.1　在线学习　　335
11.2　流处理　　336
11.2.1　Spark Streaming介绍　　337
11.2.2　Spark Streaming缓存和容错机制　　339
11.3　创建Spark Streaming应用　　340
11.3.1　消息生成器　　341
11.3.2　创建简单的流处理程序　　343
11.3.3　流式分析　　346
11.3.4　有状态的流计算　　348
11.4　使用Spark Streaming进行在线学习　　349
11.4.1　流回归　　350
11.4.2　一个简单的流回归程序　　350
11.4.3　流式K-均值　　354
11.5　在线模型评估　　355
11.6　结构化流　　358
11.7　小结　　359
第12章　Spark ML Pipeline API　　360
12.1　Pipeline简介　　360
12.1.1　DataFrame　　360
12.1.2　Pipeline组件　　360
12.1.3　转换器　　361
12.1.4　评估器　　361
12.2　Pipeline工作原理　　363
12.3　Pipeline机器学习示例　　367
12.4　小结　　375

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark机器学习（第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习算法
目　录
Machine Learning Algorithms
译者序
前言
作者简介
审校人员简介
第1章　机器学习简介1
1.1　经典机器和自适应机器简介1
1.2　机器学习的分类2
1.2.1　监督学习3
1.2.2　无监督学习5
1.2.3　强化学习7
1.3　超越机器学习——深度学习和仿生自适应系统8
1.4　机器学习和大数据9
延伸阅读10
本章小结10
第2章　机器学习的重要元素11
2.1　数据格式11
2.2　可学习性13
2.2.1　欠拟合和过拟合15
2.2.2　误差度量16
2.2.3　PAC学习18
2.3　统计学习方法19
2.3.1　最大后验概率学习20
2.3.2　最大似然学习20
2.4　信息论的要素24
参考文献26
本章小结26
第3章　特征选择与特征工程28
3.1　scikit-learn练习数据集28
3.2　创建训练集和测试集29
3.3　管理分类数据30
3.4　管理缺失特征33
3.5　数据缩放和归一化33
3.6　特征选择和过滤35
3.7　主成分分析37
3.7.1　非负矩阵分解42
3.7.2　稀疏PCA42
3.7.3　核PCA43
3.8　原子提取和字典学习45
参考文献47
本章小结47
第4章　线性回归48
4.1　线性模型48
4.2　一个二维的例子48
4.3　基于scikit-learn的线性回归和更高维50
4.4　Ridge、Lasso和ElasticNet53
4.5　随机采样一致的鲁棒回归57
4.6　多项式回归58
4.7　保序回归60
参考文献62
本章小结62
第5章　逻辑回归64
5.1　线性分类64
5.2　逻辑回归65
5.3　实现和优化67
5.4　随机梯度下降算法69
5.5　通过网格搜索找到最优超参数71
5.6　评估分类的指标73
5.7　ROC曲线77
本章小结79
第6章　朴素贝叶斯81
6.1　贝叶斯定理81
6.2　朴素贝叶斯分类器82
6.3　scikit-learn中的朴素贝叶斯83
6.3.1　伯努利朴素贝叶斯83
6.3.2　多项式朴素贝叶斯85
6.3.3　高斯朴素贝叶斯86
参考文献89
本章小结89
第7章　支持向量机90
7.1　线性支持向量机90
7.2　scikit-learn实现93
7.2.1　线性分类94
7.2.2　基于内核的分类95
7.2.3　非线性例子97
7.3　受控支持向量机101
7.4　支持向量回归103
参考文献104
本章小结104
第8章　决策树和集成学习105
8.1　二元决策树105
8.1.1　二元决策106
8.1.2　不纯度的衡量107
8.1.3　特征重要度109
8.2　基于scikit-learn的决策树分类109
8.3　集成学习113
8.3.1　随机森林114
8.3.2　AdaBoost116
8.3.3　梯度树提升118
8.3.4　投票分类器120
参考文献122
本章小结122
第9章　聚类基础124
9.1　聚类简介124
9.1.1　k均值聚类125
9.1.2　DBSCAN136
9.1.3　光谱聚类138
9.2　基于实证的评价方法139
9.2.1　同质性140
9.2.2　完整性140
9.2.3　修正兰德指数141
参考文献142
本章小结142
第10章　层次聚类143
10.1　分层策略143
10.2　凝聚聚类143
10.2.1　树形图145
10.2.2　scikit-learn中的凝聚聚类147
10.2.3　连接限制149
参考文献151
本章小结152
第11章　推荐系统简介153
11.1　朴素的基于用户的系统153
11.2　基于内容的系统156
11.3　无模式（或基于内存的）协同过滤158
11.4　基于模型的协同过滤160
11.4.1　奇异值分解策略161
11.4.2　交替最小二乘法策略163
11.4.3　用Apache Spark MLlib实现交替最小二乘法策略164
参考文献167
本章小结167
第12章　自然语言处理简介169
12.1　NLTK和内置语料库169
12.2　词袋策略171
12.2.1　标记172
12.2.2　停止词的删除174
12.2.3　词干提取175
12.2.4　向量化176
12.3　基于路透社语料库的文本分类器例子180
参考文献182
本章小结182
第13章　自然语言处理中的主题建模与情感分析183
13.1　主题建模183
13.1.1　潜在语义分析183
13.1.2　概率潜在语义分析188
13.1.3　潜在狄利克雷分配193
13.2　情感分析198
参考文献202
本章小结202
第14章　深度学习和TensorFlow简介203
14.1　深度学习简介203
14.1.1　人工神经网络203
14.1.2　深层结构206
14.2　TensorFlow简介208
14.2.1　计算梯度210
14.2.2　逻辑回归212
14.2.3　用多层感知器进行分类215
14.2.4　图像卷积218
14.3　Keras内部速览220
参考文献225
本章小结225
第15章　构建机器学习框架226
15.1　机器学习框架226
15.1.1　数据收集227
15.1.2　归一化227
15.1.3　降维227
15.1.4　数据扩充228
15.1.5　数据转换228
15.1.6　建模、网格搜索和交叉验证229
15.1.7　可视化229
15.2　用于机器学习框架的scikit-learn工具229
15.2.1　管道229
15.2.2　特征联合232
参考文献233
本章小结233
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入浅出Python机器学习
目 录
第1章 概 述
1.1 什么是机器学习——从一个小故事开始 / 002
1.2 机器学习的一些应用场景——蝙蝠公司的业务单元 / 003
1.3 机器学习应该如何入门——世上无难事 / 005
1.4 有监督学习与无监督学习 / 007
1.5 机器学习中的分类与回归 / 008
1.6 模型的泛化、过拟合与欠拟合 / 008
1.7 小结 / 009
第2章 基于Python语言的环境配置
2.1 Python的下载和安装 / 012
2.2 Jupyter Notebook的安装与使用方法 / 013
2.2.1 使用pip进行Jupyter Notebook的下载和安装 / 013
2.2.2 运行Jupyter Notebook / 014
2.2.3 Jupyter Notebook的使用方法 / 015
2.3 一些必需库的安装及功能简介 / 017
2.3.1 Numpy——基础科学计算库 / 017
2.3.2 Scipy——强大的科学计算工具集 / 018
2.3.3 pandas——数据分析的利器 / 019
2.3.4 matplotlib——画出优美的图形 / 020
深入浅出Python 机器学习
VIII
2.4 scikit-learn——非常流行的Python机器学习库 / 021
2.5 小结 / 022
第3章 K最近邻算法——近朱者赤，近墨者黑
3.1 K最近邻算法的原理 / 024
3.2 K最近邻算法的用法 / 025
3.2.1 K最近邻算法在分类任务中的应用 / 025
3.2.2 K最近邻算法处理多元分类任务 / 029
3.2.3 K最近邻算法用于回归分析 / 031
3.3 K最近邻算法项目实战——酒的分类 / 034
3.3.1 对数据集进行分析 / 034
3.3.2 生成训练数据集和测试数据集 / 036
3.3.3 使用K最近邻算法进行建模 / 038
3.3.4 使用模型对新样本的分类进行预测 / 039
3.4 小结 / 041
第4章 广义线性模型——“耿直”的算法模型
4.1 线性模型的基本概念 / 044
4.1.1 线性模型的一般公式 / 044
4.1.2 线性模型的图形表示 / 045
4.1.3 线性模型的特点 / 049
4.2 最基本的线性模型——线性回归 / 050
4.2.1 线性回归的基本原理 / 050
4.2.2 线性回归的性能表现 / 051
4.3 使用L2正则化的线性模型——岭回归 / 053
4.3.1 岭回归的原理 / 053
4.3.2 岭回归的参数调节 / 054
4.4 使用L1正则化的线性模型——套索回归 / 058
4.4.1 套索回归的原理 / 058
4.4.2 套索回归的参数调节 / 059
4.4.3 套索回归与岭回归的对比 / 060
目
录
IX
4.5 小结 / 062
第5章 朴素贝叶斯——打雷啦，收衣服啊
5.1 朴素贝叶斯基本概念 / 064
5.1.1 贝叶斯定理 / 064
5.1.2 朴素贝叶斯的简单应用 / 064
5.2 朴素贝叶斯算法的不同方法 / 068
5.2.1 贝努利朴素贝叶斯 / 068
5.2.2 高斯朴素贝叶斯 / 071
5.2.3 多项式朴素贝叶斯 / 072
5.3 朴素贝叶斯实战——判断肿瘤是良性还是恶性 / 075
5.3.1 对数据集进行分析 / 076
5.3.2 使用高斯朴素贝叶斯进行建模 / 077
5.3.3 高斯朴素贝叶斯的学习曲线 / 078
5.4 小结 / 080
第6章 决策树与随机森林——会玩读心术的算法
6.1 决策树 / 082
6.1.1 决策树基本原理 / 082
6.1.2 决策树的构建 / 082
6.1.3 决策树的优势和不足 / 088
6.2 随机森林 / 088
6.2.1 随机森林的基本概念 / 089
6.2.2 随机森林的构建 / 089
6.2.3 随机森林的优势和不足 / 092
6.3 随机森林实例——要不要和相亲对象进一步发展 / 093
6.3.1 数据集的准备 / 093
6.3.2 用get_dummies处理数据 / 094
6.3.3 用决策树建模并做出预测 / 096
6.4 小结 / 098
第7章 支持向量机SVM——专治线性不可分
7.1 支持向量机SVM基本概念 / 100
7.1.1 支持向量机SVM的原理 / 100
7.1.2 支持向量机SVM的核函数 / 102
7.2 SVM的核函数与参数选择 / 104
7.2.1 不同核函数的SVM对比 / 104
7.2.2 支持向量机的gamma参数调节 / 106
7.2.3 SVM算法的优势与不足 / 108
7.3 SVM实例——波士顿房价回归分析 / 108
7.3.1 初步了解数据集 / 109
7.3.2 使用SVR进行建模 / 110
7.4 小结 / 114
第8章 神经网络——曾入“冷宫”，如今得宠
8.1 神经网络的前世今生 / 116
8.1.1 神经网络的起源 / 116
8.1.2 第一个感知器学习法则 / 116
8.1.3 神经网络之父——杰弗瑞·欣顿 / 117
8.2 神经网络的原理及使用 / 118
8.2.1 神经网络的原理 / 118
8.2.2 神经网络中的非线性矫正 / 119
8.2.3 神经网络的参数设置 / 121
8.3 神经网络实例——手写识别 / 127
8.3.1 使用MNIST数据集 / 128
8.3.2 训练MLP神经网络 / 129
8.3.3 使用模型进行数字识别 / 130
8.4 小结 / 131
第9章 数据预处理、降维、特征提取及聚类——快
刀斩乱麻
9.1 数据预处理 / 134
9.1.1 使用StandardScaler进行数据预处理 / 134
9.1.2 使用MinMaxScaler进行数据预处理 / 135
9.1.3 使用RobustScaler进行数据预处理 / 136
9.1.4 使用Normalizer进行数据预处理 / 137
9.1.5 通过数据预处理提高模型准确率 / 138
9.2 数据降维 / 140
9.2.1 PCA主成分分析原理 / 140
9.2.2 对数据降维以便于进行可视化 / 142
9.2.3 原始特征与PCA主成分之间的关系 / 143
9.3 特征提取 / 144
9.3.1 PCA主成分分析法用于特征提取 / 145
9.3.2 非负矩阵分解用于特征提取 / 148
9.4 聚类算法 / 149
9.4.1 K均值聚类算法 / 150
9.4.2 凝聚聚类算法 / 153
9.4.3 DBSCAN算法 / 154
9.5 小结 / 157
第10章 数据表达与特征工程——锦上再添花
10.1 数据表达 / 160
10.1.1 使用哑变量转化类型特征 / 160
10.1.2 对数据进行装箱处理 / 162
10.2 数据“升维” / 166
10.2.1 向数据集添加交互式特征 / 166
10.2.2 向数据集添加多项式特征 / 170
10.3 自动特征选择 / 173
10.3.1 使用单一变量法进行特征选择 / 173
10.3.2 基于模型的特征选择 / 178
10.3.3 迭代式特征选择 / 180
10.4 小结 / 182
第11章 模型评估与优化——只有更好，没有最好
11.1 使用交叉验证进行模型评估 / 184
11.1.1 scikit-learn中的交叉验证法 / 184
11.1.2 随机拆分和“挨个儿试试” / 186
11.1.3 为什么要使用交叉验证法 / 188
11.2 使用网格搜索优化模型参数 / 188
11.2.1 简单网格搜索 / 189
11.2.2 与交叉验证结合的网格搜索 / 191
11.3 分类模型的可信度评估 / 193
11.3.1 分类模型中的预测准确率 / 194
11.3.2 分类模型中的决定系数 / 197
11.4 小结 / 198
第12章 建立算法的管道模型——团结就是力量
12.1 管道模型的概念及用法 / 202
12.1.1 管道模型的基本概念 / 202
12.1.2 使用管道模型进行网格搜索 / 206
12.2 使用管道模型对股票涨幅进行回归分析 / 209
12.2.1 数据集准备 / 209
12.2.2 建立包含预处理和MLP模型的管道模型 / 213
12.2.3 向管道模型添加特征选择步骤 / 214
12.3 使用管道模型进行模型选择和参数调优 / 216
12.3.1 使用管道模型进行模型选择 / 216
12.3.2 使用管道模型寻找更优参数 / 217
12.4 小结 / 220
第13章 文本数据处理——亲，见字如“数”
13.1 文本数据的特征提取、中文分词及词袋模型 / 222
13.1.1 使用CountVectorizer对文本进行特征提取 / 222
13.1.2 使用分词工具对中文文本进行分词 / 223
13.1.3 使用词袋模型将文本数据转为数组 / 224
13.2 对文本数据进一步进行优化处理 / 226
13.2.1 使用n-Gram改善词袋模型 / 226
13.2.2 使用tf-idf模型对文本数据进行处理 / 228
13.2.3 删除文本中的停用词 / 234
13.3 小结 / 236
第14章 从数据获取到话题提取——从“研究员”
到“段子手”
14.1 简单页面的爬取 / 238
14.1.1 准备Requests库和User Agent / 238
14.1.2 确定一个目标网站并分析其结构 / 240
14.1.3 进行爬取并保存为本地文件 / 241
14.2 稍微复杂一点的爬取 / 244
14.2.1 确定目标页面并进行分析 / 245
14.2.2 Python中的正则表达式 / 247
14.2.3 使用BeautifulSoup进行HTML解析 / 251
14.2.4 对目标页面进行爬取并保存到本地 / 256
14.3 对文本数据进行话题提取 / 258
14.3.1 寻找目标网站并分析结构 / 259
14.3.2 编写爬虫进行内容爬取 / 261
14.3.3 使用潜在狄利克雷分布进行话题提取 / 263
14.4 小结 / 265
第15章 人才需求现状与未来学习方向——你是不
是下一个“大牛”
15.1 人才需求现状 / 268
15.1.1 全球AI从业者达190万，人才需求3年翻8倍 / 268
15.1.2 AI人才需求集中于一线城市，七成从业者月薪过万 / 269
15.1.3 人才困境仍难缓解，政策支援亟不可待 / 269
15.2 未来学习方向 / 270
15.2.1 用于大数据分析的计算引擎 / 270
15.2.2 深度学习开源框架 / 271
15.2.3 使用概率模型进行推理 / 272
15.3 技能磨炼与实际应用 / 272
15.3.1 Kaggle算法大赛平台和OpenML平台 / 272
15.3.2 在工业级场景中的应用 / 273
15.3.3 对算法模型进行A/B测试 / 273
15.4 小结 / 274
参考文献 / 275
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深入浅出Python机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习vs复杂系统
第一部分 复杂性
1 复杂系统     .. 2
2 用复杂网络看世界经济（阅读难度）. 7
3 风险管理策略之复杂科学视角    11
4 从物理角度看复杂   24
第二部分 机器学习
5 白话机器学习（阅读难度）  46
6 浅谈贝叶斯分析    53
7 简单贝叶斯分类器（阅读难度）   . 57
8 决策树方法（阅读难度）    . 60
9 感知机：神经网络的基础（阅读难度）  64
10 降维：应对复杂的通用武器（阅读难度）  .. 67
第三部分 神经网络
11 神经网络不神秘    . 74
12 CNN 的几个关键词（阅读难度）   80
13 时间序列与RNN    .. 91
14 会遗忘的神经网络（阅读难度）   . 96
15 跟着AlphaGo 理解深度强化学习框架（阅读难度）  100
16 从阿尔法元看强化学习的更广阔潜力   .. 107
第四部分 宇宙间最复杂的就是我们的大脑
17 深层视觉信息的编码机制（阅读难度）   . 114
18 大脑的自由能假说——兼论认知科学与机器学习（阅读难度） 121
19 大脑中的支持向量机（阅读难度）   . 126
20 机器学习是如何巧妙理解我们大脑的工作原理的
（阅读难度）    . 133
21 大脑经济学（阅读难度）    140
22 人工智能vs 人类智能（阅读难度）   149
第五部分 人工智能应用谈
23 人工智能会取代艺术家的工作吗   . 156
24 机器学习预测心理疾病    .. 159
25 人机协作决策的两种方式    . 164
26 小数据机器学习    .. 166
27 用深度学习玩图像的七重关卡   .. 170
28 深度学习助力基因科技    .. 174
29 机器学习对战复杂系统    .. 176
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习vs复杂系统
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>利用机器学习开发算法交易系统
第一部分
第1章　机器学习　　1
1.1　机器 习定义　　1
1.2　机器学习的优缺点　　3
1.2.1　机器学习的优点　　3
1.2.2　机器学习的缺点　　4
1.3　机器学习的种类　　4
1.3.1　监督学习　　5
1.3.2　无监督学习　　6
1.4　机器学习能做的事情　　7
1.4.1　回归　　8
1.4.2　分类　　10
1.4.3　聚类　　12
1.5　机器学习算法　　13
1.5.1　回归　　14
1.5.2　分类　　15
1.5.3　聚类　　15
1.6　机器学习的过程　　16
1.6.1　第一次预处理　　16
1.6.2　训练数据集　　17
1.6.3　第二次预处理　　17
1.6.4　机器学习算法学习　　17
1.6.5　参数优化　　17
1.6.6　后期处理　　17
1.6.7　最终模型　　18
1.7　“没有免费的午餐”定理　　18
第二部分
第2章　统计　　21
2.1　统计的定义　　21
2.2　统计在机器学习中的重要性　　22
2.3　统计的基本概念和术语　　23
2.3.1　总体和样本　　23
2.3.2　参数和统计量　　24
2.3.3　抽样误差　　25
2.3.4　因变量和自变量　　26
2.3.5　连续变量和离散变量　　26
2.3.6　模型　　27
2.4　准备事项　　28
2.5　数据下载　　29
2.6　数据加载　　31
2.7　基础统计　　31
2.7.1　标准差　　32
2.7.2　四分位数　　36
2.7.3　直方图　　37
2.7.4　正态分布　　40
2.7.5　散点图　　41
2.7.6　箱形图　　44
第3章　时间序列数据　　49
3.1　时间序列数据　　50
3.2　时间序列数据分析　　51
3.3　时间序列数据的主要特征　　52
3.4　随机过程　　54
3.5　平稳时间序列数据　　55
3.6　随机过程中的期望值、方差和协方差　　57
3.7　相关　　59
3.8　自协方差　　61
3.9　自相关　　62
3.10　随机游走　　66
第三部分
第4章　算法交易　　69
4.1　算法交易简介　　69
4.2　算法交易历史上的那些人　　72
4.2.1　爱德华·索普　　72
4.2.2　詹姆斯·哈里斯·西蒙斯　　74
4.2.3　肯尼斯·格里芬　　76
4.3　算法交易模型　　77
4.4　均值回归模型　　79
4.4.1　均值回归检验　　80
4.4.2　实现均值回归模型　　86
4.5　机器学习模型　　89
4.5.1　特征选择　　90
4.5.2　是价格还是方向　　91
4.6　分类模型　　92
4.6.1　逻辑斯蒂回归　　92
4.6.2　决策树和随机森林　　94
4.6.3　支持向量机　　96
4.7　实现机器学习模型　　97
4.7.1　数据集　　98
4.7.2　拆分数据集　　100
4.7.3　生成股价走势预测变量　　101
4.7.4　股价走势预测变量的运行和评价　　102
4.8　时间衰减效应　　106
第5章　实现算法交易系统　　109
5.1　普通算法交易系统的构成　　109
5.2　实现系统的概要　　111
5.3　开发环境　　113
5.4　数据爬虫实现　　113
5.4.1　收集股票代码　　114
5.4.2　收集股价数据　　118
5.5　实现α 模型　　121
5.5.1　均值回归模型　　122
5.5.2　机器学习模型　　124
5.6　投资组合生成器　　125
5.6.1　均值回归模型的股票选择　　126
5.6.2　机器学习模型的股票选择　　130
5.7　实现Trader 类　　136
第6章　性能评价与优化　　137
6.1　算法交易系统的性能测试　　138
6.1.1　评价系统的获利能力　　138
6.1.2　比较各实现模型　　138
6.1.3　对系统的信心　　139
6.2　回溯检验　　140
6.2.1　Profit/Loss 检验　　140
6.2.2　Hit Batio　　141
6.2.3　Drawdown　　143
6.2.4　Sharpe Ratio　　145
6.3　机器学习性能测试　　147
6.3.1　混淆矩阵　　148
6.3.2　Classification Report　　150
6.3.3　ROC　　152
6.4　实时交易监控　　158
6.5　参数优化　　159
6.6　超参数优化　　160
6.6.1　网格搜索　　161
6.6.2　随机搜索　　164
6.7　“黑天鹅”　　167
后记　　171
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>利用机器学习开发算法交易系统
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习（原书第2版)
译者序
关于作者
关于审校人员
前言
第1章　赋予计算机从数据中学习的能力 1
1.1　构建把数据转换为知识的智能机器 1
1.2　三种不同类型的机器学习 1
1.2.1　用有监督学习预测未来 2
1.2.2　用强化学习解决交互问题 3
1.2.3　用无监督学习发现隐藏结构 4
1.3　基本术语与符号 4
1.4　构建机器学习系统的路线图 6
1.4.1　预处理—整理数据 6
1.4.2　训练和选择预测模型 7
1.4.3　评估模型和预测新样本数据 7
1.5　用Python进行机器学习 7
1.5.1　从Python包索引安装Python和其他包 8
1.5.2　采用Anaconda Python和软件包管理器 8
1.5.3　科学计算、数据科学和机器学习软件包 8
1.6　小结 9
第2章　训练简单的机器学习分类算法 10
2.1　人工神经元—机器学习早期历史一瞥 10
2.1.1　人工神经元的正式定义 11
2.1.2　感知器学习规则 12
2.2　在Python中实现感知器学习算法 14
2.2.1　面向对象的感知器API 14
2.2.2　在鸢尾花数据集上训练感知器模型 16
2.3　自适应神经元和学习收敛 20
2.3.1　梯度下降为最小代价函数 21
2.3.2　用Python实现Adaline 22
2.3.3　通过调整特征大小改善梯度下降 25
2.3.4　大规模机器学习与随机梯度下降 27
2.4　小结 30
第3章　scikit-learn机器学习分类器一览 32
3.1　选择分类算法 32
3.2　了解scikit-learn软件库的第一步—训练感知器 32
3.3　基于逻辑回归的分类概率建模 37
3.3.1　逻辑回归的直觉与条件概率 37
3.3.2　学习逻辑代价函数的权重 39
3.3.3　把转换的Adaline用于逻辑回归算法 41
3.3.4　用scikit-learn训练逻辑回归模型 44
3.3.5　通过正则化解决过拟合问题 45
3.4　支持向量机的最大余量分类 47
3.4.1　最大边际的直觉 48
3.4.2　用松弛变量处理非线性可分 48
3.4.3　其他的scikit-learn 实现 50
3.5　用核支持向量机求解非线性问题 50
3.5.1　处理线性不可分数据的核方法 50
3.5.2　利用核技巧，发现高维空间的分离超平面 52
3.6　决策树学习 55
3.6.1　最大限度地获取信息—获得最大收益 55
3.6.2　构建决策树 58
3.6.3　通过随机森林组合多个决策树 61
3.7　K-近邻—一种懒惰的学习算法 63
3.8　小结 65
第4章　构建良好的训练集——预处理 66
4.1　处理缺失数据 66
4.1.1　识别数据中的缺失数值 66
4.1.2　删除缺失的数据 67
4.1.3　填补缺失的数据 68
4.1.4　了解scikit-learn评估器API 68
4.2　处理分类数据 69
4.2.1　名词特征和序数特征 69
4.2.2　映射序数特征 70
4.2.3　分类标签编码 70
4.2.4　为名词特征做热编码 71
4.3　分裂数据集为独立的训练集和测试集 73
4.4　把特征保持在同一尺度上 75
4.5　选择有意义的特征 76
4.5.1　L1和L2正则化对模型复杂度的惩罚 76
4.5.2　L2正则化的几何解释 77
4.5.3　L1正则化的稀疏解决方案 78
4.5.4　为序数特征选择算法 80
4.6　用随机森林评估特征的重要性 84
4.7　小结 87
第5章　通过降维压缩数据 88
5.1　用主成分分析实现无监督降维 88
5.1.1　主成分分析的主要步骤 88
5.1.2　逐步提取主成分 89
5.1.3　总方差和解释方差 91
5.1.4　特征变换 92
5.1.5　scikit-learn的主成分分析 93
5.2　基于线性判别分析的有监督数据压缩 96
5.2.1　主成分分析与线性判别分析 96
5.2.2　线性判别分析的内部逻辑 97
5.2.3　计算散布矩阵 97
5.2.4　在新的特征子空间选择线性判别式 99
5.2.5　将样本投影到新的特征空间 101
5.2.6　用scikit-learn实现的LDA 101
5.3　非线性映射的核主成分分析 102
5.3.1　核函数与核技巧 103
5.3.2　用Python实现核主成分分析 106
5.3.3　投影新的数据点 111
5.3.4　scikit-learn的核主成分分析 113
5.4　小结 114
第6章　模型评估和超参数调优的最佳实践 115
6.1　用管道方法简化工作流 115
6.1.1　加载威斯康星乳腺癌数据集 115
6.1.2　集成管道中的转换器和评估器 116
6.2　使用k折交叉验证评估模型的性能 118
6.2.1　抵抗方法 118
6.2.2　k折交叉验证 119
6.3　用学习和验证曲线调试算法 122
6.3.1　用学习曲线诊断偏差和方差问题 122
6.3.2　用验证曲线解决过拟合和欠拟合问题 124
6.4　通过网格搜索为机器学习模型调优 126
６.4.1　通过网格搜索为超参数调优 126
6.4.2　以嵌套式交叉验证来选择算法 127
6.5　比较不同的性能评估指标 128
6.5.1　含混矩阵分析 128
6.5.2　优化分类模型的准确度和召回率 129
6.5.3　绘制受试者操作特性图 130
6.5.4　多元分类评分指标 133
6.6　处理类的不平衡问题 133
6.7　小结 135
第7章　综合不同模型的组合学习 136
7.1　集成学习 136
7.2　采用多数票机制的集成分类器 139
7.2.1　实现基于多数票的简单分类器 139
7.2.2　用多数票原则进行预测 143
7.2.3　评估和优化集成分类器 145
7.3　套袋—基于导引样本构建分类器集成 149
7.3.1　套袋简介 150
7.3.2　应用套袋技术对葡萄酒数据集中的样本分类 151
7.4　通过自适应增强来利用弱学习者 153
7.4.1　增强是如何实现的 154
7.4.2　用scikit-learn实现AdaBoost 156
7.5　小结 158
第8章　应用机器学习于情感分析 159
8.1　为文本处理预备好IMDb电影评论数据 159
8.1.1　获取电影评论数据集 159
8.1.2　把电影评论数据预处理成更方便格式的数据 160
8.2　词袋模型介绍 161
8.2.1　把词转换成特征向量 161
8.2.2　通过词频逆反文档频率评估单词相关性 162
8.2.3　清洗文本数据 164
8.2.4　把文档处理为令牌 165
8.3　训练文档分类的逻辑回归模型 166
8.4　处理更大的数据集—在线算法和核心学习 168
8.5　具有潜在狄氏分配的主题建模 171
8.5.1　使用LDA分解文本文档 171
8.5.2　LDA与scikit-learn 172
8.6　小结 174
第9章　将机器学习模型嵌入网络应用 175
9.1　序列化拟合scikit-learn评估器 175
9.2　搭建SQLite数据库存储数据 177
9.3　用Flask开发网络应用 179
9.3.1　第一个Flask网络应用 179
9.3.2　表单验证与渲染 181
9.4　将电影评论分类器转换为网络应用 184
9.4.1　文件与文件夹—研究目录树 185
9.4.2　实现主应用app.py 186
9.4.3　建立评论表单 188
9.4.4　创建一个结果页面的模板 189
9.5　在面向公众的服务器上部署网络应用 190
9.5.1　创建PythonAnywhere账户 190
9.5.2　上传电影分类应用 191
9.5.3　更新电影分类器 191
9.6　小结 193
第10章　用回归分析预测连续目标变量 194
10.1　线性回归简介 194
10.1.1　简单线性回归 194
10.1.2　多元线性回归 195
10.2　探索住房数据集 196
10.2.1　加载住房数据 196
10.2.2　可视化数据集的重要特点 197
10.2.3　用关联矩阵查看关系 198
10.3　普通最小二乘线性回归模型的实现 200
10.3.1　用梯度下降方法求解回归参数 200
10.3.2　通过scikit-learn估计回归模型的系数 203
10.4　利用RANSAC拟合稳健的回归模型 205
10.5　评估线性回归模型的性能 206
10.6　用正则化方法进行回归 209
10.7　将线性回归模型转换为曲线—多项式回归 210
10.7.1　用scikit-learn增加多项式的项 210
10.7.2　为住房数据集中的非线性关系建模 211
10.8　用随机森林处理非线性关系 214
10.8.1　决策树回归 214
10.8.2　随机森林回归 215
10.9　小结 217
第11章　用聚类分析处理无标签数据 218
11.1　用k-均值进行相似性分组 218
11.1.1　scikit-learn的k-均值聚类 218
11.1.2　k-均值++—更聪明地设置初始聚类中心的方法 221
11.1.3　硬聚类与软聚类 222
11.1.4　用肘法求解最佳聚类数 223
11.1.5　通过轮廓图量化聚类质量 224
11.2　把集群组织成有层次的树 228
11.2.1　以自下而上的方式聚类 228
11.2.2　在距离矩阵上进行层次聚类 229
11.2.3　热度图附加树状图 232
11.2.4　scikit-learn凝聚聚类方法 233
11.3　通过DBSCAN定位高密度区域 233
11.4　小结 237
第12章　从零开始实现多层人工神经网络 238
12.1　用人工神经网络为复杂函数建模 238
12.1.1　单层神经网络扼要重述 239
12.1.2　介绍多层神经网络体系 240
12.1.3　利用正向传播激活神经网络 242
12.2　识别手写数字 243
12.2.1　获取MNIST数据集 243
12.2.2　实现一个多层感知器 247
12.3　训练人工神经网络 256
12.3.1　逻辑成本函数的计算 256
12.3.2　开发反向传播的直觉 257
12.3.3　通过反向传播训练神经网络 258
12.4　关于神经网络的收敛性 260
12.5　关于神经网络实现的最后几句话 261
12.6　小结 261
第13章　用TensorFlow并行训练神经网络 262
13.1　TensorFlow与模型训练的性能 262
13.1.1　什么是TensorFlow 263
13.1.2　如何学习TensorFlow 264
13.1.3　学习TensorFlow的第一步 264
13.1.4　使用阵列结构 266
13.1.5　用TensorFlow的底层API开发简单的模型 267
13.2　用TensorFlow的高级 API高效率地训练神经网络 270
13.2.1　用TensorFlow的Layers API构建多层神经网络 270
13.2.2　用Keras研发多层神经网络 274
13.3　多层网络激活函数的选择 277
13.3.1　逻辑函数回顾 278
13.3.2　在多元分类中调用softmax函数评估类别概率 279
13.3.3　利用双曲正切拓宽输出范围 280
13.3.4　修正线性单元激活函数 281
13.4　小结 282
第14章　深入探讨TensorFlow的工作原理 283
14.1　TensorFlow的主要功能 283
14.2　TensorFlow 的排序与张量 284
14.3　了解TensorFlow的计算图 285
14.4　TensorFlow中的占位符 287
14.4.1　定义占位符 287
14.4.2　为占位符提供数据 287
14.4.3　用batchsizes 为数据阵列定义占位符 288
14.5　TensorFlow中的变量 289
14.5.1　定义变量 289
14.5.2　初始化变量 290
14.5.3　变量范围 291
14.5.4　变量复用 292
14.6　建立回归模型 295
14.7　在TensorFlow计算图中用张量名执行对象 297
14.8　在TensorFlow中存储和恢复模型 298
14.9　把张量转换成多维数据阵列 300
14.10　利用控制流构图 303
14.11　用TensorBoard可视化图 305
14.12　小结 308
第15章　深度卷积神经网络图像识别 309
15.1　构建卷积神经网络的模块 309
15.1.1　理解CNN与学习特征的层次 309
15.1.2　执行离散卷积 310
15.1.3　子采样 316
15.2　拼装构建CNN 317
15.2.1　处理多个输入或者彩色频道 317
15.2.2　通过淘汰正则化神经网络 319
15.3　用TensorFlow实现深度卷积神经网络 321
15.3.1　多层CNN体系结构 321
15.3.2　加载和预处理数据 322
15.3.3　用TensorFlow的低级API实现CNN模型 323
15.3.4　用TensorFlow 的Layers API实现CNN 332
15.4　小结 336
第16章　用递归神经网络为序列数据建模 338
16.1　序列数据 338
16.1.1　序列数据建模—顺序很重要 338
16.1.2　表示序列 339
16.1.3　不同类别的序列建模 339
16.2　用于序列建模的RNN 340
16.2.1　理解RNN的结构和数据流 340
16.2.2　在RNN中计算激活值 341
16.2.3　长期交互学习的挑战 343
16.2.4　LSTM单元 343
16.3　用TensorFlow实现多层RNN序列建模 345
16.4　项目一：利用多层RNN对IMDb电影评论进行情感分析 345
16.4.1　准备数据 345
16.4.2　嵌入式 348
16.4.3　构建一个RNN模型 350
16.4.4　情感RNN类构造器 350
16.4.5　build方法 351
16.4.6　train方法 353
16.4.7　predict方法 354
16.4.8　创建SentimentRNN类的实例 355
16.4.9　训练与优化情感分析RNN模型 355
16.5　项目二：用TensorFlow实现字符级 RNN语言建模 356
16.5.1　准备数据 356
16.5.2　构建字符级RNN语言模型 359
16.5.3　构造器 359
16.5.4　build方法 360
16.5.5　train方法 362
16.5.6　sample方法 362
16.5.7　创建和训练CharRNN模型 364
16.5.8　处于取样状态的CharRNN模型 364
16.6　总结 365
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习（原书第2版)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>SQL机器学习库MADlib技术解析
第1章  MADlib基础    1
1.1  基本概念    1
1.1.1  MADlib是什么    1
1.1.2  MADlib的设计思想    2
1.1.3  MADlib的工作原理    3
1.1.4  MADlib的执行流程    4
1.1.5  MADlib架构    5
1.2  MADlib的功能    6
1.2.1  MADlib支持的模型类型    6
1.2.2  MADlib的主要功能模块    7
1.3  MADlib的安装与卸载    9
1.3.1  确定安装平台    9
1.3.2  下载MADlib二进制压缩包    10
1.3.3  安装MADlib    10
1.3.4  卸载MADlib    12
1.4  小结    13
第2章  数据类型    14
2.1  向量    14
2.1.1  MADlib中的向量操作函数    15
2.1.2  稀疏向量    23
2.2  矩阵    30
2.2.1  矩阵定义    31
2.2.2  MADlib中的矩阵表示    31
2.2.3  MADlib中的矩阵运算函数    32
2.3  小结    49
第3章  数据转换    50
3.1  邻近度    50
3.1.1  MADlib的邻近度相关函数    50
3.1.2  距离度量的中心化和标准化    57
3.1.3  选取正确的邻近度度量    58
3.2  矩阵分解    59
3.2.1  低秩矩阵分解    59
3.2.2  奇异值分解    70
3.3  透视表    87
3.4  分类变量编码    97
3.5  小结    110
第4章  数据探索    111
4.1  描述性统计    111
4.1.1  皮尔森相关    111
4.1.2  汇总统计    117
4.2  概率统计    125
4.2.1  概率    125
4.2.2  统计推论    133
4.3  主成分分析    147
4.3.1  背景知识    147
4.3.2  MADlib的PCA相关函数    149
4.3.3  MADlib的PCA应用示例    155
4.4  小结    160
第5章  回归    161
5.1  线性回归    161
5.1.1  背景知识    161
5.1.2  MADlib的线性回归相关函数    164
5.1.3  线性回归示例    166
5.2  非线性回归    171
5.2.1  背景知识    171
5.2.2  MADlib的非线性回归相关
函数    172
5.2.3  非线性回归示例    175
5.3  逻辑回归    179
5.3.1  背景知识    179
5.3.2  MADlib的逻辑回归相关函数    180
5.3.3  逻辑回归示例    182
5.4  多类回归    187
5.4.1  背景知识    187
5.4.2  MADlib的多类回归相关函数    190
5.4.3  多类回归示例    192
5.5  序数回归    196
5.5.1  背景知识    196
5.5.2  MADlib的序数回归相关函数    197
5.5.3  序数回归示例    200
5.6  弹性网络回归    202
5.6.1  背景知识    202
5.6.2  MADlib的弹性网络回归相关
函数    204
5.6.3  弹性网络回归示例    209
5.7  小结    221
第6章  时间序列分析    222
6.1  背景知识    222
6.1.1  时间序列分析方法    222
6.1.2  ARIMA模型    223
6.2  MADlib中ARIMA相关函数    225
6.3  时间序列分析示例    228
6.4  小结    232
第7章  分类    233
7.1  K近邻    233
7.1.1  背景知识    233
7.1.2  MADlib中K近邻函数    235
7.1.3  K近邻示例    236
7.2  朴素贝叶斯    240
7.2.1  背景知识    240
7.2.2  MADlib中朴素贝叶斯分类
相关函数    242
7.2.3  朴素贝叶斯分类示例    244
7.3  支持向量机    249
7.3.1  背景知识    249
7.3.2  MADlib的支持向量机相关
函数    252
7.3.3  支持向量机示例    258
7.4  决策树    264
7.4.1  背景知识    264
7.4.2  MADlib的决策树相关函数    267
7.4.3  决策树示例    272
7.5  随机森林    281
7.5.1  背景知识    281
7.5.2  MADlib的随机森林相关函数    282
7.5.3  随机森林示例    287
7.6  小结    293
第8章  聚类    294
8.1  背景知识    294
8.1.1  聚类的概念    294
8.1.2  k-means方法    295
8.2  MADlib的k-means相关函数    297
8.2.1  训练函数    298
8.2.2  簇分配函数    300
8.2.3  轮廓系数函数    301
8.3  k-means示例    301
8.4  小结    307
第9章  关联规则    308
9.1  背景知识    308
9.1.1  基本概念    308
9.1.2  Apriori算法    311
9.2  MADlib的Apriori算法函数    312
9.3  Apriori应用示例    313
9.4  小结    319
第10章  图算法    320
10.1  背景知识    320
10.1.1  基本概念    320
10.1.2  常见图算法    321
10.1.3  单源最短路径    323
10.2  MADlib的单源最短路径相关函数    324
10.3  单源最短路径示例    325
10.4  小结    327
第11章  模型评估    328
11.1  交叉验证    328
11.1.1  背景知识    328
11.1.2  MADlib的交叉验证相关
函数    331
11.1.3  交叉验证示例    333
11.2  预测度量    336
11.3  小结    342
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>SQL机器学习库MADlib技术解析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Julia机器学习核心编程：人人可用的高性能科学计算
第1章  深入理解Julia语言的生态系统	1
1.1  Julia为什么与众不同	1
1.2  Julia的应用领域	3
1.2.1  数据可视化和绘图	3
1.2.2  构建、部署或嵌入代码	4
1.2.3  与数据互动	5
1.2.4  可扩展的机器学习	5
1.2.5  丰富的科学计算生态系统	6
1.2.6  并行和异构计算	6
1.3  安装Julia软件	7
1.3.1  在Ubuntu上安装Julia	7
1.3.2  在Fedora/CentOS/RHEL等Linux发行版上安装Julia	8
1.3.3  在Windows上安装Julia	9
1.3.4  在Mac上安装Julia	11
1.3.5  从源代码构建Julia	11
1.4  Julia在数据科学中的重要性	12
1.5  使用REPL	14
1.5.1  在Julia中使用帮助	15
1.5.2  REPL中的图表	17
1.6  使用Jupyter Notebook	18
1.7  使用Juno编写Julia	23
1.8  包管理	25
1.8.1  使用Pkg.status()显示所有已安装的包	25
1.8.2  使用Pkg.add()添加包	26
1.8.3  安装未注册包	27
1.8.4  使用Pkg.update()更新包	28
1.8.5  METADATA	28
1.8.6  开发包	28
1.8.7  创建一个新的包	29
1.9  多重分派	29
1.10  LLVM和JIT	31
1.11  本章小结	32
第2章  使用Julia进行快速编程	33
2.1  重温编程范式	33
2.1.1  命令式编程范式	34
2.1.2  逻辑式编程范式	34
2.1.3  函数式编程范式	35
2.1.4  面向对象的编程范式	36
2.1.5  开始Julia REPL编程	37
2.2  Julia中的变量	38
2.2.1  命名约定	40
2.2.2  整数、位、字节和布尔数据类型	41
2.3  Julia中的浮点数	43
2.4  浮点数的特殊符号	45
2.4.1  浮点数操作	46
2.4.2  任意精度的计算	46
2.4.3  使用系数编写表达式	47
2.5  Julia中的算术和逻辑运算	48
2.5.1  执行算术运算	48
2.5.2  执行按位运算	48
2.5.3  自更新运算符	49
2.5.4  运算符的优先级	50
2.5.5  类型转换（数字）	51
2.6  数组和矩阵	51
2.6.1  Julia中的列表解析式	53
2.6.2  矩阵运算	55
2.6.3  多维数组操作	58
2.6.4  稀疏矩阵	59
2.7  DataFrames	59
2.7.1  DataFrames中的NA数据类型	59
2.7.2  DataFrame表格	62
2.8  本章小结	63
第3章  Julia函数	64
3.1  创建函数	64
3.2  函数参数	67
3.2.1  值传递和引用传递	68
3.2.2  分享传递	68
3.2.3  return关键字	68
3.3  参数类型	69
3.3.1  无参函数	70
3.3.2  可变参数	70
3.3.3  可选参数	72
3.4  理解函数中变量的作用域	73
3.5  嵌套函数	76
3.6  匿名函数	78
3.7  多重分派	79
3.8  递归	83
3.9  内建函数	84
3.10  本章小结	92
第4章  Julia数据类型	93
4.1  Julia类型系统	93
4.1.1  静态类型语言与动态类型语言	94
4.1.2  整数类型	96
4.1.3  浮点类型	97
4.1.4  Char类型	97
4.1.5  字符串类型	97
4.1.6  布尔类型	98
4.2  类型转换	98
4.3  用户自定义数据类型和复合类型	103
4.4  内部构造	106
4.5  模块和接口	108
4.5.1  在模块中包含文件	110
4.5.2  模块文件路径	112
4.6  模块预编译	113
4.7  多重分派与解释	114
4.8  本章小结	116
第5章  Julia流程控制及异常处理	117
5.1  分支结构	117
5.1.1  简单条件语句	118
5.1.2  if条件语句	119
5.1.3  循环结构	124
5.1.4  循环范围定义	128
5.1.5  break和continue	130
5.2  异常处理	131
5.2.1  throw()	133
5.2.2  error()	136
5.2.3  try-catch/try-finally结构	137
5.3  Julia中的tasks	138
5.4  本章小结	140
第6章  Julia互操作性和元编程	141
6.1  与操作系统交互	141
6.1.1  文件系统操作	142
6.1.2  I/O操作	146
6.1.3  例证	147
6.2  调用C和Python语言	149
6.2.1  从Julia调用C语言	149
6.2.2  从Julia调用Python	150
6.3  表达式和宏	152
6.4  元编程	157
6.5  内置宏	158
6.6  类型自省和反射能力	164
6.6.1  类型自省	164
6.6.2  反射能力	165
6.7  本章小结	167
第7章  用Julia进行数值科学计算	168
7.1  数据处理	168
7.1.1  读取文本文件	171
7.1.2  读取CSV格式文件	174
7.1.3  使用DataFrames	177
7.1.4  NA	178
7.1.5  DataArray	180
7.1.6  DataFrame	181
7.2  线性代数与微分学	182
7.2.1  线性代数	182
7.2.2  微积分	184
7.3  统计数据	186
7.3.1  简单统计	186
7.3.2  在元编程中使用函数	188
7.3.3  使用DataFrames进行基本信息统计	189
7.3.4  使用Pandas	190
7.3.5  高级统计	192
7.4  优化	198
7.4.1  JuMP	198
7.4.2  Convex	200
7.5  本章小结	202
第8章  Julia数据可视化编程	203
8.1  基本图表	203
8.1.1  条形图	206
8.1.2  饼图	207
8.1.3  散点图	209
8.1.4  直方图	210
8.1.5  3D图表	211
8.2  Vega库	213
8.2.1  瀑布图	216
8.2.2  Aster图	217
8.2.3  等值线图	218
8.2.4  面积图	219
8.2.5  箱线图	219
8.2.6  带状图	220
8.2.7  散点图	221
8.2.8  文字云	222
8.3  Gadfly库	223
8.3.1  使用绘图函数与Gadfly库进行交互	224
8.3.2  使用Gadfly库绘制数据块	226
8.4  本章小结	230
第9章  Julia数据库编程	231
9.1  如何连接数据库	231
9.2  关系数据库	232
9.2.1  SQLite	233
9.2.2  MySQL	233
9.3  NoSQL数据库	235
9.4  REST简介	238
9.4.1  JSON简介	239
9.4.2  Web 框架	243
9.5  本章小结	247
第10章  Julia的核心编程结构	248
10.1  Julia的内部代码	248
10.1.1  FemtoLisp	248
10.1.2  Julia核心API	249
10.2  提升性能	249
10.2.1  全局变量	249
10.2.2  输入声明	250
10.2.3  其他技巧	252
10.3  标准库	253
10.4  理解LLVM和JIT	256
10.5  并行计算	258
10.5.1  注意全局变量	260
10.5.2  并行循环	262
10.6  TCP套接字和服务器	264
10.6.1  建立TCP/IP连接	264
10.6.2  socket和streams模块	266
10.7  创建包	267
10.7.1  包命名指南	267
10.7.2  生成包	268
10.8  本章小结	269
第11章  创建Web图书商务网站	270
11.1  安装Genie	270
11.2  使用Genie快速搭建服务器	271
11.3  创建Genie应用程序项目	275
11.4  Genie的MVC结构	279
11.4.1  使用控制器	279
11.4.2  HTML视图	282
11.4.3  使用布局	283
11.4.4  JSON转换	285
11.5  使用SearchLight模组访问数据库	289
11.5.1  设置数据库连接	289
11.5.2  使用SearchLight迁移来管理数据库架构	290
11.5.3  创建图书的数据库表	291
11.5.4  编写表迁移文件	291
11.5.5  运行迁移文件	292
11.6  定义模型	293
11.6.1  使用模型	294
11.6.2  自动加载数据库配置	295
11.7  本章小结	297
第12章  Julia机器学习框架	298
12.1  安装Flux框架	298
12.2  模型构建基础	299
12.2.1  简单模型	301
12.2.2  构建图层	302
12.2.3  堆叠	304
12.2.4  层助手	305
12.3  循环模型	305
12.4  状态模型	308
12.5  序列	309
12.6  梯度截断	310
12.7  正则化	311
12.7.1  基本层	312
12.7.2  循环层	313
12.7.3  激活功能	315
12.7.4  规范化和正规化	315
12.8  优化器	316
12.9  优化参考	318
12.10  机器学习训练	318
12.10.1  损失函数	318
12.10.2  数据集	319
12.10.3  回调	320
12.11  本章小结	320
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Julia机器学习核心编程：人人可用的高性能科学计算
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习互联网业务安全实践
第 1 章 互联网业务安全简述 ................................................................................. 1
1.1  互联网业务安全现状 ........................................................................ 1
1.2  如何应对挑战 .................................................................................... 4
1.3  本章小结 ............................................................................................ 6
参考资料 ............................................................................................ 6
第 2 章 机器学习入门 ........................................................................................... 8
2.1  相似性 ................................................................................................ 9
2.1.1  范数 ........................................................................................ 9
2.1.2  度量 ...................................................................................... 12
2.2  矩阵 .................................................................................................. 20
2.2.1  线性空间 .............................................................................. 20
2.2.2  线性算子 .............................................................................. 24
2.3  空间 .................................................................................................. 33
2.3.1  内积空间 .............................................................................. 33
2.3.2  欧几里得空间（Euclid space） .......................................... 34
2.3.3  酉空间 .................................................................................. 37
2.3.4  赋范线性空间 ...................................................................... 38
2.3.5  巴拿赫空间 .......................................................................... 39
2.3.6  希尔伯特空间 ...................................................................... 43
2.3.7  核函数 .................................................................................. 44
2.4  机器学习中的数学结构 .................................................................. 46
2.4.1  线性结构与非线性结构 ...................................................... 46
2.4.2  图论基础 .............................................................................. 47
2.4.3  树 .......................................................................................... 56
2.4.4  神经网络 .............................................................................. 62
2.4.5  深度网络结构 ...................................................................... 80
2.4.6  小结 ...................................................................................... 95
2.5  统计基础 .......................................................................................... 96
2.5.1  贝叶斯统计 .......................................................................... 96
2.5.2  共轭先验分布 ...................................................................... 99
2.6  策略与算法 .................................................................................... 106
2.6.1  凸优化的基本概念 ............................................................ 106
2.6.2  对偶原理 ............................................................................ 120
2.6.3  非线性规划问题的解决方法 ............................................ 129
2.6.4  无约束问题的最优化方法 ................................................ 134
2.7  机器学习算法应用的经验 ............................................................ 145
2.7.1  如何定义机器学习目标 .................................................... 145
2.7.2  如何从数据中获取最有价值的信息 ................................ 149
2.7.3  评估模型的表现 ................................................................ 154
2.7.4  测试效果远差于预期怎么办 ............................................ 156
2.8  本章小结 ........................................................................................ 159
参考资料 ........................................................................................ 160
第 3 章 模型 ...................................................................................................... 163
3.1  基本概念 ........................................................................................ 163
3.2  模型评价指标 ................................................................................ 166
3.2.1  混淆矩阵 ............................................................................ 167
3.2.2  分类问题的基础指标 ........................................................ 167
3.2.3 ROC 曲线与 AUC ............................................................. 171
3.2.4  基尼系数 ............................................................................ 173
3.2.5  回归问题的评价指标 ........................................................ 175
3.2.6  交叉验证 ............................................................................ 175
3.3  回归算法 ........................................................................................ 177
3.3.1  最小二乘法 ........................................................................ 177
3.3.2  脊回归 ................................................................................ 181
3.3.3 Lasso 回归线性模型 .......................................................... 181
3.3.4 多任务 Lasso ...................................................................... 181
3.3.5 L1、L2 正则杂谈............................................................... 182
3.4  分类算法 ........................................................................................ 183
3.4.1 CART 算法 ........................................................................ 183
3.4.2  支持向量机 ........................................................................ 186
3.5  降维 ................................................................................................ 188
3.5.1  贝叶斯网络 ........................................................................ 189
3.5.2  主成分分析 ........................................................................ 195
3.6 主题模型 LDA ............................................................................... 198
3.6.1  马尔可夫链蒙特卡罗法 .................................................... 198
3.6.2  贝叶斯网络与生成模型 .................................................... 199
3.6.3 学习方法在 LDA 中的应用 .............................................. 206
3.7  集成学习方法（Ensemble Method） ........................................... 215
3.7.1 Boosting 方法 .................................................................... 216
3.7.2 Bootstrap Aggregating 方法 ............................................... 220
3.7.3 Stacking 方法 ..................................................................... 221
3.7.4  小结 .................................................................................... 222
参考资料 ........................................................................................ 223
第 4 章 机器学习实践的基础包 ......................................................................... 226
4.1  简介 ................................................................................................ 226
4.2 Python 机器学习基础环境 ............................................................ 228
4.2.1  Jupyter Notebook ............................................................... 228
4.2.2 Numpy、Scipy、Matplotlib 和 pandas ............................. 231
4.2.3 scikit-learn、gensim、TensorFlow 和 Keras .................... 250
4.3 Scala 的基础库 ............................................................................... 266
4.3.1  Zeppelin .............................................................................. 266
4.3.2  Breeze ................................................................................. 267
4.3.3  Spark MLlib ....................................................................... 276
4.4  本章小结 ........................................................................................ 281
参考资料 ........................................................................................ 282
第 5 章 机器学习实践的金刚钻 ......................................................................... 283
5.1  简介 ................................................................................................ 283
5.2  XGBoost ......................................................................................... 284
5.3  Prediction IO（PIO） .................................................................... 287
5.3.1 部署 PIO ............................................................................ 287
5.3.2  机器学习模型引擎的开发 ................................................ 294
5.3.3  机器学习模型引擎的部署 ................................................ 296
5.3.4 PIO 系统的优化 ................................................................ 297
5.4  Caffe ............................................................................................... 298
5.5  TensorFlow ..................................................................................... 304
5.6  BigDL ............................................................................................. 306
5.7  本章小结 ........................................................................................ 308
参考资料 ........................................................................................ 308
第 6 章 账户业务安全 ....................................................................................... 310
6.1  背景介绍 ........................................................................................ 310
6.2  账户安全保障 ................................................................................ 312
6.2.1  注册环节 ............................................................................ 312
6.2.2  登录环节 ............................................................................ 314
6.3  聚类算法在账户安全中的应用 .................................................... 315
6.3.1 K-Means 算法 .................................................................... 315
6.3.2  高斯混合模型（GMM） .................................................. 317
6.3.3 OPTICS 算法和 DBSCAN 算法 ....................................... 326
6.3.4  应用案例 ............................................................................ 331
6.4  本章小结 ........................................................................................ 334
参考资料 ........................................................................................ 334
第 7 章 平台业务安全 ....................................................................................... 335
7.1  背景介绍 ........................................................................................ 335
7.2  电商平台业务安全 ........................................................................ 338
7.3  社交平台业务安全 ........................................................................ 343
7.4  复杂网络算法在平台业务安全中的应用 .................................... 346
7.4.1  在电商平台作弊团伙识别中的应用 ................................ 346
7.4.2  在识别虚假社交关系中的应用 ........................................ 351
7.5  本章小结 ........................................................................................ 353
参考资料 ........................................................................................ 354
第 8 章 内容业务安全 ....................................................................................... 355
8.1  背景介绍 ........................................................................................ 355
8.2  如何做好内容业务安全工作 ........................................................ 357
8.2.1  面临的挑战 ........................................................................ 357
8.2.2  部门协作 ............................................................................ 358
8.2.3  技术体系 ............................................................................ 359
8.3  卷积神经网络在内容业务安全中的应用 .................................... 361
8.3.1  人工神经网络（Artificial Neural Network） ................... 361
8.3.2  深度神经网络（Deep Neural Network） ......................... 367
8.3.3  卷积神经网络（Convolutional Neural Network） .......... 379
8.3.4  应用案例 ............................................................................ 392
8.4  本章小结 ........................................................................................ 405
参考资料 ........................................................................................ 405
第 9 章 信息业务安全 ....................................................................................... 406
9.1  背景介绍 ........................................................................................ 406
9.2  反欺诈业务 .................................................................................... 407
9.3  反爬虫业务 .................................................................................... 412
9.3.1  验证问题的可分性 ............................................................ 412
9.3.2  提升模型效果 .................................................................... 413
9.4  循环神经网络在信息安全中的应用 ............................................ 414
9.4.1 原始 RNN（Vanilla RNN） .............................................. 414
9.4.2 LSTM 算法及其变种 ........................................................ 415
9.4.3  应用案例 ............................................................................ 419
9.5  本章小结 ........................................................................................ 429
参考资料 ........................................................................................ 430
第 10 章 信贷业务安全 ..................................................................................... 432
10.1  背景介绍 ...................................................................................... 432
10.2  信贷业务安全简介 ...................................................................... 434
10.3  分类算法在信贷业务安全中的应用 .......................................... 438
10.3.1  典型分类算法的介绍 ...................................................... 438
10.3.2  应用案例：逻辑回归模型在信贷中风控阶段的应用 .. 463
10.4  本章小结 ...................................................................................... 468
参考资料 ........................................................................................ 469
第 11 章 业务安全系统技术架构 ....................................................................... 470
11.1  整体介绍 ...................................................................................... 470
11.2  平台层 .......................................................................................... 471
11.3  数据层 .......................................................................................... 473
11.4  策略层 .......................................................................................... 474
11.5  服务层 .......................................................................................... 480
11.6  业务层 .......................................................................................... 481
11.7  本章小结 ...................................................................................... 484
参考资料 ........................................................................................ 484
第 12 章 总结与展望 ......................................................................................... 486
12.1  总结 .............................................................................................. 486
12.2  展望 .............................................................................................. 487
参考资料 ........................................................................................ 489
后记一   ............................................................................................................. 490
后记二   ............................................................................................................. 491
本书常见数学符号定义   .................................................................................... 492
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习互联网业务安全实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>快乐机器学习
第 1 章 机器学习是什么——机器学习定义 .. 1
引言.. 2
1.1 数据. 5
1.1.1 结构型与非结构型数据  5
1.1.2 原始数据与加工.. 7
1.1.3 样本内数据与样本外数据 . 9
1.2 机器学习类别 9
1.2.1 有监督学习 10
1.2.2 无监督学习 10
1.2.3 半监督学习. 11
1.2.4 增强学习 11
1.2.5 深度学习 11
1.2.6 迁移学习.. 12
1.3 性能度量. 12
1.3.1 误差函数.. 13
1.3.2 回归度量.. 14
1.3.3 分类度量.. 15
1.4 总结.. 19
参考资料.. 20
第 2 章 机器学习可行吗——计算学习理论  22
引言 23
2.1 基础知识. 25
2.1.1 二分类. 25
2.1.2 对分 26
2.1.3 增长函数.. 29
2.1.4 突破点. 30
2.2 核心推导. 31
2.2.1 机器学习可行条件 . 31
2.2.2 从已知推未知. 33
2.2.3 从民意调查到机器学习  35
2.2.4 从单一到有限. 36
2.2.5 从有限到无限. 37
2.2.6 从无限到有限. 38
2.3 结论应用. 39
2.3.1 VC 不等式  39
2.3.2 VC 维度 .. 40
2.3.3 模型复杂度 40
2.3.4 样本复杂度 41
2.4 总结.. 42
参考资料.. 43
技术附录.. 43
第 3 章 机器学习怎么学——模型评估选择  47
引言 48
3.1 模型评估. 52
3.2 训练误差和测试误差. 52
3.2.1 训练误差.. 52
3.2.2 真实误差.. 54
3.2.3 测试误差.. 57
3.2.4 学习理论.. 57
3.3 验证误差和交叉验证误差. 60
3.3.1 验证误差.. 60
3.3.2 交叉验证误差. 61
3.3.3 学习理论.. 62
3.4 误差剖析. 64
3.4.1 误差来源.. 64
3.4.2 偏差—方差权衡 66
3.5 模型选择. 67
3.6 总结.. 70
参考资料.. 71
技术附录.. 71
第 4 章 线性回归 73
引言 74
4.1 基础知识. 75
4.1.1 标量微积分 75
4.1.2 向量微积分 76
4.2 模型介绍. 77
4.2.1 核心问题.. 77
4.2.2 通用线性回归模型 . 83
4.2.3 特征缩放.. 84
4.2.4 学习率设定 86
4.2.5 数值算法比较. 87
4.2.6 代码实现.. 89
4.3 总结.. 90
参考资料.. 90
第 5 章 对率回归 92
引言 93
5.1 基础内容. 94
5.1.1 联系函数.. 94
5.1.2 函数绘图.. 95
5.2 模型介绍. 96
5.2.1 核心问题.. 96
5.2.2 查准和查全. 102
5.2.3 类别不平衡. 104
5.2.4 线性不可分. 105
5.2.5 多分类问题. 106
5.2.6 代码实现 109
5.3 总结. 110
参考资料. 111
第 6 章 正则化回归 . 112
引言. 113
6.1 基础知识 114
6.1.1 等值线图. 114
6.1.2 坐标下降. 116
6.2 模型介绍 116
6.2.1 核心问题. 116
6.2.2 模型对比 122
6.2.3 最佳模型 125
6.2.4 代码实现 126
6.3 总结 126
参考资料 127
第 7 章 支持向量机 . 128
引言 129
7.1 基础知识.. 133
7.1.1 向量初体验. 133
7.1.2 拉格朗日量. 136
7.1.3 原始和对偶. 137
7.2 模型介绍.. 138
7.2.1 硬间隔 SVM 原始问题. 138
7.2.2 硬间隔 SVM 对偶问题. 144
7.2.3 软间隔 SVM 原始问题. 148
7.2.4 软间隔 SVM 对偶问题. 150
7.2.5 空间转换 151
7.2.6 核技巧. 155
7.2.7 核 SVM . 158
7.2.8 SMO 算法 .. 159
7.2.9 模型选择 161
7.3 总结 162
参考资料 164
技术附录 164
第 8 章 朴素贝叶斯 . 170
引言 171
8.1 基础知识.. 174
8.1.1 两种概率学派.. 174
8.1.2 两种独立类别.. 174
8.1.3 两种学习算法.. 175
8.1.4 两种估计方法.. 176
8.1.5 两类概率分布.. 177
8.2 模型介绍.. 179
8.2.1 问题剖析 179
8.2.2 朴素贝叶斯算法 182
8.2.3 多元伯努利模型 183
8.2.4 多项事件模型.. 184
8.2.5 高斯判别分析模型 . 184
8.2.6 多分类问题. 186
8.2.7 拉普拉斯校正.. 187
8.2.8 最大似然估计和最大后验估计 . 188
8.3 总结 190
参考资料 191
技术附录 191
第 9 章 决策树 . 195
引言 196
9.1 基础知识.. 198
9.1.1 多数规则 198
9.1.2 熵和条件熵. 198
9.1.3 信息增益和信息增益比 . 200
9.1.4 基尼指数 201
9.2 模型介绍.. 201
9.2.1 二分类决策树.. 201
9.2.2 多分类决策树.. 209
9.2.3 连续值分裂. 210
9.2.4 欠拟合和过拟合. 211
9.2.5 预修剪和后修剪 212
9.2.6 数据缺失 215
9.2.7 代码实现 218
9.3 总结 219
参考资料 219
第 10 章 人工神经网络  220
引言 221
10.1 基本知识 223
10.1.1 转换函数 223
10.1.2 单输入单层单输出神经网络 . 224
10.1.3 多输入单层单输出神经网络 . 224
10.1.4 多输入单层多输出神经网络 . 225
10.1.5 多输入多层多输出神经网络 . 225
10.2 模型应用 227
10.2.1 创建神经网络模型 .. 227
10.2.2 回归应用 230
10.2.3 分类应用 238
第 11 章 正向/反向传播 246
引言 247
11.1 基础知识 250
11.1.1 神经网络元素  250
11.1.2 链式法则  254
11.2 算法介绍 254
11.2.1 正向传播  254
11.2.2 梯度下降  257
11.2.3 反向传播  258
11.2.4 代码实现  262
11.3 总结 268
参考资料 268
技术附录 269
第 12 章 集成学习. 272
引言 273
12.1 结合假设 277
12.1.1 语文和数学. 277
12.1.2 准确和多样. 278
12.1.3 独裁和民主. 279
12.1.4 学习并结合. 279
12.2 装袋法. 280
12.2.1 基本概念 280
12.2.2 自助采样 280
12.2.3 结合假设 281
12.3 提升法. 282
12.3.1 基本概念 282
12.3.2 最优加权 283
12.3.3 结合假设 285
12.4 集成方式 286
12.4.1 同质学习器. 286
12.4.2 异质学习器. 286
12.5 总结 288
参考资料 288
第 13 章 随机森林和提升树 . 289
引言 290
13.1 基础知识 293
13.1.1 分类回归树. 293
13.1.2 前向分布算法 294
13.1.3 置换检验 295
13.2 模型介绍 296
13.2.1 随机森林 296
13.2.2 提升树.. 302
13.2.3 代码实现 306
13.3 总结 307
参考资料 307
第 14 章 极度梯度提升  309
引言 310
14.1 基础知识. 311
14.1.1 树的重定义 311
14.1.2 树的复杂度. 313
14.2 模型介绍 313
14.2.1 XGB 简介. 313
14.2.2 XGB 的泛化度 314
14.2.3 XGB 的精确度 315
14.2.4 XGB 的速度.. 318
14.2.5 代码实现 324
14.3 总结 325
参考资料 326
第 15 章 本书总结. 327
15.1 正交策略 328
15.2 单值评估指标.. 330
15.3 偏差和方差. 332
15.3.1 理论定义 332
15.3.2 实用定义 334
15.3.3 最优误差 335
15.3.4 两者权衡 336
15.3.5 学习曲线 336
结语 339
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>快乐机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PySpark机器学习、自然语言处理与推荐系统
目    录
第1章  数据革命   1
1.1  数据生成   1
1.2  Spark   2
1.2.1  Spark Core   3
1.2.2  Spark组件   4
1.3  设置环境   5
1.3.1  Windows   5
1.3.2  iOS   6
1.4  小结   7
第2章  机器学习简介   9
2.1  有监督机器学习   10
2.2  无监督机器学习   12
2.3  半监督机器学习   14
2.4  强化学习   14
2.5  小结   15
第3章  数据处理   17
3.1  加载和读取数据   17
3.2  添加一个新列   20
3.3  筛选数据   21
3.3.1  条件1   21
3.3.2  条件2   22
3.4  列中的非重复值   23
3.5  数据分组   23
3.6  聚合   25
3.7  用户自定义函数(UDF)   26
3.7.1  传统的Python函数   26
3.7.2  使用lambda函数   27
3.7.3  Pandas UDF(向量化的UDF)   28
3.7.4  Pandas UDF(多列)   29
3.8  去掉重复值   29
3.9  删除列   30
3.10  写入数据   30
3.10.1  csv   31
3.10.2  嵌套结构   31
3.11  小结   31
第4章  线性回归   33
4.1  变量   33
4.2  理论   34
4.3  说明   41
4.4  评估   42
4.5  代码   43
4.5.1  数据信息   43
4.5.2  步骤1：创建
SparkSession对象   44
4.5.3  步骤2：读取数据集   44
4.5.4  步骤3：探究式数据分析   44
4.5.5  步骤4：特征工程化   45
4.5.6  步骤5：划分数据集   47
4.5.7  步骤6：构建和训练线性回归模型   47
4.5.8  步骤7：在测试数据上评估线性回归模型   48
4.6  小结   48
第5章  逻辑回归   49
5.1  概率   49
5.1.1  使用线性回归   50
5.1.2  使用Logit   53
5.2  截距(回归系数)   54
5.3  虚变量   55
5.4  模型评估   56
5.4.1  正确的正面预测   56
5.4.2  正确的负面预测   57
5.4.3  错误的正面预测   57
5.4.4  错误的负面预测   57
5.4.5  准确率   57
5.4.6  召回率   57
5.4.7  精度   58
5.4.8  F1分数   58
5.4.9  截断/阈值概率   58
5.4.10  ROC曲线   58
5.5  逻辑回归代码   59
5.5.1  数据信息   59
5.5.2  步骤1：创建Spark会话对象   60
5.5.3  步骤2：读取数据集   60
5.5.4  步骤3：探究式数据分析   60
5.5.5  步骤4：特征工程   63
5.5.6  步骤5：划分数据集   68
5.5.7  步骤6：构建和训练逻辑回归模型   69
5.5.8  训练结果   69
5.5.9  步骤7：在测试数据上评估线性回归模型   70
5.5.10  混淆矩阵   71
5.6  小结   72
第6章  随机森林   73
6.1  决策树   73
6.1.1  熵   75
6.1.2  信息增益   76
6.2  随机森林   78
6.3  代码   80
6.3.1  数据信息   80
6.3.2  步骤1：创建SparkSession对象   81
6.3.3  步骤2：读取数据集   81
6.3.4  步骤3：探究式数据分析   81
6.3.5  步骤4：特征工程   85
6.3.6  步骤5：划分数据集   86
6.3.7  步骤6：构建和训练随机森林模型   87
6.3.8  步骤7：基于测试数据进行评估   87
6.3.9  准确率   89
6.3.10  精度   89
6.3.11  AUC曲线下的面积   89
6.3.12  步骤8：保存模型   90
6.4  小结   90
第7章  推荐系统   91
7.1  推荐   91
7.1.1  基于流行度的RS   92
7.1.2  基于内容的RS   93
7.1.3  基于协同过滤的RS   95
7.1.4  混合推荐系统   103
7.2  代码   104
7.2.1  数据信息   105
7.2.2  步骤1：创建SparkSession对象   105
7.2.3  步骤2：读取数据集   105
7.2.4  步骤3：探究式数据分析   105
7.2.5  步骤4：特征工程   108
7.2.6  步骤5：划分数据集   109
7.2.7  步骤6：构建和训练推荐系统模型   110
7.2.8  步骤7：基于测试数据进行预测和评估   110
7.2.9  步骤8：推荐活动用户可能会喜欢的排名靠前的电影   111
7.3  小结   114
第8章  聚类   115
8.1  初识聚类   115
8.2  用途   117
8.2.1  K-均值   117
8.2.2  层次聚类   127
8.3  代码   131
8.3.1  数据信息   131
8.3.2  步骤1：创建SparkSession对象   131
8.3.3  步骤2：读取数据集   131
8.3.4  步骤3：探究式数据分析   131
8.3.5  步骤4：特征工程   133
8.3.6  步骤5：构建K均值聚类模型   133
8.3.7  步骤6：聚类的可视化   136
8.4  小结   137
第9章  自然语言处理   139
9.1  引言   139
9.2  NLP涉及的处理步骤   139
9.3  语料   140
9.4  标记化   140
9.5  移除停用词   141
9.6  词袋   142
9.7  计数向量器   143
9.8  TF-IDF   144
9.9  使用机器学习进行文本分类   145
9.10  序列嵌入   151
9.11  嵌入   151
9.12  小结   160
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PySpark机器学习、自然语言处理与推荐系统
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习和图像处理实战 面部识别、目标检测和模式识别
目    录

第1章  设置环境   1
1.1  安装Anaconda   1
1.1.1  在Windows下安装   2
1.1.2  在macOS下安装   3
1.1.3  在Ubuntu下安装   3
1.2  安装OpenCV   3
1.3  安装Keras   4
1.4  测试安装   4
1.5  虚拟环境   4
第2章  图像处理入门   7
2.1  图像   7
2.2  像素   8
2.3  图像分辨率   8
2.4  PPI与DPI   9
2.5  位图图像   10
2.6  无损压缩   10
2.7  有损压缩   10
2.8  图像文件格式   11
2.9  色彩空间   12
2.9.1  RGB   12
2.9.2  XYZ   13
2.9.3  HSV/HSL   14
2.9.4  Lab   15
2.9.5  LCH   16
2.9.6  YPbPr   16
2.9.7  YUV   17
2.9.8  YIQ   17
2.10  高级图像概念   18
2.10.1  贝塞尔曲线   18
2.10.2  椭球   19
2.10.3  伽马校正   20
2.10.4  结构相似性指标   21
2.10.5  解卷积   21
2.10.6  单应性   22
2.10.7  卷积   22
第3章  Python基础和Scikit Image   23
3.1  Python入门   23
3.1.1  变量和数据类型   24
3.1.2  数据结构   25
3.1.3  循环语句   26
3.1.4  条件语句   28
3.1.5  函数   29
3.2  Scikit Image   31
3.2.1  上传和查看图像   32
3.2.2  获取图像分辨率   32
3.2.3  查看像素值   33
3.2.4  转换色彩空间   33
3.2.5  保存图像   40
3.2.6  创建基本图形   41
3.2.7  执行伽马校正   44
3.2.8  旋转、平移和缩放图像   45
3.2.9  确定结构相似度   46
第4章  OpenCV高级图像处理   47
4.1  混合两张图像   47
4.2  改变图像的对比度和 亮度   49
4.3  往图像中添加文字   51
4.4  平滑图像   52
4.4.1  中值滤波器   53
4.4.2  高斯滤波器   53
4.4.3  双边滤波器   54
4.5  改变图像的形状   55
4.6  实施图像阈限化   59
4.7  计算梯度   62
4.8  执行直方图均衡   63
第5章  基于机器学习的图像处理   67
5.1  使用SIFT算法的特征映射   67
5.1.1  步骤1：构造尺度不变的空间   68
5.1.2  步骤2：求两个高斯之差   68
5.1.3  步骤3：找出图像中的关键点   69
5.1.4  步骤4：为了高效地比较，移除非关键点   69
5.1.5  步骤5：提供关键点的方向   69
5.1.6  步骤6：确定唯一关键特征   69
5.2  使用RANSAC算法的图像配准   73
5.2.1  estimate_affine()函数   77
5.2.2  residual_lengths()函数   77
5.2.3  输出图像   78
5.2.4  全部代码   78
5.3  使用人工神经网络的图像分类   81
5.4  使用CNN的图像分类   87
5.5  使用机器学习的图像分类   92
5.5.1  决策树   92
5.5.2  支持向量机   92
5.5.3  逻辑回归   93
5.5.4  代码   93
5.6  重要术语   95
第6章  实时用例   97
6.1  找出掌纹   97
6.2  检测面部   99
6.3  识别面部   101
6.4  追踪运动   103
6.5  检测车道   104
附录  重要概念与术语   111
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python机器学习和图像处理实战 面部识别、目标检测和模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python高级机器学习
第1章 无监督机器学习　　1
1.1 主成分分析　　1
1.1.1 主成分分析入门　　2
1.1.2 应用主成分分析　　3
1.2 k均值聚类　　5
1.2.1 聚类入门　　5
1.2.2 开始聚类分析　　6
1.2.3 调整聚类参数　　10
1.3 自组织映射　　13
1.3.1 自组织映射入门　　13
1.3.2 部署自组织映射　　14
1.4 扩展阅读　　17
1.5 小结　　18
第2章 深度信念网络　　19
2.1 神经网络入门　　19
2.1.1 神经网络的组成　　20
2.1.2 网络拓扑结构　　20
2.2 受限玻尔兹曼机　　23
2.2.1 受限玻尔兹曼机简介　　23
2.2.2 受限玻尔兹曼机的应用　　26
2.2.3 受限玻尔兹曼机的扩展应用　　35
2.3 深度信念网络　　35
2.3.1 训练深度信念网络　　36
2.3.2 应用深度信念网络　　36
2.3.3 验证深度信念网络　　39
2.4 扩展阅读　　40
2.5 小结　　40
第3章 堆叠式降噪自编码机　　41
3.1 自编码机　　41
3.1.1 自编码机简介　　41
3.1.2 降噪自编码机　　43
3.1.3 应用降噪自编码机　　44
3.2 堆叠式降噪自编码机　　47
3.2.1 应用堆叠式降噪自编码机　　48
3.2.2 评估堆叠式降噪自编码机的性能　　53
3.3 扩展阅读　　54
3.4 小结　　54
第4章 卷积神经网络　　55
4.1 CNN介绍　　55
4.1.1 CNN拓扑结构　　56
4.1.2 应用CNN　　66
4.2 扩展阅读　　71
4.3 小结　　71
第5章 半监督学习　　72
5.1 简介　　72
5.2 何为半监督学习　　72
5.3 半监督算法实战　　73
5.3.1 自训练　　73
5.3.2 对比悲观似然估计　　81
5.4 扩展阅读　　89
5.5 小结　　90
第6章 文本特征工程　　91
6.1 介绍　　91
6.2 文本特征工程　　92
6.2.1 清洗文本数据　　92
6.2.2 根据文本数据构造特征　　99
6.2.3 测试准备好的数据　　103
6.3 扩展阅读　　108
6.4 小结　　109
第7章 特征工程II　　110
7.1 介绍　　110
7.2 创建特征集　　110
7.2.1 为机器学习应用构建特征　　111
7.2.2 运用特征选择技术　　117
7.3 特征工程实战　　123
7.4 扩展阅读　　141
7.5 小结　　142
第8章 集成方法　　143
8.1 集成简介　　143
8.1.1 理解平均集成　　144
8.1.2 应用提升法　　148
8.1.3 使用堆叠集成　　153
8.2 在动态应用中使用模型　　157
8.2.1 理解模型稳健性　　158
8.2.2 控制模型稳健性的策略　　163
8.3 扩展阅读　　166
8.4 小结　　166
第9章 其他Python机器学习工具　　167
9.1 可选的开发工具　　167
9.1.1 Lasagne简介　　167
9.1.2 TensorFlow简介　　169
9.1.3 何时使用这些库　　173
9.2 扩展阅读　　174
9.3 小结　　175
附录 代码运行要求　　176
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python高级机器学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据智能
第1 章 深度学习——机器大脑的结构 1
1.1 概述 3
1.1.1 可以做酸奶的面包机——通用机器的概念 3
1.1.2 连接主义 5
1.1.3 用机器设计机器 6
1.1.4 深度网络 6
1.1.5 深度学习的用武之地 7
1.2 从人脑神经元到人工神经元 8
1.2.1 生物神经元中的计算灵感 8
1.2.2 激活函数 9
1.3 参数学习 10
1.3.1 模型的评价 11
1.3.2 有监督学习 11
1.3.3 梯度下降法 12
1.4 多层前馈网络 13
1.4.1 多层前馈网络 14
1.4.2 后向传播算法计算梯度 16
1.5 逐层预训练 17
1.6 深度学习是终极神器吗 19
1.6.1 深度学习带来了什么 19
1.6.2 深度学习尚未做到什么 20
1.7 内容回顾与推荐阅读 21
1.8 参考文献 21
第2 章 知识图谱——机器大脑中的知识库 23
2.1 什么是知识图谱 25
2.2 知识图谱的构建 27
2.2.1 大规模知识库 27
2.2.2 互联网链接数据 28
2.2.3 互联网网页文本数据 29
2.2.4 多数据源的知识融合 29
2.3 知识图谱的典型应用 30
2.3.1 查询理解（Query Understanding） 30
2.3.2 自动问答（Question Answering） 32
2.3.3 文档表示（Document Representation） 33
2.4 知识图谱的主要技术 34
2.4.1 实体链指（Entity Linking） 34
2.4.2 关系抽取（Relation Extraction） 35
2.4.3 知识推理（Knowledge Reasoning） 37
2.4.4 知识表示（Knowledge Representation） 38
2.5 前景与挑战 39
2.6 内容回顾与推荐阅读 40
2.7 参考文献 41
第3 章 大数据系统——大数据背后的支撑技术 43
3.1 概述 45
3.2 高性能计算技术 46
3.2.1 超级计算机的组成 47
3.2.2 并行计算的系统支持 48
3.3 虚拟化和云计算技术 52
3.3.1 虚拟化技术 52
3.3.2 云计算服务 54
3.4 基于分布式计算的大数据系统 55
3.4.1 Hadoop 生态系统 55
3.4.2 Spark 61
3.4.3 典型的大数据基础架构 63
3.5 大规模图计算 63
3.5.1 分布式图计算框架 64
3.5.2 高效的单机图计算框架 65
3.6 NoSQL 66
3.6.1 MongoDB 简介 67
3.7 内容回顾与推荐阅读 69
3.8 参考文献 70
第4 章 智能问答——智能助手是如何炼成的 71
4.1 概述 73
4.2 问答系统的主要组成 77
4.3 文本问答系统 78
4.3.1 问题理解 78
4.3.2 知识检索 81
4.3.3 答案生成 83
4.4 社区问答系统 84
4.4.1 社区问答系统的结构 85
4.4.2 相似问题检索 86
4.4.3 答案过滤 86
4.5 多媒体问答系统 87
4.6 大型问答系统案例：IBM 沃森问答系统 89
4.6.1 沃森的总体结构 89
4.6.2 问题解析 90
4.6.3 知识储备 90
4.6.4 检索和候选答案生成 91
4.6.5 可信答案确定 92
4.7 内容回顾与推荐阅读 93
4.8 参考文献 94
第5 章 主题模型——机器的智能摘要利器 97
5.1 概述 99
5.2 主题模型出现的背景 100
5.3 第一个主题模型潜在语义分析 102
5.4 第一个正式的概率主题模型 104
5.5 第一个正式的贝叶斯主题模型 105
5.6 LDA 的概要介绍 106
5.6.1 LDA 的延伸理解——主题模型广义理解 109
5.6.2 模型求解 111
5.6.3 模型评估 112
5.6.4 模型选择：主题数目的确定 113
5.7 主题模型的变形与应用 114
5.7.1 基于LDA 的模型变种 114
5.7.2 基于LDA 的典型应用 115
5.7.3 一个基于主题模型的新浪名人话题排行榜应用 118
5.8 内容回顾与推荐阅读 122
5.9 参考文献 123
第6 章 个性化推荐系统——如何了解电脑背后的TA 129
6.1 概述 131
6.1.1 推荐系统的发展历史 132
6.1.2 推荐无处不在 133
6.1.3 从千人一面到千人千面 133
6.2 个性化推荐的基本问题 134
6.2.1 推荐系统的输入 135
6.2.2 推荐系统的输出 137
6.2.3 个性化推荐的形式化 137
6.2.4 推荐系统的三大核心问题 138
6.3 典型推荐算法浅析 139
6.3.1 推荐算法的分类 139
6.3.2 典型推荐算法介绍 140
6.3.3 基于矩阵分解的打分预测 146
6.3.4 推荐的可解释性 151
6.3.5 推荐算法的评价 153
6.3.6 我们走了多远 156
6.4 参考文献 160
第7 章 情感分析与意见挖掘——计算机如何了解人类情感 165
7.1 概述 167
7.2 情感分析的主要研究问题 172
7.3 情感分析的主要方法 175
7.3.1 构成情感和观点的基本元素 175
7.3.2 情感极性与情感词典 177
7.3.3 属性－观点对 182
7.3.4 情感分析 184
7.4 主要的情感词典资源 188
7.5 内容回顾与推荐阅读 189
7.6 参考文献 190
第8 章 面向社会媒体大数据的语言使用分析及应用 195
8.1 概述 197
8.2 面向社会媒体的自然语言使用分析 197
8.2.1 词汇的时空传播与演化 198
8.2.2 语言使用与个体差异 200
8.2.3 语言使用与社会地位 202
8.2.4 语言使用与群体分析 203
8.3 面向社会媒体的自然语言分析应用 206
8.3.1 社会预测 206
8.3.2 霸凌现象定量分析 207
8.4 未来研究的挑战与展望 208
8.5 参考文献 209
后 记 214
国际学术组织、学术会议与学术论文 214
国内学术组织、学术会议与学术论文 216
如何快速了解某个领域的研究进展 217
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学与工程技术丛书
推荐序
译者序
前言
致谢
关于技术评审人
第1章　机器学习简介 1
1.1　机器学习的起源 2
1.2　机器学习的使用与滥用 3
1.3　机器如何学习 5
1.3.1　抽象化和知识表达 6
1.3.2　一般化 7
1.3.3　评估学习的成功性 9
1.4　将机器学习应用于数据中的步骤 9
1.5　选择机器学习算法 10
1.5.1　考虑输入的数据 10
1.5.2　考虑机器学习算法的类型 11
1.5.3　为数据匹配合适的算法 13
1.6　使用R进行机器学习 13
1.7　总结 17
第2章　数据的管理和理解 18
2.1　R数据结构 18
2.2　向量 19
2.3　因子 20
2.3.1　列表 21
2.3.2　数据框 22
2.3.3　矩阵和数组 24
2.4　用R管理数据 25
2.4.1　保存和加载R数据结构 25
2.4.2　用CSV文件导入和保存数据 26
2.4.3　从SQL数据库导入数据 27
2.5　探索和理解数据 28
2.5.1　探索数据的结构	29
2.5.2　探索数值型变量 29
2.5.3　探索分类变量 37
2.5.4　探索变量之间的关系 39
2.6　总结 42
第3章　懒惰学习——使用近邻分类 44
3.1　理解使用近邻进行分类 45
3.1.1　kNN算法 45
3.1.2　为什么kNN算法是懒惰的 51
3.2　用kNN算法诊断乳腺癌 51
3.2.1　第1步——收集数据 51
3.2.2　第2步——探索和准备数据 52
3.2.3　第3步——基于数据训练模型 55
3.2.4　第4步——评估模型的性能 57
3.2.5　第5步——提高模型的性能 58
3.3　总结 60
第4章　概率学习——朴素贝叶斯分类 61
4.1　理解朴素贝叶斯 61
4.1.1　贝叶斯方法的基本概念 62
4.1.2　朴素贝叶斯算法 65
4.2　例子——基于贝叶斯算法的手机垃圾短信过滤 70
4.2.1　第1步——收集数据 70
4.2.2　第2步——探索和准备数据 71
4.2.3　数据准备——处理和分析文本数据 72
4.2.4　第3步——基于数据训练模型 78
4.2.5　第4步——评估模型的性能 79
4.2.6　第5步——提升模型的性能 80
4.3　总结 81
第5章　分而治之——应用决策树和规则进行分类 82
5.1　理解决策树 82
5.1.1　分而治之 83
5.1.2　C5.0决策树算法 86
5.2　例子——使用C5.0决策树识别高风险银行贷款 89
5.2.1　第1步——收集数据 89
5.2.2　第2步——探索和准备数据 89
5.2.3　第3步——基于数据训练模型 92
5.2.4　第4步——评估模型的性能 95
5.2.5　第5步——提高模型的性能 95
5.3　理解分类规则 98
5.3.1　独立而治之 99
5.3.2　单规则（1R）算法 101
5.3.3　RIPPER算法 103
5.3.4　来自决策树的规则 105
5.4　例子——应用规则学习识别有毒的蘑菇 105
5.4.1　第1步——收集数据 106
5.4.2　第2步——探索和准备数据 106
5.4.3　第3步——基于数据训练模型 107
5.4.4　第4步——评估模型的性能 109
5.4.5　第5步——提高模型的性能 109
5.5　总结 111
第6章　预测数值型数据——回归方法 113
6.1　理解回归 113
6.1.1　简单线性回归 115
6.1.2　普通最小二乘估计 117
6.1.3　相关系数 118
6.1.4　多元线性回归 120
6.2　例子——应用线性回归预测医疗费用 122
6.2.1　第1步——收集数据 122
6.2.2　第2步——探索和准备数据 123
6.2.3　第3步——基于数据训练模型 127
6.2.4　第4步——评估模型的性能 129
6.2.5　第5步——提高模型的性能 130
6.3　理解回归树和模型树 133
6.4　例子——用回归树和模型树估计葡萄酒的质量 135
6.4.1　第1步——收集数据 135
6.4.2　第2步——探索和准备数据 136
6.4.3　第3步——基于数据训练模型 137
6.4.4　第4步——评估模型的性能 140
6.4.5　第5步——提高模型的性能 142
6.5　总结 144
第7章　黑箱方法——神经网络和支持向量机 146
7.1　理解神经网络 146
7.1.1　从生物神经元到人工神经元 148
7.1.2　激活函数 148
7.1.3　网络拓扑 151
7.1.4　用后向传播训练神经网络 153
7.2　用人工神经网络对混凝土的强度进行建模 154
7.2.1　第1步——收集数据 154
7.2.2　第2步——探索和准备数据 155
7.2.3　第3步——基于数据训练模型 156
7.2.4　第4步——评估模型的性能 158
7.2.5　第5步——提高模型的性能 159
7.3　理解支持向量机 160
7.3.1　用超平面分类 161
7.3.2　寻找最大间隔 161
7.3.3　对非线性空间使用核函数 164
7.4　用支持向量机进行光学字符识别 165
7.4.1　第1步——收集数据 166
7.4.2　第2步——探索和准备数据 166
7.4.3　第3步——基于数据训练模型 167
7.4.4　第4步——评估模型的性能 169
7.4.5　第5步——提高模型的性能 170
7.5　总结 171
第8章　探寻模式——基于关联规则的购物篮分析 172
8.1　理解关联规则 172
8.2　例子——用关联规则确定经常一起购买的食品杂货 176
8.2.1　第1步——收集数据 176
8.2.2　第2步——探索和准备数据 177
8.2.3　第3步——基于数据训练模型 183
8.2.4　第4步——评估模型的性能 184
8.2.5　第5步——提高模型的性能 187
8.3　总结 189
第9章　寻找数据的分组——k均值聚类 191
9.1　理解聚类 191
9.1.1　聚类——一种机器学习任务 192
9.1.2　k均值聚类算法 193
9.1.3　用k均值聚类探寻青少年市场细分 198
9.1.4　第1步——收集数据 198
9.1.5　第2步——探索和准备数据 199
9.1.6　第3步——基于数据训练模型 202
9.1.7　第4步——评估模型的性能 204
9.1.8　第5步——提高模型的性能 206
9.2　总结 207
第10章　模型性能的评价 208
10.1　度量分类方法的性能 208
10.1.1　在R中处理分类预测数据 209
10.1.2　深入探讨混淆矩阵 211
10.1.3　使用混淆矩阵度量性能 212
10.1.4　准确度之外的其他性能评价指标 214
10.1.5　性能权衡的可视化 221
10.2　评估未来的性能 224
10.2.1　保持法 225
10.2.2　交叉验证 226
10.2.3　自助法抽样 229
10.3　总结 229
第11章　提高模型的性能 231
11.1　调整多个模型来提高性能 231
11.2　使用元学习来提高模型的性能 239
11.2.1　理解集成学习 239
11.2.2　bagging 241
11.2.3　boosting 243
11.2.4　随机森林 244
11.3　总结 248
第12章　其他机器学习主题 249
12.1　分析专用数据 250
12.1.1　用RCurl添加包从网上获取数据 250
12.1.2　用XML添加包读/写XML格式数据 250
12.1.3　用rjson添加包读/写JSON 251
12.1.4　用xlsx添加包读/写Microsoft Excel电子表格 251
12.1.5　生物信息学数据 251
12.1.6　社交网络数据和图数据 252
12.2　提高R语言的性能 252
12.2.1　处理非常大的数据集 253
12.2.2　使用并行处理来加快学习过程 254
12.2.3　GPU计算 257
12.2.4　部署最优的学习算法 257
12.3　总结 258
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学与工程技术丛书
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习方法
第1章  绪论  1.1  机器学习概念  1.2  机器学习系统    1.2.1  学习系统模型    1.2.2  机器学习系统结构  1.3  机器学习方法分类    1.3.1  监督学习    1.3.2  非监督学习    1.3.3  强化学习  1.4  一般性定理与规则    1.4.1  大多数原则    1.4.2  奥卡姆剃刀原理    1.4.3  无免费午餐定理  1.5  学习算法的评价    1.5.1  最短描述长度    1.5.2  预测精度分析    1.5.3  交叉验证法  1.6  本书各章概要第2章  最近邻规则第3章  贝叶斯学习第4章  决策树第5章  基于事例推理的学习第6章  关联规则学习第7章  神经网络第8章  支持向量机第9章  遗传算法第10章  集成学习第11章  基于纠错编码的机器学习第12章  聚类分析第13章  强化学习附录A  数据集描述参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器学习方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大演算
【好評推薦】
【推薦序】　大演算顛覆世界，也顛覆我的看法／林泰宏
【推薦序】　想跟上資訊革命時代的多變世界，本書是你的敲門磚／張宗堯
【推薦序】　從5萬呎的高空鳥瞰機器學習，望見未來／陳明義
【推薦序】　讓我們站在巨量資料的肩膀上，看得更高更遠／趙坤茂
【推薦序】　大演算，是飽覽大數據與機器學習的最佳指南／謝孫源
【推薦序】　大演算強化「工業3.5」，讓臺灣在物聯網時代中卡位／簡禎富
【前言】　機器學習早已融入你我的生活
第1章　機器學習的革命
進入機器學習的世界／企業為何擁抱機器學習？
增加科學方法的馬力／十億個比爾．柯林頓
一則透過傳統攻防，二則透過網路之戰
我們將走向何方？
第2章　大演算
從神經科學方面獲得的論證／從演化方面獲得的論證
從物理方面獲得的論證／從統計學方面獲得的論證
從電腦科學方面獲得的論證／機器學習專家與知識工程師
天鵝咬了機器人／大演算是隻狐狸還是刺猬？
什麼是危機所在？／一個不同的萬有理論
候選者還不夠格／機器學習的五大學派
第3章　人類的歸納問題
約會，還是不約會？／「沒有免費的午餐」定理
啟動知識學習機／如何讓世界規則化
在暗黑和幻覺之間／你可以相信的準確性
歸納法是逆向演繹法則／學習治療癌症
二十個問題的遊戲／符號理論學派
第4章　你的大腦是如何學習？
感知器的潮起潮落／物理學家用玻璃製造大腦
世界上最重要的曲線／在多維空間的爬山演算法
感知器的復仇／細胞的完整模型／更深入大腦
第5章　演化：自然學習演算法
達爾文的演算法／探索與利用的困境
適者生存的程式／性交配行為是為了什麼？
培育天性／學習最快的人勝出
第6章　貝葉斯牧師的教堂
運行世界的定理／所有模型都是錯的，但有些還是有用
從《尤金．奧涅金》到Siri手機語音行動祕書
一切都是相關聯的，但不是直接的／推理問題
學習貝氏的方法／馬爾可夫權衡事證
邏輯與機率：命運多舛的一對
第7章　你就是相似的你
如果你能與我相匹配／維度的詛咒
平面上的蛇形分割線／攀登階梯
旭日東升，光彩奪目
第8章　學習無師自通
物以類聚／發掘數據資料的形狀
享樂主義的機器人／孰能生巧
學習建立關聯
第9章　每一塊拼圖各得其所
跳脫許多模型，整合成一體／大演算
馬爾可夫邏輯網路／從休謨到你的家事機器人
行星尺度的機器學習／醫生如今會診斷你了
第10章　這是機器學習的世界
性、謊言和機器學習／數位鏡／一種模型的社會
分享或不分享，如何分享與在何處分享
類神經網路偷了我的工作／不是用人類來作戰
Google＋大演算=天網（Skynet）？
演化，第二部分
【結語】 搭上機器學習的船，航向未來
誌謝
延伸閱讀
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大演算
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于复杂网络的机器学习方法
译者序
前言
作者简介
符号列表
第1章概述
1.1背景
1.2本书主要内容
1.3本书结构
参考文献
第2章复杂网络
2.1图论简介
2.1.1图的定义
2.1.2图的连通性
2.1.3路径和环路
2.1.4子图
2.1.5树和森林
2.1.6图的矩阵表示
2.2网络演化模型
2.2.1随机网络
2.2.2小世界网络
2.2.3无标度网络
2.2.4随机聚类网络
2.2.5核心边缘网络
2.3复杂网络的统计描述
2.3.1度和度相关性
2.3.2距离和路径
2.3.3网络结构
2.3.4网络中心性
2.3.5复杂网络度量方法的分类
2.4复杂网络上的动力学过程
2.4.1随机游走
2.4.2惰性随机游走
2.4.3自避行走
2.4.4游客漫步
2.4.5流行病传播
2.5本章小结
参考文献
第3章机器学习
3.1引言
3.2监督学习
3.2.1数学表达式和基本假设
3.2.2主要算法
3.3无监督学习
3.3.1数学表达式和基本假设
3.3.2主要算法
3.4半监督学习
3.4.1研究目的
3.4.2数学表达式和基本假设
3.4.3主要算法
3.5基于网络的机器学习方法概述
3.6本章小结
参考文献
第4章网络构建技术
4.1引言
4.2相似性与相异性
4.2.1定义
4.2.2基于向量形式的相似性函数实例
4.3向量数据的网络转化
4.3.1k近邻和半径网络
4.3.2k近邻和半径组合的网络构建技术
4.3.3b匹配网络
4.3.4线性邻域网络
4.3.5松弛线性邻域网络
4.3.6聚类启发式网络
4.3.7重叠直方图网络
4.3.8其他网络构建技术
4.4时间序列数据的网络转化
4.4.1周期网络
4.4.2相关网络
4.4.3循环网络
4.4.4转移网络
4.5网络构建方法分类
4.6非结构化数据网络转化的难点
4.7本章小结
参考文献
第5章基于网络的监督学习
5.1引言
5.2典型的基于网络的监督学习技术
5.2.1基于k关联图的分类算法
5.2.2网络学习工具：NetKit
5.2.3易访问启发式的分类算法
5.3本章小结
参考文献
第6章基于网络的无监督学习
6.1引言
6.2社团检测算法
6.2.1相关概念
6.2.2数学表达式和基本假设
6.2.3前沿技术综述
6.2.4社团检测基准
6.3典型的基于网络的无监督学习技术
6.3.1介数
6.3.2模块度最大化
6.3.3谱平分法
6.3.4基于粒子竞争模型的社团检测
6.3.5变色龙算法
6.3.6基于空间变换和群体动力学的社团检测
6.3.7同步方法
6.3.8重叠社团挖掘
6.3.9网络嵌入与降维
6.4本章小结
参考文献
第7章基于网络的半监督学习
7.1引言
7.2数学假设
7.3典型的基于网络的半监督学习技术
7.3.1最大流和最小割
7.3.2高斯随机场和调和函数
7.3.3Tikhonov正则化框架
7.3.4局部和全局一致性算法
7.3.5附着法
7.3.6模块化方法
7.3.7相互作用力
7.3.8判别式游走
7.4本章小结
参考文献
第8章基于网络的监督学习专题研究：高级数据分类
8.1引言
8.2问题提出
8.3高级分类模型
8.3.1高级分类模型的总体思路
8.3.2混合分类框架的构建
8.4高级分类器的构建方法
8.4.1传统的基于网络度量方法的高级分类器构建
8.4.2基于随机游走的高级分类器构建
8.5高级分类器的数值分析
8.5.1高级分类器应用样本
8.5.2参数敏感性分析
8.6应用：手写数字识别
8.6.1相关研究
8.6.2手写数字数据集MNIST
8.6.3图像相似性计算算法
8.6.4混合分类框架中的低级分类技术
8.6.5混合分类器的性能
8.6.6手写数字识别样本8.7本章小结
参考文献
第9章基于网络的无监督学习专题研究：随机竞争学习
9.1引言
9.2随机竞争学习算法模型
9.2.1模型原理
9.2.2转移矩阵的推导
9.2.3随机非线性动力系统的定义
9.2.4计算社团数目的方法
9.2.5重叠结构的检测方法
9.2.6参数敏感性分析
9.2.7收敛分析
9.3模型的理论分析
9.3.1数学分析
9.3.2粒子竞争模型与传统的多粒子随机游走
9.3.3样本分析
9.4重叠节点及社团检测的数值分析
9.4.1扎卡里空手道俱乐部网络
9.4.2海豚社交网络
9.4.3《悲惨世界》人物关系网络
9.5应用：手写数字识别和字母聚类
9.5.1数据集情况
9.5.2最优粒子数和集簇数
9.5.3手写数字或字母聚类
9.6本章小结
参考文献
第10章基于网络的半监督学习专题研究：随机竞争合作学习
10.1引言
10.2随机竞争合作模型
10.2.1半监督学习与无监督学习的差异
10.2.2半监督学习环境
10.2.3竞争转移矩阵的修正
10.2.4系统初始条件的修正
10.3模型的理论分析
10.3.1数学分析
10.3.2样本分析
10.4模型的数值分析
10.4.1人工合成数据集上的模拟
10.4.2真实数据集上的模拟
10.5应用：错误标记数据集上的错误标签传播检测和预防
10.5.1问题提出
10.5.2错误标记训练集的检测
10.5.3错误标签传播的预防
10.5.4竞争合作模型学习系统的修正
10.5.5参数敏感性分析
10.5.6计算机模拟
10.6本章小结
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于复杂网络的机器学习方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计强化学习：现代机器学习方法
译者序
序
前言
作者简介
第一部分　简介
第1章　强化学习介绍3
1.1　强化学习3
1.2　数学形式化8
1.3　本书结构11
1.3.1　模型无关策略迭代11
1.3.2　模型无关策略搜索12
1.3.3　基于模型的强化学习13
第二部分　模型无关策略迭代
第2章　基于值函数近似的策略迭代17
2.1　值函数17
2.1.1　状态值函数17
2.1.2　状态-动作值函数18
2.2　最小二乘策略迭代19
2.2.1　瞬时奖赏回归20
2.2.2　算法21
2.2.3　正则化23
2.2.4　模型选择25
2.3　本章小结26
第3章　值函数近似中的基函数设计27
3.1　图中的高斯核27
3.1.1　MDP-诱导图27
3.1.2　通用高斯核28
3.1.3　测地线高斯核29
3.1.4　扩展到连续状态空间30
3.2　图解说明30
3.2.1　配置30
3.2.2　测地线高斯核31
3.2.3　通用高斯核33
3.2.4　图拉普拉斯特征基33
3.2.5　扩散小波35
3.3　数值示例35
3.3.1　机器人手臂控制35
3.3.2　机器人导航39
3.4　本章小结46
第4章　策略迭代中的样本重用47
4.1　形式化47
4.2　离策略值函数近似48
4.2.1　片段重要性加权49
4.2.2　每次决策的重要性加权50
4.2.3　自适应的每次决策重要性加权50
4.2.4　图解说明51
4.3　展平参数的自动选择54
4.3.1　重要性加权交叉验证54
4.3.2　图解说明55
4.4　样本重用策略迭代56
4.4.1　算法56
4.4.2　图解说明56
4.5　数值示例58
4.5.1　倒立摆58
4.5.2　小车爬山61
4.6　本章小结64
第5章　策略迭代中的主动学习65
5.1　主动学习的高效探索65
5.1.1　问题配置65
5.1.2　泛化误差的分解66
5.1.3　估计泛化误差67
5.1.4　设计采样策略68
5.1.5　图解说明69
5.2　主动策略迭代72
5.2.1　具有主动学习的样本重用策略迭代72
5.2.2　图解说明73
5.3　数值示例74
5.4　本章小结76
第6章　鲁棒策略迭代79
6.1　策略迭代中的鲁棒性和可靠性79
6.1.1　鲁棒性79
6.1.2　可靠性80
6.2　最小绝对策略迭代81
6.2.1　算法81
6.2.2　图解说明81
6.2.3　性质82
6.3　数值示例83
6.4　可能的拓展88
6.4.1　Huber损失88
6.4.2　pinball损失89
6.4.3　deadzone-linear损失90
6.4.4　切比雪夫逼近90
6.4.5　条件风险值91
6.5　本章小结92
第三部分　模型无关策略搜索
第7章　梯度上升的直接策略搜索95
7.1　形式化95
7.2　梯度方法96
7.2.1　梯度上升96
7.2.2　方差约简的基线减法98
7.2.3　梯度估计量的方差分析99
7.3　自然梯度法101
7.3.1　自然梯度上升101
7.3.2　图解说明103
7.4　计算机图形中的应用：艺术家智能体104
7.4.1　东方山水画绘画104
7.4.2　状态、动作和瞬时奖赏的设计106
7.4.3　实验结果111
7.5　本章小结113
第8章　期望最大化的直接策略搜索117
8.1　期望最大化方法117
8.2　样本重用119
8.2.1　片段重要性加权119
8.2.2　每次决策的重要性加权122
8.2.3　自适应的每次决策重要性加权123
8.2.4　展平参数的自动选择123
8.2.5　样本重用的加权奖赏回归125
8.3　数值示例125
8.4　本章小结131
第9章　策略优先搜索133
9.1　形式化133
9.2　基于参数探索的策略梯度134
9.2.1　策略优先的梯度上升134
9.2.2　方差约简的基线减法135
9.2.3　梯度估计量的方差分析136
9.2.4　数值示例138
9.3　策略优先搜索中的样本重用142
9.3.1　重要性加权142
9.3.2　基线减法的方差约简144
9.3.3　数值示例146
9.4　本章小结153
第四部分　基于模型的强化学习
第10章　转移模型估计157
10.1　条件密度估计157
10.1.1　基于回归的方法157
10.1.2　ε-邻域核密度估计158
10.1.3　最小二乘条件密度估计159
10.2　基于模型的强化学习161
10.3　数值示例162
10.3.1　连续型链条游走162
10.3.2　人形机器人控制167
10.4　本章小结171
第11章　转移模型估计的维度约简173
11.1　充分维度约简173
11.2　平方损失条件熵173
11.2.1　条件独立174
11.2.2　利用SCE进行维度约简175
11.2.3　SCE与平方损失互信息的关系176
11.3　数值示例176
11.3.1　人工和标准数据集176
11.3.2　人形机器人179
11.4　本章小结182
参考文献183
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计强化学习：现代机器学习方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>文本作者身份识别
第1章绪论
1.1基本概念
1.1.1作者身份识别
1.1.2作者身份描述
1.1.3作者聚类分析
1.1.4机器学习
1.1.5计算语言学
1.2作者身份识别研究
1.2.1文体风格特征研究内容
1.2.2作者身份建模技术研究内容
1.3作者身份建模基本方法
1.3.1基于侧面的作者身份建模
1.3.2基于实例的作者身份建模
1.4作者身份识别面临的主要问题
1.5本章小结
第2章作者身份分析应用领域
2.1英美文学作品作者身份识别
2.2中文作品作者身份识别
2.2.1中文自动分词
2.2.2中文自动分词主要方法
2.2.3中文作者身份识别相关研究
2.3其他语种作者身份识别
2.4网络文本作者身份识别
2.5作者身份属性分析
2.6作者身份法庭取证
2.7本章小结
第3章文体风格特征
3.1文体风格特征类别
3.1.1一元和多元文体风格特征
3.1.2多层面文体风格特征
3.1.3文体风格特征评述
3.2文体风格特征选择
3.3本章小结
第4章作者身份识别算法
4.1主要算法
4.1.1支持向量机算法
4.1.2朴素贝叶斯算法
4.1.3最近邻算法
4.1.4决策树算法
4.1.5神经网络算法
4.1.6其他方法
4.2性能评价指标
4.3实验平台
4.4本章小结
第5章英文博客作者身份识别
5.1博客作者身份研究
5.2英文博客作者文体特征模型
5.2.1词汇层面特征
5.2.2浅层句法特征
5.2.3基于依存关系的特征
5.2.4基于词性标注的特征
5.2.5结构层面特征
5.3博客作者身份识别实验
5.3.1数据准备
5.3.2特征组合实验
5.3.3单独使用各组特征实验
5.4本章小结
第6章中文微博作者身份识别
6.1微博作者身份相关研究
6.1.1微博作者身份研究现状
6.1.2中文微博作者身份研究现状
6.2研究思路
6.3中文微博作者文体特征模型
6.3.1词汇特征
6.3.2标点特征
6.3.3微博特征
6.3.4功能词特征
6.3.5词性标注特征
6.3.6依存句法特征
6.4中文微博作者身份识别实验
6.4.1数据准备
6.4.23位作者LibSVM实验结果及分析
6.4.38位作者身份识别实验
6.4.4特征集组合C4.5实验
6.4.5单独使用各组特征C4.5实验
6.4.6单独使用各组特征LibSVM实验
6.4.7特征选择实验
6.5本章小结
第7章基于依存关系的中文微博作者性别识别
7.1作者性别属性相关研究
7.2作者性别文体特征
7.2.1依存关系
7.2.2性别识别主要文体特征
7.3微博作者性别识别实验
7.3.1数据准备
7.3.2LibSVM、NBC、IBK和C4.5中文微博
作者性别识别
7.3.3单独使用各组特征实验
7.4本章小结
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>文本作者身份识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB金融算法分析实战
第1篇 MATLAB常用算法应用设计
第1章 MATLAB入门与提高 2
1.1 矩阵运算 4
1.2 放大局部视图 6
1.3 Monte Carlo方法 7
1.4 金融工具箱绘图函数的使用 9
第2章 MATLAB高级应用 32
2.1 正余弦函数计算 32
2.2 pcode加密 32
2.3 基本GUI设计 33
2.4 GUI的优化布局 41
2.5 日期格式函数 43
2.6 日期转化函数 45
2.7 创建一个金融时间数据序列 47
2.8 股票技术分析图函数使用 49
第3章 时间序列数据处理 55
3.1 平均绝对离差 55
3.2 序列最大值 57
3.3 序列最小值 60
3.4 简单移动平均值 62
3.5 动态移动平均值 65
3.6 指数平滑移动平均值 67
3.7 指数移动平均值 69
第4章 量化投资趋向指标 73
4.1 升降线指标 73
4.2 动力指标 76
4.3 变动速率线指标 77
4.4 瀑布线指标 79
4.5 上升动向指标 81
4.6 下降动向指标 83
4.7 动向平均数指标 85
4.8 多空指数指标 88
4.9 佳庆指标 90
4.10 市场趋势指标 92
4.11 方向标准离差指数指标 94
4.12 平均线差 97
4.13 趋向指标 98
4.14 简易波动指标 102
4.15 鬼道线指标 104
4.16 绝路航标指标 106
4.17 加速线指标 109
4.18 平滑异同平均指标 111
4.19 快速异同平均指标 113
4.20 强弱值指标 115
4.21 三重指数平滑平均线指标 117
4.22 终极指标 119
4.23 变异平均线指标 122
第5章 量化投资反趋向指标 124
5.1 幅度涨速指标 124
5.2 动态买卖人气指标 126
5.3 布林极限指标 128
5.4 乖离率指标 131
5.5 异同离差乖离率指标 133
5.6 顺势指标 135
5.7 市场能量指标 137
5.8 多空线指标 139
5.9 区间震荡线指标 141
5.10 分水岭指标 142
5.11 随机指标 144
5.12 威廉指标 148
5.13 L威廉指标 150
5.14 变动速率指标 152
5.15 相对强弱指标 153
5.16 慢速随机指标 156
5.17 摆动指标 159
5.18 动向速度比率指标 162
5.19 引力线指标 164
5.20 布林极限宽度指标 166
第2篇 MATLAB机器学习算法应用设计
第6章 BP神经网络工具箱上证指数预测 170
6.1 BP神经网络模型及其基本原理 170
6.2 MATLAB BP神经网络工具箱 171
6.3 BP神经网络执行流程 173
6.4 基于BP网络的上证指数预测 174
6.5 改进分析 178
第7章 BP神经网络工具箱多指标预测 186
7.1 BP神经网络 186
7.2 多指标选取 187
7.3 基于趋势指标的BP网络预测 195
7.4 基于反趋势指标的BP网络预测 204
7.5 基于趋势和反趋势指标的BP网络预测 211
第8章 RBF神经网络多指标预测 216
8.1 RBF神经网络 216
8.2 RBF网络结构 216
8.3 多指标选取 219
8.4 基于趋势指标的RBF网络预测 220
8.5 基于反趋势指标的RBF网络预测 224
8.6 基于趋势和反趋势指标的RBF网络预测 228
第9章 Hopfield神经网络多指标预测 232
9.1 Hopfield神经网络 232
9.2 多指标选取 234
9.3 基于趋势指标的Hopfield网络预测 234
9.4 基于反趋势指标的Hopfield网络预测 237
9.5 基于趋势和反趋势指标的Hopfield网络预测 239
第10章 马尔可夫（Markov）链上证指数预测 242
10.1 马尔可夫链模型 242
10.2 马尔可夫链模型流程 242
10.3 马尔可夫链预测 243
10.4 隐马尔可夫模型函数表 253
第11章 灰色理论下的上证指数预测 254
11.1 灰色理论分析 254
11.2 灰色关联分析流程 254
11.3 多指标灰色关联度计算 255
11.4 灰色预测模型流程 259
11.5 ACCER幅度涨速指标灰色预测 260
第12章 指数平滑下的上证指数预测 263
12.1 指数平滑分析 263
12.2 指数平滑仿真 265
第13章 支持向量机SVM下的涨跌预测 274
第14章 贝叶斯（Bayes）网络多指标预测 305
第15章 Pareto多目标优化分析 325
参考文献 353
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB金融算法分析实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>程序化交易高级教程
第一章 导论
第一节 机器学习导论
第二节 金融交易如何使用机器学习方法
第三节 本书内容和结构
第一篇机器学习交易基础
第二章 机器学习基础
第一节 机器学习的基本原理
第二节 机器学习方法分类
第三节 机器学习的常用算法
第三章 Python编程基础
第一节 Python的特点和发展
第二节 Python的环境搭建
第三节 Python的基本语法
第四节 Python的数据处理
第五节 Python的文件存取
第四章 基于Python的机器学习软件包
第一节 机器学习工具包Scikit-learn
第二节 深度学习框架TensorFlow
第三节 神经网络训练框架 Keras
第五章 国信iQuant量化交易平台
第一节 国信iQuant的基本功能
第二节 投资研究
第三节 向导式策略生成器
第四节 我的策略
第五节 策略常用 API
第六章 交易策略学习模型的数据准备
第一节 数据清理
第二节 数据标准化
第三节 数据中性化
第四节 独热编码
第二篇机器学习回归分析
第七章 线性回归估值选股模型
第一节 线性回归分析的基本思想
第二节 线性回归算法实现
第三节 线性回归估值选股模型
第八章 逻辑回归收益率预测选股模型
第一节 逻辑回归的基本思想
第二节 逻辑回归的算法实现
第三节 逻辑回归收益率预测选股模型
第三篇机器学习分类模型
第九章 决策树分类择时模型
第一节 决策树分类模型的基本原理
第二节 决策树的Python程序实现
第三节 决策树分类模型的训练和测试
第四节 决策树分类模型的程序化交易应用
第十章 朴素贝叶斯分类择时模型
第一节 朴素贝叶斯分类模型的基本原理
第二节 朴素贝叶斯的Python程序实现
第三节 朴素贝叶斯模型的程序化交易应用
第十一章 支持向量机分类择时模型
第一节 支持向量机分类模型的基本原理
第二节 支持向量机分类模型的Python程序实现
第三节 支持向量机分类模型的结果评价
第四篇机器学习聚类和关联分析
第十二章 K均值聚类分析选股模型
第一节 K均值聚类分析的原理
第二节 K均值聚类分析程序
第三节 K均值多因子选股策略
第十三章 Apriori股票关联分析模型
第一节 Apriori算法的基本原理
第二节 Apriori算法的Python代码
第三节 利用 Apriori算法挖掘高相关度股票
第五篇神经网络学习
第十四章 BP神经网络择时模型
第一节 BP神经网络择时模型的基本原理
第二节 BP神经网络择时模型的Python编程
第三节 BP神经网络择时交易案例
第四节 BP神经网络择时模型在国信iQuant的应用
第十五章 循环神经网络择时模型
第一节 循环神经网络择时模型的基本原理
第二节 循环神经网络择时模型的Python编程
第三节 循环神经网络择时交易案例
第十六章 长短期记忆择时交易模型
第一节 长短期记忆择时交易模型基本原理
第二节 长短期记忆择时交易模型的Python编程
第三节 长短期记忆择时交易案例
第十七章 卷积神经网络择时交易模型
第一节 卷积神经网络择时交易模型基本原理
第二节 卷积神经网络择时交易模型的Python程序实现
第三节 卷积神经网络择时交易案例
第十八章 结语
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>程序化交易高级教程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow移动端机器学习实战
第1章  机器学习和TensorFlow简述	1
1.1  机器学习和TensorFlow的历史及发展现状	1
1.1.1  人工智能和机器学习	1
1.1.2  TensorFlow	3
1.1.3  TensorFlow Mobile	5
1.1.4  TensorFlow Lite	5
1.2  在移动设备上运行机器学习的应用	6
1.2.1  生态和现状	7
1.2.2  从移动优先到人工智能优先	8
1.2.3  人工智能的发展	9
1.2.4  在移动设备上进行机器学习的难点和挑战	9
1.2.5  TPU	10
1.3  机器学习框架	11
1.3.1  CAFFE2	11
1.3.2  Android NNAPI	12
1.3.3  CoreML	12
1.3.4  树莓派（Raspberry Pi）	13
第2章  构建开发环境	14
2.1  开发主机和设备的选择	14
2.2  在网络代理环境下开发	15
2.3  集成开发环境IDE	16
2.3.1  Android Studio	16
2.3.2  Visual Studio Code	16
2.3.3  其他IDE	18
2.4  构建工具Bazel	18
2.4.1  Bazel生成调试	19
2.4.2  Bazel Query命令	20
2.5  装载TensorFlow	20
2.6  文档	25
第3章  基于移动端的机器学习的开发方式和流程	26
3.1  开发方式和流程简介	26
3.2  使用TPU进行训练	28
3.3  设备端进行机器学习训练	35
3.4  使用TensorFlow Serving优化TensorFlow模型	41
3.4.1  训练和导出TensorFlow模型	42
3.4.2  使用标准TensorFlow ModelServer加载导出的模型	50
3.4.3  测试服务器	50
3.5  TensorFlow扩展（Extended）	54
第4章  构建TensorFlow Mobile	55
4.1  TensorFlow Mobile的历史	55
4.2  TensorFlow代码结构	55
4.3  构建及运行	61
4.3.1  代码的流程	67
4.3.2  代码的依赖性	68
4.3.3  性能和代码跟踪	69
第5章  用TensorFlow Mobile构建机器学习应用	71
5.1  准备工作	71
5.2  图像分类（Image Classification）	74
5.2.1  应用	74
5.2.2  模型	85
5.3  物体检测（Object Detection）	87
5.3.1  应用	87
5.3.2  模型	92
5.4  时尚渲染（Stylization）	95
5.4.1  应用	95
5.4.2  模型	96
5.5  声音识别（Speech Recognization）	96
5.5.1  应用	96
5.5.2  模型	99
第6章  TensorFlow Lite的架构	101
6.1  模型格式	102
6.1.1  Protocol Buffer	102
6.1.2  FlatBuffers	105
6.1.3  模型结构	112
6.1.4  转换器（Toco）	113
6.1.5  解析器（Interpreter）	119
6.2  底层结构和设计	123
6.2.1  设计目标	123
6.2.2  错误反馈	124
6.2.3  装载模型	125
6.2.4  运行模型	126
6.2.5  定制演算子（CUSTOM Ops）	128
6.2.6  定制内核	132
6.3  工具	133
6.3.1  图像标注（label_image）	133
6.3.2  最小集成（Minimal）	143
6.3.3  Graphviz	143
6.3.4  模型评效	148
第7章  用TensorFlow Lite构建机器学习应用	151
7.1  模型设计	151
7.1.1  使用预先训练的模型	151
7.1.2  重新训练	152
7.1.3  使用瓶颈（Bottleneck）	154
7.2  开发应用	158
7.2.1  程序接口	158
7.2.2  线程和性能	162
7.2.3  模型优化	163
7.3  TensorFlow Lite的应用	170
7.3.1  声音识别	173
7.3.2  图像识别	177
7.4  TensorFlow Lite使用GPU	178
7.4.1  GPU与CPU性能比较	178
7.4.2  开发GPU代理（Delegate）	178
7.5  训练模型	182
7.5.1  仿真器	183
7.5.2  构建执行文件	183
第8章  移动端的机器学习开发	186
8.1  其他设备的支持	186
8.1.1  在iOS上运行TensorFlow的应用	186
8.1.2  在树莓派上运行TensorFlow	189
8.2  设计和优化模型	190
8.2.1  模型大小	191
8.2.2  运行速度	192
8.2.3  可视化模型	196
8.2.4  线程	196
8.2.5  二进制文件大小	197
8.2.6  重新训练移动数据	197
8.2.7  优化模型加载	198
8.2.8  保护模型文件	198
8.2.9  量化计算	199
8.2.10  使用量化计算	202
8.3  设计机器学习应用程序要点	207
第9章  TensorFlow的硬件加速	209
9.1  神经网络接口	209
9.1.1  了解Neural Networks API运行时	210
9.1.2  Neural Networks API编程模型	211
9.1.3  NNAPI 实现的实例	213
9.2  硬件加速	222
9.2.1  高通网络处理器	223
9.2.2  华为HiAI Engine	229
9.2.3  简要比较	235
9.2.4  开放式神经网络交换格式	236
第10章  机器学习应用框架	237
10.1  ML Kit	237
10.1.1  面部识别（Face Detection）	242
10.1.2  文本识别	247
10.1.3  条形码识别	248
10.2  联合学习（Federated Learning）	248
第11章  基于移动设备的机器学习的未来	252
11.1  TensorFlow 2.0和路线图	252
11.1.1  更简单的开发模型	253
11.1.2  更可靠的跨平台的模型发布	254
11.1.3  TensorFlow Lite	254
11.1.4  TensorFlow 1.0 和TensorFlow 2.0的不同	255
11.2  人工智能的发展方向	255
11.2.1  提高人工智能的可解释性	255
11.2.2  贡献社会	256
11.2.3  改善生活	258
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow移动端机器学习实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计分析：从小数据到大数据
目录
第1 部分  数据分析准备
第1 章  从业务到统计
1.1  业务需求从哪来 / 002
1.1.1  学习业务的最快途径：阅读运营报告 / 002
1.1.2  当务之急：研究痛点 / 004
1.1.3  数据分析之锚：未来战略方向 / 005
1.1.4  对数据分析“小白”的有益建议 / 005
1.2  从小数据到大数据：数据体量与信息分布 / 008
1.2.1  实验室：理论验证 / 009
1.2.2  问卷：理论验证+ 探索 / 011
1.2.3  数据库：业务验证+ 探索 / 012
1.2.4  数据信息与统计模型 / 013
1.2.5  算法应用：是否跨界 / 015
1.2.6  算法特征：角色 / 016
1.3  数据分析流程的启示 / 019
1.3.1  假设：验证与归因 / 021
1.3.2  小概率：黑天鹅的不确定 / 025
1.3.3  抽样技术：经济是根本 / 026
1.3.4  选择模型：方法论 / 028
1.3.5  显著性判断：可证伪 / 029
第2 章  变量角色与描述
2.1  如何描述变量 / 032
2.1.1  分类变量与连续变量的分界线 / 032
2.1.2  分类变量及可视化 / 033
2.1.3  连续变量及可视化 / 037
2.2  因变量的测量 / 040
2.2.1  测量级别问题 / 040
2.2.2  是否存在测量误差 / 045
2.2.3  谁会成为“主角” / 047
2.2.4  y 的量化场景 / 050
2.3  自变量的选择 / 053
2.3.1  验证性：x 的选择 / 054
2.3.2  探索性：x 的选择 / 054
第3 章  数据预分析
3.1  填补缺失 / 056
3.1.1  描述缺失数据：行、列、单元格 / 056
3.1.2  缺失类型：随机性 / 060
3.1.3  小数据填补方案：精确性探讨 / 061
3.1.4  大数据填补方案：速度问题探讨 / 068
3.2  处理异常值 / 069
3.2.1  单变量与双变量异常 / 069
3.2.2  无监督异常：聚类分析 / 070
3.2.3  监督异常：回归残差分析 / 073
3.2.4  小数据与大数据如何看待异常值 / 076
3.3  消除共线性 / 080
3.3.1  共线性及其危害 / 081
3.3.2  小数据的方案：岭回归 / 082
3.3.3  大数据方案：项目合并与逐步回归 / 084
3.4  内生性问题 / 088
3.4.1  内生性及其危害 / 088
3.4.2  问题核心：特征选择 / 089
3.4.3  三驾马车之一：数据库的应对策略 / 094
3.5  变量变换技术 / 102
3.5.1  正态分布变换：对数变换 / 102
3.5.2  从0 到1：老板最喜欢的符号% / 104
3.5.3  强异常值：秩的应用 / 105
3.5.4  量纲：标准化变换 / 106
3.6  编码技术 / 107
3.6.1  为什么需要分箱化 / 107
3.6.2  分箱技术要义：数据拐点 / 111
3.7  避免过拟合 / 113
3.7.1  导致过拟合：行列问题 / 113
3.7.2  小数据为什么不谈过拟合 / 114
3.7.3  避免过拟合：方法学 / 115
第２部分  构建模型与修正技术
第4 章  线性回归与统计家族
4.1  差异性问题：方差分析 / 121
4.1.1  差异的来源：主效应 / 121
4.1.2  差异的来源：交互效应 / 128
4.1.3  交互性解释：交互效应图制作 / 129
4.2  结构性问题：回归分析 / 131
4.2.1  回归分析流程 / 131
4.2.2  相关的风向标作用：文氏图 / 135
4.2.3  偏相关的归因：中介和调节 / 137
4.2.4  回归系数解释：偏回归图 / 142
4.2.5  如何相信R2 / 149
4.2.6  以残差看假设 / 152
4.2.7  残差信息的有和无 / 158
4.2.8  小数据需求归纳：重结构轻预测 / 158
4.3  算法进化REG：小数据专家的努力 / 159
4.3.1  算法1.0：精确度+ 结构 / 160
4.3.2  算法2.0：精确度+ 结构与预测 / 163
4.3.3  算法3.0：速度+ 预测 / 164
4.3.4  算法4.0：加速度 / 167
第5 章  Logistic 回归与统计家族
5.1  预测性问题：Logistic 回归 / 168
5.1.1  卡方的风向标作用 / 169
5.1.2  不一样的R2：预测分类表 / 170
5.1.3  回归系数解释：or 值与rr 值 / 171
5.1.4  修正技术：是x 而不是y / 174
5.1.5  大数据需求归纳：轻结构重预测 / 177
5.2  算法进化Logistic：大数据与智能 / 178
5.2.1  算法1.0：稳定性+ 结构 / 178
5.2.2  算法2.0：稳定性+ 结构与预测 / 179
5.2.3  算法3.0：速度+ 预测 / 179
5.2.4  算法4.0：加速度 / 179
5.3  算法3.0 的榜样：神经网络 / 180
5.3.1  神经网络算法 / 180
5.3.2  DM 算法预分析 / 183
5.3.3  基于神经网络的常规应用 / 185
第6 章  降维技术
6.1  主成分回归与压缩技术 / 192
6.1.1  四驾马车：实验室、问卷、数据库、云 / 192
6.1.2  主成分算法：降维 / 192
6.1.3  主成分与因子：谁应该有名字？ / 194
6.1.4  主成分回归：“回归+ 回归”模式 / 196
6.2  对应分析：一个市场调查案例 / 197
6.2.1  案例背景介绍 / 197
6.2.2  模型预分析 / 199
6.2.3  构建模型：“广义”双标图 / 203
6.2.4  结论及营销 / 214
第３部分  模型应用与评估
第7 章  回归类模型应用
7.1  结构性问题：偏回归系数 / 216
7.1.1  单结构：偏的意义 / 216
7.1.2  整体结构：条件规则 / 217
7.2  预测性问题：估计值 / 217
7.2.1  老样本预测：内衍与市场细分 / 218
7.2.2  新样本预测：外推与潜在行为 / 219
7.3  模型优劣与模型评价 / 219
7.3.1  R2 变形记 / 219
7.3.2  图示R2：R2 图与ROC 曲线 / 221
7.4  模型优劣与业务评价 / 221
7.4.1  小数据的标准：R2 / 221
7.4.2  大数据的标准：老板 / 222
第8 章  数据分析报告
8.1  可视化图形制作 / 223
8.1.1  条形图与折线图 / 223
8.1.2  频数与分布 / 223
8.1.3  多变箱体图 / 224
8.1.4  散点图与气泡图 / 225
8.2  图形制作与格式 / 227
8.2.1  图形制作：绘图、颜色 / 227
8.2.2  图形模板制作与调用 / 229
8.3  表格制作与格式 / 230
8.3.1  表格制作：制表、格式 / 230
8.3.2  表格模板制作与调用 / 232
8.3.3  OMS 控制面板 / 234
附录A  数据集__
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计分析：从小数据到大数据
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>孩子学琴那些事儿
导语Chapter 1 要不要让孩子学乐器  1.当孩子“遭遇”乐器  2.孩子是学乐器的那块“料”吗  3.用音乐点亮孩子的智慧Chapter 2 那个被神话了的兴趣  1.学乐器，兴趣重要吗  2.兴趣、父母、老师，谁才是神话的缔造者  3.几岁学乐器正当时  4.“玩玩”的态度要不得Chapter 3 钢琴·小提琴·其他乐器  1.学钢琴、小提琴的7大误区  2.小心对待孩子的选择——钢琴PK小提琴  3.买琴，给父母支几招  4.别“吊死”在钢琴这棵树上  5.电子琴转钢琴=走弯路Chapter 4 给孩子选个好老师  1.学琴市场上的N类老师  2.大课、小课，孩子该选哪一课  3.不同的孩子需要不同的老师  4.如何找到好老师Chapter 5 父母，你们准备好了吗  1.准备好，孩子一定会反抗  2.琴童心理分分类  3.应对孩子反抗的实用战术  4.父母，请不要这样做……Chapter 6 陪练的力量  1.陪练，陪的是什么  2.如何陪孩子走过“沟沟坎坎”  3.是时候请个专业陪练了Chapter 7 让TA自力更生  1.从第一堂课开始培养孩子独立性  2.如何做个合格的“懒妈妈”  3.允许孩子失败Chapter 8 说说考级那些事儿  1.五花八门的考级机构  2.考级，到底考还是不考  3.考级的准备Chapter 9 要成为下一个郎朗吗  1.我的孩子能成为郎朗吗  2.专业音乐学院知多少  3.音乐留学之路  4.进入专业院校，仅仅只是开始Chapter 10 该放手时需放手  1.“妈妈，我再也不想学琴了”  2.是时候，我们该停下来了  3.放弃，也许是另一种开始Chapter 11 学琴“八达通”  1.学琴，只为艺考吗  2.学琴，是为了考试加分吗  3.学琴用途N+1后记
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>孩子学琴那些事儿
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>华为路由器学习指南
第一篇 路由器选型及基本功能配置与管理
第1章 路由器的选型及应用 2
1.1 华为ar g3系列路由器概述 4
1.1.1 ar g3系列路由器的主要特点 4
1.1.2 ar g3的主要路由器系列 6
1.1.3 ar g3系列路由器的命名规则 7
1.1.4 ar g3系列路由器的主要特性 8
1.1.5 ar g3系列路由器的主要应用 14
1.2 ar150/150-s/160/200/200-s系列路由器 19
1.2.1 ar150/150-s/160/200/200-s系列路由器的主要特点 20
1.2.2 ar150系列产品外观结构及配置规格 20
1.2.3 ar150系列路由器指示灯说明 24
1.2.4 ar150-s系列产品外观结构及配置规格 26
1.2.5 ar150-s系列路由器指示灯说明 27
1.2.6 ar160系列路由器产品外观及配置规格 28
1.2.7 ar160系列路由器指示灯说明 30
1.2.8 ar200系列产品外观及配置规格 31
1.2.9 ar200系列路由器指示灯说明 34
1.2.10 ar200-s系列产品外观结构及配置规格 35
1.2.11 ar200-s系列路由器指示灯说明 36
1.2.12 ar150/160/200系列的基本配置和性能综合比较 37
1.2.13 ar150/150-s/160/200/200-s系列路由器的主要应用 38
1.3 ar1200/1200-s/2200/2200-s/3200系列路由器 41
1.3.1 ar1200/1200-s/2200/2200-s/3200系列路由器主要特点 41
1.3.2 ar1200系列产品外观及配置规格 43
1.3.3 ar1200系列路由器指示灯 46
1.3.4 ar1200-s系列路由器产品外观及配置规格 47
1.3.5 ar1200-s系列路由器指示灯 49
1.3.6 ar2200系列路由器产品外观及配置规格 49
1.3.7 ar2200系列路由器指示灯 53
1.3.8 ar2200-s系列路由器产品外观及配置规格 57
1.3.9 ar2200-s系列路由器指示灯 61
1.3.10 ar3200系列产品外观及配置规格 63
1.3.11 ar3200系列路由器指示灯 66
1.3.12 ar1200/1200-s/2200/2200-s/3200系列路由器基本配置和性能综合比较 66
1.3.13 ar1200/1200-s/2200/2200-s/3200系列路由器的主要应用 67
1.4 ne系列路由器 73
1.4.1 ne20e-s系列多业务路由器的主要特点 73
1.4.2 ne20e-s系列多业务路由器的主要特性 74
1.4.3 ne40e系列全业务路由器的主要特点 75
1.4.4 ne40e系列全业务路由器的主要特性 77
1.4.5 ne5000e集群路由器的主要特点 78
1.4.6 ne5000e集群路由器的主要特性 80
第2章 路由器登录及基础配置 82
2.1 ar g3系列路由器的登录 84
2.1.1 首次本地登录 84
2.1.2 首次telnet远程登录 84
2.1.3 首次登录后的基本配置 85
2.1.4 ar g3系列路由器首次登录基本配置示例 89
2.2 web登录 90
2.2.1 上传web网页文件 90
2.2.2 加载web网页文件 92
2.2.3 创建web网管账号 93
2.2.4 配置https服务器 93
2.2.5 登录web网管 95
2.3 配置系统启动 96
2.3.1 系统启动概述 97
2.3.2 保存配置文件 99
2.3.3 比较配置文件 101
2.3.4 备份配置文件 102
2.3.5 恢复配置文件 103
2.3.6 清除配置 103
2.3.7 设置设备的出厂配置 104
2.3.8 配置系统启动文件 105
2.3.9 重新启动设备 107
2.3.10 系统启动配置示例 108
2.4 bootrom菜单 110
2.4.1 bootrom简介 110
2.4.2 bootrom主菜单 110
2.4.3 串口子菜单 111
2.4.4 网络子菜单 112
2.4.5 启动选择子菜单 113
2.4.6 文件管理子菜单 116
2.4.7 密码管理菜单 118
2.5 信息中心基础 118
2.5.1 信息的分类 119
2.5.2 信息的分级 119
2.5.3 信息的输出 120
2.5.4 信息的输出格式和输出过滤 121
2.6 配置log信息输出 124
2.6.1 log信息输出配置任务 124
2.6.2 配置log信息输出基本功能 125
2.6.3 配置log信息输出到log缓冲区 127
2.6.4 配置log信息输出到日志文件 128
2.6.5 配置log信息输出到控制台或终端 130
2.6.6 配置log信息输出到日志主机 131
2.6.7 log信息输出管理 132
2.6.8 向日志文件输出log信息的配置示例 132
2.6.9 向日志主机输出log信息的配置示例 134
2.7 配置trap信息输出 136
2.7.1 trap信息输出配置任务 136
2.7.2 配置trap信息输出到snmp代理 137
2.7.3 向snmp代理输出trap信息的配置示例 138
2.8 配置输出debug信息 139
2.8.1 debug信息输出配置任务 139
2.8.2 向控制台输出debug信息的配置示例 140
2.9 u盘开局配置与管理 141
2.9.1 u盘开局流程 141
2.9.2 u盘开局文件 143
2.9.3 u盘开局索引文件制作 143
2.9.4 配置u盘开局认证 147
2.10 auto-config配置与管理 148
2.10.1 auto-config工作原理 148
2.10.2 auto-config特性的产品支持 149
2.10.3 配置同网段auto-config功能 151
2.10.4 配置跨网段auto-config功能 154
2.10.5 auto-config维护 155
2.10.6 同网段auto-config功能的配置示例 156
2.10.7 跨网段auto-config功能配置示例 158
第3章 接口配置与管理 162
3.1 路由器接口基础及基本参数配置与管理 164
3.1.1 接口分类 164
3.1.2 物理接口编号规则 166
3.1.3 接口基本参数配置 167
3.1.4 接口基本参数配置管理 169
3.2 以太网接口配置与管理 169
3.2.1 以太网接口分类 170
3.2.2 配置以太网接口基本属性 171
3.2.3 自动协商速率范围配置示例 173
3.2.4 配置二层以太网接口 174
3.2.5 端口隔离配置示例 174
3.2.6 配置三层以太网接口 175
3.2.7 以太网接口管理 177
3.2.8 典型故障分析与排除 177
3.3 serial接口配置与管理 178
3.3.1 同/异步serial接口 179
3.3.2 配置同步方式下serial接口的物理和链路属性 180
3.3.3 配置异步方式下serial接口物理和链路属性 184
3.3.4 serial接口管理 187
3.3.5 同步方式下serial接口连接网络的配置示例 187
3.4 ce1/pri接口配置与管理 189
3.4.1 ce1/pri接口简介 189
3.4.2 ce1/pri接口物理属性 190
3.4.3 配置ce1/pri接口工作在e1方式 191
3.4.4 配置ce1/pri接口工作在ce1方式 194
3.4.5 配置ce1/pri接口工作在pri方式 197
3.4.6 ce1/pri接口管理 199
3.5 e1-f接口配置与管理 199
3.5.1 e1-f接口简介 200
3.5.2 配置e1-f接口工作在非成帧方式 200
3.5.3 配置e1-f接口工作在成帧方式 202
3.5.4 e1-f接口管理 204
3.6 ct1/pri接口配置与管理 204
3.6.1 ct1/pri接口简介 204
3.6.2 ct1/pri接口物理属性 204
3.6.3 配置ct1/pri接口工作在ct1方式 205
3.6.4 配置ct1/pri接口工作在pri方式 208
3.6.5 ct1/pri接口管理 210
3.7 t1-f接口配置与管理 210
3.7.1 t1-f接口简介 211
3.7.2 配置t1-f接口 211
3.7.3 t1-f接口管理 213
3.8 3g cellular接口配置与管理 214
3.8.1 3g cellular接口简介 214
3.8.2 配置wcdma网络中的3g cellular接口 216
3.8.3 配置cdma2000网络的3g cellular接口 223
3.8.4 3g cellular接口管理 226
3.8.5 wcdma网络中3g cellular接口作为主链路接入internet的配置示例 226
3.8.6 wcdma网络中3g cellular接口作为主备链路接入internet的配置示例 229
3.9 pos接口配置与管理 231
3.9.1 pos接口简介 231
3.9.2 配置pos接口 232
3.9.3 pos接口管理 234
3.9.4 pos接口物理参数配置示例 235
3.10 cpos接口配置与管理 236
3.10.1 配置通过cpos接口实现设备相连 236
3.10.2 配置cpos接口汇聚接入e1线路 239
3.10.3 配置cpos接口汇聚接入t1线路 243
3.10.4 cpos接口管理 246
3.10.5 cpos接口通过光纤直连的配置示例 247
3.10.6 cpos接口汇聚接入e1线路的配置示例 248
3.11 pon接口配置与管理 249
3.11.1 pon概述 249
3.11.2 配置epon接口 251
3.11.3 配置gpon接口 255
3.11.4 pon接口管理 256
3.12 adsl接口配置与管理 257
3.12.1 adsl概述 257
3.12.2 adsl主要特性 258
3.12.3 配置adsl接口 260
3.12.4 adsl接口管理 262
3.12.5 adsl接口上行配置示例 262
3.13 vdsl接口配置与管理 263
3.13.1 vdsl概述 263
3.13.2 vdsl主要特性 264
3.13.3 配置atm模式下vdsl接口 265
3.13.4 配置ptm模式下vdsl接口 266
3.13.5 vdsl接口管理 267
3.13.6 vdsl接口上行配置示例 267
3.14 g.shdsl接口配置与管理 268
3.14.1 g.shdsl概述 268
3.14.2 g.shdsl接口配置任务 269
3.14.3 配置g.shdsl接口 271
3.14.4 g.shdsl接口上行配置示例 277
第4章 wan接入/互联配置与管理 280
4.1 广域网接入/互联网概述 282
4.2 dcc基础 283
4.2.1 dcc概述 283
4.2.2 两种dcc的拨号控制原理 284
4.2.3 dcc的主要应用场景 286
4.2.4 配置dcc前的准备 288
4.3 配置轮询dcc 289
4.3.1 配置拨号接口链路层协议和ip地址 289
4.3.2 使能轮询dcc并配置dcc拨号acl及与接口的关联 290
4.3.3 配置发起或接收轮询dcc呼叫 291
4.3.4 配置dcc拨号接口属性 296
4.3.5 配置dcc呼叫mp捆绑 299
4.3.6 配置拨号串循环备份 300
4.3.7 配置通过dcc实现动态路由备份 300
4.3.8 通过轮询dcc中的接口备份和3g网络实现干线链路备份的配置示例 302
4.4 配置共享dcc 304
4.5 dcc管理 307
4.6 ppp配置与管理 307
4.6.1 ppp简介及基本工作机制 307
4.6.2 配置ppp基本功能 309
4.6.3 配置ppp的pap认证 311
4.6.4 配置ppp的chap认证 313
4.6.5 配置ppp协商参数 316
4.6.6 ppp管理 317
4.6.7 pap单向认证配置示例 318
4.6.8 pap双向认证配置示例 319
4.6.9 chap单向认证配置示例 320
4.7 mp配置与管理 322
4.7.1 mp概述 322
4.7.2 mp主要特性 323
4.7.3 配置将ppp链路直接绑定到vt上实现mp 324
4.7.4 配置按照ppp链路用户名查找vt实现mp 325
4.7.5 配置将ppp链路加入mp-group实现mp 326
4.7.6 配置mp分片和捆绑数 327
4.7.7 mp管理 328
4.7.8 将ppp链路直接绑定到vt上实现mp的配置示例 328
4.7.9 按照ppp链路用户名查找vt实现mp的配置示例 329
4.7.10 将ppp链路加入mp-group实现mp的配置示例 331
4.8 pppoe配置与管理 333
4.8.1 pppoe工作原理 334
4.8.2 pppoe典型应用 335
4.8.3 配置设备作为pppoe客户端 336
4.8.4 配置设备作为pppoe服务器 339
4.8.5 pppoe管理 343
4.8.6 设备作为pppoe服务器的配置示例 343
4.8.7 设备作为pppoe客户端的配置示例 345
4.8.8 利用adsl modem将局域网接入internet的配置示例 346
第5章 dhcp/dns服务配置与管理 350
5.1 dhcp基础 352
5.1.1 dhcp概述 352
5.1.2 dhcp报文及其格式 353
5.1.3 dhcp服务ip地址自动分配原理 356
5.1.4 dhcp服务ip地址租约更新原理 362
5.1.5 dhcp中继代理服务 362
5.2 配置基于全局地址池的dhcp服务器 366
5.2.1 基于全局地址池的dhcp服务器的配置任务 366
5.2.2 配置全局地址池 367
5.2.3 配置连接客户端的接口工作在全局地址池模式 370
5.2.4 配置dhcp客户端的dns服务和netbios服务 371
5.2.5 配置防止ip地址重复分配功能 373
5.2.6 配置dhcp数据保存功能 374
5.2.7 配置dhcp服务器信任option82选项功能 375
5.2.8 配置dhcp服务器为bootp客户端分配ip地址 375
5.2.9 基于全局地址池的dhcp服务器的配置示例 376
5.3 配置基于接口地址池的dhcp服务器 378
5.3.1 配置接口地址池 379
5.3.2 配置dhcp客户端的dns服务和netbios服务 380
5.3.3 基于接口地址池的dhcp服务器的配置示例 381
5.4 配置dhcp中继 383
5.4.1 配置指定接口工作在dhcp中继模式 383
5.4.2 配置dhcp中继转发的目的dhcp服务器组 385
5.4.3 配置dhcp中继接口绑定dhcp服务器或dhcp服务器组 386
5.4.4 配置dhcp中继请求dhcp服务器释放客户端ip地址 386
5.4.5 不同网段内dhcp服务器和dhcp中继的配置示例 387
5.5 配置dhcp/bootp客户端 389
5.5.1 配置dhcp/bootp客户端属性 389
5.5.2 配置dhcp服务器路由下发属性 391
5.5.3 使能dhcp/bootp客户端功能 392
5.6 配置dhcp报文限速 392
5.6.1 dhcp报文限速配置步骤 392
5.6.2 dhcp报文限速功能配置示例 394
5.7 dhcp服务管理和典型故障排除 395
5.7.1 dhcp服务配置管理 395
5.7.2 典型故障分析与排除 396
5.8 dhcp snooping基础 398
5.8.1 dhcp snooping概述 398
5.8.2 dhcp snooping支持的option82功能 399
5.8.3 dhcp snooping的典型应用 400
5.9 dhcp snooping的基本功能配置与管理 403
5.9.1 使能dhcp snooping功能 403
5.9.2 配置接口信任状态 404
5.9.3 使能dhcp snooping用户位置迁移功能 405
5.9.4 配置arp与dhcp snooping的联动功能 405
5.9.5 配置用户下线后及时清除对应mac表项功能 406
5.9.6 配置丢弃giaddr字段非零的dhcp request报文 406
5.9.7 dhcp snooping基本功能管理 407
5.10 dhcp snooping的攻击防范功能配置与管理 407
5.10.1 配置防止dhcp服务器仿冒者攻击 407
5.10.2 配置防止仿冒dhcp报文攻击 408
5.10.3 配置防止dhcp服务器拒绝服务攻击 409
5.10.4 dhcp snooping的攻击防范功能配置示例 411
5.11 配置在dhcp报文中添加option82字段 413
5.12 dns服务配置与管理 415
5.12.1 配置作为dns客户端 415
5.12.2 配置dns proxy/relay 417
5.12.3 配置ddns客户端 419
5.12.4 dns管理 422
第6章 nat配置与管理 424
6.1 nat基础 426
6.1.1 nat主要特性 426
6.1.2 basic nat实现原理 427
6.1.3 napt实现原理 428
6.1.4 easy ip实现原理 430
6.1.5 nat server实现原理 431
6.1.6 静态nat/napt 432
6.1.7 nat与路由的本质区别 432
6.2 nat扩展技术及主要应用 433
6.2.1 nat alg 433
6.2.2 dns mapping 434
6.2.3 nat关联vpn 435
6.2.4 两次nat 437
6.2.5 nat过滤和nat映射 438
6.2.6 nat的主要应用 440
6.3 配置动态nat 442
6.3.1 配置地址转换的acl规则 443
6.3.2 配置出接口的地址关联 443
6.3.3 使能nat alg功能 445
6.3.4 配置nat过滤方式和映射模式 445
6.3.5 配置两次nat 446
6.3.6 配置nat日志输出 447
6.3.7 配置nat地址映射表项老化时间 448
6.3.8 动态nat地址转换配置示例 448
6.3.9 配置两次nat示例 450
6.4 配置静态nat 452
6.4.1 配置静态nat地址映射 453
6.4.2 配置dns mapping 455
6.4.3 静态一对一nat配置示例 456
6.5 配置nat server 457
6.5.1 配置nat server地址映射 457
6.5.2 nat server地址映射配置示例 460
6.5.3 nat综合配置示例 461
6.6 nat管理与故障排除 464
6.6.1 nat管理 464
6.6.2 典型故障分析与排除 465
第二篇 可靠性配置与管理
第7章 bfd和nqa配置与管理 470
7.1 bfd基础 472
7.1.1 bfd概述 472
7.1.2 bfd检测原理 472
7.2 bfd主要应用 475
7.2.1 bfd检测ip链路 475
7.2.2 bfd单臂回声功能 476
7.2.3 bfd与各种路由的联动 476
7.2.4 bfd的其他联动 478
7.3 bfd配置与管理 480
7.3.1 配置静态bfd单跳检测 480
7.3.2 配置静态bfd多跳检测 483
7.3.3 配置静态标识符自协商bfd 484
7.3.4 配置静态bfd单臂回声功能 484
7.3.5 配置静态bfd与接口/子接口状态联动 485
7.3.6 调整bfd参数 487
7.3.7 bfd管理 489
7.4 bfd配置示例 490
7.4.1 单跳检测二层链路配置示例 490
7.4.2 vlanif接口bfd单跳检测配置示例 492
7.4.3 bfd多跳检测配置示例 492
7.4.4 bfd状态与接口状态联动配置示例 494
7.4.5 单臂回声功能配置示例 497
7.5 nqa配置与管理 498
7.5.1 nqa综述 498
7.5.2 icmp nqa测试基本原理 499
7.5.3 配置icmp nqa测试 499
7.5.4 icmp nqa测试管理 504
7.5.5 icmp nqa测试配置示例 504
第8章 vrrp配置与管理 506
8.1 vrrp基础 508
8.1.1 vrrp概述 508
8.1.2 vrrp协议报文 509
8.1.3 vrrp基本工作原理 511
8.1.4 vrrp master选举和状态通告 513
8.1.5 vrrp的两种主备模式 514
8.1.6 vrrp的两种延伸功能 516
8.1.7 支持的vrrp主要特性 518
8.2 vrrp基本功能配置与管理 519
8.2.1 创建vrrp备份组 520
8.2.2 配置设备在备份组中的优先级 521
8.2.3 配置vrrp的时间参数 522
8.2.4 配置其他可选功能 524
8.2.5 vrrp基本功能管理 526
8.2.6 vrrp主备备份配置示例 527
8.2.7 vrrp多网关负载分担配置示例 530
8.2.8 dot1q终结子接口支持vrrp配置示例 532
8.2.9 qinq终结子接口支持vrrp配置示例 535
8.3 vrrp联动功能配置与管理 540
8.3.1 配置vrrp与接口状态联动监视上行接口 541
8.3.2 配置vrrp与bfd联动实现快速切换 542
8.3.3 配置vrrp与bfd/nqa/路由联动监视上行链路 544
8.3.4 vrrp与接口状态联动监视上行接口的配置示例 547
8.3.5 vrrp与bfd联动实现快速切换配置示例 550
8.3.6 vrrp与bfd联动监视上行链路的配置示例 553
8.3.7 vrrp与nqa联动监视上行链路配置示例 556
8.3.8 vrrp与路由联动监视上行链路配置示例 560
第9章 接口备份和双机热备份配置与管理 566
9.1 接口备份基础 568
9.1.1 接口备份概述 568
9.1.2 接口备份主要特性 568
9.2 接口备份配置与管理 572
9.2.1 配置主备接口备份基本功能 572
9.2.2 配置负载分担接口备份 573
9.2.3 配置主备接口备份联动功能 574
9.3 接口备份配置示例 578
9.3.1 以太链路+以太链路的主备接口备份配置示例 578
9.3.2 以太链路+以太链路的负载分担接口备份配置示例 580
9.3.3 adsl链路+3g网络的主备接口备份配置示例 582
9.3.4 以太链路+以太链路的接口备份与bfd联动配置示例 585
9.3.5 以太链路+以太链路的接口备份与nqa联动配置示例 588
9.3.6 以太链路+以太链路的接口备份与路由联动配置示例 591
9.4 双机热备份基础 594
9.4.1 双机热备份的备份方式 594
9.4.2 双机热备份的实现机制 595
9.5 通过vrrp实现流量切换的双机热备份功能的配置与管理 598
9.5.1 创建hsb主备服务 598
9.5.2 配置hsb备份组 599
9.5.3 使能hsb备份组 601
9.5.4 双机热备份管理及典型故障排除 601
9.5.5 配置双机热备份示例 601
第三篇 路由配置与管理
第10章 静态路由配置与管理 608
10.1 路由基础 610
10.1.1 路由的分类 610
10.1.2 路由表和fib表 611
10.1.3 路由协议的优先级 614
10.1.4 负载分担与路由备份 615
10.1.5 路由的收敛 616
10.2 静态路由基础 617
10.2.1 静态路由的组成 617
10.2.2 静态路由的主要特点 617
10.3 静态路由主要特性及应用 620
10.3.1 静态缺省路由 620
10.3.2 静态路由与bfd联动 621
10.3.3 静态路由与nqa联动 621
10.3.4 静态路由优先级 622
10.3.5 静态路由永久发布 622
10.4 静态路由配置与管理 624
10.4.1 配置静态路由基本功能 624
10.4.2 配置静态路由与静态bfd联动 626
10.4.3 配置静态路由与nqa联动 627
10.4.4 静态路由管理 629
10.4.5 静态路由配置示例 629
10.4.6 静态路由与bfd联动配置示例 631
10.4.7 静态路由与nqa联动配置示例 633
第11章 rip路由配置与管理 638
11.1 rip基础 640
11.1.1 rip的度量机制 640
11.1.2 rip协议定时器 641
11.1.3 rip路由更新机制 642
11.1.4 rip路由收敛机制 644
11.1.5 rip报文格式 647
11.2 rip配置与管理 649
11.2.1 配置rip基本功能 649
11.2.2 配置ripv2特性 652
11.2.3 配置防止路由环路 654
11.2.4 控制rip的路由选路 655
11.2.5 控制rip路由信息的发布 658
11.2.6 控制rip路由信息的接收 661
11.2.7 调整rip网络性能参数 662
11.2.8 配置rip与bfd联动 664
11.2.9 rip路由管理 668
11.2.10 rip基本功能配置示例 668
11.2.11 rip引入外部路由配置示例 670
11.2.12 rip与单臂回声静态bfd联动特性的配置示例 672
11.2.13 rip与动态bfd联动特性的配置示例 675
第12章 ospf路由配置与管理 678
12.1 ospf基础 680
12.1.1 ospf的几个重要概念 680
12.1.2 ospf网络的设计考虑 683
12.1.3 ospf lsa类型 684
12.1.4 几种特殊的ospf区域 686
12.1.5 ospf的网络类型 689
12.2 ospf报头及各种报文格式 690
12.2.1 ospf协议报头格式 690
12.2.2 ospf hello报文及格式 691
12.2.3 ospf dd报文及格式 692
12.2.4 ospf lsr报文及格式 693
12.2.5 ospf lsu报文及格式 694
12.2.6 ospf lsack报文及格式 695
12.3 ospf工作原理 696
12.3.1 ospf状态机 696
12.3.2 ospf邻接关系建立流程 697
12.3.3 ospf路由计算基本过程 699
12.3.4 理解ospf进程 704
12.4 配置ospf基本功能 706
12.4.1 创建ospf进程 706
12.4.2 创建ospf区域 707
12.4.3 使能ospf 708
12.4.4 创建虚连接 709
12.4.5 配置对ospf更新lsa的泛洪限制 711
12.4.6 ospf基本功能管理 711
12.4.7 ospf基本功能配置示例 712
12.4.8 ospf虚连接配置示例 715
12.5 配置ospf邻居或邻接的会话参数 717
12.6 配置ospf在不同网络类型中的属性 718
12.6.1 配置接口的网络类型 719
12.6.2 配置p2mp网络属性 720
12.6.3 配置nbma网络属性 721
12.6.4 ospf网络属性管理 722
12.6.5 ospf的dr选举配置示例 723
12.7 配置ospf的stub/totally stub/nssa/totally nssa区域 726
12.7.1 配置ospf的stub/totally stub区域 727
12.7.2 配置ospf的nssa/totally nssa区域 728
12.7.3 stub区域和nssa区域管理 729
12.7.4 ospf的totally stub区域配置示例 729
12.7.5 ospf的nssa区域配置示例 733
12.8 配置ospf安全功能 737
12.8.1 配置ospf gstm功能 737
12.8.2 配置ospf安全认证功能 739
12.9 调整ospf的路由选择 740
12.9.1 配置ospf的接口开销 741
12.9.2 配置等价路由 742
12.9.3 配置ospf路由选择规则 743
12.9.4 抑制接口接收和发送ospf报文 744
12.10 控制ospf路由信息的发布和接收 744
12.10.1 配置ospf引入外部路由 745
12.10.2 配置ospf将缺省路由通告到ospf区域 746
12.10.3 配置ospf路由聚合 748
12.10.4 配置ospf对接收和发布的路由进行过滤 750
12.10.5 配置对发送的lsa进行过滤 751
12.10.6 配置对abr type3 lsa进行过滤 752
12.11 调整ospf网络收敛性能 753
12.11.1 调整ospf网络收敛性能的配置任务 753
12.11.2 调整ospf网络收敛性能的配置步骤 755
12.12 配置ospf与bfd联动 757
第13章 is-is路由配置与管理 762
13.1 is-is基础 764
13.1.1 osi网络基础 764
13.1.2 is-is基本术语 765
13.1.3 is-is路由器类型 766
13.1.4 osi网络/is-is路由类型 767
13.1.5 is-is区域与ospf区域的比较 768
13.1.6 is-is的两种地址格式 770
13.2 is-is pdu报文格式 772
13.2.1 is-is主要pdu类型 772
13.2.2 is-is pdu报头格式 773
13.2.3 iih pdu报文格式 774
13.2.4 lsp pdu报文格式 776
13.2.5 snp pdu报文格式 778
13.2.6 is-is pdu可变字段格式 779
13.3 is-is基本原理 780
13.3.1 is-is邻居关系的建立 780
13.3.2 is-is的lsp交互过程 782
13.3.3 is-is报文验证 786
13.3.4 is-is路由渗透 787
13.3.5 is-is网络收敛 788
13.4 is-is基本功能配置与管理 789
13.4.1 创建is-is进程 789
13.4.2 配置网络实体名称 790
13.4.3 配置全局level级别 791
13.4.4 建立is-is邻居 792
13.4.5 配置is-is主机名映射 795
13.4.6 is-is基本功能管理 796
13.4.7 is-is基本功能配置示例 797
13.5 is-is路由聚合 802
13.5.1 配置is-is路由聚合 802
13.5.2 is-is路由聚合配置示例 803
13.6 控制is-is的路由信息交互 805
13.6.1 配置is-is发布缺省路由 806
13.6.2 配置is-is引入外部路由 807
13.6.3 配置is-is发布外部路由过滤 808
13.6.4 配置is-is路由下发ip路由表过滤 809
13.7 控制is-is的路由选路 810
13.7.1 配置is-is协议的优先级 810
13.7.2 配置is-is接口的开销 811
13.7.3 配置is-is对等价路由的处理方式 814
13.7.4 配置is-is路由渗透 815
13.7.5 控制level-1设备是否生成缺省路由 817
13.8 调整is-is路由的收敛性能 818
13.8.1 配置hello报文参数 818
13.8.2 配置lsp报文参数 820
13.8.3 配置csnp报文参数 824
13.8.4 调整spf的计算时间间隔 825
13.8.5 配置is-is路由按优先级收敛 826
13.9 提高is-is网络的安全性 828
13.9.1 配置is-is接口认证 828
13.9.2 配置区域或路由域的认证 830
13.10 配置is-is与bfd联动 831
13.10.1 配置is-is与静态bfd联动 832
13.10.2 配置is-is与动态bfd联动 834
13.10.3 is-is与静态bfd联动配置示例 836
13.10.4 is-is与动态bfd联动配置示例 839
第14章 bgp路由配置与管理 844
14.1 bgp基础 846
14.1.1 bgp简介 846
14.1.2 bgp as 848
14.1.3 bgp地址族 849
14.2 bgp报文类型及格式 850
14.2.1 open报文格式 851
14.2.2 update报文格式 852
14.2.3 notification报文格式 852
14.2.4 keepalive报文格式 853
14.2.5 route-refresh报文格式 853
14.3 bgp的主要路由属性 853
14.3.1 bgp路由属性分类 853
14.3.2 origin（源）属性 854
14.3.3 as_path属性 854
14.3.4 next_hop属性 856
14.3.5 local_pref属性 857
14.3.6 med属性 858
14.3.7 团体属性 859
14.4 路由反射器与联盟 860
14.4.1 路由反射器 860
14.4.2 bgp联盟 863
14.5 bgp工作原理 864
14.5.1 bgp协议的选路规则 864
14.5.2 bgp对等体交互原理 865
14.5.3 bgp与igp交互原理 867
14.6 bgp的基本功能配置与管理 868
14.6.1 启动bgp进程 869
14.6.2 配置bgp对等体 870
14.6.3 配置bgp对等体组 872
14.6.4 配置bgp引入路由 874
14.6.5 bgp基本功能管理 876
14.6.6 bgp基本功能配置示例 876
14.6.7 mbgp基本功能配置示例 880
14.7 bgp路由选路和负载分担配置与管理 885
14.7.1 配置bgp协议优先级 886
14.7.2 配置next_hop属性 887
14.7.3 配置bgp路由首选值 888
14.7.4 配置本机缺省local_pref属性 889
14.7.5 配置as_path属性 890
14.7.6 配置med属性 895
14.7.7 配置bgp团体属性 898
14.7.8 配置bgp负载分担 901
14.7.9 bgp路由选路和负载分担管理 903
14.7.10 通过med属性控制路由选择的配置示例 904
14.7.11 bgp团体配置示例 906
14.7.12 bgp负载分担配置示例 909
14.8 简化ibgp网络连接 911
14.8.1 配置bgp路由反射器 912
14.8.2 配置bgp联盟 913
14.8.3 bgp路由反射器配置示例 914
14.8.4 bgp联盟配置示例 917
14.9 控制bgp路由的发布和接收 919
14.9.1 控制bgp路由发布 920
14.9.2 控制bgp路由信息的接收 922
14.9.3 配置bgp软复位 924
14.9.4 配置bgp路由聚合 926
14.10 调整bgp网络的收敛速度 927
14.10.1 配置bgp连接重传定时器 928
14.10.2 配置bgp存活时间和保持时间定时器 928
14.10.3 配置bgp更新报文定时器 930
14.10.4 配置ebgp连接快速复位 930
14.11 配置bgp安全性 931
14.11.1 配置md5认证 931
14.11.2 配置keychain认证 932
14.11.3 配置bgp gtsm功能 932
14.12 bgp与bfd联动 934
14.12.1 配置bgp与bfd联动 934
14.12.2 bgp与bfd联动配置示例 935
第15章 路由策略和策略路由配置与管理 940
15.1 路由策略基础 942
15.1.1 路由策略原理 942
15.1.2 路由策略过滤器 943
15.1.3 路由策略配置任务 944
15.2 配置路由策略过滤器 945
15.2.1 配置地址前缀列表 945
15.2.2 配置as路径过滤器 949
15.2.3 配置团体属性过滤器 952
15.3 配置路由策略 954
15.3.1 创建路由策略 954
15.3.2 配置if-match子句 955
15.3.3 配置apply子句 959
15.3.4 配置路由策略生效时间 965
15.3.5 as_path过滤器配置示例 966
15.3.6 接收和发布路由过滤的配置示例 969
15.3.7 在路由引入时应用路由策略的配置示例 973
15.4 策略路由基础 976
15.4.1 策略路由概述 977
15.4.2 本地策略路由 978
15.4.3 接口策略路由 979
15.4.4 智能策略路由 979
15.5 本地策略路由配置与管理 981
15.5.1 配置本地策略路由的匹配规则 982
15.5.2 配置本地策略路由的动作 983
15.5.3 应用本地策略路由 985
15.5.4 本地策略路由管理 986
15.5.5 本地策略路由配置示例 986
15.6 接口策略路由配置与管理 990
15.6.1 定义流分类 990
15.6.2 配置流重定向 995
15.6.3 配置并应用流策略 996
15.6.4 接口策略路由管理 997
15.6.5 接口策略路由配置示例 997
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>华为路由器学习指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python深度学习
第一部分　深度学习基础
第1章　什么是深度学习　　2
1.1　人工智能、机器学习与深度学习　　2
1.1.1　人工智能　　3
1.1.2　机器学习　　3
1.1.3　从数据中学习表示　　4
1.1.4　深度学习之“深度”　　6
1.1.5　用三张图理解深度学习的工作原理　　7
1.1.6　深度学习已经取得的进展　　9
1.1.7　不要相信短期炒作　　9
1.1.8　人工智能的未来　　10
1.2　深度学习之前：机器学习简史　　11
1.2.1　概率建模　　11
1.2.2　早期神经网络　　11
1.2.3　核方法　　12
1.2.4　决策树、随机森林与梯度提升机　　13
1.2.5　回到神经网络　　14
1.2.6　深度学习有何不同　　14
1.2.7　机器学习现状　　15
1.3　为什么是深度学习，为什么是现在　　15
1.3.1　硬件　　16
1.3.2　数据　　17
1.3.3　算法　　17
1.3.4　新的投资热潮　　17
1.3.5　深度学习的大众化　　18
1.3.6　这种趋势会持续吗　　18
第2章　神经网络的数学基础　　20
2.1　初识神经网络　　20
2.2　神经网络的数据表示　　23
2.2.1　标量（0D张量）　　23
2.2.2　向量（1D张量）　　24
2.2.3　矩阵（2D张量）　　24
2.2.4　3D张量与更高维张量　　24
2.2.5　关键属性　　25
2.2.6　在Numpy中操作张量　　26
2.2.7　数据批量的概念　　27
2.2.8　现实世界中的数据张量　　27
2.2.9　向量数据　　27
2.2.10　时间序列数据或序列数据　　28
2.2.11　图像数据　　28
2.2.12　视频数据　　29
2.3　神经网络的“齿轮”：张量运算　　29
2.3.1　逐元素运算　　30
2.3.2　广播　　31
2.3.3　张量点积　　32
2.3.4　张量变形　　34
2.3.5　张量运算的几何解释　　34
2.3.6　深度学习的几何解释　　35
2.4　神经网络的“引擎”：基于梯度的优化　　36
2.4.1　什么是导数　　37
2.4.2　张量运算的导数：梯度　　38
2.4.3　随机梯度下降　　38
2.4.4　链式求导：反向传播算法　　41
2.5　回顾第一个例子　　41
本章小结　　42
第3章　神经网络入门　　43
3.1　神经网络剖析　　43
3.1.1　层：深度学习的基础组件　　44
3.1.2　模型：层构成的网络　　45
3.1.3　损失函数与优化器：配置学习过程的关键　　45
3.2　Keras简介　　46
3.2.1　Keras、TensorFlow、Theano 和CNTK　　47
3.2.2　使用Keras 开发：概述　　48
3.3　建立深度学习工作站　　49
3.3.1　Jupyter笔记本：运行深度学习实验的首选方法　　49
3.3.2　运行Keras：两种选择　　50
3.3.3　在云端运行深度学习任务：优点和缺点　　50
3.3.4　深度学习的最佳GPU　　50
3.4　电影评论分类：二分类问题　　51
3.4.1　IMDB 数据集　　51
3.4.2　准备数据　　52
3.4.3　构建网络　　52
3.4.4　验证你的方法　　56
3.4.5　使用训练好的网络在新数据上生成预测结果　　59
3.4.6　进一步的实验　　59
3.4.7　小结　　59
3.5　新闻分类：多分类问题　　59
3.5.1　路透社数据集　　60
3.5.2　准备数据　　61
3.5.3　构建网络　　61
3.5.4　验证你的方法　　62
3.5.5　在新数据上生成预测结果　　65
3.5.6　处理标签和损失的另一种方法　　65
3.5.7　中间层维度足够大的重要性　　65
3.5.8　进一步的实验　　66
3.5.9　小结　　66
3.6　预测房价：回归问题　　66
3.6.1　波士顿房价数据集　　67
3.6.2　准备数据　　67
3.6.3　构建网络　　68
3.6.4　利用K折验证来验证你的方法　　68
3.6.5　小结　　72
本章小结　　73
第4章　机器学习基础　　74
4.1　机器学习的四个分支　　74
4.1.1　监督学习　　74
4.1.2　无监督学习　　75
4.1.3　自监督学习　　75
4.1.4　强化学习　　75
4.2　评估机器学习模型　　76
4.2.1　训练集、验证集和测试集　　77
4.2.2　评估模型的注意事项　　80
4.3　数据预处理、特征工程和特征学习　　80
4.3.1　神经网络的数据预处理　　80
4.3.2　特征工程　　81
4.4　过拟合与欠拟合　　83
4.4.1　减小网络大小　　83
4.4.2　添加权重正则化　　85
4.4.3　添加dropout正则化　　87
4.5　机器学习的通用工作流程　　89
4.5.1　定义问题，收集数据集　　89
4.5.2　选择衡量成功的指标　　89
4.5.3　确定评估方法　　90
4.5.4　准备数据　　90
4.5.5　开发比基准更好的模型　　90
4.5.6　扩大模型规模：开发过拟合的模型　　91
4.5.7　模型正则化与调节超参数　　92
本章小结　　92
第二部分　深度学习实践
第5章　深度学习用于计算机视觉　　94
5.1　卷积神经网络简介　　94
5.1.1　卷积运算　　96
5.1.2　最大池化运算　　101
5.2　在小型数据集上从头开始训练一个卷积神经网络　　102
5.2.1　深度学习与小数据问题的相关性　　103
5.2.2　下载数据　　103
5.2.3　构建网络　　106
5.2.4　数据预处理　　107
5.2.5　使用数据增强　　111
5.3　使用预训练的卷积神经网络　　115
5.3.1　特征提取　　116
5.3.2　微调模型　　124
5.3.3　小结　　130
5.4　卷积神经网络的可视化　　130
5.4.1　可视化中间激活　　131
5.4.2　可视化卷积神经网络的过滤器　　136
5.4.3　可视化类激活的热力图　　142
本章小结　　146
第6章　深度学习用于文本和序列　　147
6.1　处理文本数据　　147
6.1.1　单词和字符的one-hot编码　　149
6.1.2　使用词嵌入　　151
6.1.3　整合在一起：从原始文本到词嵌入　　155
6.1.4　小结　　162
6.2　理解循环神经网络　　162
6.2.1　Keras中的循环层　　164
6.2.2　理解LSTM层和GRU层　　168
6.2.3　Keras中一个LSTM的具体例子　　170
6.2.4　小结　　172
6.3　循环神经网络的高级用法　　172
6.3.1　温度预测问题　　172
6.3.2　准备数据　　175
6.3.3　一种基于常识的、非机器学习的基准方法　　177
6.3.4　一种基本的机器学习方法　　178
6.3.5　第一个循环网络基准　　180
6.3.6　使用循环dropout来降低过拟合　　181
6.3.7　循环层堆叠　　182
6.3.8　使用双向RNN　　184
6.3.9　更多尝试　　187
6.3.10　小结　　187
6.4　用卷积神经网络处理序列　　188
6.4.1　理解序列数据的一维卷积　　188
6.4.2　序列数据的一维池化　　189
6.4.3　实现一维卷积神经网络　　189
6.4.4　结合CNN和RNN来处理长序列　　191
6.4.5　小结　　195
本章总结　　195
第7章　高级的深度学习最佳实践　　196
7.1　不用Sequential模型的解决方案：Keras 函数式API　　196
7.1.1　函数式API简介　　199
7.1.2　多输入模型　　200
7.1.3　多输出模型　　202
7.1.4　层组成的有向无环图　　204
7.1.5　共享层权重　　208
7.1.6　将模型作为层　　208
7.1.7　小结　　209
7.2　使用Keras回调函数和TensorBoard来检查并监控深度学习模型　　210
7.2.1　训练过程中将回调函数作用于模型　　210
7.2.2　TensorBoard简介：TensorFlow的可视化框架　　212
7.2.3　小结　　219
7.3　让模型性能发挥到极致　　219
7.3.1　高级架构模式　　219
7.3.2　超参数优化　　222
7.3.3　模型集成　　223
7.3.4　小结　　224
本章总结　　225
第8章　生成式深度学习　　226
8.1　使用LSTM生成文本　　227
8.1.1　生成式循环网络简史　　227
8.1.2　如何生成序列数据　　228
8.1.3　采样策略的重要性　　229
8.1.4　实现字符级的LSTM文本生成　　230
8.1.5　小结　　234
8.2　DeepDream　　235
8.2.1　用Keras实现DeepDream　　236
8.2.2　小结　　241
8.3　神经风格迁移　　241
8.3.1　内容损失　　242
8.3.2　风格损失　　243
8.3.3　用Keras实现神经风格迁移　　243
8.3.4　小结　　249
8.4　用变分自编码器生成图像　　249
8.4.1　从图像的潜在空间中采样　　249
8.4.2　图像编辑的概念向量　　250
8.4.3　变分自编码器　　251
8.4.4　小结　　256
8.5　生成式对抗网络简介　　257
8.5.1　GAN 的简要实现流程　　258
8.5.2　大量技巧　　259
8.5.3　生成器　　260
8.5.4　判别器　　261
8.5.5　对抗网络　　261
8.5.6　如何训练DCGAN　　262
8.5.7　小结　　264
本章总结　　264
第9章　总结　　265
9.1　重点内容回顾　　265
9.1.1　人工智能的各种方法　　265
9.1.2　深度学习在机器学习领域中的特殊之处　　266
9.1.3　如何看待深度学习　　266
9.1.4　关键的推动技术　　267
9.1.5　机器学习的通用工作流程　　268
9.1.6　关键网络架构　　268
9.1.7　可能性空间　　272
9.2　深度学习的局限性　　273
9.2.1　将机器学习模型拟人化的风险　　273
9.2.2　局部泛化与极端泛化　　275
9.2.3　小结　　276
9.3　深度学习的未来　　277
9.3.1　模型即程序　　277
9.3.2　超越反向传播和可微层　　278
9.3.3　自动化机器学习　　279
9.3.4　终身学习与模块化子程序复用　　279
9.3.5　长期愿景　　281
9.4　了解一个快速发展领域的最新进展　　281
9.4.1　使用Kaggle练习解决现实世界的问题　　281
9.4.2　在arXiv阅读最新进展　　282
9.4.3　探索Keras生态系统　　282
9.5　结束语　　282
附录A　在Ubuntu上安装Keras及其依赖　　283
附录B　在EC2 GPU实例上运行Jupyter笔记本　　287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数学之美 （第二版）
第二版出版说明
序言1
序言2
前言
第1 章　文字和语言 vs 数字和信息
第2 章　自然语言处理 — 从规则到统计
第3 章　统计语言模型
第4 章　谈谈分词
第5 章　隐含马尔可夫模型
第6 章　信息的度量和作用
第7 章　贾里尼克和现代语言处理
第8 章　简单之美 — 布尔代数和搜索引擎
第9 章　图论和网络爬虫
第10章　PageRank — Google的民主表决式网页排名技术
第11章　如何确定网页和查询的相关性
第12章　有限状态机和动态规划 — 地图与本地
第13章　Google AK-47 的设计者 — 阿米特· 辛格博士
第14章　余弦定理和新闻的分类
第15章　矩阵运算和文本处理中的两个分类问题
第16章　信息指纹及其应用
第17章　由电视剧《暗算》所想到的 — 谈谈密码学的数学原理
第18章　闪光的不一定是金子 — 谈谈搜索引擎
第19章　谈谈数学模型的重要性
第20章　不要把鸡蛋放到一个篮子里 — 谈谈最
第21章　拼音输入法的数学原理
第22章　自然语言处理的教父马库斯和他的优秀弟子们
第23章　布隆过滤器
第24章　马尔可夫链的扩展 — 贝叶斯网络
第25章　条件随机场、文法分析及其他
第26章　维特比和他的维特比算法
第27章　上帝的算法 — 期望最大化算法
第28章　逻辑回归和搜索广告
第29章　各个击破算法和Google 云计算的基础
第30章　Google 大脑和人工神经网络
第31章　大数据的威力——谈谈数据的重要性
附录
后记
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数学之美 （第二版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习方法
第1章 统计学习方法概论
1.1 统计学习
1.2 监督学习
1.3 统计学习三要素
1.4 模型评估与模型选择
1.5 i~则化与交叉验证
1.6 泛化能力
1.7 生成模型与判别模型
1.8 分类问题
1.9 标注问题
1.10 回归问题
本章概要
继续阅读
习题
参考文献
第2章 感知机
2.1 感知机模型
2.2 感知机学习策略
2.3 感知机学习算法
本章概要
继续阅读
习题
参考文献
第3章 众近邻法
3.1 k近邻算法
3.2 k近邻模型
3.3 k近邻法的实现：kd树
本章概要
继续阅读
习题
参考文献
第4章 朴素贝叶斯法
4.1 朴素贝叶斯法的学习与分类
4.2 朴素贝叶斯法的参数估计
本章概要
继续阅读
习题
参考文献
第5章 决策树
第6章 逻辑斯谛回归与最大熵模型
第7章 支持向量机
第8章 提升方法
第9章 em算法及其推广
第10章 隐马尔可夫模型
第11章 条件随机场
第12章 统计学习方法总结
附录a 梯度下降法
附录b 牛顿法和拟牛顿法
附录c 拉格朗日对偶性
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>利用Python进行数据分析
目录
前言 1
第1章 准备工作 5
本书主要内容 5
为什么要使用Python进行数据分析 6
重要的Python库 7
安装和设置 10
社区和研讨会 16
使用本书 16
致谢 18
第2章 引言 20
来自bit.ly的1.usa.gov数据 21
MovieLens 1M数据集 29
1880—2010年间全美婴儿姓名 35
小结及展望 47
第3章 IPython：一种交互式计算和开发环境 48
IPython基础 49
内省 51
使用命令历史 60
与操作系统交互 63
软件开发工具 66
IPython HTML Notebook 75
利用IPython提高代码开发效率的几点提示 77
高级IPython功能 79
致谢 81
第4章 NumPy基础：数组和矢量计算 82
NumPy的ndarray：一种多维数组对象 83
通用函数：快速的元素级数组函数 98
利用数组进行数据处理 100
用于数组的文件输入输出 107
线性代数 109
随机数生成 111
范例：随机漫步 112
第5章 pandas入门 115
pandas的数据结构介绍 116
基本功能 126
汇总和计算描述统计 142
处理缺失数据 148
层次化索引 153
其他有关pandas的话题 158
第6章 数据加载、存储与文件格式 162
读写文本格式的数据 162
二进制数据格式 179
使用HTML和Web API 181
使用数据库 182
第7章 数据规整化：清理、转换、合并、重塑 186
合并数据集 186
重塑和轴向旋转 200
数据转换 204
字符串操作 217
示例：USDA食品数据库 224
第8章 绘图和可视化 231
matplotlib API入门 231
pandas中的绘图函数 244
绘制地图：图形化显示海地地震危机数据 254
Python图形化工具生态系统 260
第9章 数据聚合与分组运算 263
GroupBy技术 264
数据聚合 271
分组级运算和转换 276
透视表和交叉表 288
示例：2012联邦选举委员会数据库 291
第10章 时间序列 302
日期和时间数据类型及工具 303
时间序列基础 307
日期的范围、频率以及移动 311
时区处理 317
时期及其算术运算 322
重采样及频率转换 327
时间序列绘图 334
移动窗口函数 337
性能和内存使用方面的注意事项 342
第11章 金融和经济数据应用 344
数据规整化方面的话题 344
分组变换和分析 355
更多示例应用 361
第12章 NumPy高级应用 368
ndarray对象的内部机理 368
高级数组操作 370
广播 378
ufunc高级应用 383
结构化和记录式数组 386
更多有关排序的话题 388
NumPy的matrix类 393
高级数组输入输出 395
性能建议 397
附录A Python语言精要 401
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>利用Python进行数据分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>集体智慧编程
前言
第1章　集体智慧导言
什么是集体智慧
什么是机器学习
机器学习的局限
真实生活中的例子
学习型算法的其他用途
第2章　提供推荐
协作型过滤
搜集偏好
寻找相近的用户
推荐物品
匹配商品
构建一个基于del.icio.us的链接推荐系统
基于物品的过滤
使用MovieLens数据集
基于用户进行过滤还是基于物品进行过滤
练习
第3章　发现群组
监督学习和无监督学习
单词向量
分级聚类
绘制树状图
列聚类
K-均值聚类
针对偏好的聚类
以二维形式展现数据
有关聚类的其他事宜
练习
第4章　搜索与排名
搜索引擎的组成
一个简单的爬虫程序
建立索引
查询
基于内容的排名
利用外部回指链接
从点击行为中学习
练习
第5章　优化
组团旅游
描述题解
成本函数
随机搜索
爬山法
模拟退火算法
遗传算法
真实的航班搜索
涉及偏好的优化
网络可视化
其他可能的应用场合
练习
第6章　文档过滤
过滤垃圾信息
文档和单词
对分类器进行训练
计算概率
朴素分类器
费舍尔方法
将经过训练的分类器持久化
过滤博客订阅源
对特征检测的改进
使用Akismet
替代方法
练习
第7章　决策树建模
预测注册用户
引入决策树
对树进行训练
选择最合适的拆分方案
以递归方式构造树
决策树的显示
对新的观测数据进行分类
决策树的剪枝
处理缺失数据
处理数值型结果
对住房价格进行建模
对“热度”评价进行建模
什么时候使用决策树
练习
第8章　构建价格模型
构造一个样本数据集
k-最近邻算法
为近邻分配权重
交叉验证
不同类型的变量
对缩放结果进行优化
不对称分布
使用真实数据——eBay API
何时使用k-最近邻算法
练习
第9章　高阶分类：核方法与SVM
婚介数据集
数据中的难点
基本的线性分类
分类特征
对数据进行缩放处理
理解核方法
支持向量机
使用LIBSVM
基于Facebook的匹配
练习
第10章　寻找独立特征
搜集一组新闻
先前的方法
非负矩阵因式分解
结果呈现
利用股票市场的数据
练习
第11章　智能进化
什么是遗传编程
将程序以树形方式表示
构造初始种群
测试题解
对程序进行变异
交叉
构筑环境
一个简单的游戏
更多可能性
练习
第12章　算法总结
贝叶斯分类器
决策树分类器
神经网络
支持向量机
k-最近邻
聚类
多维缩放
非负矩阵因式分解
优化
附录A：第三方函数库
附录B：数学公式
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>集体智慧编程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习
第 1 章 引言 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1
1.1 本书面向的读者 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .7
1.2 深度学习的历史趋势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1.2.1 神经网络的众多名称和命运变迁 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 8
1.2.2 与日俱增的数据量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
1.2.3 与日俱增的模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13
1.2.4 与日俱增的精度、复杂度和对现实世界的冲击 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15
第 1 部分 应用数学与机器学习基础
第 2 章 线性代数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.1 标量、向量、矩阵和张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
2.2 矩阵和向量相乘. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .21
2.3 单位矩阵和逆矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
2.4 线性相关和生成子空间 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23
2.5 范数. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .24
2.6 特殊类型的矩阵和向量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
2.7 特征分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
2.8 奇异值分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.9 Moore-Penrose 伪逆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28
2.10 迹运算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
2.11 行列式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 30
2.12 实例：主成分分析. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .30
第 3 章 概率与信息论. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .34
3.1 为什么要使用概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
3.2 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
3.3 概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
3.3.1 离散型变量和概率质量函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
3.3.2 连续型变量和概率密度函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
3.4 边缘概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
3.5 条件概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
3.6 条件概率的链式法则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
3.7 独立性和条件独立性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
3.8 期望、方差和协方差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38
3.9 常用概率分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
3.9.1 Bernoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.9.2 Multinoulli 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.9.3 高斯分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
3.9.4 指数分布和 Laplace 分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
3.9.5 Dirac 分布和经验分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
3.9.6 分布的混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
3.10 常用函数的有用性质. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .43
3.11 贝叶斯规则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
3.12 连续型变量的技术细节 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
3.13 信息论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
3.14 结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
第 4 章 数值计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
4.1 上溢和下溢 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 52
4.2 病态条件 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.3 基于梯度的优化方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.3.1 梯度之上：Jacobian 和 Hessian 矩阵 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
4.4 约束优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
4.5 实例：线性最小二乘 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
第 5 章 机器学习基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .63
5.1 学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
5.1.1 任务 T . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 63
5.1.2 性能度量 P . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
5.1.3 经验 E . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
5.1.4 示例：线性回归 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
5.2 容量、过拟合和欠拟合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
5.2.1 没有免费午餐定理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5.2.2 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74
5.3 超参数和验证集. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .76
5.3.1 交叉验证 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
5.4 估计、偏差和方差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77
5.4.1 点估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77
5.4.2 偏差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
5.4.3 方差和标准差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
5.4.4 权衡偏差和方差以最小化均方误差 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
5.4.5 一致性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
5.5 最大似然估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
5.5.1 条件对数似然和均方误差. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .84
5.5.2 最大似然的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 84
5.6 贝叶斯统计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 85
5.6.1 最大后验 (MAP) 估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
5.7 监督学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
5.7.1 概率监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
5.7.2 支持向量机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
5.7.3 其他简单的监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90
5.8 无监督学习算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .91
5.8.1 主成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
5.8.2 k-均值聚类 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .94
5.9 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
5.10 构建机器学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
5.11 促使深度学习发展的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
5.11.1 维数灾难 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
5.11.2 局部不变性和平滑正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
5.11.3 流形学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
第 2 部分 深度网络：现代实践
第 6 章 深度前馈网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
6.1 实例：学习 XOR. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
6.2 基于梯度的学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
6.2.1 代价函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
6.2.2 输出单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
6.3 隐藏单元. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .119
6.3.1 整流线性单元及其扩展 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
6.3.2 logistic sigmoid 与双曲正切函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
6.3.3 其他隐藏单元 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
6.4 架构设计. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123
6.4.1 万能近似性质和深度. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .123
6.4.2 其他架构上的考虑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126
6.5 反向传播和其他的微分算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126
6.5.1 计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
6.5.2 微积分中的链式法则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .128
6.5.3 递归地使用链式法则来实现反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
6.5.4 全连接 MLP 中的反向传播计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 131
6.5.5 符号到符号的导数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .131
6.5.6 一般化的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .133
6.5.7 实例：用于 MLP 训练的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135
6.5.8 复杂化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
6.5.9 深度学习界以外的微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
6.5.10 高阶微分 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 138
6.6 历史小记. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .139
第 7 章 深度学习中的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
7.1 参数范数惩罚 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
7.1.1 L2 参数正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
7.1.2 L1 正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
7.2 作为约束的范数惩罚. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .146
7.3 正则化和欠约束问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .147
7.4 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
7.5 噪声鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
7.5.1 向输出目标注入噪声. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .150
7.6 半监督学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
7.7 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150
7.8 提前终止. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .151
7.9 参数绑定和参数共享. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .156
7.9.1 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
7.10 稀疏表示. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .157
7.11 Bagging 和其他集成方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .158
7.12 Dropout . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .159
7.13 对抗训练. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .165
7.14 切面距离、正切传播和流形正切分类器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
第 8 章 深度模型中的优化. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .169
8.1 学习和纯优化有什么不同 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
8.1.1 经验风险最小化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
8.1.2 代理损失函数和提前终止 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
8.1.3 批量算法和小批量算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
8.2 神经网络优化中的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
8.2.1 病态 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
8.2.2 局部极小值 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
8.2.3 高原、鞍点和其他平坦区域 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175
8.2.4 悬崖和梯度爆炸 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
8.2.5 长期依赖 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
8.2.6 非精确梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
8.2.7 局部和全局结构间的弱对应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
8.2.8 优化的理论限制 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
8.3 基本算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .180
8.3.1 随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
8.3.2 动量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
8.3.3 Nesterov 动量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .183
8.4 参数初始化策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
8.5 自适应学习率算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
8.5.1 AdaGrad . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
8.5.2 RMSProp . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188
8.5.3 Adam . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
8.5.4 选择正确的优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .190
8.6 二阶近似方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
8.6.1 牛顿法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 190
8.6.2 共轭梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
8.6.3 BFGS. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
8.7 优化策略和元算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
8.7.1 批标准化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
8.7.2 坐标下降 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
8.7.3 Polyak 平均 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
8.7.4 监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
8.7.5 设计有助于优化的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 199
8.7.6 延拓法和课程学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .199
第 9 章 卷积网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
9.1 卷积运算. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .201
9.2 动机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
9.3 池化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
9.4 卷积与池化作为一种无限强的先验 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 210
9.5 基本卷积函数的变体. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .211
9.6 结构化输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
9.7 数据类型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .219
9.8 高效的卷积算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
9.9 随机或无监督的特征. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .220
9.10 卷积网络的神经科学基础 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
9.11 卷积网络与深度学习的历史 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
第 10 章 序列建模：循环和递归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
10.1 展开计算图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
10.2 循环神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .230
10.2.1 导师驱动过程和输出循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 232
10.2.2 计算循环神经网络的梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
10.2.3 作为有向图模型的循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 235
10.2.4 基于上下文的 RNN 序列建模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
10.3 双向 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
10.4 基于编码 - 解码的序列到序列架构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
10.5 深度循环网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .242
10.6 递归神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .243
10.7 长期依赖的挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
10.8 回声状态网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245
10.9 渗漏单元和其他多时间尺度的策略 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
10.9.1 时间维度的跳跃连接. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .247
10.9.2 渗漏单元和一系列不同时间尺度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
10.9.3 删除连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
10.10 长短期记忆和其他门控 RNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
10.10.1 LSTM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
10.10.2 其他门控 RNN. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .250
10.11 优化长期依赖. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251
10.11.1 截断梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 251
10.11.2 引导信息流的正则化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 252
10.12 外显记忆 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
第 11 章 实践方法论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
11.1 性能度量. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .256
11.2 默认的基准模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
11.3 决定是否收集更多数据 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
11.4 选择超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
11.4.1 手动调整超参数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .259
11.4.2 自动超参数优化算法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .262
11.4.3 网格搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
11.4.4 随机搜索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
11.4.5 基于模型的超参数优化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 264
11.5 调试策略. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .264
11.6 示例：多位数字识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
第 12 章 应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .269
12.1 大规模深度学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
12.1.1 快速的 CPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
12.1.2 GPU 实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
12.1.3 大规模的分布式实现. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .271
12.1.4 模型压缩 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
12.1.5 动态结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
12.1.6 深度网络的专用硬件实现 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
12.2 计算机视觉 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
12.2.1 预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
12.2.2 数据集增强 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
12.3 语音识别. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .278
12.4 自然语言处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .279
12.4.1 n-gram . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .280
12.4.2 神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281
12.4.3 高维输出 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 282
12.4.4 结合 n-gram 和神经语言模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 286
12.4.5 神经机器翻译 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 287
12.4.6 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289
12.5 其他应用. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .290
12.5.1 推荐系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 290
12.5.2 知识表示、推理和回答 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 292
第 3 部分 深度学习研究
第 13 章 线性因子模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
13.1 概率 PCA 和因子分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
13.2 独立成分分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .298
13.3 慢特征分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 300
13.4 稀疏编码. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .301
13.5 PCA 的流形解释 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 304
第 14 章 自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306
14.1 欠完备自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 306
14.2 正则自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .307
14.2.1 稀疏自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
14.2.2 去噪自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
14.2.3 惩罚导数作为正则. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .309
14.3 表示能力、层的大小和深度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310
14.4 随机编码器和解码器. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310
14.5 去噪自编码器详解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311
14.5.1 得分估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 312
14.5.2 历史展望 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
14.6 使用自编码器学习流形 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 314
14.7 收缩自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .317
14.8 预测稀疏分解 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .319
14.9 自编码器的应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
第 15 章 表示学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321
15.1 贪心逐层无监督预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 322
15.1.1 何时以及为何无监督预训练有效有效 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323
15.2 迁移学习和领域自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 326
15.3 半监督解释因果关系. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .329
15.4 分布式表示 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 332
15.5 得益于深度的指数增益 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 336
15.6 提供发现潜在原因的线索 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 337
第 16 章 深度学习中的结构化概率模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
16.1 非结构化建模的挑战. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .339
16.2 使用图描述模型结构. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .342
16.2.1 有向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
16.2.2 无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344
16.2.3 配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
16.2.4 基于能量的模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .346
16.2.5 分离和 d-分离 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .347
16.2.6 在有向模型和无向模型中转换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 350
16.2.7 因子图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 352
16.3 从图模型中采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353
16.4 结构化建模的优势 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353
16.5 学习依赖关系 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .354
16.6 推断和近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354
16.7 结构化概率模型的深度学习方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .355
16.7.1 实例：受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
第 17 章 蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 359
17.1 采样和蒙特卡罗方法. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .359
17.1.1 为什么需要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .359
17.1.2 蒙特卡罗采样的基础. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .359
17.2 重要采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .360
17.3 马尔可夫链蒙特卡罗方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 362
17.4 Gibbs 采样. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .365
17.5 不同的峰值之间的混合挑战 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
17.5.1 不同峰值之间通过回火来混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 367
17.5.2 深度也许会有助于混合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368
第 18 章 直面配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 369
18.1 对数似然梯度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .369
18.2 随机最大似然和对比散度 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
18.3 伪似然 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 375
18.4 得分匹配和比率匹配. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .376
18.5 去噪得分匹配 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .378
18.6 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .378
18.7 估计配分函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .380
18.7.1 退火重要采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 382
18.7.2 桥式采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384
第 19 章 近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 385
19.1 把推断视作优化问题. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .385
19.2 期望最大化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 386
19.3 最大后验推断和稀疏编码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387
19.4 变分推断和变分学习. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .389
19.4.1 离散型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
19.4.2 变分法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 394
19.4.3 连续型潜变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 396
19.4.4 学习和推断之间的相互作用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 397
19.5 学成近似推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .397
19.5.1 醒眠算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398
19.5.2 学成推断的其他形式. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .398
第 20 章 深度生成模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
20.1 玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 399
20.2 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 400
20.2.1 条件分布 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
20.2.2 训练受限玻尔兹曼机. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .402
20.3 深度信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .402
20.4 深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404
20.4.1 有趣的性质 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
20.4.2 DBM 均匀场推断 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 406
20.4.3 DBM 的参数学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408
20.4.4 逐层预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 408
20.4.5 联合训练深度玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 410
20.5 实值数据上的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413
20.5.1 Gaussian-Bernoulli RBM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 413
20.5.2 条件协方差的无向模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 414
20.6 卷积玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417
20.7 用于结构化或序列输出的玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
20.8 其他玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
20.9 通过随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 419
20.9.1 通过离散随机操作的反向传播 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
20.10 有向生成网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .422
20.10.1 sigmoid 信念网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422
20.10.2 可微生成器网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .423
20.10.3 变分自编码器 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .425
20.10.4 生成式对抗网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .427
20.10.5 生成矩匹配网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .429
20.10.6 卷积生成网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .430
20.10.7 自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430
20.10.8 线性自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .430
20.10.9 神经自回归网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .431
20.10.10 NADE . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432
20.11 从自编码器采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433
20.11.1 与任意去噪自编码器相关的马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
20.11.2 夹合与条件采样 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .434
20.11.3 回退训练过程 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .435
20.12 生成随机网络. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .435
20.12.1 判别性 GSN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436
20.13 其他生成方案. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .436
20.14 评估生成模型. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .437
20.15 结论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438
参考文献. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .439
索引 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 486
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统实践
目　 　 录
第1章　 好的推荐系统　 　 1
1.1　 什么是推荐系统　 　 1
1.2　 个性化推荐系统的应用　 　 4
1.2.1　 电子商务　 　 4
1.2.2　 电影和视频网站　 　 8
1.2.3　 个性化音乐网络电台　 　 10
1.2.4　 社交网络　 　 12
1.2.5　 个性化阅读　 　 15
1.2.6　 基于位置的服务　 　 16
1.2.7　 个性化邮件　 　 17
1.2.8　 个性化广告　 　 18
1.3　 推荐系统评测　 　 19
1.3.1　 推荐系统实验方法　 　 20
1.3.2　 评测指标　 　 23
1.3.3　 评测维度　 　 34
第2章　 利用用户行为数据　 　 35
2.1　 用户行为数据简介　 　 36
2.2　 用户行为分析　 　 39
2.2.1　 用户活跃度和物品流行度的分布　 　 39
2.2.2　 用户活跃度和物品流行度的关系　 　 41
2.3　 实验设计和算法评测　 　 41
2.3.1　 数据集　 　 42
2.3.2　 实验设计　 　 42
2.3.3　 评测指标　 　 42
2.4　 基于邻域的算法　 　 44
2.4.1　 基于用户的协同过滤算法　 　 44
2.4.2　 基于物品的协同过滤算法　 　 51
2.4.3　 UserCF和ItemCF的综合比较　 　 59
2.5　 隐语义模型　 　 64
2.5.1　 基础算法　 　 64
2.5.2　 基于LFM的实际系统的例子　 　 70
2.5.3　 LFM和基于邻域的方法的比较　 　 72
2.6　 基于图的模型　 　 73
2.6.1　 用户行为数据的二分图表示　 　 73
2.6.2　 基于图的推荐算法　 　 73
第3章　 推荐系统冷启动问题　 　 78
3.1　 冷启动问题简介　 　 78
3.2　 利用用户注册信息　 　 79
3.3　 选择合适的物品启动用户的兴趣　 　 85
3.4　 利用物品的内容信息　 　 89
3.5　 发挥专家的作用　 　 94
第4章　 利用用户标签数据　 　 96
4.1　 UGC标签系统的代表应用　 　 97
4.1.1　 Delicious　 　 97
4.1.2　 CiteULike　 　 98
4.1.3　 Last.fm　 　 98
4.1.4　 豆瓣　 　 99
4.1.5　 Hulu　 　 99
4.2　 标签系统中的推荐问题　 　 100
4.2.1　 用户为什么进行标注　 　 100
4.2.2　 用户如何打标签　 　 101
4.2.3　 用户打什么样的标签　 　 102
4.3　 基于标签的推荐系统　 　 103
4.3.1　 实验设置　 　 104
4.3.2　 一个最简单的算法　 　 105
4.3.3　 算法的改进　 　 107
4.3.4　 基于图的推荐算法　 　 110
4.3.5　 基于标签的推荐解释　 　 112
4.4　 给用户推荐标签　 　 115
4.4.1　 为什么要给用户推荐标签　 　 115
4.4.2　 如何给用户推荐标签　 　 115
4.4.3　 实验设置　 　 116
4.4.4　 基于图的标签推荐算法　 　 119
4.5　 扩展阅读　 　 119
第5章　 利用上下文信息　 　 121
5.1　 时间上下文信息　 　 122
5.1.1　 时间效应简介　 　 122
5.1.2　 时间效应举例　 　 123
5.1.3　 系统时间特性的分析　 　 125
5.1.4　 推荐系统的实时性　 　 127
5.1.5　 推荐算法的时间多样性　 　 128
5.1.6　 时间上下文推荐算法　 　 130
5.1.7　 时间段图模型　 　 134
5.1.8　 离线实验　 　 136
5.2　 地点上下文信息　 　 139
5.3　 扩展阅读　 　 143
第6章　 利用社交网络数据　 　 144
6.1　 获取社交网络数据的途径　 　 144
6.1.1　 电子邮件　 　 145
6.1.2　 用户注册信息　 　 146
6.1.3　 用户的位置数据　 　 146
6.1.4　 论坛和讨论组　 　 146
6.1.5　 即时聊天工具　 　 147
6.1.6　 社交网站　 　 147
6.2　 社交网络数据简介　 　 148社交网络数据中的长尾分布　 　 149
6.3　 基于社交网络的推荐　 　 150
6.3.1　 基于邻域的社会化推荐算法　 　 151
6.3.2　 基于图的社会化推荐算法　 　 152
6.3.3　 实际系统中的社会化推荐算法　 　 153
6.3.4　 社会化推荐系统和协同过滤推荐系统　 　 155
6.3.5　 信息流推荐　 　 156
6.4　 给用户推荐好友　 　 159
6.4.1　 基于内容的匹配　 　 161
6.4.2　 基于共同兴趣的好友推荐　 　 161
6.4.3　 基于社交网络图的好友推荐　 　 161
6.4.4　 基于用户调查的好友推荐算法对比　 　 164
6.5　 扩展阅读　 　 165
第7章　 推荐系统实例　 　 166
7.1　 外围架构　 　 166
7.2　 推荐系统架构　 　 167
7.3　 推荐引擎的架构　 　 171
7.3.1　 生成用户特征向量　 　 172
7.3.2　 特征?物品相关推荐　 　 173
7.3.3　 过滤模块　 　 174
7.3.4　 排名模块　 　 174
7.4　 扩展阅读　 　 178
第8章　 评分预测问题　 　 179
8.1　 离线实验方法　 　 180
8.2　 评分预测算法　 　 180
8.2.1　 平均值　 　 180
8.2.2　 基于邻域的方法　 　 184
8.2.3　 隐语义模型与矩阵分解模型　 　 186
8.2.4　 加入时间信息　 　 192
8.2.5　 模型融合　 　 193
8.2.6　 Netflix Prize的相关实验结果　 　 195
后记　 　 196

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>C#语言学习利器
前言第一部分  基础篇第1章  C#平台与AI-CODE概述  1．1  教育理念    1．1．1  传统教育    1．1．2  游戏教育理念    1．1．3  游戏化学习  1．2  机器人编程游戏历史    1．2．1  AI-CODE的诞生和发展    1．2．2  AI-CODE游戏教育系统简介    1．2．3  AI-CODE两大主题  1．3  什么是程序和算法    1．3．1  面向对象程序设计思想    1．3．2  什么是．NET    1．3．3  C#语言简介、起源    1．3．4  C#语言的特点    1．3．5  C#平台、环境说明    1．3．6  C#与Java语言的异同  1．4  快速体验    1．4．1  下载、安装我的AI-CODE    1．4．2  我的快乐竞技之旅    1．4．3  虚拟机器人运作平台——AIROBO    1．4．4  图形编辑器——机器人快车    1．4．5  代码编辑器——CodeCanvas第2章  AI-CODE的数学与物理知识  2．1  数学知识    2．1．1  坐标系统    2．1．2  三角几何学与方向    2．1．3  离散数学    2．1．4  数学函数  2．2  物理知识    2．2．1  机器人解剖    2．2．2  机器人速度、距离、力    2．2．3  子弹能量、热、速度    2．2．4  Force与动量守恒定理  2．3  基本参数    2．3．1  系统时钟    2．3．2  其他辅助参数第3章  图形编程——快速步入程序之门  3．1  学习目标与任务  3．2  机器人快车概述    3．2．1  机器人快车的安装与卸载    3．2．2  机器人快车简介    3．2．3  流程模块拖拉编程  3．3  向战场中央靠拢机器人  3．4  机器人快车函数封装  3．5  小结与练习第4章  我的第一个C#机器人  4．1  学习目标与任务  4．2  设置visuaI Studio．NET开发环境  4．3  机器人开发    4．3．1  AI-CODE开发目录设置    4．3．2  创建First机器人    4．3．3  机器人名称与名字空间  4．4  FirstRobot结构解析    4．4．1  Action与OnTick处理函数    4．4．2  常用函数  4．5  初识对象、类与继承    4．5．1  面向对象思想    4．5．2  First类及AI-TANK类图  4．6  知识扩展    4．6．1  关键字与注释码    4．6．2  经典例子机器人说明    4．6．3  C#程序结构  4．7  小结与练习    第二部分  中级篇第5章  基本运动与C#语言基础  5．1  学习目标与任务  5．2  基本运动策略  5．3  直线运动与C#基本元素    5．3．1  运动原理分析    5．3．2  绕墙走机器人剖析    5．3．3  数据类型、表达式、If-eIse控制  5．4  指定方向或位置运动    5．4．1  运动原理分析    5．4．2  heading与bear。ing方向解析    5．4．3  SuperCenter机器人剖析    5．4．4  C#代码规范  5．5  曲线运动    5．5．1  运动原理分析    5．5．2  圆周与倒8字运动机器人剖析    5．5．3  whiIe和for流程控制  5．6  扩展知识    5．6．1  变量与常量定义    5．6．2  三角函数与C#函数    5．6．3  switch分支语句    5．6．4  运算符和赋值概念    5．6．5  基本防御组合应用小析    5．6．6  装箱(boxing)和拆箱(unboxing)  5．7  小结与练习第6章  基本瞄准与函数  6．1  学习目标与任务  6．2  基本瞄准策略    6．2．1  三大基本瞄准策略    6．2．2  相关事件的处理  6．3  定点瞄准  6．4  线性预测瞄准    6．4．1  提前量直线瞄准原理分析与正弦定理应用    6．4．2  提前量直线瞄准机器人剖析    6．4．3  直线迭代瞄准与const常量  6．5  圆周预测瞄准与C#函数    6．5．1  圆周预测瞄准原理分析    6．5．2圆周预测瞄准机器人剖析    6．5．3 C#函数详析  6．6  小结与练习第三部分  高级篇第7章  战争情报员与数组、集合  7．1  学习目标与任务  7．2  信息收集与数组    7．2．1  信息收集机器人    7．2．2  C#数组  7．3  信息收集与集合    7．3．1  信息收集机器人    7．3．2  C#集合  7．4  小结与练习第8章  对象、类实现避弹、避墙  8．1  学习目标与任务  8．2  躲避子弹机器人    8．2．1  躲避子弹原理    8．2．2  躲避子弹机器人剖析    8．2．3  子弹类实现  8．3  对象和类再析    8．3．1  面向对象    8．3．2  类声明和成员    8．3．3  深入研究new运算符    8．3．4  构造函数与析构函数  8．4  因数避墙机器人    8．4．1  因数避墙原理    8．4．2  因数避墙机器人剖析    8．4．3  因数避墙机器人改进与扩展    8．4．4  static关键字  8．5  扩展知识    8．5．1  C#修饰符列表    8．5．2  对机器人进行管理  8．6  小结与练习第9章  继承、多态实现高级机器人  9．1  学习目标与任务  9．2  高级运动策略与继承、多态性    9．2．1  高级运动策略分析    9．2．2  高级运动机器人的实现    9．2．3  C#继承与多态    9．2．4  反重力运动机器人剖析  9．3  高级瞄准策略    9．3．1  高级瞄准策略分析    9．3．2  振荡瞄准机器人    9．3．3  模式匹配瞄准机器人    9．3．4  统计学瞄准、虚拟子弹、波    9．3．5  其他瞄准算法  9．4  扩展知识    9．4．1  随机运动策略介绍    9．4．2  this关键字    9．4．3  sealed关键字与密封类  9．5  小结与练习第10章  战略合成与C#接口、抽象  10．1  学习目标与任务  10．2  战略组合与C#接口和抽象    10．2．1  高手的秘诀：战略组合    10．2．2  设计可重用机器人结构    10．2．3  C#抽象与接口    10．2．4  C#机器人编程接口  10．3  扩展知识    10．3．1  浅析C#事件与委托    10．3．2  虚拟方法    10．3．3  重写override  10．4  小结与练习第11章  机器人异常调试  11．1  学习目标与任务  11．2  调试机器人    11．2．1  AI-TANK控制台    11．2．2  输出变量的值    11．2．3  AI-TANK调试函数  11．3  C#异常处理  11．4  Record机器人  11．5  C#IO  11．6  扩展(预处理指令)  11．7  小结与练习第12章  团队作战实现  12．1  学习目标与任务  12．2  团队作战机制与通信兵    12．2．1  创建机器人团队    12．2．2  团队内的通信  12．3  团队作战机器人    12．3．1  混战避敌原理    12．3．2  混战算法设计    12．3．3  混战避敌代码的实现    12．3．4  混战避敌算法改进与扩展  12．4  小结与练习第13章  高级调试与绘图机器人  13．1  学习目标与任务  13．2  美丽的轨迹图    13．2．1  打开机器人图形控制    13．2．2  振动波绘图机器人实现  13．3  机器人绘图类实现原理  13．4  小结与练习    第四部分  专家篇第14章  智能机器人  14．1  人工智能    14．1．1  人工智能概念    14．1．2  人工智能的研究和应用领域    14．1．3  AI-TANK在人工智能领域的研究范围  14．2  强化学习机器人    14．2．1  原理概述    14．2．2  机器人设计分析    14．2．3  算法设计  14．3  神经网络机器人    14．3．1  原理概述    14．3．2  机器人设计分析    14．3．3  反向传播算法设计  14．4  遗传算法机器人    14．4．1  原理概述    14．4．2  预设策略进化机器人剖析    14．4．3  遗传操作机器人    14．4．4  中间解释程序进化机器人  14．5  机器学习机器人    14．5．1  机器学习原理    14．5．2  Bayesian团队机器人设计    14．5．3  算法设计第15章  联赛系统、XML与内部机制  15．1  联赛系统  15．2  机器人配置与启动原理  15．3  机器人编程接口与内核  15．4  XMI入门  15．5  XMI DOM模型实现机器人通信第16章  AI-CODE外传  16．1  策略流派  16．2  天才创意机器人    16．2．1  撞击攻击机器人RamFire    16．2．2  跟踪者Tracket    16．2．3  舞蹈机器人Dancer    16．2．4  克隆机器人Dolly附录1  章节机器人对照表附录2  知识点参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>C#语言学习利器
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>计算广告
（1）第一部分介绍在线广告领域的一些基本问题和背景知识。虽然内容比较容易理解，但这部分是全书的基础，特别是对很多相关概念和术语的集中介绍，请不要略过。
（2）第二部分主要面向产品、运营、销售等人员，以及互联网产品的宏观决策者，其内容重点在于介绍计算广告的市场结构、交易模式和主要产品。这部分内容将依在线广告产品发展的顺序展开，希望能帮助大家理解各种复杂的广告产品和交易机制产生的内在规律。
（3）第三部分主要面向系统工程师、算法工程师和架构师。与前一部分的广告产品相对应，这部分也以在线广告产品发展的顺序，重点阐释实现各种广告产品的关键技术挑战，并提供基础的解决方案。
内容提要
对本书的点评
序一
序二
序三
前言
第一部分 在线广告市场与背景
第 1 章 在线广告综述
第 2 章 计算广告基础
第二部分 在线广告产品逻辑
第 3 章 在线广告产品概览
第 4 章 合约广告
第 5 章 搜索与竞价广告
第 6 章 程序化交易广告
第 7 章 移动互联与原生广告
第 8 章 在线广告产品实践
第三部分 计算广告关键技术
第 9 章 计算广告技术概览
第 10 章 基础知识准备
第 11 章 合约广告核心技术
第 12 章 受众定向核心技术
第 13 章 竞价广告核心技术
第 14 章 程序化交易核心技术
第 15 章 其他广告相关技术
第四部分 附录
附录 A 主要术语及缩写索引
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>计算广告
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据科学手册
译者序 xiii
前言 xv
第1 章　IPython：超越Python 1
1.1　shell还是Notebook 1
1.1.1　启动IPython shell 2
1.1.2　启动Jupyter Notebook 2
1.2　IPython的帮助和文档 3
1.2.1　用符号? 获取文档 3
1.2.2　通过符号?? 获取源代码 4
1.2.3　用Tab补全的方式探索模块 5
1.3　IPython shell中的快捷键 7
1.3.1　导航快捷键 7
1.3.2　文本输入快捷键 7
1.3.3　命令历史快捷键 8
1.3.4　其他快捷键 9
1.4　IPython魔法命令 9
1.4.1　粘贴代码块：%paste和%cpaste 9
1.4.2　执行外部代码：%run 10
1.4.3　计算代码运行时间：%timeit 11
1.4.4　魔法函数的帮助：?、%magic 和%lsmagic 11
1.5　输入和输出历史 12
1.5.1　IPython的输入和输出对象 12
1.5.2　下划线快捷键和以前的输出 13
1.5.3　禁止输出 13
1.5.4　相关的魔法命令 13
1.6　IPython和shell命令 14
1.6.1　shell快速入门 14
1.6.2　IPython中的shell命令 15
1.6.3　在shell中传入或传出值 15
1.7　与shell相关的魔法命令 16
1.8　错误和调试 17
1.8.1　控制异常：%xmode 17
1.8.2　调试：当阅读轨迹追溯不足以解决问题时 19
1.9　代码的分析和计时 21
1.9.1　代码段计时：%timeit和%time 22
1.9.2　分析整个脚本：%prun 23
1.9.3　用%lprun进行逐行分析 24
1.9.4　用%memit和%mprun进行内存分析 25
1.10　IPython参考资料 26
1.10.1　网络资源 26
1.10.2　相关图书 27
第2 章　NumPy入门 28
2.1　理解Python中的数据类型 29
2.1.1　Python整型不仅仅是一个整型 30
2.1.2　Python列表不仅仅是一个列表 31
2.1.3　Python中的固定类型数组 32
2.1.4　从Python列表创建数组 32
2.1.5　从头创建数组 33
2.1.6　NumPy标准数据类型 34
2.2　NumPy数组基础 35
2.2.1　NumPy数组的属性 36
2.2.2　数组索引：获取单个元素 37
2.2.3　数组切片：获取子数组 38
2.2.4　数组的变形 41
2.2.5　数组拼接和分裂 42
2.3　NumPy数组的计算：通用函数 44
2.3.1　缓慢的循环 44
2.3.2　通用函数介绍 45
2.3.3　探索NumPy的通用函数 46
2.3.4　高级的通用函数特性 49
2.3.5　通用函数：更多的信息 51
2.4　聚合：最小值、最大值和其他值 51
2.4.1　数组值求和 51
2.4.2　最小值和最大值 52
2.4.3　示例：美国总统的身高是多少 54
2.5　数组的计算：广播 55
2.5.1　广播的介绍 55
2.5.2　广播的规则 57
2.5.3　广播的实际应用 60
2.6　比较、掩码和布尔逻辑 61
2.6.1　示例：统计下雨天数 61
2.6.2　和通用函数类似的比较操作 62
2.6.3　操作布尔数组 64
2.6.4　将布尔数组作为掩码 66
2.7　花哨的索引 69
2.7.1　探索花哨的索引 69
2.7.2　组合索引 70
2.7.3　示例：选择随机点 71
2.7.4　用花哨的索引修改值 72
2.7.5　示例：数据区间划分 73
2.8　数组的排序 75
2.8.1　NumPy中的快速排序：np.sort和np.argsort 76
2.8.2　部分排序：分隔 77
2.8.3　示例：K个最近邻 78
2.9　结构化数据：NumPy的结构化数组 81
2.9.1　生成结构化数组 83
2.9.2　更高级的复合类型 84
2.9.3　记录数组：结构化数组的扭转 84
2.9.4　关于Pandas 85
第3 章　Pandas数据处理 86
3.1　安装并使用Pandas 86
3.2　Pandas对象简介 87
3.2.1　Pandas的Series对象 87
3.2.2　Pandas的DataFrame对象 90
3.2.3　Pandas的Index对象 93
3.3　数据取值与选择 95
3.3.1　Series数据选择方法 95
3.3.2　DataFrame数据选择方法 98
3.4　Pandas数值运算方法 102
3.4.1　通用函数：保留索引 102
3.4.2　通用函数：索引对齐 103
3.4.3　通用函数：DataFrame与Series的运算 105
3.5　处理缺失值 106
3.5.1　选择处理缺失值的方法 106
3.5.2　Pandas的缺失值 107
3.5.3　处理缺失值 110
3.6　层级索引 113
3.6.1　多级索引Series 113
3.6.2　多级索引的创建方法 116
3.6.3　多级索引的取值与切片 119
3.6.4　多级索引行列转换 121
3.6.5　多级索引的数据累计方法 124
3.7　合并数据集：Concat与Append操作 125
3.7.1　知识回顾：NumPy数组的合并 126
3.7.2　通过pd.concat实现简易合并 126
3.8　合并数据集：合并与连接 129
3.8.1　关系代数 129
3.8.2　数据连接的类型 130
3.8.3　设置数据合并的键 132
3.8.4　设置数据连接的集合操作规则 134
3.8.5　重复列名：suffixes参数 135
3.8.6　案例：美国各州的统计数据 136
3.9　累计与分组 140
3.9.1　行星数据 140
3.9.2　Pandas的简单累计功能 141
3.9.3　GroupBy：分割、应用和组合 142
3.10　数据透视表 150
3.10.1　演示数据透视表 150
3.10.2　手工制作数据透视表 151
3.10.3　数据透视表语法 151
3.10.4　案例：美国人的生日 153
3.11　向量化字符串操作 157
3.11.1　Pandas字符串操作简介 157
3.11.2　Pandas字符串方法列表 159
3.11.3　案例：食谱数据库 163
3.12　处理时间序列 166
3.12.1　Python的日期与时间工具 166
3.12.2　Pandas时间序列：用时间作索引 169
3.12.3　Pandas时间序列数据结构 170
3.12.4　时间频率与偏移量 172
3.12.5　重新取样、迁移和窗口 173
3.12.6　更多学习资料 178
3.12.7　案例：美国西雅图自行车统计数据的可视化 179
3.13　高性能Pandas：eval()与query() 184
3.13.1　query()与eval()的设计动机：复合代数式 184
3.13.2　用pandas.eval()实现高性能运算 185
3.13.3　用DataFrame.eval()实现列间运算 187
3.13.4　DataFrame.query()方法 188
3.13.5　性能决定使用时机 189
3.14　参考资料 189
第4 章　Matplotlib数据可视化 191
4.1　Matplotlib常用技巧 192
4.1.1　导入Matplotlib 192
4.1.2　设置绘图样式 192
4.1.3　用不用show()？如何显示图形 192
4.1.4　将图形保存为文件 194
4.2　两种画图接口 195
4.2.1　MATLAB风格接口 195
4.2.2　面向对象接口 196
4.3　简易线形图 197
4.3.1　调整图形：线条的颜色与风格 199
4.3.2　调整图形：坐标轴上下限 200
4.3.3　设置图形标签 203
4.4　简易散点图 204
4.4.1　用plt.plot画散点图 205
4.4.2　用plt.scatter画散点图 206
4.4.3　plot与scatter：效率对比 208
4.5　可视化异常处理 208
4.5.1　基本误差线 209
4.5.2　连续误差 210
4.6　密度图与等高线图 211
4.7　频次直方图、数据区间划分和分布密度 215
4.8　配置图例 219
4.8.1　选择图例显示的元素 221
4.8.2　在图例中显示不同尺寸的点 222
4.8.3　同时显示多个图例 223
4.9　配置颜色条 224
4.9.1　配置颜色条 224
4.9.2　案例：手写数字 228
4.10　多子图 230
4.10.1　plt.axes：手动创建子图 230
4.10.2　plt.subplot：简易网格子图 231
4.10.3　plt.subplots：用一行代码创建网格 233
4.10.4　plt.GridSpec：实现更复杂的排列方式 234
4.11　文字与注释 235
4.11.1　案例：节假日对美国出生率的影响 236
4.11.2　坐标变换与文字位置 237
4.11.3　箭头与注释 239
4.12　自定义坐标轴刻度 241
4.12.1　主要刻度与次要刻度 242
4.12.2　隐藏刻度与标签 243
4.12.3　增减刻度数量 244
4.12.4　花哨的刻度格式 245
4.12.5　格式生成器与定位器小结 247
4.13　Matplotlib自定义：配置文件与样式表 248
4.13.1　手动配置图形 248
4.13.2　修改默认配置：rcParams 249
4.13.3　样式表 251
4.14　用Matplotlib画三维图 255
4.14.1　三维数据点与线 256
4.14.2　三维等高线图 256
4.14.3　线框图和曲面图 258
4.14.4　曲面三角剖分 259
4.15　用Basemap可视化地理数据 261
4.15.1　地图投影 263
4.15.2　画一个地图背景 267
4.15.3　在地图上画数据 269
4.15.4　案例：美国加州城市数据 270
4.15.5　案例：地表温度数据 271
4.16　用Seaborn做数据可视化 273
4.16.1　Seaborn与Matplotlib 274
4.16.2　Seaborn图形介绍 275
4.16.3　案例：探索马拉松比赛成绩数据 283
4.17　参考资料 290
4.17.1　Matplotlib资源 290
4.17.2　其他Python画图程序库 290
第5 章　机器学习 291
5.1　什么是机器学习 291
5.1.1　机器学习的分类 292
5.1.2　机器学习应用的定性示例 292
5.1.3　小结 299
5.2　Scikit-Learn简介 300
5.2.1　Scikit-Learn的数据表示 300
5.2.2　Scikit-Learn的评估器API 302
5.2.3　应用：手写数字探索 309
5.2.4　小结 313
5.3　超参数与模型验证 313
5.3.1　什么是模型验证 314
5.3.2　选择最优模型 317
5.3.3　学习曲线 322
5.3.4　验证实践：网格搜索 326
5.3.5　小结 327
5.4　特征工程 327
5.4.1　分类特征 327
5.4.2　文本特征 329
5.4.3　图像特征 330
5.4.4　衍生特征 330
5.4.5　缺失值填充 332
5.4.6　特征管道 332
5.5　专题：朴素贝叶斯分类 333
5.5.1　贝叶斯分类 333
5.5.2　高斯朴素贝叶斯 334
5.5.3　多项式朴素贝叶斯 336
5.5.4　朴素贝叶斯的应用场景 339
5.6　专题：线性回归 340
5.6.1　简单线性回归 340
5.6.2　基函数回归 342
5.6.3　正则化 346
5.6.4　案例：预测自行车流量 349
5.7　专题：支持向量机 353
5.7.1　支持向量机的由来 354
5.7.2　支持向量机：边界最大化 355
5.7.3　案例：人脸识别 363
5.7.4　支持向量机总结 366
5.8　专题：决策树与随机森林 367
5.8.1　随机森林的诱因：决策树 367
5.8.2　评估器集成算法：随机森林 371
5.8.3　随机森林回归 373
5.8.4　案例：用随机森林识别手写数字 374
5.8.5　随机森林总结 376
5.9　专题：主成分分析 376
5.9.1　主成分分析简介 377
5.9.2　用PCA作噪音过滤 383
5.9.3　案例：特征脸 385
5.9.4　主成分分析总结 387
5.10　专题：流形学习 388
5.10.1　流形学习：“HELLO” 388
5.10.2　多维标度法（MDS） 389
5.10.3　将MDS用于流形学习 391
5.10.4　非线性嵌入：当MDS失败时 393
5.10.5　非线性流形：局部线性嵌入 395
5.10.6　关于流形方法的一些思考 396
5.10.7　示例：用Isomap 处理人脸数据 397
5.10.8　示例：手写数字的可视化结构 400
5.11　专题：k-means聚类 402
5.11.1　k-means简介 403
5.11.2　k-means算法：期望最大化 404
5.11.3　案例 409
5.12　专题：高斯混合模型 415
5.12.1　高斯混合模型（GMM）为什么会出现：k-means算法
的缺陷 415
5.12.2　一般化E-M：高斯混合模型 417
5.12.3　将GMM用作密度估计 421
5.12.4　示例：用GMM生成新的数据 425
5.13　专题：核密度估计 427
5.13.1　KDE的由来：直方图 428
5.13.2　核密度估计的实际应用 431
5.13.3　示例：球形空间的KDE 433
5.13.4　示例：不是很朴素的贝叶斯 436
5.14　应用：人脸识别管道 439
5.14.1　HOG特征 440
5.14.2　HOG实战：简单人脸识别器 441
5.14.3　注意事项与改进方案 445
5.15　机器学习参考资料 446
5.15.1　Python中的机器学习 446
5.15.2　通用机器学习资源 447
关于作者 448
关于封面 448
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据科学手册
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>动手学深度学习
对本书的赞誉
前言
如何使用本书
资源与支持
主要符号表
第1 章　深度学习简介… ………………… 1
1.1　起源…………………………………………… 2
1.2　发展…………………………………………… 4
1.3　成功案例……………………………………… 6
1.4　特点………………………………………… 7
小结…………………………………………… 8
练习…………………………………………… 8
第2 章　预备知识… ……………………… 9
2.1　获取和运行本书的代码……………………… 9
2.1.1　获取代码并安装运行环境 … ……… 9
2.1.2　更新代码和运行环境 … …………… 11
2.1.3　使用GPU版的MXNet … ………… 11
小结……………………………………………12
练习……………………………………………12
2.2　数据操作… ……………………………… 12
2.2.1　创建NDArray ………………………12
2.2.2　运算 …………………………………14
2.2.3　广播机制 ……………………………16
2.2.4　索引 …………………………………17
2.2.5　运算的内存开销 ……………………17
2.2.6　NDArray和NumPy相互变换………18
小结……………………………………………19
练习……………………………………………19
2.3　自动求梯度… …………………………… 19
2.3.1　简单例子 … …………………………19
2.3.2　训练模式和预测模式 …………… 20
2.3.3　对Python控制流求梯度 … …… 20
小结……………………………………………21
练习……………………………………………21
2.4　查阅文档… ……………………………… 21
2.4.1　查找模块里的所有函数和类 … ……21
2.4.2　查找特定函数和类的使用 ……… 22
2.4.3　在MXNet网站上查阅 …………… 23
小结………………………………………… 24
练习………………………………………… 24
第3 章　深度学习基础… ……………… 25
3.1　线性回归…………………………………… 25
3.1.1　线性回归的基本要素 … ………… 25
3.1.2　线性回归的表示方法 … ………… 28
小结………………………………………… 30
练习………………………………………… 30
3.2　线性回归的从零开始实现… …………… 30
3.2.1　生成数据集 … …………………… 30
3.2.2　读取数据集 ……………………… 32
3.2.3　初始化模型参数 ………………… 32
3.2.4　定义模型 ………………………… 33
3.2.5　定义损失函数 …………………… 33
3.2.6　定义优化算法 …………………… 33
3.2.7　训练模型 ………………………… 33
小结………………………………………… 34
练习………………………………………… 34
3.3　线性回归的简洁实现… ………………… 35
3.3.1　生成数据集 … …………………… 35
3.3.2　读取数据集 ……………………… 35
3.3.3　定义模型 ………………………… 36
3.3.4　初始化模型参数 ………………… 36
3.3.5　定义损失函数 …………………… 37
3.3.6　定义优化算法 …………………… 37
3.3.7　训练模型 ………………………… 37
小结………………………………………… 38
练习………………………………………… 38
3.4　softmax回归… ………………………… 38
3.4.1　分类问题 … ……………………… 38
3.4.2　softmax回归模型… …………… 39
3.4.3　单样本分类的矢量计算表达式…… 40
3.4.4　小批量样本分类的矢量计算表达式 …………………………… 40
3.4.5　交叉熵损失函数 ……………………41
3.4.6　模型预测及评价 ………………… 42
小结………………………………………… 42
练习………………………………………… 42
3.5　图像分类数据集（Fashion-MNIST）… ……………… 42
3.5.1　获取数据集 … …………………… 42
3.5.2　读取小批量 ……………………… 44
小结………………………………………… 45
练习………………………………………… 45
3.6　softmax回归的从零开始实现… ……… 45
3.6.1　读取数据集 … …………………… 45
3.6.2　初始化模型参数 ………………… 45
3.6.3　实现softmax运算 … …………… 46
3.6.4　定义模型 ………………………… 46
3.6.5　定义损失函数 …………………… 47
3.6.6　计算分类准确率 ………………… 47
3.6.7　训练模型 ………………………… 48
3.6.8　预测… …………………………… 48
小结………………………………………… 49
练习………………………………………… 49
3.7　softmax回归的简洁实现… …………… 49
3.7.1　读取数据集 … …………………… 49
3.7.2　定义和初始化模型 ……………… 50
3.7.3　softmax和交叉熵损失函数 … … 50
3.7.4　定义优化算法 …………………… 50
3.7.5　训练模型 ………………………… 50
小结………………………………………… 50
练习………………………………………… 50
3.8　多层感知机… …………………………… 51
3.8.1　隐藏层 … ……………………………51
3.8.2　激活函数 ………………………… 52
3.8.3　多层感知机 ……………………… 55
小结………………………………………… 55
练习………………………………………… 55
3.9　多层感知机的从零开始实现… ………… 56
3.9.1　读取数据集 … …………………… 56
3.9.2　定义模型参数 …………………… 56
3.9.3　定义激活函数 …………………… 56
3.9.4　定义模型 ………………………… 56
3.9.5　定义损失函数 …………………… 57
3.9.6　训练模型 ………………………… 57
小结………………………………………… 57
练习………………………………………… 57
3.10　多层感知机的简洁实现………………… 57
3.10.1　定义模型 ………………………… 58
3.10.2　训练模型 … …………………… 58
小结………………………………………… 58
练习………………………………………… 58
3.11　模型选择、欠拟合和过拟合… ………… 58
3.11.1　训练误差和泛化误差 …………… 59
3.11.2　模型选择 ………………………… 59
3.11.3　欠拟合和过拟合 ………………… 60
3.11.4　多项式函数拟合实验 ……………61
小结………………………………………… 65
练习………………………………………… 65
3.12　权重衰减………………………………… 65
3.12.1　方法 ……………………………… 65
3.12.2　高维线性回归实验 … ………… 66
3.12.3　从零开始实现 … ……………… 66
3.12.4　简洁实现 … …………………… 68
小结………………………………………… 70
练习………………………………………… 70
3.13　丢弃法…………………………………… 70
3.13.1　方法 ……………………………… 70
3.13.2　从零开始实现 … …………………71
3.13.3　简洁实现 … …………………… 73
小结………………………………………… 74
练习………………………………………… 74
3.14　正向传播、反向传播和计算图………… 74
3.14.1　正向传播 ……………………… 74
3.14.2　正向传播的计算图 … ………… 75
3.14.3　反向传播 … …………………… 75
3.14.4　训练深度学习模型 … ………… 76
小结………………………………………… 77
练习………………………………………… 77
3.15　数值稳定性和模型初始化……………… 77
3.15.1　衰减和爆炸 ……………………… 77
3.15.2　随机初始化模型参数 … ……… 78
小结………………………………………… 78
练习………………………………………… 79
3.16　实战Kaggle比赛：房价预测… ……… 79
3.16.1　Kaggle比赛 … ………………… 79
3.16.2　读取数据集 … ………………… 80
3.16.3　预处理数据集 … …………………81
3.16.4　训练模型 … …………………… 82
3.16.5　k 折交叉验证 …………………… 82
3.16.6　模型选择 … …………………… 83
3.16.7　预测并在Kaggle提交结果… … 84
小结………………………………………… 85
练习………………………………………… 85
第4 章　深度学习计算… ……………… 86
4.1　模型构造………………………………… 86
4.1.1　继承Block类来构造模型 … …… 86
4.1.2　Sequential类继承自Block类…………………………… 87
4.1.3　构造复杂的模型… ……………… 88
小结………………………………………… 89
练习………………………………………… 90
4.2　模型参数的访问、初始化和共享… …… 90
4.2.1　访问模型参数 … ………………… 90
4.2.2　初始化模型参数 ………………… 92
4.2.3　自定义初始化方法 ……………… 93
4.2.4　共享模型参数 …………………… 94
小结………………………………………… 94
练习………………………………………… 94
4.3　模型参数的延后初始化… ……………… 95
4.3.1　延后初始化 … …………………… 95
4.3.2　避免延后初始化 ………………… 96
小结………………………………………… 96
练习………………………………………… 97
4.4　自定义层… ……………………………… 97
4.4.1　不含模型参数的自定义层 … …… 97
4.4.2　含模型参数的自定义层 ………… 98
小结………………………………………… 99
练习………………………………………… 99
4.5　读取和存储… …………………………… 99
4.5.1　读写NDArray… ………………… 99
4.5.2　读写Gluon模型的参数… ……… 100
小结………………………………………… 101
练习………………………………………… 101
4.6　GPU计算………………………………… 101
4.6.1　计算设备 … ……………………… 102
4.6.2　NDArray的GPU计算…………… 102
4.6.3　Gluon的GPU计算 ……………… 104
小结………………………………………… 105
练习………………………………………… 105
第5 章　卷积神经网络… ……………… 106
5.1　二维卷积层………………………………… 106
5.1.1　二维互相关运算 … ……………… 106
5.1.2　二维卷积层 … …………………… 107
5.1.3　图像中物体边缘检测 … ………… 108
5.1.4　通过数据学习核数组 … ………… 109
5.1.5　互相关运算和卷积运算 … ……… 109
5.1.6　特征图和感受野… ……………… 110
小结………………………………………… 110
练习………………………………………… 110
5.2　填充和步幅… …………………………… 111
5.2.1　填充 … …………………………… 111
5.2.2　步幅 ……………………………… 112
小结………………………………………… 113
练习………………………………………… 113
5.3　多输入通道和多输出通道… …………… 114
5.3.1　多输入通道 … …………………… 114
5.3.2　多输出通道… …………………… 115
5.3.3　1×1卷积层 ……………………… 116
小结………………………………………… 117
练习………………………………………… 117
5.4　池化层… ………………………………… 117
5.4.1　二维最大池化层和平均池化层 … ………………………… 117
5.4.2　填充和步幅 ……………………… 119
5.4.3　多通道 …………………………… 120
小结………………………………………… 120
练习………………………………………… 121
5.5　卷积神经网络（LeNet）… …………… 121
5.5.1　LeNet模型 … …………………… 121
5.5.2　训练模型… ……………………… 122
小结………………………………………… 124
练习………………………………………… 124
5.6　深度卷积神经网络（AlexNet）… …… 124
5.6.1　学习特征表示 … ………………… 125
5.6.2　AlexNet… ……………………… 126
5.6.3　读取数据集 ……………………… 127
5.6.4　训练模型 ………………………… 128
小结………………………………………… 128
练习………………………………………… 129
5.7　使用重复元素的网络（VGG）………… 129
5.7.1　VGG块 …………………………… 129
5.7.2　VGG网络 … …………………… 129
5.7.3　训练模型… ……………………… 130
小结………………………………………… 131
练习………………………………………… 131
5.8　网络中的网络（NiN）… ……………… 131
5.8.1　NiN块 … ………………………… 131
5.8.2　NiN模型 … ……………………… 132
5.8.3　训练模型… ……………………… 133
小结………………………………………… 134
练习………………………………………… 134
5.9　含并行连结的网络（GoogLeNet）…… 134
5.9.1　Inception块 ……………………… 134
5.9.2　GoogLeNet模型 … …………… 135
5.9.3　训练模型 ………………………… 137
小结………………………………………… 137
练习………………………………………… 137
5.10　批量归一化……………………………… 138
5.10.1　批量归一化层 ………………… 138
5.10.2　从零开始实现 … ……………… 139
5.10.3　使用批量归一化层的LeNet … … 140
5.10.4　简洁实现 … …………………… 141
小结………………………………………… 142
练习………………………………………… 142
5.11　残差网络（ResNet） ……………… 143
5.11.1　残差块 …………………………… 143
5.11.2　ResNet模型… ………………… 145
5.11.3　训练模型………………………… 146
小结………………………………………… 146
练习………………………………………… 146
5.12　稠密连接网络（DenseNet）………… 147
5.12.1　稠密块 …………………………… 147
5.12.2　过渡层 … ……………………… 148
5.12.3　DenseNet模型 ………………… 148
5.12.4　训练模型 … …………………… 149
小结………………………………………… 149
练习………………………………………… 149
第6 章　循环神经网络… ……………… 150
6.1　语言模型………………………………… 150
6.1.1　语言模型的计算 … ……………… 151
6.1.2　n 元语法 … ……………………… 151
小结………………………………………… 152
练习………………………………………… 152
6.2　循环神经网络… ………………………… 152
6.2.1　不含隐藏状态的神经网络 … …… 152
6.2.2　含隐藏状态的循环神经网络… … 152
6.2.3　应用：基于字符级循环神经网络的语言模型 … ……………………… 154
小结………………………………………… 155
练习………………………………………… 155
6.3　语言模型数据集（歌词）…… 155
6.3.1　读取数据集 … …………………… 155
6.3.2　建立字符索引 …………………… 156
6.3.3　时序数据的采样 ………………… 156
小结………………………………………… 158
练习………………………………………… 159
6.4　循环神经网络的从零开始实现… ……… 159
6.4.1　one-hot向量 … ………………… 159
6.4.2　初始化模型参数 ………………… 160
6.4.3　定义模型 ………………………… 160
6.4.4　定义预测函数 …………………… 161
6.4.5　裁剪梯度 ………………………… 161
6.4.6　困惑度 …………………………… 162
6.4.7　定义模型训练函数 ……………… 162
6.4.8　训练模型并创作歌词 …………… 163
小结………………………………………… 164
练习………………………………………… 164
6.5　循环神经网络的简洁实现… …………… 165
6.5.1　定义模型 … ……………………… 165
6.5.2　训练模型 ………………………… 166
小结………………………………………… 168
练习………………………………………… 168
6.6　通过时间反向传播… …………………… 168
6.6.1　定义模型 … ……………………… 168
6.6.2　模型计算图 ……………………… 169
6.6.3　方法 ……………………………… 169
小结………………………………………… 170
练习………………………………………… 170
6.7　门控循环单元（GRU）………………… 170
6.7.1　门控循环单元 … ………………… 171
6.7.2　读取数据集 ……………………… 173
6.7.3　从零开始实现 …………………… 173
6.7.4　简洁实现 ………………………… 175
小结………………………………………… 176
练习………………………………………… 176
6.8　长短期记忆（LSTM）… ……………… 176
6.8.1　长短期记忆 … …………………… 176
6.8.2　读取数据集 ……………………… 179
6.8.3　从零开始实现 …………………… 179
6.8.4　简洁实现 ………………………… 181
小结………………………………………… 181
练习………………………………………… 182
6.9　深度循环神经网络… …………………… 182
小结………………………………………… 183
练习………………………………………… 183
6.10　双向循环神经网络……………………… 183
小结………………………………………… 184
练习………………………………………… 184
第7 章　优化算法… …………………… 185
7.1　优化与深度学习…………………………… 185
7.1.1　优化与深度学习的关系 … ……… 185
7.1.2　优化在深度学习中的挑战 … …… 186
小结………………………………………… 188
练习………………………………………… 189
7.2　梯度下降和随机梯度下降… …………… 189
7.2.1　一维梯度下降 … ………………… 189
7.2.2　学习率 …………………………… 190
7.2.3　多维梯度下降 …………………… 191
7.2.4　随机梯度下降 …………………… 193
小结………………………………………… 194
练习………………………………………… 194
7.3　小批量随机梯度下降… ………………… 194
7.3.1　读取数据集 … …………………… 195
7.3.2　从零开始实现 …………………… 196
7.3.3　简洁实现 ………………………… 198
小结………………………………………… 199
练习………………………………………… 199
7.4　动量法… …………………………………200
7.4.1　梯度下降的问题 … ……………… 200
7.4.2　动量法 …………………………… 201
·6·　目　　录
7.4.3　从零开始实现 …………………… 203
7.4.4　简洁实现 ………………………… 205
小结………………………………………… 205
练习………………………………………… 205
7.5　AdaGrad算法……………………………206
7.5.1　算法 … …………………………… 206
7.5.2　特点 ……………………………… 206
7.5.3　从零开始实现 …………………… 208
7.5.4　简洁实现 ………………………… 209
小结………………………………………… 209
练习………………………………………… 209
7.6　RMSProp算法… ………………………209
7.6.1　算法 … …………………………… 210
7.6.2　从零开始实现 …………………… 211
7.6.3　简洁实现 ………………………… 212
小结………………………………………… 212
练习………………………………………… 212
7.7　AdaDelta算法… ……………………… 212
7.7.1　算法… …………………………… 212
7.7.2　从零开始实现 …………………… 213
7.7.3　简洁实现 ………………………… 214
小结………………………………………… 214
练习………………………………………… 214
7.8　Adam算法… …………………………… 215
7.8.1　算法 … …………………………… 215
7.8.2　从零开始实现 …………………… 216
7.8.3　简洁实现 ………………………… 216
小结………………………………………… 217
练习………………………………………… 217
第8 章　计算性能… …………………… 218
8.1　命令式和符号式混合编程… …………… 218
8.1.1　混合式编程取两者之长 … ……… 220
8.1.2　使用HybridSequential类构造模型 … …………………………… 220
8.1.3　使用HybridBlock类构造模型… …………………………… 222
小结………………………………………… 224
练习………………………………………… 224
8.2　异步计算… ………………………………224
8.2.1　MXNet中的异步计算 …………… 224
8.2.2　用同步函数让前端等待计算结果 … …………………………… 226
8.2.3　使用异步计算提升计算性能 …… 226
8.2.4　异步计算对内存的影响 ………… 227
小结………………………………………… 229
练习………………………………………… 229
8.3　自动并行计算… …………………………229
8.3.1　CPU和GPU的并行计算 … …… 230
8.3.2　计算和通信的并行计算 ………… 231
小结………………………………………… 231
练习………………………………………… 231
8.4　多GPU计算……………………………… 232
8.4.1　数据并行 … ……………………… 232
8.4.2　定义模型 ………………………… 233
8.4.3　多GPU之间同步数据 … ……… 234
8.4.4　单个小批量上的多GPU训练 … …………………………… 236
8.4.5　定义训练函数 …………………… 236
8.4.6　多GPU训练实验 … …………… 237
小结………………………………………… 237
练习………………………………………… 237
8.5　多GPU计算的简洁实现………………… 237
8.5.1　多GPU上初始化模型参数……… 238
8.5.2　多GPU训练模型 … …………… 239
小结………………………………………… 241
练习………………………………………… 241
第9 章　计算机视觉… ………………… 242
9.1　图像增广…………………………………242
9.1.1　常用的图像增广方法 … ………… 243
9.1.2　使用图像增广训练模型 … ……… 246
小结………………………………………… 250
练习………………………………………… 250
9.2　微调… ……………………………………250
热狗识别 … ……………………………… 251
小结………………………………………… 255
练习………………………………………… 255
目　　录　·7·
9.3　目标检测和边界框… ……………………255
边界框 … ………………………………… 256
小结………………………………………… 257
练习………………………………………… 257
9.4　锚框… …………………………………… 257
9.4.1　生成多个锚框… ………………… 257
9.4.2　交并比 …………………………… 259
9.4.3　标注训练集的锚框 ……………… 260
9.4.4　输出预测边界框… ……………… 263
小结………………………………………… 265
练习………………………………………… 265
9.5　多尺度目标检测… ………………………265
小结………………………………………… 268
练习………………………………………… 268
9.6　目标检测数据集（皮卡丘）… …………268
9.6.1　获取数据集 … …………………… 269
9.6.2　读取数据集… …………………… 269
9.6.3　图示数据 ………………………… 270
小结………………………………………… 270
练习………………………………………… 271
9.7　单发多框检测（SSD）… ……………… 271
9.7.1　定义模型… ……………………… 271
9.7.2　训练模型 ………………………… 275
9.7.3　预测目标 ………………………… 277
小结………………………………………… 278
练习………………………………………… 278
9.8　区域卷积神经网络（R-CNN）系列……280
9.8.1　R-CNN … ……………………… 280
9.8.2　Fast R-CNN …………………… 281
9.8.3　Faster R-CNN ………………… 283
9.8.4　Mask R-CNN … ……………… 284
小结………………………………………… 285
练习………………………………………… 285
9.9　语义分割和数据集… ……………………285
9.9.1　图像分割和实例分割 … ………… 285
9.9.2　Pascal VOC2012语义分割数据集 … ………………………… 286
小结………………………………………… 290
练习………………………………………… 290
9.10　全卷积网络（FCN）… ………………290
9.10.1　转置卷积层 …………………… 291
9.10.2　构造模型 … …………………… 292
9.10.3　初始化转置卷积层……………… 294
9.10.4　读取数据集 … ………………… 295
9.10.5　训练模型………………………… 296
9.10.6　预测像素类别…………………… 296
小结………………………………………… 297
练习………………………………………… 297
9.11　样式迁移… ………………………………298
9.11.1　方法 ……………………………… 298
9.11.2　读取内容图像和样式图像……… 299
9.11.3　预处理和后处理图像 ………… 300
9.11.4　抽取特征 ……………………… 301
9.11.5　定义损失函数 ………………… 302
9.11.6　创建和初始化合成图像 ……… 303
9.11.7　训练模型………………………… 304
小结………………………………………… 306
练习………………………………………… 306
9.12　实战Kaggle比赛：图像
分类（CIFAR-10）……………………306
9.12.1　获取和整理数据集 ……………… 307
9.12.2　图像增广 … …………………… 310
9.12.3　读取数据集 … ………………… 310
9.12.4　定义模型………………………… 311
9.12.5　定义训练函数 … ……………… 312
9.12.6　训练模型 … …………………… 312
9.12.7　对测试集分类并在Kaggle
提交结果 … …………………… 313
小结………………………………………… 313
练习………………………………………… 313
9.13　实战Kaggle比赛：狗的品种
识别（ImageNet Dogs）…………… 314
9.13.1　获取和整理数据集 …………… 315
9.13.2　图像增广 … …………………… 316
9.13.3　读取数据集 … ………………… 317
9.13.4　定义模型 … …………………… 318
9.13.5　定义训练函数 … ……………… 318
9.13.6　训练模型 … …………………… 319
·8·　目　　录
9.13.7　对测试集分类并在Kaggle提交结果 … …………………… 319
小结………………………………………… 320
练习………………………………………… 320
第10 章　自然语言处理………………… 321
10.1　词嵌入（word2vec）………………… 321
10.1.1　为何不采用one-hot向量… …… 321
10.1.2　跳字模型 ………………………… 322
10.1.3　连续词袋模型 …………………… 323
小结………………………………………… 325
练习………………………………………… 325
10.2　近似训练…………………………………325
10.2.1　负采样 …………………………… 325
10.2.2　层序softmax …………………… 326
小结………………………………………… 327
练习………………………………………… 328
10.3　word2vec的实现………………………328
10.3.1　预处理数据集 …………………… 328
10.3.2　负采样 … ……………………… 331
10.3.3　读取数据集 … ………………… 331
10.3.4　跳字模型 … …………………… 332
10.3.5　训练模型 … …………………… 333
10.3.6　应用词嵌入模型 … …………… 335
小结………………………………………… 336
练习………………………………………… 336
10.4　子词嵌入（fastText）… ……………336
小结………………………………………… 337
练习………………………………………… 337
10.5　全局向量的词嵌入（GloVe）…………337
10.5.1　GloVe模型 …………………… 338
10.5.2　从条件概率比值理解GloVe模型……………………… 339
小结………………………………………… 340
练习………………………………………… 340
10.6　求近义词和类比词………………………340
10.6.1　使用预训练的词向量 ………… 340
10.6.2　应用预训练词向量 … ………… 341
小结………………………………………… 343
练习………………………………………… 343
10.7　文本情感分类：使用循环神经网络…… 343
10.7.1　文本情感分类数据集 ………… 343
10.7.2　使用循环神经网络的模型……… 345
小结………………………………………… 347
练习………………………………………… 347
10.8　文本情感分类：使用卷积神经网络（textCNN）… …………………347
10.8.1　一维卷积层 … ………………… 348
10.8.2　时序最大池化层 … …………… 349
10.8.3　读取和预处理IMDb数据集 … ……………………… 350
10.8.4　textCNN模型 … ……………… 350
小结………………………………………… 353
练习………………………………………… 353
10.9　编码器-解码器（seq2seq）…………353
10.9.1　编码器 ………………………… 354
10.9.2　解码器 … ……………………… 354
10.9.3　训练模型………………………… 355
小结………………………………………… 355
练习………………………………………… 355
10.10　 束搜索… ………………………………355
10.10.1　贪婪搜索 … …………………… 356
10.10.2　穷举搜索 ……………………… 357
10.10.3　束搜索 ………………………… 357
小结………………………………………… 358
练习………………………………………… 358
10.11　注意力机制… …………………………358
10.11.1　计算背景变量 … ……………… 359
10.11.2　更新隐藏状态 … ……………… 360
10.11.3　发展… ………………………… 361
小结………………………………………… 361
练习………………………………………… 361
10.12　机器翻译… …………………………… 361
10.12.1　读取和预处理数据集… ……… 361
10.12.2　含注意力机制的编码器-解码器 … …………… 363
10.12.3　训练模型 ……………………… 365
10.12.4　预测不定长的序列… ………… 367
10.12.5　评价翻译结果 ………………… 367
小结………………………………………… 369
练习………………………………………… 369
附录A　数学基础… …………………… 370
附录B　使用 Jupyter 记事本… ……… 376
附录C　使用 AWS 运行代码…………… 381
附录D　GPU 购买指南………………… 388
附录E　如何为本书做贡献… ………… 391
附录F　d2lzh 包索引…………………… 395
附录G　中英文术语对照表… ………… 397
参考文献………………………………… 402
索引……………………………………… 407
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>动手学深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>概率论及其应用
第0章 绪论概率论的性质
O.1 背景
0.2 方法和步骤
O.3 “统计”概率-
0.4 摘要
0.5 历史小记
第1章 样本空间
1.1 经验背景
1.2 例子
1.3 样本空间·事件
1.4 事件之间的关系
1.5 离散样本空间
1.6 离散样本空间中的概率预备知识
1.7 基本定义和规则
1.8 习题
第2章 组合分析概要
2.1 预备知识
2.2 有序样本
2.3 例子
2.4 子总体和分划
2.5 在占位问题中的应用
2.6 超几何分布
2.7 等待时间的例子
2.8 二项式系数
2.9 斯特林公式
2.10 习题和例子
2.1l 问题和理论性的附录
2.12 二项式系数的一些问题和恒等式
第3章 扔硬币的起伏问题和随机徘徊
3.1 一般讨论及反射原理
3.2 随机徘徊的基本记号及概念
3.3 主要引理
3.4 末次访问与长领先
3.5 符号变换
3.6 一个实验的说明
3.7 最大和初过
3.8 对偶性·最大的位置
3.9 一个等分布定理
3.10 习题
第4章 事件的组合
4.1 事件之并
4.2 在古典占位问题中的应用
4.3 N个事件中实现m件
4.4 在相合与猜测问题中的应用
4.5 杂录
4.6 习题
第5章 条件概率·随机独立性.
5.1 条件概率
5.2 用条件概率所定义的概率·罐子模型
5.3 随机独立性
5.4 乘积空间·独立试验
5.5 在遗传学中的应用
5.6 伴性性状
5.7 选择
5.8 习题
第6章 二项分布与泊松分布
6.1 伯努利试验序列
6.2 二项分布
6.3 中心项及尾项
6.4 大数定律
6.5 泊松逼近
6.6 泊松分布
6.7 符合泊松分布的观察结果
6.8 等待时问·负二项分布
6.9 多项分布
6.10 习题
第7章 二项分布的正态逼近
7.1 正态分布
7.2 预备知识：对称分布
7.3 棣莫弗一拉普拉斯极限定理
7.4 例子
7.5 与泊松逼近的关系
7.6 大偏差
7.7 习题
第8章 伯努利试验的无穷序列
8.1 试验的无穷序列
8.2 赌博的长策
8.3 波雷尔一坎特立引理
8.4 强大数定律
8.5 迭对数法则-
8.6 用数论的语言解释
8.7 习题
第9章 随机变量·期望值
9.1 随机变量
9.2 期望值
9.3 例子及应用
9.4 方差
9.5 协方差·和的方差
9.6 切比雪夫不等式
9.7 科尔莫戈罗夫不等式
9.8 相关系数
9.9 习题
第10章 大数定律
10.1 同分布的随机变量列
10.2 大数定律的证明
10.3 “公平”博弈论
10.4 彼得堡博弈
10.5 不同分布的情况
10.6 在组合分析中的应用
10.7 强大数定律
10.8 习题
第11章 取整数值的随机变量·母函数
11.1 概论
11.2 卷积
11.3 伯努利试验序列中的等待时与均等
11.4 部分分式展开
11.5 二元母函数
11.6 连续性定理
11.7 习题
第12章 复合分布·分支过程
12.1 随机个随机变量之和
12.2 复合泊松分布
12.3 分支过程的例子
12.4 分支过程的灭绝概率
12.5 分支过程的总后代
12.6 习题
第13章 循环事件·更新理论
13.1 直观导引与例子
13.2 定义
13.3 基本关系
13.4 例子
13.5 迟延循环事件·一个一般性极限定理
13.6 S出现的次数
13.7 在成功连贯中的应用
13.8 更一般的样型
13.9 几何等待时间的记忆缺损
13.10 更新理论
13.11 基本极限定理的证明
13.12 习题
第14章 随机徘徊与破产问题
14.1 一般讨论
14.2 古典破产问题
14.3 博弈持续时间的期望值
14.4 博弈持续时间和初达时的母函数
14.5 显式表达式
14.6 与扩散过程的关系
14.7 平面和空间中的随机徘徊
14.8 广义一维随机徘徊(序贯抽样)
14.9 习题
第15章 马尔可夫链
15.1 定义
15.2 直观例子-
T5.3 高阶转移概率
15.4 闭包与闭集
15.5 状态的分类
15.6 不可约链·分解
15.7 不变分布
15.8 暂留链
15.9 周期链
15.10 在洗牌中的应用
15.11 不变测度·比率极限定理
15.12 逆链·边界
15.13 一般的马尔可夫过程
15.14 习题
第16章 有限马尔可夫链的代数处理
16.1 一般理论
16.2 例子
16.3 具有反射壁的随机徘徊
16.4 暂留状态·吸收概率
16.5 在循环时间中的应用
第17章 最简单的依时的随机过程
17.1 一般概念·马尔可夫过程
17.2 泊松过程
17.3 纯生过程
17.4 发散的生过程
17.5 生灭过程
17.6 指数持续时间
17.7 等待队列与服务问题
17.8 倒退(向后)方程
17.9 一般过程
17.10 习题
习题解答
参考文献
索引
人名对照表-
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>概率论及其应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘导论
第1章 绪论	1
1.1 什么是数据挖掘	2
1.2 数据挖掘要解决的问题	2
1.3 数据挖掘的起源	3
1.4 数据挖掘任务	4
1.5 本书的内容与组织	7
文献注释	7
参考文献	8
习题	10
第2章 数据	13
2.1 数据类型	14
2.1.1 属性与度量	15
2.1.2 数据集的类型	18
2.2 数据质量	22
2.2.1 测量和数据收集问题	22
2.2.2 关于应用的问题	26
2.3 数据预处理	27
2.3.1 聚集	27
2.3.2 抽样	28
2.3.3 维归约	30
2.3.4 特征子集选择	31
2.3.5 特征创建	33
2.3.6 离散化和二元化	34
2.3.7 变量变换	38
2.4 相似性和相异性的度量	38
2.4.1 基础	39
2.4.2 简单属性之间的相似度和相异度	40
2.4.3 数据对象之间的相异度	41
2.4.4 数据对象之间的相似度	43
2.4.5 邻近性度量的例子	43
2.4.6 邻近度计算问题	48
2.4.7 选取正确的邻近性度量	50
文献注释	50
参考文献	52
习题	53
第3章 探索数据	59
3.1 鸢尾花数据集	59
3.2 汇总统计	60
3.2.1 频率和众数	60
3.2.2 百分位数	61
3.2.3 位置度量：均值和中位数	61
3.2.4 散布度量：极差和方差	62
3.2.5 多元汇总统计	63
3.2.6 汇总数据的其他方法	64
3.3 可视化	64
3.3.1 可视化的动机	64
3.3.2 一般概念	65
3.3.3 技术	67
3.3.4 可视化高维数据	75
3.3.5 注意事项	79
3.4 OLAP和多维数据分析	79
3.4.1 用多维数组表示鸢尾花数据	80
3.4.2 多维数据：一般情况	81
3.4.3 分析多维数据	82
3.4.4 关于多维数据分析的最后评述	84
文献注释	84
参考文献	85
习题	86
第4章 分类：基本概念、决策树与模型评估	89
4.1 预备知识	89
4.2 解决分类问题的一般方法	90
4.3 决策树归纳	92
4.3.1 决策树的工作原理	92
4.3.2 如何建立决策树	93
4.3.3 表示属性测试条件的方法	95
4.3.4 选择最佳划分的度量	96
4.3.5 决策树归纳算法	101
4.3.6 例子：Web 机器人检测	102
4.3.7 决策树归纳的特点	103
4.4 模型的过分拟合	106
4.4.1 噪声导致的过分拟合	107
4.4.2 缺乏代表性样本导致的过分拟合	109
4.4.3 过分拟合与多重比较过程	109
4.4.4 泛化误差估计	110
4.4.5 处理决策树归纳中的过分拟合	113
4.5 评估分类器的性能	114
4.5.1 保持方法	114
4.5.2 随机二次抽样	115
4.5.3 交叉验证	115
4.5.4 自助法	115
4.6 比较分类器的方法	116
4.6.1 估计准确度的置信区间	116
4.6.2 比较两个模型的性能	117
4.6.3 比较两种分类法的性能	118
文献注释	118
参考文献	120
习题	122
第5章 分类：其他技术	127
5.1 基于规则的分类器	127
5.1.1 基于规则的分类器的工作原理	128
5.1.2 规则的排序方案	129
5.1.3 如何建立基于规则的分类器	130
5.1.4 规则提取的直接方法	130
5.1.5 规则提取的间接方法	135
5.1.6 基于规则的分类器的特征	136
5.2 最近邻分类器	137
5.2.1 算法	138
5.2.2 最近邻分类器的特征	138
5.3 贝叶斯分类器	139
5.3.1 贝叶斯定理	139
5.3.2 贝叶斯定理在分类中的应用	140
5.3.3 朴素贝叶斯分类器	141
5.3.4 贝叶斯误差率	145
5.3.5 贝叶斯信念网络	147
5.4 人工神经网络	150
5.4.1 感知器	151
5.4.2 多层人工神经网络	153
5.4.3 人工神经网络的特点	155
5.5 支持向量机	156
5.5.1 最大边缘超平面	156
5.5.2 线性支持向量机：可分情况	157
5.5.3 线性支持向量机：不可分情况	162
5.5.4 非线性支持向量机	164
5.5.5 支持向量机的特征	168
5.6 组合方法	168
5.6.1 组合方法的基本原理	168
5.6.2 构建组合分类器的方法	169
5.6.3 偏倚—方差分解	171
5.6.4 装袋	173
5.6.5 提升	175
5.6.6 随机森林	178
5.6.7 组合方法的实验比较	179
5.7 不平衡类问题	180
5.7.1 可选度量	180
5.7.2 接受者操作特征曲线	182
5.7.3 代价敏感学习	184
5.7.4 基于抽样的方法	186
5.8 多类问题	187
文献注释	189
参考文献	190
习题	193
第6章 关联分析：基本概念和算法	201
6.1 问题定义	202
6.2 频繁项集的产生	204
6.2.1 先验原理	205
6.2.2 Apriori算法的频繁项集产生	206
6.2.3　候选的产生与剪枝	208
6.2.4 支持度计数	210
6.2.5 计算复杂度	213
6.3 规则产生	215
6.3.1 基于置信度的剪枝	215
6.3.2 Apriori算法中规则的产生	215
6.3.3 例：美国国会投票记录	217
6.4 频繁项集的紧凑表示	217
6.4.1 极大频繁项集	217
6.4.2 闭频繁项集	219
6.5 产生频繁项集的其他方法	221
6.6 FP增长算法	223
6.6.1 FP树表示法	224
6.6.2 FP增长算法的频繁项集产生	225
6.7 关联模式的评估	228
6.7.1 兴趣度的客观度量	228
6.7.2 多个二元变量的度量	235
6.7.3 辛普森悖论	236
6.8 倾斜支持度分布的影响	237
文献注释	240
参考文献	244
习题	250
第7章 关联分析：高级概念	259
7.1 处理分类属性	259
7.2 处理连续属性	261
7.2.1 基于离散化的方法	261
7.2.2 基于统计学的方法	263
7.2.3 非离散化方法	265
7.3 处理概念分层	266
7.4 序列模式	267
7.4.1 问题描述	267
7.4.2 序列模式发现	269
7.4.3 时限约束	271
7.4.4 可选计数方案	274
7.5 子图模式	275
7.5.1 图与子图	276
7.5.2 频繁子图挖掘	277
7.5.3 类Apriori方法	278
7.5.4 候选产生	279
7.5.5 候选剪枝	282
7.5.6 支持度计数	285
7.6 非频繁模式	285
7.6.1 负模式	285
7.6.2 负相关模式	286
7.6.3 非频繁模式、负模式和负相关模式比较	287
7.6.4 挖掘有趣的非频繁模式的技术	288
7.6.5 基于挖掘负模式的技术	288
7.6.6 基于支持度期望的技术	290
文献注释	292
参考文献	293
习题	295
第8章 聚类分析：基本概念和算法	305
8.1 概述	306
8.1.1 什么是聚类分析	306
8.1.2 不同的聚类类型	307
8.1.3 不同的簇类型	308
8.2 K均值	310
8.2.1 基本K均值算法	310
8.2.2 K均值：附加的问题	315
8.2.3 二分K均值	316
8.2.4 K均值和不同的簇类型	317
8.2.5 优点与缺点	318
8.2.6 K均值作为优化问题	319
8.3 凝聚层次聚类	320
8.3.1 基本凝聚层次聚类算法	321
8.3.2 特殊技术	322
8.3.3 簇邻近度的Lance-Williams公式	325
8.3.4 层次聚类的主要问题	326
8.3.5 优点与缺点	327
8.4 DBSCAN	327
8.4.1 传统的密度：基于中心的方法	327
8.4.2 DBSCAN算法	328
8.4.3 优点与缺点	329
8.5 簇评估	330
8.5.1 概述	332
8.5.2 非监督簇评估：使用凝聚度和分离度	332
8.5.3 非监督簇评估：使用邻近度矩阵	336
8.5.4 层次聚类的非监督评估	338
8.5.5 确定正确的簇个数	339
8.5.6 聚类趋势	339
8.5.7 簇有效性的监督度量	340
8.5.8 评估簇有效性度量的显著性	343
文献注释	344
参考文献	345
习题	347
第9章 聚类分析：其他问题与算法	355
9.1 数据、簇和聚类算法的特性	355
9.1.1 例子：比较K均值和DBSCAN	355
9.1.2 数据特性	356
9.1.3 簇特性	357
9.1.4 聚类算法的一般特性	358
9.2 基于原型的聚类	359
9.2.1 模糊聚类	359
9.2.2 使用混合模型的聚类	362
9.2.3 自组织映射	369
9.3 基于密度的聚类	372
9.3.1 基于网格的聚类	372
9.3.2 子空间聚类	374
9.3.3 DENCLUE：基于密度聚类的一种基于核的方案	377
9.4 基于图的聚类	379
9.4.1 稀疏化	379
9.4.2 最小生成树聚类	380
9.4.3 OPOSSUM：使用METIS的稀疏相似度最优划分	381
9.4.4 Chameleon：使用动态建模的层次聚类	381
9.4.5 共享最近邻相似度	385
9.4.6 Jarvis-Patrick聚类算法	387
9.4.7 SNN密度	388
9.4.8 基于SNN密度的聚类	389
9.5 可伸缩的聚类算法	390
9.5.1 可伸缩：一般问题和方法	391
9.5.2 BIRCH	392
9.5.3 CURE	393
9.6 使用哪种聚类算法	395
文献注释	397
参考文献	398
习题	400
第10章 异常检测	403
10.1 预备知识	404
10.1.1 异常的成因	404
10.1.2 异常检测方法	404
10.1.3 类标号的使用	405
10.1.4 问题	405
10.2 统计方法	406
10.2.1 检测一元正态分布中的离群点	407
10.2.2 多元正态分布的离群点	408
10.2.3 异常检测的混合模型方法	410
10.2.4 优点与缺点	411
10.3 基于邻近度的离群点检测	411
10.4 基于密度的离群点检测	412
10.4.1 使用相对密度的离群点检测	413
10.4.2 优点与缺点	414
10.5 基于聚类的技术	414
10.5.1 评估对象属于簇的程度	415
10.5.2 离群点对初始聚类的影响	416
10.5.3 使用簇的个数	416
10.5.4 优点与缺点	416
文献注释	417
参考文献	418
习题	420
附录A 线性代数	423
附录B 维归约	433
附录C 概率统计	445
附录D 回归	451
附录E 优化	457
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据
目　　录

第1章　 数据挖掘基本概念　　1
1.1　 数据挖掘的定义　　1
1.1.1　 统计建模　　1
1.1.2　 机器学习　　1
1.1.3　 建模的计算方法　　2
1.1.4　 数据汇总　　2
1.1.5　 特征抽取　　3
1.2　 数据挖掘的统计限制　　4
1.2.1　 整体情报预警　　4
1.2.2　 邦弗朗尼原理　　4
1.2.3　 邦弗朗尼原理的一个例子　　5
1.2.4　 习题　　6
1.3　 相关知识　　6
1.3.1　 词语在文档中的重要性　　6
1.3.2　 哈希函数　　7
1.3.3　 索引　　8
1.3.4　 二级存储器　　10
1.3.5　 自然对数的底e　　10
1.3.6　 幂定律　　11
1.3.7　 习题　　12
1.4　 本书概要　　13
1.5　 小结　　14
1.6　 参考文献　　14
第2章　 大规模文件系统及Map-Reduce　　16
2.1　 分布式文件系统　　16
2.1.1　 计算节点的物理结构　　17
2.1.2　 大规模文件系统的结构　　18
2.2　 Map-Reduce　　18
2.2.1　 Map任务　　19
2.2.2　 分组和聚合　　20
2.2.3　 Reduce任务　　20
2.2.4　 组合器　　21
2.2.5　 Map-Reduce的执行细节　　21
2.2.6　 节点失效的处理　　22
2.3　 使用Map-Reduce的算法　　22
2.3.1　 基于Map-Reduce的矩阵—向量乘法实现　　23
2.3.2　 向量v无法放入内存时的处理　　23
2.3.3　 关系代数运算　　24
2.3.4　 基于Map-Reduce的选择运算　　26
2.3.5　 基于Map-Reduce的投影运算　　26
2.3.6　 基于Map-Reduce的并、交和差运算　　27
2.3.7　 基于Map-Reduce的自然连接运算　　27
2.3.8　 一般性的连接算法　　28
2.3.9　 基于Map-Reduce的分组和聚合运算　　28
2.3.10　 矩阵乘法　　29
2.3.11　 基于单步Map-Reduce的矩阵乘法　　29
2.3.12　 习题　　30
2.4　 Map-Reduce的扩展　　31
2.4.1　 工作流系统　　31
2.4.2　 Map-Reduce的递归扩展版本　　32
2.4.3　 Pregel系统　　34
2.4.4　 习题　　35
2.5　 集群计算算法的效率问题　　35
2.5.1　 集群计算的通信开销模型　　35
2.5.2　 实耗通信开销　　36
2.5.3　 多路连接　　37
2.5.4　 习题　　40
2.6　 小结　　40
2.7　 参考文献　　42
第3章　 相似项发现　　44
3.1　 近邻搜索的应用　　44
3.1.1　 集合的Jaccard相似度　　44
3.1.2　 文档的相似度　　45
3.1.3　 协同过滤——一个集合相似问题　　46
3.1.4　 习题　　47
3.2　 文档的Shingling　　47
3.2.1　 k-Shingle　　47
3.2.2　 shingle大小的选择　　48
3.2.3　 对shingle进行哈希　　48
3.2.4　 基于词的shingle　　49
3.2.5　 习题　　49
3.3　 保持相似度的集合摘要表示　　49
3.3.1　 集合的矩阵表示　　50
3.3.2　 最小哈希　　50
3.3.3　 最小哈希及Jaccard相似度　　51
3.3.4　 最小哈希签名　　52
3.3.5　 最小哈希签名的计算　　52
3.3.6　 习题　　54
3.4　 文档的局部敏感哈希算法　　55
3.4.1　 面向最小哈希签名的LSH　　56
3.4.2　 行条化策略的分析　　57
3.4.3　 上述技术的综合　　58
3.4.4　 习题　　59
3.5　 距离测度　　59
3.5.1　 距离测度的定义　　59
3.5.2　 欧氏距离　　60
3.5.3　 Jaccard距离　　60
3.5.4　 余弦距离　　61
3.5.5　 编辑距离　　62
3.5.6　 海明距离　　63
3.5.7　 习题　　63
3.6　 局部敏感函数理论　　64
3.6.1　 局部敏感函数　　65
3.6.2　 面向Jaccard距离的局部敏感函数族　　66
3.6.3　 局部敏感函数族的放大处理　　66
3.6.4　 习题　　68
3.7　 面向其他距离测度的LSH函数族　　68
3.7.1　 面向海明距离的LSH函数族　　69
3.7.2　 随机超平面和余弦距离　　69
3.7.3　 梗概　　70
3.7.4　 面向欧氏距离的LSH函数族　　71
3.7.5　 面向欧氏空间的更多LSH函数族　　72
3.7.6　 习题　　72
3.8　 LSH函数的应用　　73
3.8.1　 实体关联　　73
3.8.2　 一个实体关联的例子　　74
3.8.3　 记录匹配的验证　　74
3.8.4　 指纹匹配　　75
3.8.5　 适用于指纹匹配的LSH函数族　　76
3.8.6　 相似新闻报道检测　　77
3.8.7　 习题　　78
3.9　 面向高相似度的方法　　79
3.9.1　 相等项发现　　79
3.9.2　 集合的字符串表示方法　　79
3.9.3　 基于长度的过滤　　80
3.9.4　 前缀索引　　81
3.9.5　 位置信息的使用　　82
3.9.6　 使用位置和长度信息的索引　　83
3.9.7　 习题　　85
3.10　 小结　　85
3.11　 参考文献　　87
第4章　 数据流挖掘　　89
4.1　 流数据模型　　89
4.1.1　 一个数据流管理系统　　89
4.1.2　 流数据源的例子　　90
4.1.3　 流查询　　91
4.1.4　 流处理中的若干问题　　92
4.2　 流当中的数据抽样　　92
4.2.1　 一个富于启发性的例子　　93
4.2.2　 代表性样本的获取　　93
4.2.3　 一般的抽样问题　　94
4.2.4　 样本规模的变化　　94
4.2.5　 习题　　95
4.3　 流过滤　　95
4.3.1　 一个例子　　95
4.3.2　 布隆过滤器　　96
4.3.3　 布隆过滤方法的分析　　96
4.3.4　 习题　　97
4.4　 流中独立元素的数目统计　　98
4.4.1　 独立元素计数问题　　98
4.4.2　 FM算法　　98
4.4.3　 组合估计　　99
4.4.4　 空间需求　　100
4.4.5　 习题　　100
4.5　 矩估计　　100
4.5.1　 矩定义　　100
4.5.2　 二阶矩估计的AMS算法　　101
4.5.3　 AMS算法有效的原因　　102
4.5.4　 更高阶矩的估计　　103
4.5.5　 无限流的处理　　103
4.5.6　 习题　　104
4.6　 窗口内的计数问题　　105
4.6.1　 精确计数的开销　　105
4.6.2　 DGIM算法　　105
4.6.3　 DGIM算法的存储需求　　107
4.6.4　 DGIM算法中的查询应答　　107
4.6.5　 DGIM条件的保持　　108
4.6.6　 降低错误率　　109
4.6.7　 窗口内计数问题的扩展　　109
4.6.8　 习题　　110
4.7　 衰减窗口　　110
4.7.1　 最常见元素问题　　110
4.7.2　 衰减窗口的定义　　111
4.7.3　 最流行元素的发现　　111
4.8　 小结　　112
4.9　 参考文献　　113
第5章　 链接分析　　115
5.1　 PageRank　　115
5.1.1　 早期的搜索引擎及词项作弊　　115
5.1.2　 PageRank的定义　　117
5.1.3　 Web结构　　119
5.1.4　 避免终止点　　121
5.1.5　 采集器陷阱及“抽税”法　　123
5.1.6　 PageRank在搜索引擎中的使用　　125
5.1.7　 习题　　125
5.2　 PageRank的快速计算　　126
5.2.1　 转移矩阵的表示　　127
5.2.2　 基于Map-Reduce的PageRank迭代计算　　128
5.2.3　 结果向量合并时的组合器使用　　128
5.2.4　 转移矩阵中块的表示　　129
5.2.5　 其他高效的PageRank迭代方法　　130
5.2.6　 习题　　131
5.3　 面向主题的PageRank　　131
5.3.1　 动机　　131
5.3.2　 有偏的随机游走模型　　132
5.3.3　 面向主题的PageRank的使用　　133
5.3.4　 基于词汇的主题推断　　134
5.3.5　 习题　　134
5.4　 链接作弊　　135
5.4.1　 垃圾农场的架构　　135
5.4.2　 垃圾农场的分析　　136
5.4.3　 与链接作弊的斗争　　137
5.4.4　 TrustRank　　137
5.4.5　 垃圾质量　　137
5.4.6　 习题　　138
5.5　 导航页和权威页　　139
5.5.1　 HITS的直观意义　　139
5.5.2　 导航度和权威度的形式化　　139
5.5.3　 习题　　142
5.6　 小结　　143
5.7　 参考文献　　145
第6章　 频繁项集　　146
6.1　 购物篮模型　　146
6.1.1　 频繁项集的定义　　146
6.1.2　 频繁项集的应用　　148
6.1.3　 关联规则　　149
6.1.4　 高可信度关联规则的发现　　150
6.1.5　 习题　　151
6.2　 购物篮及A-Priori算法　　152
6.2.1　 购物篮数据的表示　　152
6.2.2　 项集计数中的内存使用　　153
6.2.3　 项集的单调性　　154
6.2.4　 二元组计数　　155
6.2.5　 A-Priori算法　　155
6.2.6　 所有频繁项集上的A-Priori算法　　157
6.2.7　 习题　　158
6.3　 更大数据集在内存中的处理　　159
6.3.1　 PCY算法　　160
6.3.2　 多阶段算法　　161
6.3.3　 多哈希算法　　163
6.3.4　 习题　　164
6.4　 有限扫描算法　　166
6.4.1　 简单的随机化算法　　166
6.4.2　 抽样算法中的错误规避　　167
6.4.3　 SON算法　　168
6.4.4　 SON算法和Map-Reduce　　168
6.4.5　 Toivonen算法　　169
6.4.6　 Toivonen算法的有效性分析　　170
6.4.7　 习题　　170
6.5　 流中的频繁项计数　　171
6.5.1　 流的抽样方法　　171
6.5.2　 衰减窗口中的频繁项集　　172
6.5.3　 混合方法　　172
6.5.4　 习题　　173
6.6　 小结　　173
6.7　 参考文献　　175
第7章　 聚类　　176
7.1　 聚类技术介绍　　176
7.1.1　 点、空间和距离　　176
7.1.2　 聚类策略　　177
7.1.3　 维数灾难　　178
7.1.4　 习题　　179
7.2　 层次聚类　　179
7.2.1　 欧氏空间下的层次聚类　　180
7.2.2　 层次聚类算法的效率　　183
7.2.3　 控制层次聚类的其他规则　　183
7.2.4　 非欧空间下的层次聚类　　185
7.2.5　 习题　　186
7.3　 k-均值算法　　187
7.3.1　 k-均值算法基本知识　　187
7.3.2　 k-均值算法的簇初始化　　187
7.3.3　 选择k的正确值　　188
7.3.4　 BFR算法　　189
7.3.5　 BFR算法中的数据处理　　191
7.3.6　 习题　　192
7.4　 CURE算法　　193
7.4.1　 CURE算法的初始化　　194
7.4.2　 CURE算法的完成　　195
7.4.3　 习题　　195
7.5　 非欧空间下的聚类　　196
7.5.1　 GRGPF算法中的簇表示　　196
7.5.2　 簇表示树的初始化　　196
7.5.3　 GRGPF算法中的点加入　　197
7.5.4　 簇的分裂及合并　　198
7.5.5　 习题　　199
7.6　 流聚类及并行化　　199
7.6.1　 流计算模型　　199
7.6.2　 一个流聚类算法　　200
7.6.3　 桶的初始化　　200
7.6.4　 桶合并　　200
7.6.5　 查询应答　　202
7.6.6　 并行环境下的聚类　　202
7.6.7　 习题　　203
7.7　 小结　　203
7.8　 参考文献　　205
第8章　 Web广告　　207
8.1　 在线广告相关问题　　207
8.1.1　 广告机会　　207
8.1.2　 直投广告　　208
8.1.3　 展示广告的相关问题　　208
8.2　 在线算法　　209
8.2.1　 在线和离线算法　　209
8.2.2　 贪心算法　　210
8.2.3　 竞争率　　211
8.2.4　 习题　　211
8.3　 广告匹配问题　　212
8.3.1　 匹配及完美匹配　　212
8.3.2　 最大匹配贪心算法　　213
8.3.3　 贪心匹配算法的竞争率　　213
8.3.4　 习题　　214
8.4　 Adwords问题　　214
8.4.1　 搜索广告的历史　　215
8.4.2　 Adwords问题的定义　　215
8.4.3　 Adwords问题的贪心方法　　216
8.4.4　 Balance算法　　217
8.4.5　 Balance算法竞争率的一个下界　　217
8.4.6　 多投标者的Balance算法　　219
8.4.7　 一般性的Balance算法　　220
8.4.8　 Adwords问题的最后论述　　221
8.4.9　 习题　　221
8.5　 Adwords的实现　　221
8.5.1　 投标和搜索查询的匹配　　222
8.5.2　 更复杂的匹配问题　　222
8.5.3　 文档和投标之间的匹配算法　　223
8.6　 小结　　224
8.7　 参考文献　　226
第9章　 推荐系统　　227
9.1　 一个推荐系统的模型　　227
9.1.1　 效用矩阵　　227
9.1.2　 长尾现象　　228
9.1.3　 推荐系统的应用　　230
9.1.4　 效用矩阵的填充　　230
9.2　 基于内容的推荐　　231
9.2.1　 项模型　　231
9.2.2　 文档的特征发现　　231
9.2.3　 基于Tag的项特征获取　　232
9.2.4　 项模型的表示　　233
9.2.5　 用户模型　　234
9.2.6　 基于内容的项推荐　　235
9.2.7　 分类算法　　235
9.2.8　 习题　　237
9.3　 协同过滤　　238
9.3.1　 相似度计算　　238
9.3.2　 相似度对偶性　　241
9.3.3　 用户聚类和项聚类　　242
9.3.4　 习题　　243
9.4　 降维处理　　243
9.4.1　 UV分解　　244
9.4.2　 RMSE　　244
9.4.3　 UV分解的增量式计算　　245
9.4.4　 对任一元素的优化　　247
9.4.5　 一个完整UV分解算法的构建　　248
9.4.6　 习题　　250
9.5　 NetFlix竞赛　　250
9.6　 小结　　251
9.7　 参考文献　　253
索引　　254

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>凸优化
1 引言
1.1 数学优化
1.2 最小二乘和线性规划
1.3 凸优化
1.4 非线性优化
1.5 本书主要内容
1.6 符号
参考文献
I 理论
2 凸集
2.1 仿射集合和凸集
2.2 重要的例子
2.3 保凸运算
2.4 广义不等式
2.5 分离与支撑超平面
2.6 对偶锥与广义不等式
参考文献
习题
3 凸函数
3.1 基本性质和例子
3.2 保凸运算
3.3 共轭函数
3.4 拟凸函数
3.5 对数—凹函数和对数—凸函数
3.6 关于广义不等式的凸性
参考文献
习题
4 凸优化问题
4.1 优化问题
4.2 凸优化
4.3 线性规划问题
4.4 二次优化问题
4.5 几何规划
4.6 广义不等式约束
4.7 向量优化
参考文献
习题
5 对偶
5.1 Lagrange对偶函数
5.2 Lagrange对偶问题
5.3 几何解释
5.4 鞍点解释
5.5 最优性条件
5.6 扰动及灵敏度分析
5.7 例子
5.8 择一定理
5.9 广义不等式
参考文献
习题
Ⅱ 应用
应用
6 逼近与拟合
6.1 范数逼近
6.2 最小范数问题
6.3 正则化逼近
6.4 鲁棒逼近
6.5 函数拟合与插值
参考文献
习题
7 统计估计
7.1 参数分布估计
7.2 非参数分布估计
7.3 最优检测器设计及假设检验
7.4 Chebyshev界和Cherno.界
7.5 实验设计
参考文献
习题
8 几何问题
8.1 向集合投影
8.2 集合间的距离
8.3 Euclid距离和角度问题
8.4 极值体积椭球
8.5 中心
8.6 分类
8.7 布局与定位
8.8 平面布置
参考文献
习题
Ⅲ 算法
9 无约束优化
9.1 无约束优化问题
9.2 下降方法
9.3 梯度下降方法
9.4 最速下降方法
9.5 Newton方法
9.6 自和谐
9.7 实现
参考文献
习题
10 等式约束优化
10.1 等式约束优化问题
10.2 等式约束的Newton方法
10.3 不可行初始点的Newton方法
10.4 实现
参考文献
习题
11 内点法
11.1 不等式约束的极小化问题
11.2 对数障碍函数和中心路径
11.3 障碍方法
11.4 可行性和阶段1方法
11.5 自和谐条件下的复杂性分析
11.6 广义不等式问题
11.7 原对偶内点法
11.8 实现
参考文献
习题
附录
A 有关的数学知识
A.1 范数
A.2 分析
A.3 函数
A.4 导数
A.5 线性代数
参考文献
B 双二次函数的问题
B.1 单约束二次优化
B.2 S—程序
B.3 双对称矩阵的数值场
B.4 强对偶结果的证明
参考文献
C 有关的数值线性代数知识
C.1 矩阵结构与算法复杂性
C.2 求解已经因式分解的矩阵的线性方程组
C.3 LU，Cholesky和LDLT 因式分解
C.4 分块消元和Schur补
C.5 求解不确定线性方程组
650参考文献
参考文献
符号
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>凸优化
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>这就是搜索引擎
目 录
第1章 搜索引擎及其技术架构 1
1.1 搜索引擎为何重要 1
1.1.1　互联网的发展 1
1.1.2 商业搜索引擎公司的发展 3
1.1.3 搜索引擎的重要地位 3
1.2 搜索引擎技术发展史 4
1.2.1 史前时代：分类目录的一代 4
1.2.2 第一代：文本检索的一代 5
1.2.3 第二代：链接分析的一代 5
1.2.4 第三代：用户中心的一代 5
1.3 搜索引擎的3个目标 6
1.4 搜索引擎的3个核心问题 7
1.4.1 3个核心问题 7
1.4.2 与技术发展的关系 8
1.5 搜索引擎的技术架构 9
第2章 网络爬虫 12
2.1 通用爬虫框架 12
2.2 优秀爬虫的特性 15
2.3 爬虫质量的评价标准 18
2.4 抓取策略 19
2.4.1 宽度优先遍历策略（Breath First） 20
2.4.2 非完全PageRank策略（Partial PageRank） 21
2.4.3 OCIP策略（Online Page Importance Computation） 23
2.4.4 大站优先策略（Larger Sites First） 23
2.5 网页更新策略 23
2.5.1 历史参考策略 24
2.5.2 用户体验策略 24
2.5.3 聚类抽样策略 24
2.6 暗网抓取（Deep Web Crawling） 26
2.6.1 查询组合问题 27
2.6.2 文本框填写问题 29
2.7 分布式爬虫 30
2.7.1 主从式分布爬虫（Master-Slave） 31
2.7.2 对等式分布爬虫（Peer to Peer） 31
本章提要 34
本章参考文献 34
第3章 搜索引擎索引 36
3.1 索引基础 36
3.1.1 单词—文档矩阵 37
3.1.2 倒排索引基本概念 37
3.1.3 倒排索引简单实例 39
3.2 单词词典 42
3.2.1 哈希加链表 42
3.2.2 树形结构 43
3.3 倒排列表（Posting List） 44
3.4 建立索引 45
3.4.1 两遍文档遍历法（2-Pass In-Memory Inversion） 45
3.4.2 排序法（Sort-based Inversion） 46
3.4.3 归并法（Merge-based Inversion） 49
3.5 动态索引 50
3.6 索引更新策略 51
3.6.1 完全重建策略（Complete Re-Build） 51
3.6.2 再合并策略（Re-Merge） 52
3.6.3 原地更新策略（In-Place） 55
3.6.4 混合策略（Hybrid） 57
3.7 查询处理 57
3.7.1 一次一文档（Doc at a Time） 58
3.7.2 一次一单词（Term at a Time） 59
3.7.3 跳跃指针（Skip Pointers） 60
3.8 多字段索引 62
3.8.1 多索引方式 62
3.8.2 倒排列表方式 63
3.8.3 扩展列表方式（Extent List） 64
3.9 短语查询 64
3.9.1 位置信息索引（Position Index） 65
3.9.2 双词索引（Nextword Index） 66
3.9.3 短语索引（Phrase Index） 67
3.9.4 混合方法 67
3.10 分布式索引（Parallel Indexing） 68
3.10.1 按文档划分（Document Partitioning） 69
3.10.2 按单词划分（Term Partitioning） 70
3.10.3 两种方案的比较 72
本章提要 73
本章参考文献 73
第4章 索引压缩 76
4.1 词典压缩 76
4.2 倒排列表压缩算法 78
4.2.1 评价索引压缩算法的指标 79
4.2.2 一元编码与二进制编码 79
4.2.3 Elias Gamma算法与Elias Delta算法 81
4.2.4 Golomb算法与Rice算法 81
4.2.5 变长字节算法（Variable Byte） 83
4.2.6 SimpleX 系列算法 84
4.2.7 PForDelta算法 86
4.3 文档编号重排序（DocID Reordering） 89
4.4 静态索引裁剪（Static Index Pruning） 93
4.4.1 以单词为中心的索引裁剪 94
4.4.2 以文档为中心的索引裁剪 96
本章提要 97
本章参考文献 97
第5章 检索模型与搜索排序 99
5.1 布尔模型（Boolean Model） 101
5.2 向量空间模型（Vector Space Model） 102
5.2.1 文档表示 102
5.2.2 相似性计算 104
5.2.3 特征权重计算 106
5.3 概率检索模型 108
5.3.1 概率排序原理 108
5.3.2 二元独立模型（Binary Independent Model） 110
5.3.3 BM25模型 113
5.3.4 BM25F模型 115
5.4 语言模型方法 116
5.5 机器学习排序（Learning to Rank） 119
5.5.1 机器学习排序的基本思路 120
5.5.2 单文档方法（PointWise Approach） 121
5.5.3 文档对方法（PairWise Approach） 122
5.5.4 文档列表方法（ListWise Approach） 123
5.6 检索质量评价标准 125
5.6.1 精确率与召回率 126
5.6.2 P@10指标 127
5.6.3 MAP指标（Mean Average Precision） 128
本章提要 129
本章参考文献 129
第6章 链接分析 131
6.1 Web图 131
6.2 两个概念模型及算法之间的关系 133
6.2.1 随机游走模型（Random Surfer Model） 133
6.2.2 子集传播模型 135
6.2.3 链接分析算法之间的关系 136
6.3 PageRank算法 137
6.3.1 从入链数量到PageRank 137
6.3.2 PageRank计算 138
6.3.3 链接陷阱（Link Sink）与远程跳转（Teleporting） 139
6.4 HITS算法（Hypertext Induced Topic Selection） 140
6.4.1 Hub页面与Authority页面 140
6.4.2 相互增强关系 141
6.4.3 HITS算法 142
6.4.4 HITS算法存在的问题 144
6.4.5 HITS算法与PageRank算法比较 145
6.5 SALSA算法 146
6.5.1 确定计算对象集合 146
6.5.2 链接关系传播 148
6.5.3 Authority权值计算 150
6.6 主题敏感PageRank（Topic Sensitive PageRank） 152
6.6.1 主题敏感PageRank与PageRank的差异 152
6.6.2 主题敏感PageRank计算流程 153
6.6.3 利用主题敏感PageRank构造个性化搜索 156
6.7 Hilltop算法 156
6.7.1 Hilltop算法的一些基本定义 157
6.7.2 Hilltop算法 158
6.8 其他改进算法 162
6.8.1 智能游走模型（Intelligent Surfer Model） 162
6.8.2 偏置游走模型（Biased Surfer Model） 163
6.8.3 PHITS算法（Probability Analogy of HITS） 163
6.8.4 BFS算法（Backward Forward Step） 163
本章提要 164
本章参考文献 164
第7章 云存储与云计算 166
7.1 云存储与云计算概述 167
7.1.1 基本假设 167
7.1.2 理论基础 168
7.1.3 数据模型 170
7.1.4 基本问题 170
7.1.5 Google的云存储与云计算架构 171
7.2 Google文件系统（GFS） 173
7.2.1 GFS设计原则 174
7.2.2 GFS整体架构 174
7.2.3 GFS主控服务器 176
7.2.4 系统交互行为 178
7.3 Chubby锁服务 179
7.4 BigTable 181
7.4.1 BigTable的数据模型 181
7.4.2 BigTable整体结构 183
7.4.3 BigTable的管理数据 184
7.4.4 主控服务器（Master Server） 186
7.4.5 子表服务器（Tablet Server） 187
7.5 Megastore系统 191
7.5.1 实体群组切分 192
7.5.2 数据模型 193
7.5.3 数据读写与备份 195
7.6 Map/Reduce云计算模型 195
7.6.1 计算模型 196
7.6.2 整体逻辑流程 197
7.6.3 应用示例 198
7.7 咖啡因系统——Percolator 199
7.7.1 事务支持 200
7.7.2 观察/通知体系结构 202
7.8 Pregel图计算模型 203
7.9 Dynomo云存储系统 206
7.9.1 数据划分算法（Partitioning Algorithm） 207
7.9.2 数据备份（Replication） 208
7.9.3 数据读写 208
7.9.4 数据版本控制 209
7.10 PNUTS云存储系统 210
7.10.1 PNUTS整体架构 211
7.10.2 存储单元 211
7.10.3 子表控制器与数据路由器 213
7.10.4 雅虎消息代理 213
7.10.5 数据一致性 214
7.11 HayStack存储系统 215
7.11.1 HayStack整体架构 216
7.11.2 目录服务 218
7.11.3 HayStack缓存 219
7.11.4 HayStack存储系统 219
本章提要 222
本章参考文献 222
第8章 网页反作弊 224
8.1 内容作弊 224
8.1.1 常见内容作弊手段 225
8.1.2 内容农场（Content Farm） 226
8.2 链接作弊 227
8.3 页面隐藏作弊 230
8.4 Web 2.0作弊方法 231
8.5 反作弊技术的整体思路 232
8.5.1 信任传播模型 233
8.5.2 不信任传播模型 234
8.5.3 异常发现模型 234
8.6 通用链接反作弊方法 236
8.6.1 TrustRank算法 237
8.6.2 BadRank算法 238
8.6.3 SpamRank 239
8.7 专用链接反作弊技术 240
8.7.1 识别链接农场 240
8.7.2 识别Google轰炸 241
8.8 识别内容作弊 241
8.9 反隐藏作弊 241
8.9.1 识别页面隐藏 241
8.9.2 识别网页重定向 242
8.10 搜索引擎反作弊综合框架 242
本章提要 244
本章参考文献 244
第9章 用户查询意图分析 246
9.1 搜索行为及其意图 246
9.1.1 用户搜索行为 246
9.1.2 用户搜索意图分类 248
9.2 搜索日志挖掘 250
9.2.1 查询会话（Query Session） 250
9.2.2 点击图（Click Graph） 251
9.2.3 查询图（Query Graph） 252
9.3 相关搜索 253
9.3.1 基于查询会话的方法 253
9.3.2 基于点击图的方法 254
9.4 查询纠错 255
9.4.1 编辑距离（Edit Distance） 256
9.4.2 噪声信道模型（Noise Channel Model） 257
本章提要 257
本章参考文献 258
第10章 网页去重 259
10.1 通用去重算法框架 261
10.2 Shingling算法 262
10.3 I-Match算法 265
10.4 SimHash算法 268
10.4.1 文档指纹计算 269
10.4.2 相似文档查找 270
10.5 SpotSig算法 272
10.5.1 特征抽取 272
10.5.2 相似文档查找 273
本章提要 274
本章参考文献 274
第11章 搜索引擎缓存机制 276
11.1 搜索引擎缓存系统架构 277
11.2 缓存对象 279
11.3 缓存结构 281
11.4 缓存淘汰策略（Evict Policy） 283
11.4.1 动态策略 284
11.4.2 混合策略 284
11.5 缓存更新策略（Refresh Policy） 285
本章提要 286
本章参考文献 287
第12章 搜索引擎发展趋势 288
12.1 个性化搜索 288
12.2 社会化搜索 290
12.3 实时搜索 291
12.4 移动搜索 293
12.5 地理位置感知搜索 294
12.6 跨语言搜索 296
12.7 多媒体搜索 298
12.8 情境搜索 299
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>这就是搜索引擎
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能基础（高中版）
第一章 人工智能: 新时代的开启………… 1
1.1跨越时空: 铭铭的一天………… 2
1.2光辉岁月: 人工智能简史………… 5
1.3百花齐放: 人工智能在各行各业的应用………… 10
1.4初露真容: 人工智能与机器学习………… 13
1.5本章小结………… 17
第二章 牛刀小试: 察异辨花………… 19
2.1初学乍练: 分类任务………… 20
2.2含英咀华: 提取特征………… 22
2.3分门别类: 分类器………… 25
2.4实践出真知: 测试和应用………… 35
2.5五花八门: 多类别分类………… 37
2.6大显身手: 二分类在生活中的应用………… 39
2.7本章小结………… 42
第三章 别具慧眼: 识图认物………… 43
3.1温故知新: 基于手工特征的图像分类………… 44
3.2另辟蹊径: 基于深度神经网络的图像分类………… 52
3.3“网”不厌深: 深度神经网络的发展与挑战………… 60
3.4忽如一夜春风来: 图像分类在日常生活中的应用………… 66
3.5本章小结………… 68
第四 耳听八方: 析音赏乐………… 71
4.1洗耳恭听: 听声的艺术………… 73
4.2丝竹管弦: 音乐风格分类………… 78
4.3言听计从: 语音识别技术………… 82
4.4听声辨曲: 乐曲检索技术………… 84
4.5本章小结………… 85
第五章 冰雪聪明: 看懂视频………… 87
5.1化静为动: 从图像到视频………… 88
5.2明察秋毫: 视频行为识别………… 90
5.3基于深度学习的视频行为识别………… 98
5.4本章小结………… 103
第六章 无师自通: 分门别类………… 105
6.1当人工智能未曾听说花的名字………… 106
6.2物以类聚: 鸢尾花的K 均值聚类………… 108
6.3人以群分: 相册中的人脸聚类………… 111
6.4层次聚类与生物聚类………… 118
6.5本章小结………… 119
第七章 识文断字: 理解文本………… 121
7.1任务的特点………… 122
7.2文本的特征………… 124
7.3高屋建瓴: 发掘文本中潜在的主题………… 128
7.4投其所好: 基于主题的文本搜索与推荐………… 133
7.5本章小结………… 134
第八章 神来之笔: 创作图画………… 135
8.1九层之台, 起于累土: 数据空间和数据分布………… 136
8.2化腐朽为神奇的创作家: 生成网络………… 140
8.3火眼金睛的鉴赏家: 判别网络………… 142
8.4在对抗中合作与进步: 生成对抗网络………… 145
8.5得心应手地创作: 条件生成对抗网络………… 151
8.6本章小结………… 152
第九章 运筹帷幄: 围棋高手………… 153
9.1初窥门径: 阿尔法狗的走棋网络………… 155
9.2远见卓识: 阿尔法狗的大局观………… 158
9.3成就非凡: 阿尔法元………… 161
9.4本章小结………… 163
后记………… 165
参考文献………… 167
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能基础（高中版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习理论的本质
译序
第二版前言
第一版前言
0 引论：学习问题研究的四个阶段
0.1 Rosenblatt的感知器（60年代）
0.1.1 感知器模型
0.1.2 对学习过程分析的开始
0.1.3 对学习过程的应用分析与理论分析
0.2 学习理论基础的创立（60-70年代）
0.2.1 经验风险最小化原则的理论
0.2.2 解决不适定问题的理论
0.2.3 密度估计的非参数方法
0.2.4 算法复杂度的思想
0.3 神经网络（80年代）
0.3.1 神经网络的思想
0.3.2 理论分析目标的简化
0.4 回到起点（90年代）
第一章 学习问题的表示
1.1 函数估计模型
1.2 风险最小化问题
1.3 三种主要的学习问题
1.3.1 模式识别
1.3.2 回归估计
1.3.3 密度估计（Fisher-wald表示）
1.4 学习问题的一般表示
1.5 经验风险最小化归纳原则
1.6 学习理论的四个部分
非正式推导和评述——1
1.7 解决学习问题的传统模式
1.7.1 密度估计问题（最大似然方法）
1.7.2 模式识别（判别分析）问题
1.7.3 回归估计模型
1.7.4 最大似然法的局限
1.8 密度估计的非参数方法
1.9　用有限数量信息解决问题的基本原则
1.10　基于经验数据的风险最小化模型
1.11　随机逼近期间
第二章 学习过程的一致性
2.1　传统性的一致性和非平凡一致性概念
2.2　学习理论的关键定理
2.3　一致双边收敛的充分必要条件
2.4　一致单边收敛的充分必要条件
2.5　不可证伪性理论
2.6　关于不可证伪性的这定理
2.7　学习理论的三个里程碑
非正式指导和评述——2
2.8　概率论和统计学的基本问题
2.9　估计概率测度的两种方式
2.10　概率测度的强方式估计与官度估计问题
2.11 Glivenko-Cantelli及其推广
2.12　归纳的数学理论
第三章 学习过程收敛速度的界
3.1　基本不等式
3.2　对实函数集的推广
……
第四章 控制学习过程的推广能力
第五章 模式识别的方法
第六章 函数估计的方法
第七章 统计学习理论中的直接方法
第八章 邻域风险最小化原则与SVM
第九章 结论：什么是学习理论中重要的？
参考文献及评述
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习理论的本质
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习方法（第2版）
第一篇  监督学习

第二篇 无监督学习
第13章 无监督学习概论
13.1.1  无监督学习基本原理
13.1.2  基本问题
13.1.3  机器学习三要素
13.1.4  无监督学习方法


第14章 聚类方法
14.1  聚类的基本概念
14.1.1  相似度或距离
14.1.2  类或簇
14.1.3  类与类之间的距离
14.2  层次聚类
14.3  k均值聚类
14.3.1  模型
14.3.2  策略
14.3.3  算法
14.3.4  算法特点
本章概要
继续阅读
习题
参考文献


第15章  奇异值分解
15.1  奇异值分解的定义与性质
15.1.1  定义与定理
15.1.2  紧奇异值分解与截断奇异值分解
15.1.3  几何解释
15.1.4  主要性质
15.2  奇异值分解的计算
15.3  奇异值分解与矩阵近似
15.3.1  弗罗贝尼乌斯范数
15.3.2  矩阵的优近似
15.3.3  矩阵的外积展开式
本章概要
继续阅读
习题
参考文献


第16章  主成分分析
16.1  总体主成分分析
16.1.1  基本想法
16.1.2  定义和导出
16.1.3  主要性质
16.1.4  主成分的个数
16.1.5  规范化变量的总体主成分
16.2  样本主成分分析
16.2.1  样本主成分的定义和性质
16.2.2  相关矩阵的特征值分解算法
16.2.3  数据局正的奇异值分解算法
本章概要
继续阅读
习题
参考文献


第17章  潜在语义分析
17.1  单词向量空间与话题向量空间
17.1.1  单词向量空间
17.1.2  话题向量空间
17.2  潜在语义分析算法
17.2.1  矩阵奇异值分解算法
17.2.2  例子
17.3  非负矩阵分解算法
17.3.1  非负矩阵分解
17.3.2  潜在语义分析模型
17.3.3  非负矩阵分解的形式化
17.3.4  算法
本章概要
继续阅读
习题
参考文献


第18章  概率潜在语义分析
18.1  概率潜在语义分析模型
18.1.1  基本想法
18.1.2  生成模型
18.1.3  共现模型
18.1.4  模型性质
18.2  概率潜在语义分析的算法
本章概要
继续阅读
习题
参考文献



第19章  马尔可夫链蒙特卡罗法
19.1  蒙特卡罗法
19.1.1  随机抽样
19.1.2  数学期望估计
19.1.3  积分计算
19.2  马尔可夫链
19.2.1  基本定义
19.2.2  离散状态马尔可夫链
19.2.3  连续状态马尔可夫链
19.2.4  马尔可夫链的性质
19.3  马尔可夫链蒙特卡罗法
19.3.1  基本想法
19.3.2  基本步骤
19.3.3  马尔可夫链蒙特卡罗法与统计学习
19.4  Metropolis-Hastings算法
19.4.1  基本原理
19.4.2  Metropolis-Hastings算法
19.4.3  单分量Metropolis-Hastings算法
19.5  吉布斯抽样
19.5.1  基本原理
19.5.2  吉布斯抽样算法
19.5.3  抽样计算
本章概要
继续阅读
习题
参考文献


第20章  潜在狄利克雷分配
20.1  狄利克雷分布
20.1.1  分布定义
20.1.2  共轭先验
20.2  潜在狄利克雷分配模型
20.2.1  基本想法
20.2.2  模型定义
20.2.3  概率图模型
20.2.4  随机变量序列的可交换性
20.2.5  概率公式
20.3  LDA的吉布斯抽样算法
20.3.1  基本想法
20.3.2  算法的主要部分
20.3.3  算法的后处理
20.3.4  算法
20.4  LDA的变分EM算法
20.4.1  变分推理
20.4.2  变分EM算法
20.4.3  算法推导
20.4.4  算法总结
本章概要
继续阅读
习题
参考文献


第21章  PageRank算法
21.1  PageRank的定义
21.1.1  基本想法
21.1.2  有向图和随机游走模型
21.1.3  PageRank的基本定义
21.1.4  PageRank的一般定义
21.2  PageRank的计算
21.2.1  迭代算法
21.2.2  幂法
21.3.3  代数算法
本章概要
继续阅读
习题
参考文献


第22章  无监督学习方法总结
22.1  无监督学习方法的关系和特点
22.1.1  各种方法之间的关系
22.1.2  无监督学习方法
22.1.3  基础及其学习方法
22.2  话题模型之间的关系和特点
参考文献

附录A  梯度下降法
附录B  牛顿法和拟牛顿法
附录C  拉格朗日对偶性
附录D  矩阵的基本子空间
附录E  KL散度的定义和狄利克雷分布的性质

索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习方法（第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统
目　录

第1章　引言　　1
1.1　 第一部分：基本概念　　2
1.1.1　 协同过滤推荐　　2
1.1.2　 基于内容的推荐　　2
1.1.3　 基于知识的推荐　　3
1.1.4　 混合推荐方法　　4
1.1.5　 推荐系统的解释　　4
1.1.6　 评估推荐系统　　4
1.1.7　 案例研究　　5
1.2　 第二部分：最新进展　　5
第一部分　基本概念
第2章　协同过滤推荐　　8
2.1　 基于用户的最近邻推荐　　8
2.1.1　 第一个例子　　8
2.1.2　 更好的相似度和赋权体系　　10
2.1.3　 选择近邻　　11
2.2　 基于物品的最近邻推荐　　11
2.2.1　 余弦相似度度量　　12
2.2.2　 基于物品过滤的数据预处理　　13
2.3　 关于评分　　14
2.3.1　 隐式和显式评分　　14
2.3.2　 数据稀疏和冷启动问题　　15
2.4　 更多基于模型和预处理的方法　　16
2.4.1　 矩阵因子分解　　17
2.4.2　 关联规则挖掘　　20
2.4.3　 基于概率分析的推荐方法　　22
2.5　 近来实际的方法和系统　　25
2.5.1　 Slope One预测器　　26
2.5.2　 Google新闻个性化推荐引擎　　28
2.6　 讨论和小结　　30
2.7　 书目注释　　31
第3章　基于内容的推荐　　32
3.1　 内容表示和相似度　　33
3.1.1　 向量空间模型和TF-IDF　　34
3.1.2　 向量空间模型的改进及局限　　35
3.2　 基于内容相似度检索　　36
3.2.1　 最近邻　　36
3.2.2　 相关性反馈——Rocchio方法　　37
3.3　 其他文本分类方法　　40
3.3.1　 基于概率模型的方法　　40
3.3.2　 其他线性分类器和机器学习　　43
3.3.3　 显式决策模型　　44
3.3.4　 特征选择　　45
3.4　 讨论　　47
3.4.1　 对比评估　　47
3.4.2　 局限　　47
3.5　 小结　　48
3.6　 书目注释　　49
第4章　基于知识的推荐　　51
4.1　 介绍　　51
4.2　 知识表示法和推理　　52
4.2.1　 约束　　52
4.2.2　 实例与相似度　　54
4.3　 与基于约束推荐系统交互　　55
4.3.1　 默认设置　　55
4.3.2　 处理不满意的需求和空结果集　　57
4.3.3　 提出对未满足需求的修改建议　　61
4.3.4　 对基于物品/效用推荐结果的排序　　61
4.4　 与基于实例的推荐系统交互　　64
4.4.1　 评价　　65
4.4.2　 混合评价　　67
4.4.3　 动态评价　　67
4.4.4　 高级的物品推荐方法　　70
4.4.5　 评价多样性　　71
4.5　 应用实例　　72
4.5.1　 VITA——基于约束的推荐系统　　72
4.5.2　 Entree——基于实例的推荐系统　　77
4.6　 书目注释　　79
第5章　混合推荐方法　　80
5.1　 混合推荐的时机　　81
5.1.1　 推荐理论框架　　81
5.1.2　 混合设计　　82
5.2　 整体式混合设计　　83
5.2.1　 特征组合的混合方案　　84
5.2.2　 特征补充的混合方案　　85
5.3　 并行式混合设计　　87
5.3.1　 交叉式混合　　87
5.3.2　 加权式混合　　88
5.3.3　 切换式混合　　89
5.4　 流水线混合设计　　90
5.4.1　 串联混合　　90
5.4.2　 分级混合　　91
5.5　 讨论和小结　　92
5.6　 书目注释　　92
第6章　推荐系统的解释　　94
6.1　 介绍　　94
6.2　 基于约束的推荐系统中的解释　　96
6.2.1　 实例　　97
6.2.2　 通过推导生成解释　　99
6.2.3　 可靠解释的分析与概述　　100
6.2.4　 可靠解释　　102
6.3　 基于实例推荐系统的解释　　103
6.4　 协同过滤推荐系统的解释　　106
6.5　 小结　　108
第7章　评估推荐系统　　109
7.1　 介绍　　109
7.2　 评估研究的一般特性　　110
7.2.1　 总论　　110
7.2.2　 评估方案的实验对象　　111
7.2.3　 研究方法　　113
7.2.4　 评估环境　　115
7.3　 主流推荐方案　　115
7.4　 历史数据集评估　　116
7.4.1　 方法论　　116
7.4.2　 衡量标准　　117
7.4.3　 结果的分析　　121
7.5　 其他评估方案　　121
7.5.1　 实验性研究方案　　122
7.5.2　 准实验研究方案　　122
7.5.3　 非实验研究方案　　123
7.6　 小结　　123
7.7　 书目注释　　124
第8章　案例分析：移动互联网个性化游戏推荐　　125
8.1　 应用与个性化概述　　126
8.2　 算法和评级　　128
8.3　 评估　　128
8.3.1　 测量1：我的推荐　　129
8.3.2　 测量2：售后推荐　　131
8.3.3　 测量3：起始页推荐　　133
8.3.4　 测量4：演示版下载的整体效果　　135
8.3.5　 测量5：整体效果　　136
8.4　 小结与结论　　138
第二部分　最新进展
第9章　针对协同推荐系统的攻击　　140
9.1　 第一个例子　　141
9.2　 攻击维度　　141
9.3　 攻击类型　　142
9.3.1　 随机攻击　　142
9.3.2　 均值攻击　　143
9.3.3　 造势攻击　　143
9.3.4　 局部攻击　　143
9.3.5　 针对性的打压攻击　　144
9.3.6　 点击流攻击和隐式反馈　　144
9.4　 效果评估和对策　　145
9.4.1　 推举攻击　　145
9.4.2　 打压攻击　　146
9.5　 对策　　146
9.6　 隐私方面——分布式协同过滤　　148
9.6.1　 集中方法：数据扰动　　149
9.6.2　 分布式协同过滤　　150
9.7　 讨论　　153
第10章　在线消费决策　　155
10.1　 介绍　　155
10.2　 环境效应　　156
10.3　 首位/新近效应　　159
10.4　 其他效应　　160
10.5　 个人和社会心理学　　161
10.6　 书目注释　　167
第11章　推荐系统和下一代互联网　　168
11.1　 基于信任网络的推荐系统　　169
11.1.1　 利用显式的信任网络　　169
11.1.2　 信任度度量方法和效果　　171
11.1.3　 相关方法和近期进展　　172
11.2　 大众分类法及其他　　174
11.2.1　 基于大众分类法的推荐　　174
11.2.2　 推荐标签　　181
11.2.3　 在分享媒体中推荐内容　　183
11.3　 本体过滤　　185
11.3.1　 通过分类改进过滤　　185
11.3.2　 通过属性改进过滤　　188
11.4　 从网络抽取语义　　189
11.5　 小结　　191
第12章　普适环境中的推荐　　192
12.1　 介绍　　192
12.2　 上下文感知推荐　　193
12.3　 应用领域　　195
12.4　 小结　　197
第13章　总结和展望　　198
13.1　 总结　　198
13.2　 展望　　198
参考文献　　201
索引　　223

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学实战
作者介绍　　 XII
关于封面图　　XIII
前言　　XIV
第1章　简介：什么是数据科学　　1
1.1　大数据和数据科学的喧嚣　　1
1.2　冲出迷雾　　2
1.3　为什么是现在　　3
1.4　数据科学的现状和历史　　5
1.5　数据科学的知识结构　　8
1.6　思维实验：元定义　　10
1.7　什么是数据科学家　　11
1.7.1　学术界对数据科学家的定义　　12
1.7.2　工业界对数据科学家的定义　　12
第2章　统计推断、探索性数据分析和数据科学工作流程　　14
2.1　大数据时代的统计学思考　　14
2.1.1　统计推断　　15
2.1.2　总体和样本　　16
2.1.3　大数据的总体和样本　　17
2.1.4　大数据意味着大胆的假设　　19
2.1.5　建模　　21
2.2　探索性数据分析　　26
2.2.1　探索性数据分析的哲学　　27
2.2.2　练习：探索性数据分析　　29
2.3　数据科学的工作流程　　31
2.4　思维实验：如何模拟混沌　　34
2.5　案例学习：RealDirect　　35
2.5.1　RealDirect是如何赚钱的　　36
2.5.2　练一练：RealDirect公司的数据策略　　36
第3章　算法　　39
3.1　机器学习算法　　40
3.2　三大基本算法　　41
3.2.1　线性回归模型　　42
3.2.2　k 近邻模型（k-NN）　　55
3.2.3　k 均值算法　　64
3.3　练习：机器学习算法基础　　68
3.4　总结　　72
3.5　思维实验：关于统计学家的自动化　　73
第4章　垃圾邮件过滤器、朴素贝叶斯与数据清理　　74
4.1　思维实验：从实例中学习　　74
4.1.1　线性回归为何不适用　　75
4.1.2　k 近邻效果如何　　77
4.2　朴素贝叶斯模型　　78
4.2.1　贝叶斯法则　　79
4.2.2　个别单词的过滤器　　80
4.2.3　直通朴素贝叶斯　　82
4.3　拉普拉斯平滑法　　83
4.4　对比朴素贝叶斯和k 近邻　　85
4.5　Bash代码示例　　85
4.6　网页抓取：API和其他工具　　87
4.7　Jake的练习题：文章分类问题中的朴素贝叶斯模型　　88
第5章　逻辑回归　　92
5.1　思维实验　　93
5.2　分类器　　94
5.2.1　运行时间　　95
5.2.2　你自己　　95
5.2.3　模型的可解释性　　95
5.2.4　可扩展性　　96
5.3　逻辑回归：一个来自M6D 的真实案例研究　　96
5.3.1　点击模型　　96
5.3.2　模型背后　　97
5.3.3　α和β 的参数估计　　99
5.3.4　牛顿法　　101
5.3.5　随机梯度下降法　　101
5.3.6　操练　　101
5.3.7　模型评价　　102
5.4　练习题　　105
第6章　时间戳数据与金融建模　　110
6.1　Kyle Teague与GetGlue公司　　110
6.2　时间戳　　112
6.2.1　探索性数据分析（EDA）　　113
6.2.2　指标和新变量　　117
6.2.3　下一步怎么做　　117
6.3　轮到Cathy O'Neill了　　118
6.4　思维实验　　118
6.5　金融建模　　119
6.5.1　样本期内外以及因果关系　　120
6.5.2　金融数据处理　　121
6.5.3　对数收益率　　123
6.5.4　实例：标准普尔指数　　124
6.5.5　如何衡量波动率　　126
6.5.6　指数平滑法　　128
6.5.7　金融模型的反馈　　128
6.5.8　聊聊回归模型　　130
6.5.9　先验信息量　　130
6.5.10　一个小例子　　131
6.6　练习：GetGlue提供的时间戳数据　　134
第7章　从数据到结论　　136
7.1　William Cukierski　　136
7.1.1　背景介绍：数据科学竞赛　　136
7.1.2　背景介绍：众包模式　　137
7.2　Kaggle模式　　139
7.2.1　Kaggle的参赛者　　140
7.2.2　Kaggle的客户　　141
7.3　思维实验：关于作业自动评分系统　　143
7.4　特征选择　　145
7.4.1　例子：留住用户　　146
7.4.2　过滤型　　149
7.4.3　包装型　　149
7.4.4　决策树与嵌入型变量选择　　151
7.4.5　熵　　153
7.4.6　决策树算法　　155
7.4.7　如何在决策树模型中处理连续性变量　　156
7.4.8　随机森林　　157
7.4.9　用户黏性：模型的预测能力与可解释性　　159
7.5　David Huffaker：谷歌社会学研究的新方法　　160
7.5.1　从描述性统计到预测模型　　161
7.5.2　谷歌的社交研究　　163
7.5.3　隐私保护　　163
7.5.4　思维实验：如何消除用户的顾虑　　164
第8章　构建面向大量用户的推荐引擎　　165
8.1　一个真实的推荐引擎　　166
8.1.1　最近邻算法回顾　　167
8.1.2　最近邻模型的已知问题　　168
8.1.3　超越近邻模型：基于机器学习的分类模型　　169
8.1.4　高维度问题　　171
8.1.5　奇异值分解（SVD）　　172
8.1.6　关于SVD的重要特性　　172
8.1.7　主成分分析（PCA）　　173
8.1.8　交替最小二乘法　　174
8.1.9　固定矩阵V，更新矩阵U　　175
8.1.10　关于这些算法的一点思考　　176
8.2　思维实验：如何过滤模型中的泡沫　　176
8.3　练习：搭建自己的推荐系统　　176
第9章　数据可视化与欺诈侦测　　179
9.1　数据可视化的历史　　179
9.1.1　Gabriel Tarde　　180
9.1.2　Mark 的思维实验　　181
9.2　到底什么是数据科学　　181
9.2.1　Processing　　182
9.2.2　Franco Moretti　　182
9.3　一个数据可视化的方案实例　　183
9.4　Mark 的数据可视化项目　　186
9.4.1　《纽约时报》大厅里的可视化：Moveable Type　　186
9.4.2　屏幕上的生命：Cascade可视化项目　　188
9.4.3　Cronkite广场项目　　189
9.4.4　eBay与图书网购　　190
9.4.5　公共剧场里的“莎士比亚机”　　192
9.4.6　这些展览的目的是什么　　193
9.5　数据科学和风险　　193
9.5.1　关于Square公司　　194
9.5.2　支付风险　　194
9.5.3　模型效果的评估问题　　197
9.5.4　建模小贴士　　200
9.6　数据可视化在Square　　203
9.7　Ian的思维实验　　204
9.8　关于数据可视化　　204
第10章　社交网络与数据新闻学　　207
10.1　Morning Analytics与社交网络　　207
10.2　社交网络分析　　209
10.3　关于社交网络分析的相关术语　　209
10.3.1　如何衡量向心性　　210
10.3.2　使用哪种向心性测度　　211
10.4　思维实验　　212
10.5　Morningside Analytics　　212
10.6　从统计学的角度看社交网络分析　　215
10.6.1　网络的表示方法与特征值向心度　　215
10.6.2　随机网络的第一个例子：Erdos-Renyi模型　　217
10.6.3　随机网络的第二个例子：指数随机网络图模型　　217
10.7　数据新闻学　　220
10.7.1　关于数据新闻学的历史回顾　　220
10.7.2　数据新闻报告的写作：来自专家的建议　　220
第11章　因果关系研究　　222
11.1　相关性并不代表因果关系　　223
11.1.1　对因果关系提问　　223
11.1.2　干扰因子：一个关于在线约会网站的例子　　224
11.2　OK Cupid的发现　　225
11.3　黄金准则：随机化临床实验　　226
11.4　A/B测试　　228
11.5　退一步求其次：关于观察性研究　　229
11.5.1　辛普森悖论　　230
11.5.2　鲁宾因果关系模型　　231
11.5.3　因果关系的可视化　　232
11.5.4　定义：因果关系　　233
11.6　三个小建议　　235
第12章　流行病学　　236
12.1　Madigan的学术背景　　236
12.2　思维实验　　237
12.3　统计学在现代　　238
12.4　医学文献与观察性研究　　238
12.5　分层法不解决干扰因子的问题　　239
12.6　就没有更好的办法吗　　241
12.7　研究性实验（OMOP）　　242
12.8　最后的思维实验　　246
第13章　从竞赛中学到的：数据泄漏和模型评价　　247
13.1　Claudia作为数据科学家的知识结构　　247
13.1.1　首席数据科学家的生活　　248
13.1.2　作为一名女数据科学家　　248
13.2　数据挖掘竞赛　　249
13.3　如何成为出色的建模者　　250
13.4　数据泄漏　　250
13.4.1　市场预测　　251
13.4.2　亚马逊案例学习：出手阔绰的顾客　　251
13.4.3　珠宝抽样问题　　251
13.4.4　IBM 客户锁定　　252
13.4.5　乳腺癌检测　　253
13.4.6　预测肺炎　　253
13.5　如何避免数据泄漏　　254
13.6　模型评价　　255
13.6.1　准确度重要吗　　256
13.6.2　概率的重要性，不是非0 即1　　256
13.7　如何选择算法　　259
13.8　最后一个例子　　259
13.9　临别感言　　260
第14章　数据工程：MapReduce、Pregel、Hadoop　　261
14.1　关于David Crawshaw　　262
14.2　思维实验　　262
14.3　MapReduce　　263
14.4　单词频率问题　　264
14.5　其他MapReduce案例　　267
14.6　Pregel　　268
14.7　关于Josh Wills　　269
14.8　思维实验　　269
14.9　给数据科学家的话　　269
14.9.1　数据丰富和数据匮乏　　270
14.9.2　设计模型　　270
14.10　算算Hadoop的经济账　　270
14.10.1　Hadoop简介　　271
14.10.2　Cloudera　　271
14.11　Josh 的工作流程　　272
14.12　如何开始使用Hadoop　　272
第15章　听听学生们怎么说　　273
15.1　重在过程　　273
15.2　不再简单　　274
15.3　援助之手　　275
15.4　殊途同归　　277
15.5　逢山开路，遇水架桥　　279
15.6　作品展示　　279
第16章　下一代数据科学家、自大狂和职业道德　　281
16.1　前面都讲了些什么　　281
16.2　什么是数据科学（再问一次）　　282
16.3　谁是下一代的数据科学家　　283
16.3.1　成为解决问题的人　　284
16.3.2　培养软技能　　284
16.3.3　成为提问者　　285
16.4　做一个有道德感的数据科学家　　286
16.5　对于职业生涯的建议　　289
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘
出版者的话
中文版序
译者序
译者简介
第3版序
第2版序
前言
致谢
作者简介
第1章　引论1
1.1　为什么进行数据挖掘1
1.1.1　迈向信息时代1
1.1.2　数据挖掘是信息技术的进化2
1.2　什么是数据挖掘4
1.3　可以挖掘什么类型的数据6
1.3.1　数据库数据6
1.3.2　数据仓库7
1.3.3　事务数据9
1.3.4　其他类型的数据9
1.4　可以挖掘什么类型的模式10
1.4.1　类/概念描述：特征化与区分10
1.4.2　挖掘频繁模式、关联和相关性11
1.4.3　用于预测分析的分类与回归12
1.4.4　聚类分析13
1.4.5　离群点分析14
1.4.6　所有模式都是有趣的吗14
1.5　使用什么技术15
1.5.1　统计学15
1.5.2　机器学习16
1.5.3　数据库系统与数据仓库17
1.5.4　信息检索17
1.6　面向什么类型的应用18
1.6.1　商务智能18
1.6.2　Web搜索引擎18
1.7　数据挖掘的主要问题19
1.7.1　挖掘方法19
1.7.2　用户界面20
1.7.3　有效性和可伸缩性21
1.7.4　数据库类型的多样性21
1.7.5　数据挖掘与社会21
1.8　小结22
1.9　习题23
1.10　文献注释23
第2章　认识数据26
2.1　数据对象与属性类型26
2.1.1　什么是属性27
2.1.2　标称属性27
2.1.3　二元属性27
2.1.4　序数属性28
2.1.5　数值属性28
2.1.6　离散属性与连续属性29
2.2　数据的基本统计描述29
2.2.1　中心趋势度量：均值、中位数和众数30
2.2.2　度量数据散布：极差、四分位数、方差、标准差和四分位数极差32
2.2.3　数据的基本统计描述的图形显示34
2.3　数据可视化37
2.3.1　基于像素的可视化技术37
2.3.2　几何投影可视化技术38
2.3.3　基于图符的可视化技术40
2.3.4　层次可视化技术42
2.3.5　可视化复杂对象和关系42
2.4　度量数据的相似性和相异性44
2.4.1　数据矩阵与相异性矩阵45
2.4.2　标称属性的邻近性度量46
2.4.3　二元属性的邻近性度量46
2.4.4　数值属性的相异性：闵可夫斯基距离48
2.4.5　序数属性的邻近性度量49
2.4.6　混合类型属性的相异性50
2.4.7　余弦相似性51
2.5　小结52
2.6　习题53
2.7　文献注释54
第3章　数据预处理55
3.1　数据预处理：概述55
3.1.1　数据质量：为什么要对数据预处理55
3.1.2　数据预处理的主要任务56
3.2　数据清理58
3.2.1　缺失值58
3.2.2　噪声数据59
3.2.3　数据清理作为一个过程60
3.3　数据集成61
3.3.1　实体识别问题62
3.3.2　冗余和相关分析62
3.3.3　元组重复65
3.3.4　数据值冲突的检测与处理65
3.4　数据归约65
3.4.1　数据归约策略概述66
3.4.2　小波变换66
3.4.3　主成分分析67
3.4.4　属性子集选择68
3.4.5　回归和对数线性模型：参数化数据归约69
3.4.6　直方图70
3.4.7　聚类71
3.4.8　抽样71
3.4.9　数据立方体聚集72
3.5　数据变换与数据离散化73
3.5.1　数据变换策略概述73
3.5.2　通过规范化变换数据74
3.5.3　通过分箱离散化76
3.5.4　通过直方图分析离散化76
3.5.5　通过聚类、决策树和相关分析离散化76
3.5.6　标称数据的概念分层产生77
3.6　小结79
3.7　习题79
3.8　文献注释80
第4章　数据仓库与联机分析处理82
4.1　数据仓库：基本概念82
4.1.1　什么是数据仓库82
4.1.2　操作数据库系统与数据仓库的区别84
4.1.3　为什么需要分离的数据仓库85
4.1.4　数据仓库：一种多层体系结构85
4.1.5　数据仓库模型：企业仓库、数据集市和虚拟仓库87
4.1.6　数据提取、变换和装入88
4.1.7　元数据库88
4.2　数据仓库建模：数据立方体与OLAP89
4.2.1　数据立方体：一种多维数据模型89
4.2.2　星形、雪花形和事实星座：多维数据模型的模式91
4.2.3　维：概念分层的作用94
4.2.4　度量的分类和计算95
4.2.5　典型的OLAP操作96
4.2.6　查询多维数据库的星网查询模型98
4.3　数据仓库的设计与使用99
4.3.1　数据仓库的设计的商务分析框架99
4.3.2　数据仓库的设计过程100
4.3.3　数据仓库用于信息处理101
4.3.4　从联机分析处理到多维数据挖掘102
4.4　数据仓库的实现103
4.4.1　数据立方体的有效计算：概述103
4.4.2　索引OLAP数据：位图索引和连接索引105
4.4.3　OLAP查询的有效处理107
4.4.4　OLAP服务器结构：ROLAP、MOLAP、HOLAP的比较107
4.5　数据泛化：面向属性的归纳109
4.5.1　数据特征的面向属性的归纳109
4.5.2　面向属性归纳的有效实现113
4.5.3　类比较的面向属性归纳114
4.6　小结116
4.7　习题117
4.8　文献注释119
第5章　数据立方体技术121
5.1　数据立方体计算：基本概念121
5.1.1　立方体物化：完全立方体、冰山立方体、闭立方体和立方体外壳122
5.1.2　数据立方体计算的一般策略124
5.2　数据立方体计算方法126
5.2.1　完全立方体计算的多路数组聚集126
5.2.2　BUC：从顶点方体向下计算冰山立方体129
5.2.3　Star-Cubing：使用动态星树结构计算冰山立方体132
5.2.4　为快速高维OLAP预计算壳片段136
5.3　使用探索立方体技术处理高级查询141
5.3.1　抽样立方体：样本数据上基于OLAP的挖掘141
5.3.2　排序立方体：top-k查询的有效计算145
5.4　数据立方体空间的多维数据分析147
5.4.1　预测立方体：立方体空间的预测挖掘147
5.4.2　多特征立方体：多粒度上的复杂聚集149
5.4.3　基于异常的、发现驱动的立方体空间探查149
5.5　小结152
5.6　习题152
5.7　文献注释155
第6章　挖掘频繁模式、关联和相关性:基本概念和方法157
6.1　基本概念157
6.1.1　购物篮分析：一个诱发例子157
6.1.2　频繁项集、闭项集和关联规则158
6.2　频繁项集挖掘方法160
6.2.1　Apriori算法：通过限制候选产生发现频繁项集160
6.2.2　由频繁项集产生关联规则164
6.2.3　提高Apriori算法的效率165
6.2.4　挖掘频繁项集的模式增长方法166
6.2.5　使用垂直数据格式挖掘频繁项集169
6.2.6　挖掘闭模式和极大模式170
6.3　哪些模式是有趣的：模式评估方法171
6.3.1　强规则不一定是有趣的172
6.3.2　从关联分析到相关分析172
6.3.3　模式评估度量比较173
6.4　小结176
6.5　习题177
6.6　文献注释179
第7章　高级模式挖掘180
7.1　模式挖掘：一个路线图180
7.2　多层、多维空间中的模式挖掘182
7.2.1　挖掘多层关联规则182
7.2.2　挖掘多维关联规则185
7.2.3　挖掘量化关联规则186
7.2.4　挖掘稀有模式和负模式188
7.3　基于约束的频繁模式挖掘190
7.3.1　关联规则的元规则制导挖掘190
7.3.2　基于约束的模式产生：模式空间剪枝和数据空间剪枝191
7.4　挖掘高维数据和巨型模式195
7.5　挖掘压缩或近似模式198
7.5.1　通过模式聚类挖掘压缩模式199
7.5.2　提取感知冗余的top-k模式200
7.6　模式探索与应用202
7.6.1　频繁模式的语义注解202
7.6.2　模式挖掘的应用205
7.7　小结206
7.8　习题207
7.9　文献注释208
第8章　分类：基本概念211
8.1　基本概念211
8.1.1　什么是分类211
8.1.2　分类的一般方法211
8.2　决策树归纳213
8.2.1　决策树归纳214
8.2.2　属性选择度量217
8.2.3　树剪枝222
8.2.4　可伸缩性与决策树归纳224
8.2.5　决策树归纳的可视化挖掘225
8.3　贝叶斯分类方法226
8.3.1　贝叶斯定理227
8.3.2　朴素贝叶斯分类227
8.4　基于规则的分类230
8.4.1　使用IF-THEN规则分类230
8.4.2　由决策树提取规则231
8.4.3　使用顺序覆盖算法的规则归纳232
8.5　模型评估与选择236
8.5.1　评估分类器性能的度量236
8.5.2　保持方法和随机二次抽样240
8.5.3　交叉验证240
8.5.4　自助法241
8.5.5　使用统计显著性检验选择模型241
8.5.6　基于成本效益和ROC曲线比较分类器243
8.6　提高分类准确率的技术245
8.6.1　组合分类方法简介245
8.6.2　装袋246
8.6.3　提升和AdaBoost247
8.6.4　随机森林249
8.6.5　提高类不平衡数据的分类准确率250
8.7　小结251
8.8　习题251
8.9　文献注释253
第9章　分类：高级方法255
9.1　贝叶斯信念网络255
9.1.1　概念和机制255
9.1.2　训练贝叶斯信念网络257
9.2　用后向传播分类258
9.2.1　多层前馈神经网络258
9.2.2　定义网络拓扑259
9.2.3　后向传播260
9.2.4　黑盒内部：后向传播和可解释性263
9.3　支持向量机265
9.3.1　数据线性可分的情况265
9.3.2　数据非线性可分的情况268
9.4　使用频繁模式分类270
9.4.1　关联分类270
9.4.2　基于有区别力的频繁模式分类272
9.5　惰性学习法(或从近邻学习）275
9.5.1　k-最近邻分类275
9.5.2　基于案例的推理277
9.6　其他分类方法277
9.6.1　遗传算法277
9.6.2　粗糙集方法278
9.6.3　模糊集方法278
9.7　关于分类的其他问题280
9.7.1　多类分类280
9.7.2　半监督分类281
9.7.3　主动学习282
9.7.4　迁移学习283
9.8　小结284
9.9　习题285
9.10　文献注释286
第10章　聚类分析：基本概念和方法288
10.1　聚类分析288
10.1.1　什么是聚类分析288
10.1.2　对聚类分析的要求289
10.1.3　基本聚类方法概述291
10.2　划分方法293
10.2.1　k-均值：一种基于形心的技术293
10.2.2　k-中心点：一种基于代表对象的技术295
10.3　层次方法297
10.3.1　凝聚的与分裂的层次聚类298
10.3.2　算法方法的距离度量300
10.3.3　BIRCH：使用聚类特征树的多阶段聚类301
10.3.4　Chameleon:使用动态建模的多阶段层次聚类303
10.3.5　概率层次聚类304
10.4　基于密度的方法306
10.4.1　DBSCAN:一种基于高密度连通区域的基于密度的聚类307
10.4.2　OPTICS：通过点排序识别聚类结构309
10.4.3　DENCLUE：基于密度分布函数的聚类311
10.5　基于网格的方法312
10.5.1　STING:统计信息网格312
10.5.2　CLIQUE：一种类似于Apriori的子空间聚类方法314
10.6　聚类评估315
10.6.1　估计聚类趋势316
10.6.2　确定簇数317
10.6.3　测定聚类质量317
10.7　小结319
10.8　习题320
10.9　文献注释321
第11章　高级聚类分析323
11.1　基于概率模型的聚类323
11.1.1　模糊簇324
11.1.2　基于概率模型的聚类326
11.1.3　期望最大化算法328
11.2　聚类高维数据330
11.2.1　聚类高维数据：问题、挑战和主要方法330
11.2.2　子空间聚类方法331
11.2.3　双聚类332
11.2.4　维归约方法和谱聚类337
11.3　聚类图和网络数据339
11.3.1　应用与挑战339
11.3.2　相似性度量340
11.3.3　图聚类方法343
11.4　具有约束的聚类345
11.4.1　约束的分类345
11.4.2　具有约束的聚类方法347
11.5　小结349
11.6　习题349
11.7　文献注释350
第12章　离群点检测351
12.1　离群点和离群点分析351
12.1.1　什么是离群点351
12.1.2　离群点的类型352
12.1.3　离群点检测的挑战354
12.2　离群点检测方法354
12.2.1　监督、半监督和无监督方法355
12.2.2　统计方法、基于邻近性的方法和基于聚类的方法356
12.3　统计学方法357
12.3.1　参数方法357
12.3.2　非参数方法360
12.4　基于邻近性的方法361
12.4.1　基于距离的离群点检测和嵌套循环方法361
12.4.2　基于网格的方法363
12.4.3　基于密度的离群点检测364
12.5　基于聚类的方法366
12.6　基于分类的方法368
12.7　挖掘情境离群点和集体离群点369
12.7.1　把情境离群点检测转换成传统的离群点检测369
12.7.2　关于情境对正常行为建模370
12.7.3　挖掘集体离群点371
12.8　高维数据中的离群点检测371
12.8.1　扩充的传统离群点检测372
12.8.2　发现子空间中的离群点373
12.8.3　高维离群点建模373
12.9　小结374
12.10　习题375
12.11　文献注释375
第13章　数据挖掘的发展趋势和研究前沿377
13.1　挖掘复杂的数据类型377
13.1.1　挖掘序列数据：时间序列、符号序列和生物学序列377
13.1.2　挖掘图和网络381
13.1.3　挖掘其他类型的数据383
13.2　数据挖掘的其他方法385
13.2.1　统计学数据挖掘385
13.2.2　关于数据挖掘基础的观点386
13.2.3　可视和听觉数据挖掘387
13.3　数据挖掘应用391
13.3.1　金融数据分析的数据挖掘391
13.3.2　零售和电信业的数据挖掘392
13.3.3　科学与工程数据挖掘393
13.3.4　入侵检测和预防数据挖掘395
13.3.5　数据挖掘与推荐系统396
13.4　数据挖掘与社会397
13.4.1　普适的和无形的数据挖掘397
13.4.2　数据挖掘的隐私、安全和社会影响399
13.5　数据挖掘的发展趋势400
13.6　小结402
13.7　习题402
13.8　文献注释403
参考文献406
索引435
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据日知录
第0 章 当谈论大数据时我们在谈什么................ 1
0.1 大数据是什么.......................... 2
0.2 大数据之翼：技术范型转换......................................... 4
0.3 大数据商业炼金术................................ 6
0.4 “大数据”在路上................................................... 7
第1 章 数据分片与路由.............................................. 9
1.1 抽象模型.......................................................10
1.2 哈希分片（Hash Partition） ..............................11
1.2.1 Round Robin....................................11
1.2.2 虚拟桶（Virtual Buckets） ..........................12
1.2.3 一致性哈希（Consistent Hashing） ...........................13
1.3 范围分片（Range Partition） ......................................18
参考文献......................................19
第2 章 数据复制与一致性................................................20
2.1 基本原则与设计理念............................21
2.1.1 原教旨CAP 主义..............................................21
2.1.2 CAP 重装上阵（CAP Reloaded）.............................23
2.1.3 ACID 原则...............................................24
2.1.4 BASE 原则.................................................24
2.1.5 CAP/ACID/BASE 三者的关系...........................25
2.1.6 幂等性（Idempotent）........................................26
2.2 一致性模型分类.................................................26
2.2.1 强一致性............................................27
2.2.2 最终一致性........................................28
2.2.3 因果一致性.............................28
2.2.4 “读你所写”一致性....................................29
2.2.5 会话一致性....................................29
2.2.6 单调读一致性..............................................30
2.2.7 单调写一致性.....................................................30
2.3 副本更新策略...........................30
2.3.1 同时更新..........................................30
2.3.2 主从式更新.....................................31
2.3.3 任意节点更新......................................32
2.4 一致性协议...........................................................32
2.4.1 两阶段提交协议（Two-Phrase Commit，2PC）..........................33
2.4.2 向量时钟（Vector Clock） ..............................38
2.4.3 RWN 协议.................................................40
2.4.4 Paxos 协议.............................................42
2.4.5 Raft 协议.............................................45
参考文献................................................49
第3 章 大数据常用的算法与数据结构....................................51
3.1 布隆过滤器（Bloom Filter） ............................51
3.1.1 基本原理.............................................52
3.1.2 误判率及相关计算..........................................52
3.1.3 改进：计数Bloom Filter....................................53
3.1.4 应用............................................54
3.2 SkipList............................................55
3.3 LSM 树........................................58
3.4 Merkle 哈希树（Merkle Hash Tree） .............................62
3.4.1 Merkle 树基本原理..................................................62
3.4.2 Dynamo 中的应用.........................................63
3.4.3 比特币中的应用..................................................63
3.5 Snappy 与LZSS 算法..........................................65
3.5.1 LZSS 算法.............................................65
3.5.2 Snappy..........................................67
3.6 Cuckoo 哈希（Cuckoo Hashing） ..................................67
3.6.1 基本原理...............................................68
3.6.2 应用：SILT 存储系统.........................................68
参考文献...................................................70
第4 章 集群资源管理与调度.......................................71
4.1 资源管理抽象模型...................................72
4.1.1 概念模型....................................72
4.1.2 通用架构...............................................73
4.2 调度系统设计的基本问题.....................................74
4.2.1 资源异质性与工作负载异质性............................74
4.2.2 数据局部性（Data Locality） ........................................75
4.2.3 抢占式调度与非抢占式调度...................................75
4.2.4 资源分配粒度（Allocation Granularity） .............76
4.2.5 饿死（Starvation）与死锁（Dead Lock）问题...........................76
4.2.6 资源隔离方法........................................77
4.3 资源管理与调度系统范型.............................77
4.3.1 集中式调度器（Monolithic Scheduler）.......................78
4.3.2 两级调度器（Two-Level Scheduler） .........................79
4.3.3 状态共享调度器（Shared-State Scheduler） ....................79
4.4 资源调度策略...............................................81
4.4.1 FIFO 调度策略..........................................81
4.4.2 公平调度器（Fair Scheduler）......................81
4.4.3 能力调度器（Capacity Scheduler） ..........................82
4.4.4 延迟调度策略（Delay Scheduling）............................82
4.4.5 主资源公平调度策略（Dominant Resource Fair Scheduling）.............82
4.5 Mesos .................................84
4.6 YARN......................................87
参考文献..............................................90
第5 章 分布式协调系统...................................91
5.1 Chubby 锁服务...............................92
5.1.1 系统架构........................................93
5.1.2 数据模型..................................94
5.1.3 会话与KeepAlive 机制...............................95
5.1.4 客户端缓存.......................................95
5.2 ZooKeeper ................................96
5.2.1 体系结构...........................................96
5.2.2 数据模型（Data Model） .............................97
5.2.3 API ...............................98
5.2.4 ZooKeeper 的典型应用场景..................................98
5.2.5 ZooKeeper 的实际应用.......................................103
参考文献...................................104
第6 章 分布式通信..............................106
6.1 序列化与远程过程调用框架..................................107
6.1.1 Protocol Buffer 与Thrift .....................108
6.1.2 Avro...............................109
6.2 消息队列.....................................110
6.2.1 常见的消息队列系统......................................110
6.2.2 Kafka .......................111
6.3 应用层多播通信（Application-Level Multi-Broadcast）........114
6.3.1 概述...............................114
6.3.2 Gossip 协议...........................115
参考文献..........................118
第7 章 数据通道.........................................120
7.1 Log 数据收集.................................120
7.1.1 Chukwa........................121
7.1.2 Scribe......................122
7.2 数据总线......................................123
7.2.1 Databus............................125
7.2.2 Wormhole .......................127
7.3 数据导入/导出...........................................128
参考文献.............................129
第8 章 分布式文件系统....................................131
8.1 Google 文件系统（GFS） .................................132
8.1.1 GFS 设计原则...........................................132
8.1.2 GFS 整体架构..............................133
8.1.3 GFS 主控服务器..................................134
8.1.4 系统交互行为.................................136
8.1.5 Colossus ........................137
8.2 HDFS ..........................138
8.2.1 HDFS 整体架构.................................139
8.2.2 HA 方案..............................140
8.2.3 NameNode 联盟........................143
8.3 HayStack 存储系统....................................145
8.3.1 HayStack 整体架构.................................146
8.3.2 目录服务..................................147
8.3.3 HayStack 缓存...........................................148
8.3.4 HayStack 存储系统的实现...............................148
8.4 文件存储布局.........................................150
8.4.1 行式存储........................................151
8.4.2 列式存储...........................................151
8.4.3 混合式存储........................................156
8.5 纠删码（Erasure Code）.............................158
8.5.1 Reed-Solomon 编码...............................159
8.5.2 LRC 编码.....................................164
8.5.3 HDFS-RAID 架构.........................166
参考文献.....................................166
第9 章 内存KV 数据库...................................168
9.1 RAMCloud ..............................169
9.1.1 RAMCloud 整体架构................................169
9.1.2 数据副本管理与数据恢复................................170
9.2 Redis....................................172
9.3 MemBase ...............................173
参考文献................................................175
第10 章 列式数据库...........................................176
10.1 BigTable....................................177
10.1.1 BigTable 的数据模型..........................177
10.1.2 BigTable 的整体结构................................178
10.1.3 BigTable 的管理数据.............................179
10.1.4 主控服务器（Master Server）......................181
10.1.5 子表服务器（Tablet Server） ....................182
10.2 PNUTS 存储系统........................................186
10.2.1 PNUTS 的整体架构..............................186
10.2.2 存储单元...............................187
10.2.3 子表控制器与数据路由器..................................187
10.2.4 雅虎消息代理.............................188
10.2.5 数据一致性.........................................189
10.3 MegaStore..................................................190
10.3.1 实体群组切分......................191
10.3.2 数据模型........................................192
10.3.3 数据读/写与备份.................................193
10.4 Spanner .........................................194
10.4.1 SpanServer 软件栈.........................................195
10.4.2 数据模型.........................................196
10.4.3 TrueTime ...........................................196
参考文献..............................................197
第11 章 大规模批处理系统...................................199
11.1 MapReduce 计算模型与架构................................200
11.1.1 计算模型.......................................201
11.1.2 系统架构......................................203
11.1.3 MapReduce 计算的特点及不足......................................206
11.2 MapReduce 计算模式...........................206
11.2.1 求和模式（Summarization Pattern）................207
11.2.2 过滤模式（Filtering Pattern） ................208
11.2.3 组织数据模式（Data Organization Pattern） .....................210
11.2.4 Join 模式（Join Pattern）......................212
11.3 DAG 计算模型..........................................214
11.3.1 DAG 计算系统的三层结构............................214
11.3.2 Dryad .......................................215
11.3.3 FlumeJava 和Tez ........................................217
参考文献...........................................218
第12 章 流式计算........................................219
12.1 流式计算系统架构....................................222
12.1.1 主从架构............................................222
12.1.2 P2P 架构.....................................................223
12.1.3 Samza 架构..........................................224
12.2 DAG 拓扑结构..........................................224
12.2.1 计算节点.....................................................225
12.2.2 数据流..............................................226
12.2.3 拓扑结构..................................226
12.3 送达保证（Delivery Guarantees）..............................229
12.3.1 Storm 的送达保证机制.................................230
12.3.2 MillWheel 的“恰好送达一次”机制...........................233
12.4 状态持久化...........................................234
12.4.1 容错的三种模式....................................234
12.4.2 Storm 的状态持久化.......................................236
12.4.3 MillWheel 和Samza 的状态持久化......................237
参考文献............................................238
第13 章 交互式数据分析...................................240
13.1 Hive 系数据仓库.................................242
13.1.1 Hive .....................................242
13.1.2 StingerInitiative ................................250
13.2 Shark 系数据仓库..................................251
13.2.1 Shark 架构.........................................252
13.2.2 部分DAG 执行引擎（PDE） ........................253
13.2.3 数据共同分片.........................................254
13.3 Dremel 系数据仓库...................................254
13.3.1 Dremel...........................255
13.3.2 PowerDrill ..........................258
13.3.3 Impala.................................261
13.3.4 Presto...............................264
13.4 混合系数据仓库......................................265
参考文献.................................269
第14 章 图数据库：架构与算法................................271
14.1 在线查询类图数据库...........................272
14.1.1 三层结构.........................272
14.1.2 TAO 图数据库.................................273
14.2 常见图挖掘问题..........................................277
14.2.1 PageRank 计算.......................................278
14.2.2 单源最短路径（Single Source Shortest Path） ..................278
14.2.3 二部图最大匹配.............................279
14.3 离线挖掘数据分片..............................................279
14.3.1 切边法（Edge-Cut）......................................280
14.3.2 切点法（Vertex-Cut）...............................282
14.4 离线挖掘计算模型...................................284
14.4.1 以节点为中心的编程模型..........................284
14.4.2 GAS 编程模型...........................................285
14.4.3 同步执行模型.....................................286
14.4.4 异步执行模型...................................290
14.5 离线挖掘图数据库.................................292
14.5.1 Pregel..........................292
14.5.2 Giraph...............................299
14.5.3 GraphChi ............................301
14.5.4 PowerGraph.......................307
参考文献.......................................311
第15 章 机器学习：范型与架构.........................................313
15.1 分布式机器学习...........................................314
15.1.1 机器学习简介.............................................314
15.1.2 数据并行VS.模型并行.....................................316
15.2 分布式机器学习范型.....................317
15.2.1 三种范型...................................318
15.2.2 MapReduce 迭代计算模型........................319
15.2.3 BSP 计算模型...................................321
15.2.4 SSP 模型............................323
15.3 分布式机器学习架构...................................324
15.3.1 MapReduce 系列..................................325
15.3.2 Spark 及MLBase ..........................................327
15.3.3 参数服务器（Parameter Server）.............332
参考文献................................................335
第16 章 机器学习：分布式算法...............................337
16.1 计算广告：逻辑回归.......................................338
16.1.1 逻辑回归（Logistic Regression，LR）.............................338
16.1.2 并行随机梯度下降（Parallel Stochastic Gradient Descent）............341
16.1.3 批学习并行逻辑回归..................................341
16.2 推荐系统：矩阵分解................................................344
16.2.1 矩阵分解方法.......................................344
16.2.2 ALS-WR 算法............................................346
16.2.3 并行版ALS-WR 算法..............................347
16.3 搜索引擎：机器学习排序................................347
16.3.1 机器学习排序简介.................................348
16.3.2 LambdaMART.................................349
16.3.3 分布式LambdaMART........................................351
16.4 自然语言处理：文档相似性计算.......................................352
16.5 社交挖掘：谱聚类.................................355
16.5.1 社交挖掘实例...............................355
16.5.2 谱聚类....................................356
16.5.3 并行版谱聚类..........................................358
16.6 深度学习：DistBelief .............................................358
16.6.1 深度学习简介........................................359
16.6.2 DistBelief.....................360
参考文献.........................................364
第17 章 增量计算..........................................366
17.1 增量计算模式...........................367
17.1.1 两种计算模式...............................367
17.1.2 Hadoop 平台下增量计算的一般模式.............................368
17.2 Percolator................................370
17.2.1 事务支持..........................................371
17.2.2 “观察/通知”体系结构...........................373
17.3 Kineograph ............................374
17.3.1 整体架构.........................................375
17.3.2 增量计算机制....................................375
17.4 DryadInc ....................................376
参考文献..............................................................377
附录A 硬件体系结构及常用性能指标......................................378
附录B 大数据必读文献....................................380
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据日知录
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>线性代数应该这样学
第1章 向量空间
S1.1 复数
S1.2 向量空间的定义
S1.3 向量空间的性质
S1.4 子空间
S1.5 和与直和
习题
第2章 有限维向量空间
S2.1 张成与线性无关
S2.2 基
S2.3 维数
习题
第3章 线性映射
S3.1 定义与例子
S3.2 零空间与值域
S3.3 线性映射的矩阵
S3.4 可逆性
习题
第4章 多项式
S4.1 次数
S4.2 复系数
S4.3 实系数
习题
第5章 本征值与本征向量
S5.1 不变子空间
S5.2 多项式对算子的作用
S5.3 上三角矩阵
S5.4 对角矩阵
S5.5 实向量空间的不变子空间
习题
第6章 内积空间
S6.1 内积
S6.2 范数
S6.3 规范正交基
S6.4 正交投影与极小化问题
S6.5 线性泛函与伴随
习题
第7章 内积空间上的算子
S7.1 自伴算子与正规算子
S7.2 谱定理
S7.3 实内积空间上的正规算子
S7.4 正算子
S7.5 等距同构
S7.6 极分解与奇异值分解
习题
第8章 复向量空间上的算子
S8.1 广义本征向量
S8.2 特征多项式
S8.3 算子的分解
S8.4 平方根
S8.5 极小多项式
S8.6 约当形
习题
第9章 实向量空间上的算子
S9.1 方阵的本征值
S9.2 分块上三角矩阵
S9.3 特征多项式
习题
第10章 迹与行列式
S10.1 基变换
S10.2 迹
S10.3 算子的行列式
S10.4 矩阵的行列式
S10.5 体积
习题
符号索引
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>线性代数应该这样学
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>线性代数的几何意义
前 言 1
1. 为什么要给出线性代数的几何意义 1
2. 重要的几何直观意义 3
3. 如何使用这本书 4
目 录 6
第1章 什么是线性代数 11
1.1 “代数”的意义 11
1.2 “线性”的意义 14
1.2.1 线性函数的概念 14
1.2.2 线性函数概念的推广 16
1.2.3 多元线性函数的几何意义 17
1.2.4 n维(高维)空间的直观理解 19
1.3 线性映射和线性变换的几何意义 21
1.3.1 线性映射的几何意义 21
1.3.2 线性变换的几何意义 26
1.4 线性代数的故事 29
1.5 线性代数有什么用 32
第2章 向量的基本几何意义 36
2.1 向量概念的几何意义 36
2.1.1 自由向量的概念 36
2.1.2 向量的代数表示 37
2.2 向量加法的几何及物理意义 39
2.3 向量内积的几何和物理意义 42
2.3.1 向量内积的几何解释 42
2.3.2 向量内积的物理解释 44
2.4 向量叉积的几何和物理意义 45
2.4.1 叉积的定义及其几何解释 45
2.4.2 叉积的物理意义 46
2.5 向量混合运算的几何意义 49
2.5.1 向量加法的结合律的几何解释 49
2.5.2 向量数乘的分配律的几何解释 50
2.5.3 向量点积的分配律的几何解释 50
2.5.4 向量叉积的分配律的几何解释 51
2.5.5 向量混合积的几何解释 53
2.6 向量积和张量之间的关系 54
2.6.1 二维向量的内积、外积和张量 55
2.6.2 三维向量的内积、外积和张量 56
2.7 向量除法的几何意义 56
2.8 变向量的几何意义 57
2.8.1 二维变向量的几何图形 57
2.8.2 三维变向量的几何图形 59
2.8.3 变向量的应用 60
2.9 复向量的几何意义 61
2.9.1 向量与复数的关系 61
2.9.2 复向量的几何意义 62
2.10向量和微积分的关系 64
2.10.1 微分的几何意义 64
2.10.2 微元就是向量 64
2.11向量与解析几何的关系 65
第3章 行列式的几何意义 67
3.1 行列式的定义 67
3.2 二阶行列式的几何意义 70
3.2.1 二阶行列式的几何意义 70
3.2.2 二阶行列式性质的几何解释 71
3.3 三阶行列式的几何意义 75
3.3.1 三阶行列式的几何意义 75
3.3.2 三阶行列式性质的几何解释 75
3.4 行列式化为对角形的几何解释 79
3.5 行列式乘积项的几何意义 81
3.5.1 二阶行列式乘积项的几何意义 81
3.5.2 三阶行列式乘积项的几何意义 82
3.5.3 n阶行列式乘积项的几何意义 85
3.6 拉普拉斯展开定理及代数余子式的几何解释 86
3.7 克莱姆法则的几何意义 88
3.7.1 二阶克莱姆法则的几何解释 88
3.7.2 三阶克莱姆法则的几何解释 89
3.8 一类行列式的几何意义 90
3.8.1 最后一列为1的行列式 90
3.8.2 一列为1的行列式的应用 93
第4章 向量组及向量空间的几何意义 94
4.1 向量组的几何意义 94
4.1.1 向量线性表示/组合的几何意义 95
4.1.2 向量组线性相关的几何意义 97
4.1.3 向量组等价的几何解释 99
4.1.4 向量组的秩和极大无关组的几何意义 101
4.1.5 向量组例题的图解 102
4.2 向量空间的几何意义 103
4.2.1 向量张成的空间 105
4.2.2 子空间的几何意义 105
4.2.3 基、维数及其坐标的几何意义 108
4.2.4 基变换的几何意义 111
4.2.5 欧式空间及内积推广 114
4.2.6 标准正交基的几何解释 117
4.2.7 施密特正交化的几何解释 122
第5章 矩阵的几何意义 125
5.1 矩阵的概念及物理意义 125
5.1.1 矩阵是统计数表的例子 126
5.1.2 矩阵是线性函数系数的例子 127
5.2 矩阵加法的几何意义 128
5.3 矩阵与向量乘法的几何意义 129
5.3.1 矩阵与向量的乘积的概念 129
5.3.2 矩阵与向量乘积的几何意义 130
5.4 矩阵与矩阵乘法的几何意义 136
5.4.1 矩阵与矩阵乘法的意义 136
5.4.2 矩阵左乘与右乘的不同 138
5.4.3 矩阵乘幂的几何及物理解释 139
5.5 矩阵与线性变换关系的几何意义 140
5.5.1 线性变换如何用矩阵表示 140
5.5.2 线性变换矩阵定理的几何及物理意义 142
5.5.3 矩阵及其对应线性变换的几何图形 143
5.5.4 初等矩阵/初等变换的几何意义 146
5.6 矩阵乘法运算律的几何意义 153
5.6.1 两个矩阵相乘是两个线性变换的复合 153
5.6.2 矩阵的乘法不满足交换律 154
5.6.3 矩阵的乘法不满足消去律 154
5.7 矩阵秩的几何意义 155
5.7.1 矩阵秩的几何意义 155
5.7.2 矩阵的秩对图形变换的影响 156
5.8 矩阵特征值和特征向量的几何及物理意义 157
5.8.1 特征值和特征向量的几何意义 157
5.8.2 特征值和特征向量的物理意义 160
5.8.3 特征向量空间的几何图景 171
5.8.4 实对称矩阵的特征值和特征向量 174
5.8.5 复数特征值及特征向量的几何意义 176
5.9 矩阵相似的几何意义 178
5.9.1 什么是相似矩阵 178
5.9.2 矩阵相似的几何意义 180
5.9.3 矩阵相似对角化的几何解释 182
5.10矩阵行列式的几何意义 185
5.10.1 二阶矩阵行列式的几何意义 186
5.10.2 矩阵运算的行列式的几何意义 187
5.11雅可比矩阵及其行列式的几何意义 191
5.11.1 雅可比矩阵及其行列式的几何意义 191
5.11.2 雅可比矩阵在二重积分中的应用例子 192
5.12矩阵对平面和空间的旋转变换 195
5.12.1 平面上的旋转变换 195
5.12.2 空间的旋转变换 197
5.13矩阵的等价、相似与合同关系 199
5.13.1 矩阵等价、相似及合同的关系对比 199
5.13.2 等价矩阵几何意义 200
5.13.3 相似与等价矩阵几何意义的对比 202
5.13.4 合同与等价矩阵几何意义的对比 203
5.14其他各类矩阵的几何意义 204
5.14.1 逆矩阵的几何意义 204
5.14.2 转置矩阵的几何意义 206
5.14.3 伴随矩阵的几何意义 213
5.14.4 正交矩阵的几何意义 215
5.14.5 分块矩阵的代数及几何意义 218
5.14.6 三角矩阵几何意义 221
5.14.7 对角矩阵的几何意义 223
5.14.8 平移矩阵的几何意义 224
5.14.9 复数的矩阵表示 226
第6章 线性方程组的几何意义 229
6.1 两种线性方程组表示形式的几何意义 229
6.2 高斯消元法的几何解释 230
6.3 线性方程组的秩及解的关系的几何意义 233
6.3.1 二元线性方程组的秩及解的图形 233
6.3.2 三元线性方程组的秩及解的图形 236
6.4 线性方程组有解判别定理的几何解释 240
6.5 线性方程组解结构的几何意义 242
6.5.1 线性方程组解的代数形式 242
6.5.2 齐次线性方程组的解空间 245
6.5.3 非齐次线性方程组的解结构 246
6.5.4 非齐次线性方程组的例解 247
6.6 数域上的线性方程组（或向量空间）的意义 249
6.7 超定方程组的最小二乘解的几何解释 250
6.7.1 最小二乘法的向量解的几何意义 250
6.7.2 一般最小二乘解的公式推导 251
6.7.3 最小二乘解的例析 251
6.8 方程组和矩阵、向量组的关系 252
6.8.1 线性方程组与矩阵乘法的运算关系 253
6.8.2 线性方程组、矩阵、向量组的关系 254
6.8.3 秩的关系 254
第7章 二次型的几何意义 256
7.1 二次曲线及曲面的图形 257
7.1.1 二次函数的哪些系数对图形是重要的 257
7.1.2 二次函数与二次方程的关系 259
7.1.3 圆锥曲线的向量方程 261
7.2 二次型及其几何意义 262
7.2.1 二次型的定义 262
7.2.2 二次型的几何及物理意义 263
7.2.3 二次型函数与双线性函数的关系 265
7.3 二次型合同对角化的几何意义 267
7.3.1 二次型对角化之正交变换 268
7.3.2 其他二次型对角化的方法 270
7.4 惯性定理的几何及物理意义 272
7.5 二次型正定性的几何意义 273
7.5.1 二次型正定性的几何意义 274
7.5.2 二次型正定性判别法的直观理解 275
7.6 二次型的分类与二次曲面的分类 276
附录 线性代数简史和名师学习指点 280
1. 线性代数主要内容及其发展简史 280
2. 怎样学习线性代数 283
主要参考文献 289
后 记 290
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>线性代数的几何意义
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式分类
出版者的话
专家指导委员会
译者序
前言
第1章 绪论
1.1 机器感知
1.2 一个例子
1.3 模式识别系统
1.4 设计循环
1.5 学习和适应
1.6 本章小结
全书各章概要
文献和历史评述
参考文献
第2章 贝叶斯决策论
2.1 引言
2.2 贝叶斯决策论——连续特征
2.3 最小误差率分类
2.4 分类器、判别函数及判定面
2.5 正态密度
2.6 正态分布的判别函数
2.7 误差概率和误差积分
2.8 正态密度的误差上界
2.9 贝叶斯决策论——离散特征
2.10 丢失特征和噪声特征
2.11 贝叶斯置信网
2.12 复合贝叶斯决策论及上下文
本章小结
文献和历史评述
习题
上机练习
参考文献
第3章 最大似然估计和贝叶斯参数估计
第4章 非参数技术
第5章 线性判别函数
第6章 多层神经网络
第7章 随机方法
第8章 非度量方法
第9章 独立于算法的机器学习
第10章 无监督学习和聚类
附录A 数学基础
参考文献
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式分类
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Tensorflow：实战Google深度学习框架
第1章 深度学习简介 1
1.1 人工智能、机器学习与深度学习 2
1.2 深度学习的发展历程 7
1.3 深度学习的应用 10
1.3.1 计算机视觉 10
1.3.2 语音识别 14
1.3.3 自然语言处理 15
1.3.4 人机博弈 18
1.4 深度学习工具介绍和对比 19
小结 23
第2章 TensorFlow环境搭建 25
2.1 TensorFlow的主要依赖包 25
2.1.1 Protocol Buffer 25
2.1.2 Bazel 27
2.2 TensorFlow安装 29
2.2.1 使用Docker安装 30
2.2.2 使用pip安装 32
2.2.3 从源代码编译安装 33
2.3 TensorFlow测试样例 37
小结 38
第3章 TensorFlow入门 40
3.1 TensorFlow计算模型——计算图 40
3.1.1 计算图的概念 40
3.1.2 计算图的使用 41
3.2 TensorFlow数据模型——张量 43
3.2.1 张量的概念 43
3.2.2 张量的使用 45
3.3 TensorFlow运行模型——会话 46
3.4 TensorFlow实现神经网络 48
3.4.1 TensorFlow游乐场及神经网络简介 48
3.4.2 前向传播算法简介 51
3.4.3 神经网络参数与TensorFlow变量 54
3.4.4 通过TensorFlow训练神经网络模型 58
3.4.5 完整神经网络样例程序 62
小结 65
第4章 深层神经网络 66
4.1 深度学习与深层神经网络 66
4.1.1 线性模型的局限性 67
4.1.2 激活函数实现去线性化 70
4.1.3 多层网络解决异或运算 73
4.2 损失函数定义 74
4.2.1 经典损失函数 75
4.2.2 自定义损失函数 79
4.3 神经网络优化算法 81
4.4 神经网络进一步优化 84
4.4.1 学习率的设置 85
4.4.2 过拟合问题 87
4.4.3 滑动平均模型 90
小结 92
第5章 MNIST数字识别问题 94
5.1 MNIST数据处理 94
5.2 神经网络模型训练及不同模型结果对比 97
5.2.1 TensorFlow训练神经网络 97
5.2.2 使用验证数据集判断模型效果 102
5.2.3 不同模型效果比较 103
5.3 变量管理 107
5.4 TensorFlow模型持久化 112
5.4.1 持久化代码实现 112
5.4.2 持久化原理及数据格式 117
5.5 TensorFlow最佳实践样例程序 126
小结 132
第6章 图像识别与卷积神经网络 134
6.1 图像识别问题简介及经典数据集 135
6.2 卷积神经网络简介 139
6.3 卷积神经网络常用结构 142
6.3.1 卷积层 142
6.3.2 池化层 147
6.4 经典卷积网络模型 149
6.4.1 LeNet-5模型 150
6.4.2 Inception-v3模型 156
6.5 卷积神经网络迁移学习 160
6.5.1 迁移学习介绍 160
6.5.2 TensorFlow实现迁移学习 161
小结 169
第7章 图像数据处理 170
7.1 TFRecord输入数据格式 170
7.1.1 TFRecord格式介绍 171
7.1.2 TFRecord样例程序 171
7.2 图像数据处理 173
7.2.1 TensorFlow图像处理函数 174
7.2.2 图像预处理完整样例 183
7.3 多线程输入数据处理框架 185
7.3.1 队列与多线程 186
7.3.2 输入文件队列 190
7.3.3 组合训练数据（batching） 193
7.3.4 输入数据处理框架 196
小结 198
第8章 循环神经网络 200
8.1 循环神经网络简介 200
8.2 长短时记忆网络（LTSM）结构 206
8.3 循环神经网络的变种 212
8.3.1 双向循环神经网络和深层循环神经网络 212
8.3.2 循环神经网络的dropout 214
8.4 循环神经网络样例应用 215
8.4.1 自然语言建模 216
8.4.2 时间序列预测 225
小结 230
第9章 TensorBoard可视化 232
9.1 TensorBoard简介 232
9.2 TensorFlow计算图可视化 234
9.2.1 命名空间与TensorBoard图上节点 234
9.2.2 节点信息 241
9.3 监控指标可视化 246
小结 252
第10章 TensorFlow计算加速 253
10.1 TensorFlow使用GPU 253
10.2 深度学习训练并行模式 258
10.3 多GPU并行 261
10.4 分布式TensorFlow 268
10.4.1 分布式TensorFlow原理 269
10.4.2 分布式TensorFlow模型训练 272
10.4.3 使用Caicloud运行分布式TensorFlow 282
小结 287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Tensorflow：实战Google深度学习框架
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据分析与挖掘实战
前言
基础篇
第1章　数据挖掘基础2
1.1　某知名连锁餐饮企业的困惑2
1.2　从餐饮服务到数据挖掘3
1.3　数据挖掘的基本任务4
1.4　数据挖掘建模过程4
1.4.1　定义挖掘目标4
1.4.2　数据取样5
1.4.3　数据探索6
1.4.4　数据预处理7
1.4.5　挖掘建模7
1.4.6　模型评价7
1.5　常用的数据挖掘建模工具7
1.6　小结9
第2章　Python数据分析简介10
2.1　搭建Python开发平台12
2.1.1　所要考虑的问题12
2.1.2　基础平台的搭建12
2.2　Python使用入门13
2.2.1　运行方式14
2.2.2　基本命令15
2.2.3　数据结构17
2.2.4　库的导入与添加20
2.3　Python数据分析工具22
2.3.1　Numpy23
2.3.2　Scipy24
2.3.3　Matplotlib24
2.3.4　Pandas26
2.3.5　StatsModels27
2.3.6　Scikit-Learn28
2.3.7　Keras29
2.3.8　Gensim30
2.4　配套资源使用设置31
2.5　小结32
第3章　数据探索33
3.1　数据质量分析33
3.1.1　缺失值分析34
3.1.2　异常值分析34
3.1.3　一致性分析37
3.2　数据特征分析37
3.2.1　分布分析37
3.2.2　对比分析40
3.2.3　统计量分析41
3.2.4　周期性分析44
3.2.5　贡献度分析45
3.2.6　相关性分析47
3.3　Python主要数据探索函数50
3.3.1　基本统计特征函数50
3.3.2　拓展统计特征函数53
3.3.3　统计作图函数54
3.4　小结59
第4章　数据预处理60
4.1　数据清洗60
4.1.1　缺失值处理60
4.1.2　异常值处理64
4.2　数据集成64
4.2.1　实体识别64
4.2.2　冗余属性识别65
4.3　数据变换65
4.3.1　简单函数变换65
4.3.2　规范化66
4.3.3　连续属性离散化68
4.3.4　属性构造70
4.3.5　小波变换71
4.4　数据规约74
4.4.1　属性规约74
4.4.2　数值规约77
4.5　Python主要数据预处理函数80
4.6　小结81
第5章　挖掘建模83
5.1　分类与预测83
5.1.1　实现过程83
5.1.2　常用的分类与预测算法84
5.1.3　回归分析85
5.1.4　决策树89
5.1.5　人工神经网络95
5.1.6　分类与预测算法评价100
5.1.7　Python分类预测模型特点103
5.2　聚类分析104
5.2.1　常用聚类分析算法104
5.2.2　K-Means聚类算法105
5.2.3　聚类分析算法评价111
5.2.4　Python主要聚类分析算法111
5.3　关联规则113
5.3.1　常用关联规则算法114
5.3.2　Apriori算法114
5.4　时序模式119
5.4.1　时间序列算法120
5.4.2　时间序列的预处理120
5.4.3　平稳时间序列分析122
5.4.4　非平稳时间序列分析124
5.4.5　Python主要时序模式算法132
5.5　离群点检测134
5.5.1　离群点检测方法135
5.5.2　基于模型的离群点检测方法136
5.5.3　基于聚类的离群点检测方法138
5.6　小结141
实战篇
第6章　电力窃漏电用户自动识别144
6.1　背景与挖掘目标144
6.2　分析方法与过程147
6.2.1　数据抽取148
6.2.2　数据探索分析148
6.2.3　数据预处理151
6.2.4　构建专家样本156
6.2.5　模型构建157
6.3　上机实验161
6.4　拓展思考162
6.5　小结163
第7章　航空公司客户价值分析164
7.1　背景与挖掘目标164
7.2　分析方法与过程166
7.2.1　数据抽取168
7.2.2　数据探索分析168
7.2.3　数据预处理169
7.2.4　模型构建173
7.3　上机实验177
7.4　拓展思考178
7.5　小结179
第8章　中医证型关联规则挖掘180
8.1　背景与挖掘目标180
8.2　分析方法与过程181
8.2.1　数据获取183
8.2.2　数据预处理186
8.2.3　模型构建190
8.3　上机实验193
8.4　拓展思考194
8.5　小结194
第9章　基于水色图像的水质评价195
9.1　背景与挖掘目标195
9.2　分析方法与过程195
9.2.1　数据预处理197
9.2.2　模型构建199
9.2.3　水质评价201
9.3　上机实验202
9.4　拓展思考202
9.5　小结203
第10章　家用电器用户行为分析与事件识别204
10.1　背景与挖掘目标204
10.2　分析方法与过程205
10.2.1　数据抽取206
10.2.2　数据探索分析207
10.2.3　数据预处理207
10.2.4　模型构建217
10.2.5　模型检验219
10.3　上机实验220
10.4　拓展思考221
10.5　小结222
第11章　应用系统负载分析与磁盘容量预测223
11.1　背景与挖掘目标223
11.2　分析方法与过程225
11.2.1　数据抽取226
11.2.2　数据探索分析226
11.2.3　数据预处理227
11.2.4　模型构建229
11.3　上机实验235
11.4　拓展思考236
11.5　小结237
第12章　电子商务网站用户行为分析及服务推荐238
12.1　背景与挖掘目标238
12.2　分析方法与过程240
12.2.1　数据抽取242
12.2.2　数据探索分析244
12.2.3　数据预处理251
12.2.4　模型构建256
12.3　上机实验266
12.4　拓展思考267
12.5　小结269
第13章　财政收入影响因素分析及预测模型270
13.1　背景与挖掘目标270
13.2　分析方法与过程272
13.2.1　灰色预测与神经网络的组合模型273
13.2.2　数据探索分析274
13.2.3　模型构建277
13.3　上机实验294
13.4　拓展思考295
13.5　小结296
第14章　基于基站定位数据的商圈分析297
14.1　背景与挖掘目标297
14.2　分析方法与过程299
14.2.1　数据抽取299
14.2.2　数据探索分析299
14.2.3　数据预处理301
14.2.4　模型构建304
14.3　上机实验308
14.4　拓展思考309
14.5　小结309
第15章　电商产品评论数据情感分析310
15.1　背景与挖掘目标310
15.2　分析方法与过程310
15.2.1　评论数据采集311
15.2.2　评论预处理314
15.2.3　文本评论分词320
15.2.4　模型构建320
15.3　上机实验333
15.4　拓展思考334
15.5　小结335
参考文献336
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据分析与挖掘实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络设计
第1章 绪论
1．1 目的
1．2 历史
1．3 应用
1．4 生物学的启示
参考文献
第2章 神经元模型和网络结构
2．1 目的
2．1　理论和实例
2．2．1 符号
2．2．2　神经元模型
2．2．3 网络结构
2．3 小结
2．4 例题
2．5 结束语
习题
第3章 一个说明性实例
3．1 目的
3．2　理论和实例
3．2．1 问题描述
.3．2．2 感知机
3．2．3 hamming网络
3．2．4 hopfield网络
3．3 结束语
习题
第4章 感知机学习规则
4．1 目的
4. 2 理论和实例
4．2．1 学习规则
4．2．2 感知机的结构
4．2．3 感知机学习规则
4．2．4 收敛性证明
4．3 小结
4．4 例题
4．5 结束语
参考文献
习题
第5章 信号和权值向量空间
5．1 目的
5．2 理论和实例
5．2．1 线性向量空间
5．2．2 线性无关
5．2．3 生成空间
5．2．4 内积
5．2．5 范数
5．2．6 正交性
5．2．7 向量展开式
5．3 小结
5．4 例题
5．5 结束语
参考文献
习题
第6章 神经网络中的线性变换
6. 1 目的
6．2 理论和实例
6．2．1 线性变换
6．2．2 矩阵表示
6．2. 3 基变换
6．2. 4 特征值和特征向量
6．3 小结
6．4 例题
6．5 结束语
参考文献
习题
第7章 有监督的hebb学习
7．1 目的
7．2 理论和实例
7．2．1 线性联想器
7．2．2 hebb规则
7．2．3 仿逆规则
7．2．4 应用
7．2．5 hebb学习的变形
7．3 小结
7．4 例题
7．5 结束语
参考文献
习题
第8章 性能曲面和最优点
8．1 目的
8．2 理论和实例
8．2．1 泰勒级数
8．2．2 方向导数
8．2．3 极小点
8．2．4 优化的必要条件
8．2．5 二次函数
8．3 小结
8．4 例题
8．5 结束语
参考文献
习题
第9章 性能优化
9．1 目的
9．2 理论和实例
9．2．1 最速下降法
9．2．2 牛顿法
9．2．3 共扼梯度法
9．3 小结
9．4 例题
9．5 结束语
参考文献
习题
第10章 widrow-hoff学习算法
10．1 目的
10．2 理论和实例
10．2．1 adaline网络
10．2．2 均方误差
10．2．3 lms算法
10．2．4 收敛性分析
10．2．5 自适应滤波
10．3 小结
10．4 例题
10．5 结束语
参考文献
习题
第11章 反向传播
11．1 目的
11．2 理论和实例
11．2．1 多层感知机
11．2．2 反向传播算法
11．2．3 例子
11．2．4 反向传播
11．3 小结
11．4 例题
11．5 结束语
参考文献
习题
第12章 反向传播算法的变形
12．1 目的
12．2 理论和实例
12．2．1 bp算法的缺点
12．2．2 bp算法的启发式改进
12．2．3 数值优化技术
12．3 小结
12．4 例题
12．5 结束语
参考文献
习题
第13章 联想学习
13．1 目的
13．2 理论和实例
13．2．1 简单联想网络
13．2．2 无监督的hebb规则
13．2．3 简单的识别网络
13．2．4 instar规则
13．2．5 简单回忆网络
13．2．6 outstar规则
13．3 小结
13．4 例题
13．5 结束语
参考文献
习题
第14章 竞争网络
14．1 目的
14．2 理论和实例
14．2．1 hamming网络
14．2．2 竞争层
14．2．3 生物学意义上的竞争层
14．2．4 自组织特征图
14．2．5 学习向量量化
14．3 小结
14．4 例题
14．5 结束语
参考文献
习题
第15章 grossberg网络
15．1 目的
15．2 理论和实例
15. 2．1 生物学的启发：视觉
15．2．2 基本非线性模型
15．2．3 两层竞争网络
15．2．4 与kohonen规则的关系
15．3 小结
15．4 例题
15．5 结束语
参考文献
习题
第16章 自适应谐振理论
16．1 目的
16. 2 理论和实例
16．2．1 自适应谐振概述
16．2．2 第一层
16．2．3 第二层
16．2．4 调整子系统
16．2．5 学习规则：l1-l2
16．2．6 学习规则：l2-l1
16．2．7 art1算法小结
16．2．8 其他art体系结构
16．3 小结
16．4 例题
16．5 结束语
参考文献
习题
第17章 稳定性
17．1 目的
17．2 理论和实例
17．2．1 递归网络
17．2．2 稳定性概念
17．2．3 lyapunov稳定性定理
17．2．4 单摆例子
17．2．5 lasdlle不变性定理
17．3 小结
17．4 例题
17．5 结束语
参考文献
习题
第18章 hopfield网络
18．1 目的
18．2 理论和实例
18．2．1 hopfield模型
18．2．2 lyapunov函数
18．2．3 增益效应
18．2．4 hopfield网络设计
18．3 小结
18. 4 例题
18．5 结束语
参考文献
习题
第19章 结束语
19．1 目的
19．2 理论和实例
19．2．1 前馈和联想网络
19．2．2 竞争网络
19。2．3 动态联想存储器网络
19．2．4 神经网络的经典基础
19．2．5 参考书目和杂志
19．3 结束语
参考文献
附录a 文献目录
附录b 符号
附录c 软件
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络设计
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计自然语言处理（第2版）
第1章 绪论
1.1 基本概念
1.1.1 语言学与语音学
1.1.2 自然语言处理
1.1.3 关于“理解”的标准
1.2 自然语言处理研究的内容和面临的困难
1.2.1 自然语言处理研究的内容
1.2.2 自然语言处理涉及的几个层次
1.2.3 自然语言处理面临的困难
1.3 自然语言处理的基本方法及其发展
1.3.1 自然语言处理的基本方法
1.3.2 自然语言处理的发展
1.4 自然语言处理的研究现状
1.5 本书的内容安排
第2章 预备知识
2.1 概率论基本概念
2.1.1 概率
2.1.2 最大似然估计
2.1.3 条件概率
2.1.4 贝叶斯法则
2.1.5 随机变量
2.1.6 二项式分布
2.1.7 联合概率分布和条件概率分布
2.1.8 贝叶斯决策理论
2.1.9 期望和方差
2.2 信息论基本概念
2.2.1 熵
2.2.2 联合熵和条件熵
2.2.3 互信息
2.2.4 相对熵
2.2.5 交叉熵
2.2.6 困惑度
2.2.7 噪声信道模型
2.3 支持向量机
2.3.1 线性分类
2.3.2 线性不可分
2.3.3 构造核函数
第3章 形式语言与自动机
3.1 基本概念
3.1.1 图
3.1.2 树
3.1.3 字符串
3.2 形式语言
3.2.1 概述
3.2.2 形式语法的定义
3.2.3 形式语法的类型
3.2.4 CFG识别句子的派生树表示
3.3 自动机理论
3.3.1 有限自动机
3.3.2 正则文法与自动机的关系
3.3.3 上下文无关文法与下推自动机
3.3.4 图灵机
3.3.5 线性界限自动机
3.4 自动机在自然语言处理中的应用
3.4.1 单词拼写检查
3.4.2 单词形态分析
3.4.3 词性消歧
第4章 语料库与语言知识库
4.1 语料库技术
4.1.1 概述
4.1.2 语料库语言学的发展
4.1.3 语料库的类型
4.1.4 汉语语料库建设中的问题
4.1.5 典型语料库介绍
……
第5章 语言模型
第6章 概率图模型
第7章 自动分词、命名实体识别与词性标注
第8章 句法分析
第9章 语义分析
第10章 篇章分析
第11章 统计机器翻译
第12章 语音翻译
第13章 文本分类与情感分类
第14章 信息检索与问答系统
第15章 自动文摘与信息抽取
第16章 口语信息处理与人机对话系统
参考文献
自然语言处理及其相关领域的国际会议
名词术语索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计自然语言处理（第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习基础
第一章  绪论
第二章  有指导学习概述
第三章  回归的线性方法
第四章  分类的线性方法
第五章  基展开与正则化
第六章  核方法
第七章  模型评估与选择
第八章  模型推理和平均
第九章  加法模型、树和相关方法
第十章  提升和加法树
第十一章  神经网络
第十二章  支持向量机和柔性判别
第十三章  原型方法和最近邻
第十四章  无指导学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习基础
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>信息论、推理与学习算法
前言
译者序
序言
第1章 信息论导论
第2章 概率、熵与推理
第3章 有关推理的更多内容
第一部分 数据压缩
第4章 信源编码定理
第5章 符号码
第6章 符号流码
第7章 整数的码
第二部分 噪声信道编码
第8章 相关随机变量
第9章 噪声信道上的通信
第10章 噪声信道编码定理
第11章 纠错码与实际信道
第三部分 信息论中的更多专题
第12章 散列码：用于有效信息检索的码
第13章 二进制码
第14章 存在很好的线性码
第15章 有关信息论的更多习题
第16章 消息传递
第17章 受限无噪信道上的通信
第18章 纵横字谜与密码破译
第19章 为何有性?信息获取与进化
第四部分 概率与推理
第20章 一个推理任务示例：聚类
第2l章 基于完全枚举的精确推理
第22章 最大似然与聚类
第23章 有用的概率分布
第24章 精确边缘化
第25章 网格中的精确边缘化
第26章 图中的精确边缘化
第27章 拉普拉斯方法
第28章 模型比较与奥卡姆剃刀原理
第29章 蒙特卡罗方法
第30章 有效的蒙特卡罗方法
第31章 伊辛模型
第32章 精确蒙特卡罗采样
第33章 变参法
第34章 独立元素分析与隐含变量建模
第35章 有关随机推理的专题
第36章 决策论
第37章 贝叶斯推理与抽样理论
第五部分 神经网络
第38章 神经网络引言
第39章 单神经元分类器
第40章 单神经元的容量
第41章 以学习作推理
第42章 HopfieId网络
第43章 玻耳兹曼机
第44章 多层网络的有监督学习
第45章 高斯过程
第46章 反卷积
第六部分 稀疏图码
第47章 低密度奇偶校验码
第48章 卷积码与Turbo码
第49章 重复累加码
第50章 数字喷泉码
第七部分 附录
附录A 记号
附录B 一些物理知识
附录C 一些数学知识
英汉词汇表
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>信息论、推理与学习算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
第Ⅰ部分人工智能
第1章绪论
1.1什么是人工智能
1.2人工智能的基础
1.3人工智能的历史
1.4最新发展水平
1.5本章小结
参考文献与历史注释
习题
第2章智能Agent
2.1Agent和环境
2.2好的行为：理性的概念
2.3环境的性质
2.4Agent的结构
2.5本章小结
参考文献与历史注释
习题
第Ⅱ部分问题求解
第3章通过搜索进行问题求解
3.1问题求解Agent
3.2问题实例
3.3通过搜索求解
3.4无信息搜索策略
3.5有信息（启发式）的搜索策略
3.6启发式函数
3.7本章小结
参考文献与历史注释
习题
第4章超越经典搜索
4.1局部搜索算法和最优化问题
4.2连续空间中的局部搜索
4.3使用不确定动作的搜索
4.4使用部分可观察信息的搜索
4.5联机搜索Agent和未知环境
4.6本章小结
参考文献与历史注释
习题
第5章对抗搜索
5.1博弈
5.2博弈中的优化决策
5.3α—β剪枝
5.4不完美的实时决策
5.5随机博弈
5.6部分可观察的博弈
5.7博弈程序发展现状
5.8其他途径
5.9本章小结
参考文献与历史注释
习题
第6章约束满足问题
6.1定义约束满足问题
6.2约束传播：CSP中的推理
6.3CSP的回溯搜索
6.4CSP局部搜索
6.5问题的结构
6.6本章小结
参考文献与历史注释
习题
第Ⅲ部分知识、推理与规划
第7章逻辑Agent
7.1基于知识的Agent
7.2Wumpus世界
7.3逻辑
7.4命题逻辑：一种简单逻辑
7.5命题逻辑定理证明
7.6有效的命题逻辑模型检验
7.7基于命题逻辑的Agent
7.8本章小结
参考文献与历史注释
习题
第8章一阶逻辑
8.1重温表示
8.2一阶逻辑的语法和语义
8.3运用一阶逻辑
8.4一阶逻辑的知识工程
8.5本章小结
参考文献与历史注释
习题
第9章一阶逻辑的推理
9.1命题推理与一阶推理
9.2合一和提升
9.3前向链接
9.4反向链接
9.5归结
9.6本章小结
参考文献与历史注释
习题
第10章经典规划
10.1经典规划的定义
10.2状态空间搜索规划算法
10.3规划图
10.4其他经典规划方法
10.5规划方法分析
10.6本章小结
参考文献与历史注释
习题
第11章现实世界的规划与行动
11.1时间、调度和资源
11.2分层规划
11.3非确定性领域中的规划与行动
11.4多Agent规划
11.5本章小结
参考文献与历史注释
习题
第12章知识表示
12.1本体论工程
12.2类别和对象
12.3事件
12.4精神事件和精神对象
12.5类别的推理系统
12.6缺省信息推理
12.7互联网购物世界
12.8本章小结
参考文献与历史注释
习题
……
第Ⅳ部分不确定知识与推理
第Ⅴ部分学习
第Ⅵ部分通讯、感知与行动
第Ⅶ部分结论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>心智社会
赞　誉
第1章　引言　/ 1
1.1　思维智能体　/ 2
1.2　思维与脑　/ 4
1.3　心智社会　/ 5
1.4　积木的世界　/ 7
1.5　常识　/ 8
1.6　智能体和智能组　/ 9
第2章　整体和部分　/ 12
2.1　组件和联结　/ 13
2.2　创新者与简化者　/ 14
2.3　部分与整体　/ 15
2.4　整体论与部分　/ 16
2.5　容易和困难的事　/ 18
2.6　人类是机器吗　/ 19
第3章　冲突与妥协　/ 21
3.1　冲突　/ 22
3.2　无法妥协　/ 23
3.3　等级　/ 24
3.4　异层级结构　/ 26
3.5　破坏　/ 27
3.6　疼痛和愉悦带来的简化　/ 28
第4章　自我　/ 30
4.1　自我　/ 31
4.2　一个自我还是很多个自我？　/ 32
4.3　灵魂　/ 33
4.4　保守的自我　/ 34
4.5　利用　/ 35
4.6　自我控制　/ 36
4.7　长期计划　/ 38
4.8　理想　/ 39
第5章　个体性　/ 41
5.1　循环因果　/ 42
5.2　无法回答的问题　/ 43
5.3　自我遥控　/ 44
5.4　个人身份　/ 46
5.5　潮流与风格　/ 47
5.6　性格特征　/ 48
5.7　永久身份　/ 50
第6章　洞察与内省　/ 52
6.1　意识　/ 53
6.2　信号与迹象　/ 54
6.3　思维实验　/ 55
6.4　B-脑　/ 56
6.5　被冻结的反思　/ 58
6.6　短暂的思维时间　/ 59
6.7　随意的现在　/ 61
6.8　不用想的思考　/ 62
6.9　云雾中的头脑　/ 63
6.10　没有思维的世界　/ 64
6.11　洞察　/ 66
6.12　内部沟通　/ 67
6.13　自我知识很危险　/ 68
6.14　困惑　/ 69
第7章　问题与目标　/ 71
7.1　智能　/ 72
7.2　不平常的知识　/ 73
7.3　猜谜原则　/ 74
7.4　问题解决　/ 75
7.5　学习与记忆　/ 77
7.6　强化与奖励　/ 78
7.7　本地责任　/ 80
7.8　差异发动机　/ 81
7.9　意图　/ 83
7.10　天才　/ 84
第8章　记忆理论　/ 86
8.1　K线：一种记忆理论　/ 87
8.2　记住　/ 88
8.3　思维状态与倾向　/ 89
8.4　局部思维状态　/ 91
8.5　水平带　/ 92
8.6　水平　/ 94
8.7　边缘　/ 95
8.8　记忆社会　/ 97
8.9　知识树　/ 98
8.10　水平与分类　/ 99
8.11　社会的层次　/ 101
第9章　总结　/ 103
9.1　想要和喜欢　/ 104
9.2　重新划分选区　/ 105
9.3　从失败中学习　/ 106
9.4　享受不舒服　/ 108
第10章　派珀特原则　/ 110
10.1　皮亚杰的实验　/ 111
10.2　关于数量的推理　/ 112
10.3　优先选择　/ 113
10.4　派珀特原则　/ 115
10.5　更社会　/ 116
10.6　关于皮亚杰的实验　/ 117
10.7　概念的概念　/ 119
10.8　教育和发展　/ 120
10.9　学习一种等级制度　/ 121
第11章　空间的形状　/ 123
11.1　看见红色　/ 124
11.2　空间的形状　/ 125
11.3　邻近　/ 126
11.4　天生的地形　/ 127
11.5　感知相似性　/ 129
11.6　居中的自我　/ 130
11.7　注定的学习　/ 131
11.8　半脑　/ 132
11.9　哑铃理论　/ 134
第12章　学习意义　/ 136
12.1　一个积木拱门场景　/ 137
12.2　学习意义　/ 138
12.3　统一框架　/ 139
12.4　结构与功能　/ 141
12.5　结构的功能　/ 142
12.6　积累　/ 143
12.7　积累策略　/ 145
12.8　不统一的问题　/ 146
12.9　例外原则　/ 147
12.10　塔的工作原理　/ 149
12.11　原因如何起作用　/ 150
12.12　意义与定义　/ 152
12.13　桥梁定义　/ 153
第13章　看见与相信　/ 155
13.1　重新构想　/ 156
13.2　边界　/ 157
13.3　看见与相信　/ 158
13.4　儿童的绘画框架　/ 159
13.5　学习脚本　/ 161
13.6　边界效应　/ 162
13.7　副本　/ 163
第14章　重新构想　/ 165
14.1　运用重新构想　/ 166
14.2　主体-支撑概念　/ 167
14.3　方法和目的　/ 168
14.4　看见正方形　/ 170
14.5　头脑风暴　/ 171
14.6　投资原则　/ 172
14.7　组件与整体论　/ 173
14.8　消极思维的力量　/ 175
14.9　相互作用-正方形　/ 176
第15章　意识与记忆　/ 178
15.1　记忆思维状态　/ 179
15.2　自我检查　/ 180
15.3　记忆　/ 181
15.4　关于记忆的记忆　/ 182
15.5　固有幻觉　/ 184
15.6　多种记忆　/ 185
15.7　记忆重新排列　/ 187
15.8　记忆的解剖结构　/ 188
15.9　干扰与恢复　/ 189
15.10　失去条理　/ 190
15.11　递归原则　/ 192
第16章　情感　/ 194
16.1　情感　/ 195
16.2　思维发展　/ 196
16.3　思维原型专家　/ 197
16.4　交互排斥　/ 199
16.5　雪崩效应　/ 200
16.6　动机　/ 201
16.7　利用　/ 202
16.8　刺激与朿激　/ 204
16.9　婴儿情感　/ 205
16.10　成人情感　/ 207
第17章　发展　/ 209
17.1　自我教育的顺序　/ 210
17.2　依恋学习　/ 211
17.3　依恋简化　/ 212
17.4　功能性自治　/ 214
17.5　发展阶段　/ 215
17.6　发展的先决条件　/ 216
17.7　遗传时间表　/ 218
17.8　依恋影像　/ 219
17.9　不同的记忆跨度　/ 220
17.10　智能创伤　/ 222
17.11　智能理想　/ 223
第18章　推理　/ 226
18.1　机器一定要有逻辑吗　/ 227
18.2　推理的链条　/ 228
18.3　链接　/ 229
18.4　逻辑链条　/ 230
18.5　强有力的论证　/ 232
18.6　从多少到大小　/ 233
18.7　数字是什么　/ 234
18.8　数学变得更难了　/ 236
18.9　强韧与恢复　/ 237
第19章　词汇和理念　/ 239
19.1　意图的根源　/ 240
19.2　语言智能组　/ 241
19.3　词汇与理念　/ 242
19.4　客体与属性　/ 244
19.5　多忆体　/ 245
19.6　识别器　/ 247
19.7　权衡证据　/ 248
19.8　泛化　/ 249
19.9　识别思维　/ 250
19.10　封闭圆环　/ 252
第20章　背景与意义不明确　/ 254
20.1　意义模糊　/ 255
20.2　处理意义模糊　/ 256
20.3　视觉上的意义模糊　/ 257
20.4　锁定与清除　/ 258
20.5　微忆体　/ 259
20.6　忆体的螺旋　/ 261
20.7　联结　/ 262
20.8　联结线　/ 263
20.9　分布式记忆　/ 265
第21章　Trans-框架　/ 267
21.1　思维的代词　/ 268
21.2　代原体　/ 269
21.3　Trans-框架　/ 270
21.4　智能体之间的沟通　/ 272
21.5　自动性　/ 273
21.6　Trans-框架代原体　/ 275
21.7　用代原体泛化　/ 276
21.8　注意力　/ 277
第22章　表达　/ 279
22.1　代原体和多忆体　/ 280
22.2　独原体　/ 281
22.3　去专门化　/ 282
22.4　学习与教学　/ 283
22.5　推理　/ 284
22.6　表达　/ 286
22.7　原因与从句　/ 287
22.8　干扰　/ 289
22.9　代词和指代　/ 291
22.10　语言表达　/ 292
22.11　创造性表达　/ 294
第23章　对比　/ 296
23.1　差异的世界　/ 297
23.2　差异与副本　/ 298
23.3　时间闪烁　/ 299
23.4　“更”的意义　/ 301
23.5　外国口音　/ 302
第24章　框架　/ 304
24.1　思维的速度　/ 305
24.2　思维框架　/ 306
24.3　Trans-框架的工作原理　/ 307
24.4　默认假设　/ 309
24.5　非言语推理　/ 310
24.6　方向忆体　/ 311
24.7　图片-框架　/ 313
24.8　图片-框架的工作原理　/ 314
24.9　识别与记忆　/ 315
第25章　框架编队　/ 317
25.1　一次一个框架？　/ 318
25.2　框架编队　/ 319
25.3　静止的世界　/ 320
25.4　连续感　/ 322
25.5　预期　/ 323
25.6　框架理念　/ 325
第26章　语言框架　/ 327
26.1　理解语言　/ 328
26.2　理解故事　/ 329
26.3　句子-框架　/ 330
26.4　聚会-框架　/ 332
26.5　故事-框架　/ 333
26.6　真正的句子与胡话　/ 334
26.7　名词的框架　/ 336
26.8　动词的框架　/ 338
26.9　语言与视觉　/ 339
26.10　学习语言　/ 340
26.11　语法　/ 342
26.12　出言有序　/ 343
第27章　审查员和玩笑　/ 345
27.1　恶魔　/ 346
27.2　抑制器　/ 347
27.3　审查员　/ 349
27.4　逻辑中的例外　/ 350
27.5　笑话　/ 352
27.6　幽默和审查制度　/ 353
27.7　笑　/ 355
27.8　好心情　/ 357
第28章　思维和世界　/ 359
28.1　心理能量的谬误　/ 360
28.2　量与市场　/ 361
28.3　数量和属性　/ 363
28.4　精神高于物质　/ 364
28.5　思维和世界　/ 365
28.6　思维和机器　/ 367
28.7　个体身份　/ 368
28.8　重叠的思维　/ 370
第29章　思维的领域　/ 372
29.1　思维的领域　/ 373
29.2　同时运行的多重思维　/ 374
29.3　并行代原体　/ 375
29.4　跨领域通信　/ 377
29.5　统一的弊端　/ 378
29.6　孤独症儿童　/ 380
29.7　相似和类比　/ 381
29.8　比喻　/ 382
第30章　思维模式　/ 385
30.1　知道　/ 386
30.2　知道和相信　/ 387
30.3　心理模型　/ 388
30.4　世界模型　/ 390
30.5　认识自我　/ 391
30.6　意志的自由　/ 392
30.7　第三选项的谬误　/ 393
30.8　智能与智谋　/ 395
附录　/ 397
A.?遗传与环境　/ 397
B.?思维领域的起源　/ 399
C.?姿势与轨迹　/ 402
D.?脑的联结　/ 404
E.?生存本能　/ 409
F.?进化与目的　/ 410
G.?隔离与相互作用　/ 412
H.?人类思维的发展　/ 414
后记与致谢　/ 417
词汇与参考书目　/ 424
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>心智社会
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘导论
第1章　绪论　1
1.1　什么是数据挖掘　2
1.2　引发数据挖掘的挑战　2
1.3　数据挖掘的起源　3
1.4　数据挖掘任务　4
1.5　本书的内容与组织　7
文献注释　7
参考文献　8
习题　10
第2章　数据　13
2.1　数据类型　14
2.1.1　属性与度量　15
2.1.2　数据集的类型　18
2.2　数据质量　22
2.2.1　测量和数据收集问题　22
2.2.2　关于应用的问题　26
2.3　数据预处理　27
2.3.1　聚集　27
2.3.2　抽样　28
2.3.3　维归约　30
2.3.4　特征子集选择　31
2.3.5　特征创建　33
2.3.6　离散化和二元化　34
2.3.7　变量变换　38
2.4　相似性和相异性的度量　38
2.4.1　基础　39
2.4.2　简单属性之间的相似度和相异度　40
2.4.3　数据对象之间的相异度　41
2.4.4　数据对象之间的相似度　43
2.4.5　邻近性度量的例子　43
2.4.6　邻近度计算问题　48
2.4.7　选取正确的邻近性度量　50
文献注释　50
参考文献　52
习题　53
第3章　探索数据　59
3.1　鸢尾花数据集　59
3.2　汇总统计　60
3.2.1　频率和众数　60
3.2.2　百分位数　61
3.2.3　位置度量：均值和中位数　61
3.2.4　散布度量：极差和方差　62
3.2.5　多元汇总统计　63
3.2.6　汇总数据的其他方法　64
3.3　可视化　64
3.3.1　可视化的动机　64
3.3.2　一般概念　65
3.3.3　技术　67
3.3.4　可视化高维数据　75
3.3.5　注意事项　79
3.4　OLAP和多维数据分析　79
3.4.1　用多维数组表示鸢尾花数据　80
3.4.2　多维数据：一般情况　81
3.4.3　分析多维数据　82
3.4.4　关于多维数据分析的最后评述　84
文献注释　84
参考文献　85
习题　86
第4章　分类：基本概念、决策树与模型评估　89
4.1　预备知识　89
4.2　解决分类问题的一般方法　90
4.3　决策树归纳　92
4.3.1　决策树的工作原理　92
4.3.2　如何建立决策树　93
4.3.3　表示属性测试条件的方法　95
4.3.4　选择最佳划分的度量　96
4.3.5　决策树归纳算法　101
4.3.6　例子：Web 机器人检测　102
4.3.7　决策树归纳的特点　103
4.4　模型的过分拟合　106
4.4.1　噪声导致的过分拟合　107
4.4.2　缺乏代表性样本导致的过分拟合　109
4.4.3　过分拟合与多重比较过程　109
4.4.4　泛化误差估计　110
4.4.5　处理决策树归纳中的过分拟合　113
4.5　评估分类器的性能　114
4.5.1　保持方法　114
4.5.2　随机二次抽样　115
4.5.3　交叉验证　115
4.5.4　自助法　115
4.6　比较分类器的方法　116
4.6.1　估计准确度的置信区间　116
4.6.2　比较两个模型的性能　117
4.6.3　比较两种分类法的性能　118
文献注释　118
参考文献　120
习题　122
第5章　分类：其他技术　127
5.1　基于规则的分类器　127
5.1.1　基于规则的分类器的工作原理　128
5.1.2　规则的排序方案　129
5.1.3　如何建立基于规则的分类器　130
5.1.4　规则提取的直接方法　130
5.1.5　规则提取的间接方法　135
5.1.6　基于规则的分类器的特征　136
5.2　最近邻分类器　137
5.2.1　算法　138
5.2.2　最近邻分类器的特征　138
5.3　贝叶斯分类器　139
5.3.1　贝叶斯定理　139
5.3.2　贝叶斯定理在分类中的应用　140
5.3.3　朴素贝叶斯分类器　141
5.3.4　贝叶斯误差率　145
5.3.5　贝叶斯信念网络　147
5.4　人工神经网络(ANN)　150
5.4.1　感知器　151
5.4.2　多层人工神经网络　153
5.4.3　人工神经网络的特点　155
5.5　支持向量机　156
5.5.1　最大边缘超平面　156
5.5.2　线性支持向量机：可分情况　157
5.5.3　线性支持向量机：不可分情况　162
5.5.4　非线性支持向量机　164
5.5.5　支持向量机的特征　168
5.6　组合方法　168
5.6.1　组合方法的基本原理　168
5.6.2　构建组合分类器的方法　169
5.6.3　偏倚—方差分解　171
5.6.4　装袋　173
5.6.5　提升　175
5.6.6　随机森林　178
5.6.7　组合方法的实验比较　179
5.7　不平衡类问题　180
5.7.1　可选度量　180
5.7.2　接受者操作特征曲线　182
5.7.3　代价敏感学习　184
5.7.4　基于抽样的方法　186
5.8　多类问题　187
文献注释　189
参考文献　190
习题　193
第6章　关联分析：基本概念和算法　201
6.1　问题定义　202
6.2　频繁项集的产生　204
6.2.1　先验原理　205
6.2.2　Apriori算法的频繁项集产生　206
6.2.3　候选的产生与剪枝　208
6.2.4　支持度计数　210
6.2.5　计算复杂度　213
6.3　规则产生　215
6.3.1　基于置信度的剪枝　215
6.3.2　Apriori算法中规则的产生　215
6.3.3　例：美国国会投票记录　217
6.4　频繁项集的紧凑表示　217
6.4.1　最大频繁项集　217
6.4.2　频繁闭项集　219
6.5　产生频繁项集的其他方法　221
6.6　FP增长算法　223
6.6.1　FP树表示法　224
6.6.2　FP增长算法的频繁项集产生　225
6.7　关联模式的评估　228
6.7.1　兴趣度的客观度量　228
6.7.2　多个二元变量的度量　235
6.7.3　辛普森悖论　236
6.8　倾斜支持度分布的影响　237
文献注释　240
参考文献　244
习题　250
第7章　关联分析：高级概念　259
7.1　处理分类属性　259
7.2　处理连续属性　261
7.2.1　基于离散化的方法　261
7.2.2　基于统计学的方法　263
7.2.3　非离散化方法　265
7.3　处理概念分层　266
7.4　序列模式　267
7.4.1　问题描述　267
7.4.2　序列模式发现　269
7.4.3　时限约束　271
7.4.4　可选计数方案　274
7.5　子图模式　275
7.5.1　图与子图　276
7.5.2　频繁子图挖掘　277
7.5.3　类Apriori方法　278
7.5.4　候选产生　279
7.5.5　候选剪枝　282
7.5.6　支持度计数　285
7.6　非频繁模式　285
7.6.1　负模式　285
7.6.2　负相关模式　286
7.6.3　非频繁模式、负模式和负相关模式比较　287
7.6.4　挖掘有趣的非频繁模式的技术　288
7.6.5　基于挖掘负模式的技术　288
7.6.6　基于支持度期望的技术　290
文献注释　292
参考文献　293
习题　295
第8章　聚类分析：基本概念和算法　305
8.1　概述　306
8.1.1　什么是聚类分析　306
8.1.2　不同的聚类类型　307
8.1.3　不同的簇类型　308
8.2　K均值　310
8.2.1　基本K均值算法　310
8.2.2　K均值：附加的问题　315
8.2.3　二分K均值　316
8.2.4　K均值和不同的簇类型　317
8.2.5　优点与缺点　318
8.2.6　K均值作为优化问题　319
8.3　凝聚层次聚类　320
8.3.1　基本凝聚层次聚类算法　321
8.3.2　特殊技术　322
8.3.3　簇邻近度的Lance-Williams公式　325
8.3.4　层次聚类的主要问题　326
8.3.5　优点与缺点　327
8.4　DBSCAN　327
8.4.1　传统的密度：基于中心的方法　327
8.4.2　DBSCAN算法　328
8.4.3　优点与缺点　329
8.5　簇评估　330
8.5.1　概述　332
8.5.2　非监督簇评估：使用凝聚度和分离度　332
8.5.3　非监督簇评估：使用邻近度矩阵　336
8.5.4　层次聚类的非监督评估　338
8.5.5　确定正确的簇个数　339
8.5.6　聚类趋势　339
8.5.7　簇有效性的监督度量　340
8.5.8　评估簇有效性度量的显著性　343
文献注释　344
参考文献　345
习题　347
第9章　聚类分析：附加的问题与算法　355
9.1　数据、簇和聚类算法的特性　355
9.1.1　例子：比较K均值和DBSCAN　355
9.1.2　数据特性　356
9.1.3　簇特性　357
9.1.4　聚类算法的一般特性　358
9.2　基于原型的聚类　359
9.2.1　模糊聚类　359
9.2.2　使用混合模型的聚类　362
9.2.3　自组织映射　369
9.3　基于密度的聚类　372
9.3.1　基于网格的聚类　372
9.3.2　子空间聚类　374
9.3.3　DENCLUE：基于密度聚类的一种基于核的方案　377
9.4　基于图的聚类　379
9.4.1　稀疏化　379
9.4.2　最小生成树聚类　380
9.4.3　OPOSSUM：使用METIS的稀疏相似度最优划分　381
9.4.4　Chameleon：使用动态建模的层次聚类　381
9.4.5　共享最近邻相似度　385
9.4.6　Jarvis-Patrick聚类算法　387
9.4.7　SNN密度　388
9.4.8　基于SNN密度的聚类　389
9.5　可伸缩的聚类算法　390
9.5.1　可伸缩：一般问题和方法　391
9.5.2　BIRCH　392
9.5.3　CURE　393
9.6　使用哪种聚类算法　395
文献注释　397
参考文献　398
习题　400
第10章　异常检测　403
10.1　预备知识　404
10.1.1　异常的成因　404
10.1.2　异常检测方法　404
10.1.3　类标号的使用　405
10.1.4　问题　405
10.2　统计方法　406
10.2.1　检测一元正态分布中的离群点　407
10.2.2　多元正态分布的离群点　408
10.2.3　异常检测的混合模型方法　410
10.2.4　优点与缺点　411
10.3　基于邻近度的离群点检测　411
10.4　基于密度的离群点检测　412
10.4.1　使用相对密度的离群点检测　413
10.4.2　优点与缺点　414
10.5　基于聚类的技术　414
10.5.1　评估对象属于簇的程度　415
10.5.2　离群点对初始聚类的影响　416
10.5.3　使用簇的个数　416
10.5.4　优点与缺点　416
文献注释　417
参考文献　418
习题　420
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Probabilistic Graphical Models
致谢
插图目录
算法目录
专栏目录
第1章 引言
1.1 动机
1.2结构化概率模型
1.2.1概率图模型
1.2.2表示、推理、学习
1.3概述和路线图
1.3.1各章的概述
1.3.2读者指南
1.3_3与其他学科的联系
1.4历史注记
第2章基础知识
2.1 概率论
2.1.1概率分布
2.1.2概率中的基本概念
2.1.3随机变量与联合分布
2.1.4独立性与条件独立性
2.1.5查询一个分布
2.1.6连续空间
2.1.7期望与方差
2.2 图
2.2.1 节点与边
2.2.2 子图
2.2.3 路径与迹
2.2.4圈与环
2.3相关文献
2.4 习题
第Ⅰ部分表 示
第3章 贝叶斯网表示
3.1独立性性质的利用
3.1.1随机变量的独立性
3.1.2条件参数化方法
3.1.3朴素贝叶斯模型
3.2 贝叶斯网
3.2.1学生示例回顾
3.2.2 贝叶斯网的基本独立性
3.2.3 图与分布
3.3 图中的独立性
3.3.1 d.分离
3.3.2可靠性与完备性
3.3.3 d.分离算法
3.3.4 1.等价
3.4从分布到图
3.4.1 最小I—map
3.4.2 P—map
3.4.3 发现P—map
3.5 小结
3.6相关文献
3.7 习题
第4章无向图模型
4.1 误解示例
4.2 参数化
4.2.1因子
4.2.2吉布斯分布与马尔可夫网
4.2.3简化的马尔可夫网
4.3马尔可夫网的独立性
4.3.1基本独立性
4.3.2独立性回顾
4.3.3从分布到图
4.4参数化回顾
4.4.1细粒度参数化方法
4.4.2过参数化
4.5 贝叶斯网与马尔可夫网
4.5.1 从贝叶斯网到马尔可夫网
4.5.2从马尔可夫网到贝叶斯网
4.5.3 弦图
4.6部分有向模型
4.6.1条件随机场
4.6.2链图模型
4.7总结与讨论
4.8相关文献
4.9 习题
第5章局部概率模型
5.1 CPD表
5.2确定性CPD
5.2.1 表示
5.2.2独立性
5.3特定上下文CPD
5.3.1 表示
5.3.2独立性
5.4因果影响的独立性
5.4.1 Noisy—or模型
5.4.2广义线性模型
5.4.3一般公式化表示
5.4.4独立性
5.5连续变量
5.5.1混合模型
5.6条件贝叶斯网
5.7总结
5.8相关文献
5.9习题
第6章基于模板的表示
6.1引言
6.2时序模型
6.2.1基本假设
6.2.2动态贝叶斯网
6.2.3状态—观测模型
6.3模板变量与模板因子
6.4对象—关系领域的有向概率模型
6.4.1 Plate模型
6.4.2概率关系模型
6.5无向表示
6.6结构不确定性
6.6.1关系不确定性
6.6.2对象不确定性
6.7小结
6.8 相关文献
6.9习题
第7章高斯网络模型
7.1 多元高斯分布
7.1.1基本参数化方法
7.1.2高斯分布的运算
7.1.3高斯分布的独立性
7.2高斯贝叶斯网
7.3 高斯马尔可夫随机场
7.4 小结
7.5相关文献
7.6习题
第8章指数族
8.1 引言
8.2 指数族
8.2.1线性指数族
8.3因式化的指数族（factored exponential families）
8.3.1乘积分布（product distributions）
8.3.2 贝叶斯网
8.4熵和相对熵
8.4.1 熵
8.4.2相对熵
8.5 投影
8.5.1 比较
8.5.2 M.投影
8.5.3 I—投影
8.6 小结
8.7相关文献
8.8 习是亟
第Ⅱ部分推 理
第Ⅲ部分学习
第Ⅳ部分行为与决策
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Probabilistic Graphical Models
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习与图像识别：原理与实践
前言
第1章　机器视觉在行业中的应用1
1.1　机器视觉的发展背景1
1.1.1　人工智能1
1.1.2　机器视觉2
1.2　机器视觉的主要应用场景3
1.2.1　人脸识别3
1.2.2　视频监控分析4
1.2.3　工业瑕疵检测5
1.2.4　图片识别分析6
1.2.5　自动驾驶/驾驶辅助7
1.2.6　三维图像视觉8
1.2.7　医疗影像诊断8
1.2.8　文字识别9
1.2.9　图像/视频的生成及设计9
1.3　本章小结10
第2章　图像识别前置技术11
2.1　深度学习框架11
2.1.1　Theano11
2.1.2　Tensorflow12
2.1.3　MXNet13
2.1.4　Keras13
2.1.5　PyTorch14
2.1.6　Caffe14
2.2　搭建图像识别开发环境15
2.2.1　Anaconda15
2.2.2　conda18
2.2.3　Pytorch的下载与安装19
2.3　Numpy使用详解20
2.3.1　创建数组20
2.3.2　创建Numpy数组22
2.3.3　获取Numpy属性24
2.3.4　Numpy数组索引25
2.3.5　切片25
2.3.6　Numpy中的矩阵运算26
2.3.7　数据类型转换27
2.3.8　Numpy的统计计算方法28
2.3.9　Numpy中的arg运算29
2.3.10　FancyIndexing29
2.3.11　Numpy数组比较30
2.4　本章小结31
第3章　图像分类之KNN算法32
3.1　KNN的理论基础与实现32
3.1.1　理论知识32
3.1.2　KNN的算法实现33
3.2　图像分类识别预备知识35
3.2.1　图像分类35
3.2.2　图像预处理36
3.3　KNN实战36
3.3.1　KNN实现MNIST数据分类36
3.3.2　KNN实现Cifar10数据分类41
3.4　模型参数调优44
3.5　本章小结48
第4章　机器学习基础49
4.1　线性回归模型49
4.1.1　一元线性回归50
4.1.2　多元线性回归56
4.2　逻辑回归模型57
4.2.1　Sigmoid函数58
4.2.2　梯度下降法59
4.2.3　学习率的分析61
4.2.4　逻辑回归的损失函数63
4.2.5　Python实现逻辑回归66
4.3　本章小结68
第5章　神经网络基础69
5.1　神经网络69
5.1.1　神经元70
5.1.2　激活函数72
5.1.3　前向传播76
5.2　输出层80
5.2.1　Softmax80
5.2.2　one-hotencoding82
5.2.3　输出层的神经元个数83
5.2.4　MNIST数据集的前向传播83
5.3　批处理85
5.4　广播原则87
5.5　损失函数88
5.5.1　均方误差88
5.5.2　交叉熵误差89
5.5.3　Mini-batch90
5.6　最优化91
5.6.1　随机初始化91
5.6.2　跟随梯度（数值微分）92
5.7　基于数值微分的反向传播98
5.8　基于测试集的评价101
5.9　本章小结104
第6章　误差反向传播105
6.1　激活函数层的实现105
6.1.1　ReLU反向传播实现106
6.1.2　Sigmoid反向传播实现106
6.2　Affine层的实现107
6.3　Softmaxwithloss层的实现108
6.4　基于数值微分和误差反向传播的比较109
6.5　通过反向传播实现MNIST识别111
6.6　正则化惩罚114
6.7　本章小结115
第7章　PyTorch实现神经网络图像分类116
7.1　PyTorch的使用116
7.1.1　Tensor116
7.1.2　Variable117
7.1.3　激活函数118
7.1.4　损失函数120
7.2　PyTorch实战122
7.2.1　PyTorch实战之MNIST分类122
7.2.2　PyTorch实战之Cifar10分类125
7.3　本章小结128
第8章　卷积神经网络129
8.1　卷积神经网络基础129
8.1.1　全连接层129
8.1.2　卷积层130
8.1.3　池化层134
8.1.4　批规范化层135
8.2　常见卷积神经网络结构135
8.2.1　AlexNet136
8.2.2　VGGNet138
8.2.3　GoogLeNet140
8.2.4　ResNet142
8.2.5　其他网络结构144
8.3　VGG16实现Cifar10分类145
8.3.1　训练146
8.3.2　预测及评估149
8.4　本章小结152
8.5　参考文献152
第9章　目标检测153
9.1　定位+分类153
9.2　目标检测155
9.2.1　R-CNN156
9.2.2　Fast R-CNN160
9.2.3　Faster R-CNN162
9.2.4　YOLO165
9.2.5　SSD166
9.3　SSD实现VOC目标检测167
9.3.1　PASCAL VOC数据集167
9.3.2　数据准备170
9.3.3　构建模型175
9.3.4　定义Loss178
9.3.5　SSD训练细节181
9.3.6　训练186
9.3.7　测试189
9.4　本章小结190
9.5　参考文献191
第10章　分割192
10.1　语义分割193
10.1.1　FCN193
10.1.2　UNet实现裂纹分割196
10.1.3　SegNet209
10.1.4　PSPNet210
10.2　实例分割211
10.2.1　层叠式212
10.2.2　扁平式212
10.3　本章小结213
10.4　参考文献214
第11章　产生式模型215
11.1　自编码器215
11.2　对抗生成网络215
11.3　DCGAN及实战217
11.3.1　数据集218
11.3.2　网络设置220
11.3.3　构建产生网络221
11.3.4　构建判别网络223
11.3.5　定义损失函数224
11.3.6　训练过程224
11.3.7　测试227
11.4　其他GAN230
11.5　本章小结235
11.6　参考文献235
第12章　神经网络可视化236
12.1　卷积核236
12.2　特征层237
12.2.1　直接观测237
12.2.2　通过重构观测239
12.2.3　末端特征激活情况243
12.2.4　特征层的作用244
12.3　图片风格化245
12.3.1　理论介绍245
12.3.2　代码实现247
12.4　本章小结255
12.5　参考文献255
第13章　图像识别算法的部署模式257
13.1　图像算法部署模式介绍257
13.2　实际应用场景和部署模式的匹配262
13.3　案例介绍264
13.4　本章小结265
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习与图像识别：原理与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能 （第2版）
第一部分引言
第　1章人工智能概述　2
1.0　引言　2
1.0.1　人工智能的定义　3
1.0.2　思维是什么？智能是什么？　3
1.1　图灵测试　5
1.1.1　图灵测试的定义　6
1.1.2　图灵测试的争议和批评　8
1.2　强人工智能与弱人工智能　9
1.3　启发法　11
1.3.1　长方体的对角线：解决一个相对简单但相关的
问题　11
1.3.2　水壶问题：向后倒推　12
1.4　识别适用人工智能来求解的问题　13
1.5　应用和方法　15
1.5.1　搜索算法和拼图　16
1.5.2　二人博弈　18
1.5.3　自动推理　18
1.5.4　产生式规则和专家系统　19
1.5.5　细胞自动机　20
1.5.6　神经计算　21
1.5.7　遗传算法　23
1.5.8　知识表示　23
1.5.9　不确定性推理　24
1.6　人工智能的早期历史　25
1.7　人工智能的近期历史到现在　29
1.7.1　博弈　29
1.7.2　专家系统　30
1.7.3　神经计算　31
1.7.4　进化计算　31
1.7.5　自然语言处理　32
1.7.6　生物信息学　34
1.8　新千年人工智能的发展　34
1.9　本章小结　36
第二部分　基础知识
第　2章盲目搜索　46
2.0　简介：智能系统中的搜索　46
2.1　状态空间图　47
2.2　生成与测试范式　49
2.2.1　回溯　50
2.2.2　贪婪算法　54
2.2.3　旅行销售员问题　56
2.3　盲目搜索算法　58
2.3.1　深度优先搜索　58
2.3.2　广度优先搜索　60
2.4　盲目搜索算法的实现和比较　63
2.4.1　实现深度优先搜索　63
2.4.2　实现广度优先搜索　65
2.4.3　问题求解性能的测量指标　65
2.4.4　DFS和BFS的比较　66
2.5　本章小结　68
第3章　知情搜索　74
3.0　引言　74
3.1　启发法　76
3.2　知情搜索（第一部分）——找到任何解　81
3.2.1　爬山法　81
3.2.2　最陡爬坡法　82
3.3　最佳优先搜索　84
3.4　集束搜索　87
3.5　搜索算法的其他指标　89
3.6　知情搜索（第二部分）——找到最佳解　90
3.6.1　分支定界法　90
3.6.2　使用低估值的分支定界法　95
3.6.3　采用动态规划的分支定界法　98
3.6.4　A*搜索　99
3.7　知情搜索（第三部分）—高级搜索算法　100
3.7.1　约束满足搜索　100
3.7.2　与或树　101
3.7.3　双向搜索　102
3.8　本章小结　104
第4章　博弈中的搜索　109
4.0　引言　109
4.1　博弈树和极小化极大评估　110
4.1.1　启发式评估　112
4.1.2　博弈树的极小化极大评估　112
4.2　具有α-剪枝的极小化极大算法　115
4.3　极小化极大算法的变体和改进　120
4.3.1　负极大值算法　120
4.3.2　渐进深化法　122
4.3.3　启发式续篇和地平线效应　122
4.4　概率游戏和预期极小化极大值算法　123
4.5　博弈理论　125
迭代的囚徒困境　126
4.6　本章小结　127
第5章　人工智能中的逻辑　133
5.0　引言　133
5.1　逻辑和表示　134
5.2　命题逻辑　135
5.2.1　命题逻辑—基础　136
5.2.2　命题逻辑中的论证　140
5.2.3　证明命题逻辑论证有效的第二种方法　141
5.3　谓词逻辑——简要介绍　143
5.3.1　谓词逻辑中的合一　144
5.3.2　谓词逻辑中的反演　146
5.3.3　将谓词表达式转换为子句形式　148
5.4　其他一些逻辑　151
5.4.1　二阶逻辑　151
5.4.2　非单调逻辑　152
5.4.3　模糊逻辑　152
5.4.4　模态逻辑　153
5.5　本章小结　153
第6章　知识表示　160
6.0　引言　160
6.1　图形草图和人类视窗　163
6.2　图和哥尼斯堡桥问题　166
6.3　搜索树　167
6.4　表示方法的选择　169
6.5　产生式系统　172
6.6　面向对象　172
6.7　框架法　173
6.8　脚本和概念依赖系统　176
6.9　语义网络　179
6.10　关联　181
6.11　新近的方法　182
6.11.1　概念地图　182
6.11.2　概念图　184
6.11.3　Baecker的工作　184
6.12　智能体：智能或其他　185
6.12.1　智能体的一些历史　188
6.12.2　当代智能体　189
6.12.3　语义网　191
6.12.4　IBM眼中的未来世界　191
6.12.5　作者的观点　192
6.13　本章小结　192
第7章　产生式系统　199
7.0　引言　199
7.1　背景　199
7.2　基本示例　202
7.3　CARBUYER系统　204
7.4　产生式系统和推导方法　208
7.4.1　冲突消解　211
7.4.2　正向链接　213
7.4.3　反向链接　214
7.5　产生式系统和细胞自动机　219
7.6　随机过程与马尔可夫链　221
7.7　本章小结　222
第三部分　基于知识的系统
第8章　人工智能中的不确定性　228
8.0　引言　228
8.1　模糊集　229
8.2　模糊逻辑　231
8.3　模糊推理　232
8.4　概率理论和不确定性　235
8.5　本章小结　239
第9章　专家系统　242
9.0　引言　242
9.1　背景　242
9.2　专家系统的特点　249
9.3　知识工程　250
9.4　知识获取　252
9.5　经典的专家系统　254
9.5.1　DENDRAL　254
9.5.2　MYCIN　255
9.5.3　EMYCIN　258
9.5.4　PROSPECTOR　259
9.5.5　模糊知识和贝叶斯规则　261
9.6　提高效率的方法　262
9.6.1　守护规则　262
9.6.2　Rete算法　263
9.7　基于案例的推理　264
9.8　更多最新的专家系统　269
9.8.1　改善就业匹配系统　269
9.8.2　振动故障诊断的专家系统　270
9.8.3　自动牙科识别　270
9.8.4　更多采用案例推理的专家系统　271
9.9　本章小结　271
第　10章机器学习第一部分　277
10.0　引言　277
10.1　机器学习：简要概述　277
10.2　机器学习系统中反馈的作用　279
10.3　归纳学习　280
10.4　利用决策树进行学习　282
10.5　适用于决策树的问题　283
10.6　熵　284
10.7　使用ID3构建决策树　285
10.8　其余问题　287
10.9　本章小结　288
第　11章机器学习第二部分：神经网络　291
11.0　引言　291
11.1　人工神经网络的研究　292
11.2　麦卡洛克-皮茨网络　294
11.3　感知器学习规则　295
11.4　增量规则　303
11.5　反向传播　308
11.6　实现关注点　313
11.6.1　模式分析　316
11.6.2　训练方法　317
11.7　离散型霍普菲尔德网络　318
11.8　应用领域　323
11.9　本章小结　330
第　12章受到自然启发的搜索　337
12.0　引言　337
12.1　模拟退火　338
12.2　遗传算法　341
12.3　遗传规划　349
12.4　禁忌搜索　353
12.5　蚂蚁聚居地优化　356
12.6　本章小结　359
第四部分　高级专题
第　13章自然语言处理　368
13.0　引言　368
13.1　概述：语言的问题和可能性　368
13.2　自然语言处理的历史　371
13.2.1　基础期（20世纪40年代和50年代）　371
13.2.2　符号与随机方法（1957—1970）　372
13.2.3　４种范式（1970—1983）　372
13.2.4　经验主义和有限状态模型（1983—1993）　373
13.2.5　大融合（1994—1999）　373
13.2.6　机器学习的兴起（2000—2008）　374
13.3　句法和形式语法　374
13.3.1　语法类型　374
13.3.2　句法解析：CYK算法　379
13.4　语义分析和扩展语法　380
13.4.1　转换语法　381
13.4.2　系统语法　381
13.4.3　格语法　382
13.4.4　语义语法　383
13.4.5　Schank系统　383
13.5　NLP中的统计方法　387
13.5.1　统计解析　387
13.5.2　机器翻译（回顾）和IBM的Candide系统　388
13.5.3　词义消歧　389
13.6　统计NLP的概率模型　390
13.6.1　隐马尔可夫模型　390
13.6.2　维特比算法　391
13.7　统计NLP语言数据集　392
13.7.1　宾夕法尼亚州树库项目　392
13.7.2　WordNet　394
13.7.3　NLP中的隐喻模型　394
13.8　应用：信息提取和问答系统　396
13.8.1　问答系统　396
13.8.2　信息提取　401
13.9　现在和未来的研究（基于CHARNIAK的工作）　401
13.10　语音理解　402
13.11　语音理解技术的应用　405
13.12　本章小结　410
第　14章自动规划　417
14.0　引言　417
14.1　规划问题　418
14.1.1　规划术语　418
14.1.2　规划应用示例　419
14.2　一段简短的历史和一个著名的问题　424
14.3　规划方法　426
14.3.1　规划即搜索　426
14.3.2　部分有序规划　430
14.3.3　分级规划　432
14.3.4　基于案例的规划　433
14.3.5　规划方法集锦　434
14.4　早期规划系统　435
14.4.1　STRIPS　435
14.4.2　NOAH　436
14.4.3　NONLIN　436
14.5　更多现代规划系统　437
14.5.1　O-PLAN　438
14.5.2　Graphplan　439
14.5.3　规划系统集锦　441
14.5.4　学习系统的规划方法　441
14.5.5　SCIBox自动规划器　442
14.6　本章小结　444
第五部分　现在和未来
第　15章机器人技术　452
15.0　引言　452
15.1　历史：服务人类、仿效人类、增强人类和替代人类　455
15.1.1　早期机械机器人　455
15.1.2　电影与文学中的机器人　458
15.1.3　20世纪早期的机器人　458
15.2　技术问题　464
15.2.1　机器人的组件　464
15.2.2　运动　467
15.2.3　点机器人的路径规划　468
15.2.4　移动机器人运动学　469
15.3　应用：21世纪的机器人　471
15.4　本章小结　479
第　16章高级计算机博弈　482
16.0　引言　482
16.1　跳棋：从塞缪尔到舍弗尔　483
16.1.1　在跳棋博弈中用于机器学习的启发式方法　486
16.1.2　填鸭式学习与概括　488
16.1.3　签名表评估和棋谱学习　489
16.1.4　含有奇诺克程序的世界跳棋锦标赛　490
16.1.5　彻底解决跳棋游戏　491
16.2　国际象棋：人工智能的“果蝇”　494
16.2.1　计算机国际象棋的历史背景　495
16.2.2　编程方法　496
16.2.3　超越地平线效应　505
16.2.4　DeepThought和DeepBlue与特级大师的比赛（1988—1995年）　505
16.3　计算机国际象棋对人工智能的贡献　507
16.3.1　在机器中的搜索　507
16.3.2　在搜索方面，人与机器的对比　508
16.3.3　启发式、知识和问题求解　509
16.3.4　蛮力：知识vs.搜索；表现vs.能力　510
16.3.5　残局数据库和并行计算　511
16.3.6　本书第一作者的贡献　514
16.4　其他博弈　514
16.4.1　奥赛罗　515
16.4.2　西洋双陆棋　516
16.4.3　桥牌　518
16.4.4　扑克　519
16.5　围棋：人工智能的“新果蝇”？　520
16.6　本章小结　523
第　17章大事记　532
17.0　引言　532
17.1　提纲挈领——概述　532
17.2　普罗米修斯归来　534
17.3　提纲挈领——介绍人工智能的成果　535
17.4　IBM的沃森-危险边缘挑战赛　539
17.5　21世纪的人工智能　543
17.6　本章小结　545
附录A　CLIPS示例：专家系统外壳　548
附录B　用于隐马尔可夫链的维特比算法的实现（由HarunIftikhar提供）　552
附录C　对计算机国际象棋的贡献：令人惊叹的WalterShawnBrowne　555
附录D　应用程序和数据　559
附录E　部分练习的答案　560
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能 （第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习导论
目录
中文版序
译者序
前言
第1章导论
1.1统计学习概述
1.2统计学习简史
1.3关于这本书
1.4这本书适用的读者群
1.5记号与简单的矩阵代数
1.6本书的内容安排
1.7用于实验和习题的数据集
1.8本书网站
1.9致谢
第2章统计学习
2.1什么是统计学习
2.2评价模型精度
2.3实验：R语言简介
2.4习题
第3章线性回归
3.1简单线性回归
3.2多元线性回归
3.3回归模型中的其他注意
事项
3.4营销计划
3.5线性回归与K最近邻法的
比较
3.6实验：线性回归
3.7习题
第4章分类
4.1分类问题概述
4.2为什么线性回归不可用
4.3逻辑斯谛回归
4.4线性判别分析
4.5分类方法的比较
4.6R实验：逻辑斯谛回归、LDA、QDA和KNN
4.7习题
第5章重抽样方法
5.1交叉验证法
5.2自助法
5.3实验：交叉验证法和自助法
5.4习题
第6章线性模型选择与正则化
6.1子集选择
6.2压缩估计方法
6.3降维方法
6.4高维问题
6.5实验1：子集选择方法
6.6实验2：岭回归和lasso
6.7实验3：PCR和PLS回归
6.8习题
第7章非线性模型
7.1多项式回归
7.2阶梯函数
7.3基函数
7.4回归样条
7.5光滑样条
7.6局部回归
7.7广义可加模型
7.8实验：非线性建模
7.9习题
第8章基于树的方法
8.1决策树基本原理
8.2装袋法、随机森林和提升法
8.3实验：决策树
8.4习题
第9章支持向量机
9.1最大间隔分类器
9.2支持向量分类器
9.3狭义的支持向量机
9.4多分类的SVM
9.5与逻辑斯谛回归的关系
9.6实验：支持向量机
9.7习题
第10章无指导学习
10.1无指导学习的挑战
10.2主成分分析
10.3聚类分析方法
10.4实验1：主成分分析
10.5实验2：聚类分析
10.6实验3：以NCI60数据为例
10.7习题
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>贝叶斯方法
目录
第1章　贝叶斯推断的哲学　1
1.1　引言　1
1.1.1　贝叶斯思维　1
1.1.2　贝叶斯推断在实践中的运用　3
1.1.3　频率派的模型是错误的吗？　4
1.1.4　关于大数据　4
1.2　我们的贝叶斯框架　5
1.2.1　不得不讲的实例：抛硬币　5
1.2.2　实例：图书管理员还是农民　6
1.3　概率分布　8
1.3.1　离散情况　9
1.3.2　连续情况　10
1.3.3　什么是　12
1.4　使用计算机执行贝叶斯推断　12
1.4.1　实例：从短信数据推断行为　12
1.4.2　介绍我们的第一板斧：PyMC　14
1.4.3　说明　18
1.4.4　后验样本到底有什么用？　18
1.5　结论　20
1.6　补充说明　20
1.6.1　从统计学上确定两个l值是否真的不一样　20
1.6.2　扩充至两个转折点　22
1.7　习题　24
1.8　答案　24
第2章　进一步了解PyMC　27
2.1　引言　27
2.1.1　父变量与子变量的关系　27
2.1.2　PyMC变量　28
2.1.3　在模型中加入观测值　31
2.1.4　最后……　33
2.2　建模方法　33
2.2.1　同样的故事，不同的结局　35
2.2.2　实例：贝叶斯A B测试　38
2.2.3　一个简单的场景　38
2.2.4　A和B一起　41
2.2.5　实例：一种人类谎言的算法　45
2.2.6　二项分布　45
2.2.7　实例：学生作弊　46
2.2.8　另一种PyMC模型　50
2.2.9　更多的PyMC技巧　51
2.2.10　实例：挑战者号事故　52
2.2.11　正态分布　55
2.2.12　挑战者号事故当天发生了什么？　61
2.3　我们的模型适用吗？　61
2.4　结论　68
2.5　补充说明　68
2.6　习题　69
2.7　答案　69
第3章　打开MCMC的黑盒子　71
3.1　贝叶斯景象图　71
3.1.1　使用MCMC来探索景象图　77
3.1.2　MCMC算法的实现　78
3.1.3　后验的其他近似解法　79
3.1.4　实例：使用混合模型进行无监督聚类　79
3.1.5　不要混淆不同的后验样本　88
3.1.6　使用MAP来改进收敛性　91
3.2　收敛的判断　92
3.2.1　自相关　92
3.2.2　稀释　95
3.2.3　pymc.Matplot.plot()　97
3.3　MCMC的一些秘诀　98
3.3.1　聪明的初始值　98
3.3.2　先验　99
3.3.3　统计计算的无名定理　99
3.4　结论　99
第4章　从未言明的最伟大定理　101
4.1　引言　101
4.2　大数定律　101
4.2.1　直觉　101
4.2.2　实例：泊松随机变量的收敛　102
4.2.3　如何计算Var(Z)　106
4.2.4　期望和概率　106
4.2.5　所有这些与贝叶斯统计有什么关系呢　107
4.3　小数据的无序性　107
4.3.1　实例：地理数据聚合　107
4.3.2　实例：Kaggle的美国人口普查反馈比例预测比赛　109
4.3.3　实例：如何对Reddit网站上的评论进行排序　111
4.3.4　排序！　115
4.3.5　但是这样做的实时性太差了　117
4.3.6　推广到评星系统　122
4.4　结论　122
4.5　补充说明　122
4.6　习题　123
4.7　答案　124
第5章　失去一只手臂还是一条腿　127
5.1　引言　127
5.2　损失函数　127
5.2.1　现实世界中的损失函数　129
5.2.2　实例：优化“价格竞猜”游戏的展品出价　130
5.3　机器学习中的贝叶斯方法　138
5.3.1　实例：金融预测　139
5.3.2　实例：Kaggle观测暗世界 大赛　144
5.3.3　数据　145
5.3.4　先验　146
5.3.5　训练和PyMC实现　147
5.4　结论　156
第6章　弄清楚先验　157
6.1　引言　157
6.2　主观与客观先验　157
6.2.1　客观先验　157
6.2.2　主观先验　158
6.2.3　决策，决策……　159
6.2.4　经验贝叶斯　160
6.3　需要知道的有用的先验　161
6.3.1　Gamma分布　161
6.3.2　威沙特分布　162
6.3.3　Beta分布　163
6.4　实例：贝叶斯多臂老虎机　164
6.4.1　应用　165
6.4.2　一个解决方案　165
6.4.3　好坏衡量标准　169
6.4.4　扩展算法　173
6.5　从领域专家处获得先验分布　176
6.5.1　试验轮盘赌法　176
6.5.2　实例：股票收益　177
6.5.3　对于威沙特分布的专业提示　184
6.6　共轭先验　185
6.7　杰弗里斯先验　185
6.8　当N增加时对先验的影响　187
6.9　结论　189
6.10　补充说明　190
6.10.1　带惩罚的线性回归的贝叶斯视角　190
6.10.2　选择退化的先验　192
第7章　贝叶斯A B测试　195
7.1　引言　195
7.2　转化率测试的简单重述　195
7.3　增加一个线性损失函数　198
7.3.1　收入期望的分析　198
7.3.2　延伸到A B测试　202
7.4　超越转化率：t检验　204
7.4.1　t检验的设定　204
7.5　增幅的估计　207
7.5.1　创建点估计　210
7.6　结论　211
术语表　213
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>贝叶斯方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统
推荐序一
推荐序二
译者序
前言
第1章 概述  1
1.1 简介  1
1.2 推荐系统的功能  3
1.3 数据和知识资源  5
1.4 推荐技术  7
1.5 应用与评价  10
1.6 推荐系统与人机交互  12
1.6.1 信任、解释和说服力  13
1.6.2 会话系统  13
1.6.3 可视化  14
1.7 推荐系统是个交叉学科领域  15
1.8 出现的问题和挑战  16
1.8.1 本书对出现的问题的讨论  16
1.8.2 挑战  18
参考文献  20
第一部分 基础技术
第2章 推荐系统中的数据挖掘方法  28
2.1 简介  28
2.2 数据预处理  29
2.2.1 相似度度量方法  29
2.2.2 抽样  30
2.2.3 降维  31
2.2.4 去噪  33
2.3 分类  34
2.3.1 最近邻  34
2.3.2 决策树  35
2.3.3 基于规则的分类  36
2.3.4 贝叶斯分类器  36
2.3.5 人工神经网络  38
2.3.6 支持向量机  39
2.3.7 分类器的集成  40
2.3.8 评估分类器  41
2.4 聚类分析  42
2.4.1 k-means  43
2.4.2 改进的k-means  44
2.5 关联规则挖掘  44
2.6 总结  46
致谢  47
参考文献  47
第3章 基于内容的推荐系统：前沿和趋势  51
3.1 简介  51
3.2 基于内容的推荐系统的基础  52
3.2.1 基于内容的推荐系统的高层次结构  52
3.2.2 基于内容过滤的优缺点  54
3.3 基于内容的推荐系统的现状  55
3.3.1 物品表示  56
3.3.2 学习用户特征的方法  62
3.4 趋势和未来研究  65
3.4.1 推荐过程中用户产生内容的作用  65
3.4.2 超越特化：惊喜度  66
3.5 总结  68
参考文献  68
第4章 基于近邻推荐方法综述  74
4.1 简介  74
4.1.1 问题公式化定义  75
4.1.2 推荐方法概要  76
4.1.3 基于近邻方法的优势  77
4.1.4 目标和概要  78
4.2 基于近邻推荐  78
4.2.1 基于用户评分  79
4.2.2 基于用户分类  80
4.2.3 回归与分类  80
4.2.4 基于物品推荐  81
4.2.5 基于用户和基于物品推荐的对比  81
4.3 近邻方法的要素  83
4.3.1 评分标准化  83
4.3.2 相似度权重计算  85
4.3.3 近邻的选择  89
4.4 高级进阶技术  90
4.4.1 降维方法  90
4.4.2 基于图方法  92
4.5 总结  95
参考文献  96
第5章 协同过滤算法的高级课题100 5.  1
简介  100
5.2 预备知识  101
5.2.1 基准预测  102
5.2.2 Netflix数据  103
5.2.3 隐式反馈  103
5.3 因子分解模型  104
5.3.1 SVD  104
5.3.2 SVD++  105
5.3.3 时间敏感的因子模型  106
5.3.4 比较  111
5.3.5 总结  112
5.4 基于邻域的模型  112
5.4.1 相似度度量  113
5.4.2 基于相似度的插值  113
5.4.3 联合派生插值权重  115
5.4.4 总结  117
5.5 增强的基于邻域的模型  117
5.5.1 全局化的邻域模型  118
5.5.2 因式分解的邻域模型  122
5.5.3 基于邻域的模型的动态时序  126
5.5.4 总结  127
5.6 基于邻域的模型和因子分解模型的比较  127
参考文献  129
第6章 开发基于约束的推荐系统  131
6.1 简介  131
6.2 推荐知识库的开发  133
6.3 推荐过程中的用户导向  137
6.4 计算推荐结果  142
6.5 项目和案例研究的经验  143
6.6 未来的研究方法  144
6.7 总结  147
参考文献  147
第7章 情境感知推荐系统  151
7.1 简介  151
7.2 推荐系统中的情境  152
7.2.1 什么是情境  152
7.2.2 在推荐系统实现情境信息的建模  155
7.2.3 获取情境信息  158
7.3 结合情境的推荐系统形式  159
7.3.1 情境预过滤  161
7.3.2 情境后过滤  163
7.3.3 情境建模  164
7.4 多种方法结合  167
7.4.1 组合预过滤器案例研究：算法  168
7.4.2 组合预过滤器案例研究：实验结果  168
7.5 情境感知推荐系统的其他问题  170
7.6 总结  171
致谢  171
参考文献  172
第二部分 推荐系统的应用与评估
第8章 推荐系统评估  176
8.1 简介  176
8.2 实验设置  177
8.2.1 离线实验  178
8.2.2 用户调查  180
8.2.3 在线评估  182
8.2.4 得出可靠结论  182
8.3 推荐系统属性  185
8.3.1 用户偏好  185
8.3.2 预测准确度  186
8.3.3 覆盖率  191
8.3.4 置信度  192
8.3.5 信任度  193
8.3.6 新颖度  194
8.3.7 惊喜度  195
8.3.8 多样性  195
8.3.9 效用  196
8.3.10 风险  197
8.3.11 健壮性  197
8.3.12 隐私  198
8.3.13 适应性  198
8.3.14 可扩展性  199
8.4 总结  199
参考文献  199
第9章 IPTV服务提供商推荐系统：一个大规模真实产品环境的应用203 9.1 简介  203
9.2 IPTV架构  204
9.3 推荐系统架构  206
9.3.1 数据搜集  206
9.3.2 批处理和实时阶段  207
9.4 推荐算法  208
9.4.1 推荐算法概述  209
9.4.2 基于内容隐语义分析算法  210
9.4.3 基于物品的协同过滤算法  213
9.4.4 基于降维的协同过滤算法  214
9.5 推荐服务  215
9.6 系统评价  216
9.6.1 离线分析  218
9.6.2 在线分析  220
9.7 总结  223
参考文献  223
第10章 走出实验室的推荐系统  225
10.1 简介  225
10.2 设计现实环境中的推荐系统  225
10.3 理解推荐系统的环境  226
10.3.1 应用模型  226
10.3.2 用户建模  230
10.3.3 数据模型  233
10.3.4 一个使用环境模型的方法  235
10.4 在迭代设计过程中理解推荐验证步骤  236
10.4.1 算法的验证  236
10.4.2 推荐结果的验证  237
10.5 应用实例：一个语义新闻推荐系统  240
10.5.1 背景：MESH工程  240
10.5.2 MESH的环境模型  240
10.5.3 实践：模型的迭代实例化  243
10.6 总结  244
参考文献  244
第11章 匹配推荐系统的技术与领域  247
11.1 简介  247
11.2 相关工作  247
11.3 知识源  248
11.4 领域  250
11.4.1 异构性  250
11.4.2 风险性  251
11.4.3 变动性  251
11.4.4 交互风格  251
11.4.5 偏好稳定性  251
11.4.6 可理解性  252
11.5 知识源  252
11.5.1 社群知识  252
11.5.2 个人知识  253
11.5.3 基于内容的知识  253
11.6 从领域到技术  254
11.6.1 算法  255
11.6.2 抽样推荐领域  256
11.7 总结  257
致谢  257
参考文献  257
第12章 用于技术强化学习的推荐系统  261
12.1 简介  261
12.2 背景  262
12.2.1 TEL作为上下文  262
12.2.2 TEL推荐的目标  263
12.3 相关工作  264
12.3.1 自适应教育超媒体  264
12.3.2 学习网络  265
12.3.3 相同点与不同点  267
12.4 TEL推荐系统调查  268
12.5 TEL推荐系统的评估  271
12.5.1 对组件的评估  272
12.5.2 评估TEL推荐系统时需要考虑的问题  273
12.6 总结与展望  274
致谢  274
参考文献  275
第三部分 推荐系统的影响
第13章 基于评价推荐系统的进展  282
13.1 简介  282
13.2 早期：评价系统/已得益处  282
13.3 评价系统的表述与检索挑战  283
13.3.1 评价表述的方式  283
13.3.2 基于评价的推荐系统中的检索挑战  289
13.4 评价平台中的交互研究  293
13.4.1 扩展到其他评价平台  294
13.4.2 用户直接操作与限制用户控制的比较  295
13.4.3 支持性解释、置信和信任  296
13.4.4 可视化、自适应性和分区动态性  297
13.4.5 关于多文化的适用性的差异  298
13.5 评价的评估：资源、方法和标准  298
13.5.1 资源和方法  298
13.5.2 评估标准  299
13.6 总结与展望  300
参考文献  301
第14章 构建更值得信任和具有说服力的推荐系统：特性对评估推荐系统的影响  305
14.1 简介  305
14.2 推荐系统作为社交角色  306
14.3 来源可信度  306
14.3.1 可信度  306
14.3.2 专业能力  307
14.3.3 对来源可信度的影响  307
14.4 人际交互中信息特性的研究  307
14.4.1 相似度  307
14.4.2 喜好度  308
14.4.3 权威的象征  308
14.4.4 演讲的风格  308
14.4.5 外在吸引力  308
14.4.6 幽默  309
14.5 人机交互中的特性  309
14.6 用户与推荐系统交互的特性  309
14.6.1 推荐系统类型  310
14.6.2 输入特性  310
14.6.3 过程特性  311
14.6.4 输出特性  311
14.6.5 内嵌的智能体特性  312
14.7 讨论  312
14.8 影响  313
14.9 未来研究方向  314
参考文献  314
第15章 设计和评估推荐系统的解释  321
15.1 简介  321
15.2 指引  322
15.3 专家系统的说明  322
15.4 定义的目标  322
15.4.1 系统如何工作:透明性  324
15.4.2 允许用户告诉系统它是错误的：被理解  324
15.4.3 增加用户对系统上的信任：信任度  325
15.4.4 说服用户尝试或购买：说服力  326
15.4.5 帮助用户充分地决策：有效性  327
15.4.6 帮助用户快速制定决策：效率  328
15.4.7 使系统的应用愉悦：满意度  328
15.5 评估解释在推荐系统的作用  329
15.5.1 精准度  329
15.5.2 学习效率  329
15.5.3 覆盖度  330
15.5.4 接受度  330
15.6 用推荐设计展示与互动  330
15.6.1 展示推荐  330
15.6.2 与推荐系统交互  331
15.7 解释风格  332
15.7.1 基于协同风格  333
15.7.2 基于内容风格  334
15.7.3 基于案例风格  334
15.7.4 基于知识/自然语言风格  335
15.7.5 基于人口统计风格  335
15.8 总结与展望  336
参考文献  337
第16章 基于实例评价研究的产品推荐系统的可用性准则  340
16.1 简介  340
16.2 预备知识  341
16.2.1 交互模型  341
16.2.2 基于效用的推荐系统  342
16.2.3 准确率、信任度和代价的框架  344
16.2.4 本章结构  344
16.3 相关工作  345
16.3.1 推荐系统分类  345
16.3.2 基于评分的推荐系统  345
16.3.3 基于案例的推荐系统  345
16.3.4 基于效用的推荐系统  345
16.3.5 基于评价的推荐系统  346
16.3.6 其他设计指导准则  346
16.4 初始偏好提取  347
16.5 通过实例激励用户表示偏好  349
16.5.1 需要多少实例  350
16.5.2 需要哪些实例  350
16.6 偏好修正  352
16.6.1 偏好冲突和部分满足  352
16.6.2 权衡辅助  353
16.7 展示策略  354
16.7.1 一次推荐一项物品  354
16.7.2 推荐k项最匹配的物品  355
16.7.3 解释界面  355
16.8 准则验证模型  357
16.9 总结  359
参考文献  359
第17章 基于示意图的产品目录可视化  363
17.1 简介  363
17.2 基于图的可视化方法  364
17.2.1 自组织映射  364
17.2.2 树图  365
17.2.3 多维缩放  366
17.2.4 非线性主成分分析  367
17.3 产品目录图  367
17.3.1 多维缩放  368
17.3.2 非线性主成分分析  369
17.4 通过点击流分析决定属性权重  370
17.4.1 泊松回归模型  370
17.4.2 处理缺失值  371
17.4.3 使用泊松回归选择权值  371
17.4.4 阶梯式泊松回归模型  371
17.5 图像购物界面  372
17.6 电子商务应用  373
17.6.1 使用属性权值的基于MDS的产品目录图  373
17.6.2 基于NL-PCA的产品目录图  375
17.6.3 图像购物界面  377
17.7 总结与展望  379
致谢  380
参考文献  380
第四部分 推荐系统与群体
第18章 个性化Web搜索中的群体、协作与推荐系统  384
18.1 简介  384
18.2 网络搜索历史简介  385
18.3 网络搜索的未来  387
18.3.1 个性化网络搜索  387
18.3.2 协同信息检索  390
18.3.3 向社交搜索前进  392
18.4 案例研究1：基于群体的网络搜索  392
18.4.1 搜索群体中的重复性和规律性  392
18.4.2 协同网络搜索系统  393
18.4.3 评估  395
18.4.4 讨论  396
18.5 案例研究2：网络搜索共享  396
18.5.1 HeyStaks系统  397
18.5.2 HeyStaks推荐引擎  399
18.5.3 评估  400
18.5.4 讨论  402
18.6 总结  402
致谢  403
参考文献  403
第19章 社会化标签推荐系统  409
19.1 简介  409
19.2 社会化标签推荐系统  410
19.2.1 大众分类法  410
19.2.2 传统推荐系统范式  411
19.2.3 多模式推荐  412
19.3 现实社会化标签推荐系统  413
19.3.1 有哪些挑战  413
19.3.2 案例BibSonomy  413
19.3.3 标签获取  415
19.4 社会化标签系统的推荐算法  416
19.4.1 协同过滤  416
19.4.2 基于排序的推荐  418
19.4.3 基于内容的社会化标签推荐系统  421
19.4.4 评估方案和评估度量  423
19.5 算法比较  424
19.6 总结与展望  426
参考文献  427
第20章 信任和推荐  430
20.1 简介  430
20.2 信任的表示与计算  431
20.2.1 信任表示  431
20.2.2 信任计算  433
20.3 信任增强推荐系统  436
20.3.1 动机  436
20.3.2 进展  437
20.3.3 实验比较  441
20.4 进展和开放性挑战  445
20.5 总结  446
参考文献  446
第21章 组推荐系统  449
21.1 简介  449
21.2 应用场景和群组推荐系统分类  450
21.2.1 交互式电视  450
21.2.2 环绕智能  450
21.2.3 基于场景的推荐系统  451
21.2.4 基于分类的群组推荐  451
21.3 合并策略  452
21.3.1 合并策略概览  452
21.3.2 合并策略在相关工作中的应用  453
21.3.3 哪种策略效果最好  454
21.4 序列顺序的影响  455
21.5 对情感状态建模  456
21.5.1 对个人的满意度进行建模  457
21.5.2 个人满意度对群组的影响  458
21.6 情感状态在合并策略中的使用  459
21.7 对单个用户进行组推荐  460
21.7.1 多准则  460
21.7.2 冷启动问题  461
21.7.3 虚拟组成员  462
21.8 总结与挑战  462
21.8.1 提出的主要问题  463
21.8.2 警告：组建模  463
21.8.3 面临的挑战  464
致谢  464
参考文献  465
第五部分 高级算法
第22章 推荐系统中的偏好聚合468 22.1 简介  468
22.2 推荐系统中的聚合类型  468
22.2.1 协同过滤中的偏好聚合  470
22.2.2 CB与UB推荐中的特性聚合  470
22.2.3 CB与UB的配置文件构建  470
22.2.4 物品和用户相似度以及邻居的形成  471
22.2.5 基于实例推理的连接词在推荐系统中的应用  472
22.2.6 加权混合系统  472
22.3 聚合函数概论  472
22.3.1 定义和属性  472
22.3.2 聚合成员  475
22.4 聚合函数的构建  479
22.4.1 数据收集和处理  479
22.4.2 期望属性、语义、解释  480
22.4.3 函数表现的复杂度及其理解  481
22.4.4 权重和参数的确定  482
22.5 推荐系统中的复杂聚合过程:为特定应用定制  482
22.6 总结  485
22.7 进阶阅读  485
致谢  486
参考文献  486
第23章 推荐系统中的主动学习  488
23.1 简介  488
23.1.1 推荐系统中主动学习的目标  489
23.1.2 例证  490
23.1.3 主动学习的类型  490
23.2 数据集的属性  491
23.3 主动学习在推荐系统中的应用  492
23.4 主动学习公式  493
23.5 基于不确定性的主动学习  495
23.5.1 输出不确定性  495
23.5.2 决策边界不确定性  496
23.5.3 模型不确定性  497
23.6 基于误差的主动学习  498
23.6.1 基于实例的方法  498
23.6.2 基于模型的方法  500
23.7 基于组合的主动学习  501
23.7.1 基于模型的方法  501
23.7.2 基于候选的方法  502
23.8 基于会话的主动学习  504
23.8.1 基于实例的评论  504
23.8.2 基于多样性的方法  504
23.8.3 基于查询编辑的方法  505
23.9 计算因素考虑  505
23.10 总结  505
致谢  506
参考文献  506
第24章 多准则推荐系统  510
24.1 简介  510
24.2 推荐作为多准则决策问题  511
24.2.1 决策目标  512
24.2.2 准则簇  512
24.2.3 全局偏好模型  513
24.2.4 决策支持流程  513
24.3 推荐系统的MCDM框架:经验教训  515
24.4 多准则评分推荐  517
24.4.1 传统的单值评分推荐问题  517
24.4.2 引入多准则评分来扩展传统推荐系统  518
24.5 多准则评分推荐算法综述  519
24.5.1 预测中使用多准则评分  519
24.5.2 推荐中使用多准则评分  524
24.6 讨论及未来工作  526
24.7 总结  527
致谢  528
参考文献  528
第25章 具有健壮性的协同推荐  533
25.1 简介  533
25.2 问题定义  534
25.3 攻击分类  536
25.3.1 基础攻击  536
25.3.2 非充分信息攻击  537
25.3.3 打压攻击模型  537
25.3.4 知情攻击模型  538
25.4 检测系统健壮性  539
25.4.1 评估矩阵  539
25.4.2 推举攻击  540
25.4.3 打压攻击  541
25.4.4 知情攻击  542
25.4.5 攻击效果  543
25.5 攻击检测  543
25.5.1 评估矩阵  544
25.5.2 单用户检测  544
25.5.3 用户组检测  545
25.5.4 检测结果  548
25.6 健壮的推荐算法  548
25.6.1 基于模型的推荐  548
25.6.2 健壮的矩阵分解算法  549
25.6.3 其他具有健壮性的推荐算法  549
25.6.4 影响力限制器和基于信誉的推荐  550
25.7 总结  550
致谢  551
参考文献  551
本书贡献者名单  554
翻译团队名单560
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>计算机科学中的数学：信息与智能时代的必修课
第I部分 数学证明
引言	3
0.1 参考文献	4
第1章 什么是证明	5
1.1 命题	5
1.2  谓词	8
1.3  公理化方法	8
1.4 我们的公理	9
1.4.1 逻辑推理	9
1.4.2 证明的模式	10
1.5 证明蕴涵	10
1.5.1 方法#1	11
1.5.2 方法#2：证明逆反命题	12
1.6  证明“当且仅当”	13
1.6.1  方法#1：证明两个语句相互蕴涵	13
1.6.2  方法#2：构建iff链	13
1.7 案例证明法	14
1.8  反证法	15
1.9  数学证明的优秀实践	16
1.10  参考文献	18
1.1节习题	18
1.5节习题	21
1.7节习题	21
1.8节习题	23
第2章 良序原理	26
2.1 良序证明	26
2.2  良序证明模板	27
2.2.1  整数求和	27
2.3 质因数分解	29
2.4 良序集合	29
2.4.1 不一样的良序集合（选学）	30
2.2节习题	31
2.4节习题	38
第3章  逻辑公式	40
3.1  命题的命题	41
3.1.1  NOT，AND和OR	41
3.1.2  当且仅当	42
3.1.3  IMPLIES	42
3.2  计算机程序的命题逻辑	44
3.2.1  真值表计算	45
3.2.2  符号表示	46
3.3  等价性和有效性	47
3.3.1  蕴涵和逆否	47
3.3.2  永真性和可满足性	48
3.4  命题代数	49
3.4.1  命题范式	49
3.4.2  等价性证明	50
3.5  SAT问题	53
3.6  谓词公式	54
3.6.1  量词	54
3.6.2  混合量词	55
3.6.3  量词的顺序	56
3.6.4  变量与域	56
3.6.5  否定量词	57
3.6.6  谓词公式的永真性	57
3.7  参考文献	58
3.1节习题	59
3.2节习题	61
3.3节习题	65
3.4节习题	68
3.5节习题	69
3.6节习题	71
第4章  数学数据类型	79
4.1  集合	79
4.1.1  常用集合	80
4.1.2  集合的比较和组合	80
4.1.3  幂集	81
4.1.4  集合构造器标记	82
4.1.5  证明集合相等	82
4.2  序列	83
4.3  函数	84
4.3.1  域和像	84
4.3.2  函数复合	86
4.4  二元关系	86
4.4.1  关系图	87
4.4.2  关系的像	89
4.5  有限基数	90
4.5.1  有限集有多少个子集	91
4.1节习题	92
4.2节习题	96
4.4节习题	97
4.5节习题	105
第5章  归纳法	107
5.1  一般归纳法	107
5.1.1  一般归纳法的规则	108
5.1.2  举例说明	108
5.1.3  归纳法证明的模板	109
5.1.4  一般归纳法的简洁写法	110
5.1.5  更复杂的例子	111
5.1.6  错误的归纳证明	113
5.2  强归纳法	115
5.2.1  强归纳法的规则	115
5.2.2  斐波那契数列	116
5.2.3  质数的乘积	117
5.2.4  找零问题	118
5.2.5  堆盒子游戏	119
5.3  强归纳法、一般归纳法和良序法的比较	120
5.1节习题	121
5.2节习题	131
第6章 状态机	136
6.1  状态和转移	136
6.2  不变性原理	137
6.2.1  沿对角线移动的机器人	137
6.2.2  不变性原理的定义	139
6.2.3  示例：《虎胆龙威》	141
6.3  偏序正确性和终止性	143
6.3.1  快速求幂	143
6.3.2  派生变量	145
6.3.3  基于良序集合的终止性（选学）	146
6.3.4  东南方向跳跃的机器人（选学）	146
6.4  稳定的婚姻	147
6.4.1  配对仪式	148
6.4.2  我们结婚吧	150
6.4.3  他们从此幸福地生活在一起	150
6.4.4  竟然是男性……	151
6.4.5  应用	152
6.3节习题	153
6.4节习题	165
第7章  递归数据类型	172
7.1  递归定义和结构归纳法	172
7.1.1  结构归纳法	174
7.2  匹配带括号的字符串	175
7.3  非负整数上的递归函数	179
7.3.1  N上的一些标准递归函数	179
7.3.2  不规范的函数定义	179
7.4  算术表达式	181
7.4.1  Aexp的替换和求值	181
7.5  计算机科学中的归纳	185
7.1节习题	185
7.2节习题	193
7.3节习题	201
7.4节习题	202
第8章  无限集	206
8.1  无限基数集	206
8.1.1  不同之处	209
8.1.2  可数集	209
8.1.3  幂集的势严格大于原集合	211
8.1.4  对角线证明	213
8.2  停止问题	214
8.3  集合逻辑	217
8.3.1  罗素悖论	217
8.3.2  集合的ZFC公理系统	218
8.3.3  避免罗素悖论	220
8.4  这些真的有效吗	220
8.4.1  计算机科学中的无穷大	221
8.1节习题	221
8.2节习题	228
8.3节习题	233
8.4节习题	236
第Ⅱ部分 结构
引言	241
第9章 数论	242
9.1  整除	242
9.1.1  整除的性质	243
9.1.2  不可整除问题	244
9.1.3  虎胆龙威	245
9.2  最大公约数	247
9.2.1  欧几里得算法	247
9.2.2  粉碎机	249
9.2.3  水壶问题的通解	251
9.2.4  最大公约数的性质	252
9.3  质数的奥秘	253
9.4  算术基本定理	255
9.4.1  唯一分解定理的证明	256
9.5  阿兰•图灵	257
9.5.1  图灵编码（1.0版）	258
9.5.2  破解图灵编码（1.0版）	260
9.6  模运算	260
9.7  余运算	262
9.7.1  环Z_n	264
9.8  图灵编码（2.0版）	265
9.9  倒数与约去	266
9.9.1  互质	267
9.9.2  约去	268
9.9.3  解密（2.0版）	268
9.9.4  破解图灵编码（2.0版）	269
9.9.5  图灵后记	269
9.10  欧拉定理	271
9.10.1  计算欧拉ϕ函数	273
9.11  RSA公钥加密	274
9.12  SAT与RSA有什么关系	276
9.13 参考文献	277
9.1节习题	277
9.2节习题	278
9.3节习题	285
9.4节习题	285
9.6节习题	287
9.7节习题	288
9.8节习题	293
9.9节习题	293
9.10节习题	295
9.11节习题	303
第10章  有向图和偏序	309
10.1  顶点的度	311
10.2  路和通路	311
10.2.1  查找通路	313
10.3  邻接矩阵	314
10.3.1  最短路径	315
10.4  路关系	316
10.4.1  复合关系	316
10.5  有向无环图&调度	317
10.5.1  调度	318
10.5.2  并行任务调度	320
10.5.3  Dilworth引理	322
10.6  偏序	323
10.6.1  DAG中路关系的性质	323
10.6.2  严格偏序	324
10.6.3  弱偏序	325
10.7  用集合包含表示偏序	326
10.8  线性序	327
10.9  乘积序	327
10.10  等价关系	328
10.10.1  等价类	328
10.11  关系性质的总结	329
10.1节习题	330
10.2节习题	331
10.3节习题	334
10.4节习题	335
10.5节习题	338
10.6节习题	344
10.7节习题	347
10.8节习题	349
10.9节习题	352
10.10节习题	354
第11章 通信网络	357
11.1  路由	357
11.1.1  完全二叉树	357
11.1.2  路由问题	358
11.2  路由的评价指标	358
11.2.1  网络直径	358
11.2.2  交换机的数量	359
11.2.3  网络时延	359
11.2.4  拥塞	360
11.3  网络设计	361
11.3.1  二维阵列	361
11.3.2  蝶形网络	362
11.3.3 Benes ̌网络	363
11.2节习题	368
11.3节习题	368
第12章 简单图	373
12.1  顶点邻接和度	373
12.2  美国异性伴侣统计	375
12.2.1  握手引理	376
12.3  一些常见的图	377
12.4  同构	378
12.5  二分图与匹配	380
12.5.1  二分匹配问题	380
12.5.2  匹配条件	381
12.6  着色	384
12.6.1  一个考试安排问题	384
12.6.2  一些着色边界	386
12.6.3  为什么着色	387
12.7  简单路	388
12.7.1  简单图中的路、通路和圈	388
12.7.2  圈作为子图	389
12.8  连通性	390
12.8.1  连通分量	390
12.8.2  奇数长度的圈和2-着色性	391
12.8.3  k–连通图	392
12.8.4  连通图的最小边数	393
12.9  森林和树	394
12.9.1  叶子、父母和孩子	394
12.9.2  性质	395
12.9.3  生成树	397
12.9.4  最小生成树	397
12.10 参考文献	401
12.2节习题	402
12.4节习题	403
12.5节习题	406
12.6节习题	411
12.7节习题	418
12.8节习题	420
12.9节习题	424
第13章 平面图	431
13.1 在平面上绘制图形	431
13.2 平面图的定义	433
13.2.1  面	434
13.2.2  平面嵌入的递归定义	436
13.2.3  这个定义行吗	438
13.2.4  外表面在哪里呢	438
13.3  欧拉公式	439
13.4  平面图中边的数量限制	440
13.5  返回到K_5和K_3,3	441
13.6  平面图的着色	442
13.7  多面体的分类	443
13.8  平面图的另一个特征	445
13.2节习题	446
13.8节习题	447
第Ⅲ部分 计数
引言	455
第14章  求和与渐近性	457
14.1 年金的值	458
14.1.1  钱未来的价值	458
14.1.2  扰动法	459
14.1.3  年金价值的闭型	460
14.1.4  无限长的等比数列	460
14.1.5  示例	461
14.1.6  等比数列求和的变化	462
14.2  幂和	463
14.3  估算求和式子	465
14.4  超出边界	468
14.4.1  问题陈述	468
14.4.2  调和数	471
14.4.3  渐近等式	473
14.5  乘积	474
14.5.1  斯特林公式	475
14.6  双倍的麻烦	477
14.7  渐近符号	479
14.7.1  小o	479
14.7.2 大O	479
14.7.3  θ	481
14.7.4  渐近符号的误区	482
14.7.5   Ω（选学）	484
14.1节习题	484
14.2节习题	486
14.3节习题	486
14.4节习题	488
14.7节习题	490
第15章  基数法则	499
15.1  通过其他计数来计算当前计数	499
15.1.1  双射规则	499
15.2  序列计数	500
15.2.1  乘积法则	501
15.2.2  n-元素集合的子集	501
15.2.3  加和法则	502
15.2.4  密码计数	502
15.3  广义乘积法则	503
15.3.1  有缺陷的美元钞票	504
15.3.2  一个象棋问题	505
15.3.3  排列	505
15.4  除法法则	506
15.4.1  另一个象棋问题	506
15.4.2  圆桌骑士	507
15.5  子集计数	508
15.5.1  子集法则	509
15.5.2  比特序列	510
15.6  重复序列	510
15.6.1  子集序列	510
15.6.2  Bookkeeper法则	511
15.6.3  二项式定理	512
15.7  计数练习：扑克手牌	513
15.7.1  四条相同点数的手牌	514
15.7.2  葫芦手牌	514
15.7.3  两个对子的手牌	515
15.7.4  花色齐全的手牌	517
15.8  鸽子洞原理	517
15.8.1  头上的头发	518
15.8.2  具有相同和的子集	519
15.8.3  魔术	521
15.8.4  秘密	521
15.8.5  真正的秘密	523
15.8.6  如果是4张牌呢	524
15.9  容斥原理	525
15.9.1  两个集合的并集	525
15.9.2  三个集合的并集	525
15.9.3  42序列、04序列或60序列	526
15.9.4  n个集合的并集	527
15.9.5  计算欧拉函数	529
15.10  组合证明	530
15.10.1  帕斯卡三角恒等式	530
15.10.2  给出组合证明	531
15.10.3  有趣的组合证明	532
15.11  参考文献	533
15.2节习题	534
15.4节习题	537
15.5节习题	538
15.6节习题	544
15.7节习题	548
15.8节习题	550
15.9节习题	554
15.10节习题	561
第16章  母函数	566
16.1  无穷级数	566
16.1.1  不收敛性	567
16.2  使用母函数计数	568
16.2.1  苹果和香蕉	568
16.2.2  母函数的积	569
16.2.3  卷积法则	570
16.2.4  利用卷积法则数甜甜圈	570
16.2.5  卷积法则中的二项式定理	571
16.2.6  一个荒唐的计数问题	572
16.3  部分分式	573
16.3.1  带有重根的部分分式	575
16.4  求解线性递推	575
16.4.1  斐波那契数的母函数	575
16.4.2  汉诺塔	576
16.4.3  求解一般线性递推	580
16.5  形式幂级数	580
16.5.1  发散母函数	580
16.5.2  幂级数环	581
16.6  参考文献	583
16.1节习题	583
16.2节习题	583
16.3节习题	586
16.4节习题	588
16.5节习题	595
第Ⅳ部分 概率论
引言	599
第17章  事件和概率空间	601
17.1  做个交易吧	601
17.1.1  理清问题	601
17.2  四步法	602
17.2.1  步骤一：找到样本空间	602
17.2.2  步骤二：确定目标事件	605
17.2.3  步骤三：确定结果的概率	606
17.2.4  步骤四：计算事件的概率	608
17.2.5  蒙特霍尔问题的另一种解释	609
17.3  奇怪的骰子	609
17.3.1  骰子A vs. 骰子B	610
17.3.2  骰子A vs. 骰子C	612
17.3.3  骰子B vs. 骰子C	612
17.3.4  掷两次	613
17.4  生日原理	615
17.4.1  匹配概率的确切公式	615
17.5  集合论和概率	616
17.5.1  概率空间	616
17.5.2  集合论的概率法则	617
17.5.3  均匀概率空间	618
17.5.4  无穷概率空间	619
17.6  参考文献	620
17.2节习题	620
17.5节习题	623
第18章  条件概率	626
18.1  蒙特霍尔困惑	626
18.1.1  帷幕之后	627
18.2  定义和标记	627
18.2.1  问题所在	628
18.3  条件概率四步法	629
18.4  为什么树状图有效	630
18.4.1  大小为k的子集的概率	631
18.4.2  医学检测	632
18.4.3  四步分析法	633
18.4.4  固有频率	634
18.4.5  后验概率	634
18.4.6  概率的哲学	635
18.5  全概率定理	637
18.5.1  以单一事件为条件	637
18.6  辛普森悖论	638
18.7  独立性	640
18.7.1  另一个公式	640
18.7.2  独立性是一种假设	641
18.8  相互独立性	641
18.8.1  DNA检测	642
18.8.2  两两独立	643
18.9  概率vs. 置信度	645
18.9.1  肺结核测试	645
18.9.2  可能性修正	646
18.9.3  很可能正确的事实	648
18.9.4  极端事件	648
18.9.5  下一次抛掷的置信度	649
18.4节习题	650
18.5节习题	650
18.6节习题	660
18.7节习题	661
18.8节习题	663
18.9节习题	666
第19章  随机变量	667
19.1  随机变量示例	667
19.1.1  指示器随机变量	668
19.1.2  随机变量和事件	668
19.2  独立性	669
19.3  分布函数	670
19.3.1  伯努利分布	672
19.3.2  均匀分布	672
19.3.3  数字游戏	673
19.3.4  二项分布	675
19.4  期望	677
19.4.1  均匀随机变量的期望值	677
19.4.2  随机变量的倒数的期望	678
19.4.3  指示器随机变量的期望值	678
19.4.4  期望的另一种定义	678
19.4.5  条件期望	679
19.4.6  平均故障时间	680
19.4.7  赌博游戏的预期收益	682
19.5  期望的线性性质	686
19.5.1  两枚骰子的期望	687
19.5.2  指示器随机变量的和	687
19.5.3  二项分布的期望	688
19.5.4  赠券收集问题	689
19.5.5  无限和	691
19.5.6  赌博悖论	691
19.5.7  悖论的解答	692
19.5.8  乘积的期望	693
19.2节习题	694
19.3节习题	696
19.4节习题	698
19.5节习题	702
第20章  离差	712
20.1  马尔可夫定理	712
20.1.1  应用马尔可夫定理	714
20.1.2  有界变量的马尔可夫定理	714
20.2  切比雪夫定理	715
20.2.1  两个赌博游戏的方差	716
20.2.2  标准差	717
20.3  方差的性质	718
20.3.1  方差公式	719
20.3.2  故障时间的方差	719
20.3.3  常数的处理	720
20.3.4  和的方差	721
20.3.5  生日匹配	722
20.4  随机抽样估计	723
20.4.1  选民投票	723
20.4.2  两两独立采样	725
20.5  估计的置信度	726
20.6  随机变量的和	728
20.6.1  引例	728
20.6.2  切诺夫界	729
20.6.3  二项式尾的切诺夫界	729
20.6.4  彩票游戏的切诺夫界	730
20.6.5  随机负载均衡	731
20.6.6  切诺夫界的证明	732
20.6.7  边界的比较	734
20.6.8  墨菲定律	735
20.7  大期望	736
20.7.1  重复你自己	736
20.1节习题	737
20.2节习题	738
20.3节习题	739
20.5节习题	746
20.6节习题	750
20.7节习题	753
第21章  随机游走	755
21.1  赌徒破产	755
21.1.1  避免破产的概率	757
21.1.2  获胜概率递推	758
21.1.3  有偏情形的简单解释	759
21.1.4  步长多长	761
21.1.5  赢了就退出	762
21.2  图的随机游走	763
21.2.1  网页排名初探	764
21.2.2  网页图的随机游走	765
21.2.3  平稳分布与网页排名	766
21.1节习题	768
21.2节习题	769
第Ⅴ部分 递推
引言	779
第22章  递推	780
22.1  汉诺塔	780
22.1.1  上界陷阱	781
22.1.2  扩充-化简法	781
22.2  归并排序	783
22.2.1  寻找递推	784
22.2.2  求解递推	784
22.3  线性递推	786
22.3.1  爬楼梯	786
22.3.2  求解齐次线性递推	789
22.3.3  求解一般线性递推	790
22.3.4  如何猜测特解	792
22.4  分治递推	793
22.4.1  Akra-Bazzi公式	794
22.4.2  两个技术问题	795
22.4.3  Akra-Bazzi定理	796
22.4.4  主定理	797
22.5  进一步探索	797
22.4节习题	799
参考文献	802
符号表	806
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>计算机科学中的数学：信息与智能时代的必修课
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>精通数据科学：从线性回归到深度学习
第1章  数据科学概述 1
1.1　挑战　2
1.1.1　工程实现的挑战　2
1.1.2　模型搭建的挑战　3
1.2　机器学习　5
1.2.1　机器学习与传统编程　5
1.2.2　监督式学习和非监督式学习　8
1.3　统计模型　8
1.4　关于本书　10
第2章 Python安装指南与简介：告别空谈　12
2.1　Python简介　13
2.1.1　什么是Python　15
2.1.2　Python在数据科学中的地位　16
2.1.3　不可能绕过的第三方库　17
2.2　Python安装　17
2.2.1　Windows下的安装　18
2.2.2　Mac下的安装　21
2.2.3　Linux下的安装　24
2.3　Python上手实践　26
2.3.1　Python shell　26
2.3.2　第 一个Python程序：Word Count　28
2.3.3　Python编程基础　30
2.3.4　Python的工程结构　34
2.4　本章小结　35
第3章　数学基础：恼人但又不可或缺的知识　36
3.1　矩阵和向量空间　37
3.1.1　标量、向量与矩阵　37
3.1.2　特殊矩阵　39
3.1.3　矩阵运算　39
3.1.4　代码实现　42
3.1.5　向量空间　44
3.2　概率：量化随机　46
3.2.1　定义概率：事件和概率空间　47
3.2.2　条件概率：信息的价值　48
3.2.3　随机变量：两种不同的随机　50
3.2.4　正态分布：殊途同归　52
3.2.5　P-value：自信的猜测　53
3.3　微积分　55
3.3.1　导数和积分：位置、速度　55
3.3.2　极限：变化的终点　57
3.3.3　复合函数：链式法则　58
3.3.4　多元函数：偏导数　59
3.3.5　极值与最值：最优选择　59
3.4　本章小结　61
第4章　线性回归：模型之母　62
4.1　一个简单的例子　64
4.1.1　从机器学习的角度看这个问题　66
4.1.2　从统计学的角度看这个问题　69
4.2　上手实践：模型实现　73
4.2.1　机器学习代码实现　74
4.2.2　统计方法代码实现　77
4.3　模型陷阱　82
4.3.1　过度拟合：模型越复杂越好吗　84
4.3.2　模型幻觉之统计学方案：假设检验　87
4.3.3　模型幻觉之机器学习方案：惩罚项　89
4.3.4　比较两种方案　92
4.4　模型持久化　92
4.4.1　模型的生命周期　93
4.4.2　保存模型　93
4.5　本章小结　96
第5章　逻辑回归：隐藏因子　97
5.1　二元分类问题：是与否　98
5.1.1　线性回归：为何失效　98
5.1.2　窗口效应：看不见的才是关键　100
5.1.3　逻辑分布：胜者生存　102
5.1.4　参数估计之似然函数：统计学角度　104
5.1.5　参数估计之损失函数：机器学习角度　104
5.1.6　参数估计之最终预测：从概率到选择　106
5.1.7　空间变换：非线性到线性　106
5.2　上手实践：模型实现　108
5.2.1　初步分析数据：直观印象　108
5.2.2　搭建模型　113
5.2.3　理解模型结果　116
5.3　评估模型效果：孰优孰劣　118
5.3.1　查准率与查全率　119
5.3.2　ROC曲线与AUC　123
5.4　多元分类问题：超越是与否　127
5.4.1　多元逻辑回归：逻辑分布的威力　128
5.4.2　One-vs.-all：从二元到多元　129
5.4.3　模型实现　130
5.5　非均衡数据集　132
5.5.1　准确度悖论　132
5.5.2　一个例子　133
5.5.3　解决方法　135
5.6　本章小结　136
第6章　工程实现：计算机是怎么算的　138
6.1　算法思路：模拟滚动　139
6.2　数值求解：梯度下降法　141
6.3　上手实践：代码实现　142
6.3.1　TensorFlow基础　143
6.3.2　定义模型　148
6.3.3　梯度下降　149
6.3.4　分析运行细节　150
6.4　更优化的算法：随机梯度下降法　153
6.4.1　算法细节　153
6.4.2　代码实现　154
6.4.3　两种算法比较　156
6.5　本章小结　158
第7章　计量经济学的启示：他山之石　159
7.1　定量与定性：变量的数学运算合理吗　161
7.2　定性变量的处理　162
7.2.1　虚拟变量　162
7.2.2　上手实践：代码实现　164
7.2.3　从定性变量到定量变量　168
7.3　定量变量的处理　170
7.3.1　定量变量转换为定性变量　171
7.3.2　上手实践：代码实现　171
7.3.3　基于卡方检验的方法　173
7.4　显著性　175
7.5　多重共线性：多变量的烦恼　176
7.5.1　多重共线性效应　176
7.5.2　检测多重共线性　180
7.5.3　解决方法　185
7.5.4　虚拟变量陷阱　188
7.6　内生性：变化来自何处　191
7.6.1　来源　192
7.6.2　内生性效应　193
7.6.3　工具变量　195
7.6.4　逻辑回归的内生性　198
7.6.5　模型的联结　200
7.7　本章小结　201
第8章　监督式学习： 目标明确　202
8.1　支持向量学习机　203
8.1.1　直观例子　204
8.1.2　用数学理解直观　205
8.1.3　从几何直观到最优化问题　207
8.1.4　损失项　209
8.1.5　损失函数与惩罚项　210
8.1.6　Hard margin 与soft margin比较　211
8.1.7　支持向量学习机与逻辑回归：隐藏的假设　213
8.2　核函数　216
8.2.1　空间变换：从非线性到线性　216
8.2.2　拉格朗日对偶　218
8.2.3　支持向量　220
8.2.4　核函数的定义：优化运算　221
8.2.5　常用的核函数　222
8.2.6　Scale variant　225
8.3　决策树　227
8.3.1　决策规则　227
8.3.2　评判标准　229
8.3.3　代码实现　231
8.3.4　决策树预测算法以及模型的联结　231
8.3.5　剪枝　235
8.4　树的集成　238
8.4.1　随机森林　238
8.4.2　Random forest embedding　239
8.4.3　GBTs之梯度提升　241
8.4.4　GBTs之算法细节　242
8.5　本章小结　244
第9章　生成式模型：量化信息的价值　246
9.1　贝叶斯框架　248
9.1.1　蒙提霍尔问题　248
9.1.2　条件概率　249
9.1.3　先验概率与后验概率　251
9.1.4　参数估计与预测公式　251
9.1.5　贝叶斯学派与频率学派　252
9.2　朴素贝叶斯　254
9.2.1　特征提取：文字到数字　254
9.2.2　伯努利模型　256
9.2.3　多项式模型　258
9.2.4　TF-IDF　259
9.2.5　文本分类的代码实现　260
9.2.6　模型的联结　265
9.3　判别分析　266
9.3.1　线性判别分析　267
9.3.2　线性判别分析与逻辑回归比较　269
9.3.3　数据降维　270
9.3.4　代码实现　273
9.3.5　二次判别分析　275
9.4　隐马尔可夫模型　276
9.4.1　一个简单的例子　276
9.4.2　马尔可夫链　278
9.4.3　模型架构　279
9.4.4　中文分词：监督式学习　280
9.4.5　中文分词之代码实现　282
9.4.6　股票市场：非监督式学习　284
9.4.7　股票市场之代码实现　286
9.5　本章小结　289
第10章 非监督式学习：聚类与降维　290
10.1　K-means　292
10.1.1　模型原理　292
10.1.2　收敛过程　293
10.1.3　如何选择聚类个数　295
10.1.4　应用示例　297
10.2　其他聚类模型　298
10.2.1　混合高斯之模型原理　299
10.2.2　混合高斯之模型实现　300
10.2.3　谱聚类之聚类结果　303
10.2.4　谱聚类之模型原理　304
10.2.5　谱聚类之图片分割　307
10.3　Pipeline　308
10.4　主成分分析　309
10.4.1　模型原理　310
10.4.2　模型实现　312
10.4.3　核函数　313
10.4.4　Kernel PCA的数学原理　315
10.4.5　应用示例　316
10.5　奇异值分解　317
10.5.1　定义　317
10.5.2　截断奇异值分解　317
10.5.3　潜在语义分析　318
10.5.4　大型推荐系统　320
10.6　本章小结　323
第11章 分布式机器学习：集体力量　325
11.1　Spark简介　327
11.1.1　Spark安装　328
11.1.2　从MapReduce到Spark　333
11.1.3　运行Spark　335
11.1.4　Spark DataFrame　336
11.1.5　Spark的运行架构　339
11.2　最优化问题的分布式解法　341
11.2.1　分布式机器学习的原理　341
11.2.2　一个简单的例子　342
11.3　大数据模型的两个维度　344
11.3.1　数据量维度　344
11.3.2　模型数量维度　346
11.4　开源工具的另一面　348
11.4.1　一个简单的例子　349
11.4.2　开源工具的阿喀琉斯之踵　351
11.5　本章小结　351
第12章 神经网络：模拟人的大脑　353
12.1　神经元　355
12.1.1　神经元模型　355
12.1.2　Sigmoid神经元与二元逻辑回归　356
12.1.3　Softmax函数与多元逻辑回归　358
12.2　神经网络　360
12.2.1　图形表示　360
12.2.2　数学基础　361
12.2.3　分类例子　363
12.2.4　代码实现　365
12.2.5　模型的联结　369
12.3　反向传播算法　370
12.3.1　随机梯度下降法回顾　370
12.3.2　数学推导　371
12.3.3　算法步骤　373
12.4　提高神经网络的学习效率　373
12.4.1　学习的原理　373
12.4.2　激活函数的改进　375
12.4.3　参数初始化　378
12.4.4　不稳定的梯度　380
12.5　本章小结　381
第13章 深度学习：继续探索　383
13.1　利用神经网络识别数字　384
13.1.1　搭建模型　384
13.1.2　防止过拟合之惩罚项　386
13.1.3　防止过拟合之dropout　387
13.1.4　代码实现　389
13.2　卷积神经网络　394
13.2.1　模型结构之卷积层　395
13.2.2　模型结构之池化层　397
13.2.3　模型结构之完整结构　399
13.2.4　代码实现　400
13.2.5　结构真的那么重要吗　405
13.3　其他深度学习模型　406
13.3.1　递归神经网络　406
13.3.2　长短期记忆　407
13.3.3　非监督式学习　409
13.4　本章小结　411
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>精通数据科学：从线性回归到深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言实战（第2版）
第一部分 入门
第1章　R语言介绍　　3
1.1　为何要使用R　　4
1.2　R的获取和安装　　6
1.3　R的使用　　6
1.3.1　新手上路　　7
1.3.2　获取帮助　　10
1.3.3　工作空间　　10
1.3.4　输入和输出　　12
1.4　包　　13
1.4.1　什么是包　　14
1.4.2　包的安装　　14
1.4.3　包的载入　　14
1.4.4　包的使用方法　　14
1.5　批处理　　15
1.6　将输出用为输入：结果的重用　　16
1.7　处理大数据集　　16
1.8　示例实践　　16
1.9　小结　　18
第2章　创建数据集　　19
2.1　数据集的概念　　19
2.2　数据结构　　20
2.2.1　向量　　21
2.2.2　矩阵　　22
2.2.3　数组　　23
2.2.4　数据框　　24
2.2.5　因子　　27
2.2.6　列表　　28
2.3　数据的输入　　30
2.3.1　使用键盘输入数据　　31
2.3.2　从带分隔符的文本文件导入数据　　32
2.3.3　导入Excel数据　　35
2.3.4　导入XML数据　　36
2.3.5　从网页抓取数据　　36
2.3.6　导入SPSS数据　　36
2.3.7　导入SAS数据　　37
2.3.8　导入Stata数据　　37
2.3.9　导入NetCDF数据　　38
2.3.10　导入HDF5数据　　38
2.3.11　访问数据库管理系统　　38
2.3.12　通过Stat/Transfer导入数据　　40
2.4　数据集的标注　　40
2.4.1　变量标签　　40
2.4.2　值标签　　41
2.5　处理数据对象的实用函数　　41
2.6　小结　　42
第3章　图形初阶　　 43
3.1　使用图形　　43
3.2　一个简单的例子　　45
3.3　图形参数　　46
3.3.1　符号和线条　　47
3.3.2　颜色　　 49
3.3.3　文本属性　　50
3.3.4　图形尺寸与边界尺寸　　51
3.4　添加文本、自定义坐标轴和图例　　53
3.4.1　标题　　 54
3.4.2　坐标轴　　54
3.4.3　参考线　　56
3.4.4　图例　　57
3.4.5　文本标注　　58
3.4.6　数学标注　　60
3.5　图形的组合　　61
3.6　小结　　67
第4章　基本数据管理　　68
4.1　一个示例　　68
4.2　创建新变量　　70
4.3　变量的重编码　　71
4.4　变量的重命名　　72
4.5　缺失值　　74
4.5.1　重编码某些值为缺失值　　74
4.5.2　在分析中排除缺失值　　75
4.6　日期值　　76
4.6.1　将日期转换为字符型变量　　77
4.6.2　更进一步　　78
4.7　类型转换　　78
4.8　数据排序　　79
4.9　数据集的合并　　79
4.9.1　向数据框添加列　　79
4.9.2　向数据框添加行　　80
4.10　数据集取子集　　80
4.10.1　选入（保留）变量　　80
4.10.2　剔除（丢弃）变量　　81
4.10.3　选入观测　　82
4.10.4　subset()函数　　82
4.10.5　随机抽样　　83
4.11　使用SQL语句操作数据框　　83
4.12　小结　　84
第5章　高级数据管理　　85
5.1　一个数据处理难题　　85
5.2　数值和字符处理函数　　86
5.2.1　数学函数　　86
5.2.2　统计函数　　87
5.2.3　概率函数　　90
5.2.4　字符处理函数　　92
5.2.5　其他实用函数　　94
5.2.6　将函数应用于矩阵和数据框　　95
5.3　数据处理难题的一套解决方案　　96
5.4　控制流　　100
5.4.1　重复和循环　　100
5.4.2　条件执行　　101
5.5　用户自编函数　　102
5.6　整合与重构　　104
5.6.1　转置　　104
5.6.2　整合数据　　105
5.6.3　reshape2包　　106
5.7　小结　　108
第二部分 基本方法
第6章　基本图形　　110
6.1　条形图　　110
6.1.1　简单的条形图　　111
6.1.2　堆砌条形图和分组条形图　　112
6.1.3　均值条形图　　113
6.1.4　条形图的微调　　114
6.1.5　棘状图　　115
6.2　饼图　　116
6.3　直方图　　118
6.4　核密度图　　120
6.5　箱线图　　122
6.5.1　使用并列箱线图进行跨组比较　　 123
6.5.2　小提琴图　　125
6.6　点图　　127
6.7　小结　　129
第7章　基本统计分析　　130
7.1　描述性统计分析　　131
7.1.1　方法云集　　131
7.1.2　更多方法　　132
7.1.3　分组计算描述性统计量　　134
7.1.4　分组计算的扩展　　135
7.1.5　结果的可视化　　137
7.2　频数表和列联表　　137
7.2.1　生成频数表　　137
7.2.2　独立性检验　　143
7.2.3　相关性的度量　　144
7.2.4　结果的可视化　　145
7.3　相关　　145
7.3.1　相关的类型　　145
7.3.2　相关性的显著性检验　　147
7.3.3　相关关系的可视化　　149
7.4　t 检验　　 149
7.4.1　独立样本的t 检验　　150
7.4.2　非独立样本的t检验　　151
7.4.3　多于两组的情况　　151
7.5　组间差异的非参数检验　　152
7.5.1　两组的比较　　152
7.5.2　多于两组的比较　　153
7.6　组间差异的可视化　　155
7.7　小结　　155
第三部分 中级方法
第8章　回归　　158
8.1　回归的多面性　　159
8.1.1　OLS回归的适用情境　　159
8.1.2　基础回顾　　160
8.2　OLS回归　　160
8.2.1　用lm()拟合回归模型　　161
8.2.2　简单线性回归　　163
8.2.3　多项式回归　　164
8.2.4　多元线性回归　　167
8.2.5　有交互项的多元线性回归　　169
8.3　回归诊断　　171
8.3.1　标准方法　　172
8.3.2　改进的方法　　175
8.3.3　线性模型假设的综合验证　　181
8.3.4　多重共线性　　181
8.4　异常观测值　　182
8.4.1　离群点　　182
8.4.2　高杠杆值点　　182
8.4.3　强影响点　　184
8.5　改进措施　　186
8.5.1　删除观测点　　186
8.5.2　变量变换　　187
8.5.3　增删变量　　188
8.5.4　尝试其他方法　　188
8.6　选择“最佳”的回归模型　　189
8.6.1　模型比较　　189
8.6.2　变量选择　　190
8.7　深层次分析　　193
8.7.1　交叉验证　　193
8.7.2　相对重要性　　195
8.8　小结　　197
第9章　方差分析　　 198
9.1　术语速成　　198
9.2　ANOVA模型拟合　　201
9.2.1　aov()函数　　201
9.2.2　表达式中各项的顺序　　202
9.3　单因素方差分析　　203
9.3.1　多重比较　　204
9.3.2　评估检验的假设条件　　206
9.4　单因素协方差分析　　208
9.4.1　评估检验的假设条件　　209
9.4.2　结果可视化　　210
9.5　双因素方差分析　　211
9.6　重复测量方差分析　　214
9.7　多元方差分析　　217
9.7.1　评估假设检验　　218
9.7.2　稳健多元方差分析　　220
9.8　用回归来做ANOVA　　220
9.9　小结　　222
第10章　功效分析　　223
10.1　假设检验速览　　223
10.2　用pwr包做功效分析　　225
10.2.1　t检验　　226
10.2.2　方差分析　　228
10.2.3　相关性　　228
10.2.4　线性模型　　229
10.2.5　比例检验　　230
10.2.6　卡方检验　　231
10.2.7　在新情况中选择合适的效应值　　232
10.3　绘制功效分析图形　　233
10.4　其他软件包　　235
10.5　小结　　236
第11章　中级绘图　　237
11.1　散点图　　238
11.1.1　散点图矩阵　　240
11.1.2　高密度散点图　　242
11.1.3　三维散点图　　244
11.1.4　旋转三维散点图　　247
11.1.5　气泡图　　248
11.2　折线图　　250
11.3　相关图　　253
11.4　马赛克图　　258
11.5　小结　　260
第12章　重抽样与自助法　　261
12.1　置换检验　　261
12.2　用coin包做置换检验　　263
12.2.1　独立两样本和K 样本检验　　264
12.2.2　列联表中的独立性　　266
12.2.3　数值变量间的独立性　　266
12.2.4　两样本和K 样本相关性检验　　267
12.2.5　深入探究　　267
12.3　lmPerm包的置换检验　　267
12.3.1　简单回归和多项式回归　　268
12.3.2　多元回归　　269
12.3.3　单因素方差分析和协方差分析　　270
12.3.4　双因素方差分析　　271
12.4　置换检验点评　　271
12.5　自助法　　272
12.6　boot包中的自助法　　272
12.6.1　对单个统计量使用自助法　　274
12.6.2　多个统计量的自助法　　276
12.7　小结　　278
第四部分 高级方法
第13章　广义线性模型　　280
13.1　广义线性模型和glm()函数　　281
13.1.1　glm()函数　　281
13.1.2　连用的函数　　282
13.1.3　模型拟合和回归诊断　　283
13.2　Logistic回归　　284
13.2.1　解释模型参数　　286
13.2.2　评价预测变量对结果概率的影响　　287
13.2.3　过度离势　　288
13.2.4　扩展　　289
13.3　泊松回归　　289
13.3.1　解释模型参数　　291
13.3.2　过度离势　　292
13.3.3　扩展　　294
13.4　小结　　295
第14章　主成分分析和因子分析　　296
14.1　R 中的主成分和因子分析　　297
14.2　主成分分析　　 298
14.2.1　判断主成分的个数　　298
14.2.2　提取主成分　　300
14.2.3　主成分旋转　　303
14.2.4　获取主成分得分　　304
14.3　探索性因子分析　　305
14.3.1　判断需提取的公共因子数　　306
14.3.2　提取公共因子　　307
14.3.3　因子旋转　　308
14.3.4　因子得分　　312
14.3.5　其他与EFA相关的包　　312
14.4　其他潜变量模型　　312
14.5　小结　　313
第15章　时间序列　　315
15.1　在R中生成时序对象　　317
15.2　时序的平滑化和季节性分解　　319
15.2.1　通过简单移动平均进行平滑处理　　319
15.2.2　季节性分解　　321
15.3　指数预测模型　　326
15.3.1　单指数平滑　　326
15.3.2　Holt指数平滑和Holt-Winters指数平滑　　 329
15.3.3　ets()函数和自动预测　　331
15.4　ARIMA 预测模型　　333
15.4.1　概念介绍　　333
15.4.2　ARMA和ARIMA模型　　334
15.4.3　ARIMA的自动预测　　339
15.5　延伸阅读　　340
15.6　小结　　340
第16章　聚类分析　　342
16.1　聚类分析的一般步骤　　343
16.2　计算距离　　344
16.3　层次聚类分析　　345
16.4　划分聚类分析　　350
16.4.1　K均值聚类　　350
16.4.2　围绕中心点的划分　　354
16.5　避免不存在的类　　356
16.6　小结　　359
第17章　分类　　360
17.1　数据准备　　361
17.2　逻辑回归　　362
17.3　决策树　　363
17.3.1　经典决策树　　364
17.3.2　条件推断树　　366
17.4　随机森林　　368
17.5　支持向量机　　370
17.6　选择预测效果最好的解　　374
17.7　用rattle包进行数据挖掘　　376
17.8　小结　　381
第18章　处理缺失数据的高级方法　　382
18.1　处理缺失值的步骤　　383
18.2　识别缺失值　　384
18.3　探索缺失值模式　　385
18.3.1　列表显示缺失值　　385
18.3.2　图形探究缺失数据　　386
18.3.3　用相关性探索缺失值　　389
18.4　理解缺失数据的来由和影响　　391
18.5　理性处理不完整数据　　 391
18.6　完整实例分析（行删除）　　392
18.7　多重插补　　394
18.8　处理缺失值的其他方法　　397
18.8.1　成对删除　　398
18.8.2　简单（非随机）插补　　398
18.9　小结　　399
第五部分 技能拓展
第19章　使用ggplot2进行高级绘图　　402
19.1　R 中的四种图形系统　　402
19.2　ggplot2包介绍　　403
19.3　用几何函数指定图的类型　　407
19.4　分组　　411
19.5　刻面　　413
19.6　添加光滑曲线　　416
19.7　修改ggplot2图形的外观　　418
19.7.1　坐标轴　　419
19.7.2　图例　　420
19.7.3　标尺　　421
19.7.4　主题　　423
19.7.5　多重图　　425
19.8　保存图形　　426
19.9　小结　　426
第20章　高级编程　　427
20.1　R 语言回顾　　427
20.1.1　数据类型　　427
20.1.2　控制结构　　433
20.1.3　创建函数　　436
20.2　环境　　437
20.3　面向对象的编程　　439
20.3.1　泛型函数　　439
20.3.2　S3模型的限制　　441
20.4　编写有效的代码　　442
20.5　调试　　445
20.5.1　常见的错误来源　　445
20.5.2　调试工具　　446
20.5.3　支持调试的会话选项　　448
20.6　深入学习　　451
20.7　小结　　451
第21章　创建包　　452
21.1　非参分析和npar包　　453
21.2　开发包　　457
21.2.1　计算统计量　　457
21.2.2　打印结果　　460
21.2.3　汇总结果　　461
21.2.4　绘制结果　　463
21.2.5　添加样本数据到包　　464
21.3　创建包的文档　　466
21.4　建立包　　467
21.5　深入学习　　471
21.6　小结　　471
第22章　创建动态报告　　472
22.1　用模版生成报告　　474
22.2　用R和Markdown创建动态报告　　475
22.3　用R和LaTeX创建动态报告　　480
22.4　用R和Open Document创建动态报告　　483
22.5　用R和Microsoft Word创建动态报告　　485
22.6　小结　　489
第23章　使用lattice进行高级绘图　　490
23.1　lattice包　　490
23.2　调节变量　　494
23.3　面板函数　　495
23.4　分组变量　　498
23.5　图形参数　　502
23.6　自定义图形条带　　503
23.7　页面布局　　504
23.8　深入学习　　507
附录A　图形用户界面　　508
附录B　自定义启动环境　　511
附录C　从R中导出数据　　513
附录D　R中的矩阵运算　　515
附录E　本书中用到的扩展包　　517
附录F　处理大数据集　　522
附录G　更新R　　526
后记：探索R的世界　　528
参考文献　　530
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言实战（第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>编程之法
作者简介 阅读
专业书评 阅读
内容提要 阅读
序一 阅读
序二 阅读
前言 阅读
第1章 字符串 阅读
第2章 数组
第3章 树
第4章 查找
第5章 动态规划
第6章 海量数据处理 阅读
第7章 机器学习
附录 其他题型
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>编程之法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB神经网络30个案例分析
第1章 P神经网络的数据分类——语音特征信号分类
第2章 BP神经网络的非线性系统建模——非线性函数拟合
第3章 遗传算法优化BP神经网络——非线性函数拟合
第4章 神经网络遗传算法函数极值寻优——非线性函数极值寻优
第5章 基于BP_Adaboost的强分类器设计——公司财务预警建模
第6章 PID神经元网络解耦控制算法——多变量系统控制
第7章 RBF网络的回归——非线性函数回归的实现
第8章 GRNN的数据预测——基于广义回归神经网络的货运量预测
第9章 离散Hopfield神经网络的联想记忆——数字识别
第10章 离散Hopfield神经网络的分类——高校科研能力评价
第11章 连续Hopfield神经网络的优化——旅行商问题优化计算
第12章 SVM的数据分类预测——意大利葡萄酒种类识别
第13章 SVM的参数优化——如何更好的提升分类器的性能
第14章 SVM的回归预测分析——上证指数开盘指数预测
第15章 SVM的信息粒化时序回归预测——上证指数开盘指数变化趋势和变化空间预测
第16章 自组织竞争网络在模式分类中的应用——患者癌症发病预测
第17章SOM神经网络的数据分类——柴油机故障诊断
第18章Elman神经网络的数据预测——电力负荷预测模型研究
第19章 概率神经网络的分类预测——基于PNN的变压器故障诊断
第20章 神经网络变量筛选——基于BP的神经网络变量筛选
第21章 LVQ神经网络的分类——乳腺肿瘤诊断
第22章 LVQ神经网络的预测——人脸朝向识别
第23章 小波神经网络的时间序列预测——短时交通流量预测
第24章 模糊神经网络的预测算法——嘉陵江水质评价
第25章 广义神经网络的聚类算法——网络入侵聚类
第26章 粒子群优化算法的寻优算法——非线性函数极值寻优
第27章 遗传算法优化计算——建模自变量降维
第28章 基于灰色神经网络的预测算法研究——订单需求预测
第29章 基于Kohonen网络的聚类算法——网络入侵聚类
第30章 神经网络GUI的实现——基于GUI的神经网络拟合、模式识别、聚类
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB神经网络30个案例分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>矩阵分析与应用（第2版）
第1章 矩阵代数基础
1.1 矩阵的基本运算
1.1.1 矩阵与向量
1.1.2 矩阵的基本运算
1.1.3 向量的线性无关性与非奇异矩阵
1.2 矩阵的初等变换
1.2.1 初等行变换与阶梯型矩阵
1.2.2 初等行变换的两个应用
1.2.3 初等列变换
1.3 向量空间、线性映射与Hilbert空间
1.3.1 集合的基本概念
1.3.2 向量空间
1.3.3 线性映射
1.3.4 内积空间、赋范空间与Hilbert空间
1.4 内积与范数
1.4.1 向量的内积与范数
1.4.2 向量的相似比较
1.4.3 矩阵的内积与范数
1.5 随机向量
1.5.1 概率密度函数
1.5.2 随机向量的统计描述
1.5.3 高斯随机向量
1.6 矩阵的性能指标
1.6.1 矩阵的二次型
1.6.2 行列式
1.6.3 矩阵的特征值
1.6.4 矩阵的迹
1.6.5 矩阵的秩
1.7 逆矩阵与伪逆矩阵
1.7.1 逆矩阵的定义与性质
1.7.2 矩阵求逆引理
1.7.3 左逆矩阵与右逆矩阵
1.8 Moore-Penrose逆矩阵
1.8.1 Moore-Penrose逆矩阵的定义与性质
1.8.2 Moore-Penrose逆矩阵的计算
1.8.3 非一致方程的最小范数最小二乘解
1.9 矩阵的直和与Hadamard积
1.9.1 矩阵的直和
1.9.2 Hadamard积
1.10 Kronecker积与Khatri-Rao积
1.10.1 Kronecker积及其性质
1.10.2 广义Kronecner积
1.10.3 Khatri-Rao积
1.11 向量化与矩阵化
1.11.1 矩阵的向量化与向量的矩阵化
1.11.2 向量化算子的性质
1.12 稀疏表示与压缩感知
1.12.1 稀疏向量与稀疏表示
1.12.2 人脸识别的稀疏表示
1.12.3 稀疏编码
1.12.4 压缩感知的稀疏表示
本章小结
习题
第2章 特殊矩阵
2.1 Hermitian矩阵
2.2 置换矩阵、互换矩阵与选择矩阵
2.2.1 置换矩阵与互换矩阵
2.2.2 广义置换矩阵与选择矩阵
2.3 正交矩阵与酉矩阵
2.4 带型矩阵与三角矩阵
2.4.1 带型矩阵
2.4.2 三角矩阵
2.5 求和向量与中心化矩阵
2.5.1 求和向量
2.5.2 中心化矩阵
2.6 相似矩阵与相合矩阵
2.6.1 相似矩阵
2.6.2 相合矩阵
2.7 Vandermonde矩阵
2.8 Fourier矩阵
2.8.1 Fourier矩阵的定义与性质
……
第3章 矩阵微分
第4章 梯度分析与最优化
第5章 奇异值分析
第6章 矩阵方程求解
第7章 特征分析
第8章 子空间分析与跟踪
第9章 投影分析
第10章 张量分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>矩阵分析与应用（第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>集体智慧编程
前言.................................................................................................................... viii
第1章 集体智慧导言......................................................................................... 1
什么是集体智慧......................................................................................................................2
什么是机器学习......................................................................................................................3
机器学习的局限......................................................................................................................4
真实生活中的例子..................................................................................................................5
学习型算法的其他用途..........................................................................................................5
第2章 提供推荐................................................................................................ 7
协作型过滤..............................................................................................................................7
搜集偏好.................................................................................................................................8
寻找相近的用户......................................................................................................................9
推荐物品...............................................................................................................................15
匹配商品...............................................................................................................................17
构建一个基于del.icio.us的链接推荐系统..........................................................................19
基于物品的过滤....................................................................................................................22
使用MovieLens数据集........................................................................................................25
基于用户进行过滤还是基于物品进行过滤........................................................................27
练习.......................................................................................................................................28
第3章 发现群组.............................................................................................. 29
监督学习和无监督学习........................................................................................................29
单词向量...............................................................................................................................30
分级聚类...............................................................................................................................33
绘制树状图............................................................................................................................38
列聚类...................................................................................................................................40
K-均值聚类............................................................................................................................42
针对偏好的聚类....................................................................................................................44
以二维形式展现数据............................................................................................................49
有关聚类的其他事宜............................................................................................................53
练习.......................................................................................................................................53
第4章 搜索与排名.......................................................................................... 54
搜索引擎的组成....................................................................................................................54
一个简单的爬虫程序............................................................................................................56
建立索引...............................................................................................................................58
查询.......................................................................................................................................63
基于内容的排名....................................................................................................................64
利用外部回指链接................................................................................................................69
从点击行为中学习................................................................................................................74
练习.......................................................................................................................................84
第5章 优化..................................................................................................... 86
组团旅游...............................................................................................................................87
描述题解...............................................................................................................................88
成本函数...............................................................................................................................89
随机搜索...............................................................................................................................91
爬山法...................................................................................................................................92
模拟退火算法........................................................................................................................95
遗传算法...............................................................................................................................97
真实的航班搜索..................................................................................................................101
涉及偏好的优化..................................................................................................................106
网络可视化..........................................................................................................................110
其他可能的应用场合..........................................................................................................115
练习.....................................................................................................................................116
第6章 文档过滤.............................................................................................117
过滤垃圾信息......................................................................................................................117
文档和单词..........................................................................................................................118
对分类器进行训练..............................................................................................................119
计算概率..............................................................................................................................121
朴素分类器..........................................................................................................................123
费舍尔方法..........................................................................................................................127
将经过训练的分类器持久化..............................................................................................132
过滤博客订阅源..................................................................................................................134
对特征检测的改进..............................................................................................................136
使用Akismet........................................................................................................................138
替代方法..............................................................................................................................139
练习.....................................................................................................................................140
第7章 决策树建模........................................................................................ 142
预测注册用户......................................................................................................................142
引入决策树..........................................................................................................................144
对树进行训练......................................................................................................................145
选择最合适的拆分方案......................................................................................................147
以递归方式构造树..............................................................................................................149
决策树的显示......................................................................................................................151
对新的观测数据进行分类..................................................................................................153
决策树的剪枝......................................................................................................................154
处理缺失数据......................................................................................................................156
处理数值型结果..................................................................................................................158
对住房价格进行建模..........................................................................................................158
对“热度”评价进行建模..................................................................................................161
什么时候使用决策树..........................................................................................................164
练习.....................................................................................................................................165
第8章 构建价格模型..................................................................................... 167
构造一个样本数据集..........................................................................................................167
k-最近邻算法.......................................................................................................................169
为近邻分配权重..................................................................................................................172
交叉验证..............................................................................................................................176
不同类型的变量..................................................................................................................178
对缩放结果进行优化..........................................................................................................181
不对称分布..........................................................................................................................183
使用真实数据——eBay API...............................................................................................189
何时使用k-最近邻算法......................................................................................................195
练习.....................................................................................................................................196
第9章 高阶分类：核方法与SVM ................................................................. 197
婚介数据集..........................................................................................................................197
数据中的难点......................................................................................................................199
基本的线性分类..................................................................................................................202
分类特征..............................................................................................................................205
对数据进行缩放处理..........................................................................................................209
理解核方法..........................................................................................................................211
支持向量机..........................................................................................................................215
使用LIBSVM......................................................................................................................217
基于Facebook的匹配........................................................................................................219
练习.....................................................................................................................................225
第10章 寻找独立特征................................................................................... 226
搜集一组新闻......................................................................................................................227
先前的方法..........................................................................................................................231
非负矩阵因式分解..............................................................................................................232
结果呈现..............................................................................................................................240
利用股票市场的数据..........................................................................................................243
练习.....................................................................................................................................248
第11章 智能进化.......................................................................................... 250
什么是遗传编程..................................................................................................................250
将程序以树形方式表示......................................................................................................253
构造初始种群......................................................................................................................257
测试题解..............................................................................................................................259
对程序进行变异..................................................................................................................260
交叉.....................................................................................................................................263
构筑环境..............................................................................................................................265
一个简单的游戏..................................................................................................................268
更多可能性..........................................................................................................................273
练习.....................................................................................................................................276
第12章 算法总结.......................................................................................... 277
贝叶斯分类器......................................................................................................................277
决策树分类器......................................................................................................................281
神经网络..............................................................................................................................285
支持向量机..........................................................................................................................289
k-最近邻...............................................................................................................................293
聚类.....................................................................................................................................296
多维缩放..............................................................................................................................300
非负矩阵因式分解..............................................................................................................302
优化.....................................................................................................................................304
附录A：第三方函数库..................................................................................... 309
附录B：数学公式............................................................................................. 316
索引.................................................................................................................. 323
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>集体智慧编程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark高级数据分析
推荐序　　ix
译者序　　xi
序　　xiii
前言　　xv
第1章　大数据分析　　1
1.1　数据科学面临的挑战　　2
1.2　认识Apache Spark　　4
1.3　关于本书　　5
第2章　用Scala和Spark进行数据分析　　7
2.1　数据科学家的Scala　　8
2.2　Spark 编程模型　　9
2.3　记录关联问题　　9
2.4　小试牛刀：Spark shell和SparkContext　　10
2.5　把数据从集群上获取到客户端　　15
2.6　把代码从客户端发送到集群　　18
2.7　用元组和case class对数据进行结构化　　19
2.8　聚合　　23
2.9　创建直方图　　24
2.10　连续变量的概要统计　　25
2.11　为计算概要信息创建可重用的代码　　26
2.12　变量的选择和评分简介　　30
2.13　小结　　31
第3章　音乐推荐和Audioscrobbler数据集　　33
3.1　数据集　　34
3.2　交替最小二乘推荐算法　　35
3.3　准备数据　　37
3.4　构建第一个模型　　39
3.5　逐个检查推荐结果　　42
3.6　评价推荐质量　　43
3.7　计算AUC　　44
3.8　选择超参数　　46
3.9　产生推荐　　48
3.10　小结　　49
第4章　 用决策树算法预测森林植被　　51
4.1　回归简介　　52
4.2　向量和特征　　52
4.3　样本训练　　53
4.4　决策树和决策森林　　54
4.5　Covtype数据集　　56
4.6　准备数据　　57
4.7　第一棵决策树　　58
4.8　决策树的超参数　　62
4.9　决策树调优　　63
4.10　重谈类别型特征　　65
4.11　随机决策森林　　67
4.12　进行预测　　69
4.13　小结　　69
第5章　基于K均值聚类的网络流量异常检测　　71
5.1　异常检测　　72
5.2　K均值聚类　　72
5.3　网络入侵　　73
5.4　KDD Cup 1999数据集　　73
5.5　初步尝试聚类　　74
5.6　K 的选择　　76
5.7　基于R的可视化　　79
5.8　特征的规范化　　81
5.9　类别型变量　　83
5.10　利用标号的熵信息　　84
5.11　聚类实战　　85
5.12　小结　　86
第6章　基于潜在语义分析算法分析维基百科　　89
6.1　词项-文档矩阵　　90
6.2　获取数据　　91
6.3　分析和准备数据　　92
6.4　词形归并　　93
6.5　计算TF-IDF　　94
6.6　奇异值分解　　97
6.7　找出重要的概念　　98
6.8　基于低维近似的查询和评分　　101
6.9　词项-词项相关度　　102
6.10　文档-文档相关度　　103
6.11　词项-文档相关度　　105
6.12　多词项查询　　106
6.13　小结　　107
第7章　用GraphX分析伴生网络　　109
7.1　对MEDLINE文献引用索引的网络分析　　110
7.2　获取数据　　111
7.3　用Scala XML工具解析XML文档　　113
7.4　分析MeSH主要主题及其伴生关系　　114
7.5　用GraphX来建立一个伴生网络　　116
7.6　理解网络结构　　119
7.6.1　连通组件　　119
7.6.2　度的分布　　122
7.7　过滤噪声边　　124
7.7.1　处理EdgeTriplet　　125
7.7.2　分析去掉噪声边的子图　　126
7.8　小世界网络　　127
7.8.1　系和聚类系数　　128
7.8.2　用Pregel计算平均路径长度　　129
7.9　小结　　133
第8章　纽约出租车轨迹的空间和时间数据分析　　135
8.1　数据的获取　　136
8.2　基于Spark的时间和空间数据分析　　136
8.3　基于JodaTime和NScalaTime的时间数据处理　　137
8.4　基于Esri Geometry API和Spray的地理空间数据处理　　138
8.4.1　认识Esri Geometry API　　139
8.4.2　GeoJSON简介　　140
8.5　纽约市出租车客运数据的预处理　　142
8.5.1　大规模数据中的非法记录处理　　143
8.5.2　地理空间分析　　147
8.6　基于Spark的会话分析　　149
8.7　小结　　153
第9章　基于蒙特卡罗模拟的金融风险评估　　155
9.1　术语　　156
9.2　VaR计算方法　　157
9.2.1　方差-协方差法　　157
9.2.2　历史模拟法　　157
9.2.3　蒙特卡罗模拟法　　157
9.3　我们的模型　　158
9.4　获取数据　　158
9.5　数据预处理　　159
9.6　确定市场因素的权重　　162
9.7　采样　　164
9.8　运行试验　　167
9.9　回报分布的可视化　　170
9.10　结果的评估　　171
9.11　小结　　173
第10章　基因数据分析和BDG项目　　175
10.1　分离存储与模型　　176
10.2　用ADAM CLI导入基因学数据　　178
10.3　从ENCODE数据预测转录因子结合位点　　185
10.4　查询1000 Genomes项目中的基因型　　191
10.5　小结　　193
第11章　基于PySpark和Thunder的神经图像数据分析　　195
11.1　PySpark简介　　196
11.2　Thunder工具包概况和安装　　199
11.3　用Thunder加载数据　　200
11.4　用Thunder对神经元进行分类　　207
11.5　小结　　211
附录A　Spark进阶　　213
附录B　即将发布的MLlib Pipelines API　　221
作者介绍　　226
封面介绍　　226
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark高级数据分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言处理综论（第二版）
第1章导论
1.1语音与语言处理中的知识
1.2歧义
1.3模型和算法
1.4语言、思维和理解
1.5学科现状与近期发展
1.6语音和语言处理简史
1.6.1基础研究：20世纪40年代和20世纪50年代
1.6.2两个阵营：1957年至1970年
1.6.3四个范型：1970年至1983年
1.6.4经验主义和有限状态模型的复苏：1983年至1993年
1.6.5不同领域的合流：1994年至1999年
1.6.6机器学习的兴起：2000年至2008年
1.6.7关于多重发现
1.6.8心理学的简要注记
1.7小结
1.8文献和历史说明
第一部分词汇的计算机处理
第2章正则表达式与自动机
2.1正则表达式
2.1.1基本正则表达式模式
2.1.2析取、组合与优先关系
2.1.3一个简单的例子
2.1.4一个比较复杂的例子
2.1.5高级算符
2.1.6正则表达式中的替换、存储器与ELIZA
2.2有限状态自动机
2.2.1用FSA来识别羊的语言
2.2.2形式语言
2.2.3其他例子
2.2.4非确定FSA
2.2.5使用NFSA接收符号串
2.2.6识别就是搜索
2.2.7确定自动机与非确定自动机的关系
2.3正则语言与FSA
2.4小结
2.5文献和历史说明
第3章词与转录机
3.1英语形态学概观
3.1.1屈折形态学
3.1.2派生形态学
3.1.3附着
3.1.4非毗连形态学
3.1.5一致关系
3.2有限状态形态剖析
3.3有限状态词表的建造
3.4有限状态转录机
3.4.1定序转录机和确定性
3.5用于形态剖析的FST
3.6转录机和正词法规则
3.7把FST词表与规则相结合
3.8与词表无关的FST：Porter词干处理器
3.9单词和句子的词例还原
3.9.1中文的自动切词
3.10拼写错误的检查与更正
3.11最小编辑距离
3.12人是怎样进行形态处理的
3.13小结
3.14文献和历史说明
第4章N元语法
4.1语料库中单词数目的计算
4.2简单的（非平滑的）N元语法
4.3训练集和测试集
4.3.1N元语法及其对训练语料库的敏感性
4.3.2未知词：开放词汇与封闭词汇
4.4N元语法的评测：困惑度
4.5平滑
4.5.1Laplace平滑
4.5.2GoodTuring打折法
4.5.3GoodTuring估计的一些高级专题
4.6插值法
4.7回退法
4.7.1高级专题：计算Katz回退的α和P*
4.8实际问题：工具包和数据格式
4.9语言模型建模中的高级专题
4.9.1高级的平滑方法：KneserNey平滑法
4.9.2基于类别的N元语法
4.9.3语言模型的自适应和网络（Web）应用
4.9.4长距离信息的使用：简要的综述
4.10信息论背景
4.10.1用于比较模型的交叉熵
4.11高级问题：英语的熵和熵率均衡性
4.12小结
4.13文献和历史说明
第5章词类标注
5.1（大多数）英语词的分类
5.2英语的标记集
5.3词类标注
5.4基于规则的词类标注
5.5基于隐马尔可夫模型的词类标注
5.5.1计算最可能的标记序列：一个实例
5.5.2隐马尔可夫标注算法的形式化
5.5.3使用Viterbi算法来进行HMM标注
5.5.4把HMM扩充到三元语法
5.6基于转换的标注
5.6.1怎样应用TBL规则
5.6.2怎样学习TBL规则
5.7评测和错误分析
5.7.1错误分析
5.8词类标注中的高级专题
5.8.1实际问题：标记的不确定性与词例还原
5.8.2未知词
5.8.3其他语言中的词类标注
5.8.4标注算法的结合
5.9高级专题：拼写中的噪声信道模型
5.9.1上下文错拼更正
5.10小结
5.11文献和历史说明
第6章隐马尔可夫模型与最大熵模型
6.1马尔可夫链
6.2隐马尔可夫模型
6.3似然度的计算：向前算法
6.4解码：Viterbi算法
6.5HMM的训练：向前向后算法
6.6最大熵模型：背景
6.6.1线性回归
6.6.2逻辑回归
6.6.3逻辑回归：分类
6.6.4高级专题：逻辑回归的训练
6.7最大熵模型
6.7.1为什么称为最大熵
6.8最大熵马尔可夫模型
6.8.1MEMM的解码和训练
6.9小结
6.10文献和历史说明
第二部分语音的计算机处理
第7章语音学
7.1言语语音与语音标音法
7.2发音语音学
7.2.1发音器官
7.2.2辅音：发音部位
7.2.3辅音：发音方法
7.2.4元音
7.2.5音节
7.3音位范畴与发音变异
7.3.1语音特征
7.3.2语音变异的预测
7.3.3影响语音变异的因素
7.4声学语音学和信号
7.4.1波
7.4.2语音的声波
7.4.3频率与振幅：音高和响度
7.4.4从波形来解释音子
7.4.5声谱和频域
7.4.6声源滤波器模型
7.5语音资源
7.6高级问题：发音音系学与姿态音系学
7.7小结
7.8文献和历史说明
第8章语音合成
8.1文本归一化
8.1.1句子的词例还原
8.1.2非标准词
8.1.3同形异义词的排歧
8.2语音分析
8.2.1查词典
8.2.2名称
8.2.3字位—音位转换
8.3韵律分析
8.3.1韵律的结构
8.3.2韵律的突显度
8.3.3音调
8.3.4更精巧的模型：ToBI
8.3.5从韵律标记计算音延
8.3.6从韵律标记计算F0
8.3.7文本分析的最后结果：内部表示
8.4双音子波形合成
8.4.1建立双音子数据库的步骤
8.4.2双音子毗连和用于韵律的TD—PSOLA
8.5单元选择（波形）合成
8.6评测
8.7文献和历史说明
第9章语音自动识别
9.1语音识别的总体结构
9.2隐马尔可夫模型应用于语音识别
9.3特征抽取：MFCC矢量
9.3.1预加重
9.3.2加窗
9.3.3离散傅里叶变换
9.3.4Mel滤波器组和对数
9.3.5倒谱：逆向傅里叶变换
9.3.6Delta特征与能量
9.3.7总结：MFCC
9.4声学似然度的计算
9.4.1矢量量化
9.4.2高斯概率密度函数
9.4.3概率、对数概率和距离函数
9.5词典和语言模型
9.6搜索与解码
9.7嵌入式训练
9.8评测：词错误率
9.9小结
9.10文献和历史说明
第10章语音识别：高级专题
10.1多遍解码：N最佳表和格
10.2A*解码算法（“栈”解码算法）
10.3依赖于上下文的声学模型：三音子
10.4分辨训练
10.4.1最大互信息估计
10.4.2基于后验分类器的声学模型
10.5语音变异的建模
10.5.1环境语音变异和噪声
10.5.2说话人变异和说话人适应
10.5.3发音建模：由于语类的差别而产生的变异
10.6元数据：边界、标点符号和不流利现象
10.7人的语音识别
10.8小结
10.9文献和历史说明
第11章计算音系学
11.1有限状态音系学
11.2高级有限状态音系学
11.2.1元音和谐
11.2.2模板式形态学
11.3计算优选理论
11.3.1优选理论中的有限状态转录机模型
11.3.2优选理论的随机模型
11.4音节切分
11.5音位规则和形态规则的机器学习
11.5.1音位规则的机器学习
11.5.2形态规则的机器学习
11.5.3优选理论中的机器学习
11.6小结
11.7文献和历史说明
第三部分句法的计算机处理
第12章英语的形式语法
12.1组成性
12.2上下文无关语法
12.2.1上下文无关语法的形式定义
12.3英语的一些语法规则
12.3.1句子一级的结构
12.3.2子句与句子
12.3.3名词短语
12.3.4一致关系
12.3.5动词短语和次范畴化
12.3.6助动词
12.3.7并列关系
12.4树库
12.4.1树库的例子：宾州树库课题
12.4.2作为语法的树库
12.4.3树库搜索
12.4.4中心词与中心词的发现
12.5语法等价与范式
12.6有限状态语法和上下文无关语法
12.7依存语法
12.7.1依存和中心词之间的关系
12.7.2范畴语法
12.8口语的句法
12.8.1不流畅现象与口语修正
12.8.2口语树库
12.9语法和人的语言处理
12.10小结
12.11文献和历史说明
第13章句法剖析
13.1剖析就是搜索
13.1.1自顶向下剖析
13.1.2自底向上剖析
13.1.3自顶向下剖析与自底向上剖析比较
13.2歧义
13.3面对歧义的搜索
13.4动态规划剖析方法
13.4.1CKY剖析
13.4.2Earley算法
13.4.3线图剖析
13.5局部剖析
13.5.1基于规则的有限状态组块分析
13.5.2基于机器学习的组块分析方法
13.5.3组块分析系统的评测
13.6小结
13.7文献和历史说明
第14章统计剖析
14.1概率上下文无关语法
14.1.1PCFG用于排歧
14.1.2PCFG用于语言建模
14.2PCFG的概率CKY剖析
14.3PCFG规则概率的学习途径
14.4PCFG的问题
14.4.1独立性假设忽略了规则之间的结构依存关系
14.4.2缺乏对词汇依存关系的敏感性
14.5使用分离非终极符号的办法来改进PCFG
14.6概率词汇化的CFG
14.6.1Collins剖析器
14.6.2高级问题：Collins剖析器更多的细节
14.7剖析器的评测
14.8高级问题：分辨再排序
14.9高级问题：基于剖析器的语言模型
14.10人的剖析
14.11小结
14.12文献和历史说明
第15章特征与合一
15.1特征结构
15.2特征结构的合一
15.3语法中的特征结构
15.3.1一致关系
15.3.2中心语特征
15.3.3次范畴化
15.3.4长距离依存关系
15.4合一的实现
15.4.1合一的数据结构
15.4.2合一算法
15.5带有合一约束的剖析
15.5.1把合一结合到Earley剖析器中
15.5.2基于合一的剖析
15.6类型与继承
15.6.1高级问题：类型的扩充
15.6.2合一的其他扩充
15.7小结
15.8文献和历史说明
第16章语言和复杂性
16.1Chomsky层级
16.2怎么判断一种语言不是正则的
16.2.1抽吸引理
16.2.2证明各种自然语言不是正则语言
16.3自然语言是上下文无关的吗
16.4计算复杂性和人的语言处理
16.5小结
16.6文献和历史说明
第四部分语义和语用的计算机处理
第17章意义的表示
17.1意义表示的计算要求
17.1.1可验证性
17.1.2无歧义性
17.1.3规范形式
17.1.4推理与变量
17.1.5表达能力
17.2模型论语义学
17.3一阶逻辑
17.3.1一阶逻辑基础
17.3.2变量和量词
17.3.3λ表示法
17.3.4一阶逻辑的语义
17.3.5推理
17.4事件与状态的表示
17.4.1时间表示
17.4.2体
17.5描述逻辑
17.6意义的具体化与情境表示方法
17.7小结
17.8文献和历史说明
第18章计算语义学
18.1句法驱动的语义分析
18.2句法规则的语义扩充
18.3量词辖域歧义及非确定性
18.3.1存储与检索方法
18.3.2基于约束的方法
18.4基于合一的语义分析方法
18.5语义与Earley分析器的集成
18.6成语和组成性
18.7小结
18.8文献和历史说明
第19章词汇语义学
19.1词义
19.2含义间的关系
19.2.1同义关系和反义关系
19.2.2上下位关系
19.2.3语义场
19.3WordNet：词汇关系信息库
19.4事件参与者
19.4.1题旨角色
19.4.2因素交替（DiathesisAlternations）
19.4.3题旨角色的问题
19.4.4命题库
19.4.5FrameNet
19.4.6选择限制
19.5基元分解
19.6高级问题：隐喻
19.7小结
19.8文献和历史说明
第20章计算词汇语义学
20.1词义排歧：综述
20.2有监督词义排歧
20.2.1监督学习的特征抽取
20.2.2朴素贝叶斯分类器和决策表分类器
20.3WSD评价方法、基准线和上限
20.4WSD：字典方法和同义词库方法
20.4.1Lesk算法
20.4.2选择限制和选择优先度
20.5最低限度的监督WSD：自举法
20.6词语相似度：语义字典方法
20.7词语相似度：分布方法
20.7.1定义词语的共现向量
20.7.2度量与上下文的联系
20.7.3定义两个向量之间的相似度
20.7.4评价分布式词语相似度
20.8下位关系和其他词语关系
20.9语义角色标注
20.10高级主题：无监督语义排歧
20.11小结
20.12文献和历史说明
第21章计算话语学
21.1话语分割
21.1.1无监督话语分割
21.1.2有监督话语分割
21.1.3话语分割的评价
21.2文本连贯性
21.2.1修辞结构理论
21.2.2自动连贯指派
21.3指代消解
21.4指代现象
21.4.1指示语的五种类型
21.4.2信息状态
21.5代词指代消解所使用的特征
21.5.1用来过滤潜在指代对象的特征
21.5.2代词解释中的优先关系
21.6指代消解的三种算法
21.6.1代词指代基准系统：Hobbs算法
21.6.2指代消解的中心算法
21.6.3代词指代消解的对数线性模型
21.6.4代词指代消解的特征
21.7共指消解
21.8共指消解的评价
21.9高级问题：基于推理的连贯判定
21.10所指的心理语言学研究
21.11小结
21.12文献和历史说明
第五部分应用
第22章信息抽取
22.1命名实体识别
22.1.1命名实体识别中的歧义
22.1.2基于序列标注的命名实体识别
22.1.3命名实体识别的评价
22.1.4实用NER架构
22.2关系识别和分类
22.2.1用于关系分析的有监督学习方法
22.2.2用于关系分析的弱监督学习方法
22.2.3关系分析系统的评价
22.3时间和事件处理
22.3.1时间表达式的识别
22.3.2时间的归一化
22.3.3事件检测和分析
22.3.4TimeBank
22.4模板填充
22.4.1模板填充的统计方法
22.4.2有限状态机模板填充系统
22.5高级话题：生物医学信息的抽取
22.5.1生物学命名实体识别
22.5.2基因归一化
22.5.3生物学角色和关系
22.6小结
22.7文献和历史说明
第23章问答和摘要
23.1信息检索
23.1.1向量空间模型
23.1.2词语权重计算
23.1.3词语选择和建立
23.1.4信息检索系统的评测
23.1.5同形关系、多义关系和同义关系
23.1.6改进用户查询的方法
23.2事实性问答
23.2.1问题处理
23.2.2段落检索
23.2.3答案处理
23.2.4事实性答案的评价
23.3摘要
23.4单文档摘要
23.4.1无监督的内容选择
23.4.2基于修辞分析的无监督摘要
23.4.3有监督的内容选择
23.4.4句子简化
23.5多文档摘要
23.5.1多文档摘要的内容选择
23.5.2多文档摘要的信息排序
23.6主题摘要和问答
23.7摘要的评价
23.8小结
23.9文献和历史说明
第24章对话与会话智能代理
24.1人类会话的属性
24.1.1话轮和话轮转换
24.1.2语言作为行动：言语行为
24.1.3语言作为共同行动：对话的共同基础
24.1.4会话结构
24.1.5会话隐含
24.2基本的对话系统
24.2.1ASR组件
24.2.2NLU组件
24.2.3生成和TTS组件
24.2.4对话管理器
24.2.5错误处理：确认和拒绝
24.3VoiceXML
24.4对话系统的设计和评价
24.4.1设计对话系统
24.4.2评价对话系统
24.5信息状态和对话行为
24.5.1使用对话行为
24.5.2解释对话行为
24.5.3检测纠正行为
24.5.4生成对话行为：确认和拒绝
24.6马尔可夫决策过程架构
24.7高级问题：基于规划的对话行为
24.7.1规划推理解释和生成
24.7.2对话的意图结构
24.8小结
24.9文献和历史说明
第25章机器翻译
25.1为什么机器翻译如此困难
25.1.1类型学
25.1.2其他的结构差异
25.1.3词汇的差异
25.2经典的机器翻译方法与Vauquois三角形
25.2.1直接翻译
25.2.2转换方法
25.2.3传统机器翻译系统中的直接和转换相融合的方法
25.2.4中间语言的思想：使用意义
25.3统计机器翻译
25.4P（F|E）：基于短语的翻译模型
25.5翻译中的对齐
25.5.1IBM模型1
25.5.2HMM对齐
25.6对齐模型的训练
25.6.1训练对齐模型的EM算法
25.7用于基于短语机器翻译的对称对齐
25.8基于短语统计机器翻译的解码
25.9机器翻译评价
25.9.1使用人工评价者
25.9.2自动评价：BLEU
25.10高级问题：机器翻译的句法模型
25.11高级问题：IBM模型3和繁衍度
25.11.1模型3的训练
25.12高级问题：机器翻译的对数线性模型
25.13小结
25.14文献和历史说明
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言处理综论（第二版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>最优化导论
第一部分数学知识回顾
第1章证明方法与相关记法
1.1证明方法
1.2记法
习题
第2章向量空间与矩阵
2.1向量与矩阵
2.2矩阵的秩
2.3线性方程组
2.4内积和范数
习题
第3章变换
3.1线性变换
3.2特征值与特征向量
3.3正交投影
3.4二次型函数
3.5矩阵范数
习题
第4章有关几何概念
4.1线段
4.2超平面与线性簇
4.3凸集
4.4邻域
4.5多面体和多胞形
习题
第5章微积分基础
5.1序列与极限
5.2可微性
5.3导数矩阵
5.4微分法则
5.5水平集与梯度
5.6泰勒级数
习题
第二部分无约束优化问题
第6章集合约束和无约束优化问题的基础知识
6.1引言
6.2局部极小点的条件
习题
第7章一维搜索方法
7.1引言
7.2黄金分割法
7.3斐波那契数列法
7.4二分法
7.5牛顿法
7.6割线法
7.7划界法
7.8多维优化问题中的一维搜索
习题
第8章梯度方法
8.1引言
8.2最速下降法
8.3梯度方法性质分析
习题
第9章牛顿法
9.1引言
9.2牛顿法性质分析
9.3Levenberg Marquardt修正
9.4牛顿法在非线性最小二乘问题中的应用
习题
第10章共轭方向法
10.1引言
10.2基本的共轭方向算法
10.3共轭梯度法
10.4非二次型问题中的共轭梯度法
习题
第11章拟牛顿法
11.1引言
11.2黑塞矩阵逆矩阵的近似
11.3秩1修正公式
11.4DFP算法
11.5BFGS算法
习题
第12章求解线性方程组
12.1最小二乘分析
12.2递推最小二乘算法
12.3线性方程组的最小范数解
12.4Kaczmarz算法
12.5一般意义下的线性方程组的求解
习题
第13章无约束优化问题和神经网络
13.1引言
13.2单个神经元训练
13.3反向传播算法
习题
第14章全局搜索算法
14.1引言
14.2Nelder Mead单纯形法
14.3模拟退火法
14.4粒子群优化算法
14.5遗传算法
习题
第三部分线 性 规 划
第15章线性规划概述
15.1线性规划简史
15.2线性规划的简单例子
15.3二维线性规划
15.4凸多面体和线性规划
15.5线性规划问题的标准型
15.6基本解
15.7基本解的性质
15.8几何视角下的线性规划
习题
第16章单纯形法
16.1利用行变换求解线性方程组
16.2增广矩阵的规范型
16.3更新增广矩阵
16.4单纯形法
16.5单纯形法的矩阵形式
16.6两阶段单纯形法
16.7修正单纯形法
习题
第17章对偶
17.1对偶线性规划
17.2对偶问题的性质
习题
第18章非单纯形法
18.1引言
18.2Khachiyan算法
18.3仿射尺度法
18.4Karmarkar算法
习题
第19章整数规划
19.1概述
19.2幺模矩阵
19.3Gomory割平面法
习题
第四部分有约束的非线性优化问题
第20章仅含等式约束的优化问题
20.1引言
20.2问题描述
20.3切线空间和法线空间
20.4拉格朗日条件
20.5二阶条件
20.6线性约束下二次型函数的极小化
习题
第21章含不等式约束的优化问题
21.1卡罗需库恩塔克（Karush Kuhn Tucker）条件
21.2二阶条件
习题
第22章凸优化问题
22.1引言
22.2凸函数
22.3凸优化问题
22.4半定规划
习题
第23章有约束优化问题的求解算法
23.1引言
23.2投影法
23.3求解含线性约束优化问题的投影梯度法
23.4拉格朗日法
23.5罚函数法
习题
第24章多目标优化
24.1引言
24.2帕累托解
24.3帕累托前沿的求解
24.4多目标优化到单目标优化的转换
24.5存在不确定性的线性规划
习题
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>最优化导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
第一篇 技术篇：颠覆性技术的真相
第一章 认知鸿沟下的人工智能
第二章 人工智能的过去
第三章 人工智能的现在与未来
第二篇 产业篇：人工智能发展全貌
第四章 人工智能产业发展概况
第五章 自动驾驶
第六章 智能机器人
第七章 智能医疗
第八章 智能投顾
第九章 虚拟现实和增强现实
第十章 智能家居
第十一章 无人飞行器
第十二章 人工智能创业
第三篇 战略篇：细看各国如何布局
第十三章 顶层设计
第十四章 资本的力量
第十五章 有形的手
第十六章 善良的AI
第十七章 人才争夺战
第四篇 法律篇：智能时代的公平正义
第十八章 AI要怎么负责？
第十九章 隐私深处的忧虑
第二十章 看不见的非正义
第二十一章 作者之死
第二十二章 我是谁？
第二十三章 法律人工智能十大趋势
第五篇 伦理篇：人类价值与人机关系
第二十四章 道德机器
第二十五章 人工智能23条“军规”
第二十六章 未来人机关系
第六篇 治理篇：平衡发展与规制
第二十七章 从互联网治理到AI治理
第二十八章 AI治理的挑战
第二十九章 AI之治
第七篇 未来篇：畅想未来AI社会
第三十章 砸了谁的饭碗？
第三十一章 战争机器人
第三十二章 灵魂伴侣
第三十三章 新的生产力
附件
附件1 合伦理设计：利用人工智能和自主系统（AI/AS）最大化人类福祉的愿景
附件2 美国国家创新战略
附件3 2016美国机器人发展路线图
附件4 美国国家人工智能研究和发展战略计划
附件5 欧盟机器人研发计划
附件6 英国人工智能的未来监管措施与目标概述
附件7 日本机器人战略
附件8 联合国的人工智能政策
附件9 国外部分智能投顾平台
注释
后记
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据挖掘入门与实践
第1章 　开始数据挖掘之旅　　1
1.1 　数据挖掘简介　　1
1.2 　使用Python和IPython Notebook　　2
1.2.1 　安装Python　　2
1.2.2 　安装IPython　　4
1.2.3 　安装scikit-learn库　　5
1.3 　亲和性分析示例　　5
1.3.1 　什么是亲和性分析　　5
1.3.2 　商品推荐　　6
1.3.3 　在NumPy中加载数据集　　6
1.3.4 　实现简单的排序规则　　8
1.3.5 　排序找出最佳规则　　10
1.4 　分类问题的简单示例　　12
1.5 　什么是分类　　12
1.5.1 　准备数据集　　13
1.5.2 　实现OneR算法　　14
1.5.3 　测试算法　　16
1.6 　小结　　18
第2章 　用scikit-learn估计器分类　　19
2.1 　scikit-learn估计器　　19
2.1.1 　近邻算法　　20
2.1.2 　距离度量　　20
2.1.3 　加载数据集　　22
2.1.4 　努力实现流程标准化　　24
2.1.5 　运行算法　　24
2.1.6 　设置参数　　25
2.2 　流水线在预处理中的应用　　27
2.2.1 　预处理示例　　28
2.2.2 　标准预处理　　28
2.2.3 　组装起来　　29
2.3 　流水线　　29
2.4 　小结　　30
第3章 　用决策树预测获胜球队　　31
3.1 　加载数据集　　31
3.1.1 　采集数据　　31
3.1.2 　用pandas加载数据集　　32
3.1.3 　数据集清洗　　33
3.1.4 　提取新特征　　34
3.2 　决策树　　35
3.2.1 　决策树中的参数　　36
3.2.2 　使用决策树　　37
3.3 　NBA比赛结果预测　　37
3.4 　随机森林　　41
3.4.1 　决策树的集成效果如何　　42
3.4.2 　随机森林算法的参数　　42
3.4.3 　使用随机森林算法　　43
3.4.4 　创建新特征　　44
3.5 　小结　　45
第4章 　用亲和性分析方法推荐电影　　46
4.1 　亲和性分析　　46
4.1.1 　亲和性分析算法　　47
4.1.2 　选择参数　　47
4.2 　电影推荐问题　　48
4.2.1 　获取数据集　　48
4.2.2 　用pandas加载数据　　49
4.2.3 　稀疏数据格式　　49
4.3 　Apriori算法的实现　　50
4.3.1 　Apriori算法　　51
4.3.2 　实现　　52
4.4 　抽取关联规则　　54
4.5 　小结　　60
第5章 　用转换器抽取特征　　62
5.1 　特征抽取　　62
5.1.1 　在模型中表示事实　　62
5.1.2 　通用的特征创建模式　　64
5.1.3 　创建好的特征　　66
5.2 　特征选择　　67
5.3 　创建特征　　71
5.4 　创建自己的转换器　　75
5.4.1 　转换器API　　76
5.4.2 　实现细节　　76
5.4.3 　单元测试　　77
5.4.4 　组装起来　　79
5.5 　小结　　79
第6章 　使用朴素贝叶斯进行社会媒体挖掘　　80
6.1 　消歧　　80
6.1.1 　从社交网站下载数据　　81
6.1.2 　加载数据集并对其分类　　83
6.1.3 　Twitter数据集重建　　87
6.2 　文本转换器　　90
6.2.1 　词袋　　91
6.2.2 　N元语法　　92
6.2.3 　其他特征　　93
6.3 　朴素贝叶斯　　93
6.3.1 　贝叶斯定理　　93
6.3.2 　朴素贝叶斯算法　　94
6.3.3 　算法应用示例　　95
6.4 　应用　　96
6.4.1 　抽取特征　　97
6.4.2 　将字典转换为矩阵　　98
6.4.3 　训练朴素贝叶斯分类器　　98
6.4.4 　组装起来　　98
6.4.5 　用F1值评估　　99
6.4.6 　从模型中获取更多有用的特征　　100
6.5 　小结　　102
第7章 　用图挖掘找到感兴趣的人　　104
7.1 　加载数据集　　104
7.1.1 　用现有模型进行分类　　106
7.1.2 　获取Twitter好友信息　　107
7.1.3 　构建网络　　110
7.1.4 　创建图　　112
7.1.5 　创建用户相似度图　　114
7.2 　寻找子图　　117
7.2.1 　连通分支　　117
7.2.2 　优化参数选取准则　　119
7.3 　小结　　123
第8章 　用神经网络破解验证码　　124
8.1 　人工神经网络　　124
8.2 　创建数据集　　127
8.2.1 　绘制验证码　　127
8.2.2 　将图像切分为单个的字母　　129
8.2.3 　创建训练集　　130
8.2.4 　根据抽取方法调整训练数据集　　131
8.3 　训练和分类　　132
8.3.1 　反向传播算法　　134
8.3.2 　预测单词　　135
8.4 　用词典提升正确率　　138
8.4.1 　寻找最相似的单词　　138
8.4.2 　组装起来　　139
8.5 　小结　　140
第9章 　作者归属问题　　142
9.1 　为作品找作者　　142
9.1.1 　相关应用和使用场景　　143
9.1.2 　作者归属　　143
9.1.3 　获取数据　　144
9.2 　功能词　　147
9.2.1 　统计功能词　　148
9.2.2 　用功能词进行分类　　149
9.3 　支持向量机　　150
9.3.1 　用SVM分类　　151
9.3.2 　内核　　151
9.4 　字符N元语法　　152
9.5 　使用安然公司数据集　　153
9.5.1 　获取安然数据集　　153
9.5.2 　创建数据集加载工具　　154
9.5.3 　组装起来　　158
9.5.4 　评估　　158
9.6 　小结　　160
第10章 　新闻语料分类　　161
10.1 　获取新闻文章　　161
10.1.1 　使用Web API获取数据　　162
10.1.2 　数据资源宝库reddit　　164
10.1.3 　获取数据　　165
10.2 　从任意网站抽取文本　　167
10.2.1 　寻找任意网站网页中的主要内容　　167
10.2.2 　组装起来　　168
10.3 　新闻语料聚类　　170
10.3.1 　k-means算法　　171
10.3.2 　评估结果　　173
10.3.3 　从簇中抽取主题信息　　175
10.3.4 　用聚类算法做转换器　　175
10.4 　聚类融合　　176
10.4.1 　证据累积　　176
10.4.2 　工作原理　　179
10.4.3 　实现　　180
10.5 　线上学习　　181
10.5.1 　线上学习简介　　181
10.5.2 　实现　　182
10.6 　小结　　184
第11章 　用深度学习方法为图像中的物体进行分类　　185
11.1 　物体分类　　185
11.2 　应用场景和目标　　185
11.3 　深度神经网络　　189
11.3.1 　直观感受　　189
11.3.2 　实现　　189
11.3.3 　Theano简介　　190
11.3.4 　Lasagne简介　　191
11.3.5 　用nolearn实现神经网络　　194
11.4 　GPU优化　　197
11.4.1 　什么时候使用GPU进行
计算　　198
11.4.2 　用GPU运行代码　　198
11.5 　环境搭建　　199
11.6 　应用　　201
11.6.1 　获取数据　　201
11.6.2 　创建神经网络　　202
11.6.3 　组装起来　　204
11.7 　小结　　205
第12章 　大数据处理　　206
12.1 　大数据　　206
12.2 　大数据应用场景和目标　　207
12.3 　MapReduce　　208
12.3.1 　直观理解　　209
12.3.2 　单词统计示例　　210
12.3.3 　Hadoop MapReduce　　212
12.4 　应用　　212
12.4.1 　获取数据　　213
12.4.2 　朴素贝叶斯预测　　215
12.5 　小结　　226
附录 　接下来的方向　　227
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据挖掘入门与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>从掷骰子到阿尔法狗：趣谈概率
序言
第一章：趣谈概率
1. 帕斯卡和法国数学：概率论的诞生
2. 似是而非的答案：古典概率悖论
3. 几何概型和贝特朗悖论
4. 别相信直觉：概率论帮助侦破“财务造假”
5. 赌徒谬误：赌博与概率
6. 随处可见的钟形曲线：中心极限定理
第二章：趣谈贝叶斯学派
1. 三门问题
2. 三门问题引发的思考
3. 频率学派和贝叶斯学派
4. 主观和客观
5. 量子贝叶斯模型
6. 贝叶斯台球问题
7. 德国坦克问题
第三章：趣谈随机过程
1. 马尔可夫链
2. 酒鬼漫步的数学
3. 赌徒破产及鸟儿回家
4. 微粒之“酒鬼漫步”--布朗运动
5. 麦穗问题和博士相亲
第四章：趣谈“熵”
1. 从卡诺谈起-天妒英才
2. “熵”- 热力学中闪亮登场
3. “熵”- 名字古怪性情乖张
4.  时间之矢贯穿宇宙
5. 易辛模型及应用
6. 麦克斯韦妖
第五章：趣谈信息熵
1. “熵”- 信息世界大显身手
2. “熵”- 品类繁多个个逞强
3.  老鼠和毒药问题
4.  称球问题
5. 不要把鸡蛋放一个篮子里
第六章：趣谈互联网中之概率
1. 大网络中的小世界
2. 网络和图论
3. 网络之大小
4. 有趣的随机大网络
第七章：趣谈人工智能之统计
1.  阿尔法狗世纪大战
2. 人工智能研究的坎坷路
3. 隐马尔可夫过程
4. 支持向量机
5. 朴素贝叶斯分类器
6. 分布之分布
7. 中国餐馆过程
8. 机器深度学习的奥秘
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>从掷骰子到阿尔法狗：趣谈概率
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python神经网络编程
版权
版权声明
内容提要
译者序
序言
前言
第 1 章　神经网络如何工作 001
1.1　尺有所短，寸有所长 001
1.2　一台简单的预测 003
1.3　分类器与预测器并无太大差别 008
1.4　训练简单的分类 011
1.5　有时候一个分类器不足以求解问题 020
1.6　神经元——大自然的计算机器 024
1.7　在神经网络中追踪信号 033
1.8　凭心而论，矩阵乘法大有用途 037
1.9　使用矩阵乘法的三层神经网络示例 043
1.10　学习来自多个节点的权重 051
1.11　多个输出节点反向传播误差 053
1.12　反向传播误差到更多层中 054
1.13　使用矩阵乘法进行反向传播误差 058
1.14　我们实际上如何更新权重 061
1.15　权重更新成功范例 077
1.16　准备数据 078
第 2 章　使用Python进行DIY 083
2.1　Python 083
2.2　交互式Python = IPython 084
2.3　优雅地开始使用Python 085
2.4　使用Python制作神经网络 105
2.5　手写数字的数据集MNIST 121
第 3 章　趣味盎然 153
3.1　自己的手写数字 153
3.2　神经网络大脑内部 156
3.3　创建新的训练数据：旋转图像 160
3.4　结语 164
附录A　微积分简介 165
A.1　一条平直的线 166
A.2　一条斜线 168
A.3　一条曲线 170
A.4　手绘微积分 172
A.5　非手绘微积分 174
A.6　无需绘制图表的微积分 177
A.7　模式 180
A.8　函数的函数 182
附录B　使用树莓派来工作 186
B.1　安装IPython 187
B.2　确保各项工作正常进行 193
B.3　训练和测试神经网络 194
B.4　树莓派成功了 195
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python神经网络编程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学完全教程
译者前言
原书序
第1章 概率
第2章 随机变量
第3章 数学期望
第4章 不等式
第5章 随机变量的收敛
第6章 模型、统计推断与学习
第7章 CDF和统计泛函的估计
第8章 Bootstrap方法
第9章 参数推断
第10章 假设检验和p值
第11章 贝叶斯推断
第12章 统计决策理论
第13章 线性回归和Logistic回归
第14章 多变量模型
第15章 独立性推断
第16章 因果推断
第17章 有向图与条件独立性
第18章 无向图
第19章 对数线性模型
第20章 非参数曲线估计
第21章 正交函数光滑法
第22章 分类
第23章 重温概率：随机过程
第24章 模拟方法
参考文献
符号列表
名词索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学完全教程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学入门
前言　　xiii
第1章　导论　　1
1.1　数据的威力　　1
1.2　什么是数据科学　　1
1.3　激励假设：DataSciencester　　2
1.3.1　寻找关键联系人　　3
1.3.2　你可能知道的数据科学家　　5
1.3.3　工资与工作年限　　8
1.3.4　付费账户　　10
1.3.5　兴趣主题　　11
1.4　展望　　12
第2章　Python速成　　13
2.1　基础内容　　13
2.1.1　Python获取　　13
2.1.2　Python之禅　　14
2.1.3　空白形式　　14
2.1.4　模块　　15
2.1.5　算法　　16
2.1.6　函数　　16
2.1.7　字符串　　17
2.1.8　异常　　18
2.1.9　列表　　18
2.1.10　元组　　19
2.1.11　字典　　20
2.1.12　集合　　22
2.1.13　控制流　　23
2.1.14　真和假　　24
2.2　进阶内容　　25
2.2.1　排序　　25
2.2.2　列表解析　　25
2.2.3　生成器和迭代器　　26
2.2.4　随机性　　27
2.2.5　正则表达式　　28
2.2.6　面向对象的编程　　28
2.2.7　函数式工具　　29
2.2.8　枚举　　31
2.2.9　压缩和参数拆分　　31
2.2.10　args 和kwargs　　32
2.2.11　欢迎来到DataSciencester　　33
2.3　延伸学习　　33
第3章　可视化数据　　34
3.1　matplotlib　　34
3.2　条形图　　36
3.3　线图　　40
3.4　散点图　　41
3.5　延伸学习　　44
第4章　线性代数　　45
4.1　向量　　45
4.2　矩阵　　49
4.3　延伸学习　　51
第5章　统计学　　53
5.1　描述单个数据集　　53
5.1.1　中心倾向　　55
5.1.2　离散度　　56
5.2　相关　　58
5.3　辛普森悖论　　60
5.4　相关系数其他注意事项　　61
5.5　相关和因果　　62
5.6　延伸学习　　63
第6章　概率　　64
6.1　不独立和独立　　64
6.2　条件概率　　65
6.3　贝叶斯定理　　66
6.4　随机变量　　68
6.5　连续分布　　68
6.6　正态分布　　69
6.7　中心极限定理　　72
6.8　延伸学习　　74
第7章　假设与推断　　75
7.1　统计假设检验　　75
7.2　案例：掷硬币　　75
7.3　置信区间　　79
7.4　P-hacking　　80
7.5　案例：运行A/B测试　　81
7.6　贝叶斯推断　　82
7.7　延伸学习　　85
第8章　梯度下降　　86
8.1　梯度下降的思想　　86
8.2　估算梯度　　87
8.3　使用梯度　　90
8.4　选择正确步长　　90
8.5　综合　　91
8.6　随机梯度下降法　　92
8.7　延伸学习　　93
第9章　获取数据　　94
9.1　stdin和stdout　　94
9.2　读取文件　　96
9.2.1　文本文件基础　　96
9.2.2　限制的文件　　97
9.3　网络抓取　　99
9.3.1　HTML 和解析方法　　99
9.3.2　案例：关于数据的O'Reilly图书　　101
9.4　使用API　　105
9.4.1　JSON（和XML）　　105
9.4.2　使用无验证的API　　106
9.4.3　寻找API　　107
9.5　案例：使用Twitter API　　108
9.6　延伸学习　　111
第10章　数据工作　　112
10.1　探索你的数据　　112
10.1.1　探索一维数据　　112
10.1.2　二维数据　　114
10.1.3　多维数据　　116
10.2　清理与修改　　117
10.3　数据处理　　119
10.4　数据调整　　122
10.5　降维　　123
10.6　延伸学习　　129
第11章　机器学习　　130
11.1　建模　　130
11.2　什么是机器学习　　131
11.3　过拟合和欠拟合　　131
11.4　正确性　　134
11.5　偏倚- 方差权衡　　136
11.6　特征提取和选择　　137
11.7　延伸学习　　138
第12章　k近邻法　　139
12.1　模型　　139
12.2　案例：最喜欢的编程语言　　141
12.3　维数灾难　　146
12.4　延伸学习　　151
第13章　朴素贝叶斯算法　　152
13.1　一个简易的垃圾邮件过滤器　　152
13.2　一个复杂的垃圾邮件过滤器　　153
13.3　算法的实现　　154
13.4　测试模型　　156
13.5　延伸学习　　158
第14章　简单线性回归　　159
14.1　模型　　159
14.2　利用梯度下降法　　162
14.3　最大似然估计　　162
14.4　延伸学习　　163
第15章　多重回归分析　　164
15.1　模型　　164
15.2　最小二乘模型的进一步假设　　165
15.3　拟合模型　　166
15.4　解释模型　　167
15.5　拟合优度　　167
15.6　题外话：Bootstrap　　168
15.7　回归系数的标准误差　　169
15.8　正则化　　170
15.9　延伸学习　　172
第16章　逻辑回归　　173
16.1　问题　　173
16.2　Logistic函数　　176
16.3　应用模型　　178
16.4　拟合优度　　179
16.5　支持向量机　　180
16.6　延伸学习　　184
第17章　决策树　　185
17.1　什么是决策树　　185
17.2　熵　　187
17.3　分割之熵　　189
17.4　创建决策树　　190
17.5　综合运用　　192
17.6　随机森林　　194
17.7　延伸学习　　195
第18章　神经网络　　196
18.1　感知器　　196
18.2　前馈神经网络　　198
18.3　反向传播　　201
18.4　实例：战胜CAPTCHA　　202
18.5　延伸学习　　206
第19章　聚类分析　　208
19.1　原理　　208
19.2　模型　　209
19.3　示例：聚会　　210
19.4　选择聚类数目k　　213
19.5　示例：对色彩进行聚类　　214
19.6　自下而上的分层聚类　　216
19.7　延伸学习　　221
第20章　自然语言处理　　222
20.1　词云　　222
20.2　n-grams模型　　　224
20.3　语法　　227
20.4　题外话：吉布斯采样　　229
20.5　主题建模　　231
20.6　延伸学习　　236
第21章　网络分析　　237
21.1　中介中心度　　237
21.2　特征向量中心度　　242
21.2.1　矩阵乘法　　242
21.2.2　中心度　　244
21.3　有向图与PageRank　　246
21.4　延伸学习　　248
第22章　推荐系统　　249
22.1　手工甄筛　　250
22.2　推荐流行事物　　250
22.3　基于用户的协同过滤方法　　251
22.4　基于物品的协同过滤算法　　254
22.5　延伸学习　　256
第23章　数据库与SQL　　257
23.1　CREATE TABLE与INSERT　　257
23.2　UPDATE　　259
23.3　DELETE　　260
23.4　SELECT　　260
23.5　GROUP BY　　262
23.6　ORDER BY　　264
23.7　JOIN　　264
23.8　子查询　　267
23.9　索引　　267
23.10　查询优化　　268
23.11　NoSQL　　268
23.12　延伸学习　　269
第24章　MapReduce　　270
24.1　案例：单词计数　　270
24.2　为什么是MapReduce　　272
24.3　更加一般化的MapReduce　　272
24.4　案例：分析状态更新　　273
24.5　案例：矩阵计算　　275
24.6　题外话：组合器　　276
24.7　延伸学习　　277
第25章　数据科学前瞻　　278
25.1　IPython　　278
25.2　数学　　279
25.3　不从零开始　　279
25.3.1　NumPy　　279
25.3.2　pandas　　280
25.3.3　scikit-learn　　280
25.3.4　可视化　　280
25.3.5　R　　281
25.4　寻找数据　　281
25.5　从事数据科学　　281
25.5.1　Hacker News　　282
25.5.2　消防车　　282
25.5.3　T 恤　　282
25.5.4　你呢？　　283
作者简介　　284
关于封面　　284
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学入门
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>社交网站的数据挖掘与分析
前言1
第1章绪论：Twitter 数据的处理9
Python 开发工具的安装9
Twitter 数据的收集和处理11
小结24
第2章微格式：语义标记和常识碰撞26
XFN 和朋友27
使用XFN 来探讨社交关系29
地理坐标：兴趣爱好的共同主线37
（以健康的名义）对菜谱进行交叉分析41
对餐厅评论的搜集43
小结45
第3章邮箱：虽然老套却很好用47
mbox：Unix 的入门级邮箱48
mbox+CouchDB= 随意的Email 分析54
将对话线程化到一起70
使用SIMILE Timeline 将邮件“事件”可视化79
分析你自己的邮件数据82
小结84
第4章Twitter ：朋友、关注者和Setwise 操作85
REST 风格的和OAuth-Cladded API86
干练而中肯的数据采集器90
友谊图的构建108
小结116
第5章Twitter：tweet ，所有的tweet ，只有tweet 118
笔PK 剑：和tweet PK 机枪（?!?）118
对tweet 的分析（每次一个实体）121
并置潜在的社交网站（或#JustinBieber VS #TeaParty）144
对大量tweet 的可视化155
小结163
第6章LinkedIn ：为了乐趣（和利润？）将职业网络聚类164
聚类的动机165
按职位将联系人聚类167
获取补充个人信息183
从地理上聚类网络188
小结192
第7章Google Buzz：TF-IDF 、余弦相似性和搭配194
Buzz=Twitter+ 博客（???）195
使用NLTK 处理数据198
文本挖掘的基本原则201
查找相似文档208
在二元语法中发Buzz 215
利用Gmail 221
在中断之前试着创建一个搜索引擎……225
小结226
第8章博客及其他：自然语言处理（等）228
NLP ：帕累托式介绍228
使用NLTK 的典型NLP 管线231
使用NLTK 检测博客中的句子234
对文件的总结237
以实体为中心的分析：对数据的深层了解245
小结256
第9章Facebook ：一体化的奇迹257
利用社交网络数据258
对Facebook 数据的可视化274
小结294
第10 章语义网：简短的讨论296
发展中的变革296
人不可能只靠事实生活297
期望301
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>社交网站的数据挖掘与分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>强化学习：原理与Python实现
前言
第1章　初识强化学习  1
1.1　强化学习及其关键元素  1
1.2　强化学习的应用  3
1.3　智能体/环境接口  4
1.4　强化学习的分类  6
1.4.1　按任务分类  6
1.4.2　按算法分类  7
1.5　如何学习强化学习  8
1.5.1　学习路线  9
1.5.2　学习资源  9
1.6　案例：基于Gym库的智能体/环境交互  9
1.6.1　安装Gym库  10
1.6.2　使用Gym库  10
1.6.3　小车上山  12
1.7　本章小结  14
第2章　Markov决策过程  16
2.1　Markov决策过程模型  16
2.1.1　离散时间Markov决策过程  16
2.1.2　环境与动力  18
2.1.3　智能体与策略  19
2.1.4　奖励、回报与价值函数  19
2.2　Bellman期望方程  21
2.3　最优策略及其性质  25
2.3.1　最优策略与最优价值函数  25
2.3.2　Bellman最优方程  25
2.3.3　用Bellman最优方程求解最优策略  29
2.4　案例：悬崖寻路  31
2.4.1　实验环境使用  31
2.4.2　求解Bellman期望方程  32
2.4.3　求解Bellman最优方程  33
2.5　本章小结  35
第3章　有模型数值迭代  37
3.1　度量空间与压缩映射  37
3.1.1　度量空间及其完备性  37
3.1.2　压缩映射与Bellman算子  38
3.1.3　Banach不动点定理  39
3.2　有模型策略迭代  40
3.2.1　策略评估  40
3.2.2　策略改进  42
3.2.3　策略迭代  44
3.3　有模型价值迭代  45
3.4　动态规划  46
3.4.1　从动态规划看迭代算法  46
3.4.2　异步动态规划  47
3.5　案例：冰面滑行  47
3.5.1　实验环境使用  48
3.5.2　有模型策略迭代求解  49
3.5.3　有模型价值迭代求解  51
3.6　本章小结  52
第4章　回合更新价值迭代  54
4.1　同策回合更新  54
4.1.1　同策回合更新策略评估  54
4.1.2　带起始探索的同策回合更新  58
4.1.3　基于柔性策略的同策回合更新  60
4.2　异策回合更新  62
4.2.1　重要性采样  62
4.2.2　异策回合更新策略评估  64
4.2.3　异策回合更新最优策略求解  65
4.3　案例：21点游戏  66
4.3.1　实验环境使用  66
4.3.2　同策策略评估  67
4.3.3　同策最优策略求解  70
4.3.4　异策策略评估  72
4.3.5　异策最优策略求解  73
4.4　本章小结  74
第5章　时序差分价值迭代  76
5.1　同策时序差分更新  76
5.1.1　时序差分更新策略评估  78
5.1.2　SARSA算法  81
5.1.3　期望SARSA算法  83
5.2　异策时序差分更新  85
5.2.1　基于重要性采样的异策算法  85
5.2.2　Q学习  86
5.2.3　双重Q学习  87
5.3　资格迹  89
5.3.1　λ回报  89
5.3.2　TD(λ)  90
5.4　案例：出租车调度  92
5.4.1　实验环境使用  93
5.4.2　同策时序差分学习调度  94
5.4.3　异策时序差分学习调度  97
5.4.4　资格迹学习调度  99
5.5　本章小结  100
第6章　函数近似方法  101
6.1　函数近似原理  101
6.1.1　随机梯度下降  101
6.1.2　半梯度下降  103
6.1.3　带资格迹的半梯度下降  105
6.2　线性近似  107
6.2.1　精确查找表与线性近似的关系  107
6.2.2　线性最小二乘策略评估  107
6.2.3　线性最小二乘最优策略求解  109
6.3　函数近似的收敛性  109
6.4　深度Q学习  110
6.4.1　经验回放  111
6.4.2　带目标网络的深度Q学习  112
6.4.3　双重深度Q网络  114
6.4.4　对偶深度Q网络  114
6.5　案例：小车上山  115
6.5.1　实验环境使用  116
6.5.2　用线性近似求解最优策略  117
6.5.3　用深度Q学习求解最优策略  120
6.6　本章小结  123
第7章　回合更新策略梯度方法  125
7.1　策略梯度算法的原理  125
7.1.1　函数近似与动作偏好  125
7.1.2　策略梯度定理  126
7.2　同策回合更新策略梯度算法  128
7.2.1　简单的策略梯度算法  128
7.2.2　带基线的简单策略梯度算法  129
7.3　异策回合更新策略梯度算法  131
7.4　策略梯度更新和极大似然估计的关系  132
7.5　案例：车杆平衡  132
7.5.1　同策策略梯度算法求解最优策略  133
7.5.2　异策策略梯度算法求解最优策略  135
7.6　本章小结  137
第8章　执行者/评论者方法  139
8.1　同策执行者/评论者算法  139
8.1.1　动作价值执行者/评论者算法  140
8.1.2　优势执行者/评论者算法  141
8.1.3　带资格迹的执行者/评论者算法  143
8.2　基于代理优势的同策算法  143
8.2.1　代理优势  144
8.2.2　邻近策略优化  145
8.3　信任域算法  146
8.3.1　KL散度  146
8.3.2　信任域  147
8.3.3　自然策略梯度算法  148
8.3.4　信任域策略优化  151
8.3.5　Kronecker因子信任域执行者/评论者算法  152
8.4　重要性采样异策执行者/评论者算法  153
8.4.1　基本的异策算法  154
8.4.2　带经验回放的异策算法  154
8.5　柔性执行者/评论者算法  157
8.5.1　熵  157
8.5.2　奖励工程和带熵的奖励  158
8.5.3　柔性执行者/评论者的网络设计  159
8.6　案例：双节倒立摆  161
8.6.1　同策执行者/评论者算法求解最优策略  162
8.6.2　异策执行者/评论者算法求解最优策略  168
8.7　本章小结  170
第9章　连续动作空间的确定性策略  172
9.1　同策确定性算法  172
9.1.1　策略梯度定理的确定性版本  172
9.1.2　基本的同策确定性执行者/评论者算法  174
9.2　异策确定性算法  176
9.2.1　基本的异策确定性执行者/评论者算法  177
9.2.2　深度确定性策略梯度算法  177
9.2.3　双重延迟深度确定性策略梯度算法  178
9.3　案例：倒立摆的控制  180
9.3.1　用深度确定性策略梯度算法求解  181
9.3.2　用双重延迟深度确定性算法求解  184
9.4　本章小结  187
第10章　综合案例：电动游戏  188
10.1　Atari游戏环境  188
10.1.1　Gym库的完整安装  188
10.1.2　游戏环境使用  190
10.2　基于深度Q学习的游戏AI  191
10.2.1　算法设计  192
10.2.2　智能体的实现  193
10.2.3　智能体的训练和测试  197
10.3　本章小结  198
第11章　综合案例：棋盘游戏  200
11.1　双人确定性棋盘游戏  200
11.1.1　五子棋和井字棋  200
11.1.2　黑白棋  201
11.1.3　围棋  202
11.2　AlphaZero算法  203
11.2.1　回合更新树搜索  203
11.2.2　深度残差网络  206
11.2.3　自我对弈  208
11.2.4　算法流程  210
11.3　棋盘游戏环境boardgame2  210
11.3.1　为Gym库扩展自定义环境  211
11.3.2　boardgame2设计  211
11.3.3　Gym环境接口的实现  214
11.3.4　树搜索接口的实现  216
11.4　AlphaZero算法实现  218
11.4.1　智能体类的实现  218
11.4.2　自我对弈的实现  223
11.4.3　训练智能体  224
11.5　本章小结  225
第12章　综合案例：自动驾驶  226
12.1　AirSim开发环境使用  226
12.1.1　安装和运行AirSim  226
12.1.2　用Python访问AirSim  228
12.2　基于强化学习的自动驾驶  229
12.2.1　为自动驾驶设计强化学习环境  230
12.2.2　智能体设计和实现  235
12.2.3　智能体的训练和测试  237
12.3　本章小结  239
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>强化学习：原理与Python实现
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>21个项目玩转深度学习
第1章  MNIST机器学习入门  1
1.1  MNIST数据集  2
1.1.1  简介  2
1.1.2  实验：将MNIST数据集保存为图片  5
1.1.3  图像标签的独热(one-hot)表示  6
1.2  利用TensorFlow识别MNIST  8
1.2.1  Softmax回归  8
1.2.2  两层卷积网络分类  14
1.3  总结  18
第2章  CIFAR-10与ImageNet图像识别  19
2.1  CIFAR-10数据集  20
2.1.1  CIFAR-10简介  20
2.1.2  下载CIFAR-10数据  21
2.1.3  TensorFlow的数据读取机制  23
2.1.4  实验：将CIFAR-10数据集保存为图片形式  30
2.2  利用TensorFlow训练CIFAR-10识别模型  34
2.2.1  数据增强（Data Augmentation）  34
2.2.2  CIFAR-10识别模型  36
2.2.3  训练模型  39
2.2.4  在TensorFlow中查看训练进度  39
2.2.5  测试模型效果  42
2.3  ImageNet图像识别模型  44
2.3.1  ImageNet数据集简介  44
2.3.2  历代ImageNet图像识别模型  45
2.4  总结  49
第3章  打造自己的图像识别模型  50
3.1  微调（Fine-tune）的原理  51
3.2  数据准备  52
3.3  使用TensorFlow Slim微调模型  56
3.3.1  下载TensorFlow Slim的源代码  56
3.3.2  定义新的datasets文件  57
3.3.3  准备训练文件夹  59
3.3.4  开始训练  60
3.3.5  训练程序行为  62
3.3.6  验证模型正确率  63
3.3.7  TensorBoard可视化与超参数选择  64
3.3.8  导出模型并对单张图片进行识别  65
3.4  总结  69
第4章  Deep Dream模型  70
4.1  Deep Dream的技术原理  71
4.2  TensorFlow中的Deep Dream模型实践  73
4.2.1  导入Inception模型  73
4.2.2  生成原始的Deep Dream图像  76
4.2.3  生成更大尺寸的Deep Dream图像  78
4.2.4  生成更高质量的Deep Dream图像  82
4.2.5  最终的Deep Dream模型  87
4.3  总结  90
第5章  深度学习中的目标检测  91
5.1  深度学习中目标检测的原理  92
5.1.1  R-CNN的原理  92
5.1.2  SPPNet的原理  94
5.1.3  Fast R-CNN的原理  97
5.1.4  Faster R-CNN的原理  98
5.2  TensorFlow Object Detection API  101
5.2.1  安装TensorFlow Object Detection API  101
5.2.2  执行已经训练好的模型  103
5.2.3  训练新的模型  109
5.2.4  导出模型并预测单张图片  113
5.3  总结  114
第6章  人脸检测和人脸识别  115
6.1  MTCNN的原理  116
6.2  使用深度卷积网络提取特征  121
6.2.1  三元组损失（Triplet Loss）的定义  123
6.2.2  中心损失（Center Loss）的定义  123
6.3  使用特征设计应用  125
6.4  在TensorFlow中实现人脸识别  126
6.4.1  项目环境设置  126
6.4.2  LFW人脸数据库  127
6.4.3  LFW数据库上的人脸检测和对齐  128
6.4.4  使用已有模型验证LFW数据库准确率  129
6.4.5  在自己的数据上使用已有模型  130
6.4.6  重新训练新模型  133
6.4.7  三元组损失和中心损失的定义  138
6.5  总结  140
第7章  图像风格迁移  141
7.1  图像风格迁移的原理  142
7.1.1  原始图像风格迁移的原理  142
7.1.2  快速图像风格迁移的原理  148
7.2  在TensorFlow中实现快速风格迁移  149
7.2.1  使用预训练模型  150
7.2.2  训练自己的模型  153
7.2.3  在TensorBoard中监控训练情况  154
7.2.4  项目实现细节  157
7.3  总结  162
第8章  GAN和DCGAN入门  163
8.1  GAN的原理  164
8.2  DCGAN的原理  166
8.3  在TensorFlow中用DCGAN生成图像  169
8.3.1  生成MNIST图像  170
8.3.2  使用自己的数据集训练  171
8.3.3  程序结构分析：如何将图像读入模型  173
8.3.4  程序结构分析：可视化方法  177
8.4  总结  180
第9章  pix2pix模型与自动上色技术  181
9.1  cGAN的原理  182
9.2  pix2pix模型的原理  184
9.3  TensorFlow中的pix2pix模型  187
9.3.1  执行已有的数据集  187
9.3.2  创建自己的数据集  191
9.4  使用TensorFlow为灰度图像自动上色  194
9.4.1  为食物图片上色  194
9.4.2  为动漫图片进行上色  196
9.5  总结  198
第10章  超分辨率：如何让图像变得更清晰  199
10.1  数据预处理与训练  200
10.1.1  去除错误图片  200
10.1.2  将图像裁剪到统一大小  202
10.1.3  为代码添加新的操作  202
10.2  总结  209
第11章  CycleGAN与非配对图像转换  210
11.1  CycleGAN的原理  211
11.2  在TensorFlow中用训练CycleGAN模型  213
11.2.1  下载数据集并训练  213
11.2.2  使用自己的数据进行训练  217
11.3  程序结构分析  220
11.4  总结  224
第12章  RNN基本结构与Char RNN文本生成  225
12.1  RNN的原理  226
12.1.1  经典RNN的结构  226
12.1.2  N VS 1 RNN的结构  229
12.1.3  1 VS N RNN的结构  230
12.2  LSTM的原理  231
12.3  Char RNN的原理  235
12.4  TensorFlow中的RNN实现方式  237
12.4.1  实现RNN的基本单元：RNNCell  238
12.4.2  对RNN进行堆叠：MultiRNNCell  239
12.4.3  注意点：BasicRNNCell和BasicLSTMCell的output  240
12.4.4  使用tf.nn.dynamic_rnn展开时间维度  241
12.5  使用TensorFlow实现Char RNN  242
12.5.1  定义输入数据  243
12.5.2  定义多层LSTM模型  244
12.5.3  定义损失  245
12.5.4  训练模型与生成文字  246
12.5.5  更多参数说明  250
12.5.6  运行自己的数据  250
12.6  总结  251
第13章  序列分类问题详解  252
13.1  N VS 1的RNN结构  253
13.2  数列分类问题与数据生成  254
13.3  在TensorFlow中定义RNN分类模型  258
13.3.1  定义模型前的准备工作  258
13.3.2  定义RNN分类模型  259
13.3.3  定义损失并进行训练  261
13.4  模型的推广  262
13.5  总结  263
第14章  词的向量表示：word2vec与词嵌入  264
14.1  为什么需要做词嵌入  265
14.2  词嵌入的原理  266
14.2.1  CBOW实现词嵌入的原理  266
14.2.2  Skip-Gram实现词嵌入的原理  269
14.3  在TensorFlow中实现词嵌入  270
14.3.1  下载数据集  270
14.3.2  制作词表  272
14.3.3  生成每步的训练样本  274
14.3.4  定义模型  276
14.3.5  执行训练  279
14.3.6  可视化  281
14.4  与第12章的对比  284
14.5  总结  285
第15章  在TensorFlow中进行时间序列预测  286
15.1  时间序列问题的一般形式  287
15.2  用TFTS读入时间序列数据  287
15.2.1  从Numpy数组中读入时间序列数据  288
15.2.2  从CSV文件中读入时间序列数据  291
15.3  使用AR模型预测时间序列  293
15.3.1  AR模型的训练  293
15.3.2  AR模型的验证和预测  295
15.4  使用LSTM模型预测时间序列  297
15.4.1  LSTM模型中的单变量时间序列预测  297
15.4.2  LSTM模型中的多变量时间序列预测  299
15.5  总结  301
第16章  神经网络机器翻译技术  302
16.1  Encoder-Decoder模型的原理  303
16.2  注意力机制（Attention）  305
16.3  使用TensorFlow NMT搭建神经网络翻译引擎  309
16.3.1  示例：将越南语翻译为英语  309
16.3.2  构建中英翻译引擎  313
16.4  TensorFlow NMT源码简介  317
16.5  总结  319
第17章  看图说话：将图像转换为文字  320
17.1  Image Caption技术综述  321
17.1.1  从Encoder-Decoder结构谈起  321
17.1.2  将Encoder-Decoder应用到Image Caption任务上  322
17.1.3  对Encoder-Decoder的改进1：加入Attention机制  323
17.1.4  对Encoder-Decoder的改进2：加入高层语义  325
17.2  在TensorFlow中实现Image Caption  327
17.2.1  下载代码  327
17.2.2  环境准备  328
17.2.2  编译和数据准备  328
17.2.3  训练和验证  330
17.2.4  测试单张图片  331
17.3  总结  332
第18章  强化学习入门之Q  333
18.1  强化学习中的几个重要概念  334
18.2  Q Learning的原理与实验  336
18.2.1  环境定义  336
18.2.2  Q函数  338
18.2.3  Q函数的学习策略  339
18.2.4  ?-greedy策略  341
18.2.5  简单的Q Learning示例  341
18.2.6  更复杂的情况  342
18.3  总结  343
第19章  强化学习入门之SARSA算法  344
19.1  SARSA 算法的原理  345
19.1.1  通过与Q Learning对比学习SARSA算法  345
19.1.2  off-policy与on-policy  346
19.2  SARSA 算法的实现  347
19.3  总结  348
第20章  深度强化学习：Deep Q Learning  349
20.1  DQN算法的原理  350
20.1.1  问题简介  350
20.1.2  Deep Q Network  351
20.1.3  训练方法  352
20.2  在TensorFlow中运行DQN算法  353
20.2.1  安装依赖库  353
20.2.2  训练  355
20.2.3  测试  356
20.3  在TensorFlow中DQN算法的实现分析  357
20.4  总结  360
第21章  策略梯度（Policy Gradient）算法  361
21.1  策略梯度（Policy Gradient）算法的原理  362
21.1.1  Cartpole游戏  362
21.1.2  策略网络（Policy Network）  363
21.1.3  训练策略网络  364
21.2  在TensorFlow中实现策略梯度 算法  365
21.2.1  初始化  365
21.2.2  定义策略网络  366
21.2.3  训练  367
21.3  总结  371
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>21个项目玩转深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>解析深度学习：语音识别实践
译者序 iv
序 vii
前言 ix
术语缩写 xxii
符号 xxvii
第 1 章 简介 1
1.1 自动语音识别：更好的沟通之桥 . . . . . . . . . . . . . . . . . . . . . . . 1
1.1.1 人类之间的交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.1.2 人机交流 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
1.2 语音识别系统的基本结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.3 全书结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 6
1.3.1 第一部分：传统声学模型 . . . . . . . . . . . . . . . . . . . . . . 6
1.3.2 第二部分：深度神经网络 . . . . . . . . . . . . . . . . . . . . . . 6
1.3.3 第三部分：语音识别中的 DNN-HMM 混合系统 . . . . . . . . . . 7
1.3.4 第四部分：深度神经网络中的表征学习 . . . . . . . . . . . . . . 7
1.3.5 第五部分：高级的深度模型 . . . . . . . . . . . . . . . . . . . . . 7
第一部分 传统声学模型 9
第 2 章 混合高斯模型 11
2.1 随机变量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.2 高斯分布和混合高斯随机变量 . . . . . . . . . . . . . . . . . . . . . . . . 12
2.3 参数估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
2.4 采用混合高斯分布对语音特征建模 . . . . . . . . . . . . . . . . . . . . . 16
第 3 章 隐马尔可夫模型及其变体 19
3.1 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3.2 马尔可夫链 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21
3.3 序列与模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
3.3.1 隐马尔可夫模型的性质 . . . . . . . . . . . . . . . . . . . . . . . . 23
3.3.2 隐马尔可夫模型的仿真 . . . . . . . . . . . . . . . . . . . . . . . . 24
3.3.3 隐马尔可夫模型似然度的计算 . . . . . . . . . . . . . . . . . . . . 24
3.3.4 计算似然度的高效算法 . . . . . . . . . . . . . . . . . . . . . . . . 26
3.3.5 前向与后向递归式的证明 . . . . . . . . . . . . . . . . . . . . . . 27
3.4 期望最大化算法及其在学习 HMM 参数中的应用 . . . . . . . . . . . . . 28
3.4.1 期望最大化算法介绍 . . . . . . . . . . . . . . . . . . . . . . . . . 28
3.4.2 使用 EM 算法来学习 HMM 参数——Baum-Welch 算法 . . . . . . 30
3.5 用于解码 HMM 状态序列的维特比算法 . . . . . . . . . . . . . . . . . . . 34
3.5.1 动态规划和维特比算法 . . . . . . . . . . . . . . . . . . . . . . . . 34
3.5.2 用于解码 HMM 状态的动态规划算法 . . . . . . . . . . . . . . . . 35
3.6 隐马尔可夫模型和生成语音识别模型的变体 . . . . . . . . . . . . . . . . 37
3.6.1 用于语音识别的 GMM-HMM 模型 . . . . . . . . . . . . . . . . . 38
3.6.2 基于轨迹和隐藏动态模型的语音建模和识别 . . . . . . . . . . . . 39
3.6.3 使用生成模型 HMM 及其变体解决语音识别问题 . . . . . . . . . 40
第二部分 深度神经网络 43
第 4 章 深度神经网络 45
4.1 深度神经网络框架 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
4.2 使用误差反向传播来进行参数训练 . . . . . . . . . . . . . . . . . . . . . 48
4.2.1 训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
4.2.2 训练算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
4.3 实际应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
4.3.1 数据预处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
4.3.2 模型初始化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
4.3.3 权重衰减 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
4.3.4 丢弃法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
4.3.5 批量块大小的选择 . . . . . . . . . . . . . . . . . . . . . . . . . . 58
4.3.6 取样随机化 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
4.3.7 惯性系数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
4.3.8 学习率和停止准则 . . . . . . . . . . . . . . . . . . . . . . . . . . 61
4.3.9 网络结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
4.3.10 可复现性与可重启性 . . . . . . . . . . . . . . . . . . . . . . . . . 62
第 5 章 高级模型初始化技术 65
5.1 受限玻尔兹曼机 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
5.1.1 受限玻尔兹曼机的属性 . . . . . . . . . . . . . . . . . . . . . . . . 67
5.1.2 受限玻尔兹曼机参数学习 . . . . . . . . . . . . . . . . . . . . . . 70
5.2 深度置信网络预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73
5.3 降噪自动编码器预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
5.4 鉴别性预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
5.5 混合预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78
5.6 采用丢弃法的预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79
第三部分 语音识别中的深度神经网络–隐马尔可夫混合模型 81
第 6 章 深度神经网络–隐马尔可夫模型混合系统 83
6.1 DNN-HMM 混合系统 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
6.1.1 结构 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83
6.1.2 用 CD-DNN-HMM 解码 . . . . . . . . . . . . . . . . . . . . . . . . 85
6.1.3 CD-DNN-HMM 训练过程 . . . . . . . . . . . . . . . . . . . . . . . 86
6.1.4 上下文窗口的影响 . . . . . . . . . . . . . . . . . . . . . . . . . . 88
6.2 CD-DNN-HMM 的关键模块及分析 . . . . . . . . . . . . . . . . . . . . . 90
6.2.1 进行比较和分析的数据集和实验 . . . . . . . . . . . . . . . . . . 90
6.2.2 对单音素或者三音素的状态进行建模 . . . . . . . . . . . . . . . . 92
6.2.3 越深越好 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
6.2.4 利用相邻的语音帧 . . . . . . . . . . . . . . . . . . . . . . . . . . 94
6.2.5 预训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
6.2.6 训练数据的标注质量的影响 . . . . . . . . . . . . . . . . . . . . . 95
6.2.7 调整转移概率 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
6.3 基于 KL 距离的隐马尔可夫模型 . . . . . . . . . . . . . . . . . . . . . . . 96
第 7 章 训练和解码的加速 99
7.1 训练加速 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
7.1.1 使用多 GPU 流水线反向传播 . . . . . . . . . . . . . . . . . . . . 100
7.1.2 异步随机梯度下降 . . . . . . . . . . . . . . . . . . . . . . . . . . 103
7.1.3 增广拉格朗日算法及乘子方向交替算法 . . . . . . . . . . . . . . 106
7.1.4 减小模型规模 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107
7.1.5 其他方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 108
7.2 加速解码 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
7.2.1 并行计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
7.2.2 稀疏网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
7.2.3 低秩近似 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
7.2.4 用大尺寸 DNN 训练小尺寸 DNN . . . . . . . . . . . . . . . . . . 114
7.2.5 多帧 DNN . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
第 8 章 深度神经网络序列鉴别性训练 117
8.1 序列鉴别性训练准则 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
8.1.1 最大相互信息 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 118
8.1.2 增强型 MMI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 119
8.1.3 最小音素错误/状态级最小贝叶斯风险 . . . . . . . . . . . . . . . 120
8.1.4 统一的公式 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
8.2 具体实现中的考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
8.2.1 词图产生 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
8.2.2 词图补偿 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
8.2.3 帧平滑 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
8.2.4 学习率调整 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
8.2.5 训练准则选择 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
8.2.6 其他考量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
8.3 噪声对比估计 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
8.3.1 将概率密度估计问题转换为二分类设计问题 . . . . . . . . . . . . 127
8.3.2 拓展到未归一化的模型 . . . . . . . . . . . . . . . . . . . . . . . . 129
8.3.3 在深度学习网络训练中应用噪声对比估计算法 . . . . . . . . . . 130
第四部分 深度神经网络中的特征表示学习 133
第 9 章 深度神经网络中的特征表示学习 135
9.1 特征和分类器的联合学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
9.2 特征层级 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
9.3 使用随意输入特征的灵活性 . . . . . . . . . . . . . . . . . . . . . . . . . 140
9.4 特征的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
9.4.1 对说话人变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . 141
9.4.2 对环境变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 142
9.5 对环境的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
9.5.1 对噪声的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
9.5.2 对语速变化的鲁棒性 . . . . . . . . . . . . . . . . . . . . . . . . . 147
9.6 缺乏严重信号失真情况下的推广能力 . . . . . . . . . . . . . . . . . . . . 148
第 10 章 深度神经网络和混合高斯模型的融合 151
10.1 在 GMM-HMM 系统中使用由 DNN 衍生的特征 . . . . . . . . . . . . . . 151
10.1.1 使用 Tandem 和瓶颈特征的 GMM-HMM 模型 . . . . . . . . . . . 151
10.1.2 DNN-HMM 混合系统与采用深度特征的 GMM-HMM 系统的比较 154
10.2 识别结果融合技术 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
10.2.1 识别错误票选降低技术（ ROVER） . . . . . . . . . . . . . . . . . 157
10.2.2 分段条件随机场（ SCARF） . . . . . . . . . . . . . . . . . . . . . 159
10.2.3 最小贝叶斯风险词图融合 . . . . . . . . . . . . . . . . . . . . . . 160
10.3 帧级别的声学分数融合 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
10.4 多流语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
第 11 章 深度神经网络的自适应技术 165
11.1 深度神经网络中的自适应问题 . . . . . . . . . . . . . . . . . . . . . . . . 165
11.2 线性变换 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
11.2.1 线性输入网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
11.2.2 线性输出网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
11.3 线性隐层网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169
11.4 保守训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 170
11.4.1 L 2 正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
11.4.2 KL 距离正则项 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
11.4.3 减少每个说话人的模型开销 . . . . . . . . . . . . . . . . . . . . . 173
11.5 子空间方法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
11.5.1 通过主成分分析构建子空间 . . . . . . . . . . . . . . . . . . . . . 175
11.5.2 噪声感知、说话人感知及设备感知训练 . . . . . . . . . . . . . . 176
11.5.3 张量 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
11.6 DNN 说话人自适应的效果 . . . . . . . . . . . . . . . . . . . . . . . . . . 181
11.6.1 基于 KL 距离的正则化方法 . . . . . . . . . . . . . . . . . . . . . 181
11.6.2 说话人感知训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 183
第五部分 先进的深度学习模型 185
第 12 章 深度神经网络中的表征共享和迁移 187
12.1 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
12.1.1 多任务学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
12.1.2 迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
12.2 多语言和跨语言语音识别 . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
12.2.1 基于 Tandem 或瓶颈特征的跨语言语音识别 . . . . . . . . . . . . 190
12.2.2 共享隐层的多语言深度神经网络 . . . . . . . . . . . . . . . . . . 191
12.2.3 跨语言模型迁移 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 194
12.3 语音识别中深度神经网络的多目标学习 . . . . . . . . . . . . . . . . . . . 197
12.3.1 使用多任务学习的鲁棒语音识别 . . . . . . . . . . . . . . . . . . 197
12.3.2 使用多任务学习改善音素识别 . . . . . . . . . . . . . . . . . . . . 198
12.3.3 同时识别音素和字素（ graphemes） . . . . . . . . . . . . . . . . . 199
12.4 使用视听信息的鲁棒语音识别 . . . . . . . . . . . . . . . . . . . . . . . . 199
第 13 章 循环神经网络及相关模型 201
13.1 介绍 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
13.2 基本循环神经网络中的状态-空间公式 . . . . . . . . . . . . . . . . . . . . 203
13.3 沿时反向传播学习算法 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 204
13.3.1 最小化目标函数 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
13.3.2 误差项的递归计算 . . . . . . . . . . . . . . . . . . . . . . . . . . 205
13.3.3 循环神经网络权重的更新 . . . . . . . . . . . . . . . . . . . . . . 206
13.4 一种用于学习循环神经网络的原始对偶技术 . . . . . . . . . . . . . . . . 208
13.4.1 循环神经网络学习的难点 . . . . . . . . . . . . . . . . . . . . . . 208
13.4.2 回声状态（ Echo-State）性质及其充分条件 . . . . . . . . . . . . . 208
13.4.3 将循环神经网络的学习转化为带约束的优化问题 . . . . . . . . . 209
13.4.4 一种用于学习 RNN 的原始对偶方法 . . . . . . . . . . . . . . . . 210
13.5 结合长短时记忆单元（ LSTM）的循环神经网络 . . . . . . . . . . . . . . 212
13.5.1 动机与应用 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 212
13.5.2 长短时记忆单元的神经元架构 . . . . . . . . . . . . . . . . . . . . 213
13.5.3 LSTM-RNN 的训练 . . . . . . . . . . . . . . . . . . . . . . . . . . 214
13.6 循环神经网络的对比分析 . . . . . . . . . . . . . . . . . . . . . . . . . . . 214
13.6.1 信息流方向的对比：自上而下还是自下而上 . . . . . . . . . . . . 215
13.6.2 信息表征的对比：集中式还是分布式 . . . . . . . . . . . . . . . . 217
13.6.3 解释能力的对比：隐含层推断还是端到端学习 . . . . . . . . . . 218
13.6.4 参数化方式的对比：吝啬参数集合还是大规模参数矩阵 . . . . . 218
13.6.5 模型学习方法的对比：变分推理还是梯度下降 . . . . . . . . . . 219
13.6.6 识别正确率的比较 . . . . . . . . . . . . . . . . . . . . . . . . . . 220
13.7 讨论 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
第 14 章 计算型网络 223
14.1 计算型网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
14.2 前向计算 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 224
14.3 模型训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
14.4 典型的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
14.4.1 无操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . . . . 232
14.4.2 含一个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 232
14.4.3 含两个操作数的计算节点 . . . . . . . . . . . . . . . . . . . . . . 237
14.4.4 用来计算统计量的计算节点类型 . . . . . . . . . . . . . . . . . . 244
14.5 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
14.6 循环连接 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
14.6.1 只在循环中一个接一个地处理样本 . . . . . . . . . . . . . . . . . 249
14.6.2 同时处理多个句子 . . . . . . . . . . . . . . . . . . . . . . . . . . 251
14.6.3 创建任意的循环神经网络 . . . . . . . . . . . . . . . . . . . . . . 252
第 15 章 总结及未来研究方向 255
15.1 路线图 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
15.1.1 语音识别中的深度神经网络启蒙 . . . . . . . . . . . . . . . . . . 255
15.1.2 深度神经网络训练和解码加速 . . . . . . . . . . . . . . . . . . . . 258
15.1.3 序列鉴别性训练 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
15.1.4 特征处理 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
15.1.5 自适应 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
15.1.6 多任务和迁移学习 . . . . . . . . . . . . . . . . . . . . . . . . . . 261
15.1.7 卷积神经网络 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
15.1.8 循环神经网络和长短时记忆神经网络 . . . . . . . . . . . . . . . . 261
15.1.9 其他深度模型 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
15.2 技术前沿和未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
15.2.1 技术前沿简析 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
15.2.2 未来方向 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
参考文献 267
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>解析深度学习：语音识别实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络设计（原书第2版）
出版者的话
译者序
前言
第1章　引言1
1.1　目标1
1.2　历史1
1.3　应用3
1.4　生物学启示4
1.5　扩展阅读5
第2章　神经元模型及网络结构8
2.1　目标8
2.2　理论与例子8
2.2.1　记号8
2.2.2　神经元模型8
2.2.3　网络结构11
2.3　小结15
2.4　例题17
2.5　结束语18
2.6　习题18
第3章　一个说明性的实例20
3.1　目标20
3.2　理论与例子20
3.2.1　问题描述20
3.2.2　感知机21
3.2.3　Hamming网络23
3.2.4　Hopfield网络26
3.3　结束语27
3.4　习题28
第4章　感知机学习规则31
4.1　目标31
4.2　理论与例子31
4.2.1　学习规则31
4.2.2　感知机结构32
4.2.3　感知机的学习规则35
4.2.4　收敛性证明39
4.3　小结41
4.4　例题42
4.5　结束语48
4.6　扩展阅读49
4.7　习题49
第5章　信号与权值向量空间53
5.1　目标53
5.2　理论与例子53
5.2.1　线性向量空间53
5.2.2　线性无关54
5.2.3　生成空间55
5.2.4　内积56
5.2.5　范数56
5.2.6　正交性56
5.2.7　向量展开式58
5.3　小结60
5.4　例题61
5.5　结束语66
5.6　扩展阅读67
5.7　习题67
第6章　神经网络中的线性变换71
6.1　目标71
6.2　理论与例子71
6.2.1　线性变换71
6.2.2　矩阵表示72
6.2.3　基变换74
6.2.4　特征值与特征向量76
6.3　小结79
6.4　例题79
6.5　结束语85
6.6　扩展阅读85
6.7　习题86
第7章　有监督的Hebb学习90
7.1　目标90
7.2　理论与例子90
7.2.1　线性联想器91
7.2.2　Hebb规则91
7.2.3　伪逆规则93
7.2.4　应用95
7.2.5　Hebb学习的变形96
7.3　小结97
7.4　例题98
7.5　结束语105
7.6　扩展阅读105
7.7　习题106
第8章　性能曲面和最优点108
8.1　目标108
8.2　理论与例子108
8.2.1　泰勒级数108
8.2.2　方向导数110
8.2.3　极小点111
8.2.4　优化的必要条件113
8.2.5　二次函数114
8.3　小结119
8.4　例题120
8.5　结束语127
8.6　扩展阅读127
8.7　习题128
第9章　性能优化131
9.1　目标131
9.2　理论与例子131
9.2.1　最速下降法131
9.2.2　牛顿法136
9.2.3　共轭梯度法139
9.3　小结142
9.4　例题142
9.5　结束语150
9.6　扩展阅读150
9.7　习题151
第10章　Widrow-Hoff学习153
10.1　目标153
10.2　理论与例子153
10.2.1　ADALINE网络153
10.2.2　均方误差154
10.2.3　LMS算法156
10.2.4　收敛性分析157
10.2.5　自适应滤波器159
10.3　小结164
10.4　例题165
10.5　结束语174
10.6　扩展阅读174
10.7　习题175
第11章　反向传播179
11.1　目标179
11.2　理论与例子179
11.2.1　多层感知机179
11.2.2　反向传播算法182
11.2.3　例子186
11.2.4　批量训练和增量训练188
11.2.5　使用反向传播188
11.3　小结192
11.4　例题193
11.5　结束语201
11.6　扩展阅读201
11.7　习题202
第12章　反向传播算法的变形210
12.1　目标210
12.2　理论与例子210
12.2.1　反向传播算法的缺点210
12.2.2　反向传播算法的启发式改进215
12.2.3　数值优化技术218
12.3　小结226
12.4　例题228
12.5　结束语235
12.6　扩展阅读236
12.7　习题237
第13章　泛化241
13.1　目标241
13.2　理论与例子241
13.2.1　问题描述242
13.2.2　提升泛化能力的方法243
13.3　小结257
13.4　例题258
13.5　结束语265
13.6　扩展阅读265
13.7　习题266
第14章　动态网络270
14.1　目标270
14.2　理论与例子270
14.2.1　分层数字动态网络271
14.2.2　动态学习的基本原则273
14.2.3　动态反向传播276
14.3　小结288
14.4　例题290
14.5　结束语296
14.6　扩展阅读296
14.7　习题297
第15章　竞争网络302
15.1　目标302
15.2　理论与例子302
15.2.1　Hamming网络303
15.2.2　竞争层304
15.2.3　生物学中的竞争层307
15.2.4　自组织特征图308
15.2.5　学习向量量化310
15.3　小结314
15.4　例题315
15.5　结束语322
15.6　扩展阅读322
15.7　习题323
第16章　径向基网络329
16.1　目标329
16.2　理论与例子329
16.2.1　径向基网络329
16.2.2　训练RBF网络333
16.3　小结343
16.4　例题344
16.5　结束语347
16.6　扩展阅读347
16.7　习题348
第17章　实际训练问题352
17.1　目标352
17.2　理论与例子352
17.2.1　训练前的步骤353
17.2.2　网络训练359
17.2.3　训练结果分析362
17.3　结束语368
17.4　扩展阅读368
第18章　实例研究1:函数逼近370
18.1　目标370
18.2　理论与例子370
18.2.1　智能传感系统描述370
18.2.2　数据收集与预处理371
18.2.3　网络结构选择372
18.2.4　网络训练372
18.2.5　验证373
18.2.6　数据集374
18.3　结束语375
18.4　扩展阅读375
第19章　实例研究2：概率估计376
19.1　目标376
19.2　理论与例子376
19.2.1　CVD过程描述376
19.2.2　数据收集与预处理377
19.2.3　网络结构选择378
19.2.4　网络训练379
19.2.5　验证381
19.2.6　数据集382
19.3　结束语382
19.4　扩展阅读383
第20章　实例研究3：模式识别384
20.1　目标384
20.2　理论与例子384
20.2.1　心肌梗死识别问题描述384
20.2.2　数据收集与预处理384
20.2.3　网络结构选择387
20.2.4　网络训练387
20.2.5　验证388
20.2.6　数据集389
20.3　结束语390
20.4　扩展阅读390
第21章　实例研究4：聚类391
21.1　目标391
21.2　理论与例子391
21.2.1　森林覆盖问题描述391
21.2.2　数据收集与预处理392
21.2.3　网络结构选择392
21.2.4　网络训练393
21.2.5　验证394
21.2.6　数据集396
21.3　结束语396
21.4　扩展阅读396
第22章　实例研究5：预测398
22.1　目标398
22.2　理论与例子398
22.2.1　磁悬浮系统描述398
22.2.2　数据收集与预处理399
22.2.3　网络结构选择399
22.2.4　网络训练401
22.2.5　验证402
22.2.6　数据集404
22.3　结束语404
22.4　扩展阅读405
附录A　参考文献406
附录B　记号413
附录C　软件417
索引420
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络设计（原书第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python计算机视觉编程
《python计算机视觉编程》
推荐序 xi
前言 xiii
第1章　基本的图像操作和处理 1
1.1　pil：python图像处理类库 1
1.1.1　转换图像格式 2
1.1.2　创建缩略图 3
1.1.3　复制和粘贴图像区域 3
1.1.4　调整尺寸和旋转 3
1.2　matplotlib 4
1.2.1　绘制图像、点和线 4
1.2.2　图像轮廓和直方图 6
1.2.3　交互式标注 7
1.3　numpy 8
1.3.1　图像数组表示 8
1.3.2　灰度变换 9
1.3.3　图像缩放 11
1.3.4　直方图均衡化 11
1.3.5　图像平均 13
1.3.6　图像的主成分分析（pca） 14
1.3.7　使用pickle模块 16
1.4　scipy 17
1.4.1　图像模糊 18
1.4.2　图像导数 19
1.4.3　形态学：对象计数 22
1.4.4　一些有用的scipy模块 23
1.5　高级示例：图像去噪 24
练习 28
代码示例约定 29
第2章　局部图像描述子 31
2.1　harris角点检测器 31
2.2　sift（尺度不变特征变换） 39
2.2.1　兴趣点 39
2.2.2　描述子 39
2.2.3　检测兴趣点 40
2.2.4　匹配描述子 43
2.3　匹配地理标记图像 47
2.3.1　从panoramio下载地理标记图像 47
2.3.2　使用局部描述子匹配 50
2.3.3　可视化连接的图像 52
练习 54
第3章　图像到图像的映射 57
3.1　单应性变换 57
3.1.1　直接线性变换算法 59
3.1.2　仿射变换 60
3.2　图像扭曲 61
3.2.1　图像中的图像 63
3.2.2　分段仿射扭曲 67
3.2.3　图像配准 70
3.3　创建全景图 76
3.3.1　ransac 77
3.3.2　稳健的单应性矩阵估计 78
3.3.3　拼接图像 81
练习 84
第4章　照相机模型与增强现实 85
4.1　针孔照相机模型 85
4.1.1　照相机矩阵 86
4.1.2　三维点的投影 87
4.1.3　照相机矩阵的分解 89
4.1.4　计算照相机中心 90
4.2　照相机标定 91
4.3　以平面和标记物进行姿态估计 93
4.4　增强现实 97
4.4.1　pygame和pyopengl 97
4.4.2　从照相机矩阵到opengl格式 98
4.4.3　在图像中放置虚拟物体 100
4.4.4　综合集成 102
4.4.5　载入模型 104
练习 106
第5章　多视图几何 107
5.1　外极几何 107
5.1.1　一个简单的数据集 109
5.1.2　用matplotlib绘制三维数据 111
5.1.3　计算f：八点法 112
5.1.4　外极点和外极线 113
5.2　照相机和三维结构的计算 116
5.2.1　三角剖分 116
5.2.2　由三维点计算照相机矩阵 118
5.2.3　由基础矩阵计算照相机矩阵 120
5.3　多视图重建 122
5.3.1　稳健估计基础矩阵 123
5.3.2　三维重建示例 125
5.3.3　多视图的扩展示例 129
5.4　立体图像 130
练习 135
第6章　图像聚类 137
6.1　k-means聚类 137
6.1.1　scipy聚类包 138
6.1.2　图像聚类 139
6.1.3　在主成分上可视化图像 140
6.1.4　像素聚类 142
6.2　层次聚类 144
6.3　谱聚类 152
练习 157
第7章　图像搜索 159
7.1　基于内容的图像检索 159
7.2　视觉单词 160
7.3　图像索引 164
7.3.1　建立数据库 164
7.3.2　添加图像 165
7.4　在数据库中搜索图像 167
7.4.1　利用索引获取候选图像 168
7.4.2　用一幅图像进行查询 169
7.4.3　确定对比基准并绘制结果 171
7.5　使用几何特性对结果排序 172
7.6　建立演示程序及web应用 176
7.6.1　用cherrypy创建web应用 176
7.6.2　图像搜索演示程序 176
练习 179
第8章　图像内容分类 181
8.1　k邻近分类法（knn） 181
8.1.1　一个简单的二维示例 182
8.1.2　用稠密sift作为图像特征 185
8.1.3　图像分类：手势识别 187
8.2　贝叶斯分类器 190
8.3　支持向量机 195
8.3.1　使用libsvm 196
8.3.2　再论手势识别 198
8.4　光学字符识别 199
8.4.1　训练分类器 200
8.4.2　选取特征 200
8.4.3　多类支持向量机 201
8.4.4　提取单元格并识别字符 202
8.4.5　图像校正 205
练习 206
第9章　图像分割 209
9.1　图割（graph cut） 209
9.1.1　从图像创建图 211
9.1.2　用户交互式分割 216
9.2　利用聚类进行分割 218
9.3　变分法 224
练习 226
第10章　opencv 227
10.1　opencv的python接口 227
10.2　opencv基础知识 228
10.2.1　读取和写入图像 228
10.2.2　颜色空间 228
10.2.3　显示图像及结果 229
10.3　处理视频 232
10.3.1　视频输入 232
10.3.2　将视频读取到numpy数组中 234
10.4　跟踪 234
10.4.1　光流 235
10.4.2　lucas-kanade算法 237
10.5　更多示例 243
10.5.1　图像修复 243
10.5.2　利用分水岭变换进行分割 244
10.5.3　利用霍夫变换检测直线 245
练习 246
附录a　安装软件包 247
a.1　numpy和scipy 247
a.1.1　windows 247
a.1.2　mac os x 247
a.1.3　linux 248
a.2　matplotlib 248
a.3　pil 248
a.4　libsvm 249
a.5　opencv 249
a.5.1　windows 和 unix 249
a.5.2　mac os x 249
a.5.3　linux 250
a.6　vlfeat 250
a.7　pygame 250
a.8　pyopengl 250
a.9　pydot 251
a.10　python-graph 251
a.11　simplejson 252
a.12　pysqlite 252
a.13　cherrypy 252
附录b　图像集 253
b.1　flickr 253
b.2　panoramio 254
b.3　牛津大学视觉几何组 255
b.4　肯塔基大学识别基准图像 255
b.5　其他 256
b.5.1　prague texture segmentation datagenerator与基准 256
b.5.2　微软研究院grab cut数据集 256
b.5.3　caltech 101 256
b.5.4　静态手势数据库 256
b.5.5　middlebury stereo数据集 256
附录c　图片来源 257
c.1　来自flickr的图像 257
c.2　其他图像 258
c.3　插图 258
参考文献 259
索引 263
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python计算机视觉编程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>概率图模型：原理与技术
目 录
致谢  29
插图目录  31
算法目录  39
专栏目录  41
第 1章引言 .. 1
1.1动机 . 1
1.2结构化概率模型 . 2
1.2.1  概率图模型 . 3
1.2.2  表示、推理、学习 . 5
1.3概述和路线图 . 6
1.3.1  各章的概述 . 6
1.3.2  读者指南 . 9
1.3.3  与其他学科的联系 ... 10
1.4历史注记 ... 12
第 2章 基础知识  15
2.1概率论 ... 15
2.1.1  概率分布 ... 15
2.1.2  概率中的基本概念 ... 17
2.1.3  随机变量与联合分布 ... 19
2.1.4  独立性与条件独立性 ... 22
2.1.5  查询一个分布 ... 25
2.1.6  连续空间 ... 27
2.1.7  期望与方差 ... 30
2.2图 ... 33
2.2.1  节点与边 ... 33
2.2.2  子图... 34
2.2.3  路径与迹 ... 35
2.2.4  圈与环 ... 36
2.3相关文献 ... 37
2.4习题 ... 38
第Ⅰ部分表示
第 3章贝叶斯网表示  45
3.1独立性性质的利用 ... 45
3.1.1  随机变量的独立性 ... 45
3.1.2  条件参数化方法 ... 46
3.1.3  朴素贝叶斯模型 ... 48
3.2贝叶斯网 ... 51
3.2.1  学生示例回顾 ... 51
3.2.2  贝叶斯网的基本独立性 ... 55
3.2.3  图与分布 ... 59
3.3图中的独立性 ... 68
3.3.1  d-分离 ... 68
3.3.2  可靠性与完备性 ... 71
3.3.3  d-分离算法 ... 73
3.3.4  I-等价  75
3.4从分布到图 ... 77
3.4.1  昀小 I-map  78
3.4.2 P-map  80
3.4.3  发现 P-map* . 82
3.5小结 ... 91
3.6相关文献 ... 92
3.7习题 ... 95
第 4章无向图模型 .. 103
4.1误解示例 . 103
4.2参数化 . 106
4.2.1  因子. 106
4.2.2  吉布斯分布与马尔可夫网 . 107
4.2.3  简化的马尔可夫网 . 110
4.3马尔可夫网的独立性 . 113
4.3.1  基本独立性 . 113
4.3.2  独立性回顾 . 116
4.3.3  从分布到图 . 119
4.4参数化回顾 . 121
4.4.1  细粒度参数化方法 . 121
4.4.2  过参数化 . 127
4.5贝叶斯网与马尔可夫网 . 132
4.5.1  从贝叶斯网到马尔可夫网 . 132
4.5.2  从马尔可夫网到贝叶斯网 . 136
4.5.3  弦图. 138
4.6部分有向模型 . 140
4.6.1  条件随机场 . 141
4.6.2  链图模型 *... 146
4.7总结与讨论 . 149
4.8相关文献 . 150
4.9习题 . 151
第 5章局部概率模型 .. 155
5.1 CPD表  155
5.2确定性 CPD  156
5.2.1  表示. 156
5.2.2  独立性 . 157
5.3特定上下文 CPD  160
5.3.1  表示. 160
5.3.2  独立性 . 168
5.4因果影响的独立性 . 172
5.4.1  Noisy-or模型 . 172
5.4.2  广义线性模型 . 175
5.4.3  一般公式化表示 . 179
5.4.4  独立性 . 180
5.5连续变量 . 181
5.5.1  混合模型 . 185
5.6条件贝叶斯网 . 187
5.7总结 . 189
5.8相关文献 . 189
5.9习题 . 191
第 6章基于模板的表示 .. 195
6.1引言 . 195
6.2时序模型 . 196
6.2.1  基本假设 . 196
6.2.2  动态贝叶斯网 . 198
6.2.3  状态-观测模型 ... 203
6.3模板变量与模板因子 . 208
6.4对象-关系领域的有向概率模型  211
6.4.1  Plate模型 211
6.4.2  概率关系模型 . 217
6.5无向表示 . 223
6.6结构不确定性 * ... 227
6.6.1  关系不确定性 . 227
6.6.2  对象不确定性 . 230
6.7小结 . 235
6.8相关文献 . 236
6.9习题 . 237
第 7章高斯网络模型 .. 241
7.1多元高斯分布 . 241
7.1.1  基本参数化方法 . 241
7.1.2  高斯分布的运算 . 243
7.1.3  高斯分布的独立性 . 244
7.2高斯贝叶斯网 . 245
7.3高斯马尔可夫随机场 . 248
7.4小结 . 251
7.5相关文献 . 251
7.6习题 . 252
第 8章指数族 .. 255
8.1引言 . 255
8.2指数族 . 255
8.2.1  线性指数族 . 257
8.3因式化的指数族( factored exponential families)... 260
8.3.1  乘积分布( product distributions) 260
8.3.2  贝叶斯网 . 261
8.4熵和相对熵 . 263
8.4.1  熵. 263
8.4.2  相对熵 . 266
8.5投影 . 267
8.5.1  比较. 268
8.5.2  M-投影 270
8.5.3  I-投影 .. 275
8.6小结 . 275
8.7相关文献 . 276
8.8习题 . 276
第Ⅱ部分推理
第 9章精确推理：变量消除 .. 281
9.1复杂性分析 . 281
9.1.1  精确推理分析 . 282
9.1.2  近似推理分析 . 284
9.2变量消除：基本思路 . 286
9.3变量消除 . 290
9.3.1  基本消除 . 290
9.3.2  证据处理 . 295
9.4复杂度与图结构：变量消除 . 298
9.4.1  简单分析 . 298
9.4.2  图论分析 . 299
9.4.3  寻找消除顺序 *... 302
9.5条件作用 * ... 308
9.5.1  条件作用算法 . 308
9.5.2  条件作用与变量消除 . 309
9.5.3  图论分析 . 313
9.5.4  改进的条件作用算法 . 314
9.6用结构 CPD推理*.. 316
9.6.1  因果影响的独立性 . 316
9.6.2  上下文特定的独立性 . 319
9.6.3  讨论. 326
9.7总结和讨论 . 327
9.8相关文献 . 328
9.9习题 . 329
第 10章精确推理：团树  337
10.1  变量消除与团树 ... 337
10.1.1  聚类图 . 337
10.1.2  团树. 338
10.2  消息传递：和积 ... 340
10.2.1  团树中的变量消除 . 341
10.2.2  团树校准 . 346
10.2.3  将校准团树作为一个分布 . 352
10.3  消息传递：置信更新 ... 355
10.3.1  使用除法的消息传递 . 356
10.3.2  和-积与置信-更新消息的等价性 .. 359
10.3.3  回答查询 . 360
10.4  构建一个团树 ... 364
10.4.1  源自变量消除的团树 . 364
10.4.2  源自弦图的团树 . 365
10.5  小结 ... 367
10.6  相关文献 ... 368
10.7  习题 ... 369
第 11章作为优化的推理  373
11.1引言 ... 373
11.1.1  再议精确推理 * ... 374
11.1.2  能量泛函 . 376
11.1.3  优化能量泛函 . 377
11.2作为优化的精确推理 ... 378
11.2.1  不动点刻画 . 379
11.2.2  推理优化 . 382
11.3基于传播的近似 ... 382
11.3.1  一个简单的例子 . 383
11.3.2  聚类图置信传播 . 387
11.3.3  聚类图置信传播的性质 . 391
11.3.4  收敛性分析 * ... 393
11.3.5  构建聚类图 . 395
11.3.6  变分分析 . 401
11.3.7  其他熵近似 * ... 404
11.3.8  讨论. 417
11.4近似消息传播 *.. 419
11.4.1  因子分解的消息 . 419
11.4.2  近似消息计算 . 422
11.4.3  近似消息推理 . 425
11.4.4  期望传播 . 431
11.4.5  变分分析 . 434
11.4.6  讨论. 436
11.5结构化的变分近似 ... 437
11.5.1  平均场近似 . 438
11.5.2  结构化的近似 . 445
11.5.3  局部变分法 * ... 456
11.6总结与讨论 ... 460
11.7相关文献 ... 462
11.8习题 ... 464
第 12章基于粒子的近似推理  475
12.1  前向采样 ... 476
12.1.1  从贝叶斯网中采样 . 476
12.1.2  误差分析 . 478
12.1.3  条件概率查询 . 479
12.2  似然加权与重要性采样 ... 480
12.2.1  似然加权：直觉 . 480
12.2.2  重要性采样 . 482
12.2.3  贝叶斯网的重要性采样 . 486
12.2.4  重要性采样回顾 . 492
12.3  马尔可夫链的蒙特卡罗方法 ... 492
12.3.1  吉布斯采样算法 . 493
12.3.2  马尔可夫链 . 494
12.3.3  吉布斯采样回顾 . 499
12.3.4  马尔可夫链的一个更广泛的类 * ... 502
12.3.5  马尔可夫链的使用 . 505
12.4  坍塌的粒子 ... 512
12.4.1  坍塌的似然加权 *... 513
12.4.2  坍塌的 MCMC ... 517
12.5  确定性搜索方法 * . 522
12.6  小结 ... 525
12.7  相关文献 ... 527
12.8  习题 ... 529
第 13章最大后验概率推理  537
13.1  综述 ... 537
13.1.1  计算复杂性 . 537
13.1.2  解决方法综述 . 538
13.2  (边缘) MAP的变量消除.. 540
13.2.1  昀大-积变量消除 ... 540
13.2.2  找到昀可能的赋值 . 542
13.2.3  边缘 MAP的变量消除*  545
13.3  团树中的昀大 -积.. 547
13.3.1  计算昀大 -边缘 ... 548
13.3.2  作为再参数化的信息传递 . 549
13.3.3  昀大-边缘解码 ... 550
13.4  多圈聚类图中的昀大 -积置信传播 .. 553
13.4.1  标准昀大 -积消息传递 ... 553
13.4.2  带有计数的昀大 -积 BP* 557
13.4.3  讨论. 560
13.5  作为线性优化问题的 MAP* 562
13.5.1  整数规划的公式化 . 562
13.5.2  线性规划松弛 . 564
13.5.3  低温极限 . 566
13.6  对 MAP使用图割. 572
13.6.1  使用图割的推理 . 572
13.6.2  非二元变量 . 575
13.7  局部搜索算法 * . 579
13.8  小结 ... 580
13.9  相关文献 ... 582
13.10习题 . 584
第 14章混合网络中的推理  589
14.1  引言 ... 589
14.1.1  挑战. 589
14.1.2  离散化 . 590
14.1.3  概述. 591
14.2  高斯网络中的变量消除 ... 592
14.2.1  标准型 . 592
14.2.2  和-积算法 ... 595
14.2.3  高斯置信传播 . 596
14.3  混合网络 ... 598
14.3.1  面临的困难 . 599
14.3.2  混合高斯网络的因子运算 . 601
14.3.3  CLG网络的 EP .. 604
14.3.4  一个“准确的” CLG算法* .. 609
14.4  非线性依赖 ... 613
14.4.1  线性化 . 614
14.4.2  使用高斯近似的期望传播 . 620
14.5  基于粒子的近似方法 ... 624
14.5.1  在连续空间中采样 . 625
14.5.2  贝叶斯网中的前向采样 . 626
14.5.3  马尔可夫链 -蒙特卡罗方法 626
14.5.4  坍塌的粒子 . 627
14.5.5  非参数消息传递 . 628
14.6  总结与讨论 ... 629
14.7  相关文献 ... 630
14.8  习题 ... 631
第 15章时序模型中的推理  635
15.1  推理任务 ... 636
15.2  精确推理 ... 637
15.2.1  状态观测模型的滤波 . 637
15.2.2  作为团树传播的滤波 . 638
15.2.3  DBN中的团树推理 ... 639
15.2.4  复杂情况探讨 . 640
15.3  近似推理 ... 644
15.3.1  核心思想 . 645
15.3.2  因子分解的置信状态方法 . 646
15.3.3  粒子滤波 . 648
15.3.4  确定性搜索方法 . 658
15.4  混合 DBN.. 659
15.4.1  连续模型 . 659
15.4.2  混合模型 . 667
15.5  小结 ... 671
15.6  相关文献 ... 672
15.7  习题 ... 674
第 Ⅲ部分学习
第 16章图模型学习：概述  681
16.1  动机 ... 681
16.2  学习目标 ... 682
16.2.1  密度估计 . 682
16.2.2  具体的预测任务 . 684
16.2.3  知识发现 . 685
16.3  优化学习 ... 686
16.3.1  经验风险与过拟合 . 686
16.3.2  判别式与生成式训练 . 693
16.4  学习任务 ... 695
16.4.1  模型限制 . 695
16.4.2  数据的可观测性 . 696
16.4.3  学习任务的分类 . 697
16.5  相关文献 ... 698
第 17章参数估计  699
17.1  昀大似然估计( MLE) 699
17.1.1  图钉的例子 . 699
17.1.2  昀大似然准则 . 701
17.2  贝叶斯网的 MLE.. 704
17.2.1  一个简单的例子 . 704
17.2.2  全局似然分解 . 706
17.2.3  CPD表 707
17.2.4  高斯贝叶斯网 *... 709
17.2.5  作为 M-投影的昀大似然估计* . 713
17.3  贝叶斯参数估计 ... 714
17.3.1  图钉例子的回顾 . 714
17.3.2  先验分布与后验分布 . 719
17.4  贝叶斯网中的贝叶斯参数估计 ... 723
17.4.1  参数独立性与全局分解 . 723
17.4.2  局部分解 . 727
17.4.3  贝叶斯网学习的先验分布 . 729
17.4.4  MAP估计* . 732
17.5  具有共享参数的学习模型 ... 735
17.5.1  全局参数共享 . 736
17.5.2  局部参数共享 . 741
17.5.3  具有共享参数的贝叶斯推断 . 742
17.5.4  层次先验 *... 744
17.6  泛化分析 * . 750
17.6.1  渐近性分析 . 750
17.6.2  PAC界  751
17.7  小结 ... 757
17.8  相关文献 ... 758
17.9  习题 ... 759
第 18章贝叶斯网中的结构学习  767
18.1  引言 ... 767
18.1.1  问题定义 . 767
18.1.2  方法概述 . 769
18.2  基于约束的方法 ... 769
18.2.1  总体框架 . 769
18.2.2  独立性检验 . 771
18.3  结构得分 ... 774
18.3.1  似然得分 . 774
18.3.2  贝叶斯得分 . 778
18.3.3  单个变量的边缘似然 . 780
18.3.4  贝叶斯网的贝叶斯得分 . 782
18.3.5  理解贝叶斯得分 . 785
18.3.6  先验性 . 787
18.3.7  得分等价性 *... 790
18.4  结构搜索 ... 791
18.4.1  学习树结构网络 . 791
18.4.2  给定顺序 . 793
18.4.3  一般图 . 794
18.4.4  用等价类学习 *... 804
18.5  贝叶斯模型平均 * . 807
18.5.1  基本理论 . 807
18.5.2  基于给定序的模型平均 . 809
18.5.3  一般的情况 . 811
18.6  带有附加结构的学习模型 ... 815
18.6.1  带有局部结构的学习 . 816
18.6.2  学习模板模型 . 819
18.7  总结与讨论 ... 821
18.8  相关文献 ... 822
18.9  习题 ... 825
第 19章部分观测数据  833
19.1  基础知识 ... 833
19.1.1  数据的似然和观测模型 . 833
19.1.2  观测机制的解耦 . 837
19.1.3  似然函数 . 840
19.1.4  可识别性 . 843
19.2  参数估计 ... 846
19.2.1  梯度上升方法 . 846
19.2.2  期望昀大化（ EM）... 852
19.2.3  比较：梯度上升与 EM.. 870
19.2.4  近似推理 *... 876
19.3  使用不完备数据的贝叶斯学习 *.. 880
19.3.1  概述. 880
19.3.2  MCMC采样 ... 881
19.3.3  变分贝叶斯学习 . 887
19.4  结构学习 ... 890
19.4.1  结构得分 . 891
19.4.2  结构搜索 . 898
19.4.3  结构 EM.. 902
19.5  带有隐变量的学习模型 ... 907
19.5.1  隐变量的信息内容 . 908
19.5.2  确定基数 . 909
19.5.3  引入隐变量 . 912
19.6  小结 ... 914
19.7  相关文献 ... 915
19.8  习题 ... 917
第 20章学习无向模型  927
20.1  概述 ... 927
20.2  似然函数 ... 928
20.2.1  一个例子 . 928
20.2.2  似然函数的形式 . 930
20.2.3  似然函数的性质 . 930
20.3  昀大（条件）似然参数估计 ... 932
20.3.1  昀大似然估计 . 933
20.3.2  条件训练模型 . 934
20.3.3  用缺失数据学习 . 937
20.3.4  昀大熵和昀大似然 *... 939
20.4  参数先验与正则化 ... 941
20.4.1  局部先验 . 942
20.4.2  全局先验 . 944
20.5  用近似推理学习 ... 945
20.5.1  信念传播 . 945
20.5.2  基于 MAP的学习*  950
20.6  替代目标 ... 953
20.6.1  伪似然及其推广 . 953
20.6.2  对比优化准则 . 957
20.7  结构学习 ... 962
20.7.1  使用独立性检验的结构学习 . 962
20.7.2  基于得分的学习：假设空间 . 964
20.7.3  目标函数 . 965
20.7.4  优化任务 . 968
20.7.5  评估模型的改变 . 975
20.8  小结 ... 978
20.9  相关文献 ... 981
20.10习题 . 984
第 Ⅳ部分行为与决策
第 21章因果关系  993
21.1  动机与概述 ... 993
21.1.1  条件作用与干预 . 993
21.1.2  相关关系和因果关系 . 996
21.2  因果关系模型 ... 998
21.3  结构性因果关系的可识别性 . 1000
21.3.1  查询简化规则 ... 1001
21.3.2  迭代的查询简化 ... 1003
21.4  机制与响应变量 * ... 1009
21.5  函数因果模型中的部分可识别性 * 1013
21.6  虚拟查询 * ... 1017
21.6.1  成对的网络 ... 1017
21.6.2  虚拟查询的界 ... 1020
21.7  学习因果模型 . 1021
21.7.1  学习没有混合因素的因果模型 ... 1022
21.7.2  从干预数据中学习 ... 1025
21.7.3  处理隐变量 *. 1029
21.7.4  学习功能因果关系模型 *.. 1032
21.8  小结 . 1033
21.9  相关文献 . 1034
21.10习题 ... 1035
第 22章效用和决策 .. 1039
22.1  基础：期望效用昀大化 . 1039
22.1.1  不确定性情况下的决策制定 ... 1039
22.1.2  理论证明 *. 1041
22.2  效用曲线 . 1044
22.2.1  货币效用 ... 1044
22.2.2  风险态度 ... 1046
22.2.3  合理性 ... 1047
22.3  效用的获取 . 1048
22.3.1  效用获取过程 ... 1048
22.3.2  人类生命的效用 ... 1049
22.4  复杂结果的效用 . 1050
22.4.1  偏好和效用独立性 *. 1051
22.4.2  加法独立性特性 ... 1053
22.5  小结 . 1060
22.6  相关文献 . 1061
22.7  习题 . 1063
第 23章结构化决策问题 .. 1065
23.1  决策树 . 1065
23.1.1  表示... 1065
23.1.2  逆向归纳算法 ... 1067
23.2  影响图 . 1068
23.2.1  基本描述 ... 1068
23.2.2  决策规则 ... 1070
23.2.3时间与记忆 ... 1071
23.2.4 语义与昀优性准则 ... 1072
23.3  影响图的逆向归纳 . 1075
23.3.1  影响图的决策树 ... 1075
23.3.2  求和-昀大化-求和规则  1077
23.4  期望效用的计算 . 1079
23.4.1  简单的变量消除 ... 1079
23.4.2  多个效用变量：简单的方法 ... 1080
23.4.3 广义变量消除 *. 1081
23.5  影响图中的昀优化 . 1086
23.5.1  昀优化一个单一的决策规则 ... 1086
23.5.2  迭代优化算法 ... 1087
23.5.3  策略关联与全局昀优性 *. 1089
23.6  忽略无关的信息 * ... 1097
23.7  信息的价值 . 1100
23.7.1  单一观察 ... 1100
23.7.2  多重观察 ... 1103
23.8  小结 . 1105
23.9  相关文献 . 1106
23.10习题 ... 1108
第 24章结束语 .. 1113
附录 A背景材料  1117
A.1信息论 .. 1117
A.1.1  压缩和熵 . 1117
A.1.2  条件熵与信息 . 1119
A.1.3  相对熵和分布距离 . 1120
A.2收敛界 .. 1123
A.2.1  中心极限定理 . 1124
A.2.2  收敛界 . 1125
A.3算法与算法复杂性 .. 1126
A.3.1  基本图算法 .. 1126
A.3.2  算法复杂性分析 .. 1127
A.3.3  动态规划 .. 1129
A.3.4  复杂性理论 .. 1130
A.4组合优化与搜索 .. 1134
A.4.1  优化问题 .. 1134
A.4.2  局部搜索 .. 1134
A.4.3  分支限界搜索 .. 1141
A.5连续昀优化 .. 1142
A.5.1  连续函数昀优解的刻画 .. 1142
A.5.2  梯度上升方法 .. 1144
A.5.3  约束优化 .. 1148
A.5.4  凸对偶性 .. 1152
参考文献  1155
符号索引  1191
主题索引 1195
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>概率图模型：原理与技术
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习：21天实战Caffe
上篇 初见
第1天 什么是深度学习 2
1.1 星星之火，可以燎原 3
1.2 师夷长技 4
1.2.1 谷歌与微软 4
1.2.2 Facebook、亚马逊与NVIDIA 5
1.3 中国崛起 6
1.3.1 BAT在路上 6
1.3.2 星光闪耀 7
1.3.3 企业热是风向标 8
1.4 练习题 9
第2天 深度学习的过往 10
2.1 传统机器学习的局限性 10
2.2 从表示学习到深度学习 11
2.3 监督学习 12
2.4 反向传播算法 13
2.5 卷积神经网络 15
2.6 深度学习反思 17
2.7 练习题 18
2.8 参考资料 18
第3天 深度学习工具汇总 19
3.1 Caffe 19
3.2 Torch & OverFeat 20
3.3 MxNet 22
3.4 TensorFlow 22
3.5 Theano 24
3.6 CNTK 24
3.7 练习题 25
3.8 参考资料 26
第4天 准备Caffe环境 27
4.1 Mac OS环境准备 27
4.2 Ubuntu环境准备 28
4.3 RHEL/Fedora/CentOS环境准备 29
4.4 Windows环境准备 29
4.5 常见问题 32
4.6 练习题 32
4.7 参考资料 33
第5天 Caffe依赖包解析 34
5.1 ProtoBuffer 34
5.2 Boost 38
5.3 GFLAGS 38
5.4 GLOG 39
5.5 BLAS 40
5.6 HDF5 41
5.7 OpenCV 42
5.8 LMDB和LEVELDB 42
5.9 Snappy 43
5.10 小结 43
5.11 练习题 49
5.12 参考资料 49
第6天 运行手写体数字识别例程 50
6.1 MNIST数据集 50
6.1.1 下载MNIST数据集 50
6.1.2 MNIST数据格式描述 51
6.1.3 转换格式 53
6.2 LeNet-5模型 60
6.2.1 LeNet-5模型描述 60
6.2.2 训练超参数 65
6.2.3 训练日志 66
6.2.4 用训练好的模型对数据进行预测 76
6.2.5 Windows下训练模型 76
6.3 回顾 78
6.4 练习题 79
6.5 参考资料 79
篇尾语 80
中篇 热恋
第7天 Caffe代码梳理 82
7.1 Caffe目录结构 82
7.2 如何有效阅读Caffe源码 84
7.3 Caffe支持哪些深度学习特性 86
7.3.1 卷积层 86
7.3.2 全连接层 89
7.3.3 激活函数 91
7.4 小结 99
7.5 练习题 99
7.6 参考资料 100
第8天 Caffe数据结构 101
8.1 Blob 101
8.1.1 Blob基本用法 102
8.1.2 数据结构描述 108
8.1.3 Blob是怎样炼成的 109
8.2 Layer 125
8.2.1 数据结构描述 126
8.2.2 Layer是怎样建成的 127
8.3 Net 136
8.3.1 Net基本用法 136
8.3.2 数据结构描述 139
8.3.3 Net是怎样绘成的 139
8.4 机制和策略 146
8.5 练习题 147
8.6 参考资料 148
第9天 Caffe I/O模块 149
9.1 数据读取层 149
9.1.1 数据结构描述 149
9.1.2 数据读取层实现 150
9.2 数据变换器 155
9.2.1 数据结构描述 155
9.2.2 数据变换器的实现 156
9.3 练习题 171
第10天 Caffe模型 172
10.1 prototxt表示 173
10.2 内存中的表示 176
10.3 磁盘上的表示 176
10.4 Caffe Model Zoo 178
10.5 练习题 180
10.6 参考资料 180
第11天 Caffe前向传播计算 181
11.1 前向传播的特点 181
11.2 前向传播的实现 182
11.2.1 DAG构造过程 182
11.2.2 Net Forward实现 190
11.3 练习题 192
第12天 Caffe反向传播计算 193
12.1 反向传播的特点 193
12.2 损失函数 193
12.2.1 算法描述 194
12.2.2 参数描述 195
12.2.3 源码分析 195
12.3 反向传播的实现 203
12.4 练习题 205
第13天 Caffe最优化求解过程 207
13.1 求解器是什么 207
13.2 求解器是如何实现的 208
13.2.1 算法描述 208
13.2.2 数据结构描述 210
13.2.3 CNN训练过程 218
13.2.4 CNN预测过程 225
13.2.5 Solver的快照和恢复功能 227
13.3 练习题 230
第14天 Caffe实用工具 231
14.1 训练和预测 231
14.2 特征提取 241
14.3 转换图像格式 247
14.4 计算图像均值 254
14.5 自己编写工具 257
14.6 练习题 257
篇尾语 258
下篇 升华
第15天 Caffe计算加速 260
15.1 Caffe计时功能 260
15.2 Caffe GPU加速模式 262
15.2.1 GPU是什么 262
15.2.2 CUDA是什么 263
15.2.3 GPU、CUDA和深度学习 263
15.2.4 Caffe GPU环境准备 264
15.2.5 切换到Caffe GPU加速模式 268
15.3 Caffe cuDNN加速模式 269
15.3.1 获取cuDNN 270
15.3.2 切换到Caffe cuDNN加速模式 270
15.3.3 Caffe不同硬件配置性能 272
15.4 练习题 273
15.5 参考资料 273
第16天 Caffe可视化方法 275
16.1 数据可视化 275
16.1.1 MNIST数据可视化 275
16.1.2 CIFAR10数据可视化 277
16.1.3 ImageNet数据可视化 278
16.2 模型可视化 279
16.2.1 网络结构可视化 279
16.2.2 网络权值可视化 281
16.3 特征图可视化 288
16.4 学习曲线 295
16.5 小结 298
16.6 练习题 298
16.7 参考资料 299
第17天 Caffe迁移和部署 300
17.1 从开发测试到生产部署 300
17.2 使用Docker 302
17.2.1 Docker基本概念 302
17.2.2 Docker安装 303
17.2.3 Docker入门 305
17.2.4 Docker使用进阶 312
17.3 练习题 317
17.4 参考资料 317
第18天 关于ILSVRC不得不说的一些事儿 318
18.1 ImageNet数据集 318
18.2 ILSVRC比赛项目 319
18.2.1 图像分类（CLS） 320
18.2.2 目标定位（LOC） 320
18.2.3 目标检测（DET） 321
18.2.4 视频目标检测（VID） 322
18.2.5 场景分类 322
18.3 Caffe ILSVRC实践 323
18.4 练习题 326
18.5 参考资料 326
第19天 放之四海而皆准 327
19.1 图像分类 327
19.1.1 问题描述 327
19.1.2 应用案例--商品分类 330
19.2 图像中的字符识别 332
19.2.1 问题描述 332
19.2.2 应用案例--身份证实名认证 333
19.3 目标检测 337
19.3.1 问题描述 337
19.3.2 最佳实践--运行R-CNN例程 337
19.4 人脸识别 340
19.4.1 问题描述 340
19.4.2 最佳实践--使用Face++ SDK实现人脸检测 342
19.5 自然语言处理 343
19.5.1 问题描述 343
19.5.2 最佳实践--NLP-Caffe 344
19.6 艺术风格 350
19.6.1 问题描述 350
19.6.2 最佳实践--style-transfer 352
19.7 小结 354
19.8 练习题 354
19.9 参考资料 355
第20天 继往开来的领路人 356
20.1 Caffe Traps and Pitfalls 356
20.1.1 不支持任意数据类型 356
20.1.2 不够灵活的高级接口 357
20.1.3 繁杂的依赖包 357
20.1.4 堪忧的卷积层实现 357
20.1.5 架构之殇 358
20.1.6 应用场景局限性 358
20.2 最佳实践--Caffe2 359
20.3 练习题 361
20.4 参考资料 362
第21天 新生 363
21.1 三人行，必有我师 363
21.2 路漫漫其修远兮，吾将上下而求索 364
篇尾语 366
结束语 367
附录A 其他深度学习工具
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习：21天实战Caffe
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习之TensorFlow
配套学习资源
前言
第1篇 深度学习与TensorFlow基础
第1章 快速了解人工智能与TensorFlow	2
1.1 什么是深度学习	2
1.2 TensorFlow是做什么的	3
1.3 TensorFlow的特点	4
1.4 其他深度学习框架特点及介绍	5
1.5 如何通过本书学好深度学习	6
1.5.1 深度学习怎么学	6
1.5.2 如何学习本书	7
第2章 搭建开发环境	8
2.1 下载及安装Anaconda开发工具	8
2.2 在Windows平台下载及安装TensorFlow	11
2.3 GPU版本的安装方法	12
2.3.1 安装CUDA软件包	12
2.3.2 安装cuDNN库	13
2.3.3 测试显卡	14
2.4 熟悉Anaconda 3开发工具	15
2.4.1 快速了解Spyder	16
2.4.2 快速了解Jupyter Notebook	18
第3章 TensorFlow基本开发步骤——以逻辑回归拟合二维数据为例	19
3.1 实例1：从一组看似混乱的数据中找出y≈2x的规律	19
3.1.1 准备数据	20
3.1.2 搭建模型	21
3.1.3 迭代训练模型	23
3.1.4 使用模型	25
3.2 模型是如何训练出来的	25
3.2.1 模型里的内容及意义	25
3.2.2 模型内部的数据流向	26
3.3 了解TensorFlow开发的基本步骤	27
3.3.1 定义输入节点的方法	27
3.3.2 实例2：通过字典类型定义输入节点	28
3.3.3 实例3：直接定义输入节点	28
3.3.4 定义“学习参数”的变量	29
3.3.5 实例4：通过字典类型定义“学习参数”	29
3.3.6 定义“运算”	29
3.3.7 优化函数，优化目标	30
3.3.8 初始化所有变量	30
3.3.9 迭代更新参数到最优解	31
3.3.10 测试模型	31
3.3.11 使用模型	31
第4章 TensorFlow编程基础	32
4.1 编程模型	32
4.1.1 了解模型的运行机制	33
4.1.2 实例5：编写hello world程序演示session的使用	34
4.1.3 实例6：演示with session的使用	35
4.1.4 实例7：演示注入机制	35
4.1.5 建立session的其他方法	36
4.1.6 实例8：使用注入机制获取节点	36
4.1.7 指定GPU运算	37
4.1.8 设置GPU使用资源	37
4.1.9 保存和载入模型的方法介绍	38
4.1.10 实例9：保存/载入线性回归模型	38
4.1.11 实例10：分析模型内容，演示模型的其他保存方法	40
4.1.12 检查点（Checkpoint）	41
4.1.13 实例11：为模型添加保存检查点	41
4.1.14 实例12：更简便地保存检查点	44
4.1.15 模型操作常用函数总结	45
4.1.16 TensorBoard可视化介绍	45
4.1.17 实例13：线性回归的TensorBoard可视化	46
4.2 TensorFlow基础类型定义及操作函数介绍	48
4.2.1 张量及操作	49
4.2.2 算术运算函数	55
4.2.3 矩阵相关的运算	56
4.2.4 复数操作函数	58
4.2.5 规约计算	59
4.2.6 分割	60
4.2.7 序列比较与索引提取	61
4.2.8 错误类	62
4.3 共享变量	62
4.3.1 共享变量用途	62
4.3.2 使用get-variable获取变量	63
4.3.3 实例14：演示get_variable和Variable的区别	63
4.3.4 实例15：在特定的作用域下获取变量	65
4.3.5 实例16：共享变量功能的实现	66
4.3.6 实例17：初始化共享变量的作用域	67
4.3.7 实例18：演示作用域与操作符的受限范围	68
4.4 实例19：图的基本操作	70
4.4.1 建立图	70
4.4.2 获取张量	71
4.4.3 获取节点操作	72
4.4.4 获取元素列表	73
4.4.5 获取对象	73
4.4.6 练习题	74
4.5 配置分布式TensorFlow	74
4.5.1 分布式TensorFlow的角色及原理	74
4.5.2 分布部署TensorFlow的具体方法	75
4.5.3 实例20：使用TensorFlow实现分布式部署训练	75
4.6 动态图（Eager）	81
4.7 数据集（tf.data）	82
第5章 识别图中模糊的手写数字（实例21）	83
5.1 导入图片数据集	84
5.1.1 MNIST数据集介绍	84
5.1.2 下载并安装MNIST数据集	85
5.2 分析图片的特点，定义变量	87
5.3 构建模型	87
5.3.1 定义学习参数	87
5.3.2 定义输出节点	88
5.3.3 定义反向传播的结构	88
5.4 训练模型并输出中间状态参数	89
5.5 测试模型	90
5.6 保存模型	91
5.7 读取模型	92
第2篇 深度学习基础——神经网络
第6章 单个神经元	96
6.1 神经元的拟合原理	96
6.1.1 正向传播	98
6.1.2 反向传播	98
6.2 激活函数——加入非线性因素，解决线性模型缺陷	99
6.2.1 Sigmoid函数	99
6.2.2 Tanh函数	100
6.2.3 ReLU函数	101
6.2.4 Swish函数	103
6.2.5 激活函数总结	103
6.3 softmax算法——处理分类问题	103
6.3.1 什么是softmax	104
6.3.2 softmax原理	104
6.3.3 常用的分类函数	105
6.4 损失函数——用真实值与预测值的距离来指导模型的收敛方向	105
6.4.1 损失函数介绍	105
6.4.2 TensorFlow中常见的loss函数	106
6.5 softmax算法与损失函数的综合应用	108
6.5.1 实例22：交叉熵实验	108
6.5.2 实例23：one_hot实验	109
6.5.3 实例24：sparse交叉熵的使用	110
6.5.4 实例25：计算loss值	110
6.5.5 练习题	111
6.6 梯度下降——让模型逼近最小偏差	111
6.6.1 梯度下降的作用及分类	111
6.6.2 TensorFlow中的梯度下降函数	112
6.6.3 退化学习率——在训练的速度与精度之间找到平衡	113
6.6.4 实例26：退化学习率的用法举例	114
6.7 初始化学习参数	115
6.8 单个神经元的扩展——Maxout网络	116
6.8.1 Maxout介绍	116
6.8.2 实例27：用Maxout网络实现MNIST分类	117
6.9 练习题	118
第7章 多层神经网络——解决非线性问题	119
7.1 线性问题与非线性问题	119
7.1.1 实例28：用线性单分逻辑回归分析肿瘤是良性还是恶性的	119
7.1.2 实例29：用线性逻辑回归处理多分类问题	123
7.1.3 认识非线性问题	129
7.2 使用隐藏层解决非线性问题	130
7.2.1 实例30：使用带隐藏层的神经网络拟合异或操作	130
7.2.2 非线性网络的可视化及其意义	133
7.2.3 练习题	135
7.3 实例31：利用全连接网络将图片进行分类	136
7.4 全连接网络训练中的优化技巧	137
7.4.1 实例32：利用异或数据集演示过拟合问题	138
7.4.2 正则化	143
7.4.3 实例33：通过正则化改善过拟合情况	144
7.4.4 实例34：通过增大数据集改善过拟合	145
7.4.5 练习题	146
7.4.6 dropout——训练过程中，将部分神经单元暂时丢弃	146
7.4.7 实例35：为异或数据集模型添加dropout	147
7.4.8 实例36：基于退化学习率dropout技术来拟合异或数据集	149
7.4.9 全连接网络的深浅关系	150
7.5 练习题	150
第8章 卷积神经网络——解决参数太多问题	151
8.1 全连接网络的局限性	151
8.2 理解卷积神经网络	152
8.3 网络结构	153
8.3.1 网络结构描述	153
8.3.2 卷积操作	155
8.3.3 池化层	157
8.4 卷积神经网络的相关函数	158
8.4.1 卷积函数tf.nn.conv2d	158
8.4.2 padding规则介绍	159
8.4.3 实例37：卷积函数的使用	160
8.4.4 实例38：使用卷积提取图片的轮廓	165
8.4.5 池化函数tf.nn.max_pool（avg_pool）	167
8.4.6 实例39：池化函数的使用	167
8.5 使用卷积神经网络对图片分类	170
8.5.1 CIFAR介绍	171
8.5.2 下载CIFAR数据	172
8.5.3 实例40：导入并显示CIFAR数据集	173
8.5.4 实例41：显示CIFAR数据集的原始图片	174
8.5.5 cifar10_input的其他功能	176
8.5.6 在TensorFlow中使用queue	176
8.5.7 实例42：协调器的用法演示	178
8.5.8 实例43：为session中的队列加上协调器	179
8.5.9 实例44：建立一个带有全局平均池化层的卷积神经网络	180
8.5.10 练习题	183
8.6 反卷积神经网络	183
8.6.1 反卷积神经网络的应用场景	184
8.6.2 反卷积原理	184
8.6.3 实例45：演示反卷积的操作	185
8.6.4 反池化原理	188
8.6.5 实例46：演示反池化的操作	189
8.6.6 实例47：演示gradients基本用法	192
8.6.7 实例48：使用gradients对多个式子求多变量偏导	192
8.6.8 实例49：演示梯度停止的实现	193
8.7 实例50：用反卷积技术复原卷积网络各层图像	195
8.8 善用函数封装库	198
8.8.1 实例51：使用函数封装库重写CIFAR卷积网络	198
8.8.2 练习题	201
8.9 深度学习的模型训练技巧	201
8.9.1 实例52：优化卷积核技术的演示	201
8.9.2 实例53：多通道卷积技术的演示	202
8.9.3 批量归一化	204
8.9.4 实例54：为CIFAR图片分类模型添加BN	207
8.9.5 练习题	209
第9章 循环神经网络——具有记忆功能的网络	210
9.1 了解RNN的工作原理	210
9.1.1 了解人的记忆原理	210
9.1.2 RNN网络的应用领域	212
9.1.3 正向传播过程	212
9.1.4 随时间反向传播	213
9.2 简单RNN	215
9.2.1 实例55：简单循环神经网络实现——裸写一个退位减法器	215
9.2.2 实例56：使用RNN网络拟合回声信号序列	220
9.3 循环神经网络（RNN）的改进	225
9.3.1 LSTM网络介绍	225
9.3.2 窥视孔连接（Peephole）	228
9.3.3 带有映射输出的STMP	230
9.3.4 基于梯度剪辑的cell	230
9.3.5 GRU网络介绍	230
9.3.6 Bi-RNN网络介绍	231
9.3.7 基于神经网络的时序类分类CTC	232
9.4 TensorFlow实战RNN	233
9.4.1 TensorFlow中的cell类	233
9.4.2 通过cell类构建RNN	234
9.4.3 实例57：构建单层LSTM网络对MNIST数据集分类	239
9.4.4 实例58：构建单层GRU网络对MNIST数据集分类	240
9.4.5 实例59：创建动态单层RNN网络对MNIST数据集分类	240
9.4.6 实例60：静态多层LSTM对MNIST数据集分类	241
9.4.7 实例61：静态多层RNN-LSTM连接GRU对MNIST数据集分类	242
9.4.8 实例62：动态多层RNN对MNIST数据集分类	242
9.4.9 练习题	243
9.4.10 实例63：构建单层动态双向RNN对MNIST数据集分类	243
9.4.11 实例64：构建单层静态双向RNN对MNIST数据集分类	244
9.4.12 实例65：构建多层双向RNN对MNIST数据集分类	246
9.4.13 实例66：构建动态多层双向RNN对MNIST数据集分类	247
9.4.14 初始化RNN	247
9.4.15 优化RNN	248
9.4.16 实例67：在GRUCell中实现LN	249
9.4.17 CTC网络的loss——ctc_loss	251
9.4.18 CTCdecoder	254
9.5 实例68：利用BiRNN实现语音识别	255
9.5.1 语音识别背景	255
9.5.2 获取并整理样本	256
9.5.3 训练模型	265
9.5.4 练习题	272
9.6 实例69：利用RNN训练语言模型	273
9.6.1 准备样本	273
9.6.2 构建模型	275
9.7 语言模型的系统学习	279
9.7.1 统计语言模型	279
9.7.2 词向量	279
9.7.3 word2vec	281
9.7.4 实例70：用CBOW模型训练自己的word2vec	283
9.7.5 实例71：使用指定侯选采样本训练word2vec	293
9.7.6 练习题	296
9.8 处理Seq2Seq任务	296
9.8.1 Seq2Seq任务介绍	296
9.8.2 Encoder-Decoder框架	297
9.8.3 实例72：使用basic_rnn_seq2seq拟合曲线	298
9.8.4 实例73：预测当天的股票价格	306
9.8.5 基于注意力的Seq2Seq	310
9.8.6 实例74：基于Seq2Seq注意力模型实现中英文机器翻译	313
9.9 实例75：制作一个简单的聊天机器人	339
9.9.1 构建项目框架	340
9.9.2 准备聊天样本	340
9.9.3 预处理样本	340
9.9.4 训练样本	341
9.9.5 测试模型	342
9.10 时间序列的高级接口TFTS	344
第10章 自编码网络——能够自学习样本特征的网络	346
10.1 自编码网络介绍及应用	346
10.2 最简单的自编码网络	347
10.3 自编码网络的代码实现	347
10.3.1 实例76：提取图片的特征，并利用特征还原图片	347
10.3.2 线性解码器	351
10.3.3 实例77：提取图片的二维特征，并利用二维特征还原图片	351
10.3.4 实例78：实现卷积网络的自编码	356
10.3.5 练习题	358
10.4 去噪自编码	359
10.5 去噪自编码网络的代码实现	359
10.5.1 实例79：使用去噪自编码网络提取MNIST特征	359
10.5.2 练习题	363
10.6 栈式自编码	364
10.6.1 栈式自编码介绍	364
10.6.2 栈式自编码在深度学习中的意义	365
10.7 深度学习中自编码的常用方法	366
10.7.1 代替和级联	366
10.7.2 自编码的应用场景	366
10.8 去噪自编码与栈式自编码的综合实现	366
10.8.1 实例80：实现去噪自编码	367
10.8.2 实例81：添加模型存储支持分布训练	375
10.8.3 小心分布训练中的“坑”	376
10.8.4 练习题	377
10.9 变分自编码	377
10.9.1 什么是变分自编码	377
10.9.2 实例82：使用变分自编码模拟生成MNIST数据	377
10.9.3 练习题	384
10.10 条件变分自编码	385
10.10.1 什么是条件变分自编码	385
10.10.2 实例83：使用标签指导变分自编码网络生成MNIST数据	385
第3篇 深度学习进阶
第11章 深度神经网络	392
11.1 深度神经网络介绍	392
11.1.1 深度神经网络起源	392
11.1.2 经典模型的特点介绍	393
11.2 GoogLeNet模型介绍	394
11.2.1 MLP卷积层	394
11.2.2 全局均值池化	395
11.2.3 Inception 原始模型	396
11.2.4 Inception v1模型	396
11.2.5 Inception v2模型	397
11.2.6 Inception v3模型	397
11.2.7 Inception v4模型	399
11.3 残差网络（ResNet）	399
11.3.1 残差网络结构	399
11.3.2 残差网络原理	400
11.4 Inception-ResNet-v2结构	400
11.5 TensorFlow中的图片分类模型库——slim	400
11.5.1 获取models中的slim模块代码	401
11.5.2 models中的Slim目录结构	401
11.5.3 slim中的数据集处理	403
11.5.4 实例84：利用slim读取TFRecord中的数据	405
11.5.5 在slim中训练模型	407
11.6 使用slim中的深度网络模型进行图像的识别与检测	410
11.6.1 实例85：调用Inception_ResNet_v2模型进行图像识别	410
11.6.2 实例86：调用VGG模型进行图像检测	413
11.7 实物检测模型库——Object Detection API	417
11.7.1 准备工作	418
11.7.2 实例87：调用Object Detection API进行实物检测	421
11.8 实物检测领域的相关模型	425
11.8.1 RCNN基于卷积神经网络特征的区域方法	426
11.8.2 SPP-Net：基于空间金字塔池化的优化RCNN方法	426
11.8.3 Fast-R-CNN快速的RCNN模型	426
11.8.4 YOLO：能够一次性预测多个位置和类别的模型	427
11.8.5 SSD：比YOLO更快更准的模型	428
11.8.6 YOLO2：YOLO的升级版模型	428
11.9 机器自己设计的模型（NASNet）	428
第12章 对抗神经网络（GAN）	430
12.1 GAN的理论知识	430
12.1.1 生成式模型的应用	431
12.1.2 GAN的训练方法	431
12.2 DCGAN——基于深度卷积的GAN	432
12.3 InfoGAN和ACGAN：指定类别生成模拟样本的GAN	432
12.3.1 InfoGAN：带有隐含信息的GAN	432
12.3.2 AC-GAN：带有辅助分类信息的GAN	433
12.3.3 实例88：构建InfoGAN生成MNIST模拟数据	434
12.3.4 练习题	440
12.4 AEGAN：基于自编码器的GAN	441
12.4.1 AEGAN原理及用途介绍	441
12.4.2 实例89：使用AEGAN对MNIST数据集压缩特征及重建	442
12.5 WGAN-GP：更容易训练的GAN	447
12.5.1 WGAN：基于推土机距离原理的GAN	448
12.5.2 WGAN-GP：带梯度惩罚项的WGAN	449
12.5.3 实例90：构建WGAN-GP生成MNIST数据集	451
12.5.4 练习题	455
12.6 LSGAN（最小乘二GAN）：具有WGAN 同样效果的GAN	455
12.6.1 LSGAN介绍	455
12.6.2 实例91：构建LSGAN生成MNIST模拟数据	456
12.7 GAN-cls：具有匹配感知的判别器	457
12.7.1 GAN-cls的具体实现	458
12.7.2 实例92：使用GAN-cls技术实现生成标签匹配的模拟数据	458
12.8 SRGAN——适用于超分辨率重建的GAN	461
12.8.1 超分辨率技术	461
12.8.2 实例93：ESPCN实现MNIST数据集的超分辨率重建	463
12.8.3 实例94：ESPCN实现flowers数据集的超分辨率重建	466
12.8.4 实例95：使用残差网络的ESPCN	472
12.8.5 SRGAN的原理	477
12.8.6 实例96：使用SRGAN实现flowers数据集的超分辨率修复	477
12.9 GAN网络的高级接口TFGAN	485
12.10 总结	486
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习之TensorFlow
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数值最优化方法
第一章 引论{1}
第二章 无约束最优化方法的基本结构{8}
2.1 最优性条件{8}
2.2 方法的特性{12}
2.3 线搜索准则{18}
2.4 线搜索求步长{25}
2.5 信赖域方法{32}
2.6 常用最优化方法软件介绍{35}
后记{35}
习题{36}
第三章 负梯度方法与Newton 型方法{38}
3.1 最速下降方法{38}
3.2 Newton 方法{46}
3.3 拟Newton 方法{57}
3.4 拟Newton 方法的基本性质{65}
3.5 DFP 公式的意义{70}
3.6 数值试验{76}
3.7 BB 方法{85}
后记{88}
习题{89}
上机习题{92}
第四章 共轭梯度方法{95}
4.1 共轭方向及其性质{95}
4.2 对正定二次函数的共轭梯度方法{99}
4.3 非线性共轭梯度方法{105}
4.4 数值试验{110}
4.5 Broyden 族方法搜索方向的共轭性{112}
后记{113}
习题{114}
上机习题{117}
第五章 非线性最小二乘问题{119}
5.1 最小二乘问题{119}
5.2 Gauss-Newton 方法{121}
5.3 LMF 方法{129}
5.4 Dogleg 方法{135}
5.5 大剩余量问题{137}
5.6 数值试验{138}
后记{143}
习题{144}
上机习题{148}
第六章 约束最优化问题的最优性理论{153}
6.1 一般约束最优化问题{153}
6.2 约束规范条件{161}
6.3 约束最优化问题的一阶最优性条件{167}
6.4 约束最优化问题的二阶最优性条件{172}
后记{181}
习题{181}
第七章 罚函数方法{185}
7.1 外点罚函数方法{185}
7.2 障碍函数方法{194}
7.3 等式约束最优化问题的增广Lagrange函数方法{198}
7.4 一般约束最优化问题的增广Lagrange函数方法{204}
7.5 数值试验{208}
后记{209}
习题{210}
上机习题{213}
第八章 二次规划{215}
8.1 二次规划问题{215}
8.2 等式约束二次规划问题{217}
8.3 起作用集方法{226}
后记{236}
习题{236}
上机习题{238}
第九章 序列二次规划方法{240}
9.1 序列二次规划方法的提出{240}
9.2 约束相容问题{244}
9.3 Lagrange 函数Hesse矩阵的近似{245}
9.4 价值函数{247}
9.5 SQP 算法{249}
后记{250}
习题{251}
上机习题{251}
附录{252}
附录I 凸集与凸函数{252}
附录II 正交变换与QR分解{257}
符号说明{263}
习题解答提示{265}
参考文献{274}
名词索引{281}
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数值最优化方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统
目　录
Recommender Systems Handbook,Second Edition
出版者的话
推荐序一
推荐序二
推荐序三
译者序
前言
译者简介
第1章　推荐系统：简介和挑战1
1.1　简介1
1.2　推荐系统的功能3
1.3　数据和知识来源5
1.4　推荐技术7
1.5　推荐系统评估10
1.6　推荐系统应用11
1.7　推荐系统与人机交互13
1.8　高级话题14
1.9　挑战16
1.9.1　偏好获取与分析16
1.9.2　交互17
1.9.3　新的推荐任务18
参考文献19
第一部分　推荐系统技术
第2章　基于邻域的推荐方法综述24
2.1　简介24
2.1.1　基于邻域方法的优势25
2.1.2　目标和概要26
2.2　问题定义和符号26
2.3　基于邻域的推荐27
2.3.1　基于用户的评分预测28
2.3.2　基于用户的分类预测方法28
2.3.3　回归与分类29
2.3.4　基于物品的推荐29
2.3.5　基于用户和基于物品的推荐方法的比较30
2.4　基于邻域方法的要素31
2.4.1　评分标准化31
2.4.2　相似度权重的计算33
2.4.3　邻域的选择37
2.5　高级进阶技术37
2.5.1　基于图的方法38
2.5.2　基于学习的方法40
2.6　总结44
参考文献44
第3章　协同过滤方法进阶48
3.1　简介48
3.2　预备知识49
3.2.1　基准预测49
3.2.2　Netflix数据50
3.2.3　隐式反馈51
3.3　矩阵分解模型51
3.3.1　SVD52
3.3.2　SVD++53
3.3.3　时间敏感的因子模型54
3.3.4　比较57
3.3.5　小结58
3.4　基于邻域的模型59
3.4.1　相似度度量59
3.4.2　基于相似度的插值60
3.4.3　联合派生插值权重61
3.4.4　小结63
3.5　增强的基于邻域的模型63
3.5.1　全局化的邻域模型64
3.5.2　因式分解的邻域模型67
3.5.3　基于邻域模型的动态时序71
3.5.4　小结72
3.6　基于邻域的模型和因子分解模型的比较73
参考文献75
第4章　基于内容的语义感知推荐系统77
4.1　简介77
4.2　基于内容的推荐系统概述77
4.2.1　基于关键词的向量空间模型79
4.2.2　用户特征学习的方法80
4.2.3　基于内容过滤的优缺点81
4.3　自上而下的语义方法82
4.3.1　基于本体资源的方法83
4.3.2　基于非结构化或半结构化百科知识的方法84
4.3.3　基于关联开放数据的方法86
4.4　自下而上的语义方法90
4.4.1　基于判别式模型的方法90
4.5　方法比较与小结94
4.6　总结与未来挑战95
致谢96
参考文献96
第5章　基于约束的推荐系统103
5.1　简介103
5.2　推荐知识库的开发105
5.3　推荐过程中的用户导向作用108
5.4　计算推荐结果113
5.5　实际应用的经验114
5.6　未来的研究方法116
5.7　总结118
参考文献118
第6章　情境感知推荐系统123
6.1　简介和动机123
6.2　推荐系统中的情境124
6.2.1　什么是情境124
6.2.2　推荐系统中模型化情境信息的表征性方法125
6.2.3　推荐系统中主要的情境信息建模方法127
6.2.4　获取情境信息130
6.3　结合具有代表性情境的推荐系统范式131
6.3.1　情境预过滤133
6.3.2　情境后过滤136
6.3.3　情境建模137
6.4　讨论和总结138
致谢140
参考文献140
第7章　推荐系统中的数据挖掘方法145
7.1　简介145
7.2　数据预处理146
7.2.1　相似度度量方法146
7.2.2　抽样147
7.2.3　降维148
7.2.4　去噪150
7.3　监督学习150
7.3.1　分类150
7.3.2　分类器的集成157
7.3.3　评估分类器157
7.4　无监督学习159
7.4.1　聚类分析159
7.4.2　关联规则挖掘161
7.5　总结162
参考文献163
第二部分　推荐系统评估
第8章　推荐系统的评估170
8.1　简介170
8.2　实验设置171
8.2.1　离线实验172
8.2.2　用户调查173
8.2.3　在线评估175
8.2.4　得出可靠结论176
8.3　推荐系统属性178
8.3.1　用户偏好179
8.3.2　预测精度179
8.3.3　覆盖率186
8.3.4　置信度187
8.3.5　信任度188
8.3.6　新颖性188
8.3.7　惊喜度189
8.3.8　多样性190
8.3.9　效用191
8.3.10　风险191
8.3.11　健壮性192
8.3.12　隐私192
8.3.13　适应性193
8.3.14　可扩展性193
8.4　结论193
参考文献194
第9章　使用用户实验评估推荐系统198
9.1　简介198
9.2　理论基础与现有工作199
9.2.1　理论基础：Knijnenburg等人提出的评估框架199
9.2.2　现有以用户为中心的研究概览以及有前景的方向201
9.3　实践指南203
9.3.1　研究模型203
9.3.2　参与者206
9.3.3　实验操控207
9.3.4　测量209
9.3.5　统计评估214
9.4　结论219
参考文献221
第10章　对推荐结果的解释：设计和评估228
10.1　简介228
10.2　推荐设计的呈现和交互229
10.2.1　推荐呈现229
......
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度强化学习
第一篇 初探强化学习
--第1章 强化学习绪论
--第2章 数学基础及环境
第二篇 求解强化学习
--第3章 动态规划法
--第4章 蒙特卡洛法
--第5章 时间差分法
第三篇 求解强化学习进阶
--第6章 值函数近似法
--第7章 策略梯度法
--第8章 整合学习与规划
第四章 深度强化学习
--第9章 深度强化学习
--第10章 深度Q网络
--第11章 深度强化学习算法框架
--第12章 从围棋AlphaGo到AlphaGo Zero
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度强化学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow：实战Google深度学习框架（第2版）
第1章 深度学习简介
1.1 人工智能、机器学习与深度学习
1.2 深度学习的发展历程
1.3 深度学习的应用
1.3.1 计算机视觉
1.3.2 语音识别
1.3.3 自然语言处理
1.3.4 人机博弈
1.4 深度学习工具介绍和对比
小结
第2章 TensorFlow环境搭建
2.1 TensorFlow的主要依赖包
2.1.1 Protocol Buffer
2.1.2 Bazel
2.2 TensorFlow安装
2.2.1 使用Docker安装
2.2.2 使用pip安装
2.2.3 从源代码编译安装
2.3 TensorFlow测试样例
小结
第3章 TensorFlow入门
3.1 TensorFlow计算模型——计算图
3.1.1 计算图的概念
3.1.2 计算图的使用
3.2 TensorFlow数据模型——张量
3.2.1 张量的概念
3.2.2 张量的使用
3.3 TensorFlow运行模型——会话
3.4 TensorFlow实现神经网络
3.4.1 TensorFlow游乐场及神经网络简介
3.4.2 前向传播算法简介
3.4.3 神经网络参数与TensorFlow变量
3.4.4 通过TensorFlow训练神经网络模型
3.4.5 完整神经网络样例程序
小结
第4章 深层神经网络
4.1 深度学习与深层神经网络
4.1.1 线性模型的局限性
4.1.2 激活函数实现去线性化
4.1.3 多层网络解决异或运算
4.2 损失函数定义
4.2.1 经典损失函数
4.2.2 自定义损失函数
4.3 神经网络优化算法
4.4 神经网络进一步优化
4.4.1 学习率的设置
4.4.2 过拟合问题
4.4.3 滑动平均模型
小结
第5章 MNIST数字识别问题
5.1 MNIST数据处理
5.2 神经网络模型训练及不同模型结果对比
5.2.1 TensorFlow训练神经网络
5.2.2 使用验证数据集判断模型效果
5.2.3 不同模型效果比较
5.3 变量管理
5.4 TensorFlow模型持久化
5.4.1 持久化代码实现
5.4.2 持久化原理及数据格式
5.5 TensorFlow最佳实践样例程序
小结
第6章 图像识别与卷积神经网络
6.1 图像识别问题简介及经典数据集
6.2 卷积神经网络简介
6.3 卷积神经网络常用结构
6.3.1 卷积层
6.3.2 池化层
6.4 经典卷积网络模型
6.4.1 LeNet-5模型
6.4.2 Inception-v3模型
6.5 卷积神经网络迁移学习
6.5.1 迁移学习介绍
6.5.2 TensorFlow实现迁移学习
小结
第7章 图像数据处理
7.1 TFRecord输入数据格式
7.1.1 TFRecord格式介绍
7.1.2 TFRecord样例程序
7.2 图像数据处理
7.2.1 TensorFlow图像处理函数
7.2.2 图像预处理完整样例
7.3 多线程输入数据处理框架
7.3.1 队列与多线程
7.3.2 输入文件队列
7.3.3 组合训练数据（batching）
7.3.4 输入数据处理框架
7.4 数据集（Dataset）
7.4.1 数据集的基本使用方法
7.4.2 数据集的高层操作
小结
第8章 循环神经网络
8.1 循环神经网络简介
8.2 长短时记忆网络（LSTM）结构
8.3 循环神经网络的变种
8.3.1 双向循环神经网络和深层循环神经网络
8.3.2 循环神经网络的dropout
8.4 循环神经网络样例应用
小结
第9章 自然语言处理
9.1 语言模型的背景知识
9.1.1 语言模型简介
9.1.2 语言模型的评价方法
9.2 神经语言模型
9.2.1 PTB数据集的预处理
9.2.2 PTB数据的batching方法
9.2.3 基于循环神经网络的神经语言模型
9.3 神经网络机器翻译
9.3.1 机器翻译背景与Seq2Seq模型介绍
9.3.2 机器翻译文本数据的预处理
9.3.3 Seq2Seq模型的代码实现
9.3.4 注意力机制
小结
第10章 TensorFlow高层封装
10.1 TensorFlow高层封装总览
10.2 Keras介绍
10.2.1 Keras基本用法
10.2.2 Keras高级用法
10.3 Estimator介绍
10.3.1 Estimator基本用法
10.3.2 Estimator自定义模型
10.3.3 使用数据集（Dataset）作为Estimator输入
小结
第11章 TensorBoard可视化
11.1 TensorBoard简介
11.2 TensorFlow计算图可视化
11.2.1 命名空间与TensorBoard图上节点
11.2.2 节点信息
11.3 监控指标可视化
11.4 高维向量可视化
小结
第12章 TensorFlow计算加速
12.1 TensorFlow使用GPU
12.2 深度学习训练并行模式
12.3 多GPU并行
12.4 分布式TensorFlow
12.4.1 分布式TensorFlow原理
12.4.2 分布式TensorFlow模型训练
小结
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow：实战Google深度学习框架（第2版）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能Web算法
前言	XV
致谢	XIX
关于本书	XXI
1  什么是智能Web？	1
1.1  智能Web应用实例	3
1.2  智能应用的基本要素	4
1.3  什么应用会受益于智能?	5
1.3.1  社交网络	6
1.3.2  Mashup	7
1.3.3  门户网站	8
1.3.4  维基	9
1.3.5  文件分享网站	9
1.3.6  网络游戏	11
1.4  如何构建智能应用？	11
1.4.1  检查功能和数据	12
1.4.2  获取更多的数据	12
1.5  机器学习、数据挖掘及其他	16
1.6  智能应用中八个常见的误区	17
1.6.1  误区1：数据是可靠的	18
1.6.2  误区2：计算能马上完成	19
1.6.3  误区3：不用考虑数据规模	19
1.6.4  误区4：不考虑解决方案的可扩展性	19
1.6.5  误区5：随处使用同样的方法	19
1.6.6  误区6：总是能知道计算时间	20
1.6.7  误区7：复杂的模型更好	20
1.6.8  误区8：存在无偏见的模型	20
1.7  小结	20
1.8  参考资料	21
2  搜索	22
2.1  用Lucene实现搜索	23
2.1.1  理解Lucene代码	24
2.1.2  搜索的基本步骤	31
2.2  为什么搜索不仅仅是索引？	33
2.3  用链接分析改进搜索结果	35
2.3.1  PageRank简介	35
2.3.2  计算PageRank向量	37
2.3.3  alpha：网页间跳转的影响	38
2.3.4  理解幂方法	40
2.3.5  结合索引分值和PageRank分值	45
2.4  根据用户点击改进搜索结果	47
2.4.1  用户点击初探	48
2.4.2  朴素贝叶斯分类器的使用	50
2.4.3  整合Lucene索引、PageRank和用户点击	54
2.5  Word、PDF等无链接文档的排序	58
2.5.1  DocRank算法简介	58
2.5.2  DocRank的原理	60
2.6  大规模实现的有关问题	65
2.7  用户得到了想要的结果吗？精确度和查全率	67
2.8  总结	69
2.9  To Do	70
2.10  参考资料	72
3  推荐系统	73
3.1  一个在线音乐商店：基本概念	74
3.1.1  距离与相似度的概念	75
3.1.2  走近相似度的计算	80
3.1.3  什么才是最好的相似度计算公式？	83
3.2  推荐引擎是怎么工作的	84
3.2.1  基于相似用户的推荐	85
3.2.2  基于相似条目的推荐	94
3.2.3  基于内容的推荐	98
3.3  推荐朋友、文章与新闻报道	104
3.3.1  MyDiggSpace.com简介	105
3.3.2  发现朋友	106
3.3.3  DiggDelphi的内部工作机制	108
3.4  像Netflix.com那样推荐电影	114
3.4.1  电影数据集的介绍及推荐器	114
3.4.2  数据标准化与相关系数	117
3.5  大规模的实现与评估	123
3.6  总结	124
3.7  To Do	125
3.8  参考资料	127
4  聚类：事物的分组	128
4.1  聚类的需求	129
4.1.1  网站中的用户组：案例研究	129
4.1.2  用SQL order by子句分组	131
4.1.3  用数组排序分组	132
4.2  聚类算法概述	135
4.2.1  基于分组结构的聚类算法分类	136
4.2.2  基于数据类型和结构的聚类算法分类	137
4.2.3  根据数据规模的聚类算法分类	137
4.3  基于链接的算法	138
4.3.1  树状图：基本的聚类数据结构	139
4.3.2  基于链接的算法概况	141
4.3.3  单链接算法	142
4.3.4  平均链接算法	144
4.3.5  最小生成树算法	147
4.4  k-means算法	149
4.4.1  初识k-means算法	150
4.4.2  k-means的内部原理	151
4.5  鲁棒的链接型聚类（ROCK）	153
4.5.1  ROCK简介	154
4.5.2  为什么ROCK这么强大？	154
4.6  DBSCAN	159
4.6.1  基于密度的算法简介	159
4.6.2  DBSCAN的原理	162
4.7  超大规模数据聚类	165
4.7.1  计算复杂性	166
4.7.2  高维度	167
4.8  总结	168
4.9  To Do	169
4.10  参考资料	171
5  分类：把事物放到它该在的地方	172
5.1  对分类的需求	173
5.2  分类器的概述	177
5.2.1  结构分类算法	178
5.2.2  统计分类算法	180
5.2.3  分类器的生命周期	181
5.3  邮件的自动归类与垃圾邮件过滤	182
5.3.1  朴素贝叶斯分类	184
5.3.2  基于规则的分类	197
5.4  用神经网络做欺诈检测	210
5.4.1  交易数据中关于欺诈检测的一个用例	210
5.4.2  神经网络概览	212
5.4.3  一个可用的神经网络欺诈检测器	214
5.4.4  神经网络欺诈检测器剖析	218
5.4.5  创建通用神经网络的基类	226
5.5  你的结果可信吗？	232
5.6  大数据集的分类	235
5.7  总结	237
5.8  To Do	239
5.9  参考资料	242
6  分类器组合	244
6.1  信贷价值：分类器组合案例研究	246
6.1.1  数据的简要说明	247
6.1.2  为真实问题生成人工数据	250
6.2  用单分类器做信用评估	255
6.2.1  朴素贝叶斯的基准线	255
6.2.2  决策树基准线	258
6.2.3  神经网络的基准线	260
6.3  在同一个数据集中比较多个分类器	263
6.3.1  McNemar检验	264
6.3.2  差额比例检验	266
6.3.3  Cochran Q检验与F检验	268
6.4  bagging: bootstrap聚合（bootstrap aggregating）	270
6.4.1  bagging实例	272
6.4.2  bagging分类器底层细节	274
6.4.3  分类器集成	276
6.5  boosting：一种迭代提高的方法	279
6.5.1  boosting分类器实例	280
6.5.2  boosting分类器底层细节	282
6.6  总结	286
6.7  To Do	288
6.8  参考资料	292
7  智能技术大汇集：一个智能新闻门户	293
7.1  功能概览	295
7.2  获取并清洗内容	296
7.2.1  各就位、预备、开抓！	296
7.2.2  搜索预备知识回顾	298
7.2.3  一个抓取并处理好的新闻数据集	299
7.3  搜索新闻	301
7.4  分配新闻类别	304
7.4.1  顺序问题	304
7.4.2  使用NewsProcessor类进行分类	309
7.4.3  分类器	310
7.4.4  分类策略：超越底层的分类	313
7.5  用NewsProcessor类创建新闻分组	316
7.5.1  聚类全部文章	317
7.5.2  在一个新闻类别中聚类文章	321
7.6  基于用户评分的动态内容展示	325
7.7  总结	328
7.8  To Do	329
7.9  参考资料	333
附录A  BeanShell简介	334
A.1  什么是BeanShell？	334
A.2  为什么使用BeanShell？	335
A.3  运行BeanShell	335
A.4  参考资料	336
附录B  网络采集	337
B.1  爬虫组件概况	337
B.1.1  采集的步骤	338
B.1.2  我们的简单爬虫	338
B.1.3  开源Web爬虫	339
B.2  参考资料	340
附录C  数学知识回顾	341
C.1  向量和矩阵	341
C.2  距离的度量	342
C.3  高级矩阵方法	344
C.4  参考资料	344
附录D  自然语言处理	345
D.1  参考资料	347
附录E  神经网络	348
E.1  参考资料	349
索引	350
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能Web算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>与机器人共舞
中文版序    智能机器时代的抉择
前言     是谦逊地生存，还是傲慢地死去
01 人与机器，谁将称王
无论机器人是否在现实世界帮助了我们，人工智能已经不可辩驳地日益成为我们生活的一部分。今时今日，麦卡锡和恩格尔巴特最为核心的冲突仍然悬而未决—— 一种方法要用日益强大的计算机硬件和软件组合取代人类；另一种方法则要使用相同的工具，在脑力、经济、社会等方面拓展人类的能力。需要再次注意的是，若软件和硬件机器人都足够灵活，它们最终都会变成我们在程序中为它们设计的模样。
◇ 比尔• 杜瓦尔，在AI 和IA 中游走的第一人
◇ 两大阵营的奇点之争：主人、奴隶还是伙伴
◇ 人机交互，机器的终极智慧
◇ 悬而未决的伦理困境
02 无人驾驶汽车，将人类排除在外
DARPA 大赛是两个世界的分界线——在一个世界中，机器人被视作玩具或研究人员的玩物；而在另一个世界中，人们开始接受机器人能够在世界上自由移动的事实。如今，“半自动”汽车已经在市场上出现，它们给交通的未来开启了两条路—— 一条路配有更智慧、更安全的人类司机；而在另一条路上，人类将成为乘客。机器智能时代的到来
◇ 特瑟的自动驾驶汽车挑战赛
◇ 问鼎冠军，威廉•惠特克的复仇
◇ 塞巴斯蒂安•特龙，用科技重塑交通系统
◇ 谷歌无人驾驶汽车的诞生
◇ 2014，无人驾驶汽车商业化元年
◇ Mobileye，无人驾驶汽车的另一种可能
◇ 应对分心，将人类完全排除在驾驶之外
◇ 手推车难题，是否选择“更小的恶魔”
03  跨越2045 年，人类将去往何处
随着机器学习能力的增强，它们日益呈现出了极强的独立性，而这一新机器时代正掀起一场十分严酷的工业革命，可以将一名工厂工人置于不被雇用的地步。奇点临近，到底谁才是人类命运的主宰者？ 2045 年，对人类来说究竟将是艰难的一年，还是会掀起一场技术盛宴的一年，抑或是两种可能同时发生的一年？
◇ 诺伯特• 维纳，一位科学家的反叛
◇ 技能错配，技术性失业的元凶
◇ 奇点临近，人类会否被机器取代
◇ 生产力之争，回归还是告别
04  从寒冬到野蛮生长，人工智能的前世今生
虽然很多人相信世界上第一个机器人Shakey 预示了人工智能的未来，但其商业化进程却不甚理想。20 世纪80 年代初，人工智能公司一家接一家地走向崩溃。现如今，新一波人工智能技术预示着新“思维机器”的出现。而随着微软、谷歌等公司的加入，新一波人工智能浪潮再次被唤起。
◇ 世界首个机器人Shakey，引爆人工智能大爆炸
◇ 约翰•麦卡锡，“人工智能”概念之父
◇ 斯坦福大学人工智能实验室，语音识别技术滥觞
◇ 汉斯•莫维拉克，人工智能最坚定的信徒
◇ 人工智能商业化的冬天
◇ 像人脑一样思考，人工神经网络出现突破
◇ 机器学习重燃人工智能研究
◇ 人工智能再现巨浪
05  以人为本，重新定义“机器”智能
在交互式计算的前50 年中，计算机更多的是在增强而非取代人类，人工智能遭遇了“滑铁卢”，很多人背离过往，将自己职业生涯的剩余时间贡献给了“以人为本”的计算，也即智能增强。他们“遗弃”了人工智能圈，将注意力从建造智能机器转到了让人类变得更聪明上。
◇ 人机共生，AI 与IA 重塑的新世界
◇ AI vs. IA，数十年的科学家大战
◇ “理性主义”与“以人为本”之争
◇ 拟人化界面，来自人机交互的冲击
◇ 软件助手，数字化生存之道
06  学会协作，人类与机器共存
马文• 明斯基、杰夫• 霍金斯和雷• 库兹韦尔等多位电子工程师都宣称，实现人类级别的智能的方法是发现并整合那些人类大脑中隐藏着的认知的简单算法。这通常能制造出有用、有趣的系统。或许，与机器人交互的那种自由、放松之感，正是因为在连线的另一边并不是一个令人难以捉摸的人类。也许，这根本与人际关系无关，更多的在于是取得控制成为主人，或者，是成为奴隶。
◇ 让工具变成玩具
◇ 是伙伴不是敌人
◇ 虚拟机器人，更自由、更放松的人机交互
07  救援机器人，从模拟智慧到智能增强
霍姆斯泰德 - 迈阿密举行的机器人大赛让一件事情变得清晰起来，那就是，有两个不同的方向能够定义即将到来的人类与机器人的世界：一个迈向人机共生的世界，而另一个则在向着机器取代人类的方向发展。正如诺伯特• 维纳在计算机和机器人的启蒙时期所意识到的一样，其中一种未来对于人类来说可能将是凄凉黯淡的，而走出这条死路的方法是将人类放置在设计环节的中心，重新塑造个人计算，把它作为增强人类智慧的终极工具。
◇ 从机械兽到机械展馆
◇ 仿生机器人，进入极端环境作业
◇ 安迪• 鲁宾，移动机器人时代的预言家
◇ 谷歌的机器人帝国计划
◇ 巅峰之战：DARPA 机器人挑战赛
◇ 机械手，触摸的科学
◇ 加里• 布拉德斯基，将机器视觉技术融入机械手臂之中
◇ 智能增强，以人类为中心重塑计算
08  收购Siri，苹果正式踏入智能增强阵营
收购Siri是乔布斯在为苹果铺平通向未来的道路——迎接将来人机交互的另一次重要转换。在计算机世界最后的一幕，乔布斯选择落地，径直走进了智能增强阵营：让人类控制他们自己的计算系统，站在了增强和合作的阵营。
◇ 收购Siri，乔布斯的最后一件事情
◇ 汤姆•格鲁伯，从建模知识到建模策略
◇ Intraspect，流星般的人机交互系统
◇ Web2.0，群体智慧改变一切
◇ 亚当•奇耶，下一个恩格尔巴特
◇ Siri核心创始团队的建立
◇ 携手苹果，让人类与机器优雅地合作
结语  选择，一切与机器无关
致谢
译者后记
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>与机器人共舞
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据之魅
第1 章导论
数据分析
本书内容
关于讲习班
关于数学
需要具备的知识
本书不涉及的内容
第Ⅰ部分图表：观察数据
第 2 章单一变量：形状和分布
数据点和抖动图
直方图和核密度估计
直方图
核密度估计
(选学)如何选择最优带宽
累积分布函数
(选学)概率图分布和QQ 图
分布的对比
秩序图和上升图
仅用于适当时机：汇总统计量和箱形图
汇总统计量
Box-and-Whisker 图
(讲习班)NumPy
NumPy 实践
NumPy 详解
扩展阅读
第3 章两个变量：建立关系
散点图
克服噪声：平滑
样条
LOESS
示例
残差
其他观点及提醒
对数图
倾斜
线性回归以及诸如此类的方法
描述重要信息
图形分析与图形演示
(讲习班)matplotlib
交互式使用matplotlib
案例学习：matplotlib 与
LOESS
控制属性
matplotlib 对象模型及结构
零碎知识
扩展阅读
第4 章以时间为变量：
时序分析
示例
任务
需求和现实
平滑处理
移动平均法
指数平滑法
不要忽视显而易见的东西
相关函数
示例
实现上的问题
(选学)过滤器和卷积
(讲习班)scipysignal
扩展阅读
第5 章多变量：图形的多变量分析
假色图
概览：多值图
散点图矩阵
协作图
变种
组成问题
组成的改变
多维组成：树形图和马赛克图
新颖的曲线类型标识符
平行坐标图
交互式探索
查询和缩放
连接和涂层
大游览与投影寻踪工具
(讲习班)多变量图形工具R
实验工具Python 的Chaco 库
扩展阅读
第6 章插曲：数据分析会话
数据分析会话
(讲习班)gnuplot 软件
扩展阅读
第Ⅱ部分分析：数据建模
第 7 章推算和粗略计算
推算的原理
估计大小
建立关联
使用数字
10 的幂
小扰动
对数
更多示例
我所知道的一些常见事(物)
的相关数字
这些数字是否足够好？
准备工作：可行性和成本
完成之后：引用和
呈现数字
(选学)进一步探索摄动理论和
误差传播
误差传播
(讲习班)Gnu 科学库(GSL)
扩展阅读
第8 章缩放参数模型
模型
建模
模型的运用和误用
参数的缩放
缩放参数
示例：维度参数
示例：优化问题
示例：成本模型
(选学)缩放参数与
量纲分析
其他理论
平均场近似
背景知识和其他示例
常见的时间演变方案
无限增长和衰减现象
约束增长：逻辑斯谛方程
振荡
案例学习：多少台服务器才是
最好的？
为什么要建模？
(讲习班)Sage
扩展阅读
第9 章关于概率模型的讨论
91 二项分布和伯努利试验
精确的结果
利用伯努利试验建立平均场
模型
92 高斯分布和中心极限定理
中心极限定理
中心项与尾项
为什么高斯分布如此实用？
(选学)高斯积分
幂律分布和非常规统计学
幂律分布的用法
(选学)期望值为无限时的
分布
接下来的研究
其他分布
几何分布
泊松分布
对数正态分布
特殊用途的分布
(选学)案例学习--随时间变化的单一访问者数量
(讲习班)幂律分布
扩展阅读
第10 章你真正需要了解的经典统计学知识起源
统计学的定义
从统计学角度解释
示例：公式测验
VS 图解法
控制实验VS 观察研究
实验设计
前景
(选学)贝叶斯统计--
另一种观点
用频率论来解释概率
用贝叶斯方法来理解概率
贝叶斯数据分析： 一个实际有
效的例子
贝叶斯推理：总结与讨论
(讲习班)R 语言
扩展阅读
第11 章插叙：数学大搜捕--
大脚怪和最小二
乘等
111 如何平均均值
辛普森(Simpson)悖论
标准差
如何计算
(选学)应该选择哪一个
(选学)标准误差
最小二乘
统计参数估计
函数逼近
扩展阅读
第Ⅲ部分计算：数据挖掘
第 12 章模拟
热身问题
蒙特卡洛模拟
组合问题
获得结果分布
优点和缺点
重新采样方法
拔靴法
拔靴法适用于哪些情况？
拔靴变量
(讲习班)SimPy 离散事件模拟
SimPy 简介
最简单的排队过程
(选学)排队理论
运行SimPy 模拟
小结
扩展阅读
第13 章找出簇
簇由什么组成？
一种不同的观点
距离计算和相似度计算
常见的距离和相似度
计算方法
聚类方法
中心探索法
树形构造器
邻居生长器
前期处理和后期处理
规模的规范化
类的属性和评估
其他想法
具体案例：超市购物篮的
分析
提醒
(讲习班)Pycluster 和C 聚类库
扩展阅读
第14 章一木见林：
找出重要属性
主成分分析法
动机
(选学)理论
解释
计算
实用观点
双标图
可视化技术
多元尺度法
网络图
柯霍南图
(讲习班)用R 进行PCA
扩展阅读
线性代数
第15 章插曲：当数据不成
比例地增长时
一个真实的故事
一些建议
map/reduce 如何
(讲习班)生成排列
扩展阅读
第Ⅳ部分应用：数据的使用
第 16 章报表、商务智能和
仪表板
商务智能
报表
企业指标和仪表板
关于指标计划的建议
数据的质量问题
数据的可用性
数据的一致性
(讲习班)Berkeley DB 和SQLite
Berkeley DB
SQLite
扩展阅读
第17 章金融计算与建模
货币的时间价值
一次性支付：未来值和
现值
多笔付款：复利
复利的计算技巧
概览：现金流分析和
净现值
计划成本和机会成本中的
不确定性
用账户的期望值来考虑
不确定性
机会成本
成本概念及贬值
直接成本和间接成本
固定成本和可变成本
资本开支与运营成本
是否应该加以关注？
这些就是全部吗？
(讲习班)报纸经销商问题
(选学)精确解
扩展阅读
报纸经销商问题
第18 章预测分析
预测分析的主题
一些分类术语
分类算法
基于实例的分类和最近邻
分类算法
贝叶斯分类器
回归
支持向量机
决策树和基于规则的
分类器
其他分类算法
流程
集成方法：Bagging 和
Boosting
估计预测误差
类不平衡问题
私家秘诀
统计学习的本质
(讲习班)自己编写的两个
分类器
扩展阅读
第19 章结语：事实并非
现实
附录A 科学计算与数据分析的
编程环境
附录B 应用：微积分
附录C 使用数据
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据之魅
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>驾驭大数据
第一部分　大数据的兴起
第1章　什么是大数据，大数据为什么重要
第2章　网络数据：原始的大数据
第3章　典型大数据源及其价值
第二部分　驾驭大数据：技术、流程以及方法
第4章　分析可扩展性的演进
第5章　分析流程的演进
第6章　分析工具与方法的演进
第三部分　驾驭大数据：人和方法
第7章　如何提供优质分析
第8章　如何成为优秀的分析专家
第9章　如何打造优秀的分析团队
第四部分　整合：分析文化
第10章　促进分析创新
第11章　营造创新和探索的文化氛围
结论：再敢想一些
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>驾驭大数据
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习理论
引论：归纳和统计推理问题
第一部分 学习和推广性理论
第1章 处理学习问题的两种方法
第1章附录 解不适定问题的方法
第2章 概率测度估计与学习问题
第3章 经验风险最小化原则一致性的条件
第4章 指示损失函数风险的界
第4章附录 关于ERM原则风险的下界
第5章 实损失函数风险的界
第6章 结构风险最小化原则
第6章附录 基于间接测量的函数估计
第7章 随机不适定问题
第8章 估计给定点上的函数值
第二部分 函数的支持向量估计
……
第三部分 学习理论的统计学基础
……
注释与参考文献评述
参考文献
中英文术语对照表
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习理论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow实战
1 TensorFlow基础 1
1.1 TensorFlow概要 1
1.2 TensorFlow编程模型简介 4
2 TensorFlow和其他深度学习框架的对比 18
2.1 主流深度学习框架对比 18
2.2 各深度学习框架简介 20
3 TensorFlow第一步 39
3.1 TensorFlow的编译及安装 39
3.2 TensorFlow实现SoftmaxRegression识别手写数字 46
4 TensorFlow实现自编码器及多层感知机 55
4.1 自编码器简介 55
4.2 TensorFlow实现自编码器 59
4.3 多层感知机简介 66
4.4 TensorFlow实现多层感知机 70
5 TensorFlow实现卷积神经网络 74
5.1 卷积神经网络简介 74
5.2 TensorFlow实现简单的卷积网络 80
5.3 TensorFlow实现进阶的卷积网络 83
6 TensorFlow实现经典卷积神经网络 95
6.1 TensorFlow实现AlexNet 97
6.2 TensorFlow实现VGGNet 108
6.3 TensorFlow实现GoogleInceptionNet 119
6.4 TensorFlow实现ResNet 143
6.5 卷积神经网络发展趋势 156
7 TensorFlow实现循环神经网络及Word2Vec 159
7.1 TensorFlow实现Word2Vec 159
7.2 TensorFlow实现基于LSTM的语言模型 173
7.3 TensorFlow实现BidirectionalLSTMClassifier 188
8 TensorFlow实现深度强化学习 195
8.1 深度强化学习简介 195
8.2 TensorFlow实现策略网络 201
8.3 TensorFlow实现估值网络 213
9 TensorBoard、多GPU并行及分布式并行 233
9.1 TensorBoard 233
9.2 多GPU并行 243
9.3 分布式并行 249
10 TF.Learn从入门到精通 259
10.1 分布式Estimator 259
10.2 深度学习Estimator 267
10.3 机器学习Estimator 272
10.4 DataFrame 278
10.5 监督器Monitors 279
11 TF.Contrib的其他组件 283
11.1 统计分布 283
11.2 Layer模块 285
11.3 性能分析器tfprof 293
参考文献 297
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
第1章 导论
1.1 模式识别的重要性
1.2 特征、特征向量和分类器
1.3 有监督、无监督和半监督学习
1.4 MATLAB程序
1.5 本书的内容安排
第2章 基于贝叶斯决策理论的分类器
2.1 引言
2.2 贝叶斯决策理论
2.3 判别函数和决策面
2.4 正态分布的贝叶斯分类
2.5 未知概率密度函数的估计
2.6 最近邻规则
2.7 贝叶斯网络
习题
MATLAB编程和练习
参考文献
第3章 线性分类器
3.1 引言
3.2 线性判别函数和决策超平面
3.3 感知器算法
3.4 最小二乘法
3.5 均方估计的回顾
3.6 逻辑识别
3.7 支持向量机
习题
MATLAB编程和练习
参考文献
第4章 非线性分类器
4.1 引言
4.2 异或问题
4.3 两层感知器
4.4 三层感知器
4.5 基于训练集准确分类的算法
4.6 反向传播算法
4.7 反向传播算法的改进
4.8 代价函数选择
4.9 神经网络大小的选择
4.10 仿真实例
4.11 具有权值共享的网络
4.12 线性分类器的推广
4.13 线性二分法中1维空间的容量
4.14 多项式分类器
4.15 径向基函数网络
4.16 通用逼近
4.17 概率神经元网络
4.18 支持向量机：非线性情况
4.19 超越SVM的范例
4.20 决策树
4.21 合并分类器
4.22 合并分类器的增强法
4.23 类的不平衡问题
4.24 讨论
习题
MATLAB编程和练习
参考文献
第5章 特征选择
5.1 引言
5.2 预处理
5.3 峰值现象
5.4 基于统计假设检验的特征选择
5.5 接收机操作特性（ROC）曲线
5.6 类可分性测量
5.7 特征子集的选择
5.8 最优特征生成
5.9 神经网络和特征生成/选择
5.10 推广理论的提示
5.11 贝叶斯信息准则
习题
MATLAB编程和练习
参考文献
第6章 特征生成I：线性变换
6.1 引言
6.2 基本向量和图像
6.3 Karhunen-Loève变换
6.4 奇异值分解
6.5 独立成分分析
6.6 非负矩阵因子分解
6.7 非线性维数降低
6.8 离散傅里叶变换（DFT）
6.9 离散正弦和余弦变换
6.10 Hadamard变换
6.11 Haar变换
6.12 回顾Haar展开式
6.13 离散时间小波变换（DTWT）
6.14 多分辨解释
6.15 小波包
6.16 二维推广简介
6.17 应用
习题
MATLAB编程和练习
参考文献
第7章 特征生成II
7.1 引言
7.2 区域特征
7.3 字符形状和大小的特征
7.4 分形概述
7.5 语音和声音分类的典型特征
习题
MATLAB编程和练习
参考文献
第8章 模板匹配
8.1 引言
8.2 基于最优路径搜索技术的测度
8.3 基于相关的测度
8.4 可变形的模板模型
8.5 基于内容的信息检索：相关反馈
习题
MATLAB编程和练习
参考文献
第9章 上下文相关分类
9.1 引言
9.2 贝叶斯分类器
9.3 马尔可夫链模型
9.4 Viterbi算法
9.5 信道均衡
9.6 隐马尔可夫模型
9.7 状态驻留的HMM
9.8 用神经网络训练马尔可夫模型
9.9 马尔可夫随机场的讨论
习题
MATLAB编程和练习
参考文献
第10章 监督学习：尾声
10.1 引言
10.2 误差计算方法
10.3 探讨有限数据集的大小
10.4 医学图像实例研究
10.5 半监督学习
习题
参考文献
第11章 聚类：基本概念
11.1 引言
11.2 近邻测度
习题
参考文献
第12章 聚类算法I：顺序算法
12.1 引言
12.2 聚类算法的种类
12.3 顺序聚类算法
12.4 BSAS的改进
12.5 两个阈值的顺序方法
12.6 改进阶段
12.7 神经网络的实现
习题
MATLAB编程和练习
参考文献
第13章 聚类算法II：层次算法
13.1 引言
13.2 合并算法
13.3 cophenetic矩阵
13.4 分裂算法
13.5 用于大数据集的层次算法
13.6 最佳聚类数的选择
习题
MATLAB编程和练习
参考文献
第14章 聚类算法III：基于函数最优方法
14.1 引言
14.2 混合分解方法
14.3 模糊聚类算法
14.4 可能性聚类
14.5 硬聚类算法
14.6 向量量化
附录
习题
MATLAB编程和练习
参考文献
第15章 聚类算法IV
15.1 引言
15.2 基于图论的聚类算法
15.3 竞争学习算法
15.4 二值形态聚类算法
15.5 边界检测算法
15.6 谷点搜索聚类算法
15.7 通过代价最优聚类（回顾）
15.8 核聚类方法
15.9 对大数据集的基于密度算法
15.10 高维数据集的聚类算法
15.11 其他聚类算法
15.12 聚类组合
习题
MATLAB编程和练习
参考文献
第16章 聚类有效性
16.1 引言
16.2 假设检验回顾
16.3 聚类有效性中的假设检验
16.4 相关准则
16.5 单独聚类有效性
16.6 聚类趋势
习题
参考文献
附录A 概率论和统计学的相关知识
附录B 线性代数基础
附录C 代价函数的优化
附录D 线性系统理论的基本定义
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>标签
译者序
前言
致谢
第1章 什么是标记
1.1.1 标记是如何起作用的 3
1.1.1 标记系统的基础模型 4
1.1.2 当今的标记系统 6
1.1.3 标记的3个视角 12
1.2 标记为何重要 16
1.2.1 标记很流行 18
1.2.2 标记是多面的 18
1.2.3 标记是社会化的 18
1.2.4 标记是灵活的 19
1.2.5 标记适用于流 19
1.3 小结 20
第2章 标记的价值 21
2.1 标签能为你做什么 21
2.2 体验回报：使用标记的5个动机 23
2.2.1 易用性 23
2.2.2 管理个人信息 24
2.2.3 协作与分享 27
2.2.4 娱乐 28
2.2.5 自我表达 29
2.3 投资回报：商业上的7个益处 31
2.3.1 辅助协同工作 31
2.3.2 获取描述性元数据 31
2.3.3 增强可寻性 32
2.3.4 增加用户参与 32
2.3.5 识别模式 34
2.3.6 强化现有分类成果 34
2.3.7 激发创新 34
2.3.8 另有一事：让你的工作符合系统目标 35
2.4 小结 37
第3章 标记系统架构 39
3.1 用户、资源和标签：探索我们的三部分标记模型 41
3.1.1 第1部分：用户 42
3.1.2 第2部分：资源 46
3.1.3 第3部分：标签 50
3.2 标记实践：现实世界的例子 54
3.2.1 4个标记系统及其架构选择 54
3.2.2 5个常见的标记陷阱（及其解决办法） 55
3.3 小结 61
第4章 标签、元数据和分类系统 63
4.1 面向大众的元数据 64
4.1.1 三种元数据：描述型、管理型和结构型 65
4.1.2 作为元数据的标签 66
4.2 传统分类法和受控词汇表 67
4.2.1 受控词汇表 68
4.2.2 传统分类法 72
4.3 分面 76
4.3.1 理解分面 76
4.3.2 分面标记的两个具体实现：Buzzillions.com和Mefeedia 77
4.4 大众分类法 82
4.4.1 大众分类法的4个特征 84
4.5 元数据生态系统中的标签 86
4.5.1 元数据垃圾问题 87
4.5.2 中等规模的问题 90
4.5.3 速度分层问题 91
4.5.4 一个生态学解决方案 92
4.6 小结 93
第5章 导航与可视化 95
5.1 标签云 95
5.1.1 标签云：基础知识 96
5.1.2 制作标签云 97
5.1.3 扩展标签云 101
5.2 导航标签 104
5.2.1 中心点浏览 105
5.2.2 热门度 107
5.2.3 过滤 109
5.3 地理标记 111
5.4 小结 116
第6章 界面 117
6.1 标记界面中的模式 118
6.1.1 添加并标记资源 119
6.1.2 批量标记 120
6.1.3 只标记已存在资源 121
6.2 标签输入 123
6.2.1 快速与简洁性 123
6.2.2 字符分隔的系统 124
6.2.3 动作分隔的系统 125
6.3 标签推荐 127
6.3.1 三种推荐方式 127
6.3.2 推荐的价值如何 131
6.4 标签管理 132
6.4.1 编辑和删除标签 132
6.4.2 批量编辑和拆分 132
6.4.3 管理还是忽略 133
6.5 小结 135
第7章 技术设计 137
7.1 数据模型 138
7.1.1 简单标记模型 139
7.1.2 协同标记模型 140
7.2 标签云 143
7.2.1 按比例缩放 143
7.2.2 线性缩放 146
7.2.3 分类缩放 149
7.3 FreeTag 149
7.3.1 FreeTag基础知识 149
7.3.2 FreeTag云 152
7.3.3 使用FreeTag和Ajax产生标签推荐 153
7.4 小结 160
附录A 案例研究：社会化书签标注 161
附录B 例研究：媒体分享 181
附录C 案例研究：个人信息管理 193
索引 203
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>标签
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
出版者的话
专家指导委员会
译者序
序
第2版序
致谢
第1章 基于知识的智能系统概述
1.1 智能机器概述
1.2 人工智能发展历史
1.3 小结
复习题
参考文献
第2章 基于规则的专家系统
2.1 知识概述
2.2 规则是一种知识表达技术
2.3 专家系统研发团队中的主要参与者
2.4 基于规则的专家系统的结构
2.5 专家系统的基本特征
2.6 前向链接和后向链接推理技术
2.7 实例
2.8 冲突的解决方案
2.9 基于规则的专家系统的优缺点
2.10 小结
复习题
参考文献
第3章 基于规则的专家系统的不确定管理
3.1 不确定性简介
3.2 基本概率论
3.3 贝叶斯推理
3.4 FORECAST：贝叶斯证据累积
3.5 贝叶斯方法的偏差
3.6 确定因子理论和证据推理
3.7 FORECAST：确定因子的应用
3.8 贝叶斯推理和确定因子的比较
3.9 小结
复习题
参考文献
第4章 模糊专家系统
4.1 概述
4.2 模糊集
4.3 语言变量和模糊限制语
4.4 模糊集的操作
4.5 模糊规则
4.6 模糊推理
4.7 建立模糊专家系统
4.8 小结
复习题
参考文献
参考书目
第5章 基于框架的专家系统
5.1 框架简介
5.2 作为知识表达技术的框架
5.3 基于框架系统中的继承
5.4 方法和守护程序
5.5 框架和规则的交互
5.6 基于框架的专家系统实例：Buy Smart
5.7 小结
复习题
参考文献
参考书目
第6章 人工神经网络
6.1 人脑工作机制简介
6.2 作为简单计算元素的神经元
6.3 感知器
6.4 多层神经网络
6.5 多层神经网络的加速学习
6.6 Hopfield神经网络
6.7 双向相关记忆
6.8 自组织神经网络
6.9 小结
复习题
参考文献
第7章 进化计算
7.1 进化是智能的吗
7.2 模拟自然进化
7.3 遗传算法
7.4 遗传算法如何工作
7.5 实例：用遗传算法来维护计划
7.6 进化策略
7.7 遗传编程
7.8 小结
复习题
参考文献
参考书目
第8章 混合智能系统
8.1 概述
8.2 神经专家系统
8.3 神经模糊系统
8.4 ANFIS：自适应性神经模糊推理系统
8.5 进化神经网络
8.6 模糊进化系统
8.7 小结
复习题
参考文献
第9章 知识工程和数据挖掘
9.1 知识工程简介
9.2 专家系统可以解决的问题
9.3 模糊专家系统可以解决的问题
9.4 神经网络可以解决的问题
9.5 遗传算法可以解决的问题
9.6 混合智能系统可以解决的问题
9.7 数据挖掘和知识发现
9.8 小结
复习题
参考文献
术语表
附录 人工智能工具和厂商
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘中的新方法：支持向量机
序言
符号表
第1章 最优化问题及其基本理论
1.1 最优化问题
1.2 最优性条件
1.3 对偶理论
1.4 注记
参考文献
第2章 求解分类问题和回归问题的直观途径
2.1 分类问题的提出
2.2 线性分类学习机
2.3 支持向量分类机
2.4 线性回归学习机
2.5 支持向量回归机
2.6 注记
参考文献
第3章 核
3.1 描述相似性的工具——内积
3.2 多项式空间和多项式核
3.3 Mercer核
3.4 正定核
3.5 核的构造
3.6 注记
参考文献
第4章 推广能力的理论估计
4.1 损失函数和期望风险
4.2 求解分类问题的一种途径和一个算法模型
4.3 VC维
4.4 学习算法在概率意义下的近似正确性
4.5 一致性概念和关键定理
4.6 结构风险最小化
4.7 基于间隔的推广估计
4.8 注记
参考文献
第5章 分类问题
5.1 最大间隔原则
5.2 线性可分支持向量分类机
5.3 线性支持向量分类机
5.4 支持向量分类机
5.5 ν-支持向量分类机（ν-SVC）
5.6 ν-支持向量分类机（ν-SVC）和C-支持向量分类机（C-SVC）的关系
5.7 多类分类问题
5.8 一个例子
5.9 注记
参考文献
第6章 回归估计
6.1 回归问题
6.2 ε-支持向量回归机
6.3 ν-支持向量回归机
6.4 ε-支持向量回归机（ε-SVR）与ν-支持向量回归机（ν-SVR）的关系
6.5 其他形式的支持向量回归机
6.6 其他形式的损失函数
6.7 一些例子
6.8 注记
参考文献
第7章 算法
7.1 无约束问题解法
7.2 内点算法
7.3 求解大型问题的算法
7.4 注记参考文献
第8章 应用
8.1 模型选择问题
8.2 分类问题的线性分划中的特征选择
8.3 模型选择
8.4 静态图像中球的识别
8.5 自由曲面的重建问题
8.6 应用简介
8.7 核技巧的应用
8.8 注记
参考文献
附录A 基础知识
A.1 基本定义
A.2 梯度和Hesse矩阵
A.3 方向导数
A.4 Taylor展开式
A.5 分离定理
附录B Hilbert空间
B.1 向量空间
B.2 内积空间
B.3 Hilbert空间
B.4 算子、特征值和特征向量
附录C 概率
C.1 概率空间
C.2 随机变量及其分布
C.3 随机变量的数字特征
C.4 大数定律
附录D 鸢尾属植物数据集
英汉术语对照表
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘中的新方法：支持向量机
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能狂潮
人工智能：是机遇，更是挑战
前言  人工智能的春天
第一章  不断进化的人工智能——人工智能是否会毁灭人类？  / 1
开始超越人类的人工智能  / 2
汽车会改变，机器人也会改变  / 4
超高速运算的威力  / 5
人工智能能否成为科幻小说作家？  / 7
全球对于人工智能研究的投资正在增加  / 9
濒临失业的人们  / 11
人类危机即将来临  / 13
本书的阅读方法  / 14
注解  / 17
第二章  什么是“人工智能”——专家与坊间的认识差距  / 19
人工智能尚未实现  / 20
基本命题：人工智能“没理由不能实现”  / 21
什么是人工智能——专家定义梳理  / 24
人工智能与机器人的区别  / 28
什么是人工智能——坊间的看法  / 30
临时工、一般职员、课长与经理人  / 33
强人工智能与弱人工智能  / 35
注解  / 37
第三章 “推理”与“搜索”的时代——第一次人工智能浪潮  / 39
热潮与严冬交替出现  / 40
“人工智能”术语的起源  / 43
用搜索树探寻迷宫  / 44
梵塔问题  / 47
机器人行动过程规划  / 49
博弈组合庞大无比  / 50
在国际象棋和将棋方面已超越人类  / 52
秘诀一：能够发现更好的特征量  / 54
秘诀二：“蒙特卡洛法”改变评估机制  / 55
难解现实问题之困境  / 57
注解  / 58
第四章  知识，让计算机更聪明——第二次人工智能浪潮  / 59
人机对话  / 60
“专家系统”堪比专家  / 62
专家系统相关课题  / 64
什么是“知识表示”?  / 65
如何正确描述知识——本体研究  / 67
重量级本体与轻量级本体  / 70
沃森  / 71
机器翻译难在何处？  / 74
框架问题  / 76
符号接地问题  / 77
生不逢时的“第五代计算机”  / 79
第二次人工智能浪潮消退  / 80
注解  / 81
第五章 “机器学习”悄然兴起——第三次人工智能浪潮之一  / 83
数据激增与机器学习的兴起  / 84
“学习”即“区分”  / 85
有监督学习与无监督学习  / 86
各式各样的“分类”方法  / 87
用人工神经网络识别手写文字  / 94
“学习”需数天，“预测”一瞬间  / 98
机器学习的难点  / 100
人工智能为何仍未实现？  / 103
注解  / 105
第六章 “深度学习”打破沉寂——第三次人工智能浪潮之二  / 107
深度学习开创新时代  / 108
自动编码器：输入与输出相同  / 111
如何从全国天气推测局部地区天气？  / 113
手写文字中的“信息量”  / 116
多层架构深度挖掘  / 118
谷歌的猫脸识别  / 121
飞跃发展的关键——“鲁棒性”  / 124
如何提升鲁棒性？  / 128
回归基本命题  / 129
注解  / 131
第七章  人工智能会超越人类吗——深度学习之后又
将如何发展？/ 133
深度学习之后的技术发展  / 134
人工智能不具有本能  / 143
计算机有创造力吗？  / 147
智能的社会性意义  / 148
奇点真的会发生吗？  / 150
假如人工智能妄想征服人类……  / 152
人工智能须造福大众  / 155
注解  / 158
第八章 不断变化的世界——人工智能对产业与社会的影响及应对策略  / 159
变化不止的事物  / 160
对产业发展的影响  / 162
人工智能的影响逐渐扩大  / 166
将要消失的职业与被保留的职业  / 170
人工智能催生新业务  / 176
人工智能与军事  / 180
“知识转移”改变产业结构  / 182
人工智能垄断阴云  / 185
日本人工智能发展的课题  / 187
人才——逆转的制胜法宝  / 190
怀着对前人的无比敬意  / 192
注解  / 194
后记  寄语尚未实现的人工智能  / 195
作译者简介  / 201
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能狂潮
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>走进搜索引擎
第1章 引言
1.1 搜索引擎概述
1.1.1 目录式搜索引擎
1.1.2 全文搜索引擎
1.1.3 元搜索引擎（Meta-Search Engine）
1.2 搜索引擎的主要需求
1.2.1 快
1.2.2 全
1.2.3 准
1.2.4 稳
1.2.5 省
1.3 搜索引擎的4大系统
1.3.1 搜索引擎的体系结构
第2章 搜索引擎的下载系统
2.1 爬虫的发展历史
2.1.1 世界上第1个爬虫
2.1.2 爬虫的发展历程
2.2 万维网及其网页分析
2.2.1 蝴蝶结型的万维网
2.2.2 万维网的直径
2.2.3 万维网的规模及变化特征
2.2.4 网页的特征
2.3 有关爬虫的基本概念
2.3.1 爬虫
2.3.2 种子站点
2.3.3 URL
2.3.4 Backlinks
2.4 网页抓取原理
2.4.1 telnet和wget
2.4.2 从种子站点开始逐层抓取
2.4.3 不重复抓取策略
2.4.4 网页抓取优先策略
2.4.5 网页重访策略
2.4.6 Robots协议
2.4.7 其他应该注意的礼貌性问题
2.4.8 重要性网页优先抓取策略
2.4.9 抓取提速策略（合作抓取策略）
2.5 网页库
2.6 下载系统回顾及未来发展
参考文献
第3章 搜索引擎的分析系统
3.1 知识准备
3.1.1 HTML语言
3.1.2 锚文本（anchor text）
3.1.3 半结构化数据（semi-structured data）
3.2 信息抽取及网页信息结构化
3.2.1 网页结构化的目标
3.2.2 建立HTML标签树
3.2.3 通过投票方法得到正文
3.2.4 网页结构化过程回顾
3.3 网页查重
3.3.1 网页查重技术发展历史
3.3.2 网页查重实现方法
3.4 中文分词
3.4.1 什么是中文分词
3.4.2 通过字典实现分词
3.4.3 基于统计的分词方法
3.5 PageRank
3.5.1 PageRank的来由
3.5.2 PageRank的基本想法
3.5.3 PageRank的计算公式
3.5.4 PageRank的计算方法
3.6 分析系统结构图
参考文献
第4章 搜索引擎的索引系统
4.1 知识准备
4.1.1 信息
4.1.2 索引
4.1.3 倒排索引、倒排表、临时倒排文件、最终倒排文件
4.1.4 其他概念
4.2 全文检索
4.3 文档编号
4.3.1 编号的本质
4.3.2 文档编号的方法
4.3.3 游程编码
4.4 倒排索引
4.4.1 经典的倒排索引
4.4.2 正排索引（前向索引）
4.4.3 倒排索引
4.5 数据规模的估计
4.5.1 齐普夫法则
4.5.2 布尔检索模型下的索引规模估计
4.6 涉及存储规模的一些计算
4.6.1 正排表与倒排表的合并
4.6.2 多个临时倒排文件的归并
4.6.3 倒排索引分布式存储
4.6.4 倒排文件缓存
4.6.5 倒排索引词典统计信息的计算
4.7 倒排索引文件的创建过程
4.7.1 创建倒排表
4.7.2 计算统计信息
参考文献
第5章 搜索引擎的查询系统
5.1 知识准备
5.1.1 什么是信息熵
5.1.2 检索和查询的区别
5.1.3 检索词和查询词的区别
5.1.4 自动文本摘要（Automatic Text Summarization）
5.2 网页信息检索
5.2.1 早期的检索模型
5.2.2 向量空间模型（Vector Space Models）
5.2.3 关键词权重的量化方法TF/IDF
5.2.4 搜索引擎采用的检索模型
5.2.5 多文档列表求交计算
5.2.6 检索结果排序
5.2.7 堆排序
5.3 中文自动摘要
5.3.1 自动摘要的发展历史
5.3.2 自动摘要的含义和实现
5.4 生成搜索结果页
5.4.1 生成搜索结果页
5.5 搜索结果页的缓存
5.6 推测用户查询意图
5.6.1 查询分类
5.6.2 推测信息类、事物类的查询意图
5.7 查询系统的当前热点和发展方向
5.7.1 查询系统的当前热点
5.7.2 查询系统的发展方向
参考文献
第6章 搜索引擎日志分析
6.1 简介
6.1.1 人机交互的记录——日志
6.1.2 分析搜索引擎日志的意义
6.1.3 本章的主要内容
6.2 知识准备
6.2.1 二分图模型（Bipartite Model）
6.2.2 图模型(graphical model)
6.2.3 LDA（Latent Dirichlet Allocation）模型
6.2.4 随机游走 (Random Walk)
6.2.5 小结
6.3 查询日志分析
6.3.1 查询日志的内容
6.3.2 查询词频统计
6.3.3 查询串提示（Suggestion）
6.3.4 命名实体（Named Entity）类别识别
6.3.5 小结
6.4 点击日志分析
6.4.1 点击日志的内容
6.4.2 查询串提示（Suggestion）再分析
6.4.3 查询和结果类别属性传递
6.4.4 搜索结果相似性度量
6.4.5 查询结果排序
6.4.6 点击数据的稀疏性
6.4.7 小结
6.5 隐私问题
6.5.1 日志的两面性
6.5.2 日志的安全使用
6.5.3 小结
6.6 本章总结
参考文献
第7章 排序学习（Learning to Rank）
7.1 排序概述
7.2 传统的排序模型
7.2.1 查询相关的排序模型
7.2.2 查询无关的排序模型
7.3 排序学习简介以及研究现状
7.3.1 排序学习简介
7.3.2 排序学习问题的研究现状
7.4 排序学习模型的应用实例
7.5 排序学习方法的框架
7.5.1 参数设置
7.5.2 排序学习方法的框架
7.6 评测数据集
7.6.1 LETOR数据集
7.6.2 Microsoft Learning to Rank数据集
7.6.3 Yahoo Webscope数据集
7.7 排序学习模型简介
7.7.1 实例
7.7.2 Pointwise方法
7.7.3 Pairwise方法
7.7.4 Listwise方法
7.7.5 3种排序方法的对比
7.8 排序学习模型性能比较
7.8.1 评测方法
7.8.2 排序模型性能的比较
7.9 排序学习的研究方向
7.9.1 标准标注的自动构建
7.9.2 排序特征
7.9.3 半监督学习/主动学习
7.9.4 查询相关的排序模型
7.9.5 利用用户行为特征
7.10 总结
参考文献
第8章 搜索引擎的性能调优
8.1 系统调优概述
8.2 瓶颈识别
8.3 涉及CPU的优化方法
8.3.1 上下文切换问题（context switching）
8.3.2 中断和轮询
8.3.3 CPU的Affinity问题
8.3.4 流水线问题
8.4 涉及内存的优化方法
8.4.1 概述
8.4.2 对换区
8.4.3 cache line
8.4.4 false sharing问题
8.4.5 内存的锁问题
8.4.6 内存库的使用
8.5 涉及磁盘的优化方法
8.5.1 磁盘IO的调度
8.5.2 其他常见磁盘参数调优
8.5.3 磁盘读写方式
8.5.4 文件缓存问题
8.5.5 5分钟法则
8.6 涉及网络的优化方法
8.6.1 搜索首页，结果页提速方法
8.6.2 Web server的架构选择
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>走进搜索引擎
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>商业数据挖掘导论
译者序
作者简介
前言
第一部分 导论
第1章 商业数据挖掘简介
1.1 介绍
1.2 进行数据挖掘需要什么
1.3 数据挖掘
1.4 集聚营销
1.5 商业数据挖掘
1.6 数据挖掘工具
第2章 数据挖掘过程与知识发
2.1 CRISP-DM
2.2 知识发现过程
第3章 数据挖掘的数据库支持
3.1 数据仓库
3.2 数据集市
3.3 联机分析处理
3.4 数据仓库的实现
3.5 元数据
3.6 系统示范
3.7 数据质量
3.8 软件产品
3.9 实例
第二部分 数据挖掘工具
第4章 数据挖掘方法概述
4.1 数据挖掘方法
4.2 数据挖掘视野
4.3 数据挖掘的作用
4.4 实证数据集
附录4A
第5章 聚类分析
5.1 聚类分析
5.2 聚类分析的描述
5.3 类数量的变动
5.4 聚类分析的运用
5.5 在软件中使用聚类分析
5.6 大数据集的方法运用
5.7 软件产品
附录5A
第6章 数据挖掘中的回归算法
6.1 回归模型
6.2 逻辑回归
6.3 线性判别分析
6.4 数据挖掘中回归的实际应用
6.5 大样本数据集的模型应用
第7章 数据挖掘中的神经网络
7.1 神经网络
7.2 数据挖掘中的神经网络
7.3 神经网络的商业应用
7.4 神经网络应用于大样本数据集
7.5 神经网络产品
第8章 决策树算法
8.1 决策树的工作方式
8.2 机器学习
8.3 决策树的应用
8.4 决策树法运用到大型的数据集
8.5 决策树的软件产品
附录8A
第9章 基于线性规划的方法
9.1 线性判别分析
9.2 多重标准线性规划分类
9.3 模糊线性规划分类
9.4 信用卡证券管理：线性规划的实际应用
9.5 线性规划的软件支持
附录9A
第三部分 商业应用
第10章 商业数据挖掘的应用
10.1 应用
10.2 不同数据挖掘方法的比较
第11章 市场购物篮分析
11.1 定义
11.2 实证
11.3 市场购物篮分析的局限
11.4 市场购物篮分析软件
附录11A
第四部分 发展中的问题
第12章 文本挖掘与web挖掘
12.1 文本挖掘
12.2 Web挖掘
附录12A
第13章 数据挖掘中的道德规范
13.1 数据访问的隐患
13.2 Web数据挖掘问题
13.3 网络问题
13.4 网络道德
13.5 控制方法
术语表
注释
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>商业数据挖掘导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>支持向量机
序言
符号表
第1章 最优化基础
1．1 欧式空间上的最优化问题
1．1．1 最优化问题实例
1．1．2 最优化问题及其解
1．1．3 最优化问题的几何解释
1．2 欧式空间上的凸规划
1．2．1 凸集和凸函数
1．2．2 凸规划问题及其基本性质
1．2．3 凸规划的对偶理论
1．2．4 凸规划的最优性条件
1．2．5 线性规划
1．3 Hilbert空间上的凸规划
1．3．1 凸函数及Frechet导数
1．3．2 凸规划问题
1．3．3 凸规划的对偶理论
1．3．4 凸规划的最优性条件
1．4 欧式空间上带有广义不等式约束的凸规划
1．4．1 带有广义不等式约束的凸规划
1．4．2 带有广义不等式约束的凸规划的对偶理论
1．4．3 带有广义不等式约束的凸规划的最优性条件
1．4．4 二阶锥规划
1．4．5 半定规划
1．5 Hilbert空间上带有广义不等式约束的凸规划
1．5．1 K－凸函数与Frechet导数
1．5．2 凸规划问题
1．5．3 凸规划的对偶理论
1．5．4 凸规划的最优性条件
第2章 线性分类机
2．1 分类问题的提出
2．1．1 例子（心脏病诊断）
2．1．2 分类问题和分类机
2．2 线性可分问题的支持向量分类机
2．2．1 最大间隔法_
2．2．2 线性可分问题的支持向量分类机
2．2．3 支持向量
2．3 线性支持向量分类机
2．3．1 最大间隔法
2．3．2 线性支持向量分类机
第3章 线性回归机
3．1 回归问题和线性回归问题
3．2 硬ε带超平面
3．2．1 从线性回归问题到硬乒带超平面
3．2．2 硬ε-带超平面与线性分划
3．2．3 构造硬ε带超平面的最优化问题
3．3 线性硬ε-带支持向量回归机
3．3．1 原始问题
3．3．2 对偶问题及其与原始问题解的关系
3．3．3 线性硬ε-带支持向量回归机
3．4 线性ε-支持向量回归机
3．4．1 原始问题
3．4．2 对偶问题及其与原始问题解的关系
3．4．3 线性ε-支持向量回归机
第4章 核与支持向量机
4．1 从线性分划到非线性分划
4．1．1 非线性分划的例子
4．1．2 基于非线性分划的分类算法
4．1．3 基于非线性分划的回归算法
4．2 核函数
4．2．1 核函数及其特征
4．2．2 核函数的判定和常用的核函数
4．3 支持向量机及其性质
4．3．1 支持向量分类机
4．3．2 支持向量回归机
4．4 支持向量机中核函数的选取
4．4．1 已知训练集时核函数的选取
4．4．2 核函数的直接构造
第5章 C-支持向量分类机的统计学基础
5．1 分类问
5．1．1 概率分布
5．1．2 分类问题的统计学提法
5．2 经验风险最小化原则
5．3 VC维
5．4 结构风险最小化原则
5．5 结构风险最小化原则的一个直接实现
5．5．1 原始问题
5．5．2 拟对偶问题及其与原始问题的关系
5．5．3 结构风险最小化分类机
5．6 C-支持向量分类机的统计学习理论基础
5．6．1 C-支持向量分类机的回顾
5．6．2 对偶问题与拟对偶问题的关系
5．6．3 C-线性支持向量分类机的统计学习理论解释
……
第6章模型选择
第7章算法
第8章支持向量机的变形与拓广
参考文献
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>支持向量机
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言处理的形式模型
总序
前言
第1章 自然语言处理的学科定位
1.1 从自然语言处理的过程来考察其学科定位
1.2 从自然语言处理的范围来考察其学科定位
1.3 从自然语言处理的历史来考察其学科定位
1.4 当前自然语言处理发展的几个特点
第2章 语言计算研究的先驱
2.1 Markov链
2.2 Zipf定律
2.3 Shannon关于“熵”的研究
2.4 Bar-Hillel的范畴语法
2.5 Harris的语言串分析法
2.6 o.c.KysmrHHa的语言集合论模型
第3章 基于短语结构语法的形式模型
3.1 语法的Chomsky层级
3.2 有限状态语法和它的局限性
3.3 短语结构语法
3.4 递归转移网络和扩充转移网络
3.5 自底向上分析和自顶向下分析
3.6 通用句法生成器和线图分析法
3.7 Earley算法
3.8 左角分析法
3.9 CYK算法
3.10 Tomita算法
3.11 管辖-约束理论与最简方案
3.12 Joshi的树邻接语法
3.13 汉字结构的形式描述
第4章 基于合一运算的形式模型
4.1 中文信息MMT模型
4.2 Kaplan的词汇功能语法
4.3 MartinKay的功能合一语法
4.4 Gazdar的广义短语结构语法
4.5 Shieber的PATR
4.6 Pollard的中心语驱动的短语结构语法
4.7 Pereira和Warren定子句语法
第5章 基于依存和配价的形式模型
5.1 配价观念的起源
5.2 Tesni6re的依存语法
5.3 依存语法在自然语言处理中的应用
5.4 配价语法
5.5 配价语法在自然语言处理中的应用
第6章 基于格语法的形式模型
6.1 Fillmore的格语法
6.2 Fillmore的框架网络
第7章 基于词汇主义的形式模型
7.1 Gross的词汇语法
7.2 链语法
7.3 词汇语义学
7.4 知识本体
7.5 词网WordNet
7.6 知网HowNet
第8章 语义自动处理的形式模型
8.1 义素分析法
8.2 语义场
8.3 语义网络
8.4 Montague的蒙塔鸠语法
8.5 Wilks的优选语义学
8.6 Schank的概念依存理论
8.7 Mel’chuk的意义㈢文本理论
8.8 词义排歧方法
第9章 系统功能语法
9.1 系统功能语法的基本概念
9.2 系统功能语法在自然语言处理中的应用
第10章 语用自动处理的形式模型
10.1 Mann和Thompson的修辞结构理论
10.2 文本连贯中的常识推理技术
第11章 概率语法
11.1 概率上下文无关语法与句子的歧义
11.2 概率上下文无关语法的基本原理
11.3 概率上下文无关语法的三个假设
11.4 概率词汇化上下文无关语法
第12章 Bayes公式与动态规划算法
12.1 拼写错误的检查与更正
12.2 Bayes公式与噪声信道模型
12.3 最小编辑距离算法
12.4 发音问题研究中的Bayes方法
12.5 发音变异的决策树模型
12.6 加权自动机
12.7 向前算法
12.8 Viterbi算法
本章附录
第13章 N元语法和数据平滑
13.1 N元语法
13.2 数据平滑
第14章 隐马尔可夫模型（HMM）
14.1 HMM模型概述
14.2 HMM模型在语音识别中的应用
第15章 统计机器翻译中的形式模型
15.1 机器翻译与噪声信道模型
15.2 最大熵模型
15.3 基于平行概率语法的形式模型
15.4 基于短语的统计机器翻译
15.5 基于句法的统计机器翻译
第16章 自然语言处理系统的评测
16.1 评测的一般原则和方法
16.2 语音合成和文语转换系统的评测
16.3 机器翻译系统的评测
16.4 语料库系统的评测
16.5 国外自然语言处理系统的评测
第17章 自然语言处理中的理性主义与经验主义
17.1 哲学中的理性主义和经验主义
17.2 自然语言处理中理性主义和经验主义的消长
17.3 理性主义和经验主义的利弊得失
17.4 探索理性主义方法和经验主义方法结合的途径
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言处理的形式模型
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘原理
第1章 给论
1.1 数据挖掘简介
1.2 数据集属性
1.3 结构类型：模型和模式
1.4 数据挖掘任务
1.5 数据挖掘算法的组件
1.5.1 评分函数
1.5.2 优化和搜索方法
1.5.3 数据管理策略
1.6 统计和数据挖掘的相互关系
1.7 数据挖掘：打捞、探查还是垂钓
1.8 本章归纳
1.9 补充读物
第2章 测量和数据
2.1 简介
2.2 测量类型
2.3 距离尺度
2.4 数据转化
2.5 数据形式
2.6 单个测量的数据质量
2.7 数据群体的数据质量
2.8 本章归纳
2.9 补充读物
第3章 可视化和探索数据
3.1 简介
3.2 总结数据：几个简单例子
3.3 显示单个变量的一些工具
3.4 显示两个变量间关系的工具
3.5 显示两个以上变量间关系的工具
3.6 主分量分析
3.7 多维缩放
3.8 补充读物
第4章 数据分析和不确定性
4.1 简介
4.2 处理不确定性
4.3 随机变量和它们的关系
4.4 样本和统计推理
4.5 估计
4.5.1 估计量的理想属性
4.5.2 最大似然估计
4.5.3 贝叶斯估计
4.6 假设检验
4.6.1 古典假设检验
4.6.2 数据挖掘中的假设检验
4.7 采样方法
4.8 本章归纳
4.9 补充读物
第5章 数据挖掘算法概览
5.1 简介
5.2 建立树分类器的CART算法
5.3 数据挖掘算法的化约主义观点
5.3.1 用于回归和分类的多层感知器
5.3.2 关联规则学习的A Priori算法
5.3.3 检索文本的向量空间算法
5.4 讨论
5.5 补充读物
第6章 模型和模式
6.1 概述
6.2 建模基础
6.3 用于预测的模型结构
6.3.1 具有线性结构的回归模型
6.3.2 用于回归的局部分段模型结构
6.3.3 “基于记忆”的非参数局部模型
6.3.4 模型结构的随机部分
6.3.5 用于分类的预测模型
6.3.6 选择适当复杂度的模型
6.4 概率分布和密度函数模型
6.4.1 一般概念
6.4.2 混合模型
6.4.3 无序范畴型数据的联合分布
6.4.4 因式分解和高维空间中的独立性
6.5 维度效应
6.5.1 高维数据的变量选择
6.5.2 高维数据的变换
6.6 用于结构化数据的模型
6.7 模式结构
6.7.1 数据矩阵中的模式
6.7.2 字符串模式
6.3 参考读物
第7章 数据挖掘算法的评分函数
7.1 简介
7.2 对模式进行评价
7.3 预测性评分函数和描述性评分函数
7.3.1 评价预测模型的评分函数
7.3.2 评价描述模型的评分函数
7.4 评价不同复杂度的模型
7.4.1 模型比较的一般概念
7.4.2 再谈偏差一方差
7.4.3 惩罚复杂模型的评分函数
7.4.4 使用外部验证的评分函数
7.5 模型和模式的评价
7.6 鲁棒方法
7.7 补充读物
第8章 搜索和优化方法
8.1 简介
8.2 搜索模型或模式
8.2.1 搜索背景
8.2.2 数据挖掘中的状态空间搜索
8.2.3 简单贪婪搜索算法
8.2.4 系统搜索和搜索启示
8.2.5 分支定界法
8.3 参数优化方法
8.3.1 参数优化：背景
8.3.2 闭合形式解和线性代数方法
8.3.3 优化平滑函数的基于梯度方法
8.3.4 一元参数优化
8.3.5 多元参数优化
8.3.6 约束优化
8.4 存在残缺数据时的优化：EM算法
8.5 在线和单扫描算法
8.6 随机搜索和优化技术
8.7 补充读物
第9章 描述建模
9.1 简介
9.2 通过概率分布和密度描述数据
9.2.1 简介
9.2.2 用来估计概率分布和密度的评分函数
9.2.3 参数密度模型
9.2.4 混合分布和密度
9.2.5 混合模型的EM算法
9.2.6 非参数的密度估计
9.2.7 范畴型数据的联合分布
9.3 聚类分析背景
9.4 基于划分的聚类算法
9.4.1基于划分聚类的评分函数
9.4.2 基于划分聚类的基本算法
9.5 层次聚类
9.5.1 凝聚方法
9.5.2 分裂方法
9.6 基于混合模型的概率聚类
9.7 补充读物
第10章 用于分类的预测建模
10.1 预测建模概览
10.2 分类建模简介
10.2.1 判别分类和决策边界
10.2.2 分类的概率模型
10.2.3 建立实际的分类器
10.3 感知器
10.4 线性判别式
10.5 树模型
10.6 最近邻方法
10.7 1ogistic判别式分析
10.8 朴素贝叶斯模型
10.9 其他方法
10.10 分类器的评估和比较
10.11 高维分类的特征选取
10.12 补充读物
第11章 用于回归的预测建模
11.1简介
11.2 线性模型和最小二乘法拟合
11.2.1 拟合模型的计算问题
11.2.2 线性回归的概率解释
11.2.3 拟合后模型的解释
11.2.4 推理和泛化
11.2.5 模型搜索和建模
11.2.6 模型诊断和审查
11.3 推广的线性模型
11.4 人工神经网络
11.5 其他高度参数化的模型
11.5.1 推广的相加模型
11.5.2 投影追踪回归
11.6 补充读物
第12章 数据组织和数据库
12.1 简介
12.2 存储器层次
12.3 索引结构
12.3.1 B-树
12.3.2 哈希索引
12.4 多维索引
12.5 关系数据库
12.6 操纵表格
12.7 结构化查询语言
12.8 查询的执行和优化
12.9 数据仓库和在线分析处理
12.10 O1AP的数据结构
12.11 字符串数据库
12.12 海量数据集、数据管理和数据挖掘
12.12.1 把数据都放入主存储器
12.12.2 数据挖掘算法的可伸缩版本
12.12.3 考虑磁盘访问的有针对性算法
12.12.4 伪数据集和充分统计量
12.13 补充读物
第13章 寻找模式和规则
13.1 简介
13.2 规则表示
13.3 频繁项集和关联规则
13.3.1 简介
13.3.2 寻找频繁集和关联规则
13.4 推广
13.5 寻找序列中的片段
13.6 选择发现的模式和规则
13.6.1 简介
13.6.2 寻找模式的启发式搜索
13.6.3 有趣度标准
13.7 从局部模式到全局模型
13.8 预测规则归纳
13.9 补充读物
第14章 根据内容检索
14.1 简介
14.2 检索系统的评价
14.2.1 评价检索性能的困难之处
14.2.2 查准率对查全率
14.2.3 查准率和查全率的实践应用
14.3 文本检索
14.3.1 文本的表示
14.3.2 匹配查询和文档
14.3.3 隐含语义索引
14.3.4 文档和文本分类
14.4 对个人偏好建模
14.4.1 相关性反馈
14.4.2 自动推荐系统
14.5 图像检索
14.5.1 图像理解
14.5.2 图像表示
14.5.3 图像查询
14.5.4 图像恒定性
14.5.5 图像检索的推广
14.6 时间序列和序列检索
14.6.1 时间序列数据的全局模型
14.6.2 时间序列的结构和形状
14.7 本章归纳
14.8 补充读物
附录 随机变量
参考文献
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘原理
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器人科技
第1篇　机器人新领域 1
第1章　双子机器人　　2
第2章　人机交互　　6
第3章　连接人类与机器人的心理学　　12
第4章　机器人听觉　　16
第5章　仿生学　　20
第6章　分子机器人学　　24
第7章　生物体与机器人的融合　　28
第8章　认知型BMI下的外部机器控制系统　　32
第9章　机器人与设计的融合　　36
第10章　机器人安全　　40
第11章　认知发展机器人学　　44
第12章　筑波机器人挑战赛　　48
第2篇　机器人系统　53
第1章　仿人机器人　　54
第2章　强化服　　58
第3章　沟通型机器人　　62
第4章　水下机器人　　66
第5章　无人飞行器　　72
第6章　微型机器人　　76
第7章　软体机器人　　80
第8章　并联机构　　84
第9章　义手与义足　　88
第10章　操控装置与机械手　　92
第11章　高速操控装置　　96
第12章　智能生活空间　　100
第13章　智慧城市　　104
第14章　无所不在的机器人学　　108
第3篇　机器人应用　　113
第1章　医疗机器人　　114
第2章　看护机器人　　118
第3章　救援机器人　　122
第4章　建筑机器人　　126
第5章　清洁机器人　　130
第6章　农业机器人　　134
第7章　太空机器人　　138
第8章　个人交通工具　　142
第9章　娱乐机器人（I-Fairy）　　146
第10章　触觉反馈装置　　152
第11章　数字人技术　　156
第12章　虚拟现实技术（VR）　　160
第4篇　机器人硬件　　165
第1章　动作传感器　　166
第2章　激光测距仪　　172
第3章　触觉硬件　　176
第4章　味觉传感器与嗅觉传感器　　182
第5章　人工肌肉、高分子致动器　　186
第6章　RC伺服电机　　190
第7章　微型致动器　　194
第8章　ER/MR流体　　198
第9章　高速视觉系统　　202
第10章　作为定位传感器使用的GPS与GNSS　　206
第5篇　机器人软件　　211
第1章　软件平台　　212
第2章　物理引擎　　216
第3章　OpenCV　　220
第4章　ROS（机器人OS）　　224
第6篇　机器人动作　　229
第1章　二足步行　　230
第2章　被动步行与基于动态控制　　234
第3章　机器学习与统计决定行动　　238
第4章　运动规划　　242
第7篇　机器人知觉　　247
第1章　同步定位与建图　　248
第2章　动作识别理解　　252
第3章　人脸识别　　256
第4章　粒子滤波器　　260
第5章　动作捕捉　　264
第8篇　机器人竞赛　　269
第1章　机器人竞赛的意义　　270
第2章　RoboCup　　274
第3章　ROBO-ONE　　278
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器人科技
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言处理简明教程
第一章 自然语言处理与理论语言学
第二章 词汇自动处理
第三章 形态自动处理
第四章 句法自动处理
第五章 结构歧义
第六章 良构子串表与线图
第七章 复杂特征与合一运算
第八章 语义自动处理
第九章 马尔可夫链与隐马尔可夫模型
第十章 语料库语言学
第十一章 机器翻译
第十二章 信息自动检索
第十三章 信息抽取和自动文摘
第十四章 文本数据挖掘
第十五章 自然语言理解、自动问答与人机接口
第十六章 术语数据库与计算术语学
第十七章 计算机辅助语言教学和语言测试
第十八章 语音合成、语音识别和汉字识别
结语
附录
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言处理简明教程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>写给程序员的数据挖掘实践指南
内容提要
作译者简介
译者序
序
前言
第1章 数据挖掘简介及本书使用方法
第2章 协同过滤—爱你所爱
第3章 协同过滤—隐式评级及基于物品的过滤
第4章 内容过滤及分类—基于物品属性的过滤
第5章 分类的进一步探讨—算法评估及kNN
第6章 概率及朴素贝叶斯—朴素贝叶斯
第7章 朴素贝叶斯及文本—非结构化文本分类
第8章 聚类—群组发现
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>写给程序员的数据挖掘实践指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Mahout实战
第1章　初识Mahout　　1
1.1 　Mahout的故事　　1
1.2 　Mahout的机器学习主题　　2
1.2.1 　推荐引擎　　2
1.2.2 　聚类　　3
1.2.3 　分类　　4
1.3 　利用Mahout和Hadoop处理大规模数据　　4
1.4 　安装Mahout　　6
1.4.1 　Java和IDE　　6
1.4.2 　安装Maven　　7
1.4.3 　安装Mahout　　7
1.4.4 　安装Hadoop　　8
1.5 　小结　　8
第一部分 　推荐
第2章　推荐系统　　10
2.1 　推荐的定义　　10
2.2 　运行第一个推荐引擎　　11
2.2.1 　创建输入　　11
2.2.2 　创建一个推荐程序　　13
2.2.3 　分析输出　　14
2.3 　评估一个推荐程序　　14
2.3.1 　训练数据与评分　　15
2.3.2 　运行RecommenderEvaluator　　15
2.3.3 　评估结果　　16
2.4 　评估查准率与查全率　　17
2.4.1 　运行RecommenderIRStats-Evaluator　　17
2.4.2 　查准率和查全率的问题　　19
2.5 　评估GroupLens数据集　　19
2.5.1 　提取推荐程序的输入　　19
2.5.2 　体验其他推荐程序　　20
2.6 　小结　　20
第3章　推荐数据的表示　　21
3.1 　偏好数据的表示　　21
3.1.1 　Preference对象　　21
3.1.2 　PreferenceArray及其实现　　22
3.1.3 　改善聚合的性能　　23
3.1.4 　FastByIDMap和FastIDSet　　23
3.2 　内存级DataModel　　24
3.2.1 　GenericDataModel　　24
3.2.2 　基于文件的数据　　25
3.2.3 　可刷新组件　　25
3.2.4 　更新文件　　26
3.2.5 　基于数据库的数据　　26
3.2.6 　JDBC和MySQL　　27
3.2.7 　通过JNDI进行配置　　27
3.2.8 　利用程序进行配置　　28
3.3 　无偏好值的处理　　29
3.3.1 　何时忽略值　　29
3.3.2 　无偏好值时的内存级表示　　30
3.3.3 　选择兼容的实现　　31
3.4 　小结　　33
第4章　进行推荐　　34
4.1 　理解基于用户的推荐　　34
4.1.1 　推荐何时会出错　　34
4.1.2 　推荐何时是正确的　　35
4.2 　探索基于用户的推荐程序　　36
4.2.1 　算法　　36
4.2.2 　基于GenericUserBased-Recommender实现算法　　36
4.2.3 　尝试GroupLens数据集　　37
4.2.4 　探究用户邻域　　38
4.2.5 　固定大小的邻域　　39
4.2.6 　基于阈值的邻域　　39
4.3 　探索相似性度量　　40
4.3.1 　基于皮尔逊相关系数的相似度　　40
4.3.2 　皮尔逊相关系数存在的问题　　42
4.3.3 　引入权重　　42
4.3.4 　基于欧氏距离定义相似度　　43
4.3.5 　采用余弦相似性度量　　43
4.3.6 　采用斯皮尔曼相关系数基于相对排名定义相似度　　44
4.3.7 　忽略偏好值基于谷本系数计算相似度　　45
4.3.8 　基于对数似然比更好地计算相似度　　46
4.3.9 　推测偏好值　　47
4.4 　基于物品的推荐　　47
4.4.1 　算法　　48
4.4.2 　探究基于物品的推荐程序　　49
4.5 　Slope-one推荐算法　　50
4.5.1 　算法　　50
4.5.2 　Slope-one实践　　51
4.5.3 　DiffStorage和内存考虑　　52
4.5.4 　离线计算量的分配　　53
4.6 　最新以及试验性质的推荐算法　　53
4.6.1 　基于奇异值分解的推荐算法　　53
4.6.2 　基于线性插值物品的推荐算法　　54
4.6.3 　基于聚类的推荐算法　　55
4.7 　对比其他推荐算法　　56
4.7.1 　为Mahout引入基于内容的技术　　56
4.7.2 　深入理解基于内容的推荐算法　　57
4.8 　对比基于模型的推荐算法　　57
4.9 　小结　　57
第5章　让推荐程序实用化　　59
5.1 　分析来自约会网站的样本数据　　59
5.2 　找到一个有效的推荐程序　　61
5.2.1 　基于用户的推荐程序　　61
5.2.2 　基于物品的推荐程序　　62
5.2.3 　slope-one推荐程序　　63
5.2.4 　评估查准率和查全率　　63
5.2.5 　评估性能　　64
5.3 　引入特定域的信息　　65
5.3.1 　采用一个定制的物品相似性度量　　65
5.3.2 　基于内容进行推荐　　66
5.3.3 　利用IDRescorer修改推荐结果　　66
5.3.4 　在IDRescorer中引入性别　　67
5.3.5 　封装一个定制的推荐程序　　69
5.4 　为匿名用户做推荐　　71
5.4.1 　利用PlusAnonymousUser-DataModel处理临时用户　　71
5.4.2 　聚合匿名用户　　73
5.5 　创建一个支持Web访问的推荐程序　　73
5.5.1 　封装WAR文件　　74
5.5.2 　测试部署　　74
5.6 　更新和监控推荐程序　　75
5.7 　小结　　76
第6章　分布式推荐　　78
6.1 　分析Wikipedia数据集　　78
6.1.1 　挑战规模　　79
6.1.2 　分布式计算的优缺点　　80
6.2 　设计一个基于物品的分布式推荐算法　　81
6.2.1 　构建共现矩阵　　81
6.2.2 　计算用户向量　　82
6.2.3 　生成推荐结果　　82
6.2.4 　解读结果　　83
6.2.5 　分布式实现　　83
6.3 　基于MapReduce实现分布式算法　　83
6.3.1 　MapReduce简介　　84
6.3.2 　向MapReduce转换：生成用户向量　　84
6.3.3 　向MapReduce转换：计算共现关系　　85
6.3.4 　向MapReduce转换：重新思考矩阵乘　　87
6.3.5 　向MapReduce转换：通过部分乘积计算矩阵乘　　87
6.3.6 　向MapReduce转换：形成推荐　　90
6.4 　在Hadoop上运行MapReduce　　91
6.4.1 　安装Hadoop　　92
6.4.2 　在Hadoop上执行推荐　　92
6.4.3 　配置mapper和reducer　　94
6.5 　伪分布式推荐程序　　94
6.6 　深入理解推荐　　95
6.6.1 　在云上运行程序　　95
6.6.2 　考虑推荐的非传统用法　　97
6.7 　小结　　97
第二部分 　聚类
第7章　聚类介绍　　100
7.1 　聚类的基本概念　　100
7.2 　项目相似性度量　　102
7.3 　Hello World：运行一个简单的聚类示例　　103
7.3.1 　生成输入数据　　103
7.3.2 　使用Mahout聚类　　104
7.3.3 　分析输出结果　　107
7.4 　探究距离测度　　108
7.4.1 　欧氏距离测度　　108
7.4.2 　平方欧氏距离测度　　108
7.4.3 　曼哈顿距离测度　　108
7.4.4 　余弦距离测度　　109
7.4.5 　谷本距离测度　　110
7.4.6 　加权距离测度　　110
7.5 　在简单示例上使用各种距离测度　　111
7.6 　小结　　111
第8章　聚类数据的表示　　112
8.1 　向量可视化　　113
8.1.1 　将数据转换为向量　　113
8.1.2 　准备Mahout所用的向量　　115
8.2 　将文本文档表示为向量　　116
8.2.1 　使用TF-IDF改进加权　　117
8.2.2 　通过n-gram搭配词考察单词的依赖性　　118
8.3 　从文档中生成向量　　119
8.4 　基于归一化改善向量的质量　　123
8.5 　小结　　124
第9章　Mahout中的聚类算法　　125
9.1 　k-means聚类　　125
9.1.1 　关于k-means你需要了解的　　126
9.1.2 　运行k-means聚类　　127
9.1.3 　通过canopy聚类寻找最佳k值　　134
9.1.4 　案例学习：使用k-means对新闻聚类　　138
9.2 　超越k-means: 聚类技术概览　　141
9.2.1 　不同类型的聚类问题　　141
9.2.2 　不同的聚类方法　　143
9.3 　模糊k-means聚类　　145
9.3.1 　运行模糊k-means聚类　　145
9.3.2 　多模糊会过度吗　　147
9.3.3 　案例学习：用模糊k-means对新闻进行聚类　　148
9.4 　基于模型的聚类　　149
9.4.1 　k-means的不足　　149
9.4.2 　狄利克雷聚类　　150
9.4.3 　基于模型的聚类示例　　151
9.5 　用LDA进行话题建模　　154
9.5.1 　理解LDA　　155
9.5.2 　对比TF-IDF与LDA　　156
9.5.3 　LDA参数调优　　156
9.5.4 　案例学习：寻找新闻文档中的话题　　156
9.5.5 　话题模型的应用　　158
9.6 　小结　　158
第10章　评估并改善聚类质量　　160
10.1 　检查聚类输出　　160
10.2 　分析聚类输出　　162
10.2.1 　距离测度与特征选择　　163
10.2.2 　簇间与簇内距离　　163
10.2.3 　簇的混合与重叠　　166
10.3 　改善聚类质量　　166
10.3.1 　改进文档向量生成过程　　166
10.3.2 　编写自定义距离测度　　169
10.4 　小结　　171
第11章　将聚类用于生产环境　　172
11.1 　Hadoop下运行聚类算法的快速入门　　172
11.1.1 　在本地Hadoop集群上运行聚类算法　　173
11.1.2 　定制Hadoop配置　　174
11.2 　聚类性能调优　　176
11.2.1 　在计算密集型操作中避免性能缺陷　　176
11.2.2 　在I/O密集型操作中避免性能缺陷　　178
11.3 　批聚类及在线聚类　　178
11.3.1 　案例分析：在线新闻聚类　　179
11.3.2 　案例分析：对维基百科文章聚类　　180
11.4 　小结　　181
第12章　聚类的实际应用　　182
12.1 　发现Twitter上的相似用户　　182
12.1.1 　数据预处理及特征加权　　183
12.1.2 　避免特征选择中的常见陷阱　　184
12.2 　为Last.fm上的艺术家推荐标签　　187
12.2.1 　利用共现信息进行标签推荐　　187
12.2.2 　构建Last.fm艺术家词典　　188
12.2.3 　将Last.fm标签转换成以艺术家为特征的向量　　190
12.2.4 　在Last.fm数据上运行k-means算法　　191
12.3 　分析Stack Overflow数据集　　193
12.3.1 　解析Stack Overflow数据集　　193
12.3.2 　在Stack Overflow中发现聚类问题　　193
12.4 　小结　　194
第三部分 　分类
第13章　分类　　198
13.1 　为什么用Mahout做分类　　198
13.2 　分类系统基础　　199
13.2.1 　分类、推荐和聚类的区别　　201
13.2.2 　分类的应用　　201
13.3 　分类的工作原理　　202
13.3.1 　模型　　203
13.3.2 　训练、测试与生产　　203
13.3.3 　预测变量与目标变量　　204
13.3.4 　记录、字段和值　　205
13.3.5 　预测变量值的4种类型　　205
13.3.6 　有监督学习与无监督学习　　207
13.4 　典型分类项目的工作流　　207
13.4.1 　第一阶段工作流：训练分类模型　　208
13.4.2 　第二阶段工作流：评估分类模型　　212
13.4.3 　第三阶段工作流：在生产中使用模型　　212
13.5 　循序渐进的简单分类示例　　213
13.5.1 　数据和挑战　　213
13.5.2 　训练一个模型来寻找颜色填充：初步设想　　214
13.5.3 　选择一个学习算法来训练模型　　215
13.5.4 　改进填充颜色分类器的性能　　217
13.6 　小结　　221
第14章　训练分类器　　222
14.1 　提取特征以构建分类器　　222
14.2 　原始数据的预处理　　224
14.2.1 　原始数据的转换　　224
14.2.2 　一个计算营销的例子　　225
14.3 　将可分类数据转换为向量　　226
14.3.1 　用向量表示数据　　226
14.3.2 　用Mahout API做特征散列　　228
14.4 　用SGD对20 Newsgroups数据集进行分类　　231
14.4.1 　开始：数据集预览　　231
14.4.2 　20 Newsgroups数据特征的解析和词条化　　234
14.4.3 　20 Newsgroups数据的训练代码　　234
14.5 　选择训练分类器的算法　　238
14.5.1 　非并行但仍很强大的算法：SGD和SVM　　239
14.5.2 　朴素分类器的力量：朴素贝叶斯及补充朴素贝叶斯　　239
14.5.3 　精密结构的力量：随机森林算法　　240
14.6 　用朴素贝叶斯对20 Newsgroups数据分类　　241
14.6.1 　开始：为朴素贝叶斯提取数据　　241
14.6.2 　训练朴素贝叶斯分类器　　242
14.6.3 　 测试朴素贝叶斯模型　　242
14.7 　小结　　244
第15章　分类器评估及调优　　245
15.1 　Mahout中的分类器评估　　245
15.1.1 　获取即时反馈　　246
15.1.2 　确定分类“好”的含义　　246
15.1.3 　认识不同的错误代价　　247
15.2 　分类器评估API　　247
15.2.1 　计算AUC　　248
15.2.2 　计算混淆矩阵和熵矩阵　　250
15.2.3 　计算平均对数似然　　252
15.2.4 　模型剖析　　253
15.2.5 　20 Newsgroups语料上SGD分类器的性能指标计算　　254
15.3 　分类器性能下降时的处理　　257
15.3.1 　目标泄漏　　258
15.3.2 　特征提取崩溃　　260
15.4 　分类器性能调优　　262
15.4.1 　问题调整　　262
15.4.2 　分类器调优　　265
15.5 　小结　　267
第16章　分类器部署　　268
16.1 　巨型分类系统的部署过程　　268
16.1.1 　理解问题　　269
16.1.2 　根据需要优化特征提取过程　　269
16.1.3 　根据需要优化向量编码　　269
16.1.4 　部署可扩展的分类器服务　　270
16.2 　确定规模和速度需求　　270
16.2.1 　多大才算大　　270
16.2.2 　在规模和速度之间折中　　272
16.3 　对大型系统构建训练流水线　　273
16.3.1 　获取并保留大规模数据　　274
16.3.2 　非规范化及下采样　　275
16.3.3 　训练中的陷阱　　276
16.3.4 　快速读取数据并对其进行编码　　278
16.4 　集成Mahout分类器　　282
16.4.1 　提前计划：集成中的关键问题　　283
16.4.2 　模型序列化　　287
16.5 　案例：一个基于Thrift的分类服务器　　288
16.5.1 　运行分类服务器　　292
16.5.2 　访问分类器服务　　294
16.6 　小结　　296
第17章　案例分析——Shop It To Me　　297
17.1 　Shop It To Me选择Mahout的原因　　297
17.1.1 　Shop It To Me公司简介　　298
17.1.2 　Shop It To Me需要分类系统的原因　　298
17.1.3 　对Mahout向外扩展　　298
17.2 　邮件交易系统的一般结构　　299
17.3 　训练模型　　301
17.3.1 　定义分类项目的目标　　301
17.3.2 　按时间划分　　303
17.3.3 　避免目标泄漏　　303
17.3.4 　调整学习算法　　303
17.3.5 　特征向量编码　　304
17.4 　加速分类过程　　306
17.4.1 　特征向量的线性组合　　307
17.4.2 　模型得分的线性扩展　　308
17.5 　小结　　310
附录A 　JVM调优　　311
附录B 　Mahout数学基础　　313
附录C 　相关资源　　318
索引　　320
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Mahout实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式分析的核方法
第一部分　基本概念
第1章　模式分析
1.1　数据中的模式
1.2　模式分析算法
1.3　利用模式
1.4　小结
1.5　进一步阅读和高级主题
第2章　核方法概要
2.1　概述
2.2　特征空间中的线性回归
2.3　其他例子
2.4　核方法的模块性
2.5　本书的路线图
2.6　小结
2.7　进一步阅读高级主题
第3章　核的性质
3.1　内积和半正定矩阵
3.2　核的描述
3.3　核矩阵
3.4　核的构造
3.5　小结
3.6　进一步阅读和高级主题
第4章　检测稳定的模式
4.1　集中度不等式
4.2　容量和正则化：Rademacher理论
4.3　基于核的类的模式稳定性
4.4　一种实用的方法
4.5　小结
4.6　进一步阅读和高级主题
第二部分　模式分析算法
第5章　特征空间中的基本算法
5.1　均值和距离
5.2　计算投影：Gram-Schmidt法、QR法和Cholesky法
5.3　衡量数据的分散度
5.4　Fisher判别式分析I
5.5　小结
5.6　进一步阅读和高级主题
第6章　利用特征分解法做模式分析
6.1　奇异值分解
6.2　主成分分析
6.3　最大协方差的方向
6.4　广义特征向量问题
6.5　典型相关分析
6.6　Fisher判别式分析II
6.7　用于线性回归的方法
6.8　小结
6.9　进一步阅读和高级主题
第7章　利用凸优化法做模式分析
7.1　最小封闭超球体
7.2　用于分类的支持向量机
7.3　用于回归的支持向量机
7.4　在线分类和回归
7.5　小结
7.6　进一步阅读和高级主题
第8章　排列、聚类和数据可视化
第三部分　构造核
第9章　基本的核和核的类型
第10章　文本核
第11章　用于结构化数据的核
第12章　来自生成模型的核
附录A　正文中省略的证明
附录B　数学符号约定
索引
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式分析的核方法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>干净的数据：数据清洗入门与实践
第1章 　为什么需要清洗数据　　1
1.1 　新视角　　1
1.2 　数据科学过程　　2
1.3 　传达数据清洗工作的内容　　3
1.4 　数据清洗环境　　4
1.5 　入门示例　　5
1.6 　小结　　9
第2章 　基础知识——格式、 类型与编码　　11
2.1 　文件格式　　11
2.1.1 　文本文件与二进制文件　　11
2.1.2 　常见的文本文件格式　　14
2.1.3 　分隔格式　　14
2.2 　归档与压缩　　20
2.2.1 　归档文件　　20
2.2.2 　压缩文件　　21
2.3 　数据类型、空值与编码　　24
2.3.1 　数据类型　　25
2.3.2 　数据类型间的相互转换　　29
2.3.3 　转换策略　　30
2.3.4 　隐藏在数据森林中的空值　　37
2.3.5 　字符编码　　41
2.4 　小结　　46
第3章 　数据清洗的老黄牛——电子表格和文本编辑器　　47
3.1 　电子表格中的数据清洗　　47
3.1.1 　Excel的文本分列功能　　47
3.1.2 　字符串拆分　　51
3.1.3 　字符串拼接　　51
3.2 　文本编辑器里的数据清洗　　54
3.2.1 　文本调整　　55
3.2.2 　列选模式　　56
3.2.3 　加强版的查找与替换功能　　56
3.2.4 　文本排序与去重处理　　58
3.2.5 　Process Lines Containing　　60
3.3 　示例项目　　60
3.3.1 　第一步：问题陈述　　60
3.3.2 　第二步：数据收集　　60
3.3.3 　第三步：数据清洗　　61
3.3.4 　第四步：数据分析　　63
3.4 　小结　　63
第4章 　讲通用语言——数据转换　　64
4.1 　基于工具的快速转换　　64
4.1.1 　从电子表格到CSV　　65
4.1.2 　从电子表格到JSON　　65
4.1.3 　使用phpMyAdmin从SQL
语句中生成CSV或JSON　　67
4.2 　使用PHP实现数据转换　　69
4.2.1 　使用PHP实现SQL到JSON的数据转换　　69
4.2.2 　使用PHP实现SQL到CSV的数据转换　　70
4.2.3 　使用PHP实现JSON到CSV的数据转换　　71
4.2.4 　使用PHP实现CSV到JSON的数据转换　　71
4.3 　使用Python实现数据转换　　72
4.3.1 　使用Python实现CSV到JSON的数据转换　　72
4.3.2 　使用csvkit实现CSV到JSON的数据转换　　73
4.3.3 　使用Python实现JSON到CSV的数据转换　　74
4.4 　示例项目　　74
4.4.1 　第一步：下载GDF格式的Facebook数据　　75
4.4.2 　第二步：在文本编辑器中查看GDF文件　　75
4.4.3 　第三步：从GDF格式到JSON格式的转换　　76
4.4.4 　第四步：构建D3图　　79
4.4.5 　第五步：把数据转换成Pajek格式　　81
4.4.6 　第六步：简单的社交网络分析　　83
4.5 　小结　　84
第5章 　收集并清洗来自网络的数据　　85
5.1 　理解HTML页面结构　　85
5.1.1 　行分隔模型　　86
5.1.2 　树形结构模型　　86
5.2 　方法一：Python和正则表达式　　87
5.2.1 　第一步：查找并保存实验用的Web文件　　88
5.2.2 　第二步：观察文件内容并判定有价值的数据　　88
5.2.3 　第三步：编写Python程序把数据保存到CSV文件中　　89
5.2.4 　第四步：查看文件并确认清洗结果　　89
5.2.5 　使用正则表达式解析HTML的局限性　　90
5.3 　方法二：Python和BeautifulSoup　　90
5.3.1 　第一步：找到并保存实验用的文件　　90
5.3.2 　第二步：安装BeautifulSoup　　91
5.3.3 　第三步：编写抽取数据用的Python程序　　91
5.3.4 　第四步：查看文件并确认清洗结果　　92
5.4 　方法三：Chrome Scraper　　92
5.4.1 　第一步：安装Chrome扩展Scraper　　92
5.4.2 　第二步：从网站上收集数据　　92
5.4.3 　第三步：清洗数据　　94
5.5 　示例项目：从电子邮件和论坛中抽取数据　　95
5.5.1 　项目背景　　95
5.5.2 　第一部分：清洗来自Google Groups电子邮件的数据　　96
5.5.3 　第二部分：清洗来自网络论坛的数据　　99
5.6 　小结　　105
第6章 　清洗PDF文件中的数据　　106
6.1 　为什么PDF文件很难清洗　　106
6.2 　简单方案——复制　　107
6.2.1 　我们的实验文件　　107
6.2.2 　第一步：把我们需要的数据复制出来　　108
6.2.3 　第二步：把复制出来的数据粘贴到文本编辑器中　　109
6.2.4 　第三步：轻量级文件　　110
6.3 　第二种技术——pdfMiner　　111
6.3.1 　第一步：安装pdfMiner　　111
6.3.2 　第二步：从PDF文件中提取文本　　111
6.4 　第三种技术——Tabula　　113
6.4.1 　第一步：下载Tabula　　113
6.4.2 　第二步：运行Tabula　　113
6.4.3 　第三步：用Tabula提取数据　　114
6.4.4 　第四步：数据复制　　114
6.4.5 　第五步：进一步清洗　　114
6.5 　所有尝试都失败之后——第四种技术　　115
6.6 　小结　　117
第7章 　RDBMS清洗技术　　118
7.1 　准备　　118
7.2 　第一步：下载并检查Sentiment140　　119
7.3 　第二步：清洗要导入的数据　　119
7.4 　第三步：把数据导入MySQL　　120
7.4.1 　发现并清洗异常数据　　121
7.4.2 　创建自己的数据表　　122
7.5 　第四步：清洗&amp;字符　　123
7.6 　第五步：清洗其他未知字符　　124
7.7 　第六步：清洗日期　　125
7.8 　第七步：分离用户提及、标签和URL　　127
7.8.1 　创建一些新的数据表　　128
7.8.2 　提取用户提及　　128
7.8.3 　提取标签　　130
7.8.4 　提取URL　　131
7.9 　第八步：清洗查询表　　132
7.10 　第九步：记录操作步骤　　134
7.11 　小结　　135
第8章 　数据分享的最佳实践　　136
8.1 　准备干净的数据包　　136
8.2 　为数据编写文档　　139
8.2.1 　README文件　　139
8.2.2 　文件头　　141
8.2.3 　数据模型和图表　　142
8.2.4 　维基或CMS　　144
8.3 　为数据设置使用条款与许可协议　　144
8.4 　数据发布　　146
8.4.1 　数据集清单列表　　146
8.4.2 　Stack Exchange上的Open Data　　147
8.4.3 　编程马拉松　　147
8.5 　小结　　148
第9章 　Stack Overflow项目　　149
9.1 　第一步：关于Stack Overflow的问题　　149
9.2 　第二步：收集并存储Stack Overflow数据　　151
9.2.1 　下载Stack Overflow数据　　151
9.2.2 　文件解压　　152
9.2.3 　创建MySQL数据表并加载数据　　152
9.2.4 　构建测试表　　154
9.3 　第三步：数据清洗　　156
9.3.1 　创建新的数据表　　157
9.3.2 　提取URL并填写新数据表　　158
9.3.3 　提取代码并填写新表　　159
9.4 　第四步：数据分析　　161
9.4.1 　哪些代码分享网站最为流行　　161
9.4.2 　问题和答案中的代码分享网站都有哪些　　162
9.4.3 　提交内容会同时包含代码分享URL和程序源代码吗　　165
9.5 　第五步：数据可视化　　166
9.6 　第六步：问题解析　　169
9.7 　从测试表转向完整数据表　　169
9.8 　小结　　170
第10章 　Twitter项目　　171
10.1 　第一步：关于推文归档数据的问题　　171
10.2 　第二步：收集数据　　172
10.2.1 　下载并提取弗格森事件的
数据文件　　173
10.2.2 　创建一个测试用的文件　　174
10.2.3 　处理推文ID　　174
10.3 　第三步：数据清洗　　179
10.3.1 　创建数据表　　179
10.3.2 　用Python为新表填充数据　　180
10.4 　第四步：简单的数据分析　　182
10.5 　第五步：数据可视化　　183
10.6 　第六步：问题解析　　186
10.7 　把处理过程应用到全数据量（非测试用）数据表　　186
10.8 　小结　　187

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>干净的数据：数据清洗入门与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
第1章 概论
1.1 模式与模式识别
1.2 模式识别的主要方法
1.3 监督模式识别与非监督模式识别
1.4 模式识别系统举例
1.5 模式识别系统的典型构成
1.6 本书的主要内容
第2章 统计决策方法
2.1 引言： 一个简单的例子
2.2 最小错误率贝叶斯决策
2.3 最小风险贝叶斯决策
2.4 两类错误率、NeymanPearson决策与ROC曲线
2.5 正态分布时的统计决策
2.5.1 正态分布及其性质回顾
2.5.2 正态分布概率模型下的最小错误率贝叶斯决策
2.6 错误率的计算
2.6.1 正态分布且各类协方差矩阵相等情况下错误率的计算
2.6.2 高维独立随机变量时错误率的估计
2.7 离散概率模型下的统计决策举例
2.8 小结与讨论
第3章 概率密度函数的估计
3.1 引言
3.2 最大似然估计
3.2.1 最大似然估计的基本原理
3.2.2 最大似然估计的求解
3.2.3 正态分布下的最大似然估计
3.3 贝叶斯估计与贝叶斯学习
3.3.1 贝叶斯估计
3.3.2 贝叶斯学习
3.3.3 正态分布时的贝叶斯估计
3.3.4 其他分布的情况
3.4 概率密度估计的非参数方法
3.4.1 非参数估计的基本原理与直方图方法
3.4.2 kN近邻估计方法
3.4.3 Parzen窗法
3.5 讨论
第4章 线性分类器
4.1 引言
4.2 线性判别函数的基本概念
4.3 Fisher线性判别分析
4.4 感知器
4.5 最小平方误差判别
4.6 最优分类超平面与线性支持向量机
4.6.1 最优分类超平面
4.6.2 大间隔与推广能力
4.6.3 线性不可分情况
4.7 多类线性分类器
4.7.1 多个两类分类器的组合
4.7.2 多类线性判别函数
4.8 小结与讨论
第5章 非线性分类器
5.1 引言
5.2 分段线性判别函数
5.2.1 分段线性距离分类器
5.2.2 一般的分段线性判别函数
5.3 二次判别函数
5.4 多层感知器神经网络
5.4.1 神经元与感知器
5.4.2 用多个感知器实现非线性分类
5.4.3 采用反向传播算法的多层感知器
5.4.4 多层感知器网络用于模式识别
5.4.5 神经网络结构的选择
5.4.6 前馈神经网络与传统模式识别方法的关系
5.4.7 人工神经网络的一般知识
5.5 支持向量机
5.5.1 广义线性判别函数
5.5.2 核函数变换与支持向量机
5.5.3 支持向量机应用举例
5.5.4 支持向量机的实现算法
5.5.5 多类支持向量机
5.5.6 用于函数拟合的支持向量机
5.6 核函数机器
5.6.1 大间隔机器与核函数机器
5.6.2 核Fisher判别
5.7 小结与讨论
第6章 其他分类方法
6.1 近邻法
6.1.1 最近邻法
6.1.2 k近邻法
6.1.3 近邻法的快速算法
6.1.4 剪辑近邻法
6.1.5 压缩近邻法
6.2 决策树与随机森林
6.2.1 非数值特征
6.2.2 决策树
6.2.3 过学习与决策树的剪枝
6.2.4 随机森林
6.3 罗杰斯特回归
6.4 Boosting方法
6.5 讨论
第7章 特征选择
7.1 引言
7.2 特征的评价准则
7.2.1 基于类内类间距离的可分性判据
7.2.2 基于概率分布的可分性判据
7.2.3 基于熵的可分性判据
7.2.4 利用统计检验作为可分性判据
7.3 特征选择的最优算法
7.4 特征选择的次优算法
7.5 特征选择的遗传算法
7.6 以分类性能为准则的特征选择方法
7.7 讨论
第8章 特征提取
8.1 引言
8.2 基于类别可分性判据的特征提取
8.3 主成分分析方法
8.4 KarhunenLoève变换
8.4.1 KL变换的基本原理
8.4.2 用于监督模式识别的KL变换
8.5 KL变换在人脸识别中的应用举例
8.6 高维数据的低维显示
8.7 多维尺度法
8.7.1 MDS的基本概念
8.7.2 古典尺度法
8.7.3 度量型MDS
8.7.4 非度量型MDS
8.7.5 MDS在模式识别中的应用
8.8 非线性变换方法简介
8.8.1 核主成分分析（KPCA）
8.8.2 IsoMap方法和LLE方法
8.9 讨论
第9章 非监督模式识别
9.1 引言
9.2 基于模型的方法
9.3  混合模型的估计
9.3.1 非监督最大似然估计
9.3.2 正态分布情况下的非监督参数估计
9.4 动态聚类算法
9.4.1 C均值算法
9.4.2 ISODATA方法
9.4.3 基于样本与核的相似性度量的动态聚类算法
9.5 模糊聚类方法
9.5.1 模糊集的基本知识
9.5.2 模糊C均值算法
9.5.3 改进的模糊C均值算法
9.6 分级聚类方法
9.7 自组织映射神经网络
9.7.1 SOM网络结构
9.7.2 SOM学习算法和自组织特性
9.7.3 SOM用于模式识别
9.8 讨论
第10章 模式识别系统的评价
10.1 监督模式识别方法的错误率估计
10.1.1 训练错误率
10.1.2 测试错误率
10.1.3 交叉验证
10.1.4 自举法与632估计
10.2 有限样本下错误率的区间估计问题
10.2.1 问题的提出
10.2.2 用扰动重采样估计SVM错误率的置信区间
10.3 特征提取与选择对分类器性能估计的影响
10.4 从分类的显著性推断特征与类别的关系
10.5 非监督模式识别系统性能的评价
10.6 讨论
索引
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
第1章 绪论
第2章 贝叶斯决策理论
第3章 概率密度函数的估计
第4章 线性判别函数
第5章 非线性判别函数
第6章 近邻法
第7章 经验风险最小化和有序风险最小方法
第8章 特征的选择与提取
第9章 基于K-L展开式的特征提取
第10章 非监督学习方法
第11章 人工神经网络
第12章 模糊模式识别方法
第13章 统计学习理论和支持向量机
第14章 模式识别在语音信号数字处理中的应用举例
第15章 印刷体汉字识别中的特征提取
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB智能算法30个案例分析
第1章  谢菲尔德大学的MATLAB遗传算法工具箱第2章  基于遗传算法和非线性规期的函数寻优算法第4章  基于遗传算法的TSP算法第5章  基于遗传算法的LQR控制器优化设计第7章  多种群遗传算法的函数优化算法第8章  基于量子遗传算法的函数寻优算法第9章  基于遗传算法的多目标优化算法第10章  基于粒子群算法的多目标搜索算法第11章  基于多层编码遗传算法的车间调度算法第12章  免疫优化算法在物流配送中心选址中的应用第13章  粒子群算法的寻优算法第14章  基于粒子群算法的PID控制器优化设计第15章  基于混合粒子群算法的TSP搜索算法”第16章  基于动态粒子群算法的动态环境寻优算法第17章  基于PSO工具箱的函数寻优算法第18章  基于鱼群算法的函数寻优算法第19章  基于模拟退火算法的TSP算法第20章  基于遗传模拟退火算法的聚类算法第21章  模拟退火算法工具箱及应用第22章  蚁群算法的优化计算——旅行商问题(TSP)优化第23章  基于蚁群算法的二维路径规划算法第24章  基于蚁群算法的三维路径规划算法第25章  有导师学习神经网络的回归拟合——基于近红外光谱的汽油辛烷值预测第26章  有导师学习神经网络的分类——鸢尾花种类识别第27章  无导师学习神经网络的分类——矿井突水水源判别第28章  支持向量机的分类——基于乳腺组织电阻抗特性的乳腺癌诊断第29章  支持向量机的回归拟合——混凝土抗压强度预测第30章  极限学习机的回归拟合及分类——对比实验研究参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>MATLAB智能算法30个案例分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络与深度学习
第0章　写在前面：神经网络的历史 1
第1章　神经网络是个什么东西 13
1.1　买橙子和机器学习 13
1.1.1　规则列表 14
1.1.2　机器学习 15
1.2　怎么定义神经网络 16
1.3　先来看看大脑如何学习 16
1.3.1　信息输入 17
1.3.2　模式加工 17
1.3.3　动作输出 18
1.4　生物意义上的神经元 19
1.4.1　神经元是如何工作的 19
1.4.2　组成神经网络 22
1.5　大脑如何解决现实生活中的分类问题 24
第2章　构造神经网络 26
2.1　构造一个神经元 26
2.2　感知机 30
2.3　感知机的学习 32
2.4　用代码实现一个感知机 34
2.4.1　Neuroph：一个基于Java的神经网络框架 34
2.4.2　代码实现感知机 37
2.4.3　感知机学习一个简单逻辑运算 39
2.4.4　XOR问题 42
2.5　构造一个神经网络 44
2.5.1　线性不可分 45
2.5.2　解决XOR问题（解决线性不可分） 49
2.5.3　XOR问题的代码实现 51
2.6　解决一些实际问题 54
2.6.1　识别动物 54
2.6.2　我是预测大师 59
第3章　深度学习是个什么东西 66
3.1　机器学习 67
3.2　特征 75
3.2.1　特征粒度 75
3.2.2　提取浅层特征 76
3.2.3　结构性特征 78
3.3　浅层学习和深度学习 81
3.4　深度学习和神经网络 83
3.5　如何训练神经网络 84
3.5.1　BP算法：神经网络训练 84
3.5.2　BP算法的问题 85
3.6　总结深度学习及训练过程 86
第4章　深度学习的常用方法 89
4.1　模拟大脑的学习和重构 90
4.1.1　灰度图像 91
4.1.2　流行感冒 92
4.1.3　看看如何编解码 93
4.1.4　如何训练 95
4.1.5　有监督微调 97
4.2　快速感知：稀疏编码（Sparse Coding） 98
4.3　栈式自编码器 100
4.4　解决概率分布问题：限制波尔兹曼机 102
4.4.1　生成模型和概率模型 102
4.4.2　能量模型 107
4.4.3　RBM的基本概念 109
4.4.4　再看流行感冒的例子 111
4.5　DBN 112
4.6　卷积神经网络 114
4.6.1　卷积神经网络的结构 116
4.6.2　关于参数减少与权值共享 120
4.6.3 举个典型的例子：图片内容识别 124
4.7　不会忘记你：循环神经网络 131
4.7.1　什么是RNN 131
4.7.2　LSTM网络 136
4.7.3　LSTM变体 141
4.7.4　结论 143
4.8　你是我的眼：利用稀疏编码器找图像的基本单位 143
4.9　你是我的眼（续） 150
4.10　使用深度信念网搞定花分类 160
第5章　深度学习的胜利：AlphaGo 169
5.1　AI如何玩棋类游戏 169
5.2　围棋的复杂性 171
5.3　AlphaGo的主要原理 173
5.3.1　策略网络 174
5.3.2　MCTS拯救了围棋算法 176
5.3.3　强化学习："周伯通，左右互搏" 179
5.3.4　估值网络 181
5.3.5　将所有组合到一起：树搜索 182
5.3.6　AlphaGo有多好 185
5.3.7　总结 187
5.4　重要的技术进步 189
5.5　一些可以改进的地方 190
5.6　未来 192
第6章　两个重要的概念 194
6.1　迁移学习 194
6.2　概率图模型 197
6.2.1　贝叶斯的网络结构 201
6.2.2　概率图分类 204
6.2.3　如何应用PGM 208
第7章　杂项 210
7.1　如何为不同类型的问题选择模型 210
7.2　我们如何学习"深度学习" 211
7.3　如何理解机器学习和深度学习的差异 212
7.4　大规模学习（Large Scale Learning）和并行计算 214
7.5　如果喜欢应用领域，可以考虑以下几种应用 215
7.6　类脑：人工智能的终极目标 216
参考文献 218
术语 220
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络与深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>信息检索
出版者的话
译者序
序
前言
符号
第一部分基 础 知 识
第1章绪论
1.1什么是信息检索
1.1.1Web搜索
1.1.2其他搜索应用
1.1.3其他信息检索应用
1.2信息检索系统
1.2.1信息检索系统基础架构
1.2.2文档及其更新
1.2.3性能评价
1.3使用电子文本
1.3.1文本格式
1.3.2英文文本中的分词
1.3.3词项分布
1.3.4语言模型
1.4测试集
1.5开源信息检索系统
1.5.1Lucene
1.5.2Indri
1.5.3Wumpus
1.6延伸阅读
1.7练习
1.8参考文献
第2章基础技术
2.1倒排索引
2.1.1延伸例子：词组查找
2.1.2实现倒排索引
2.1.3文档和其他元素
2.2检索与排名
2.2.1向量空间模型
2.2.2邻近度排名
2.2.3布尔检索
2.3评价
2.3.1查全率和查准率
2.3.2排名检索的有效性指标
2.3.3创建测试集
2.3.4效率指标
2.4总结
2.5延伸阅读
2.6练习
2.7参考文献
第3章词条与词项
3.1英语
3.1.1标点与大写
3.1.2词干提取
3.1.3停词
3.2字符
3.3字符ngram
3.4欧洲语言
3.5CJK语言
3.6延伸阅读
3.7练习
3.8参考文献
第二部分索引
第4章静态倒排索引
4.1索引的组成部分和索引的生命周期
4.2词典
4.3位置信息列表
4.4交错词典和位置信息列表
4.5索引的构建
4.5.1基于内存的索引构建法
4.5.2基于排序的索引构建法
4.5.3基于合并的索引构建法
4.6其他索引
4.7总结
4.8延伸阅读
4.9练习
4.10参考文献
第5章查询处理
5.1排名检索的查询处理
5.1.1documentatatime查询处理
5.1.2termatatime查询处理
5.1.3预计算得分贡献
5.1.4影响力排序
5.1.5静态索引裁剪
5.2轻量级结构
5.2.1广义索引表
5.2.2操作符
5.2.3例子
5.2.4实现
5.3延伸阅读
5.4练习
5.5参考文献
第6章索引压缩
6.1通用数据压缩
6.2符号数据压缩
6.2.1建模和编码
6.2.2哈夫曼编码
6.2.3算术编码
6.2.4基于符号的文本压缩
6.3压缩位置信息列表
6.3.1无参数间距压缩
6.3.2参数间距压缩
6.3.3上下文感知的压缩方法
6.3.4高查询性能的索引压缩
6.3.5压缩效果
6.3.6解码性能
6.3.7文档重排
6.4压缩词典
6.5总结
6.6延伸阅读
6.7练习
6.8参考文献
第7章动态倒排索引
7.1批量更新
7.2增量式索引更新
7.2.1连续倒排列表
7.2.2非连续倒排列表
7.3文档删除
7.3.1无效列表
7.3.2垃圾回收
7.4文档修改
7.5讨论及延伸阅读
7.6练习
7.7参考文献
第三部分检索和排名
第8章概率检索
8.1相关性建模
8.2二元独立模型
8.3Robertson/Sprck Jones权重公式
8.4词频
8.4.1Bookstein的双泊松模型
8.4.2双泊松模型的近似
8.4.3查询词频
8.5文档长度：BM25
8.6相关反馈
8.6.1词项选择
8.6.2伪相关反馈
8.7区域权重：BM25F
8.8实验对比
8.9延伸阅读
8.10练习
8.11参考文献
第9章语言模型及其相关方法
9.1从文档中产生查询
9.2语言模型和平滑
9.3使用语言模型排名
9.4KullbackLeibler距离
9.5随机差异性
9.5.1一个随机模型
9.5.2精华性
9.5.3文档长度规范化
9.6段落检索及排名
9.6.1段落评分
9.6.2实现
9.7实验对比
9.8延伸阅读
9.9练习
9.10参考文献
第10章分类和过滤
10.1详细示例
10.1.1面向主题的批过滤
10.1.2在线过滤
10.1.3从历史样本中学习
10.1.4语言分类
10.1.5在线自适应垃圾邮件过滤系统
10.1.6二元分类的阈值选择
10.2分类
10.2.1比值和比值比
10.2.2构造分类器
10.2.3学习模型
10.2.4特征工程
10.3概率分类器
10.3.1概率估计
10.3.2联合概率估计
10.3.3实际考虑
10.4线性分类器
10.4.1感知器算法
10.4.2支持向量机
10.5基于相似度的分类器
10.5.1Rocchio法
10.5.2基于记忆的方法
10.6广义线性模型
10.7信息理论模型
10.7.1模型比较
10.7.2序列压缩模型
10.7.3决策树与树桩
10.8实验对比
10.8.1面向主题的在线过滤器
10.8.2在线自适应垃圾信息过滤
10.9延伸阅读
10.10练习
10.11参考文献
第11章融合和元学习
11.1搜索结果融合
11.1.1固定临界值合成
11.1.2排名和得分合成
11.2叠加自适应过滤器
11.3叠加批分类器
11.3.1holdout验证
11.3.2交叉验证
11.4bagging
11.5boosting
11.6多类排名和分类
11.6.1文档得分与类别得分
11.6.2文档排名融合与类别排名融合
11.6.3多类方法
11.7学习排名
11.7.1什么是学习排名
11.7.2学习排名的方法
11.7.3优化什么
11.7.4分类的学习排名
11.7.5排名检索的学习
11.7.6LETOR数据集
11.8延伸阅读
11.9练习
11.10参考文献
第四部分评价
第12章度量有效性
12.1传统的有效性指标
12.1.1查全率和查准率
12.1.2前k个文档的查准率（P@k）
12.1.3平均查准率
12.1.4排名倒数
12.1.5算术平均与几何平均
12.1.6用户满意度
12.2TREC
12.3在评价中使用统计
12.3.1基础和术语
12.3.2置信区间
12.3.3比较评价
12.3.4被认为有害的假设检验
12.3.5配对和未配对差值
12.3.6显著性检验
12.3.7统计检验的效度和检验力
12.3.8报告指标的查准率
12.3.9元分析
12.4最小化判定工作
12.4.1为判定选择合适的文档
12.4.2对池进行抽样
12.5非传统的有效性指标
12.5.1分级相关性
12.5.2不完整判定和偏差判定
12.5.3新颖性和多样性
12.6延伸阅读
12.7练习
12.8参考文献
第13章度量效率
13.1效率标准
13.1.1吞吐量和延迟
13.1.2汇总统计和用户满意度
13.2排队论
13.2.1肯德尔符号
13.2.2M/M/1排队模型
13.2.3延迟量和平均利用率
13.3查询调度
13.4缓存
13.4.1三级缓存
13.4.2缓存策略
13.4.3预取搜索结果
13.5延伸阅读
13.6练习
13.7参考文献
第五部分应用和扩展
第14章并行信息检索
14.1并行查询处理
14.1.1文档划分
14.1.2词项划分
14.1.3混合方案
14.1.4冗余和容错
14.2MapReduce
14.2.1基本框架
14.2.2合并
14.2.3辅助关键字
14.2.4机器失效
14.3延伸阅读
14.4练习
14.5参考文献
第15章Web搜索
15.1Web的结构
15.1.1Web图
15.1.2静态与动态网页
15.1.3暗网
15.1.4Web的规模
15.2查询与用户
15.2.1用户意图
15.2.2点击曲线
15.3静态排名
15.3.1基本PageRank
15.3.2扩展的PageRank
15.3.3PageRank的性质
15.3.4其他链接分析方法：HITS和SALSA
15.3.5其他静态排名方法
15.4动态排名
15.4.1锚文本
15.4.2新颖性
15.5评价Web搜索
15.5.1指定页面发现
15.5.2用户隐式反馈
15.6Web爬虫
15.6.1爬虫的组成
15.6.2抓取顺序
15.6.3重复与近似重复
15.7总结
15.8延伸阅读
15.8.1链接分析
15.8.2锚文本
15.8.3隐式反馈
15.8.4Web爬虫
15.9练习
15.10参考文献
第16章XML检索
16.1XML的本质
16.1.1文档类型定义
16.1.2XML模式
16.2路径、树和FLWOR
16.2.1XPath
16.2.2NEXI
16.2.3XQuery
16.3索引和查询处理
16.4排名检索
16.4.1排名元素
16.4.2重叠元素
16.4.3可检索元素
16.5评价
16.5.1测试集
16.5.2有效性指标
16.6延伸阅读
16.7练习
16.8参考文献
第六部分附录
附录A计算机性能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>信息检索
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kinect应用开发实战
推荐序一
推荐序二
前　　言
第一部分　准备篇
引　言　从科幻电影谈起/2
第1章　自然人机交互技术漫谈/10
1.1　自然人机交互技术的发展/10
1.1.1　第六感设备：技术的组合创新/10
1.1.2　追影技术：摄像头也疯狂/12
1.1.3　虚拟现实：真实的体验场景/13
1.1.4　增强现实：真实与虚拟的叠加/14
1.1.5　多点触摸：信息就在指尖 /15
1.1.6　语音识别：从ViaVoice到Siri/16
1.1.7　眼球跟踪：从霍金的座椅谈起/17
1.1.8　人脸识别：Photo DNA/19
1.1.9　体感操作：达芬奇手术机器人/20
1.1.10　脑机界面：霍金座椅的升级版/20
1.2　“你就是控制器”—Kinect宣言/21
1.2.1　Kinect销售记录及命名来历/21
1.2.2　未来照进现实/22
第二部分　原理篇
第2章　揭开Kinect的神秘面纱—硬件设备解剖/26
2.1　两款Kinect传感器对比/26
2.2　Kinect传感器的硬件组成/28
2.2.1　Kinect的“心脏”—PS1080 SoC/30
2.2.2　Kinect的“三只眼”—投影机和两个摄像头/32
2.2.3　Kinect的“四只耳朵”—麦克风阵列/34
2.2.4　会摇摆的“相控雷达”—传动马达/35
2.2.5　姿态控制—三轴加速度计/36
2.2.6　USB接口及电源/37
2.2.7　Kinect风扇控制/38
2.3　Kinect相关技术规格/38
2.3.1　Kinect近景模式/39
2.3.2　Kinect放大镜/40
2.4　本章小结/40
第3章　Kinect工作原理大揭秘/41
3.1　Kinect for Xbox 360的产品设计/42
3.2　基于“管道”的系统架构/43
3.2.1　骨骼跟踪/45
3.2.2　动作识别/46
3.2.3　人脸识别/48
3.2.4　语音识别/49
3.3　Kinect眼里的三维世界/50
3.3.1　深度数据是Kinect的精髓/51
3.3.2　2D视觉与3D视觉/55
3.4　深度图像成像原理/56
3.4.1　ToF光学测距与结构光测量/56
3.4.2　Light Coding技术/57
3.4.3　激光散斑原理/58
3.4.4　光源标定/59
3.5　从深度图像到骨骼图/60
3.5.1　动静分离，识别人体/60
3.5.2　人体部位分类/62
3.5.3　从人体部位识别关节/63
3.5.4　会“机器学习”的“Kinect大脑”/65
3.5.5　骨骼跟踪的精度和效率/68
3.6　创建你的Avatar/70
3.6.1　“有骨有肉”/70
3.6.2　泊松方程噪声滤除/70
3.6.3　粗糙变平滑、缺陷自动补齐/71
3.7　本章小结/71
第三部分　基础篇
第4章　Kinect for Windows SDK导读/74
4.1　什么是Kinect SDK/74
4.1.1　Kinect SDK的发展历程/74
4.1.2　SDK v1.5的新特性/75
4.1.3　SDK v1.5尚未提供的API/76
4.1.4　从底层进行封装/76
4.2　Kinect for Windows体系架构/78
4.3　应用层API详解/80
4.3.1　Kinect的核心NUI API/80
4.3.2　Kinect Audio DMO/82
4.3.3　Windows Speech SDK/83
4.4　数据流概述/84
4.4.1　彩色图像数据/84
4.4.2　用户分割数据/85
4.4.3　深度图像数据/86
4.4.4　如何获取数据流/87
4.5　骨骼跟踪/89
4.5.1　骨骼信息检索/90
4.5.2　主动跟踪和被动跟踪/90
4.5.3　骨骼跟踪对象选择/91
4.6　NUI坐标转换/92
4.6.1　深度图像空间坐标/93
4.6.2　骨骼空间坐标/93
4.6.3　坐标变换/93
4.6.4　传感器阵列和倾斜补偿/95
4.6.5　地面测量/95
4.6.6　骨骼镜像/95
4.7　本章小结/96
第5章　Kinect用户交互设计的若干思考/97
5.1　Xbox 360 Kinect Hub界面和Metro风格/97
5.1.1　什么是Metro风格/97
5.1.2　Kinect Hub手势原型设计/98
5.1.3　“悬停选择”和“翻页控制”/99
5.2　体感游戏的优势及局限性/100
5.2.1　更多的自由度/101
5.2.2　关节点重叠的处理办法/102
5.2.3　情感因素和心理暗示/102
5.2.4　Kinect体感操作的局限性及对策/103
5.3　用户交互的趋势和新特性/104
5.3.1　Kinect使交互“柔软化”/105
5.3.2　用户交互设计也可能是一项专利/106
5.4　Kinect“体感操作”交互设计的七条军规/106
5.4.1　控制手势集符合人类自然手势/107
5.4.2　让用户的肢体移动幅度尽可能小/107
5.4.3　操作界面的对象采用Metro风格/109
5.4.4　“确认操作”保持简单、一致/109
5.4.5　手势操作尽可能在同一个平面内/110
5.4.6　从三维的视角去看交互设计/110
5.4.7　配有简单明了的手势说明/111
5.5　本章小结/112
第四部分　开发篇
第6章　开发前的准备工作/114
6.1　开发Kinect应用所需的技能/114
6.2　系统要求/115
6.3　下载和安装Kinect SDK/116
6.3.1　Kinect for Windows SDK v1.5/118
6.3.2　Developer Toolkit/118
6.3.3　Kinect快速开发工具箱/119
6.3.4　XNA开发环境/119
6.4　加载驱动、检验及测试/120
6.5　配置开发环境/122
6.6　要点和故障排除/122
6.7　本章小结/123
第7章　Hello，Kinect！/124
7.1　一行代码的“Hello, Kinect!”/124
7.1.1　创建WPF工程/124
7.1.2　添加KinectDiagnosticViewer控件/126
7.1.3　编写一行代码/127
7.1.4　编译运行/127
7.2　控制台界面HelloKinectMatrix/128
7.2.1　创建Console工程/128
7.2.2　编写代码/129
7.2.3　运行效果/130
7.3　KinectContrib快速工程模板/130
7.4　KinectWpfViewers工具控件/131
7.5　本章小结/132
第8章　Kinect开发循序渐进/133
8.1　一个简单的编程模型/133
8.1.1　初始化、启用Kinect设备/134
8.1.2　彩色图像流事件处理/136
8.1.3　深度数据捕获/138
8.1.4　骨骼跟踪/141
8.1.5　关闭Kinect设备/145
8.1.6　Kinect设备状态管理及异常处理/145
8.2　更专业的深度图/146
8.2.1　改进转换方法/146
8.2.2　事件处理/148
8.3　控制Kinect仰角/148
8.3.1　“你的塑身”游戏/149
8.3.2　垂直调整Kinect仰角/150
8.4　本章小结/151
第9章　Kinect深度数据测量技术及应用/152
9.1　什么是Kinect视角场/152
9.2　深度值与实际距离的对比/153
9.3　深度图像的直方图/155
9.3.1　直方图统计信息的价值/156
9.3.2　深度图像直方图的意义/158
9.4　Kinect深度数据测量的应用/159
9.4.1　近景模式：自动锁屏工具/159
9.4.2　Kinect视角场几何推导：测量人体身高/163
9.4.3　近距离探测：制作地形电子沙盘/169
9.5　本章小结/170
第五部分　实例篇
第10章　用Kinect表演“变脸”/172
10.1　在人的面部变换脸谱/172
10.2　代码实现/173
10.2.1　WPF工程、控件及初始化/173
10.2.2　骨骼跟踪/176
10.2.3　变脸及坐标变换/178
10.3　合理暂停骨骼跟踪/181
10.4　道具平滑跟随/181
10.5　调整幕布大小/183
10.6　练习作业/184
第11章　用Kinect唤起“红白机”的回忆/185
11.1　用身体控制马里奥/185
11.2　代码实现/185
11.2.1　WPF工程、控件及初始化/185
11.2.2　模拟键盘输入工具类/188
11.2.3　肢体语言映射到键盘事件/192
11.3　副产品：PPT演示“空手道”/193
11.4　练习作业/195
第12章　用Kinect玩PC版的《水果忍者》/197
12.1　空气鼠标设计思路/197
12.1.1　找到离Kinect最近的那个人/198
12.1.2　兼容左手习惯和右手习惯/199
12.1.3　从骨骼坐标系到鼠标坐标系/199
12.1.4　模拟鼠标工具类/200
12.1.5　让“空气鼠标”移动自如/202
12.1.6　模拟鼠标左键事件/203
12.2　在PC中用Kinect玩《水果忍者》/203
12.2.1　核心代码示例/203
12.2.2　如何双手挥刀/206
12.3　更多游戏：《割绳子》/206
12.4　练习作业/207
第13章　创建你的Kinect Hub Demo界面/208
13.1　Metro风格界面设计/208
13.2　使用Kinect骨骼跟踪/209
13.3　使用Coding4Fun Kinect Toolkit开发加速器/210
13.4　悬停选择/210
13.5　本章小结/213
第14章　用Kinect导播天气预报/214
14.1　天气预报是这样炼成的/214
14.1.1　绘制幕布，定义前景图片/214
14.1.2　对象定义及初始化/215
14.1.3　实现“画中画”效果/216
14.2　一些优化的话题/219
14.2.1　使用Using及时回收资源/219
14.2.2　使用WriteableBitmap优化图片显示性能/219
14.2.3　多线程和“轮询模型”/220
14.2.4　使用中值滤波边缘去噪/220
14.3　Kinect语音导播切换/221
14.3.1　引用Microsoft.Speech命名空间/221
14.3.2　音频数据流和语音识别引擎/221
14.3.3　语音识别事件/223
14.4　本章小结/224
第15章　基于Kinect的家庭监控系统/225
15.1　通过Kinect进行目标探测/225
15.2　使用计算机视觉库/226
15.2.1　Open CV程序库/226
15.2.2　Emgu CV引用/226
15.2.3　保存快照/227
15.2.4　录制视频/227
15.3　目标人体探测和影像录制/228
15.4　扩展功能和更多应用场景/231
15.5　本章小结/231
第16章　“Kinect牌”梦境录音笔/232
16.1　Kinect音频采集/232
16.1.1　使用音频数据流/232
16.1.2　“波束跟踪”信心值的另类用法/233
16.2　音频录制/233
16.2.1　WAV文件/233
16.2.2　WAVEFORMATEX结构体/234
16.2.3　梦境录音笔的实现/234
16.3　练习作业/240
第六部分　进阶篇
第17章　再谈姿态识别和手势识别/242
17.1　姿态和手势/242
17.2　动作与算法/243
17.2.1　如何设定动作集合/243
17.2.2　借鉴正则表达式和状态机/244
17.2.3　转换为几何三角问题/245
17.3　常见手势识别/245
17.3.1　挥手激活/245
17.3.2　悬停按钮/246
17.3.3　磁石悬停/247
17.3.4　划动手势/247
17.3.5　滑动解锁/248
17.3.6　推按钮/249
17.3.7　通用暂停/249
17.4　工具介绍/250
17.4.1　动作录制和识别GesturePak/250
17.4.2　手和手指的“空气多点触摸”/251
17.5　本章小结/253
第18章　Kinect在手术室的应用原型/254
18.1　原型设计/254
18.2　交互设计/255
18.2.1　“悬停选择”进行功能导航/255
18.2.2　“空气鼠标”的激活和隐藏/256
18.2.3　通过“划动”手势翻阅医学影像/257
18.2.4　放大、缩小医学影像病灶部位/257
18.2.5　“垂直摆动”翻阅病历/258
18.2.6　体感操作结合语音控制/258
18.3　体感操作的实现/259
18.3.1　基于SwipeGestureRecognizer/259
18.3.2　基于单个部位运动序列的轨迹分析匹配/262
18.3.3　基于多个部位姿态快照的状态机匹配/266
18.4　利用SDK v1.5的新特性/280
18.4.1　近景模式下的上半身骨骼跟踪/280
18.4.2　利用关节点朝向信息进行手势识别和三维操作/280
18.4.3　人脸识别用于手术登录验证/283
18.4.4　调试工具Kinect Studio/283
18.5　本章小结/284
第19章　Hello，Kinect 3D World! /285
19.1　点、面、云/285
19.1.1　像素和彩色图像帧/285
19.1.2　深度图像帧和点云/285
19.1.3　多Kinect设备的接入/286
19.2　Kinect体感应用开发工具简介/287
19.2.1　软件开发平台XNA/287
19.2.2　游戏引擎Unity 3D/288
19.2.3　3D场景重建工具ReconstructMe/289
19.3　本章小结/289
第七部分　展望篇
第20章　奇思妙想—Kinect效应/292
20.1　四旋翼飞行器的“导航雷达”/292
20.2　宠物看护机器人/292
20.3　空气吉他/293
20.4　倒车雷达系统/294
20.5　Kinect购物车/294
20.6　魔术道具/295
20.7　本章小结/295
第21章　Kinect企业级应用/296
21.1　思维导图/296
21.2　体感操作应用/297
21.2.1　手术室/297
21.2.2　体育运动竞技研究/297
21.2.3　动作捕捉、CG动画制作/298
21.2.4　虚拟试衣镜/298
21.2.5　课堂/299
21.2.6　虚拟汽车展厅/299
21.2.7　管理你的银行账户/300
21.2.8　聋哑人的同声翻译/300
21.3　深度数据应用/301
21.3.1　老年人监护/301
21.3.2　康复训练/301
21.3.3　家庭监控系统/302
21.3.4　道路交通稽查/302
21.3.5　冰川消融研究/303
21.3.6　给宇航员称体重/304
21.4　实物3D建模应用/304
21.4.1　实物3D数字化/304
21.4.2　文物3D模型“数字敦煌”计划/305
21.4.3　3D扫描和打印/306
21.5　机器人视觉与控制/306
21.5.1　地震搜救机器人/307
21.5.2　深海探测机器人/307
21.5.3　工程机械臂控制/307
21.6　本章小结/308
第22章　下一代人机交互技术/309
22.1　下一代Kinect技术若干猜想/309
22.2　未来惊鸿一瞥/310
第八部分　附录
附录A　Kinect SDK命名空间速查手册 /312
附录B　推荐阅读及网络资源/328
后记/338
参考资料/339
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Kinect应用开发实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据天才：数据科学家修炼之道
第1章  数据科学是什么  1
-真伪数据科学对比  2
- - 伪数据科学的两个例子  5
- - 新大学的面貌  7
-数据科学家  10
- - 数据科学家与数据工程师  10
- - 数据科学家与统计学家  12
- - 数据科学家与业务分析师  13
-13个真实世界情景中的数据科学应用  14
- - 情景1：国家对烈性酒销售的垄断结束后，DUI（酒后驾驶）逮捕量减少  15
- - 情景2：数据科学与直觉  17
- - 情景3：数据故障将数据变成乱码  19
- - 情景4：异常空间的回归  21
- - 情景5：分析与诱导在提升销量上有何不同价值  22
- - 情景6：关于隐藏数据  24
- - 情景7：汽油中的铅会导致高犯罪率。真的吗  25
- - 情景8：波音787（梦幻客机）问题  26
- - 情景9：NLP的7个棘手句子  27
- - 情景10：数据科学家决定着我们所吃的食品  28
- - 情景11：用较好的相关性增加亚马逊的销售量  30
- - 情景12：检测Facebook上的假档案或假“喜欢”数  32
- - 情景13：餐厅的分析  33
-数据科学的历史、开拓者和现代趋势  33
- - 统计学将会复兴  34
- - 历史与开拓者  36
- - 现代的趋势  38
- - 最近的问答讨论  40
-总结  44
第2章  大数据的独特性  45
-两个大数据的问题  45
- - 大数据“诅咒”  45
- - 数据快速流动问题  50
-大数据技术示例  56
- - 大数据问题是数据科学所面临挑战的缩影  56
- - 大规模数据集的聚类和分类  58
- - 1亿行的Excel  63
-MapReduce不能做什么  67
- - 问题  67
- - 3种解决方案  68
- - 结论：何时使用MapReduce  69
-沟通问题  70
-数据科学：统计学的终结  72
- - 8种最差的预测建模技术  72
- - 把计算机科学、统计学和行业专业知识结合在一起  74
-大数据生态系统  78
-总结  79
第3章  成为一名数据科学家  80
-数据科学家的主要特征  80
- - 数据科学家的职能  80
- - 横向与纵向数据科学家  83
-数据科学家的类型  86
- - 伪数据科学家  86
- - 自学成才的数据科学家  86
- - 业余数据科学家  87
- - 极限数据科学家  89
-数据科学家人群特征  90
-数据科学方面的培训  91
- - 大学课程  91
- - 公司和协会培训项目  95
- - 免费培训项目  96
-数据科学家职业道路  98
- - 独立顾问  98
- - 创业者  105
-总结  118
第4章  数据科学的技术（I）  119
-新型指标  120
- - 优化数字营销活动的指标  121
- - 欺诈检测的指标  122
-选择合适的分析工具  124
- - 分析软件  124
- - 可视化工具  125
- - 实时产品  126
- - 编程语言  128
-可视化  128
- - 用R生成数据视频  129
- - 更复杂的视频  133
-无模型的统计建模  134
- - 无模型的统计建模是什么  135
- - 该算法是如何工作的  135
- - 源代码生成数据集  137
-三类指标：中心性、波动性、颠簸性  137
- - 中心性、波动性和颠簸性之间的关系  138
- - 定义颠簸性  138
- - 在Excel中计算颠簸性  139
- - 使用颠簸系数  141
-大数据的统计聚类  141
-大数据的相关性和拟合度  143
- - 一系列新的秩相关性  146
- - 渐近分布与归一化  148
- - -计算复杂度  152
- - 计算q(n)  152
- - 理论上的解决方案  155
-结构系数  156
-确定簇的数量  157
- - 方法  157
- - 例子  158
-网络拓扑映射  159
-安全通信：数据加密  163
-总结  166
第5章  数据科学的技术（II）  167
-数据字典  168
- - 什么是数据字典  168
- - 建立数据字典  169
-隐性决策树  169
- - 实现方法  171
- - 示例：互联网流量打分  173
- - 结论  175
-与模型无关的置信区间  175
- - 方法  175
- - 分析桥第一定理  176
- - 应用  177
- - 源代码  178
-随机数  179
-解决问题的4个办法  181
- - 拥有超强直觉能力的业务分析师的直观法  182
- - 软件工程师的蒙特卡洛模拟法  182
- - 统计学家的统计建模方法  183
- - 计算机科学家的大数据方法  183
-因果关系和相关性  183
-怎样检测因果关系  184
-数据科学项目的生命周期  186
-预测模型的错误  189
-逻辑相关回归  191
- - 变量之间的相互作用  191
- - 一阶近似  191
- - 二阶近似  193
- - 用Excel进行回归分析  195
-实验设计  196
- - 有趣的指标  196
- - 把患者分成不同的人群进行治疗  196
- - 私人定制的治疗  197
-分析即服务和应用程序接口  198
- - 工作原理  199
- - 实施案例  199
- - 关键词相关的API的源代码  200
-其他主题  204
- - 当数据库改变时，保存好数值  204
- - 优化网络爬虫  205
- - 哈希连接  206
- - 用于模拟簇的简单源代码  207
-Hadoop和大数据的新型合成方差  208
- - Hadoop和MapReduce的介绍  208
- - 综合指标  209
- - Hadoop、数值的和统计的稳定性  210
- - 方差的抽象概念  211
- - 一个新的大数据定理  213
- - 平移不变性的度量标准  214
- - 实现：通信和计算成本  214
- - 最终意见  215
-总结  215
第6章  数据科学应用案例研究  217
-股票市场  217
- - 使回报率提高500%的模式  217
- - 优化统计交易策略  220
- - 股票交易的API：统计模型  222
- - 股票交易的API：具体实现  225
- - 股票市场模拟  226
- - 些许数学知识  229
- - 新趋势  231
-加密  232
- - 数据科学应用：隐写术  232
- - 好的电子邮件加密  236
- - 验证码破解  239
-欺诈检测  240
- - 点击欺诈  241
- - 连续点击评分与二进制欺诈/非欺诈  242
- - 数学模型与基准  244
- - 虚假转化产生的偏差  245
- - 一些误解  246
- - 统计面临的挑战  246
- - 点击评分优化关键词出价  247
- - 组合优化自动快速的特征选择  249
- - 特征的预测能力：交叉验证  250
- - 勾连检测和僵尸网络的关联规则检测  254
- - 模式检测的极值理论  255
-数字分析  256
- - 在线广告：到达率和频率的计算公式  256
- - 电子邮件营销：提高300%的性能  257
- - 在7天内优化关键词广告宣传活动  258
- - 自动新闻提要优化  260
- - 用bit-ly进行竞争情报分析  261
- - 测量 Twitter 哈希标签（hashtag）的收益  263
- - 用3个修补方法提升谷歌搜索  267
- - 改进相关性的算法  270
- - 广告循环问题  272
-杂项  273
- - 简单模型会获得更好的销售预测  273
- - 更好的医疗欺诈检测  275
- - 归因模型  276
- - 预测陨石撞击  277
- - 在路口停车场收集数据  281
- - 数据科学的其他应用  282
-总结  282
第7章  踏上你的数据科学职业之路  283
-面试问题  283
- - 关于工作经验的问题  283
- - 技术问题  285
- - 一般性问题  286
- - 关于数据科学项目的问题  288
-测试你自己的视觉和分析思维  291
- - 通过肉眼的检测模式  292
- - 识别偏差  294
- - 误导性的时间序列和随机游走  295
-从统计学家到数据科学家  296
- - 数据科学家也是统计从业人员  297
- - 谁应该给数据科学家教统计学  298
- - 雇佣问题  298
- - 数据科学家与数据架构师密切合作  299
- - 谁应该参与战略思考  299
- - 两种类型的统计学家  300
- - 大数据与取样  301
-数据科学家的分类  302
- - 数据科学最流行的技能集合  302
- - LinkedIn上的顶级数据科学家  306
-400个数据科学家职位头衔  309
-薪酬调查  311
- - 根据技能和位置的薪酬分类  312
- - 创建自己的薪酬调查表  316
-总结  317
第8章  数据科学资源  318
-专业资源  318
- - 数据集  318
- - 书籍  319
- - 会议与组织  322
- - 网站  324
- - 概念定义  324
-职业建设资源  327
- - 招聘数据科学家的公司  328
- - 数据科学招聘广告的样本  329
- - 简历样本  329
-总结  331
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据天才：数据科学家修炼之道
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学家养成手册
认知篇
第1章　什么是科学家	2
1.1　从太阳东升西落开始	2
1.1.1　农历	2
1.1.2　公历	5
1.1.3　小结	7
1.2　阿基米德爱洗澡？	7
1.3　托勒密的秘密	10
1.4　牛顿为什么那么牛	11
1.4.1　苹果和三大定律	11
1.4.2　极限和微积分	12
1.5　高斯——高，实在是高	15
1.6　离经叛道的爱因斯坦	17
1.7　本章小结	20
第2章　什么是科学	23
2.1　科学之科	23
2.2　边界的迷茫	23
2.3　科学之殇	26
2.4　本章小结	27
第3章　数据与数学	28
3.1　什么是数据	28
3.2　数学的奥妙	29
3.2.1　《几何原本》	29
3.2.2　《九章算术》	30
3.2.3　高等数学	34
3.3　本章小结	37
第4章　数据科学的使命	38
4.1　走近数据科学	38
4.1.1　介质	38
4.1.2　从信息到数据	41
4.1.3　数据科学的本质	43
4.2　万能的数据科学	44
4.2.1　测量	44
4.2.2　统计计算	47
4.2.3　指标	52
4.3　使命必达	53
4.3.1　高效生产	53
4.3.2　破除迷信	56
4.3.3　目标一致与不一致	57
4.4　本章小结	58
第5章　矛盾的世界	59
5.1　古希腊——学者高产的国度	59
5.2　矛盾无处不在	61
5.3　世界究竟是否可知	63
5.4　薛定谔的“喵星人”	64
5.5　本章小结	66
第6章　实验和哲学	68
6.1　朴素的认知方法	68
6.1.1　眼见为实	69
6.1.2　归纳与总结	70
6.2　哲学靠谱吗	71
6.3　数学的尽头是哲学	72
6.4　本章小结	73
第7章　辩证思维	74
7.1　要不要辩证有多大区别	74
7.2　谁对谁错	76
7.3　做到客观不容易	77
7.4　观念的存弭	79
7.5　本章小结	82
分化篇
第8章　统计学	86
8.1　数理统计鼻祖—阿道夫·凯特勒	86
8.2　统计就是统共合计	88
8.3　数据来源	90
8.4　抽样	91
8.5　对照实验	91
8.6　误差	94
8.6.1　抽样误差	94
8.6.2　非抽样误差	96
8.7　概括性度量	97
8.7.1　集中趋势度量	98
8.7.2　离散程度度量	100
8.7.3　小结	100
8.8　概率与分布	100
8.8.1　数学期望	102
8.8.2　正态分布	103
8.8.3　其他分布	106
8.9　统计学与大数据	107
第9章　信息论	109
9.1　模拟信号	109
9.2　信息量与信息熵	110
9.3　香农公式	111
9.4　数字信号	112
9.5　编码与压缩	113
9.5.1　无损压缩	114
9.5.2　有损压缩	117
9.6　本章小结	126
第10章　混沌论	127
10.1　洛伦兹在想什么	128
10.2　罗伯特·梅的养鱼计划	129
10.3　有限的大脑，无限的维	130
10.4　谋杀上帝的拉普拉斯	132
10.5　庞加莱不是省油的灯	134
10.6　未知居然还能做预测	137
10.7　本章小结	137
第11章　算法学	139
11.1　离散的世界	139
11.2　成本的度量	142
11.3　穷举法——暴力破解	143
11.4　分治法——化繁为简	152
11.5　回溯法——能省则省	154
11.6　贪心法——局部最优	155
11.7　迭代法——步步逼近	156
11.7.1　牛顿法	157
11.7.2　梯度下降法	158
11.7.3　遗传算法	159
11.8　机器学习——自动归纳	161
11.8.1　非监督学习	162
11.8.2　监督学习	164
11.8.3　强化学习	176
11.9　神经网络——深度学习	178
11.9.1　神经元	178
11.9.2　BP神经网络	180
11.9.3　损失函数	181
11.9.4　非线性分类	183
11.9.5　激励函数	187
11.9.6　卷积神经网络	189
11.9.7　循环神经网络	191
11.9.8　小结	194
11.10　本章小结	195
实践篇
第12章　数据采集	198
12.1　数据的源头	198
12.2　日志收集	199
12.2.1　实时上传	200
12.2.2　延时上传	203
12.2.3　加密问题	204
12.2.4　压缩问题	205
12.2.5　连接方式	206
12.2.6　消息格式	208
12.2.7　维度分解	210
12.3　这只是不靠谱的开始	211
12.4　本章小结	212
第13章　数据存储	213
13.1　读写不对等	213
13.1.1　读多写少	214
13.1.2　读少写多	214
13.1.3　读写都多	215
13.2　进快还是出快	216
13.2.1　最快写入	216
13.2.2　读出最快	218
13.3　文件还是数据库	218
13.4　要不要支持事务	219
13.5　表分区和索引	221
13.5.1　表分区	222
13.5.2　索引	222
13.6　稳定最重要	225
13.7　安全性和副本	226
13.7.1　RAID	226
13.7.2　软冗余	228
13.8　本章小结	229
第14章　数据统计	230
14.1　此“统计”恐非彼“统计”	230
14.2　要精确还是要简洁	234
14.3　统计是万能的吗	235
14.4　注意性能	237
14.5　本章小结	238
第15章　数据建模	239
15.1　模型是宝贵的财富	240
15.2　量化是关键	241
15.3　该算法出马了	241
15.3.1　统计学模型	242
15.3.2　线性关系	243
15.3.3　复杂的非线性关系	243
15.4　算法的哲学	244
15.5　本章小结	245
第16章　数据可视化与分析	247
16.1　看得见，摸得着	247
16.2　颜色很重要	247
16.3　别说布局没有用	249
16.3.1　由上而下，由简而繁	249
16.3.2　总-分，分-总，总-分-总	251
16.3.3　毗邻吸引	252
16.4　有图就别要表格	253
16.5　分析的内涵	254
16.5.1　相关性分析	255
16.5.2　预测分析	256
16.5.3　其他分析	257
16.6　有趣的统计应用	257
16.6.1　不规则图形的面积	258
16.6.2　套出你的实话	258
16.6.3　巧测圆周率	259
16.7　仁者见仁，智者见智	260
16.8　永恒的困惑	261
16.9　本章小结	263
第17章　数据决策	264
17.1　决策就是“拍脑袋”	264
17.2　哪里有物质，哪里就有数据	265
17.2.1　目的的统一	265
17.2.2　数据胜于雄辩	266
17.3　这是风险博弈	267
17.3.1　性价比优先	267
17.3.2　小迭代至上	268
17.3.3　不要“输不起”	268
17.3.4　留得青山在	269
17.4　本章小结	270
第18章　案例分析	272
18.1　K线图里的秘密	272
18.1.1　什么是市场	273
18.1.2　谁在控制价格	273
18.1.3　货币价格的形成	276
18.1.4　零和博弈	277
18.1.5　涨跌都盈利	278
18.1.6　价格的预测	279
18.1.7　形态	280
18.1.8　K线图周期	282
18.1.9　造市商与点差	283
18.1.10　科学分析	284
18.1.11　小结	317
18.2　数学能救命	317
18.2.1　阴云下的大西洋	317
18.2.2　护航船队的救星	318
18.2.3　数学家的天下	324
18.2.4　小结	324
18.3　人人都能运筹帷幄	325
第19章　与本书相关内容的问与答	326
后记	333
附录A	335
A.1　VMware Workstation的安装	335
A.1.1　VMware简介	335
A.1.2　安装准备工作	335
A.2　CentOS虚拟机的安装	338
A.2.1　下载DVD镜像	338
A.2.2　创建VMware虚拟机	338
A.3　Ubuntu虚拟机的安装	344
A.4　Python语言简介	350
A.4.1　安装Python	350
A.4.2　Hello Python	350
A.4.3　行与缩进	350
A.4.4　变量类型	351
A.4.5　循环语句	352
A.4.6　函数	353
A.4.7　模块	354
A.4.8　小结	354
A.5　Scikit-learn库简介	355
A.6　安装Theano	356
A.7　安装Keras	356
A.8　安装MySQL	357
A.9　安装MySQL-Python驱动	358
A.10　MT4平台简介	359
参考文献	363
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学家养成手册
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>泛函分析讲义(下册)
第五章 Banach代数
1 代数准备知识
……
第六章 无界算子
1 闭算子
……
第七章 算子半群
1 无穷小生成元
……
第八章 无穷维空间上的测度论
1 C[0，T]空间上的Wirner测度
……
符号表
索引

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>泛函分析讲义(下册)
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>网络机器人Java编程指南
第1章
Java套接字编程技术
套接字家族
网络编程
Java I/O编程技术
代理的问题
Java中的套接字编程
客户端套接字

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>网络机器人Java编程指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark快速数据处理
译者序
作者简介
前言
第1章　安装Spark以及构建Spark集群 / 1
1.1　单机运行Spark / 4
1.2　在EC2上运行Spark / 5
1.3　在ElasticMapReduce上部署Spark / 11
1.4　用Chef(opscode)部署Spark / 12
1.5　在Mesos上部署Spark / 14
1.6　在Yarn上部署Spark / 15
1.7　通过SSH部署集群 / 16
1.8　链接和参考 / 21
1.9　小结 / 21
第2章　Spark shell的使用 / 23
2.1　加载一个简单的text文件 / 24
2.2　用Spark shell运行逻辑回归 / 26
2.3　交互式地从S3加载数据 / 28
2.4　小结 / 30
第3章　构建并运行Spark应用 / 31
3.1　用sbt构建Spark作业 / 32
3.2　用Maven构建Spark作业 / 36
3.3　用其他工具构建Spark作业 / 39
3.4　小结 / 39
第4章　创建SparkContext / 41
4.1　Scala / 43
4.2　Java / 43
4.3　Java和Scala共享的API / 44
4.4　Python / 45
4.5　链接和参考 / 45
4.6　小结 / 46
第5章　加载与保存数据 / 47
5.1　RDD / 48
5.2　加载数据到RDD中 / 49
5.3　保存数据 / 54
5.4　连接和参考 / 55
5.5　小结 / 55
第6章　操作RDD / 57
6.1　用Scala和Java操作RDD / 58
6.2　用Python操作RDD / 79
6.3　链接和参考 / 83
6.4　小结 / 84
第7章　Shark-Hive和Spark的综合运用 / 85
7.1　为什么用Hive/Shark / 86
7.2　安装Shark / 86
7.3　运行Shark / 88
7.4　加载数据 / 88
7.5　在Spark程序中运行HiveQL查询 / 89
7.6　链接和参考 / 92
7.7　小结 / 93
第8章　测试 / 95
8.1　用Java和Scala测试 / 96
8.2　用Python测试 / 103
8.3　链接和参考 / 104
8.4　小结 / 105
第9章　技巧和窍门 / 107
9.1　日志位置 / 108
9.2　并发限制 / 108
9.3　内存使用与垃圾回收 / 109
9.4　序列化 / 110
9.5　IDE集成环境 / 111
9.6　Spark与其他语言 / 112
9.7　安全提示 / 113
9.8　邮件列表 / 113
9.9　链接和参考 / 113
9.10　小结 / 114
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark快速数据处理
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大嘴巴漫谈数据挖掘
目录
第一境昨夜西风凋碧树。独上高楼，望尽天涯路…… /10
1.1数据挖掘简介 / 11
开篇点题引五问 /12
大数据中求价值 /13
定义概述归特点 /14
知识决策跨领域 /15
架构特征多形式 /17
数据立方展多维 /19
功能挖掘四大类 /22
分类刻画类标识 /23
数据聚类辨亲疏 /24
预测未来训模型 /25
关联源自购物篮 /27
模型过程方法论 /28
十大算法成经典 /32
1.2数据挖掘应用 /33
行业推广多应用 /34
用户为王放心中 /36
指导运营全周期 /37
定位目标寻用户 /38
精准营销成闭环 /39
交叉产品有关联 /40
细分用户刻画像 /41
用户体验模型化 /43
指标评测建体系 /44
流失预警保用户 /45
跟踪评估验效果 /47
第二境衣带渐宽终不悔，为伊消得人憔悴…… /48
2.1概率定义 /49
浮生难料尽偶然 /50
一枚硬币抛正反 /51
引出随机小试验 /53
样本空间样本点 /54
事件三分包万象 /55
试验频率需频繁 /58
次数无限值极限 /59
描述概率定特点 /60
古典概型等可能 /61
事件B后A在前 /62
求出概率称条件 /65
独立事件A和B /67
抽签中奖公平性 /71
常用概率两公式 /76
交空并全划样本 /77
综合状态全概率 /78
前因后果贝叶斯 /80
2.2随机变量 /81
随机试验数量化 /82
统计规律双类型 /83
离散变量分布律 /84
硬币抛掷是一零 /85
分布函数连续型 /87
函数求导得密度 /89
高斯分布称正态 /91
标准正态分位点 /95
2.3数字特征 / 98
随机变量有特征 /98
平均取值是期望 /100
方差衡量偏离值 /101
标准开根同量纲 /103
变量关系协方差 /104
相关系数相关度 /105
研究总体要抽样 /108
抽样分布统计量 /109
2.4参数估计 /111
最小二乘估参数 /112
极大似然大概率 /116
区间估计置信度 /119
2.5假设检验 / 123
总体假设来检验 /124
服从正态抽样本 /125
统计量中验假设 /126
弃真取伪两错误 /127
显著检验小概率 /128
小概率中拒绝域 /130
检验流程出决策 /131
已知总体方差值 /132
检验中验均值 /133
第三境众里寻她千百度，蓦然回首，那人却在，灯火阑珊处。 /134
3.1关联规则 / 135
购物篮中找关联 /136
数据事务若干项 /137
事务空间含项集 /138
置信支持提升度 /142
规则源于频繁项 /145
k项连接和剪枝 /146
生成非空规则集 /148
关联效果来评估 /149
3.2决策树 /155
决策思维成树形 /156
分类预测工作流 /161
原理基于信息熵 /162
信息增益条件熵 /164
节点拆分选特征 /170
3.3贝叶斯 /186
预测分类贝叶斯 /187
类别概率要最大 /188
分类数据新预测 /195
3.4聚类分析 / 196
物以类聚人以群 /197
样本变量定矩阵 /198
R型Q型换空间 /199
距离度量相似度 /200
系数聚类统计量 /202
标准样本选欧氏 /203
层次聚合归大类 /205
3.5神经网络 /209
神经网络神经元 /210
神经元中有加权 /211
输入映射输出层 /213
求出误差调参数 /214
权重偏置学习率 /216
实例分析模型流 /217
3.6线性回归 /222
研究身高引回归 /223
单自变量归一元 /224
最小二乘估回归 /226
数据差异总离差 /228
分为解释和误差 /229
判定系数拟合度 /230
多元回归建方程 /231
回归面中展二元 /233
求得回归系数解 /234
衡量拟合验效果 /236
3.7逻辑回归 /237
因变量中二分类 /238
二项逻辑回归式 /240
极大似然解方程 /242
预测分类符合率 /244
3.8因子分析 /245
相关变量纳因子 /246
因子构造筑模型 /248
因子载荷统计性 /251
衡量信息共同度 /252
方差贡献重要性 /253
因子分析四步曲 /254
构造因子求载荷 /255
旋转因子得命名 /260
因子组合求得分 /265
3.9信度分析 /268
设计问卷来调研 /269
信度检验可靠性 /270
3.10效度分析 /272
结构方程协方差 /273
测量模型内外生 /276
结构模型潜变量 /279
效度分析路径图 /280
提出假设依理论 /281
固定负荷识模型 /282
相关阵中估参数 /283
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大嘴巴漫谈数据挖掘
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘十大算法
第1章C4.5 1
1.1引言2
1.2算法描述3
1.3算法特性6
1.3.1决策树剪枝6
1.3.2连续型属性8
1.3.3缺失值处理8
1.3.4规则集诱导9
1.4软件实现10
1.5示例10
1.5.1 Golf数据集10
1.5.2 Soybean数据集11
1.6高级主题11
1.6.1二级存储12
1.6.2斜决策树12
1.6.3特征选择12
1.6.4集成方法12
1.6.5分类规则13
1.6.6模型重述13
1.7习题14
参考文献15
第2章k-means18
2.1引言19
2.2算法描述19
2.3可用软件22
2.4示例23
2.5高级主题27
2.6小结28
2.7习题28
参考文献29
第3章SVM： 支持向量机31
3.1支持向量分类器32
3.2支持向量分类器的软间隔优化34
3.3核技巧35
3.4理论基础38
3.5支持向量回归器40
3.6软件实现41
3.7当前和未来的研究41
3.7.1计算效率41
3.7.2核的选择41
3.7.3泛化分析42
3.7.4结构化支持向量机的学习42
3.8习题43
参考文献44
第4章Apriori47
4.1引言48
4.2算法描述48
4.2.1挖掘频繁模式和关联规则48
4.2.2挖掘序列模式52
4.2.3讨论53
4.3软件实现54
4.4示例55
4.4.1可行示例55
4.4.2性能评估60
4.5高级主题61
4.5.1改进Apriori类型的频繁模式挖掘61
4.5.2无候选的频繁模式挖掘62
4.5.3增量式方法63
4.5.4稠密表示: 闭合模式和最大模式63
4.5.5量化的关联规则64
4.5.6其他的重要性/兴趣度度量方法65
4.5.7类别关联规则66
4.5.8使用更丰富的形式： 序列、树和图66
4.6小结67
4.7习题67
参考文献68
第5章EM72
5.1引言73
5.2算法描述74
5.3软件实现74
5.4示例75
5.4.1例5.1： 多元正态混合75
5.4.2例5.2: 混合因子分析78
5.5高级主题80
5.6习题81
参考文献87
第6章PageRank90
6.1引言91
6.2算法描述92
6.3一个扩展： Timed-PageRank95
6.4小结96
6.5习题96
参考文献97
第7章AdaBoost98
7.1引言99
7.2算法描述99
7.2.1符号定义99
7.2.2通用推举过程100
7.2.3AdaBoost算法101
7.3示例103
7.3.1异或问题求解103
7.3.2真实数据上的性能104
7.4实际应用105
7.5高级主题107
7.5.1理论问题107
7.5.2多类别AdaBoost110
7.5.3其他高级主题111
7.6软件实现111
7.7习题112
参考文献113
第8章kNN： k-最近邻115
8.1引言116
8.2算法描述116
8.2.1宏观描述116
8.2.2若干议题117
8.2.3软件实现118
8.3示例118
8.4高级主题120
8.5习题121
致谢121
参考文献122
第9章Naive Bayes124
9.1引言125
9.2算法描述125
9.3独立给力127
9.4模型扩展128
9.5软件实现130
9.6示例130
9.6.1例1130
9.6.2例2132
9.7高级主题133
9.8习题133
参考文献134
第10章CART： 分类和回归树136
10.1前身137
10.2概述138
10.3示例138
10.4算法描述140
10.5分裂准则141
10.6先验概率和类别均衡142
10.7缺失值的处理144
10.8属性的重要度145
10.9动态特征构造146
10.10代价敏感学习147
10.11停止准则、剪枝、树序列和树选择147
10.12概率树149
10.13理论基础150
10.14 CART之后的相关研究150
10.15可用软件151
10.16习题152
参考文献153
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘十大算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>随机过程初级教程
第1章  随机过程初步  1．1  基本术语、随机变量和分布函数性质的复习  1．2  随机过程的两个简单例子  1．3  一般随机过程的分类  1．4  随机过程的确定  初等问题  问题  附记  参考书目第2章  马尔可夫链  2．1  定义  2．2  马尔可夫链的例子  2．3  马尔可夫链的转移概率矩阵  2．4  马尔可夫链的状态分类  2．5  常返性  2．6  常返马尔可夫链的例子  2．7  关于常返性的补充  初等问题  问题  附记  参考书目第3章  马尔可夫链的基本极限定理和应用  3．1  离散更新方程  3．2  定理1．1的证明  3．3  吸收概率  3．4  常返性准则  3．5 一个排队例子  3．6  另一个排队模型  3．7  随机游动  初等问题  问题  附记  参考书目第4章  连续时间马尔可夫链的古典例子  4．1  一般纯生过程和泊松过程  4．2  泊松过程的补充  4．3  计数模型  4．4  生灭过程  4．5  生灭过程的微分方程  4．6  生灭过程的例子  4．7  带有吸收状态的生灭过程  4．8  有限状态连续时间马尔可夫链  初等问题  问题  附记  参考书目第5章  更新过程  5．1  更新过程的定义和有关概念  5．2  更新过程的一些例子  5．3  若干特殊更新过程的补充  5．4  更新方程和初等更新定理  5．5  更新定理  5．6  更新定理的应用  5．7  更新过程的推广  5．8  更新理论更复杂的应用  5．9  更新过程的叠加  初等问题  问题  参考书目第6章  鞅  6．1  初步定义和例子  6．2  上鞅和下鞅  6．3  可选抽样定理  6．4  可选抽样定理的若干应用  6．5  鞅收敛定理  6．6  鞅收敛定理的应用和扩展  6．7  关于■域族的鞅  6．8  其他类型的鞅  初等问题  问题  附记  参考书目第7章  布朗运动  7．1  背景材料  7．2  布朗运动的联合概率  7．3  轨道的连续性和最大值变量  7．4  变形和推广  7．5  用鞅方法计算若干布朗运动的量  7．6  多维布朗运动  7．7  布朗运动的轨道  初等问题  问题  附记  参考书目第8章  分支过程  8．1  离散时间分支过程  8．2  分支过程的母函数表示  8．3  消失概率  8．4  例子  8．5  二维分支过程  8．6  多维分支过程  8．7  连续时间分支过程  8．8  连续时间分支过程的消失概率  8．9  连续时间分支过程的极限定理  8．10  二维连续时间分支过程  8．1l  一般寿命的分支过程  初等问题  问题  附记  参考书目第9章  平稳过程  9．1  定义和例子  9．2  平均平方距离  9．3  平均平方误差预测  9．4  协方差平稳过程的预测  9．5  遍历理论和平稳过程  9．6  遍历理论的应用  9．7  协方差平稳过程的谱分析  9．8  高斯系统  9．9  平稳点过程  9．10  水平交叉问题  初等问题  问题  附记  参考书目附录  矩阵分析的复习索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>随机过程初级教程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>应用随机过程
第1章　概率论引论
1.1　引言
1.2　样本空间与事件
1.3　定义在事件上的概率
1.4　条件概率
1.5　独立事件
1.6　贝叶斯公式
习题
参考文献
第2章　随机变量
2.1　随机变量
2.2　离散随机变量
2.2.1　伯努利随机变量
2.2.2　二项随机变量
2.2.3　几何随机变量
2.2.4　泊松随机变量
2.3　连续随机变量
2.3.1　均匀随机变量
2.3.2　指数随机变量
2.3.3　伽玛随机变量
2.3.4　正态随机变量
2.4　随机变量的期望
2.4.1　离散情形
2.4.2　连续情形
2.4.3　随机变量的函数的期望
2.5　联合分布的随机变量
2.5.1　联合分布函数
2.5.2　独立随机变量
2.5.3　随机变量和的方差与协方差
2.5.4　随机变量的函数的联合概率分布
2.6　矩母函数
2.7　发生事件数的分布
2.8　极限定理
2.9　随机过程
习题
参考文献
第3章　条件概率与条件期望
3.1　引言
3.2　离散情形
3.3　连续情形
3.4　通过取条件计算期望
3.5　通过取条件计算概率
3.6　一些应用
3.6.1　列表模型
3.6.2　随机图
3.6.3　均匀先验、波利亚坛子模型和Bose-Einstein分布
3.6.4　模式的平均时间
3.6.5　离散随机变量的k记录值
3.6.6　不带左跳的随机徘徊
3.7　复合随机变量的恒等式
3.7.1　泊松复合分布
3.7.2　二项复合分布
3.7.3　与负二项随机变量有关的一个复合分布
习题
第4章　马尔可夫链
4.1　引言
4.2　C-K方程
4.3　状态的分类
4.4　极限概率
4.5　一些应用
4.5.1　赌徒破产问题
4.5.2　算法有效性的一个模型
4.5.3　用随机游动分析可满足性问题的概率算法
4.6　在暂态停留的平均时间
4.7　分支过程
4.8　时间可逆的马尔可夫链
4.9　马尔可夫链蒙特卡罗方法
4.10　马尔可夫决策过程
4.11　隐马尔可夫链
习题
参考文献
第5章　指数分布与泊松过程
5.1　引言
5.2　指数分布
5.2.1　定义
5.2.2　指数分布的性质
5.2.3　指数分布的进一步性质
5.2.4　指数随机变量的卷积
5.3　泊松过程
5.3.1　计数过程
5.3.2　泊松过程的定义
5.3.3　到达间隔时间与等待时间的分布
5.3.4　泊松过程的进一步性质
5.3.5　到达时间的条件分布
5.3.6　软件可靠性的估计
5.4　泊松过程的推广
5.4.1　非时齐泊松过程
5.4.2　复合泊松过程
5.4.3　条件(混合)泊松过程
习题
参考文献
第6章　连续时间的马尔可夫链
6.1　引言
6.2　连续时间的马尔可夫链
6.3　生灭过程
6.4　转移概率函数Pij(t)
6.5　极限概率
6.6　时间可逆性
6.7　均匀化
6.8　计算转移概率
习题
参考文献
第7章　更新理论及其应用
7.1　引言
7.2　N(t)的分布
7.3　极限定理及其应用
7.4　更新报酬过程
7.5　再生过程
7.6　半马尔可夫过程
7.7　检验悖论
7.8　计算更新函数
7.9　有关模式的一些应用
7.9.1　离散随机变量的模式
7.9.2　不同值的最大连贯的期望时间
7.9.3　连续随机变量的递增连贯
?7.10　保险破产问题
习题
参考文献
第8章　排队理论
8.1　引言
8.2　预备知识
8.2.1　价格方程
8.2.2　稳态概率
8.3　指数模型
8.3.1　单条服务线的指数排队系统
8.3.2　有限容量的单条服务线的指数排队系统
8.3.3　生灭排队模型
8.3.4　擦鞋店
8.3.5　具有批量服务的排队系统
8.4　排队网络
8.4.1　开放系统
8.4.2　封闭系统
8.5　M/G/1系统
8.5.1　预备知识：功与另一个价格恒等式
8.5.2　在M/G/1中功的应用
8.5.3　忙期
8.6　M/G/1的变形
8.6.1　有随机容量的批量到达的M/G/1
8.6.2　优先排队模型
8.6.3　一个M/G/1优化的例子
8.6.4　具有中断服务线的M/G/1排队系统
8.7　G/M/1模型
8.8　有限源模型
8.9　多服务线系统
8.9.1　Erlang损失系统
8.9.2　M/M/k排队系统
8.9.3　G/M/k排队系统
8.9.4　M/G/k排队系统
习题
参考文献
第9章　可靠性理论
9.1　引言
9.2　结构函数
9.3　独立部件系统的可靠性
9.4　可靠性函数的界
9.4.1　包含与排斥方法
9.4.2　得到r(p)的界的第二种方法
9.5　系统寿命作为部件寿命的函数
9.6　期望系统寿命
9.7　可修复的系统
习题
参考文献
第10章　布朗运动与平稳过程
10.1　布朗运动
10.2　击中时刻、最大随机变量和赌徒破产问题
10.3　布朗运动的变形
10.3.1　漂移布朗运动
10.3.2　几何布朗运动
10.4　股票期权的定价
10.4.1　期权定价的示例
10.4.2　套利定理
10.4.3　Black-Scholes期权定价公式
10.5　白噪声
10.6　高斯过程
10.7　平稳和弱平稳过程
10.8　弱平稳过程的调和分析
习题
参考文献
第11章　模拟
11.1　引言
11.2　模拟连续随机变量的一般方法
11.2.1　逆变换方法
11.2.2　拒绝法
11.2.3　风险率方法
11.3　模拟连续随机变量的特殊方法
11.3.1　正态分布
11.3.2　伽玛分布
11.3.3　卡方分布
11.3.4　贝塔分布(b (n, m)分布)
11.3.5　指数分布——冯?诺伊曼算法
11.4　离散分布的模拟
11.5　随机过程
11.5.1　模拟非时齐泊松过程
11.5.2　模拟二维泊松过程
11.6　方差缩减技术
11.6.1　对偶变量的应用
11.6.2　通过取条件缩减方差
11.6.3　控制变量
11.6.4　重要抽样
11.7　确定运行的次数
11.8　马尔可夫链的平稳分布的生成
11.8.1　过去耦合法
11.8.2　另一种方法
习题
参考文献
附录　带星号习题的解
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>应用随机过程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>面向机器智能的TensorFlow实践
译者序
前言
第一部分　开启TensorFlow之旅
第1章　引言2
1.1　无处不在的数据2
1.2　深度学习2
1.3　TensorFlow：一个现代的机器学习库3
1.4　TensorFlow：技术概要3
1.5　何为TensorFlow4
1.5.1　解读来自官网的单句描述4
1.5.2　单句描述未体现的内容6
1.6　何时使用TensorFlow7
1.7　TensorFlow的优势8
1.8　使用TensorFlow所面临的挑战9
1.9　高歌猛进9
第2章　安装TensorFlow10
2.1　选择安装环境10
2.2　Jupyter Notebook与matplotlib12
2.3　创建Virtualenv环境12
2.4　TensorFlow的简易安装13
2.5　源码构建及安装实例：在64位Ubuntu Linux上安装GPU版TensorFlow14
2.5.1　安装依赖库14
2.5.2　安装Bazel15
2.5.3　安装CUDA软件（仅限NVIDIA GPU）16
2.5.4　从源码构建和安装TensorFlow18
2.6　安装Jupyter Notebook20
2.7　安装matplotlib20
2.8　测试TensorFlow、Jupyter Notebook及matplotlib21
2.9　本章小结23
第二部分　TensorFlow与机器学习基础
第3章　TensorFlow基础26
3.1　数据流图简介26
3.1.1　数据流图基础26
3.1.2　节点的依赖关系29
3.2　在TensorFlow中定义数据流图33
3.2.1　构建第一个TensorFlow数据流图33
3.2.2　张量思维39
3.2.3　张量的形状43
3.2.4　TensorFlow的Operation44
3.2.5　TensorFlow的Graph对象46
3.2.6　TensorFlow Session48
3.2.7　利用占位节点添加输入52
3.2.8　Variable对象53
3.3　通过名称作用域组织数据流图56
3.4　练习：综合运用各种组件61
3.4.1　构建数据流图63
3.4.2　运行数据流图66
3.5　本章小结71
第4章　机器学习基础72
4.1　有监督学习简介72
4.2　保存训练检查点74
4.3　线性回归76
4.4　对数几率回归78
4.5　softmax分类83
4.6　多层神经网络85
4.7　梯度下降法与误差反向传播算法88
第三部分　用TensorFlow实现更高级的深度模型
第5章　目标识别与分类96
5.1　卷积神经网络97
5.2　卷积100
5.2.1　输入和卷积核100
5.2.2　跨度102
5.2.3　边界填充104
5.2.4　数据格式104
5.2.5　深入探讨卷积核105
5.3　常见层107
5.3.1　卷积层108
5.3.2　激活函数108
5.3.3　池化层111
5.3.4　归一化113
5.3.5　高级层114
5.4　图像与TensorFlow116
5.4.1　加载图像116
5.4.2　图像格式117
5.4.3　图像操作121
5.4.4　颜色127
5.5　CNN的实现129
5.5.1　Stanford Dogs数据集129
5.5.2　将图像转为TFRecord文件130
5.5.3　加载图像133
5.5.4　模型134
5.5.5　训练136
5.5.6　用TensorBoard调试滤波器137
5.6　本章小结139
第6章　循环神经网络与自然语言处理140
6.1　循环神经网络简介140
6.1.1　时序的世界140
6.1.2　近似任意程序141
6.1.3　随时间反向传播142
6.1.4　序列的编码和解码143
6.1.5　实现第一个循环神经网络145
6.1.6　梯度消失与梯度爆炸145
6.1.7　长短时记忆网络147
6.1.8　RNN结构的变种148
6.2　词向量嵌入149
6.2.1　准备维基百科语料库151
6.2.2　模型结构155
6.2.3　噪声对比分类器156
6.2.4　训练模型156
6.3　序列分类157
6.3.1　Imdb影评数据集158
6.3.2　使用词向量嵌入159
6.3.3　序列标注模型159
6.3.4　来自最后相关活性值的softmax层161
6.3.5　梯度裁剪162
6.3.6　训练模型163
6.4　序列标注164
6.4.1　OCR数据集164
6.4.2　时间步之间共享的soft-max层166
6.4.3　训练模型169
6.4.4　双向RNN171
6.5　预测编码174
6.5.1　字符级语言建模174
6.5.2　ArXiv摘要API175
6.5.3　数据预处理177
6.5.4　预测编码模型178
6.5.5　训练模型182
6.5.6　生成相似序列185
6.6　本章小结188
第四部分　其他提示、技术与特性
第7章　产品环境中模型的部署190
7.1　搭建TensorFlow服务开发环境190
7.1.1　Docker镜像190
7.1.2　Bazel工作区191
7.2　导出训练好的模型192
7.3　定义服务器接口195
7.4　实现推断服务器197
7.5　客户端应用201
7.6　产品准备203
7.7　本章小结203
第8章　辅助函数、代码结构和类204
8.1　确保目录结构存在204
8.2　下载函数204
8.3　磁盘缓存修饰器205
8.4　属性字典206
8.5　惰性属性修饰器207
8.6　覆盖数据流图修饰器209
第9章　结语：其他资源212
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>面向机器智能的TensorFlow实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学家修炼之道
本书目录
版权
作者简介
版权声明
内容提要
前言
第1章　数据科学与大数据
第2章　数据科学的重要性
第3章　数据科学家的类型
第4章　数据科学家的思维体系
第5章　技术资质
第6章　经验
第7章　社交圈
第8章　所用的软件
第9章　学习新知与解决问题
第10章　机器学习与R语言平台
第11章　数据科学的处理流程
第12章　所需的具体技能
第13章　数据科学职位哪家寻
第14章　自我展示
第15章　自由职业数据科学家之路
第16章　职业数据科学家的案例学习
第17章　资深数据科学家案例学习
第18章　新数据科学家的召唤
结语
术语表
附录1　有用的网页链接
附录2　相关文章
附录3　线下资源
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学家修炼之道
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>《裂变：秒懂人工智能的基础课》
第1篇 数学基础
1 九层之台，起于累土：线性代数
2 月有阴晴圆缺，此事古难全：概率论
3 窥一斑而知全豹：数理统计
4 不畏浮云遮望眼：最优化方法
5 万物皆数，信息亦然：信息论
6 明日黄花迹难寻：形式逻辑
第2篇 机器学习
7 “数”山有路，学海无涯：机器学习概论
8 简约而不简单：线性回归
9 大道至简：朴素贝叶斯方法
10 衍化至繁：逻辑回归
11 步步为营，有章可循：决策树
12 穷则变，变则通：支持向量机
13 三个臭皮匠，赛过诸葛亮：集成学习
14 物以类聚，人以群分：聚类分析
15 好钢用在刀刃上：降维学习
第3篇 人工神经网络
16 道法自然，久藏玄冥：神经网络的生理学背景
17 一个青年才俊的意外死亡：神经元与感知器
18 左手信号，右手误差：多层感知器
19 各人自扫门前雪：径向基函数神经网络
20 看不见的手：自组织特征映射
21 水无至清，人莫至察：模糊神经网络
第4篇 深度学习
22 空山鸣响，静水流深：深度学习概述
23 前方有路，未来可期：深度前馈网络
24 小树不修不直溜：深度学习中的正则化
25 玉不琢不成器：深度学习中的优化
26 空竹里的秘密：自编码器
27 困知勉行者勇：深度强化学习
第5篇 神经网络实例
28 枯木逢春：深度信念网络
29 见微知著：卷积神经网络
30 昨日重现：循环神经网络
31 左右互搏：生成式对抗网络
32 三重门：长短期记忆网络
第6篇 深度学习之外的人工智能
33 一图胜千言：概率图模型
34 乌合之众的逆袭：集群智能
35 授人以鱼不如授人以渔：迁移学习
36 滴水藏海：知识图谱
第7篇 应用场景
37 你是我的眼：计算机视觉
38 嘿，Siri：语音处理
39 心有灵犀一点通：对话系统
40 数字巴别塔：机器翻译
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>《裂变：秒懂人工智能的基础课》
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>驾驭文本
第1章　开始驾驭文本 ...............................................................................1
1.1　驾驭文本重要的原因 ...............................................................................................2
1.2　预览：一个基于事实的问答系统 ...........................................................................4
1.2.1　嗨，弗兰肯斯坦医生 ...................................................................................5
1.3　理解文本很困难 .......................................................................................................8
1.4　驾驭的文本 .............................................................................................................11
1.5　文本及智能应用：搜索及其他 .............................................................................13
1.5.1　搜索和匹配 .................................................................................................13
1.5.2　抽取信息 .....................................................................................................14
1.5.3　对信息分组 .................................................................................................15
1.5.4　一个智能应用 .............................................................................................15
1.6　小结 .........................................................................................................................15
1.7　相关资源 .................................................................................................................16
第2章　驾驭文本的基础 ..........................................................................17
2.1　语言基础知识 .........................................................................................................18
2.1.1　词语及其类别 .............................................................................................19
2.1.2　短语及子句 .................................................................................................20
2.1.3　词法 .............................................................................................................21
2.2　文本处理常见工具 .................................................................................................23
2.2.1　字符串处理工具 .........................................................................................23
2.2.2　词条及切词 .................................................................................................23
2.2.3　词性标注 .....................................................................................................25
2.2.4　词干还原 .....................................................................................................27
2.2.5　句子检测 .....................................................................................................29
2.2.6　句法分析和文法 .........................................................................................31
2.2.7　序列建模 .....................................................................................................33
2.3　从常见格式文件中抽取内容并做预处理 .............................................................34
2.3.1　预处理的重要性 .........................................................................................35
2.3.2　利用Apache Tika抽取内容 ........................................................................37
2.4　小结 .........................................................................................................................39
2.5　相关资源 .................................................................................................................40
第3章　搜索 ............................................................................................41
3.1　搜索和多面示例：Amazon.com ............................................................................42
3.2　搜索概念入门 .........................................................................................................44
3.2.1　索引内容 .....................................................................................................45
3.2.2　用户输入 .....................................................................................................47
3.2.3　利用向量空间模型对文档排名 .................................................................51
3.2.4　结果展示 .....................................................................................................54
3.3　Apache Solr搜索服务器介绍 .................................................................................57
3.3.1　首次运行Solr ..............................................................................................58
3.3.2　理解Solr中的概念 ......................................................................................59
3.4　利用Apache Solr对内容构建索引 .........................................................................63
3.4.1　使用XML构建索引 ....................................................................................64
3.4.2　利用Solr和Apache Tika对内容进行抽取和索引 ......................................66
3.5　利用Apache Solr来搜索内容 .................................................................................69
3.5.1　Solr查询输入参数 ......................................................................................71
3.5.2　抽取内容的多面展示 .................................................................................74
3.6　理解搜索性能因素 .................................................................................................77
3.6.1　数量判定 .....................................................................................................77
3.6.2　判断数量 .....................................................................................................81
3.7　提高搜索性能 .........................................................................................................82
3.7.1　硬件改进 .....................................................................................................82
3.7.2　分析的改进 .................................................................................................83
3.7.3　提高查询性能 .............................................................................................85
3.7.4　其他评分模型 .............................................................................................88
3.7.5　提升Solr性能的技术 ..................................................................................89
3.8　其他搜索工具 .........................................................................................................91
3.9　小结 .........................................................................................................................93
3.10　相关资源 ...............................................................................................................93
第4章　模糊字符串匹配 ..........................................................................94
4.1　模糊字符串匹配方法 .............................................................................................96
4.1.1　字符重合度度量方法 .................................................................................96
4.1.2　编辑距离 .....................................................................................................99
4.1.3　n元组编辑距离 .........................................................................................102
4.2　寻找模糊匹配串 ...................................................................................................105
4.2.1　在Solr中使用前缀来匹配 ........................................................................105
4.2.2　利用trie树进行前缀匹配 .........................................................................106
4.2.3　使用n元组进行匹配 ..................................................................................111
4.3　构建模糊串匹配应用 ...........................................................................................112
4.3.1　在搜索中加入提前输入功能 ...................................................................113
4.3.2　搜索中的查询拼写校正 ...........................................................................117
4.3.3　记录匹配 ...................................................................................................122
4.4　小结 .......................................................................................................................127
4.5　相关资源 ...............................................................................................................128
第5章　命名实体识别 ...........................................................................129
5.1　命名实体的识别方法 ...........................................................................................131
5.1.1　基于规则的实体识别 ...............................................................................131
5.1.2　基于统计分类器的实体识别 ...................................................................132
5.2　基于OpenNLP的基本实体识别 ...........................................................................133
5.2.1　利用OpenNLP寻找人名 ...........................................................................134
5.2.2　OpenNLP识别的实体解读 .......................................................................136
5.2.3　基于概率过滤实体 ...................................................................................137
5.3　利用OpenNLP进行深度命名实体识别 ...............................................................137
5.3.1　利用OpenNLP识别多种实体类型 ...........................................................138
5.3.2　OpenNLP识别实体的背后机理 ...............................................................141
5.4　OpenNLP的性能 ...................................................................................................143
5.4.1　结果的质量 ...............................................................................................144
5.4.2　运行性能 ...................................................................................................145
5.4.3　OpenNLP的内存使用 ...............................................................................146
5.5　对新领域定制OpenNLP实体识别 .......................................................................147
5.5.1　训练模型的原因和方法 ...........................................................................147
5.5.2　训练OpenNLP模型 ...................................................................................148
5.5.3　改变建模输入 ...........................................................................................150
5.5.4　对实体建模的新方法 ...............................................................................152
5.6　小结 .......................................................................................................................154
5.7　进一步阅读材料 ...................................................................................................155
第6章　文本聚类 ..................................................................................156
6.1　Google News中的文档聚类 .................................................................................157
6.2　聚类基础 ...............................................................................................................158
6.2.1　三种聚类的文本类型 ...............................................................................158
6.2.2　选择聚类算法 ...........................................................................................160
6.2.3　确定相似度 ...............................................................................................161
6.2.4　给聚类结果打标签 ...................................................................................162
6.2.5　聚类结果的评估 .......................................................................................163
6.3　搭建一个简单的聚类应用 ...................................................................................165
6.4　利用Carrot2对搜索结果聚类 ...............................................................................166
6.4.1　使用Carrot2API ........................................................................................166
6.4.2　使用Carrot2对Solr的搜索结果聚类 ........................................................168
6.5　利用Apache Mahout对文档集聚类 ......................................................................171
6.5.1　对聚类的数据进行预处理 .......................................................................172
6.5.2　K-means聚类 ............................................................................................175
6.6　利用Apache Mahout进行主题建模 ......................................................................180
6.7　考察聚类性能 .......................................................................................................183
6.7.1　特征选择与特征约简 ...............................................................................183
6.7.2　Carrot2的性能和质量 ...............................................................................186
6.7.3　Mahout基准聚类算法 ..............................................................................187
6.8　致谢 .......................................................................................................................192
6.9　小结 .......................................................................................................................192
6.10　参考文献 .............................................................................................................193
第7章　分类及标注 ...............................................................................195
7.1　分类及归类概述 ...................................................................................................197
7.2　分类过程 ...............................................................................................................200
7.2.1　选择分类机制 ...........................................................................................201
7.2.2　识别文本分类中的特征 ...........................................................................202
7.2.3　训练数据的重要性 ...................................................................................203
7.2.4　评估分类器性能 .......................................................................................206
7.2.5　将分类器部署到生产环境 .......................................................................208
7.3　利用Apache Lucene构建文档分类器 ..................................................................209
7.3.1　利用Lucene对文本进行分类 ...................................................................210
7.3.2　为MoreLikeThis分类器准备训练数据 ....................................................212
7.3.3　训练MoreLikeThis分类器 ........................................................................214
7.3.4　利用MoreLikeThis分类器对文档进行分类 ............................................217
7.3.5　测试MoreLikeThis分类器 ........................................................................220
7.3.6　将MoreLikeThis投入生产环境 ................................................................223
7.4　利用Apache Mahout训练朴素贝叶斯分类器 ......................................................223
7.4.1　利用朴素贝叶斯算法进行文本分类 .......................................................224
7.4.2　准备训练数据 ...........................................................................................225
7.4.3　留存测试数据 ...........................................................................................229
7.4.4　训练分类器 ...............................................................................................229
7.4.5　测试分类器 ...............................................................................................231
7.4.6　改进自举过程 ...........................................................................................232
7.4.7　将Mahout贝叶斯分类器集成到Solr ........................................................234
7.5　利用OpenNLP进行文档分类 ...............................................................................238
7.5.1　回归模型及最大熵文档分类 ...................................................................239
7.5.2　为最大熵文档分类器准备训练数据 .......................................................241
7.5.3　训练最大熵文档分类器 ...........................................................................242
7.5.4　测试最大熵文档分类器 ...........................................................................248
7.5.5　生产环境下的最大熵文档分类器 ...........................................................249
7.6　利用Apache Solr构建标签推荐系统 ...................................................................250
7.6.1　为标签推荐收集训练数据 .......................................................................253
7.6.2　准备训练数据 ...........................................................................................255
7.6.3　训练Solr标签推荐系统 ............................................................................256
7.6.4　构建推荐标签 ...........................................................................................258
7.6.5　对标签推荐系统进行评估 .......................................................................261
7.7　小结 .......................................................................................................................263
7.8　参考文献 ...............................................................................................................265
第8章　构建示例问答系统 ....................................................................266
8.1　问答系统基础知识 ...............................................................................................268
8.2　安装并运行QA代码 .............................................................................................270
8.3　一个示例问答系统的架构 ...................................................................................271
8.4　理解问题并产生答案 ...........................................................................................274
8.4.1　训练答案类型分类器 ...............................................................................275
8.4.2　对查询进行组块分析 ...............................................................................279
8.4.3　计算答案类型 ...........................................................................................280
8.4.4　生成查询 ...................................................................................................283
8.4.5　对候选段落排序 .......................................................................................285
8.5　改进系统的步骤 ...................................................................................................287
8.6　本章小结 ...............................................................................................................287
8.7　相关资源 ...............................................................................................................288
第9章　未驾驭的文本：探索未来前沿 ..................................................289
9.1　语义、篇章和语用：探索高级NLP ....................................................................290
9.1.1　语义 ...........................................................................................................291
9.1.2　篇章 ...........................................................................................................292
9.1.3　语用 ...........................................................................................................294
9.2　文档及文档集自动摘要 .......................................................................................295
9.3　关系抽取 ...............................................................................................................298
9.3.1　关系抽取方法综述 ...................................................................................299
9.3.2　评估 ...........................................................................................................302
9.3.3　关系抽取工具 ...........................................................................................303
9.4　识别重要内容和人物 ...........................................................................................303
9.4.1　全局重要性及权威度 ...............................................................................304
9.4.2　个人重要性 ...............................................................................................305
9.4.3　与重要性相关的资源及位置 ...................................................................306
9.5　通过情感分析来探测情感 ...................................................................................306
9.5.1　历史及综述 ...............................................................................................307
9.5.2　工具及数据需求 .......................................................................................308
9.5.3　一个基本的极性算法 ...............................................................................309
9.5.4　高级话题 ...................................................................................................311
9.5.5　用于情感分析的开源库 ...........................................................................312
9.6　跨语言检索 ...........................................................................................................313
9.7　本章小结 ...............................................................................................................315
9.8　相关资源 ...............................................................................................................315
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>驾驭文本
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据
第1章 数据挖掘基本概念　　1
1.1 数据挖掘的定义　　1
1.1.1 统计建模　　1
1.1.2 机器学习　　1
1.1.3 建模的计算方法　　2
1.1.4 数据汇总　　2
1.1.5 特征抽取　　3
1.2 数据挖掘的统计限制　　4
1.2.1 整体情报预警　　4
1.2.2 邦弗朗尼原理　　4
1.2.3 邦弗朗尼原理的一个例子　　5
1.2.4 习题　　6
1.3 相关知识　　6
1.3.1 词语在文档中的重要性　　6
1.3.2 哈希函数　　7
1.3.3 索引　　8
1.3.4 二级存储器　　9
1.3.5 自然对数的底e　　10
1.3.6 幂定律　　11
1.3.7 习题　　12
1.4 本书概要　　13
1.5 小结　　14
1.6 参考文献　　15
第2章 MapReduce及新软件栈　　16
2.1 分布式文件系统　　17
2.1.1 计算节点的物理结构　　17
2.1.2 大规模文件系统的结构　　18
2.2 MapReduce　　19
2.2.1 Map任务　　20
2.2.2 按键分组　　20
2.2.3 Reduce任务　　21
2.2.4 组合器　　21
2.2.5 MapReduce的执行细节　　22
2.2.6 节点失效的处理　　23
2.2.7 习题　　23
2.3 使用MapReduce的算法　　23
2.3.1 基于MapReduce的矩阵—向量乘法实现　　24
2.3.2 向量v无法放入内存时的处理　　 24
2.3.3 关系代数运算　　25
2.3.4 基于MapReduce的选择运算27
2.3.5 基于MapReduce的投影运算27
2.3.6 基于MapReduce的并、交和差运算　　28
2.3.7 基于MapReduce的自然连接运算　　28
2.3.8 基于MapReduce的分组和聚合运算　　29
2.3.9 矩阵乘法　　29
2.3.10 基于单步MapReduce的矩阵乘法　　30
2.3.11 习题　　31
2.4 MapReduce的扩展　　31
2.4.1 工作流系统　　32
2.4.2 MapReduce的递归扩展版本.33
2.4.3 Pregel系统　　35
2.4.4 习题　　35
2.5 通信开销模型　　36
2.5.1 任务网络的通信开销　　36
2.5.2 时钟时间　　37
2.5.3 多路连接　　38
2.5.4 习题　　41
2.6 MapReduce复杂性理论　　41
2.6.1 Reducer规模及复制率　　41
2.6.2 一个例子：相似性连接　　42
2.6.3 MapReduce问题的一个图模型　　 44
2.6.4 映射模式　　45
2.6.5 并非所有输入都存在时的处理　　 46
2.6.6 复制率的下界　　46
2.6.7 案例分析：矩阵乘法　　48
2.6.8 习题　　51
2.7 小结　　51
2.8 参考文献　　53
第3章 相似项发现　　55
3.1 近邻搜索的应用　　55
3.1.1 集合的Jaccard相似度　　55
3.1.2 文档的相似度　　56
3.1.3 协同过滤——一个集合相似问题　　57
3.1.4 习题　　58
3.2 文档的shingling　　58
3.2.1 k-shingle　　58
3.2.2 shingle大小的选择　　59
3.2.3 对shingle进行哈希　　59
3.2.4 基于词的shingle　　60
3.2.5 习题　　60
3.3 保持相似度的集合摘要表示　　61
3.3.1 集合的矩阵表示　　61
3.3.2 最小哈希　　62
3.3.3 最小哈希及Jaccard相似度　　62
3.3.4 最小哈希签名　　63
3.3.5 最小哈希签名的计算　　63
3.3.6 习题　　66
3.4 文档的局部敏感哈希算法　　67
3.4.1 面向最小哈希签名的LSH　　67
3.4.2 行条化策略的分析　　68
3.4.3 上述技术的综合　　69
3.4.4 习题　　70
3.5 距离测度　　70
3.5.1 距离测度的定义　　71
3.5.2 欧氏距离　　71
3.5.3 Jaccard距离　　72
3.5.4 余弦距离　　72
3.5.5 编辑距离　　73
3.5.6 海明距离　　74
3.5.7 习题　　74
3.6 局部敏感函数理论　　75
3.6.1 局部敏感函数　　76
3.6.2 面向Jaccard距离的局部敏感函数族　　77
3.6.3 局部敏感函数族的放大处理.77
3.6.4 习题　　79
3.7 面向其他距离测度的LSH函数族　　80
3.7.1 面向海明距离的LSH函数族　　 80
3.7.2 随机超平面和余弦距离　　80
3.7.3 梗概　　81
3.7.4 面向欧氏距离的LSH函数族　　 82
3.7.5 面向欧氏空间的更多LSH函数族　　83
3.7.6 习题　　83
3.8 LSH 函数的应用　　84
3.8.1 实体关联　　84
3.8.2 一个实体关联的例子　　85
3.8.3 记录匹配的验证　　86
3.8.4 指纹匹配　　87
3.8.5 适用于指纹匹配的LSH函数族　　87
3.8.6 相似新闻报道检测　　88
3.8.7 习题　　89
3.9 面向高相似度的方法　　90
3.9.1 相等项发现　　90
3.9.2 集合的字符串表示方法　　91
3.9.3 基于长度的过滤　　91
3.9.4 前缀索引　　92
3.9.5 位置信息的使用　　93
3.9.6 使用位置和长度信息的索引.94
3.9.7 习题　　96
3.10 小结　　97
3.11 参考文献　　98
第4章 数据流挖掘　　100
4.1 流数据模型　　100
4.1.1 一个数据流管理系统　　100
4.1.2 流数据源的例子　　101
4.1.3 流查询　　102
4.1.4 流处理中的若干问题　　103
4.2 流当中的数据抽样　　103
4.2.1 一个富于启发性的例子　　104
4.2.2 代表性样本的获取　　104
4.2.3 一般的抽样问题　　105
4.2.4 样本规模的变化　　105
4.2.5 习题　　106
4.3 流过滤　　106
4.3.1 一个例子　　106
4.3.2 布隆过滤器　　107
4.3.3 布隆过滤方法的分析　　107
4.3.4 习题　　108
4.4 流中独立元素的数目统计　　109
4.4.1 独立元素计数问题　　109
4.4.2 FM 算法　　109
4.4.3 组合估计　　110
4.4.4 空间需求　　111
4.4.5 习题　　111
4.5 矩估计　　111
4.5.1 矩定义　　111
4.5.2 二阶矩估计的AMS算法　　112
4.5.3 AMS算法有效的原因　　113
4.5.4 更高阶矩的估计　　113
4.5.5 无限流的处理　　114
4.5.6 习题　　115
4.6 窗口内的计数问题　　116
4.6.1 精确计数的开销　　116
4.6.2 DGIM算法　　116
4.6.3 DGIM算法的存储需求　　118
4.6.4 DGIM算法中的查询应答　　118
4.6.5 DGIM条件的保持　　119
4.6.6 降低错误率　　120
4.6.7 窗口内计数问题的扩展　　120
4.6.8 习题　　121
4.7 衰减窗口　　121
4.7.1 最常见元素问题　　121
4.7.2 衰减窗口的定义　　122
4.7.3 最流行元素的发现　　123
4.8 小结　　123
4.9 参考文献　　124
第5章 链接分析　　126
5.1 PageRank　　126
5.1.1 早期的搜索引擎及词项作弊　　 126
5.1.2 PageRank 的定义　　128
5.1.3 Web结构　　130
5.1.4 避免终止点　　132
5.1.5 采集器陷阱及“抽税”法　　134
5.1.6 PageRank 在搜索引擎中的使用　　136
5.1.7 习题　　136
5.2 PageRank的快速计算　　137
5.2.1 转移矩阵的表示　　137
5.2.2 基于MapReduce的PageRank迭代计算　　138
5.2.3 结果向量合并时的组合器使用　　139
5.2.4 转移矩阵中块的表示　　140
5.2.5 其他高效的PageRank迭代方法　　141
5.2.6 习题　　142
5.3 面向主题的PageRank　　142
5.3.1 动机　　142
5.3.2 有偏的随机游走模型　　143
5.3.3 面向主题的PageRank 的使用　　 144
5.3.4 基于词汇的主题推断　　144
5.3.5 习题　　145
5.4 链接作弊　　145
5.4.1 垃圾农场的架构　　145
5.4.2 垃圾农场的分析　　147
5.4.3 与链接作弊的斗争　　147
5.4.4 TrustRank　　148
5.4.5 垃圾质量　　148
5.4.6 习题　　149
5.5 导航页和权威页　　149
5.5.1 HITS的直观意义　　150
5.5.2 导航度和权威度的形式化　　150
5.5.3 习题　　153
5.6 小结　　153
5.7 参考文献　　155
第6章 频繁项集　　157
6.1 购物篮模型　　157
6.1.1 频繁项集的定义　　157
6.1.2 频繁项集的应用　　159
6.1.3 关联规则　　160
6.1.4 高可信度关联规则的发现　　161
6.1.5 习题　　162
6.2 购物篮及A-Priori算法　　163
6.2.1 购物篮数据的表示　　163
6.2.2 项集计数中的内存使用　　164
6.2.3 项集的单调性　　165
6.2.4 二元组计数　　166
6.2.5 A-Priori算法　　166
6.2.6 所有频繁项集上的A-Priori算法　　168
6.2.7 习题　　169
6.3 更大数据集在内存中的处理　　170
6.3.1 PCY算法　　171
6.3.2 多阶段算法　　172
6.3.3 多哈希算法　　174
6.3.4 习题　　175
6.4 有限扫描算法　　177
6.4.1 简单的随机化算法　　177
6.4.2 抽样算法中的错误规避　　178
6.4.3 SON算法　　179
6.4.4 SON算法和MapReduce　　179
6.4.5 Toivonen算法　　180
6.4.6 Toivonen算法的有效性分析　　 181
6.4.7 习题　　181
6.5 流中的频繁项计数　　182
6.5.1 流的抽样方法　　182
6.5.2 衰减窗口中的频繁项集　　183
6.5.3 混合方法　　183
6.5.4 习题　　184
6.6 小结　　184
6.7 参考文献　　186
第7章 聚类　　187
7.1 聚类技术介绍　　187
7.1.1 点、空间和距离　　187
7.1.2 聚类策略　　188
7.1.3 维数灾难　　189
7.1.4 习题　　190
7.2 层次聚类　　190
7.2.1 欧氏空间下的层次聚类　　191
7.2.2 层次聚类算法的效率　　194
7.2.3 控制层次聚类的其他规则　　194
7.2.4 非欧空间下的层次聚类　　196
7.2.5 习题　　197
7.3 k-均值算法　　198
7.3.1 k-均值算法基本知识　　198
7.3.2 k-均值算法的簇初始化　　198
7.3.3 选择正确的k值　　199
7.3.4 BFR算法　　200
7.3.5 BFR算法中的数据处理　　202
7.3.6 习题　　203
7.4 CURE算法　　204
7.4.1 CURE算法的初始化　　205
7.4.2 CURE算法的完成　　206
7.4.3 习题　　206
7.5 非欧空间下的聚类　　207
7.5.1 GRGPF算法中的簇表示　　207
7.5.2 簇表示树的初始化　　207
7.5.3 GRGPF算法中的点加入　　208
7.5.4 簇的分裂及合并　　209
7.5.5 习题　　210
7.6 流聚类及并行化　　210
7.6.1 流计算模型　　210
7.6.2 一个流聚类算法　　211
7.6.3 桶的初始化　　211
7.6.4 桶合并　　211
7.6.5 查询应答　　213
7.6.6 并行环境下的聚类　　213
7.6.7 习题　　214
7.7 小结　　214
7.8 参考文献　　216
第8章 Web广告　　218
8.1 在线广告相关问题　　218
8.1.1 广告机会　　218
8.1.2 直投广告　　219
8.1.3 展示广告的相关问题　　219
8.2 在线算法　　220
8.2.1 在线和离线算法　　220
8.2.2 贪心算法　　221
8.2.3 竞争率　　222
8.2.4 习题　　222
8.3 广告匹配问题　　223
8.3.1 匹配及完美匹配　　223
8.3.2 最大匹配贪心算法　　224
8.3.3 贪心匹配算法的竞争率　　224
8.3.4 习题　　225
8.4 adwords问题　　225
8.4.1 搜索广告的历史　　226
8.4.2 adwords问题的定义　　226
8.4.3 adwords问题的贪心方法　　227
8.4.4 Balance算法　　228
8.4.5 Balance算法竞争率的一个下界　　228
8.4.6 多投标者的Balance算法　　230
8.4.7 一般性的Balance算法　　231
8.4.8 adwords问题的最后论述　　232
8.4.9 习题　　232
8.5 adwords的实现　　232
8.5.1 投标和搜索查询的匹配　　233
8.5.2 更复杂的匹配问题　　233
8.5.3 文档和投标之间的匹配算法　　 234
8.6 小结　　235
8.7 参考文献　　237
第9章 推荐系统　　238
9.1 一个推荐系统的模型　　238
9.1.1 效用矩阵　　238
9.1.2 长尾现象　　239
9.1.3 推荐系统的应用　　241
9.1.4 效用矩阵的填充　　241
9.2 基于内容的推荐　　242
9.2.1 项模型　　242
9.2.2 文档的特征发现　　242
9.2.3 基于Tag的项特征获取　　243
9.2.4 项模型的表示　　244
9.2.5 用户模型　　245
9.2.6 基于内容的项推荐　　246
9.2.7 分类算法　　247
9.2.8 习题　　248
9.3 协同过滤　　249
9.3.1 相似度计算　　249
9.3.2 相似度对偶性　　252
9.3.3 用户聚类和项聚类　　253
9.3.4 习题　　254
9.4 降维处理　　254
9.4.1 UV分解　　255
9.4.2 RMSE　　255
9.4.3 UV分解的增量式计算　　256
9.4.4 对任一元素的优化　　259
9.4.5 一个完整UV 分解算法的构建　　259
9.4.6 习题　　261
9.5 NetFlix竞赛　　262
9.6 小结　　263
9.7 参考文献　　264
第10章 社会网络图挖掘　　265
10.1 将社会网络看成图　　265
10.1.1 社会网络的概念　　265
10.1.2 将社会网络看成图　　266
10.1.3 各种社会网络的例子　　267
10.1.4 多类型节点构成的图　　268
10.1.5 习题　　269
10.2 社会网络图的聚类　　269
10.2.1 社会网络图的距离计算　　269
10.2.2 应用标准的聚类算法　　270
10.2.3 中介度　　271
10.2.4 Girvan-Newman算法　　271
10.2.5 利用中介度来发现社区　　274
10.2.6 习题　　275
10.3 社区的直接发现　　275
10.3.1 团的发现　　276
10.3.2 完全二部图　　276
10.3.3 发现完全二部子图　　277
10.3.4 完全二部子图一定存在的原因　　277
10.3.5 习题　　279
10.4 图划分　　280
10.4.1 图划分的好坏标准　　280
10.4.2 归一化割　　280
10.4.3 描述图的一些矩阵　　281
10.4.4 拉普拉斯矩阵的特征值　　282
10.4.5 其他图划分方法　　284
10.4.6 习题　　284
10.5 重叠社区的发现　　285
10.5.1 社区的本质　　285
10.5.2 极大似然估计　　286
10.5.3 关系图模型　　287
10.5.4 避免成员隶属关系的离散式变化　　288
10.5.5 习题　　290
10.6 Simrank　　290
10.6.1 社会网络上的随机游走者　　 290
10.6.2 带重启的随机游走　　291
10.6.3 习题　　293
10.7 三角形计数问题　　293
10.7.1 为什么要对三角形计数　　294
10.7.2 一个寻找三角形的算法　　294
10.7.3 三角形寻找算法的最优性　　 295
10.7.4 基于MapReduce寻找三角形　　295
10.7.5 使用更少的Reduce任务.297
10.7.6 习题　　297
10.8 图的邻居性质　　298
10.8.1 有向图和邻居　　298
10.8.2 图的直径　　299
10.8.3 传递闭包和可达性　　300
10.8.4 基于MapReduce的传递闭包求解　　301
10.8.5 智能传递闭包　　303
10.8.6 基于图归约的传递闭包　　304
10.8.7 邻居规模的近似计算　　305
10.8.8 习题　　306
10.9 小结　　307
10.10 参考文献　　310
第11章 降维处理　　312
11.1 特征值和特征向量　　312
11.1.1 定义　　312
11.1.2 特征值与特征向量计算　　313
11.1.3 基于幂迭代方法的特征对求解　　315
11.1.4 特征向量矩阵　　317
11.1.5 习题　　317
11.2 主成分分析　　318
11.2.1 一个示例　　318
11.2.2 利用特征向量进行降维　　321
11.2.3 距离矩阵　　322
11.2.4 习题　　323
11.3 奇异值分解　　323
11.3.1 SVD的定义　　323
11.3.2 SVD解析　　325
11.3.3 基于SVD的降维　　326
11.3.4 将较低奇异值置为0后有效的原因　　327
11.3.5 使用概念进行查询处理　　328
11.3.6 矩阵SVD的计算　　329
11.3.7 习题　　330
11.4 CUR 分解　　331
11.4.1 CUR 的定义　　331
11.4.2 合理选择行和列　　332
11.4.3 构建中间矩阵　　333
11.4.4 完整的CUR 分解　　334
11.4.5 去除重复行和列　　335
11.4.6 习题　　335
11.5 小结　　336
11.6 参考文献　　337
第12章 大规模机器学习　　338
12.1 机器学习模型　　338
12.1.1 训练集　　338
12.1.2 一些例子　　339
12.1.3 机器学习方法　　341
12.1.4 机器学习架构　　342
12.1.5 习题　　344
12.2 感知机　　344
12.2.1 训练阈值为0 的感知机　　344
12.2.2 感知机的收敛性　　347
12.2.3 Winnow算法　　347
12.2.4 允许阈值变化的情况　　349
12.2.5 多类感知机　　350
12.2.6 变换训练集　　351
12.2.7 感知机的问题　　351
12.2.8 感知机的并行实现　　353
12.2.9 习题　　354
12.3 支持向量机　　354
12.3.1 支持向量机的构成　　354
12.3.2 超平面归一化　　356
12.3.3 寻找最优逼近分界面　　357
12.3.4 基于梯度下降法求解SVM　　 359
12.3.5 随机梯度下降　　363
12.3.6 SVM的并行实现　　363
12.3.7 习题　　363
12.4 近邻学习　　364
12.4.1 近邻计算的框架　　364
12.4.2 最近邻学习　　365
12.4.3 学习一维函数　　365
12.4.4 核回归　　367
12.4.5 处理高维欧氏空间数据　　368
12.4.6 对非欧距离的处理　　369
12.4.7 习题　　369
12.5 各种学习方法的比较　　370
12.6 小结　　371
12.7 参考文献　　372
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计机器翻译
第1章 绪论
1.1 概述
1.1.1 第1章：绪论
1.1.2 第2章：词、句子和语料
1.1.3 第3章：概率论
1.1.4 第4章：基于词的翻译模型
1.1.5 第5章：基于短语的翻译模型
1.1.6 第6章：解码
1.1.7 第7章：语言模型
1.1.8 第8章：评测
1.1.9 第9章：判别式训练
1.1.10 第10章：整合语言学信息
1.1.11 第11章：基于树的翻译模型
1.2 机器翻译简史
1.2.1 肇始
1.2.2 ALPAC报告及其后果
1.2.3 首批商用系统
1.2.4 基于中间语系统的研究
1.2.5 数据驱动方法
1.2.6 目前的开发商
1.2.7 技术现状
1.3 应用
1.3.1 全自动高质量机器翻译
1.3.2 要旨翻译
1.3.3 集成语音技术
1.3.4 手持设备中的翻译
1.3.5 后编辑
1.3.6 译者的工具
1.4 可用资源
1.4.1 工具
1.4.2 语料
1.4.3 评测竞赛
1.5 小结
1.5.1 核心概念
1.5.2 延伸阅读
1.6 习题
第2章 词、句子和语料
2.1 词
2.1.1 词例化
2.1.2 词的分布
2.1.3 词性
2.1.4 形态学
2.1.5 词汇语义学
2.2 句子
2.2.1 句子结构
2.2.2 语法理论
2.2.3 句子结构的翻译
2.2.4 语篇
2.3 语料
2.3.1 文本的类型
2.3.2 获取平行语料
2.3.3 句子对齐
2.4 小结
2.4.1 核心概念
2.4.2 延伸阅读
2.4.3 习题
第3章 概率论
3.1 概率分布估计
3.1.1 估计分析
3.1.2 常见概率分布
3.1.3 基于统计的概率估计
3.2 概率分布计算
3.2.1 形式定义
3.2.2 联合概率分布
3.2.3 条件概率分布
3.2.4 贝叶斯法则
3.2.5 插值
3.3 概率分布的特性
3.3.1 均值和方差
3.3.2 期望和方差
3.3.3 熵
3.3.4 互信息
3.4 小结
3.4.1 核心概念
3.4.2 延伸阅读
3.4.3 习题
第二部分 核心方法
第4章 基于词的翻译模型
4.1 基于词的机器翻译
4.1.1 词汇翻译
4.1.2 数据统计
4.1.3 估计概率分布
4.1.4 对齐
4.1.5 IBM模型1
4.2 学习词汇翻译模型
4.2.1 语料不完备问题
4.2.2 期望最大化算法
4.2.3 IBM模型1中的期望最大化算法
4.2.4 困惑度
4.3 确保流畅的输出
4.3.1 流利译文的经验证据
4.3.2 语言模型
4.3.3 噪声信道模型
4.4 更高级的IBM模型
4.4.1 IBM模型2
4.4.2 IBM模型3
4.4.3 训练模型3：采样对齐空间
4.4.4 IBM模型4
4.4.5 IBM模型5
4.5 词对齐
4.5.1 词对齐任务
4.5.2 词对齐质量评估
4.5.3 基于IBM模型的词对齐
4.6 小结
4.6.1 核心概念
4.6.2 延伸阅读
4.6.3 习题
第5章 基于短语的翻译模型
5.1 标准模型
5.1.1 基于短语的翻译模型提出的动因
5.1.2 数学定义
5.2 学习短语翻译表
5.2.1 从词对齐中抽取短语
5.2.2 一致性定义
5.2.3 短语抽取算法
5.2.4 应用实例
5.2.5 短语翻译概率估计
5.3 翻译模型的扩展
5.3.1 对数线性模型
5.3.2 双向翻译概率
5.3.3 词汇化加权
5.3.4 词语惩罚
5.3.5 短语惩罚
5.3.6 作为分类问题的短语翻译
5.4 调序模型的扩展
5.4.1 调序限制
5.4.2 词汇化调序
5.5 基于短语模型的期望最大化训练
5.5.1 短语对齐的联合模型
5.5.2 对齐空间的复杂度
5.5.3 模型训练
5.6 小结
5.6.1 核心概念
5.6.2 延伸阅读
5.6.3 习题
第6章 解码
6.1 翻译过程
6.1.1 翻译一个句子
6.1.2 计算句子的翻译概率
6.2 柱搜索
6.2.1 翻译选项
6.2.2 通过假设扩展的解码过程
6.2.3 计算复杂度
6.2.4 翻译假设重组
6.2.5 栈解码
6.2.6 直方图剪枝和阈值剪枝
6.2.7 调序限制
6.3 未来代价估计
6.3.1 不同的翻译困难
6.3.2 翻译选项的未来代价估计
6.3.3 任意输入跨度的未来代价估计
6.3.4 在搜索中使用未来代价
6.4 其他解码算法
6.4.1 基于覆盖栈的柱搜索算法
6.4.2 A*搜索算法
6.4.3 贪婪爬山解码
6.4.4 有限状态转换机解码
6.5 小结
6.5.1 核心概念
6.5.2 延伸阅读
6.5.3 习题
第7章 语言模型
7.1 n元文法语言模型
7.1.1 马尔可夫链
7.1.2 估计
7.1.3 困惑度
7.2 计数平滑
7.2.1 加1平滑法
7.2.2 删除估计平滑法
7.2.3 古德图灵平滑法
7.2.4 评估
7.3 插值和后备
7.3.1 插值
7.3.2 递归插值
7.3.3 后备
7.3.4 预测词的差异性
7.3.5 历史的差异性
7.3.6 修正的Kneser-Ney平滑算法
7.3.7 评估
7.4 控制语言模型的大小
7.4.1 不同的n元文法的数目
7.4.2 在磁盘上进行估计
7.4.3 高效的数据结构
7.4.4 减小词汇表规模
7.4.5 抽取相关的n元文法
7.4.6 根据需要加载n元文法
7.5 小结
7.5.1 核心概念
7.5.2 延伸阅读
7.5.3 习题
第8章 评测
8.1 人工评测
8.1.1 流利度和忠实度
8.1.2 评测目的
8.1.3 其他评测标准
8.2 自动评测
8.2.1 准确率和召回率
8.2.2 词错误率
8.2.3 BLEU：一个双语评测的替代指标
8.2.4 METEOR
8.2.5 关于评测的争论
8.2.6 评测指标的评测
8.2.7 自动评测不足的证据
8.3 假设检验
8.3.1 计算置信区间
8.3.2 成对比较
8.3.3 自举重采样
8.4 面向任务的评测
8.4.1 后编辑的代价
8.4.2 内容理解测试
8.5 小结
8.5.1 核心概念
8.5.2 延伸阅读
8.5.3 习题
第三部分 前沿研究
第9章 判别式训练
9.1 寻找候选译文
9.1.1 搜索图
9.1.2 词格
9.1.3 n-best列表
9.2 判别式方法的原理
9.2.1 译文的特征表示
9.2.2 标注译文的正确性
9.2.3 监督学习
9.2.4 最大熵
9.3 参数调节
9.3.1 实验设置
9.3.2 Powell搜索方法
9.3.3 单纯型算法
9.4 大规模判别式训练
9.4.1 训练问题
9.4.2 目标函数
9.4.3 梯度下降
9.4.4 感知机
9.4.5 正则化
9.5 后验方法与系统融合
9.5.1 最小贝叶斯风险
9.5.2 置信度估计
9.5.3 系统融合
9.6 小结
9.6.1 核心概念
9.6.2 延伸阅读
9.6.3 习题
第10章 整合语言学信息
10.1 直译
10.1.1 数字和名字
10.1.2 名字翻译
10.1.3 直译的有限状态方法
10.1.4 资源
10.1.5 反向直译与翻译
10.2 形态学
10.2.1 词素
10.2.2 简化丰富的形态变化
10.2.3 翻译形态丰富的语言
10.2.4 单词拆分
10.3 句法重构
10.3.1 基于输入语言句法的调序
10.3.2 学习调序规则
10.3.3 基于词性标记的调序
10.3.4 基于句法树的调序
10.3.5 预留选择
10.4 句法特征
10.4.1 方法论
10.4.2 数的一致性
10.4.3 一致性
10.4.4 句法分析概率
10.5 因子化翻译模型
10.5.1 因子化翻译的分解
10.5.2 因子化模型训练
10.5.3 模块的融合
10.5.4 高效解码
10.6 小结
10.6.1 核心概念
10.6.2 延伸阅读
10.6.3 习题
第11章 基于树的翻译模型
11.1 同步文法
11.1.1 短语结构语法
11.1.2 同步短语结构语法
11.1.3 同步树替换文法
11.2 同步文法的学习
11.2.1 层次短语模型的学习
11.2.2 句法翻译规则的学习
11.2.3 规则的简化
11.2.4 文法规则的打分
11.3 基于句法分析算法的解码
11.3.1 线图分析
11.3.2 核心算法
11.3.3 线图的组织
11.3.4 假设重组
11.3.5 栈剪枝
11.3.6 文法规则的使用
11.3.7 立方剪枝
11.3.8 文法二叉化
11.3.9 外向代价估计
11.4 小结
11.4.1 核心概念
11.4.2 延伸阅读
11.4.3 习题
参考文献
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计机器翻译
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据分析的道与术
第一篇 道	1
第1章 大数据分析之道	2
1．1 做好数据分析的关键	3
1．2 业务调研	10
1．3 创新思考	14
1．4 逻辑推理	25
1．5 可行建议	48
1．6 补充阅读：数据分析报告的撰写要点	51
第二篇 术	63
第2章 统计是怎么发明的？	64
2．1 重启思维模式	65
2．2 统计的意义及指标	71
2．3 统计图形是如何设计的？	102
第3章 我们能相信统计吗？	115
3．1 统计可信吗？	116
3．2 基于概率的信任	120
3．3 如何实现基于概率的信任？	126
3．4 应用理念：细致与置信的权衡之道	140
3．5 评估：正确的认识世界	144
3．6 设计统计方案中的方法论	156
第4章 统计分析方法	159
4．1 拆指标-1 分布分析	161
4．2 拆指标-2 趋势分析	165
4．3 拆指标-3 因素分析	177
4．4 拆数据-1 个案分析	186
4．5 拆数据-2 异常分析	188
4．6 拆数据-3 分组分析	193
4．7 附加阅读：消费者偏好和企业差异化战略	197
4．8 不同分析方法的结合与创新	209
4．9 与领域相关的分析方法	213
第5章 数据分析的高级工具：OLAP与机器学习	220
5．1 OLAP技术	221
5．2 无监督学习模型	225
5．3 监督学习模型	234
第三篇 释	287
第6章 大数据时代	288
6．1 大数据的价值	289
6．2 企业如何向数据技术转型？	301
6．3 数据技术的职业发展	315
第7章 数据技术团队组建和发展	331
7．1 自我修炼与领导团队	332
7．2 数据技术团队的组织结构	334
7．3 数据技术团队发展中的优劣势	336
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据分析的道与术
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络在应用科学和工程中的应用
译者序
前言
致谢
作者简介
第1章  从数据到模型：理解生物学、生态学和自然系统的复杂性和挑战
1.1　概述
1.2　本书安排
参考文献
第2章　神经网络基础和线性数据分析模型
2.1　概述
2.2　神经网络及其能力
2.3　生物学的启示
2.4　神经元信息处理的建模
2.5　神经元模型和学习策略
2.5.1　作为一个简单分类器的阈值神经元
2.5.2　神经元和神经集合的学习模型
2.5.2.1　Hebbian学习
2.5.2.2　无监督学习或竞争学习
2.5.2.3　有监督学习
2.5.3　作为分类器的有监督学习的感知器
2.5.3.1　感知器学习算法
2.5.3.2　基于大量现实数据集的感知器实例：根据测定的成长年轮直径辨识鱼的起源
2.5.3.3　统计学中带有线性判别函数分析的感知器比较
2.5.3.4　多种类分类中的多输出感知器
2.5.3.5　使用感知器的高维分类
2.5.3.6　感知器小结
2.5.4　用于线性分类和预报的线性神经元
2.5.4.1　利用delta规则的学习
2.5.4.2　作为分类器的线性神经元
2.5.4.3　作为预报能力子集的线性神经元的分类属性
2.5.4.4　实例：作为预报器的线性神经元
2.5.4.5　线性预报的实例：预报一个家庭的热流
2.5.4.6　线性神经元模型与线性回归的比较
2.5.4.7  实例：多输入线性神经元模型——提高一个家庭的热流预报精确度
2.5.4.8　一个多输入线性神经元与多重线性回归的比较
2.5.4.9　多线性神经元模型
2.5.4.10　多重线性神经网络与正则相关性分析的比较
2.5.4.11　线性神经元和线性网络小结
2.6　小结
习题
参考文献
第3章　用于非线性模式识别的神经网络
3.1　概述
3.2　非线性神经元
3.2.1　神经元激励函数
3.2.1.1 S形函数
3.2.1.2高斯函数
3.2.2　实例：利用非线性神经元对人口增长建模
3.2.3　非线性神经元与非线性回归分析的比较
3.3　单输入多层非线性网络
3.3.1　用单一非线性隐含层神经元处理
3.3.2　实例：用多非线性神经元建立循环现象模型
3.3.2.1　实例1：逼近一个方波
3.3.2.2　实例2：为物种的季节性迁移建立模型
3.4　两输入的多层感知器网络
3.4.1　用非线性神经元处理二维输入
3.4.2　网络输出
3.4.3　实例：二维预报和分类
3.4.3.1　实例1：二维非线性函数逼近
3.4.3.2　实例2：二维非线性分类模型
3.5　用非线性多层感知器网络为多维数据建模
3.6　小结
习题
参考文献
第4章　神经网络对非线性模式的学习
4.1　概述
4.2　非线性模式识别中网络的监督训练
4.3　梯度下降法和误差最小化
4.4　BP学习
4.4.1　实例：BP训练——手工计算
……
第5章　从数据中抽取可靠模式的神经网络模型的实现
第6章　数据探测、维数约简和特征提取
第7章　使用贝叶斯统计的神经网络模型的不确定性评估
第8章　应用自组织映射的方法发现数据中的未知聚类
第9章　神经网络在时间序列预测中的应用
附录
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>神经网络在应用科学和工程中的应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘教程
第一部分  导论
第一章  概述
第二章  相关概念
第三章  数据挖掘技术
第二部分  核心课题
第四章  分类
第五章  聚类
第六章  关联规则
第三部分  高级课题
第七章  Web挖掘
第八章  空间数据挖掘
第九章  时序数据挖掘
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘教程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>实用数据分析
译者序
序
前言
评审者简介
致谢
第1章　开始  1
1.1　计算机科学  1
1.2　人工智能  1
1.3　机器学习  2
1.4　统计学  2
1.5　数学  2
1.6　专业领域知识  2
1.7　数据、信息和知识  3
1.8　数据的本质  3
1.9　数据分析过程  4
1.9.1　问题  5
1.9.2　数据准备  5
1.9.3　数据探索  5
1.9.4　预测建模  6
1.9.5　结果可视化  6
1.10　定量与定性数据分析  7
1.11　数据可视化的重要性  7
1.12　大数据  8
1.12.1　传感器和摄像头  9
1.12.2　社会化网络分析  10
1.12.3　本书的工具和练习  11
1.12.4　为什么使用Python  11
1.12.5　为什么使用mlpy  11
1.12.6　为什么使用D3.js  12
1.12.7　为什么使用MongoDB  12
1.13　小结  12
第2章　数据准备与处理  13
2.1　数据源  13
2.1.1　开源数据  14
2.1.2　文本文件  14
2.1.3　Excel文件  15
2.1.4　SQL数据库  15
2.1.5　NoSQL数据库  16
2.1.6　多媒体  17
2.1.7　网页检索  17
2.2　数据清洗  19
2.2.1　统计方法  20
2.2.2　文本解析  20
2.2.3　数据转化  21
2.3　数据格式  22
2.3.1　CSV   22
2.3.2　JSON  24
2.3.3　XML  25
2.3.4　YAML  26
2.4　开始使用OpenRefine工具  27
2.4.1　Text facet  27
2.4.2　聚类  27
2.4.3　文件过滤器  28
2.4.4　numeric facet  29
2.4.5　数据转化  29
2.4.6　数据输出  30
2.4.7　处理历史  31
2.5　小结  31
第3章　数据可视化  32
3.1　数据导向文件  32
3.1.1　HTML  33
3.1.2　DOM  33
3.1.3　CSS  34
3.1.4　JavaScript  34
3.1.5　SVG  34
3.2　开始使用D3.js  34
3.2.1　柱状图  35
3.2.2　饼图  39
3.2.3　散点图  41
3.2.4　单线图  43
3.2.5　多线图  46
3.3　交互与动画  49
3.4　小结  52
第4章　文本分类  53
4.1　学习和分类  53
4.2　贝叶斯分类  54
4.3　E-mail主题测试器  55
4.4　数据  56
4.5　算法  57
4.6　分类器的准确性  61
4.7　小结  62
第5章　基于相似性的图像检索  63
5.1　图像相似性搜索  63
5.2　动态时间规整  64
5.3　处理图像数据集  65
5.4　执行DTW  66
5.5　结果分析  68
5.6　小结  70
第6章　模拟股票价格  71
6.1　金融时间序列  71
6.2　随机游走模拟  72
6.3　蒙特•卡罗方法  73
6.4　生成随机数  73
6.5　用D3.js实现  74
6.6　小结  80
第7章　预测黄金价格  82
7.1　处理时间序列数据  82
7.2　平滑时间序列  85
7.3　数据——历史黄金价格  87
7.4　非线性回归  88
7.4.1　核岭回归  88
7.4.2　平滑黄金价格时间序列  90
7.4.3　平滑时间序列的预测  91
7.4.4　对比预测值  92
7.5　小结  93
第8章　使用支持向量机的方法进行分析  94
8.1　理解多变量数据集  94
8.2　降维  97
8.2.1　线性无差别分析  98
8.2.2　主成分分析  98
8.3　使用支持向量机  100
8.3.1　核函数  101
8.3.2　双螺旋问题  101
8.3.3　在mlpy中执行SVM  102
8.4　小结  105
第9章　应用细胞自动机的方法对传染病进行建模  106
9.1　流行病学简介  106
9.2　流行病模型  108
9.2.1　SIR模型  108
9.2.2　使用SciPy来解决SIR模型的常微分方程  108
9.2.3　SIRS模型  110
9.3　对细胞自动机进行建模  111
9.3.1　细胞、状态、网格和邻域  111
9.3.2　整体随机访问模型  111
9.4　通过D3.js模拟CA中的SIRS模型  112
9.5　小结  120
第10章　应用社会化图谱  121
10.1　图谱的结构  121
10.1.1　间接图谱  121
10.1.2　直接图谱  122
10.2　社会化网络分析  122
10.3　捕获Facebook图谱  123
10.4　使用Gephi对图谱进行再现  126
10.5　统计分析  128
10.6　度的分布  129
10.6.1　图谱直方图  130
10.6.2　集中度  131
10.7　将GDF转化为JSON  133
10.8　在D3.js环境下进行图谱可视化  135
10.9　小结  139
第11章　对Twitter数据进行情感分析  140
11.1　解析Twitter数据  140
11.1.1　tweet  140
11.1.2　粉丝  141
11.1.3　热门话题  141
11.2　使用OAuth访问API  142
11.3　开始使用Twython  143
11.3.1　简单查询  144
11.3.2　处理时间表  147
11.3.3　处理粉丝  149
11.3.4　处理地点和趋势信息  151
11.4　情感分类  153
11.4.1　ANEW  154
11.4.2　语料库  154
11.5　使用NLTK  155
11.5.1　单词包  156
11.5.2　朴素贝叶斯  156
11.5.3　tweet的情感分析  158
11.6　小结  159
第12章　使用MongoDB进行数据处理和聚合  160
12.1　开始使用MongoDB  160
12.1.1　数据库  161
12.1.2　集合  161
12.1.3　文件  162
12.1.4　Mongo shell  162
12.1.5　Insert/Update/Delete  163
12.1.6　Queries查询  163
12.2　数据准备  165
12.2.1　使用OpenRefine进行数据转换  165
12.2.2　通过PyMongo来插入文件  167
12.3　分组  169
12.4　聚合框架  172
12.4.1　流水线  173
12.4.2　表达式  174
12.5　小结  175
第13章　使用MapReduce方法  176
13.1　MapReduce概述  176
13.2　编程模型  177
13.3　在MongoDB中使用MapReduce  178
13.3.1　map函数  178
13.3.2　reduce函数  178
13.3.3　使用Mongo shell  179
13.3.4　使用UMongo  180
13.3.5　使用PyMongo  182
13.4　过滤输入集合  184
13.5　分组和聚合  184
13.6　文字云对tweet中最常见的积极词汇进行可视化  186
13.7　小结  191
第14章　使用IPython和Wakari进行在线数据分析  192
14.1　开始使用Wakari  192
14.2　开始使用IPython记事本  195
14.3　通过PIL进行图像处理简介  197
14.3.1　打开一个图像  197
14.3.2　图像直方图  198
14.3.3　过滤  198
14.3.4　操作  200
14.3.5　转化  201
14.4　使用Pandas  202
14.4.1　处理时间序列  202
14.4.2　通过数据框架来操作多变量数据集  206
14.4.3　分组、聚合和相关  208
14.5　使用IPython进行多机处理  211
14.6　分享你的记事本  212
14.7　小结  214
附录　环境搭建  215
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>实用数据分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>第一本无人驾驶技术书
1    无人车：正在开始的未来	1
1.1  正在走来的无人驾驶	2
1.2  自动驾驶的分级	4
1.3  无人驾驶系统简介	7
1.4  序幕刚启	18
1.5  参考资料	18
2    光学雷达在无人驾驶技术中的应用	21
2.1  无人驾驶技术简介	21
2.2  光学雷达基础知识	22
2.3  LiDAR在无人驾驶技术中的应用领域	24
2.4  LiDAR技术面临的挑战	26
2.5  展望未来	28
2.6  参考资料	28
3    GPS及惯性传感器在无人驾驶中的应用	30
3.1  无人驾驶定位技术	30
3.2  GPS简介	31
3.3  惯性传感器简介	34
3.4  GPS和惯性传感器的融合	36
3.5  结论	37
3.6  参考资料	38
4    基于计算机视觉的无人驾驶感知系统	39
4.1  无人驾驶的感知	39
4.3  计算机视觉能帮助无人车辆解决的问题	42
4.4  Optical Flow和立体视觉	43
4.5  物体的识别与追踪	45
4.6  视觉里程计算法	47
4.7  结论	48
4.8  参考资料	49
5    卷积神经网络在无人驾驶中的应用	50
5.1  CNN简介	50
5.2  无人驾驶双目3D感知	51
5.3  无人驾驶物体检测	54
5.4  结论	59
5.5  参考资料	59
6    增强学习在无人驾驶中的应用	61
6.1  增强学习的简介	61
6.2  增强学习算法	63
6.3  使用增强学习帮助决策	68
6.4  无人驾驶的决策介绍	70
6.5  参考资料	74
7    无人驾驶的规划与控制	75
7.1  规划与控制简介	75
7.2  路由寻径	77
7.3  行为决策	84
7.4  动作规划	93
7.5  反馈控制	102
7.6  无人车规划控制结语	105
7.7  参考资料	106
8    基于ROS的无人驾驶系统	108
8.1  无人驾驶：多种技术的集成	108
8.2  机器人操作系统（ROS）简介	110
8.3  系统可靠性	115
8.4  系统通信性能提升	116
8.5  系统资源管理与安全性	117
8.6  结论	118
8.7  参考资料	118
9    无人驾驶的硬件平台	120
9.1  无人驾驶：复杂系统	120
9.2  传感器平台	121
9.3  计算平台	140
9.4  控制平台	150
9.5  结论	157
9.6  参考资料	158
10    无人驾驶系统安全	160
10.1  针对无人驾驶的安全威胁	160
10.2  无人驾驶传感器的安全	161
10.3  无人驾驶操作系统的安全	162
10.4  无人驾驶控制系统的安全	163
10.5  车联网通信系统的安全性	165
10.6  安全模型校验方法	168
10.7  参考资料	169
11    基于Spark与ROS的分布式无人驾驶模拟平台	171
11.1  无人驾驶模拟技术	171
11.2  基于ROS的无人驾驶模拟器	173
11.3  基于Spark的分布式的模拟平台	175
11.4  结论	178
11.5  参考资料	178
12    无人驾驶中的高精地图	180
12.1  电子地图分类	180
12.2  高精地图的特点	183
12.3  高精地图的生产	185
12.4  无人驾驶场景中的应用	188
12.5  高精地图的现状与结论	190
12.6  参考资料	191
13    无人驾驶的未来	192
13.1  无人驾驶的商业前景	192
13.2  无人驾驶汽车面临的障碍	194
13.3  无人驾驶产业	198
13.4  全球化下的无人驾驶	203
13.5  无人驾驶发展对策	205
13.6  可预见的未来	207
13.7  参考资料	208
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>第一本无人驾驶技术书
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>多元统计分析导论
.习题 　　　 78
第 4 章 样本相关系数的分布和利用 　84
4.1 引言　　84
4.2 二元变量样本的相关系数 　　　 85
4.3 偏相关系数, 条件分布 　　98
4.4 多重相关系数 　　 104
4.5 椭球等高分布 　　 114
习题 　　118
第 5 章 广义 t2 统计量　　 124
5.1 引言 　　　124
5.2 广义 t2 统计量的推导及分布 　 124
5.3 t2 统计量的应用 　 129
5.4 备择假设下 t2 的分布, 功效函数　 135
5.5 协方差阵不等时的两样本问题　 136
5.6 t2 检验的一些最优性质 　　　 139
5.7 椭球等高分布 　　 146
习题 　147
第 6 章 观察值的分类　　 151
6.1 分类问题 　　151
6.2 精确分类的标准 　 151
6.3 概率分布已知的两总体的判别 　 154
6.4 两多元正态总体的判别 　　157
6.5 具有估计参数的两多元正态总体的判别 　　160
6.6 误判概率 　　165
6.7 多总体的分类 　170
6.8 多个多元正态总体的分类 　173
6.9 多个多元正态总体分类的一个例子 　　175
6.10 具有不同协方差阵的两多元正态总体的分类　　 177
习题 　182
第 7 章 样本协方差阵和样本广义方差的分布 　　　184
7.1 引言 　　　184
7.2 wishart 分布　184
7.3 wishart 分布的一些性质 　189
7.4 cochran 定理 　　 192
7.5 广义方差 　　194
7.6 总体协方差阵为对角矩阵时相关系数集的分布 　　198
7.7 逆 wishart 分布, 协方差阵的贝叶斯估计 　　200
7.8 协方差阵的改进估计　　　203
7.9 椭球等高分布 　　 208
习题 　210
第 8 章 一般的线性假设检验, 多元方差分析 　　　　 215
8.1 引言 　　　215
8.2 多元线性回归中的参数估计 　　 216
8.3 关于回归系数线性假设检验的似然比准则　220
8.4 假设成立时似然比准则的分布 225
8.5 似然比准则的分布的渐近展开 234
8.6 检验线性假设的其他准则 　　242
8.7 关于回归系数矩阵和置信区域的假设检验　　251
8.8 具有相同协方差阵的几个正态分布均值相等的检验　　　254
8.9 多元方差分析 　　 258
8.10 检验的一些最优性质 　　263
8.11 椭球等高分布 　　 276
习题 　279
第 9 章 检验变量集间的独立性　　285
9.1 引言 　　　285
9.2 变量集独立性检验的似然比准则 　 285
9.3 当原假设为真时似然比准则的分布 　　　289
9.4 似然比准则的分布的渐近展开 292
9.5 其他准则 　　293
9.6 逐步下降法　　　 294
9.7 例子 　　　297
9.8 两个变量集的情形 　　　298
9.9 似然比检验的容许性　　　　301
9.10 子集间独立性检验的功效函数的单调性 　302
9.11 椭球等高分布 　　 304
习题 　307
第 10 章 协方差阵相等以及均值向量和协方差阵均相等的假设检验 　　309
10.1 引言 　　309
10.2 检验几个协方差阵相等的准则 　　309
10.3 检验几个正态分布相等的准则 　　　311
10.4 准则的分布　　313
10.5 准则的分布的渐近展开 　　319
10.6 两个总体的情形　 321
10.7 检验协方差阵与给定矩阵成正比的假设; 球形检验 　　325
10.8 检验一个协方差阵等于一个给定的矩阵的假设　　　329
10.9 检验均值向量和协方差阵分别等于给定的向量和矩阵的假设 　　　334
10.10 检验的容许性 　　336
10.11 椭球等高分布族 　339
习题 　342
第 11 章 主成分 　　346
11.1 引言 　　　　 346
11.2 总体中主成分的定义 　　347
11.3 主成分和它们的方差的极大似然估计　　　352
11.4 主成分的极大似然估计的计算 　　　353
11.5 例子 　　　　 355
11.6 统计推断 　　　 357
11.7 关于协方差阵的特征根的假设检验　　　 360
12 目 录
11.8 椭球等高分布 　　 363
习题 　364
第 12 章 典型相关和典型变量 　367
12.1 引言 　　 367
12.2 总体的典型相关和典型变量 　　　　 368
12.3 典型相关和典型变量的估计 　　　　 376
12.4 统计推断 　　　 379
12.5 一个例子 　　　 381
12.6 线性相关期望值 383
12.7 降秩回归 　　　 387
12.8 联立方程模型 　　 388
习题 　396
第 13 章 特征根和特征向量的分布 　398
13.1 引言 　　　　 398
13.2 两个 wishart 矩阵的情况 　　　　 398
13.3 一个非奇异 wishart 矩阵的情况　　　 405
13.4 典型相关 　　　 409
13.5 有一个 wishart 矩阵情况下的渐近分布 　410
13.6 有两个 wishart 矩阵情况下的渐近分布 　413
13.7 一个回归模型下的渐近分布 　　　　 417
13.8 椭球等高分布 　　 424
习题 　427
第 14 章 因子分析 　　　 428
14.1 引言 　　　　 428
14.2 模型 　　　　 428
14.3 随机正交因子的极大似然估计量 　　　　 433
14.4 不变因子的估计 441
14.5 因子的解释和变换 　　　442
14.6 指定零识别的估计 　　　　 444
14.7 因子得分的估计 445
习题 　446
第 15 章 相依性模式, 图模型 　　447
15.1 引言 　　　　 447
15.2 无向图 　　448
15.3 有向图 　　453
15.4 链图 　　　　458
15.5 统计推断 　　　460
附录 a 矩阵理论 　　469
a.1 矩阵和矩阵运算的定义 　　469
a.2 特征根和特征向量 　　473
a.3 分块向量和分块矩阵　　　476
a.4 其他方面的一些结果　　　479
a.5 gram-schmidt 正交化和线性方程组的解 　　484
附录 b 表 　　487
参考文献 　　525
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>多元统计分析导论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于R应用的统计学丛书·应用回归及分类
第一章 引言
第二章 经典线性回归
第三章 广义线性模型
第四章 纵向数据及分层模型
第五章 机器学习回归方法
第六章 生存分析及Cox模型
第七章 经典分类：判别分析
第八章 机器学习分类方法
附录 练习：熟练使用R软件
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>基于R应用的统计学丛书·应用回归及分类
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学与大数据分析
第1章 大数据分析介绍 1
1.1 大数据概述 2
1.1.1 数据结构 4
1.1.2 数据存储的分析视角 9
1.2 分析的实践状态 10
1.2.1 商业智能 VS 数据科学 11
1.2.2 当前分析架构 12
1.2.3 大数据的驱动力 14
1.2.4 新的大数据生态系统和新的分析方法 15
1.3 新的大数据生态系统中的关键角色 17
1.4 大数据分析案例 20
1.5 总结 21
1.6 练习 21
参考书目 21
第2章 数据分析生命周期 23
2.1 数据分析生命周期概述 24
2.1.1 一个成功分析项目的关键角色 24
2.1.2 数据分析生命周期的背景和概述 26
2.2 第1阶段：发现 28
2.2.1 学习业务领域 29
2.2.2 资源 29
2.2.3 设定问题 30
2.2.4 确定关键利益相关者 30
2.2.5 采访分析发起人 31
2.2.6 形成初始假设 32
2.2.7 明确潜在数据源 32
2.3 第2阶段：数据准备 33
2.3.1 准备分析沙箱 34
2.3.2 执行ETLT 35
2.3.3 研究数据 36
2.3.4 数据治理 37
2.3.5 调查和可视化 37
2.3.6 数据准备阶段的常用工具 38
2.4 第3阶段：模型规划 39
2.4.1 数据探索和变量选择 40
2.4.2 模型的选择 41
2.4.3 模型设计阶段的常用工具 42
2.5 第4阶段：模型建立 42
2.5.1 模型构建阶段中的常用工具 44
2.6 第5阶段：沟通结果 45
2.7 第6阶段：实施 46
2.8 案例研究：全球创新网络和分析（GINA） 49
2.8.1 第1阶段：发现 50
2.8.2 第2阶段：数据准备 51
2.8.3 第3阶段：模型规划 51
2.8.4 第4阶段：模型建立 51
2.8.5 第5阶段：沟通结果 53
2.8.6 第6阶段：实施 54
2.9 总结 55
2.10 练习 55
参考书目 55
第3章 使用R进行基本数据分析 57
3.1 R简介 58
3.1.1 R图形用户界面 61
3.1.2 数据导入和导出 63
3.1.3 属性和数据类型 64
3.1.4 描述性统计(descriptive statistics) 72
3.2 探索性数据分析 73
3.2.1 在分析之前先可视化 74
3.2.2 脏数据 77
3.2.3 可视化单个变量 80
3.2.4 研究多个变量 83
3.2.5 对比数据探索和数据演示 90
3.3 用于评估的统计方法 92
3.3.1 假设检验 93
3.3.2 均值差异 94
3.3.3 Wilcoxon秩和检验 98
3.3.4 I型和II型错误 99
3.3.5 功效和抽样大小 100
3.3.6 ANOVA 100
3.4 总结 104
3.5 练习 104
参考文献 105
第4章 高级分析理论与方法：聚类 107
4.1 聚类概述 108
4.2 k均值聚类 108
4.2.1 使用案例 109
4.2.2 方法概述 110
4.2.3 确定聚类簇的数量 112
4.2.4 诊断 117
4.2.5 选择原因及注意事项 118
4.3 其他算法 122
4.4 总结 122
4.5 练习 123
参考书目 123
第5章 高级分析理论与方法：关联规则 124
5.1 概述 125
5.2 Apriori算法 127
5.3 评估候选规则 128
5.4 关联规则的应用 129
5.5 杂货店交易示例 130
5.5.1 杂货店数据集 130
5.5.2 生成频繁数据集 132
5.5.3 规则的生成和可视化 137
5.6 验证和测试 143
5.7 诊断 143
5.8 总结 144
5.9 练习 144
参考书目 145
第6章 高级分析理论与方法：回归 147
6.1 线性回归 148
6.1.1 用例 148
6.1.2 模型描述 149
6.1.3 诊断 158
6.2 逻辑回归 163
6.2.1 用例 163
6.2.2 模型描述 163
6.2.3 诊断 165
6.3 选择理由和注意事项 172
6.4 其他回归模型 173
6.5 总结 173
6.6 练习 174
第7章 高级分析理论与方法：分类 175
7.1 决策树 176
7.1.1 决策树概览 177
7.1.2 通用算法 181
7.1.3 决策树算法 185
7.1.4 评估决策树 186
7.1.5 R中的决策树 189
7.2 朴素贝叶斯 193
7.2.1 贝叶斯定理 194
7.2.2 朴素贝叶斯分类器 196
7.2.3 平滑 198
7.2.4 诊断 198
7.2.5 R中的朴素贝叶斯 199
7.3 分类器诊断 204
7.4 其他分类方法 208
7.5 总结 209
7.6 练习 210
参考书目 210
第8章 高级分析理论与方法：时间序列分析 212
8.1 时间序列分析概述 213
8.1.1 Box-Jenkins方法 214
8.2 ARIMA模型 215
8.2.1 自相关函数（ACF） 215
8.2.2 自回归模型 216
8.2.3 移动平均模型 218
8.2.4 ARMA和ARIMA模型 219
8.2.5 建立和评估ARIMA模型 222
8.2.6 选择理由及注意事项 230
8.3 其他方法 230
8.4 总结 231
8.5 练习 231
第9章 高级分析理论与方法：文本分析 232
9.1 文本分析步骤 234
9.2 一个文本分析的示例 235
9.3 收集原始数据 237
9.4 表示文本 240
9.5 词频-逆文档频率（TFIDF） 245
9.6 通过主题来分类文件 249
9.7 情感分析 253
9.8 获得洞察力 258
9.9 总结 263
9.10 练习 263
参考书目 264
第10章 高级分析技术与工具：MapReduce和Hadoop 267
10.1 非结构化数据分析 268
10.1.1 用例 268
10.1.2 MapReduce 270
10.1.3 Apache Hadoop 271
10.2 Hadoop生态系统 277
10.2.1 Pig 278
10.2.2 Hive 279
10.2.3 HBase 282
10.2.4 Mahout 290
10.3 NoSQL 292
10.4 总结 293
10.5 练习 294
参考书目 294
第11章 高级分析技术与工具：数据库内分析 297
11.1 SQL基本要素 298
11.1.1 连接 299
11.1.2 set运算符 301
11.1.3 grouping扩展 303
11.2 数据库内的文本分析 307
11.3 高级SQL技术 311
11.3.1 窗口函数 311
11.3.2 用户定义函数与聚合 315
11.3.3 排序聚合 318
11.3.4 MABlib 319
11.4 总结 323
11.5 练习 323
参考书目 323
第12章 结尾 324
12.1 沟通和实施一个分析项目 325
12.2 创建最终可交付成果 327
12.2.1 为多个受众群体创建核心材料 329
12.2.2 项目目标 330
12.2.3 主要发现 331
12.2.4 方法 333
12.2.5 模型描述 334
12.2.6 有数据支持的关键论点 335
12.2.7 模型细节 336
12.2.8 建议 337
12.2.9 关于最终演示文档的额外提示 338
12.2.10 提供技术规范和代码 339
12.3 数据可视化基础 340
12.3.1 有数据支持的要点 341
12.3.2 图的演进 342
12.3.3 通用表示方法 348
12.3.4 如何清理图形 349
12.3.5 额外考虑 353
12.4 总结 355
12.5 练习 355
12.6 参考文献与扩展阅读 355
参考书目 356
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学与大数据分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Software Design 中文版 01
IT工程师必须知道的最新术语[55]   OpenCloud（Ⅱ）杉山贵章　　001
自己家的服务器机架之推荐篇   机架的电源问题（1）tomocha　　002
新潮数码[175]   GoogleI/O2013开发者大会上出现的数码设备 安藤幸央    005
结城浩的再发现随想[2]   Threshold 结城浩    008
enchant～激发创造力的魔法～[3]   在秋叶原创建NASA清水亮    010
我所偏爱的键盘图鉴[3]   人体工学键盘的最强者：KINESIS Contoured&Maltrondualhand3D 滨野圣人    014
发自秋叶原！创客在行动[33]2013旧金山湾区制汇节见闻坪井义浩    016
特辑1  学习数据分析，从这里开始—Excel·R·Mahout·大数据—
chapter1   献给软件工程师们 数据科学入门及学习指导 柏野雄太    022
chapter2   数据分析入门必备知识① 让数据分析工具助你一臂之力[Excel篇] 高木基成    028
chapter2   数据分析入门必备知识② 让数据分析工具助你一臂之力[R·Mahout篇] 高木基成    038
chapter3   不用数学公式也能学？ 如何掌握机器学习 竹迫良范    046
专栏   机器学习的广泛应用及未来 鹿岛久嗣    052
特辑2  基准测试应用技术
Part1   基准测试的基础[PC篇] 圆藤优沙    056
Part2   基准测试的基础[服务器篇] 藤城拓哉    065
分布式数据库“未来工房”   只使用Riak和Nginx搭建的静态文件服务器 上西康太    076
从小规模工程学习活用Jenkins   第一回真的有必要用程序来做这些吗？ 岛崎聪    086
安全实践鬼手诀   密码的重新思考 铃木弘信    094
菜鸟编程入门开发一个iPhone阅读类应用[3]    准备APP开发需要的图片 GimmiQ    101
如何构建超级系统管理程序[10]   用IntelVT-x构建超级系统管理程序之六用户空间（userland）的I/O模拟 浅田拓也    108
轻松获取文本数据大彻大悟shell脚本[19]   编写CGI脚本(1)——用标准输出向Web服务器传输数据 上田隆一    114
网络虚拟化的陷阱[2]   端点模型的验证——VXLAN、NVGRE、STT、独自扩展问题 伊势幸一    120
Debian热点[5]   Debian7.0“Wheezy”的变化之处 山根秀树    128
红帽波士顿报道[10]   红帽与富士通的关联 小崎资广    132
Ubuntu月报[39]   编译ChromiumOS Ubuntu日本团队    134
Linux内核观光游[16]   Linux3.10新功能——pvpanic 青田直大    138
jus快讯[21]   jus走过的30年历程 法林浩之    144
创造互联网服务未来的人们[24]   探索CyberAgent公司的网络基础设施（前篇） 川添贵生    146
Android 工程师的邀请函[38]   如何发布放心安全的Android应用 谷口岳    148
温故知新 IT的古老传说[24]   6809/OS-9/6829MMU 竹冈尚三    155
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Software Design 中文版 01
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>你不可不知的50个互联网知识
引言
基础
1 互联网
2 万维网
3 互联网接入服务
4 电子邮件
5 个人电脑
6 服务器
7 浏览器
8 标记语言
9 搜索
迈向数字现在
10 Web 2.0
11 网络礼仪
12 博客
13 聚合
14 聊天
15 文件共享
16 流媒体
17 富互联网应用
18 无线网络
19 智能手机
阴暗面
20 恶意软件
21 垃圾信息
22 隐私
23 深网
24 黑客
25 网络战
休闲娱乐
26 社交网站
27 游戏机
28 混搭
29 文化干扰
商务与政务
30 电子商务
31 网络广告
32 分析
33 光学字符识别
34 机器翻译
35 基于位置的服务
36 虚拟商品
37 电子政务
革命性趋势
38 众包
39 自由软件运动
40 数字发行
41 云计算
42 病毒化
塑造数字未来
43 虚拟世界
44 虚拟化身
45 网络中立
46 语义网
47 增强现实
48 技术融合
49 物联网
50 注意力分散
术语表
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>你不可不知的50个互联网知识
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>现代模式识别
第一章 绪论
1.1 概述
1.2 特征矢量和特征空间
1.3 矢量的描述
1.4 正态分布
参考文献
第二章 聚类分析
2.1 聚类分析的概念
2.2 模式相似性测度
2.3 类的定义与类间距离
2.4 准则函数
2.5 聚类的算法
文献简评 应用简介
习题
上机练习
参考文献
第三章 判别域代数界面方程法
3.1 用判别域界面方程分类的概念
3.2 线性判别函数
3.3 判别函数值的鉴别意义、权空间及解空间
3.4 Fisher线性判别
3.5 线性可分条件下判别函数的权矢量算法
3.6 一般情况下的判别函数权矢量算法
3.7 线性规划方法
3.8 线性二分能力
3.9 广义线性判别函数
3. 二次判别函数
3.11 分段线性判别函数
3.12 位势函数分类法
3.13 支持矢量机简介
3.14 小概率机
文献简评 应用简介
习题
上机练习
参考文献
第四章 统计判决
4.1 小误判概率准则判决
4.2 小损失准则判决
4.3 小损失准则
4.4 N—P（Neyman—Pearson）判决
4.5 序贯判决（SPRD）
4.6 Fisher准则判决
4.7 特征数据缺损或被噪声污染下的Bayes判决
4.8 批对象的复合判决
文献简评 应用简介
习题
上机练习
参考文献
第五章 统计决策中的学习与错误率估计
5.1 统计推断概述
5.2 参数估计
5.3 Bayes学习
5.4 概密的窗函数估计法
5.5 有限项正交函数级数逼近法
5.6 用位势函数法逼近Bayes判决函数
5.7 逼近方法求类的后验概率
5.8 统计决策准则下线性判决函数的训练生成
5.9 错误率估计
5. 基于平均损失估计的学习及小误判概率的估计
5.11 无监督估计（盲估计）
5.12 期望化算法
5.13 集成学习
文献简评 应用简介
习题
上机练习
参考文献
第六章 近邻法
6.1 基本的近邻法
6.2 剪辑近邻法
6.3 引入拒绝决策的近邻法
6.4 近邻法中的距离及其实际计算
文献简评 应用简介
习题
参考文献
第七章 特征提取与选择
7.1 概述
7.2 类别可分性判据
7.3 基于可分性判据进行变换的特征提取与选择
7.4 鉴别矢量的提取
7.5 离散K—L变换及其在特征提取与选择中的应用
7.6 独立成分分析
7.7 基于决策界的特征提取
7.8 特征选择中的直接挑选法
7.9 多维尺度分析
文献简评 应用简介
习题
参考文献
第八章 模糊模式识别
8.1 引言
8.2 普通集合与模糊集合
8.3 普通集合上的关系及有关知识
8.4 模糊关系与模糊变换
8.5 模糊度和特征提取与选择
8.6 模糊识别的基本方法
8.7 基于模糊相似矩阵的分类方法
8.8 模糊C—均值聚类算法
8.9 树法模式识别
8. 几何图形的模糊识别
文献简评 应用简介
习题
参考文献
第九章 神经网络在模式识别中的应用
9.1 人工神经网络的基本知识
9.2 前向型人工神经网络
9.3 BP网的性能和学习改进
9.4 Hopfield网络
9.5 神经网络
9.6 自适应共振理论神经网络
9.7 自组织特征映射神经网络
9.8 模糊神经网络
9.9 概率神经网络
9. RCE神经网络
文献简评 应用简介
习题
上机练习
参考文献
第十章 信息融合
.1 概述
.2 融合技术层次性及融合系统功能模块和结构
.3 关于信息融合的熵理论
.4 观测不相关的分布式小损失准则下的检测与决策融合
.5 观测相关的决策融合
.6 N—P准则下的决策融合
.7 分布式检测决策融合全局优概述及某些约束条件下优解
.8 D—S证据理论的融合算法
文献简评 应用简介
习题
参考文献
第十一章 结构模式识别
11.1 结构模式识别概述
11.2 形式语言
11.3 高维文法与文法
11.4 模式的描述
11.5 句法分析
11.6 文法推断
文献简评 应用简介
习题
参考文献
第十二章 智能化方法
12.1 人工智能
12.2 专家系统
12.3 知识的表示
12.4 智能推理技术
12.5 不确定性推理
文献简评 应用简介
习题
参考文献
第十三章 树分类器
13.1 树分类器原理
13.2 树分类器的设计原则
13.3 树分类器的关键技术
13.4 决策树生成算法
文献简评 应用简介
习题
上机练习
参考文献
第十四章 支持矢量机
14.1 优化的分析方法原理
14.2 优分类界面
14.3 广义优分类界面
14.4 优界面与广义优界面分类性能的统计特性
14.5 支持矢量机（SVM）
14.6 基于Adaboost的SVM组合
文献简评 应用简介
习题
参考文献
第十五章 基于隐马尔可夫模型识别方法
15.1 一阶马尔可夫模型（MM）
15.2 一阶隐马尔可夫模型（HMM）
15.3 可见序列概率估计
15.4 隐状态估计
15.5 模型参数估计
15.6 隐马尔可夫模型方法模式识别
文献简评 应用简介
习题
参考文献
第十六章 子空间模式识别方法
16.1 概述
16.2 子空间投影
16.3 子空间判别法
16.4 线性回归模型法
16.5 正交子空间法
16.6 Kohonen学习子空间法
16.7 子空间的平均学习法
文献简评 应用简介
习题
参考文献
第十七章 机器统计学习理论
17.1 机器统计学习理论概述
17.2 经验风险小化设计
17.3 经验风险小化原则的一致性条件
17.4 优指示函数判决风险的界
17.5 训练序列的长度和识别率估计精度的关系
17.6 结构风险小化
文献简评 应用简介
习题
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>现代模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习:方法及应用
目录
译者序
原书序
1引言
1.1深度学习的定义与背景
1.2本书的结构安排
2深度学习的历史
3三类深度学习网络
3.1三元分类方式
3.2无监督和生成式学习深度网络
3.3监督学习深度网络
3.4混合深度网络
4深度自编码器——一种无监督学习方法
4.1引言
4.2利用深度自编码器来提取语音特征
4.3堆叠式去噪自编码器
4.4转换自编码器
5预训练的深度神经网络——一种混合方法
5.1受限玻尔兹曼机
5.2无监督逐层预训练
5.3DNN和HMM结合
6深度堆叠网络及其变形——有监督学习
6.1简介
6.2深度堆叠网络的基本结构
6.3一种学习DSN权值的方法
6.4张量深度堆叠网络
6.5核化深度堆叠网络
7语音和音频处理中的应用
7.1语音识别中声学模型的建立
7.2语音合成
7.3音频和音乐处理
8在语言模型和自然语言处理中的相关应用
8.1语言模型
8.2自然语言处理
9信息检索领域中的应用
9.1信息检索简介
9.2用基于深度自编码器的语义哈希方法对文档进行索引和检索
9.3文档检索中的深度结构语义模型
9.4信息检索中深度堆叠网络的应用
10在目标识别和计算机视觉中的应用
10.1无监督或生成特征学习
10.2有监督特征学习和分类
11多模态和多任务学习中的典型应用
11.1多模态：文本和图像
11.2多模态：语音和图像
11.3在语音、自然语言处理或者图像领域的多任务学习
12结论
附录
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习:方法及应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据分析实战
第1章　数据分析简介　　1
1.1　数据分析　　1
1.2　数据分析师的知识范畴　　2
1.2.1　计算机科学　　2
1.2.2　数学和统计学　　3
1.2.3　机器学习和人工智能　　3
1.2.4　数据来源领域　　3
1.3　理解数据的性质　　4
1.3.1　数据到信息的转变　　4
1.3.2　信息到知识的转变　　4
1.3.3　数据的类型　　4
1.4　数据分析过程　　4
1.4.1　问题定义　　5
1.4.2　数据抽取　　6
1.4.3　数据准备　　6
1.4.4　数据探索和可视化　　7
1.4.5　预测模型　　7
1.4.6　模型评估　　8
1.4.7　部署　　8
1.5　定量和定性数据分析　　9
1.6　开放数据　　9
1.7　Python和数据分析　　11
1.8　结论　　11
第2章　Python世界简介　　12
2.1　Python——编程语言　　12
2.2　Python——解释器　　13
2.2.1　Cython　　14
2.2.2　Jython　　14
2.2.3　PyPy　　14
2.3　Python 2和Python 3　　14
2.4　安装Python　　15
2.5　Python发行版　　15
2.5.1　Anaconda　　15
2.5.2　Enthought Canopy　　16
2.5.3　Python(x,y)　　17
2.6　使用Python　　17
2.6.1　Python shell　　17
2.6.2　运行完整的Python程序　　17
2.6.3　使用IDE编写代码　　18
2.6.4　跟Python交互　　18
2.7　编写Python代码　　18
2.7.1　数学运算　　18
2.7.2　导入新的库和函数　　19
2.7.3　函数式编程　　21
2.7.4　缩进　　22
2.8　IPython　　23
2.8.1　IPython shell　　23
2.8.2　IPython Qt-Console　　24
2.9　PyPI仓库——Python包索引　　25
2.10　多种Python IDE　　26
2.10.1　IDLE　　26
2.10.2　Spyder　　27
2.10.3　Eclipse（pyDev）　　27
2.10.4　Sublime　　28
2.10.5　Liclipse　　29
2.10.6　NinjaIDE　　29
2.10.7　Komodo IDE　　29
2.11　SciPy　　30
2.11.1　NumPy　　30
2.11.2　pandas　　30
2.11.3　matplotlib　　31
2.12　小结　　31
第3章　NumPy库　　32
3.1　NumPy简史　　32
3.2　NumPy安装　　32
3.3　ndarray：NumPy库的心脏　　33
3.3.1　创建数组　　34
3.3.2　数据类型　　34
3.3.3　dtype选项　　35
3.3.4　自带的数组创建方法　　36
3.4　基本操作　　37
3.4.1　算术运算符　　37
3.4.2　矩阵积　　38
3.4.3　自增和自减运算符　　39
3.4.4　通用函数　　40
3.4.5　聚合函数　　40
3.5　索引机制、切片和迭代方法　　41
3.5.1　索引机制　　41
3.5.2　切片操作　　42
3.5.3　数组迭代　　43
3.6　条件和布尔数组　　45
3.7　形状变换　　45
3.8　数组操作　　46
3.8.1　连接数组　　46
3.8.2　数组切分　　47
3.9　常用概念　　49
3.9.1　对象的副本或视图　　49
3.9.2　向量化　　50
3.9.3　广播机制　　50
3.10　结构化数组　　52
3.11　数组数据文件的读写　　53
3.11.1　二进制文件的读写　　54
3.11.2　读取文件中的列表形式数据　　54
3.12　小结　　55
第4章　pandas库简介　　56
4.1　pandas：Python数据分析库　　56
4.2　安装　　57
4.2.1　用Anaconda安装　　57
4.2.2　用PyPI安装　　58
4.2.3　在Linux系统的安装方法　　58
4.2.4　用源代码安装　　58
4.2.5　Windows模块仓库　　59
4.3　测试pandas是否安装成功　　59
4.4　开始pandas之旅　　59
4.5　pandas数据结构简介　　60
4.5.1　Series对象　　60
4.5.2　DataFrame对象　　66
4.5.3　Index对象　　72
4.6　索引对象的其他功能　　74
4.6.1　更换索引　　74
4.6.2　删除　　75
4.6.3　算术和数据对齐　　77
4.7　数据结构之间的运算　　78
4.7.1　灵活的算术运算方法　　78
4.7.2　DataFrame和Series对象之间的运算　　78
4.8　函数应用和映射　　79
4.8.1　操作元素的函数　　79
4.8.2　按行或列执行操作的函数　　80
4.8.3　统计函数　　81
4.9　排序和排位次　　81
4.10　相关性和协方差　　84
4.11　NaN数据　　85
4.11.1　为元素赋NaN值　　85
4.11.2　过滤NaN　　86
4.11.3　为NaN元素填充其他值　　86
4.12　等级索引和分级　　87
4.12.1　重新调整顺序和为层级排序　　89
4.12.2　按层级统计数据　　89
4.13　小结　　90
第5章　pandas：数据读写　　91
5.1　I/O API 工具　　91
5.2　CSV和文本文件　　92
5.3　读取CSV或文本文件中的数据　　92
5.3.1　用RegExp解析TXT文件　　94
5.3.2　从TXT文件读取部分数据　　96
5.3.3　往CSV文件写入数据　　97
5.4　读写HTML文件　　98
5.4.1　写入数据到HTML文件　　99
5.4.2　从HTML文件读取数据　　100
5.5　从XML读取数据　　101
5.6　读写Microsoft Excel文件　　103
5.7　JSON数据　　105
5.8　HDF5格式　　107
5.9　pickle——Python对象序列化　　108
5.9.1　用cPickle实现Python对象序列化　　109
5.9.2　用pandas实现对象序列化　　109
5.10　对接数据库　　110
5.10.1　SQLite3数据读写　　111
5.10.2　PostgreSQL数据读写　　112
5.11　NoSQL数据库MongoDB数据读写　　114
5.12　小结　　116
第6章　深入pandas：数据处理　　117
6.1　数据准备　　117
6.2　拼接　　122
6.2.1　组合　　124
6.2.2　轴向旋转　　125
6.2.3　删除　　127
6.3　数据转换　　128
6.3.1　删除重复元素　　128
6.3.2　映射　　129
6.4　离散化和面元划分　　132
6.5　排序　　136
6.6　字符串处理　　137
6.6.1　内置的字符串处理方法　　137
6.6.2　正则表达式　　139
6.7　数据聚合　　140
6.7.1　GroupBy　　141
6.7.2　实例　　141
6.7.3　等级分组　　142
6.8　组迭代　　143
6.8.1　链式转换　　144
6.8.2　分组函数　　145
6.9　高级数据聚合　　145
6.10　小结　　148
第7章　用matplotlib实现数据可视化　　149
7.1　matplotlib库　　149
7.2　安装　　150
7.3　IPython和IPython QtConsole　　150
7.4　matplotlib架构　　151
7.4.1　Backend层　　152
7.4.2　Artist层　　152
7.4.3　Scripting层（pyplot）　　153
7.4.4　pylab和pyplot　　153
7.5　pyplot　　154
7.5.1　生成一幅简单的交互式图表　　154
7.5.2　设置图形的属性　　156
7.5.3　matplotlib和NumPy　　158
7.6　使用kwargs　　160
7.7　为图表添加更多元素　　162
7.7.1　添加文本　　162
7.7.2　添加网格　　165
7.7.3　添加图例　　166
7.8　保存图表　　168
7.8.1　保存代码　　169
7.8.2　将会话转换为HTML文件　　170
7.8.3　将图表直接保存为图片　　171
7.9　处理日期值　　171
7.10　图表类型　　173
7.11　线性图　　173
7.12　直方图　　180
7.13　条状图　　181
7.13.1　水平条状图　　183
7.13.2　多序列条状图　　184
7.13.3　为pandas DataFrame生成多序列条状图　　185
7.13.4　多序列堆积条状图　　186
7.13.5　为pandas DataFrame绘制堆积条状图　　189
7.13.6　其他条状图　　190
7.14　饼图　　190
7.15　高级图表　　193
7.15.1　等值线图　　193
7.15.2　极区图　　195
7.16　mplot3d　　197
7.16.1　3D曲面　　197
7.16.2　3D散点图　　198
7.16.3　3D条状图　　199
7.17　多面板图形　　200
7.17.1　在其他子图中显示子图　　200
7.17.2　子图网格　　202
7.18　小结　　204
第8章　用scikit-learn库实现机器学习　　205
8.1　scikit-learn库　　205
8.2　机器学习　　205
8.2.1　有监督和无监督学习　　205
8.2.2　训练集和测试集　　206
8.3　用scikit-learn实现有监督学习　　206
8.4　Iris数据集　　206
8.5　K-近邻分类器　　211
8.6　Diabetes数据集　　214
8.7　线性回归：最小平方回归　　215
8.8　支持向量机　　219
8.8.1　支持向量分类　　219
8.8.2　非线性SVC　　223
8.8.3　绘制SVM分类器对Iris数据集的分类效果图　　225
8.8.4　支持向量回归　　227
8.9　小结　　229
第9章　数据分析实例——气象数据　　230
9.1　待检验的假设：靠海对气候的影响　　230
9.2　数据源　　233
9.3　用IPython Notebook做数据分析　　234
9.4　风向频率玫瑰图　　246
9.5　小结　　251
第10章　IPython Notebook内嵌JavaScript库D3　　252
10.1　开放的人口数据源　　252
10.2　JavaScript库D3　　255
10.3　绘制簇状条状图　　259
10.4　地区分布图　　262
10.5　2014年美国人口地区分布图　　266
10.6　小结　　270
第11章　识别手写体数字　　271
11.1　手写体识别　　271
11.2　用scikit-learn识别手写体数字　　271
11.3　Digits数据集　　272
11.4　学习和预测　　274
11.5　小结　　276
附录A　用LaTeX编写数学表达式　　277
附录B　开放数据源　　287
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据分析实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>发现数据之美：数据分析原理与实践
第1 章 业务分析是一个蓬勃发展的方向 ................................. 1
1.1 业务分析是什么 .............................................. 2
1.2 业务分析的应用现状 ..................................... 3
1.3 如何应用业务分析 .......................................... 5
1.4 大数据与业务分析 .................................. 8
1.5 我们还在等什么 .............................. 9
第2 章 开始我们的旅程——从数据谈起 .................................... 10
2.1 我们讨论的数据结构 ..................................... 11
2.1.1 行（Row）是什么 .................................................................................................. 12
2.1.2 列（Column）是什么 ............................................................................................. 13
2.1.3 多少行数据才合适 ................................................................................................. 15
2.1.4 我们需要什么样的列 ............................................................................................. 16
2.2 Statistics 和Modeler 的基本知识 ................................................ 18
2.3 数据导入（Loading Data） ....................................................... 24
2.4 数据探查（Data Exploring） ............................. 27
2.4.1 正态分布（Normal Distribution） ......................................................................... 28
2.4.2 数据探查的常见统计量 ......................................................................................... 30
2.4.3 数据可视化 ............................................................................................................. 35
2.5 本章小结 ............................................................... 47
第3 章 在分析之前，还需要数据预处理 ............................................ 48
3.1 数据的问题 ............................................. 49
3.2 数据校验 .......................................................... 50
3.2.1 验证规则 ................................................................................................................. 50
3.2.2 验证数据 ................................................................................................................. 53
3.2.3 数据审计（Data Audit） ........................................................................................ 57
3.2.4 识别异常数据 ......................................................................................................... 60
3.3 数据集成（Data Integration） ............................................ 65
3.3.1 在Statistics 中进行数据集成 ................................................................................. 66
3.3.2 在Modeler 中进行数据集成 .................................................................................. 68
3.4 数据转换（Data Transformation） ..................................................... 73
3.4.1 分箱（Binning） ..................................................................................................... 73
3.4.2 数据调整（Data Rescale） .................................................................................... 78
3.4.3 数据重新编码（Recode） ..................................................................................... 79
3.5 自动数据准备 ................................................................ 83
3.5.1 Statistics 中的自动数据准备 .................................................................................. 83
3.5.2 Modeler 中的自动数据准备 ................................................................................... 88
3.6 本章小结 ............................................... 89
第4 章 经典分析——统计学的魅力 .................................. 91
4.1 随机变量及分布 ..................................................... 92
4.2 数理统计导引 .............................................. 94
4.3 参数估计 ................................................ 96
4.3.1 点估计...................................................................................................................... 96
4.3.2 区间估计 ................................................................................................................. 97
4.4 假设检验 .............................................................. 98
4.4.1 正态分布检验和t 检验 ........................................................................................ 101
4.4.2 非参数检验 ........................................................................................................... 108
4.5 相关分析 ............................................................ 111
4.6 方差分析 ............................................................... 113
4.7 回归分析 ............................................. 114
4.7.1 线性回归分析 ....................................................................................................... 114
4.7.2 自动化线性回归分析 ........................................................................................... 120
4.7.3 广义线性模型 ....................................................................................................... 122
4.7.4 广义线性混合模型（Generalized Linear Mixed Mode，GLMM） .................. 128
4.8 本章小结 ........................................................... 135
第5 章 我想预测未来 ................................................................ 136
5.1 数据挖掘的技术分类 ............................................................... 136
5.1.1 有监督的建模技术 ............................................................................................... 137
5.1.2 无监督的建模技术 ............................................................................................... 138
5.1.3 Feature Selection 对于分类的意义 ...................................................................... 139
5.1.4 查看建模的结果 ................................................................................................... 139
5.2 决策树 ................................................................................................ 140
5.2.1 C5.0 算法 ............................................................................................................... 141
5.2.2 分类和回归树 ....................................................................................................... 145
5.2.3 卡方自动交互检测法（CHAID） ....................................................................... 147
5.2.4 快速、无偏、高效的统计树（QUEST） .......................................................... 148
5.2.5 交互式的决策树构建方式 ................................................................................... 149
5.3 决策表 .............................................................................................. 150
5.3.1 决策表算法的设置 ............................................................................................... 151
5.3.2 交互式决策表的生成方式 ................................................................................... 153
5.4 贝叶斯网络 ........................................................................ 154
5.4.1 一些基本概念 ....................................................................................................... 154
5.4.2 IBM SPSS 的做法 ................................................................................................. 156
5.5 神经网络（Neural Networks） ...................................................... 158
5.5.1 神经网络是什么 ................................................................................................... 158
5.5.2 SPSS 神经网络算法 .............................................................................................. 160
5.6 支持向量机（Support Vector Machine） ................................... 162
5.6.1 什么是线性分类器 ............................................................................................... 162
5.6.2 Modeler 中的支持向量机 ..................................................................................... 163
5.7 最近相邻（Nearest Neighbor） .................................... 165
5.8 我该选用哪种算法 ......................................................... 167
5.9 如何评价预测结果 .............................................. 170
5.9.1 基本指标 ............................................................................................................... 170
5.9.2 Gains ...................................................................................................................... 171
5.9.3 Lift .......................................................................................................................... 173
5.9.4 Response ................................................................................................................ 175
5.9.5 Profit ...................................................................................................................... 175
5.9.6 ROI ......................................................................................................................... 177
5.10 本章小结 .............................................................. 177
第6 章 我想发现聚类（Cluster） ............................................... 179
6.1 聚类技术 ......................................................................... 180
6.2 分层聚类 ......................................................................... 181
6.3 K-means ....................................................................................... 184
6.4 TwoStep ...................................................................... 188
6.4.1 预聚类.................................................................................................................... 189
6.4.2 离群值处理 ........................................................................................................... 189
6.4.3 聚类 ........................................................................................................................ 189
6.4.4 TwoStep 的使用 .................................................................................................... 190
6.5 Kohonen network .................................................. 192
6.6 我怎么知道聚类结果是好的 ............................................................. 194
6.6.1 考察聚类的数量和每个聚类中的记录数 ........................................................... 194
6.6.2 考察聚类内的特征 ............................................................................................... 195
6.6.3 考察聚类间的特征 ............................................................................................... 195
6.6.4 一个综合的考察指标Silhouette .......................................................................... 196
6.7 自动聚类 ......................................................... 197
6.8 理解聚类的结果 ........................................................................... 198
6.9 一个聚类分析应用的例子 ............................................. 201
6.10 本章小结 ............................................................... 202
第7 章 周而复始的规律——时间序列分析 .......................................... 203
7.1 时间序列 ................................................................................ 204
7.1.1 时间序列的类型 ................................................................................................... 204
7.1.2 时间序列的特征 ................................................................................................... 205
7.2 指数平滑模型 ............................................................................. 206
7.2.1 简单指数平滑法 ................................................................................................... 206
7.2.2 带有趋势调整的指数平滑法（霍尔特指数平滑法） ....................................... 208
7.2.3 带有阻尼趋势的指数平滑法 ............................................................................... 208
7.2.4 简单季节指数平滑法 ........................................................................................... 209
7.2.5 带有趋势和季节调整的指数平滑法（温特斯指数平滑法） ........................... 209
7.2.6 指数平滑法的初始化 ........................................................................................... 210
7.2.7 去除时间序列的趋势和季节性因素 ................................................................... 211
7.3 自回归模型 ................................................ 212
7.3.1 自回归模型 ........................................................................................................... 212
7.3.2 移动平均模型 ....................................................................................................... 213
7.3.3 自回归移动平均模型（ARMA） ....................................................................... 213
7.3.4 差分自回归移动平均模型 ................................................................................... 214
7.4 SPSS 产品中的时间序列模型 ............................................... 214
7.4.1 Statistics 中的时间序列模型 ................................................................................ 214
7.4.2 Modeler 中的时间序列模型 ................................................................................. 235
7.5 时间序列分析的评价 ...................................................... 238
7.6 本章小结 ......................................................... 239
第8 章 你的行为完全可能被猜中——关联规则分析 ................................. 240
8.1 基本概念 ............................................................. 241
8.2 Apriori 算法 ....................................................................... 245
8.2.1 Apriori 算法工作步骤 ........................................................................................... 245
8.2.2 Apriori 算法的评估方法 ....................................................................................... 246
8.2.3 Apriori 节点 ........................................................................................................... 247
8.3 CARMA 算法 ................................................................................ 249
8.3.1 CARMA 算法的工作步骤 .................................................................................... 249
8.3.2 CARMA 节点 ........................................................................................................ 251
8.4 序列算法 ................................................................... 252
8.5 关联规则的评价 .......................................................................... 255
8.6 典型应用案例 .................................................................. 256
第9 章 我们还需要优化技术的帮忙 ......................................... 257
9.1 什么是优化技术 ....................................................................... 258
9.2 优化问题的分类 ....................................................................... 259
9.2.1 线性规划 ............................................................................................................... 260
9.2.2 整数规划 ............................................................................................................... 261
9.2.3 多目标规划 ........................................................................................................... 262
9.2.4 动态规划 ............................................................................................................... 262
9.3 IBM ILOG Optimization 介绍 ................................................. 263
9.4 本章小结 ...................................................................... 265
第10 章 有关方法论的问题 ..................................... 266
10.1 为什么我们要讨论方法论 .................................................. 267
10.2 CRISP-DM .............................................................................. 267
10.2.1 CRISP-DM 方法学 .............................................................................................. 268
10.2.2 CRISP-DM 参考模型.......................................................................................... 270
10.3 IBM SPSS CaDS ...................................................................... 273
10.3.1 Repository ............................................................................................................ 273
10.3.2 Job ........................................................................................................................ 274
10.3.3 Model Refresh and Champion Challenger .......................................................... 274
10.3.4 Scoring ................................................................................................................. 274
10.4 模型的部署不是终点............................................................... 275
第11 章 一个时髦的领域——决策管理 .................................................. 276
11.1 决策管理系统 ..................................................................... 276
11.1.1 什么是决策 .......................................................................................................... 277
11.1.2 什么是决策管理系统 .......................................................................................... 279
11.1.3 决策支持与决策管理的比较.............................................................................. 281
11.2 构建决策管理系统 ......................................................................... 282
11.2.1 构建决策支持系统的原则 .................................................................................. 282
11.2.2 合适的决策 .......................................................................................................... 283
11.2.3 如何找到合适的决策 .......................................................................................... 285
11.2.4 怎样在决策管理系统中定义决策 ..................................................................... 287
11.2.5 决策管理系统中的优化技术.............................................................................. 292
11.2.6 决策影响的评估 .................................................................................................. 294
11.2.7 监控决策 .............................................................................................................. 297
11.2.8 决策的持续改进 .................................................................................................. 298
11.2.9 构建和部署决策服务 .......................................................................................... 299
11.2.10 实施决策管理的一些要求................................................................................ 300
11.3 IBM ADM ....................................................................... 301
11.3.1 ADM 是SPSS 数据分析能力的窗口 ................................................................ 301
11.3.2 ADM 的着眼点是将数据分析结果转化为决策 ............................................... 302
11.3.3 ADM 是一个可以配置的决策服务平台 ........................................................... 303
11.3.4 ADM 的工作步骤 ............................................................................................... 306
11.4 本章小结 ................................................................................ 308
后记 为未来做好准备 ......................................................... 309
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>发现数据之美：数据分析原理与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言计算机形式分析的理论与方法(精)/当代科学技术基础理论与前沿问题研究丛书
序
第1章自然语言处理的学科定位
1.1从自然语言处理的过程来考察其学科定位
1.2从自然语言处理的范围来考察其学科定位
1.3从自然语言处理的历史来考察其学科定位
1.4当前自然语言处理发展的几个特点
参考文献
第2章语言计算研究的先驱
2.1Markov链
2.2Zipf定律
2.3Shannon关于“熵”的研究
2.4Bar-Hillel的范畴语法
2.5Harris的语言串分析法
2.6О.С.Кулагина的语言集合论模型
参考文献
第3章基于短语结构语法的形式模型
3.1语法的Chomsky层级
3.2有限状态语法和它的局限性
3.3短语结构语法
3.4递归转移网络和扩充转移网络
3.5自底向上分析和自顶向下分析
3.6通用句法处理器和线图分析法
3.7Earley算法
3.8左角分析法
3.9CYK算法
3.10Tomita算法
3.11管辖约束理论与最简方案
3.12Joshi的树邻接语法
3.13汉字结构的形式描述
3.14Hausser的左结合语法
参考文献
第4章基于合一运算的形式模型
4.1中文信息MMT模型
4.2Kaplan的词汇功能语法
4.3Martin Kay的功能合一语法
4.4Gazdar的广义短语结构语法
4.5Shieber的PATR
4.6Pollard的中心语驱动的短语结构语法
4.7Pereira和Warren的定子句语法
参考文献
第5章基于依存和配价的形式模型
5.1配价观念的起源
5.2Tesnière的依存语法
5.3依存语法在自然语言处理中的应用
5.4配价语法
5.5配价语法在自然语言处理中的应用
参考文献
第6章基于格语法的形式模型
6.1Fillmore的格语法
6.2Fillmore的框架网络
参考文献
第7章基于词汇主义的形式模型
7.1Gross的词汇语法
7.2链语法
7.3词汇语义学
7.4知识本体
7.5词网
7.6知网
7.7Pustejovesky的生成词库理论
参考文献
第8章语义自动处理的形式模型
8.1义素分析法
8.2语义场
8.3语义网络
8.4Montague语法
8.5Wilks的优选语义学
8.6Schank的概念依存理论
8.7Mel’chuk的意义文本理论
8.8词义排歧方法
参考文献
第9章系统功能语法
9.1系统功能语法的基本概念
9.2系统功能语法在自然语言处理中的应用
参考文献
第10章语用自动处理的形式模型
10.1Mann和Thompson的修辞结构理论
10.2文本连贯中的常识推理技术
10.3言语行为理论和会话智能代理
参考文献
第11章 概率语法
11.1概率上下文无关语法与句子的歧义
11.2概率上下文无关语法的基本原理
11.3概率上下文无关语法的三个假设
11.4概率词汇化上下文无关语法
参考文献
第12章Bayes公式与动态规划算法
12.1拼写错误的检查与更正
12.2Bayes公式与噪声信道模型
12.3最小编辑距离算法
12.4发音问题研究中的Bayes方法
12.5发音变异的决策树模型
12.6加权自动机
12.7向前算法
12.8Viterbi算法
附录
参考文献
第13章N元语法和数据平滑
13.1N元语法
13.2数据平滑
参考文献
第14章隐Markov模型（HMM）
14.1HMM概述
14.2HMM在语音识别中的应用
参考文献
第15章语音自动处理的形式模型
15.1语音和音位的形式描述方法
15.2声学语音学和信号
15.3语音自动合成的方法
15.4语音自动识别的方法
参考文献
第16章统计机器翻译中的形式模型
16.1机器翻译与噪声信道模型
16.2最大熵模型
16.3基于平行概率语法的形式模型
16.4基于短语的统计机器翻译
16.5基于句法的统计机器翻译
参考文献
第17章自然语言处理系统的评测
17.1评测的一般原则和方法
17.2语音合成和文语转换系统的评测
17.3机器翻译系统的评测
17.4语料库系统的评测
17.5国外自然语言处理系统的评测
参考文献
第18章自然语言处理中的理性主义与经验主义
18.1哲学中的理性主义和经验主义
18.2自然语言处理中理性主义和经验主义的消长
18.3理性主义方法和经验主义方法的利弊得失
18.4探索理性主义方法和经验主义方法结合的途径
参考文献
附录走在文理结合的道路上——记自然语言处理专家冯志伟先生
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>自然语言计算机形式分析的理论与方法(精)/当代科学技术基础理论与前沿问题研究丛书
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>全栈数据之门
前言　自强不息，厚德载物 / XIX
0x1　Linux，自由之光 / 001
0x10　Linux，你是我的眼 / 001
0x11　Linux 基础，从零开始 / 003
01 Linux 之门 / 003
02 文件操作 / 004
03 权限管理 / 006
04 软件安装 / 008
05 实战经验 / 010
0x12　Sed 与Grep，文本处理 / 010
01 文本工具 / 010
02 grep 的使用 / 011
03 grep 家族 / 013
04 sed 的使用 / 014
05 综合案例 / 016
0x13　数据工程，必备Shell / 018
01 Shell 分析 / 018
02 文件探索 / 019
03 内容探索 / 020
04 交差并补 / 020
05 其他常用的命令 / 021
06 批量操作 / 022
07 结语 / 025
0x14　Shell 快捷键，Emacs 之门 / 025
01 提高效率 / 025
02 光标移动 / 026
03 文本编辑 / 027
04 命令搜索 / 028
05 Emacs 入门 / 029
06 Emacs 思维 / 031
0x15　缘起Linux，一入Mac 误终身 / 032
01 开源生万物 / 032
02 有钱就换Mac / 032
03 程序员需求 / 033
04 非程序员需求 / 034
05 一入Mac 误终身 / 035
0x16　大成就者，集群安装 / 036
01 离线安装 / 036
02 Host 与SSH 配置 / 037
03 sudo 与JDK 环境 / 039
04 准备Hadoop 包 / 040
05 开启HTTP 与配置源 / 041
06 安装ambari-server / 041
07 后续服务安装 / 042
08 结语 / 044
0x2　Python，道法自然 / 045
0x20　Python，灵犀一指 / 045
0x21　Python 基础，兴趣为王 / 047
01 第一语言 / 047
02 数据结构 / 047
03 文件读写 / 049
04 使用模块 / 050
05 函数式编程 / 052
06 一道面试题 / 053
07 兴趣驱动 / 055
0x22　喜新厌旧，2 迁移3 / 056
01 新旧交替 / 056
02 基础变化 / 057
03 编码问题 / 058
04 其他变化 / 058
05 2to3 脚本 / 060
06 PySpark 配置 / 061
07 喜新厌旧 / 062
0x23　Anaconda，IPython / 062
01 Anaconda / 062
02 安装与配置 / 063
03 pip 与源 / 064
04 IPython 与Jupyter / 065
05 结语 / 067
0x24　美不胜收，Python 工具 / 067
01 缘起 / 067
02 调试与开发 / 068
03 排版与格式化 / 070
04 辅助工具 / 072
05 实用推荐 / 074
0x25　numpy 基础，线性代数 / 075
01 numpy 的使用 / 075
02 索引与切片 / 076
03 变形与统计 / 078
04 矩阵运算 / 080
05 实用方法 / 083
06 结语 / 085
0x26　numpy 实战，PCA 降维 / 085
01 PCA 介绍 / 085
02 数据均值化 / 086
03 协方差矩阵 / 087
04 特征值与向量 / 088
05 数据映射降维 / 089
06 sklearn 实现 / 090
0x3　大数据，其大无外 / 093
0x30　太大数据，极生两仪 / 093
0x31　神象住世，Hadoop / 095
01 Hadoop / 095
02 HDFS / 096
03 角色与管理 / 097
04 文件操作 / 098
05 结语 / 100
0x32　分治之美，MapReduce / 100
01 map 与reduce 函数 / 100
02 分而治之 / 102
03 Hello,World / 103
04 Streaming 接口 / 105
0x33　Hive 基础，蜂巢与仓库 / 106
01 引言 / 106
02 Hive 接口 / 107
03 分区建表 / 108
04 分区机制 / 110
05 数据导入/ 导出 / 111
06 Hive-QL / 112
07 结语 / 114
0x34　Hive 深入，实战经验 / 115
01 排序与分布式 / 115
02 多表插入与mapjoin / 116
03 加载map-reduce 脚本 / 117
04 使用第三方UDF / 119
05 实战经验 / 120
06 生成唯一ID / 121
0x35　HBase 库，实时业务 / 122
01 理论基础 / 122
02 Shell 操作 / 123
03 关联Hive 表 / 126
04 数据导入 / 128
05 实用经验 / 130
0x36　SQL 与NoSQL，Sqoop 为媒 / 130
01 SQL 与NOSQL / 130
02 从MySQL 导入HDFS / 131
03 增量导入 / 134
04 映射到Hive / 135
05 导入Hive 表 / 136
06 从HDFS 导出到MySQL / 137
07 从Hive 导出到MySQL / 138
0x4　数据分析，见微知著 / 141
0x40　大数据分析，鲁班为祖师 / 141
0x41　SQL 技能，必备MySQL / 143
01 SQL 工具 / 143
02 基础操作 / 144
03 查询套路 / 145
04 join 查询 / 146
05 union 与exists / 149
06 实战经验 / 151
0x42　快刀awk，斩乱数据 / 152
01 快刀 / 152
02 一二三要点 / 152
03 一个示例 / 154
04 应用与统计 / 154
05 斩乱麻 / 156
0x43　Pandas，数据之框 / 157
01 数据为框 / 157
02 加载数据 / 158
03 行列索引 / 159
04 行列操作 / 161
05 合并聚合 / 163
06 迭代数据 / 164
07 结语 / 165
0x44　Zeppelin，一统江湖 / 166
01 心潮澎湃 / 166
02 基本使用 / 168
03 SQL 与可视化 / 169
04 安装Zeppelin / 172
05 配置Zeppelin / 173
06 数据安全 / 174
07 使用心得 / 176
0x45　数据分组，聚合窗口 / 177
01 MySQL 聚合 / 177
02 Spark 聚合 / 178
03 非聚合字段 / 179
04 Hive 实现 / 180
05 group_concat / 181
06 Hive 窗口函数 / 183
07 DataFrame 窗口 / 184
08 结语 / 185
0x46　全栈分析，六层内功 / 186
01 引言 / 186
02 MySQL 版本 / 186
03 awk 版本 / 187
04 Python 版本 / 188
05 Hive 版本 / 189
06 map-reduce 版本 / 190
07 Spark 版本 / 190
08 结语 / 191
0x5　机器学习，人类失控 / 193
0x50　机器学习，琅琊论断 / 193
0x51　酸酸甜甜，Orange / 195
01 可视化学习 / 195
02 数据探索 / 196
03 模型与评估 / 199
04 组件介绍 / 200
05 与Python 进行整合 / 202
06 结语 / 204
0x52　sklearn，机器学习 / 205
01 sklearn 介绍 / 205
02 数据预处理 / 206
03 建模与预测 / 207
04 模型评估 / 209
05 模型持久化 / 210
06 三个层次 / 210
0x53　特征转换，量纲伸缩 / 211
01 特征工程 / 211
02 独热编码 / 212
03 sklearn 示例 / 213
04 标准化与归一化 / 215
05 sklearn 与Spark 实现 / 216
06 结语 / 219
0x54　描述统计，基础指标 / 220
01 描述性统计 / 220
02 Pandas 实现 / 222
03 方差与协方差 / 223
04 Spark-RDD 实现 / 224
05 DataFrame 实现 / 226
06 Spark-SQL 实现 / 227
07 结语 / 227
0x55　模型评估，交叉验证 / 228
01 测试与训练 / 228
02 评价指标 / 229
03 交叉验证 / 231
04 验证数据 / 232
05 OOB 数据 / 233
0x56　文本特征，词袋模型 / 234
01 自然语言 / 234
02 中文分词 / 235
03 词袋模型 / 236
04 词频统计 / 237
05 TF-IDF / 238
06 结语 / 239
0x6　算法预测，占天卜地 / 241
0x60　命由己做，福自己求 / 241
0x61　近朱者赤，相亲kNN / 243
01 朴素的思想 / 243
02 算法介绍 / 243
03 分类与回归 / 244
04 k 与半径 / 245
05 优化计算 / 246
06 实例应用 / 247
0x62　物以类聚，Kmeans / 248
01 算法描述 / 248
02 建立模型 / 249
03 理解模型 / 251
04 距离与相似性 / 252
05 降维与可视化 / 253
06 无监督学习 / 255
0x63　很傻很天真，朴素贝叶斯 / 257
01 朴素思想 / 257
02 概率公式 / 257
03 三种实现 / 258
04 sklearn 示例 / 260
05 朴素却不傻 / 262
0x64　菩提之树，决策姻缘 / 263
01 缘起 / 263
02 Orange 演示 / 264
03 scikit-learn 模拟 / 266
04 熵与基尼指数 / 267
05 决策过程分析 / 268
06 Spark 模拟 / 270
07 结语 / 271
0x65　随机之美，随机森林 / 271
01 树与森林 / 271
02 处处随机 / 273
03 sklearn 示例 / 274
04 MLlib 示例 / 275
05 特点与应用 / 276
0x66　自编码器，深度之门 / 277
01 深度学习 / 277
02 特征学习 / 278
03 自动编码器 / 280
04 Keras 代码 / 282
05 抗噪编码器 / 283
0x7　Spark，唯快不破 / 285
0x70　人生苦短，快用Spark / 285
0x71　PySpark 之门，强者联盟 / 287
01 全栈框架 / 287
02 环境搭建 / 288
03 分布式部署 / 289
04 示例分析 / 290
05 两类算子 / 292
06 map 与reduce / 293
07 AMPLab 的野心 / 294
0x72　RDD 算子，计算之魂 / 295
01 算子之道 / 295
02 获取数据 / 296
03 过滤与排序 / 297
04 聚合数据 / 298
05 join 连接 / 299
06 union 与zip / 300
07 读写文件 / 301
08 结语 / 303
0x73　分布式SQL，蝶恋飞舞 / 304
01 SQL 工具 / 304
02 命令行CLI / 304
03 读Hive 数据 / 305
04 将结果写入Hive / 306
05 读写MySQL 数据 / 307
06 读写三种文件 / 308
0x74　DataFrame，三角之恋 / 310
01 DataFrame / 310
02 生成数据框 / 311
03 合并与join / 313
04 select 操作 / 314
05 SQL 操作 / 315
06 自定义UDF / 316
07 三角之恋 / 318
0x75　神器之父，Scala 入世 / 319
01 Spark 与Scala / 319
02 Scala REPL / 320
03 编译Scala / 321
04 sbt 编译 / 322
05 示例分析 / 323
06 编译提交 / 325
0x76　机器之心，ML 套路 / 326
01 城市套路深 / 326
02 算法与特征工程 / 327
03 管道工作流 / 328
04 OneHotEncoder 示例 / 329
05 ML 回归实战 / 331
06 特征处理与算法 / 332
07 拟合与评估 / 334
0x8　数据科学，全栈智慧 / 337
0x80　才高八斗，共分天下 / 337
0x81　自学数据，神蟒领舞 / 339
01 机器学习 / 339
02 语言领域 / 339
03 Python 数据生态 / 340
04 相关资料 / 341
05 书籍推荐 / 342
06 性感的职业 / 343
0x82　数据科学，七大技能 / 343
01 七大技能 / 343
02 SQL 与NoSQL 技能 / 344
03 Linux 工具集 / 344
04 Python 或者R 语言生态 / 345
05 Hadoop 与Spark 生态 / 345
06 概率、统计与线性代数 / 346
07 机器学习与深度学习 / 346
08 业务及杂项 / 347
09 结语 / 347
0x83　大无所大，生态框架 / 348
01 计算生态 / 348
02 离线计算 / 348
03 交互分析 / 349
04 实时处理 / 350
05 算法挖掘 / 351
06 发行版本 / 352
07 其他工具 / 353
0x84　集体智慧，失控哲学 / 354
01 数据是宝 / 354
02 一分为二 / 355
03 回归统一 / 356
04 聚少成多 / 356
05 你中有我 / 357
06 从小看大 / 358
07 大事化小 / 358
08 少即是多 / 359
0x85　一技之长，一生之用 / 359
01 一技之长 / 359
02 数据分析相关 / 360
03 Python 相关 / 360
04 Hadoop 相关 / 361
05 Spark 相关 / 361
06 模型相关 / 362
07 算法相关 / 362
08 一生之用 / 363
0x86 知识作谱，数据为栈 / 363
01 知识作谱 / 363
02 理论基础 / 363
03 Python/R 编程 / 364
04 分析与可视化 / 365
05 大数据 / 365
06 ETL 与特征工程 / 366
07 机器学习与深度学习 / 366
08 工具与库 / 367
09 全栈为用 / 367
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>全栈数据之门
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习理论基础
译者序
前言
第1章引言：分类、学习、
特征及应用
1.1范围
1.2为什么需要机器学习？
1.3一些应用
1.3.1图像识别
1.3.2语音识别
1.3.3医学诊断
1.3.4统计套利
1.4测量、特征和特征向量
1.5概率的需要
1.6监督学习
1.7小结
1.8附录：归纳法
1.9问题
1.10参考文献
第2章概率
2.1一些基本事件的概率
2.2复合事件的概率
2.3条件概率
2.4不放回抽取
2.5一个经典的生日问题
2.6随机变量
2.7期望值
2.8方差
2.9小结
2.10附录：概率诠释
2.11问题
2.12参考文献
第3章概率密度
3.1一个二维实例
3.2在\[0,1\]区间的随机数
3.3密度函数
3.4高维空间中的概率密度
3.5联合密度和条件密度
3.6期望和方差
3.7大数定律
3.8小结
3.9附录:可测性
3.10问题
3.11参考文献
第4章模式识别问题
4.1一个简单例子
4.2决策规则
4.3成功基准
4.4最佳分类器：贝叶斯决策
规则
4.5连续特征和密度
4.6小结
4.7附录：不可数概念
4.8问题
4.9参考文献
第5章最优贝叶斯决策规则
5.1贝叶斯定理
5.2贝叶斯决策规则
5.3最优及其评论
5.4一个例子
5.5基于密度函数的贝叶斯定理
及决策规则
5.6小结
5.7附录：条件概率的定义
5.8问题
5.9参考文献
第6章从实例中学习
6.1概率分布知识的欠缺
6.2训练数据
6.3对训练数据的假设
6.4蛮力学习方法
6.5维数灾难、归纳偏置以及
无免费午餐原理
6.6小结
6.7附录:学习的类型
6.8问题
6.9参考文献
第7章最近邻规则
7.1最近邻规则
7.2最近邻规则的性能
7.3直觉判断与性能证明框架
7.4使用更多邻域
7.5小结
7.6附录:当人们使用最近邻域
进行推理时的一些问题
7.6.1谁是单身汉?
7.6.2法律推理
7.6.3道德推理
7.7问题
7.8参考文献
第8章核规则
8.1动机
8.2最近邻规则的变体
8.3核规则
8.4核规则的通用一致性
8.5势函数
8.6更多的通用核
8.7小结
8.8附录：核、相似性和特征
8.9问题
8.10参考文献
第9章神经网络:感知器
9.1多层前馈网络
9.2神经网络用于学习和分类
9.3感知器
9.3.1阈值
9.4感知器学习规则
9.5感知器的表达能力
9.6小结
9.7附录：思想模型
9.8问题
9.9参考文献
第10章多层神经网络
10.1多层网络的表征能力
10.2学习及S形输出
10.3训练误差和权值空间
10.4基于梯度下降的误差最小化
10.5反向传播
10.6反向传播方程的推导
10.6.1单神经元情况下的推导
10.6.2多层网络情况下的推导
10.7小结
10.8附录:梯度下降与反射平衡
推理
10.9问题
10.10参考文献
第11章可能近似正确（PAC）
学习
11.1决策规则分类
11.2来自一个类中的最优规则
11.3可能近似正确准则
11.4PAC学习
11.5小结
11.6附录：识别不可辨元
11.7问题
11.8参考文献
第12章VC维
12.1近似误差和估计误差
12.2打散
12.3VC维
12.4学习结果
12.5举例
12.6神经网络应用
12.7小结
12.8附录:VC维与波普尔
（Popper）维度
12.9问题
12.10参考文献
第13章无限VC维
13.1类层次及修正的PAC准则
13.2失配与复杂性间的平衡
13.3学习结果
13.4归纳偏置与简单性
13.5小结
13.6附录：均匀收敛与泛
致性
13.7问题
13.8参考文献
第14章函数估计问题
14.1估计
14.2成功准则
14.3最优估计：回归函数
14.4函数估计中的学习
14.5小结
14.6附录：均值回归
14.7问题
14.8参考文献
第15章学习函数估计
15.1函数估计与回归问题回顾
15.2最近邻规则
15.3核方法
15.4神经网络学习
15.5基于确定函数类的估计
15.6打散、伪维数与学习
15.7结论
15.8附录：估计中的准确度、
精度、偏差及方差
15.9问题
15.10参考文献
第16章简明性
16.1科学中的简明性
16.1.1对简明性的明确倡导
16.1.2这个世界简单吗?
16.1.3对简明性的错误诉求
16.1.4对简明性的隐性诉求
16.2排序假设
16.2.1两种简明性排序法
16.3两个实例
16.3.1曲线拟合
16.3.2枚举归纳
16.4简明性即表征简明性
16.4.1要确定表征系统吗?
16.4.2参数越少越简单吗?
16.5简明性的实用理论
16.6简明性和全局不确定性
16.7小结
16.8附录:基础科学和统计学习
理论
16.9问题
16.10参考文献
第17章支持向量机
17.1特征向量的映射
17.2间隔最大化
17.3优化与支持向量
17.4实现及其与核方法的关联
17.5优化问题的细节
17.5.1改写分离条件
17.5.2间隔方程
17.5.3用于不可分实例的松弛
变量
17.5.4优化问题的重构和求解
17.6小结
17.7附录:计算
17.8问题
17.9参考文献
第18章集成学习
18.1弱学习规则
18.2分类器组合
18.3训练样本的分布
18.4自适应集成学习算法
（AdaBoost）
18.5训练数据的性能
18.6泛化性能
18.7小结
18.8附录：集成方法
18.9问题
18.10参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计学习理论基础
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>应用预测建模
译者序
前言
第1章 导论
1.1 预测与解释
1.2 预测模型的关键部分
1.3 专业术语
1.4 实例数据集和典型数据场景
1.5 概述
1.6 符号
第一部分 一般策略
第2章 预测建模过程简介
2.1 案例分析：预测燃油效能
2.2 主题
2.3 总结
第3章 数据预处理
3.1 案例分析：高内涵筛选中的细胞分组
3.2 单个预测变量数据变换
3.3 多个预测变量数据变换
3.4 处理缺失值
3.5 移除预测变量
3.6 增加预测变量
3.7 区间化预测变量
3.8 计算
习题
第4章 过度拟合与模型调优
4.1 过度拟合的问题
4.2 模型调优
4.3 数据分割
4.4 重抽样技术
4.5 案例分析：信用评分
4.6 选择调优参数值
4.7 数据划分建议
4.8 不同模型间的选择
4.9 计算
习题
第二部分 回归模型
第5章 衡量回归模型的效果
5.1 模型效果的定量度量
5.2 方差偏差的权衡
5.3 计算
第6章 线性回归及其扩展
6.1 案例分析：定量构效关系建模
6.2 线性回归
6.3 偏最小二乘法
6.4 惩罚模型
6.5 计算
习题
第7章 非线性回归模型
7.1 神经网络
7.2 多元自适应回归样条
7.3 支持向量机
7.4 K近邻
7.5 计算
习题
第8章 回归树与基于规则的模型
8.1 简单回归树
8.2 回归模型树
8.3 基于规则的模型
8.4 装袋树
8.5 随机森林
8.6 助推法
8.7 Cubist
8.8 计算
习题
第9章 溶解度模型总结
第10章 案例研究：混凝土混合物的抗压强度
10.1 模型构建策略
10.2 模型性能
10.3 优化抗压强度
10.4 计算
第三部分 分类模型
第11章 分类模型的效果度量
11.1 类预测
11.2 评估预测类
11.3 评估类概率
11.4 计算
第12章 判别分析和其他线性分类模型
12.1 案例分析：预测是否成功申请经费
12.2 逻辑回归
12.3 线性判别分析
12.4 偏最小二乘判别分析
12.5 惩罚模型
12.6 最近收缩质心
12.7 计算
习题
第13章 非线性分类模型
13.1 非线性判别分析
13.2 神经网络
13.3 灵活判别分析
13.4 支持向量机
13.5 K近邻
13.6 朴素贝叶斯
13.7 计算
习题
第14章 分类树与基于规则的模型
14.1 基本的分类树
14.2 基于规则的模型
14.3 装袋决策树
14.4 随机森林
14.5 助推法
14.6 C5.0
14.7 比较两种分类预测变量编码方式
14.8 计算
习题
第15章 经费申请模型的总结
第16章 对严重类失衡的补救方法
16.1 案例分析: 预测房车保险所有权
16.2 类失衡的影响
16.3 模型调优
16.4 选择截点
16.5 调整先验概率
16.6 不等案例权重
16.7 抽样方法
16.8 成本敏感度训练
16.9 计算
习题
第17章 案例研究：作业调度
17.1 数据切分和模型策略
17.2 结果
17.3 计算
第18章 衡量预测变量重要性
18.1 数值结果变量
18.2 分类结果变量
18.3 其他方法
18.4 计算
习题
第19章 特征选择介绍
19.1 使用无信息预测变量的结果
19.2 减少预测变量个数的方法
19.3 绕封法
19.4 过滤法
19.5 选择偏差
19.6 案例分析：预测认知损伤
19.7 计算
习题
第20章 影响模型表现的因素
20.1 第Ⅲ类错误
20.2 结果变量的测量误差
20.3 预测变量的测量误差
20.4 连续变量离散化
20.5 模型预测何时是可信的
20.6 大样本的影响
20.7 计算
习题
附录
附录A 各种模型的总结
附录B R语言介绍
附录C 值得关注的网站
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>应用预测建模
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据分析
第1章 Python程序库入门 1
1.1 本书用到的软件 2
1.1.1 软件的安装和设置 2
1.1.2 Windows平台 2
1.1.3 Linux平台 3
1.1.4 Mac OS X平台 4
1.2 从源代码安装NumPy、SciPy、matplotlib和IPython 6
1.3 用setuptools安装 7
1.4 NumPy数组 7
1.5 一个简单的应用 8
1.6 将IPython用作shell 11
1.7 学习手册页 13
1.8 IPython notebook 14
1.9 从何处寻求帮助和参考资料 14
1.10 小结 15
第2章 NumPy数组 16
2.1 NumPy数组对象 16
2.2 创建多维数组 18
2.3 选择NumPy数组元素 18
2.4 NumPy的数值类型 19
2.4.1 数据类型对象 21
2.4.2 字符码 21
2.4.3 Dtype构造函数 22
2.4.4 dtype属性 23
2.5 一维数组的切片与索引 23
2.6 处理数组形状 24
2.6.1 堆叠数组 27
2.6.2 拆分NumPy数组 30
2.6.3 NumPy数组的属性 33
2.6.4 数组的转换 39
2.7 创建数组的视图和拷贝 40
2.8 花式索引 41
2.9 基于位置列表的索引方法 43
2.10 用布尔型变量索引NumPy数组 44
2.11 NumPy数组的广播 46
2.12 小结 49
第3章 统计学与线性代数 50
3.1 Numpy和Scipy模块 50
3.2 用NumPy进行简单的描述性统计计算 55
3.3 用NumPy进行线性代数运算 57
3.3.1 用NumPy求矩阵的逆 57
3.3.2 用NumPy解线性方程组 59
3.4 用NumPy计算特征值和特征向量 61
3.5 NumPy随机数 63
3.5.1 用二项式分布进行博弈 63
3.5.2 正态分布采样 66
3.5.3 用SciPy进行正态检验 67
3.6 创建掩码式NumPy数组 70
3.7 小结 75
第4章 pandas入门 76
4.1 pandas的安装与概览 77
4.2 pandas数据结构之DataFrame 78
4.3 pandas数据结构之Series 81
4.4 利用pandas查询数据 85
4.5 利用pandas的DataFrame进行统计计算 89
4.6 利用pandas的DataFrame实现数据聚合 91
4.7 DataFrame的串联与附加操作 95
4.8 连接DataFrames 96
4.9 处理缺失数据问题 99
4.10 处理日期数据 102
4.11 数据透视表 106
4.12 访问远程数据 107
4.13 小结 109
第5章 数据的检索、加工与存储 110
5.1 利用NumPy和pandas对CSV文件进行写操作 110
5.2 NumPy.npy与pandas DataFrame 112
5.3 使用PyTables存储数据 115
5.4 Pandas DataFrame与HDF5仓库之间的读写操作 118
5.5 使用pandas读写Excel文件 120
5.6 使用REST Web服务和JSON 123
5.7 使用pandas读写JSON 124
5.8 解析RSS和Atom订阅 126
5.9 使用Beautiful Soup解析HTML 127
5.10 小结 134
第6章 数据可视化 136
6.1 matplotlib的子库 137
6.2 matplotlib绘图入门 137
6.3 对数图 139
6.4 散点图 141
6.5 图例和注解 143
6.6 三维图 145
6.7 pandas绘图 148
6.8 时滞图 150
6.9 自相关图 151
6.10 Plot.ly 153
6.11 小结 155
第7章 信号处理与时间序列 156
7.1 statsmodels子库 157
7.2 移动平均值 157
7.3 窗口函数 159
7.4 协整的定义 161
7.5 自相关 164
7.6 自回归模型 166
7.7 ARMA模型 170
7.8 生成周期信号 172
7.9 傅里叶分析 174
7.10 谱分析 177
7.11 滤波 177
7.12 小结 179
第8章 应用数据库 180
8.1 基于sqlite3的轻量级访问 181
8.2 通过pandas访问数据库 183
8.3 SQLAlchemy 185
8.3.1 SQLAlchemy的安装和配置 186
8.3.2 通过SQLAlchemy填充数据库 188
8.3.3 通过SQLAlchemy查询数据库 189
8.4 Pony ORM 191
8.5 Dataset：懒人数据库 192
8.6 PyMongo与MongoDB 195
8.7 利用Redis存储数据 196
8.8 Apache Cassandra 197
8.9 小结 201
第9章 分析文本数据和社交媒体 203
9.1 安装NLTK 203
9.2 滤除停用字、姓名和数字 206
9.3 词袋模型 208
9.4 词频分析 209
9.5 朴素贝叶斯分类 211
9.6 情感分析 214
9.7 创建词云 217
9.8 社交网络分析 222
9.9 小结 224
第10章 预测性分析与机器学习 225
10.1 scikit-learn概貌 226
10.2 预处理 228
10.3 基于逻辑回归的分类 230
10.4 基于支持向量机的分类 232
10.5 基于ElasticNetCV的回归分析 235
10.6 支持向量回归 237
10.7 基于相似性传播算法的聚类分析 240
10.8 均值漂移算法 242
10.9 遗传算法 244
10.10 神经网络 249
10.11 决策树 251
10.12 小结 253
第11章 Python生态系统的外部环境和云计算 255
11.1 与MATLAB/Octave交换信息 256
11.2 Installing rpy2安装rpy2 257
11.3 连接R 257
11.4 为Java传递NumPy数组 260
11.5 集成SWIG和NumPy 261
11.6 集成Boost和Python 264
11.7 通过f2py使用Fortran代码 266
11.8 配置谷歌应用引擎 267
11.9 在PythonAnywhere上运行程序 269
11.10 使用Wakari 270
11.11 小结 271
第12章 性能优化、性能分析与并发性 272
12.1 代码的性能分析 272
12.2 安装Cython 277
12.3 调用C代码 281
12.4 利用multiprocessing创建进程池 283
12.5 通过Joblib提高for循环的并发性 286
12.6 比较Bottleneck函数与NumPy函数 287
12.7 通过Jug实现MapReduce 289
12.8 安装MPI for Python 292
12.9 IPython Parallel 292
12.10 小结 296
附录A 重要概念 298
附录B 常用函数 303
附录C 在线资源 309
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python数据分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow技术解析与实战
第一篇　基础篇
第1章　人工智能概述 2
1.1　什么是人工智能 2
1.2　什么是深度学习 5
1.3　深度学习的入门方法 7
1.4　什么是TensorFlow 11
1.5　为什么要学TensorFlow 12
1.5.1　TensorFlow的特性 14
1.5.2　使用TensorFlow的公司 15
1.5.3　TensorFlow的发展 16
1.6　机器学习的相关赛事 16
1.6.1　ImageNet的ILSVRC 17
1.6.2　Kaggle 18
1.6.3　天池大数据竞赛 19
1.7　国内的人工智能公司 20
1.8　小结 22
第2章　TensorFlow环境的准备 23
2.1　下载TensorFlow 1.1.0 23
2.2　基于pip的安装 23
2.2.1　Mac OS环境准备 24
2.2.2　Ubuntu/Linux环境准备 25
2.2.3　Windows环境准备 25
2.3　基于Java的安装 28
2.4　从源代码安装 29
2.5　依赖的其他模块 30
2.5.1　numpy 30
2.5.2　matplotlib 31
2.5.3　jupyter 31
2.5.4　scikit-image 32
2.5.5　librosa 32
2.5.6　nltk 32
2.5.7　keras 33
2.5.8　tflearn 33
2.6　小结 33
第3章　可视化TensorFlow 34
3.1　PlayGround 34
3.1.1　数据 35
3.1.2　特征 36
3.1.3　隐藏层 36
3.1.4　输出 37
3.2　TensorBoard 39
3.2.1　SCALARS面板 40
3.2.2　IMAGES面板 41
3.2.3　AUDIO面板 42
3.2.4　GRAPHS面板 42
3.2.5　DISTRIBUTIONS面板 43
3.2.6　HISTOGRAMS面板 43
3.2.7　EMBEDDINGS面板 44
3.3　可视化的例子 44
3.3.1　降维分析 44
3.3.2　嵌入投影仪 48
3.4　小结 51
第4章　TensorFlow基础知识 52
4.1　系统架构 52
4.2　设计理念 53
4.3　编程模型 54
4.3.1　边 56
4.3.2　节点 57
4.3.3　其他概念 57
4.4　常用API 60
4.4.1　图、操作和张量 60
4.4.2　可视化 61
4.5　变量作用域 62
4.5.1　variable_scope示例 62
4.5.2　name_scope示例 64
4.6　批标准化 64
4.6.1　方法 65
4.6.2　优点 65
4.6.3　示例 65
4.7　神经元函数及优化方法 66
4.7.1　激活函数 66
4.7.2　卷积函数 69
4.7.3　池化函数 72
4.7.4　分类函数 73
4.7.5　优化方法 74
4.8　模型的存储与加载 79
4.8.1　模型的存储与加载 79
4.8.2　图的存储与加载 82
4.9　队列和线程 82
4.9.1　队列 82
4.9.2　队列管理器 85
4.9.3　线程和协调器 86
4.10　加载数据 87
4.10.1　预加载数据 87
4.10.2　填充数据 87
4.10.3　从文件读取数据 88
4.11　实现一个自定义操作 92
4.11.1　步骤 92
4.11.2　最佳实践 93
4.12　小结 101
第5章　TensorFlow源代码解析 102
5.1　TensorFlow的目录结构 102
5.1.1　contirb 103
5.1.2　core 104
5.1.3　examples 105
5.1.4　g3doc 105
5.1.5　python 105
5.1.6　tensorboard 105
5.2　TensorFlow源代码的学习方法 106
5.3　小结 108
第6章　神经网络的发展及其TensorFlow实现 109
6.1　卷积神经网络 109
6.2　卷积神经网络发展 110
6.2.1　网络加深 111
6.2.2　增强卷积层的功能 115
6.2.3　从分类任务到检测任务 120
6.2.4　增加新的功能模块 121
6.3　MNIST的AlexNet实现 121
6.3.1　加载数据 121
6.3.2　构建网络模型 122
6.3.3　训练模型和评估模型 124
6.4　循环神经网络 125
6.5　循环神经网络发展 126
6.5.1　增强隐藏层的功能 127
6.5.2　双向化及加深网络 129
6.6　TensorFlow Model Zoo 131
6.7　其他研究进展 131
6.7.1　强化学习 132
6.7.2　深度森林 132
6.7.3　深度学习与艺术 132
6.8　小结 133
第7章　TensorFlow的高级框架 134
7.1　TFLearn 134
7.1.1　加载数据 134
7.1.2　构建网络模型 135
7.1.3　训练模型 135
7.2　Keras 135
7.2.1　Keras的优点 136
7.2.2　Keras的模型 136
7.2.3　Keras的使用 137
7.3　小结 141
第二篇　实战篇
第8章　第一个TensorFlow程序 144
8.1　TensorFlow的运行方式 144
8.1.1　生成及加载数据 144
8.1.2　构建网络模型 145
8.1.3　训练模型 145
8.2　超参数的设定 146
8.3　小结 147
第9章　TensorFlow在MNIST中的应用 148
9.1　MNIST数据集简介 148
9.1.1　训练集的标记文件 148
9.1.2　训练集的图片文件 149
9.1.3　测试集的标记文件 149
9.1.4　测试集的图片文件 150
9.2　MNIST的分类问题 150
9.2.1　加载数据 150
9.2.2　构建回归模型 151
9.2.3　训练模型 151
9.2.4　评估模型 152
9.3　训练过程的可视化 152
9.4　MNIST的卷积神经网络 156
9.4.1　加载数据 157
9.4.2　构建模型 157
9.4.3　训练模型和评估模型 159
9.5　MNIST的循环神经网络 161
9.5.1　加载数据 161
9.5.2　构建模型 161
9.5.3 训练数据及评估模型 163
9.6　MNIST的无监督学习 164
9.6.1　自编码网络 164
9.6.2　TensorFlow的自编码网络实现 165
9.7　小结 169
第10章　人脸识别 170
10.1　人脸识别简介 170
10.2　人脸识别的技术流程 171
10.2.1　人脸图像采集及检测 171
10.2.2　人脸图像预处理 171
10.2.3　人脸图像特征提取 171
10.2.4　人脸图像匹配与识别 172
10.3　人脸识别的分类 172
10.3.1　人脸检测 172
10.3.2　人脸关键点检测 173
10.3.3　人脸验证 174
10.3.4　人脸属性检测 174
10.4　人脸检测 175
10.4.1　LFW数据集 175
10.4.2　数据预处理 175
10.4.3　进行检测 176
10.5　性别和年龄识别 178
10.5.1　数据预处理 179
10.5.2　构建模型 181
10.5.3　训练模型 182
10.5.4　验证模型 184
10.6　小结 185
第11章　自然语言处理 186
11.1　模型的选择 186
11.2　英文数字语音识别 187
11.2.1　定义输入数据并预处理数据 188
11.2.2　定义网络模型 188
11.2.3　训练模型 188
11.2.4　预测模型 189
11.3　智能聊天机器人 189
11.3.1　原理 190
11.3.2　最佳实践 191
11.4　小结 200
第12章　图像与语音的结合 201
12.1　看图说话模型 201
12.1.1　原理 202
12.1.2　最佳实践 203
12.2　小结 205
第13章　生成式对抗网络 206
13.1　生成式对抗网络的原理 206
13.2　生成式对抗网络的应用 207
13.3　生成式对抗网络的实现 208
13.4　生成式对抗网络的改进 214
13.5　小结 214
第三篇　提高篇
第14章　分布式TensorFlow 216
14.1　分布式原理 216
14.1.1　单机多卡和分布式 216
14.1.2　分布式部署方式 217
14.2　分布式架构 218
14.2.1　客户端、主节点和工作节点的关系 218
14.2.2　客户端、主节点和工作节点的交互过程 220
14.3　分布式模式 221
14.3.1　数据并行 221
14.3.2　同步更新和异步更新 222
14.3.3　模型并行 224
14.4　分布式API 225
14.5　分布式训练代码框架 226
14.6　分布式最佳实践 227
14.7　小结 235
第15章　TensorFlow线性代数编译框架XLA 236
15.1　XLA的优势 236
15.2　XLA的工作原理 237
15.3　JIT编译方式 238
15.3.1　打开JIT编译 238
15.3.2　将操作符放在XLA设备上 238
15.4　JIT编译在MNIST上的实现 239
15.5　小结 240
第16章　TensorFlow Debugger 241
16.1　Debugger的使用示例 241
16.2　远程调试方法 245
16.3　小结 245
第17章　TensorFlow和Kubernetes结合 246
17.1　为什么需要Kubernetes 246
17.2　分布式TensorFlow在Kubernetes中的运行 247
17.2.1　部署及运行 247
17.2.2　其他应用 253
17.3　小结 254
第18章　TensorFlowOnSpark 255
18.1　TensorFlowOnSpark的架构 255
18.2　TensorFlowOnSpark在MNIST上的实践 257
18.3　小结 261
第19章　TensorFlow移动端应用 262
19.1　移动端应用原理 262
19.1.1　量化 263
19.1.2　优化矩阵乘法运算 266
19.2　iOS系统实践 266
19.2.1　环境准备 266
19.2.2　编译演示程序并运行 267
19.2.3　自定义模型的编译及运行 269
19.3　Android系统实践 273
19.3.1　环境准备 274
19.3.2　编译演示程序并运行 275
19.3.3　自定义模型的编译及运行 277
19.4　树莓派实践 278
19.5　小结 278
第20章　TensorFlow的其他特性 279
20.1　TensorFlow Serving 279
20.2　TensorFlow Flod 280
20.3　TensorFlow计算加速 281
20.3.1　CPU加速 281
20.3.2　TPU加速和FPGA加速 282
20.4　小结 283
第21章　机器学习的评测体系 284
21.1　人脸识别的性能指标 284
21.2　聊天机器人的性能指标 284
21.3　机器翻译的评价方法 286
21.3.1　BLEU 286
21.3.2　METEOR 287
21.4　常用的通用评价指标 287
21.4.1　ROC和AUC 288
21.4.2　AP和mAP 288
21.5　小结 288
附录A　公开数据集 289
附录B　项目管理经验小谈 292
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow技术解析与实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>科学计算中的蒙特卡罗策略
第1章 引言与实例
1.1 对蒙特卡罗技术的需求
1.2 全书的范围及概要
1.3 统计物理学中的计算
1.4 分子结构模拟
1.5 生物信息学：找弱重复图样
1.6 非线性动力系统：目标追踪
1.7 天文观测中的假设检验
1.8 多层模型的贝叶斯推断
1.9 蒙特卡罗和缺失数据问题
第2章 基本原理：舍取法、加权法以及其他方法
2.1 生成简单随机变量
2.2 舍取法
2.3 方差减少法.
2.4 链式结构模型的精确方法
2.4.1 动态规划
2.4.2 精确模拟
2.5 重点抽样和加权样本
2.5.1 一个例子
.2.5.2 基本思想
2.5.3 重点抽样的经验法则
2.5.4 加权样本的概念
2.5.5 重点抽样中的边际化方法
2.5.6 例子：求解一个线性系统
2.5.7 例子：贝叶斯缺失数据问题
2.6 高级重点抽样技术
2.6.1 自适应重点抽样
2.6.2 舍取和加权
2.6.3 序贯重点抽样
2.6.4 序贯重点抽样中的舍取控制
2.7 sis在群体遗传学中的应用
2.8 问题
第3章 序贯蒙特卡罗的理论
3.1 早期发展：凝聚成聚合物
3.1.1 一个简单的聚合物模型：自避免游动
3.1.2 在方格子点上凝聚成聚合物
3.1.3 增长性方法的局限性
3.2 统计缺失数据问题的序贯补借
3.2.1 似然计算
3.2.2 贝叶斯计算
3.3 非线性滤波
3.4 一般框架
3.4.1 抽样分布的选择
3.4.2 归一化常数
3.4.3 修剪、增峰和重抽样
3.4.4 再谈重抽样
3.4.5 部分舍取控制
3.4.6 边际化、先行和延迟估计
3.5 问题
第4章 应用序贯蒙特卡罗
4.1 生物学问题
44.1.1 分子模拟
4.1.2 种群遗传学中的推断
4.1.3 找dna序列的基序模式
4.2 近似积和
4.3 有固定边际和的0-1表格的计算
4.4 贝叶斯缺失数据问题
4.4.1 murray数据
4.4.2 二项分布数据的非参数贝叶斯分析
4.5 信号处理问题
4.5.1 混杂信号的目标跟踪和混合kalman滤波
4.5.2 衰落信道的数字信号提取
4.6 问题
第5章 metropolis算法及其推广
5.1 metropolis算法
5.2 数学公式和hastings的推广
5.3 为什么metropolis算法是正确的?
5.4 一些特殊算法
5.4.1 随机游动metropolis算法
5.4.2 metropolis化独立抽样
5.4.3 结构偏差(configurationalbias)蒙特卡罗
5.5 多点：metropolis方法
5.5.1 多重独立建议
5.5.2 关联性多点建议
5.6 可逆跳跃法则
5.7 动态权
5.8 输出分析和算法的效率
5.9 问题
第6章 gibbs抽样
6.1 gibbs抽样算法
6.2 实例分析
6.3 一些特殊的抽样
6.3.1 切片(slice)抽样
6.3.2 metropolis化gibbs抽样
6.3 ,3打了就走(hit-and-run)算法
6.4 数据扩充算法
6.4.1 贝叶斯缺失数据问题
6.4.2 最初的da算法
6.4.3 与gibbs抽样的联系
6.4.4 一个例子：分层贝叶斯模型
6.5 找生物序列中的重复基序
6.5.1 探测隐基序的gibbs抽样
6.5.2 排列与分类
6.6 gibbs抽样的协方差结构
6.6.1 数据增广
6.6.2 随机扫描gibbs抽样的自协方差
6.6.3 蒙特卡罗抽样更为有效的应用
6.7 gibbs抽样中的折叠与聚类
6.8 问题
第7章 伊辛模型的聚类算法
7.1 伊辛模型和potts模型的回访
7.2 数据增广的swendsen-wang算法
7.3 收敛分析和推广
7.4 wolff改进算法
7.5 进一步的推广
7.6 讨论
7.7 问题
第8章 广义条件抽样
8.1 部分重抽样
8.2 部分重抽样的案例研究
8.2.1 高斯随机场模型
8.2.2 纹理合成
8.2.3 多元t分布的推断
8.3 变换群和广义gibbs
8.4 应用：数据增广的参数扩张
8.5 贝叶斯推断中的一些例子
8.5.1 probit回归
8.5.2 蒙特卡罗与随机微分方程的联系
8.6 问题
第9章 分子动力学和杂交蒙特卡罗方法
9.1 牛顿力学基础
9.2 分子动力学模拟
9.3 杂交蒙特卡罗
9.4 与hmc相关的算法
9.4.1 langevin-euler移动
9.4.2 广义杂交蒙特卡罗
……
第10章 多层抽样和优化方法
第11章 基于总体的蒙特卡罗方法
第12章 马尔可夫链及其收敛性
第13章 精选的理论论题
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>科学计算中的蒙特卡罗策略
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>颠覆大数据分析
目录
前言
致谢
关于作者
1 引言：为什么要超越 Hadoop Map-Reduce  1
Hadoop的适用范围  3
大数据分析之机器学习实现的革命  10
第一代机器学习工具 /范式  11
第二代机器学习工具 /范式  11
第三代机器学习工具 /范式  14
小结  18
参考文献  19
2 何为伯克利数据分析栈（BDAS）  23
实现 BDAS的动机  24
Spark：动机  25
Shark：动机  26
Mesos：动机  28
BDAS的设计及架构  29
Spark：高效的集群数据处理的范式  34
Spark的弹性分布式数据集  36
Spark的实现  40
Spark VS. 分布式共享内存系统  42
RDD的表达性  44
类似 Spark的系统  45
Shark：分布式系统上的 SQL接口  46
Spark为 Shark提供的扩展  47
列内存存储  49
分布式数据加载  50
完全分区智能连接  50
分区修剪  50
机器学习的支持  51
Mesos：集群调度及管理系统  51
Mesos组件  52
资源分配  54
隔离  55
容错性  57
小结  58
参考文献  59
3 使用 Spark实现机器学习算法  66
机器学习基础知识  66
机器学习：随机森林示例  68
逻辑回归：概述  72
二元形式的逻辑回归  73
逻辑回归估计  75
多元逻辑回归  76
Spark中的逻辑回归算法  77
支持向量机  80
复杂决策面  81
支持向量机背后的数学原理  82
Spark中的支持向量机  84
Spark对 PMML的支持  85
PMML结构  87
PMML的生产者及消费者  92
Spark对朴素贝叶斯的 PMML支持  94
Spark对线性回归的 PMML支持  95
在 Spark中使用 MLbase进行机器学习  97
参考文献  99
4 实现实时的机器学习算法 101
Storm简介  101
数据流  103
拓扑  104
Storm集群  105
简单的实时计算例子  106
数据流组  108
Storm的消息处理担保  109
基于 Storm的设计模式  111
分布式远程过程调用  111
Trident：基于 Storm的实时聚合  115
实现基于 Storm的逻辑回归算法  116
实现基于 Storm的支持向量机算法  120
Storm对朴素贝叶斯 PMML的支持  122
实时分析的应用  126
工业日志分类  126
互联网流量过滤器  130
Storm的替代品  131
Spark流  133
D-Streams的动机  133
参考文献  135
5 图处理范式 138
Pregel：基于 BSP的图处理框架  139
类似的做法  141
开源的 Pregel实现  143
Giraph  143
GoldenORB  145
Phoebus  145
Apache Hama  146
Stanford GPS  146
GraphLab  147
GraphLab：多核版本  148
分布式的 GraphLab  150
PowerGraph  152
通过 GraphLab实现网页排名算法  156
顶点程序  158
基于 GraphLab实现随机梯度下降算法  163
参考文献  167
6 结论：超越Hadoop Map-Reduce的大数据分析  171
Hadoop YARN概览  172
Hadoop YARN的动机  172
作为资源调度器的 YARN  174
YARN上的其他框架  175
大数据分析的未来是怎样的  177
参考文献  180
附录A 代码笔记  182
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>颠覆大数据分析
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
第一部分 引论
第一章 引论
第二部分 逻辑和搜索
第二章 逻辑
第三章 搜索
第四章 自动逻辑推理
第三部分 不确定性
第五章 贝叶斯网络I
第六章 贝叶斯网络II
第七章 其他不确定性方法
第四部分 行动决策
第八章 决策网络
第九章 规划I
第十章 规划II
第五部分 学习
第十一章 学习引论
第十二章 决策树学习
第十三章 归纳逻辑程序设计
第十四章 强化学习
第十五章 神经网络I
第十六章 神经网络II
第十七章 遗传算法
第六部分 自然语言理解与感知
第十八章 自然语言处理I
第十九章 自然语言处理II
第二十章 语音处理
第二十一章 视觉
第七部分 代理，哲学和应用
第二十二章 代理
第二十三章 人工智能的哲学
第二十四章 人工智能的若干应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>人工智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习核心技术与实践
第1 部分深度学习基础篇1
1 概述2
1.1 人工智能  3
1.1.1 人工智能的分类  3
1.1.2 人工智能发展史  3
1.2 机器学习  7
1.2.1 机器学习的由来  7
1.2.2 机器学习发展史  9
1.2.3 机器学习方法分类  10
1.2.4 机器学习中的基本概念  11
1.3 神经网络  12
1.3.1 神经网络发展史  13
参考文献  16
2 神经网络17
2.1 在神经科学中对生物神经元的研究  17
2.1.1 神经元激活机制  17
2.1.2 神经元的特点  18
2.2 神经元模型  19
2.2.1 线性神经元  19
2.2.2 线性阈值神经元  19
2.2.3 Sigmoid 神经元  21
2.2.4 Tanh 神经元  22
2.2.5 ReLU  22
2.2.6 Maxout  24
2.2.7 Softmax  24
2.2.8 小结  25
2.3 感知机  27
2.3.1 感知机的提出  27
2.3.2 感知机的困境  28
2.4 DNN  29
2.4.1 输入层、输出层及隐层  30
2.4.2 目标函数的选取  30
2.4.3 前向传播  32
2.4.4 后向传播  33
2.4.5 参数更新  35
2.4.6 神经网络的训练步骤  36
参考文献  36
3 初始化模型38
3.1 受限玻尔兹曼机  38
3.1.1 能量模型  39
3.1.2 带隐藏单元的能量模型  40
3.1.3 受限玻尔兹曼机基本原理  41
3.1.4 二值RBM  43
3.1.5 对比散度  45
3.2 自动编码器  47
3.2.1 稀疏自动编码器  48
3.2.2 降噪自动编码器  48
3.2.3 栈式自动编码器  49
3.3 深度信念网络  50
参考文献  52
4 卷积神经网络53
4.1 卷积算子  53
4.2 卷积的特征  56
4.3 卷积网络典型结构  59
4.3.1 基本网络结构  59
4.3.2 构成卷积神经网络的层  59
4.3.3 网络结构模式  60
4.4 卷积网络的层  61
4.4.1 卷积层  61
4.4.2 池化层  66
参考文献  67
5 循环神经网络68
5.1 循环神经网络简介  68
5.2 RNN、LSTM 和GRU  69
5.3 双向RNN  76
5.4 RNN 语言模型的简单实现  77
参考文献  80
6 深度学习优化算法81
6.1 SGD  81
6.2 Momentum  82
6.3 NAG  83
6.4 Adagrad  85
6.5 RMSProp  86
6.6 Adadelta  87
6.7 Adam  88
6.8 AdaMax  90
6.9 Nadam  90
6.10 关于优化算法的使用  92
参考文献  92
7 深度学习训练技巧94
7.1 数据预处理  94
7.2 权重初始化  95
7.3 正则化  96
7.3.1 提前终止  96
7.3.2 数据增强  96
7.3.3 L2/L1 参数正则化  98
7.3.4 集成  100
7.3.5 Dropout  101
参考文献  102
8 深度学习框架103
8.1 Theano  103
8.1.1 Theano  103
8.1.2 安装  104
8.1.3 计算图  104
8.2 Torch  105
8.2.1 概述  105
8.2.2 安装  106
8.2.3 核心结构  107
8.2.4 小试牛刀  110
8.3 PyTorch  113
8.3.1 概述  113
8.3.2 安装  113
8.3.3 核心结构  114
8.3.4 小试牛刀  114
8.4 Caffe  117
8.4.1 概述  117
8.4.2 安装  118
8.4.3 核心组件  119
8.4.4 小试牛刀  125
8.5 TensorFlow  125
8.5.1 概述  125
8.5.2 安装  126
8.5.3 核心结构  126
8.5.4 小试牛刀  127
8.6 MXNet  131
8.6.1 概述  131
8.6.2 安装  131
8.6.3 核心结构  132
8.6.4 小试牛刀  133
8.7 Keras  135
8.7.1 概述  135
8.7.2 安装  136
8.7.3 模块介绍  136
8.7.4 小试牛刀  136
参考文献  139
第2 部分计算机视觉篇140
9 计算机视觉背景141
9.1 传统计算机视觉  141
9.2 基于深度学习的计算机视觉  145
9.3 参考文献  146
10 图像分类模型147
10.1 LeNet-5  147
10.2 AlexNet  149
10.3 VGGNet  154
10.3.1 网络结构  155
10.3.2 配置  157
10.3.3 讨论  157
10.3.4 几组实验  158
10.4 GoogLeNet  159
10.4.1 NIN  161
10.4.2 GoogLeNet 的动机  161
10.4.3 网络结构细节  162
10.4.4 训练方法  164
10.4.5 后续改进版本  165
10.5 ResNet  165
10.5.1 基本思想  165
10.5.2 网络结构  167
10.6 DenseNet  169
10.7 DPN  170
参考文献  170
11 目标检测173
11.1 相关研究  175
11.1.1 选择性搜索  175
11.1.2 OverFeat  177
11.2 基于区域提名的方法  179
11.2.1 R-CNN  179
11.2.2 SPP-net  181
11.2.3 Fast R-CNN  182
11.2.4 Faster R-CNN  184
11.2.5 R-FCN  185
11.3 端到端的方法  186
11.3.1 YOLO  186
11.3.2 SSD  187
11.4 小结  188
参考文献  190
12 语义分割192
12.1 全卷积网络  193
12.1.1 FCN  193
12.1.2 DeconvNet  195
12.1.3 SegNet  197
12.1.4 DilatedConvNet  198
12.2 CRF/MRF 的使用  199
12.2.1 DeepLab  199
12.2.2 CRFasRNN  201
12.2.3 DPN  203
12.3 实例分割  205
12.3.1 Mask R-CNN  205
参考文献  206
13 图像检索的深度哈希编码208
13.1 传统哈希编码方法  208
13.2 CNNH  209
13.3 DSH  210
13.4 小结  212
参考文献  212
第3 部分语音识别篇214
14 传统语音识别基础215
14.1 语音识别简介  215
14.2 HMM 简介  216
14.2.1 HMM 是特殊的混合模型  218
14.2.2 转移概率矩阵  219
14.2.3 发射概率  220
14.2.4 Baum-Welch 算法  220
14.2.5 后验概率  224
14.2.6 前向-后向算法  224
14.3 HMM 梯度求解  227
14.3.1 梯度算法1  228
14.3.2 梯度算法2  230
14.3.3 梯度求解的重要性  234
14.4 孤立词识别  234
14.4.1 特征提取  234
14.4.2 孤立词建模  235
14.4.3 GMM-HMM  237
14.5 连续语音识别  240
14.6 Viterbi 解码  243
14.7 三音素状态聚类  245
14.8 判别式训练  248
参考文献  254
15 基于WFST 的语音解码256
15.1 有限状态机  257
15.2 WFST 及半环定义  257
15.2.1 WFST  257
15.2.2 半环（Semiring）  258
15.3 自动机操作  260
15.3.1 自动机基本操作  261
15.3.2 转换器基本操作  262
15.3.3 优化操作  265
15.4 基于WFST 的语音识别系统  277
15.4.1 声学模型WFST  279
15.4.2 三音素WFST  281
15.4.3 发音字典WFST  281
15.4.4 语言模型WFST  282
15.4.5 WFST 组合和优化  284
15.4.6 组合和优化实验  285
15.4.7 WFST 解码  286
参考文献  287
16 深度语音识别288
16.1 CD-DNN-HMM  288
16.2 TDNN  292
16.3 CTC  295
16.4 EESEN  299
16.5 Deep Speech  301
16.6 Chain  310
参考文献  313
17 CTC 解码315
17.1 序列标注  315
17.2 序列标注任务的解决办法  316
17.2.1 序列分类  316
17.2.2 分割分类  317
17.2.3 时序分类  318
17.3 隐马模型  318
17.4 CTC 基本定义  319
17.5 CTC 前向算法  321
17.6 CTC 后向算法  324
17.7 CTC 目标函数  325
17.8 CTC 解码基本原理  327
17.8.1 最大概率路径解码  327
17.8.2 前缀搜索解码  328
17.8.3 约束解码  329
参考文献  333
第4 部分自然语言处理篇334
18 自然语言处理简介335
18.1 NLP 的难点  335
18.2 NLP 的研究范围  336
19 词性标注338
19.1 传统词性标注模型  338
19.2 基于神经网络的词性标注模型  340
19.3 基于Bi-LSTM 的神经网络词性标注模型  342
参考文献  344
20 依存句法分析345
20.1 背景  346
20.2 SyntaxNet 技术要点  348
20.2.1 Transition-based 系统  349
20.2.2 “模板化” 技术  353
20.2.3 Beam Search  355
参考文献  357
21 word2vec 358
21.1 背景  359
21.1.1 词向量  359
21.1.2 统计语言模型  359
21.1.3 神经网络语言模型  362
21.1.4 Log-linear 模型  364
21.1.5 Log-bilinear 模型  365
21.1.6 层次化Log-bilinear 模型  365
21.2 CBOW 模型  366
21.3 Skip-gram 模型  369
21.4 Hierarchical Softmax 与Negative Sampling  371
21.5 fastText  372
21.6 GloVe  373
21.7 小结  374
参考文献  374
22 神经网络机器翻译376
22.1 机器翻译简介  376
22.2 神经网络机器翻译基本模型  377
22.3 基于Attention 的神经网络机器翻译  379
22.4 谷歌机器翻译系统GNMT  381
22.5 基于卷积的机器翻译  382
22.6 小结  383
参考文献  384
第5 部分深度学习研究篇385
23 Batch Normalization 386
23.1 前向与后向传播  387
23.1.1 前向传播  387
23.1.2 后向传播  390
23.2 有效性分析  393
23.2.1 内部协移  393
23.2.2 梯度流  393
23.3 使用与优化方法  395
23.4 小结  396
参考文献  396
24 Attention 397
24.1 从简单RNN 到RNN + Attention  398
24.2 Soft Attention 与Hard Attention  398
24.3 Attention 的应用  399
24.4 小结  401
参考文献  402
25 多任务学习403
25.1 背景  403
25.2 什么是多任务学习  404
25.3 多任务分类与其他分类概念的关系  406
25.3.1 二分类  406
25.3.2 多分类  407
25.3.3 多标签分类  407
25.3.4 相关关系  408
25.4 多任务学习如何发挥作用  409
25.4.1 提高泛化能力的潜在原因  410
25.4.2 多任务学习机制  410
25.4.3 后向传播多任务学习如何发现任务是相关的  412
25.5 多任务学习被广泛应用  413
25.5.1 使用未来预测现在  413
25.5.2 多种表示和度量  413
25.5.3 时间序列预测  413
25.5.4 使用不可操作特征  414
25.5.5 使用额外任务来聚焦  414
25.5.6 有序迁移  414
25.5.7 多个任务自然地出现  414
25.5.8 将输入变成输出  414
25.6 多任务深度学习应用  416
25.6.1 脸部特征点检测  416
25.6.2 DeepID2  418
25.6.3 Fast R-CNN  419
25.6.4 旋转人脸网络  420
25.6.5 实例感知语义分割的MNC  422
25.7 小结  423
参考文献  425
26 模型压缩426
26.1 模型压缩的必要性  426
26.2 较浅的网络  428
26.3 剪枝  428
26.4 参数共享  434
26.5 紧凑网络  437
26.6 二值网络  438
26.7 小结  442
参考文献  442
27 增强学习445
27.1 什么是增强学习  445
27.2 增强学习的数学表达形式  448
27.2.1 MDP  449
27.2.2 策略函数  450
27.2.3 奖励与回报  450
27.2.4 价值函数  452
27.2.5 贝尔曼方程  453
27.2.6 最优策略性质  453
27.3 用动态规划法求解增强学习问题  454
27.3.1 Agent 的目标  454
27.3.2 策略评估  455
27.3.3 策略改进  456
27.3.4 策略迭代  457
27.3.5 策略迭代的例子  458
27.3.6 价值迭代  459
27.3.7 价值迭代的例子  461
27.3.8 策略函数和价值函数的关系  462
27.4 无模型算法  462
27.4.1 蒙特卡罗法  463
27.4.2 时序差分法  465
27.4.3 Q-Learning  466
27.5 Q-Learning 的例子  467
27.6 AlphaGo 原理剖析  469
27.6.1 围棋与机器博弈  469
27.6.2 Alpha-Beta 树  472
27.6.3 MCTS  473
27.6.4 UCT  476
27.6.5 AlphaGo 的训练策略  478
27.6.6 AlphaGo 的招式搜索算法  482
27.6.7 围棋的对称性  484
27.7 AlphaGo Zero  484
参考文献  484
28 GAN 486
28.1 生成模型  486
28.2 生成对抗模型的概念  488
28.3 GAN 实战  492
28.4 InfoGAN——探寻隐变量的内涵  493
28.5 Image-Image Translation  496
28.6 WGAN（Wasserstein GAN）  499
28.6.1 GAN 目标函数的弱点  500
28.6.2 Wasserstein 度量的优势  501
28.6.3 WGAN 的目标函数  504
参考文献  505
A 本书涉及的开源资源列表 506
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习核心技术与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘
目 录
第1章  数据挖掘的概念	1
1.1  概述	1
1.2  数据挖掘的起源	3
1.3  数据挖掘过程	4
1.4  大型数据集	7
1.5  数据仓库	10
1.6  数据挖掘的商业方面：为什么
数据挖掘项目会失败	13
1.7  本书结构安排	15
1.8  复习题	16
1.9  参考书目	17
第2章  数据准备	19
2.1  原始数据的表述	19
2.2  原始数据的特性	23
2.3  原始数据的转换	24
2.3.1  标准化	24
2.3.2  数据平整	25
2.3.3  差值和比率	25
2.4  丢失数据	26
2.5  时间相关数据	27
2.6  异常点分析	30
2.7  复习题	35
2.8  参考书目	38
第3章  数据归约	41
3.1  大型数据集的维度	41
3.2  特征归约	43
3.2.1  特征选择	44
3.2.2  特征提取	48
3.3  Relief算法	50
3.4  特征排列的熵度量	51
3.5  主成分分析	53
3.6  值归约	55
3.7  特征离散化：
ChiMerge技术	58
3.8  案例归约	61
3.9  复习题	63
3.10  参考书目	64
第4章  从数据中学习	67
4.1  学习机器	68
4.2  统计学习原理	72
4.3  学习方法的类型	75
4.4  常见的学习任务	77
4.5  支持向量机	80
4.6  kNN：最近邻分类器	90
4.7  模型选择与泛化	92
4.8  模型的评估	95
4.9  90%准确的情形	100
4.9.1  保险欺诈检测	101
4.9.2  改进心脏护理	102
4.10  复习题	103
4.11  参考书目	104
第5章  统计方法	107
5.1  统计推断	107
5.2  评测数据集的差异	109
5.3  贝叶斯定理	112
5.4  预测回归	114
5.5  方差分析	118
5.6  对数回归	120
5.7  对数-线性模型	121
5.8  线性判别分析	124
5.9  复习题	126
5.10  参考书目	128
第6章  决策树和决策规则	131
6.1  决策树	132
6.2  C4.5算法：生成决策树	134
6.3  未知属性值	139
6.4  修剪决策树	142
6.5  C4.5算法：生成决策规则	143
6.6  CART算法和Gini指标	146
6.7  决策树和决策规则的
局限性	148
6.8  复习题	150
6.9  参考书目	153
第7章  人工神经网络	155
7.1  人工神经元的模型	156
7.2  人工神经网络的结构	159
7.3  学习过程	161
7.4  使用ANN完成的
学习任务	164
7.4.1  模式联想	164
7.4.2  模式识别	164
7.5  多层感知机	166
7.6  竞争网络和竞争学习	172
7.7  SOM	174
7.8  复习题	178
7.9  参考书目	180
第8章  集成学习	183
8.1  集成学习方法论	184
8.2  多学习器组合方案	187
8.3  bagging和boosting	188
8.4  AdaBoost算法	189
8.5  复习题	190
8.6  参考书目	193
第9章  聚类分析	195
9.1  聚类的概念	195
9.2  相似度的度量	198
9.3  凝聚层次聚类	203
9.4  分区聚类	206
9.5  增量聚类	208
9.6  DBSCAN算法	211
9.7  BIRCH 算法	213
9.8  聚类验证	215
9.9  复习题	215
9.10  参考书目	218
第10章  关联规则	221
10.1  购物篮分析	222
10.2  Apriori 算法	223
10.3  从频繁项集中得到
关联规则	225
10.4  提高Apriori算法的效率	226
10.5  FP增长方法	227
10.6  关联分类方法	229
10.7  多维关联规则挖掘	231
10.8  复习题	232
10.9  参考书目	236
第11章  Web挖掘和文本挖掘	237
11.1  Web挖掘	237
11.2  Web内容、结构与
使用挖掘	238
11.3  HITS和LOGSOM算法	240
11.4  挖掘路径遍历模式	245
11.5  PageRank算法	247
11.6  文本挖掘	249
11.7  潜在语义分析	252
11.8  复习题	255
11.9  参考书目	257
第12章  数据挖掘高级技术	259
12.1  图挖掘	259
12.2  时态数据挖掘	270
12.2.1  时态数据表示	271
12.2.2  序列之间的相似性
度量	274
12.2.3  时态数据模型	276
12.2.4  数据挖掘	277
12.3  空间数据挖掘(SDM)	281
12.4  分布式数据挖掘(DDM)	284
12.5  关联并不意味着存在
因果关系	290
12.6  数据挖掘的隐私、安全及
法律问题	295
12.7  复习题	299
12.8  参考书目	300
第13章  遗传算法	303
13.1  遗传算法的基本原理	304
13.2  用遗传算法进行优化	305
13.2.1  编码方案和初始化	306
13.2.2  适合度估计	306
13.2.3  选择	307
13.2.4  交叉	308
13.2.5  突变	308
13.3  遗传算法的简单例证	310
13.3.1  表述	310
13.3.2  初始群体	311
13.3.3  评价	311
13.3.4  交替	312
13.3.5  遗传算子	312
13.3.6  评价(第二次迭代)	313
13.4  图式	314
13.5  旅行推销员问题	316
13.6  使用遗传算法的
机器学习	318
13.6.1  规则交换	320
13.6.2  规则概化	320
13.6.3  规则特化	321
13.6.4  规则分割	321
13.7  遗传算法用于聚类	321
13.8  复习题	323
13.9  参考书目	324
第14章  模糊集和模糊逻辑	327
14.1  模糊集	327
14.2  模糊集的运算	332
14.3  扩展原理和模糊关系	335
14.4  模糊逻辑和模糊
推理系统	339
14.5  多因子评价	342
14.6  从数据中提取模糊模型	344
14.7  数据挖掘和模糊集	349
14.8  复习题	350
14.9  参考书目	352
第15章  可视化方法	353
15.1  感知和可视化	353
15.2  科学可视化和信息
可视化	354
15.3  平行坐标	359
15.4  放射性可视化	361
15.5  使用自组织映射进行
可视化	363
15.6  数据挖掘的可视化系统	365
15.7  复习题	368
15.8  参考书目	369
附录A  数据挖掘工具	371
附录B  数据挖掘应用	393
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习原理与TensorFlow实践
1    深度学习简介  1
1.1  深度学习介绍  1
1.2  深度学习的趋势  7
1.3  参考资料  10
2    TensorFlow系统介绍  12
2.1  TensorFlow诞生的动机  12
2.2  TensorFlow系统简介  14
2.3  TensorFlow基础概念  16
2.3.1  计算图  16
2.3.2  Session会话  18
2.4  系统架构  19
2.5  源码结构  21
2.5.1  后端执行引擎  22
2.5.2  前端语言接口  24
2.6  小结  24
2.7  参考资料  25
3    Hello TensorFlow  26
3.1  环境准备  26
3.1.1  Mac OS安装  27
3.1.2  Linux GPU服务器安装  28
3.1.3  常用Python库  32
3.2  Titanic题目实战  34
3.2.1  Kaggle平台介绍  34
3.2.2  Titanic题目介绍  35
3.2.3  数据读入及预处理  38
3.2.4  构建计算图  40
3.2.5  构建训练迭代过程  44
3.2.6  执行训练  46
3.2.7  存储和加载模型参数  47
3.2.8  预测测试数据结果  50
3.3  数据挖掘的技巧  51
3.3.1  数据可视化  52
3.3.2  特征工程  54
3.3.3  多种算法模型  57
3.4  TensorBoard可视化  58
3.4.1  记录事件数据  58
3.4.2  启动TensorBorad服务  60
3.5  数据读取  62
3.5.1  数据文件格式  63
3.5.2  TFRecord  63
3.6  SkFlow、TFLearn与TF-Slim  67
3.7  小结  69
3.8  参考资料  69
4    CNN“看懂”世界  71
4.1  图像识别的难题  72
4.2  CNNs的基本原理  74
4.2.1  卷积的数学意义  75
4.2.2  卷积滤波  77
4.2.3  CNNs中的卷积层  81
4.2.4  池化（Pooling）  83
4.2.5  ReLU  84
4.2.6  多层卷积  86
4.2.7  Dropout  86
4.3  经典CNN模型  87
4.3.1  AlexNet  88
4.3.2  VGGNets  95
4.3.3  GoogLeNet & Inception  98
4.3.4  ResNets  106
4.4  图像风格转换  109
4.4.1  量化的风格  109
4.4.2  风格的滤镜  116
4.5  小结  120
4.6  参考资料  121
5    RNN“能说会道”  123
5.1  文本理解和文本生成问题  124
5.2  标准RNN模型  128
5.2.1  RNN模型介绍  128
5.2.2  BPTT算法  130
5.2.3  灵活的RNN结构  132
5.2.4  TensorFlow实现正弦序列预测  135
5.3  LSTM模型  138
5.3.1  长期依赖的难题  138
5.3.2  LSTM基本原理  139
5.3.3  TensorFlow构建LSTM模型  142
5.4  更多RNN的变体  144
5.5  语言模型  146
5.5.1  NGram语言模型  146
5.5.2  神经网络语言模型  148
5.5.3  循环神经网络语言模型  150
5.5.4  语言模型也能写代码  152
5.5.5  改进方向  163
5.6  对话机器人  164
5.6.1  对话机器人的发展  165
5.6.2  基于seq2seq的对话机器人  169
5.7  小结  181
5.8  参考资料  182
6    CNN+LSTM看图说话  183
6.1  CNN+LSTM网络模型与图像检测问题  184
6.1.1  OverFeat和Faster R-CNN图像检测算法介绍  185
6.1.2  遮挡目标图像检测方法  187
6.1.3  ReInspect算法实现及模块说明  188
6.1.4  ReInspect算法的实验数据与结论  204
6.2  CNN+LSTM网络模型与图像摘要问题  207
6.2.1  图像摘要问题  208
6.2.2  NIC图像摘要生成算法  209
6.2.3  NIC图像摘要生成算法实现说明  214
6.2.4  NIC算法的实验数据与结论  243
6.3  小结  249
6.4  参考资料  250
7    损失函数与优化算法  253
7.1  目标函数优化策略  254
7.1.1  梯度下降算法  254
7.1.2  RMSProp优化算法  256
7.1.3  Adam优化算法  257
7.1.4  目标函数优化算法小结  258
7.2  类别采样（Candidate Sampling）损失函数  259
7.2.1  softmax类别采样损失函数  261
7.2.2  噪声对比估计类别采样损失函数  281
7.2.3  负样本估计类别采样损失函数  286
7.2.4  类别采样logistic损失函数  286
7.3  小结  287
7.4  参考资料  288
结语  289
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习原理与TensorFlow实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能大数据SMART准则
引 言 欢迎来到更为智能的世界  / 1
智能运动  / 2
智能保健  / 3
智能家居  / 4
智能恋爱  / 5
智能育儿  / 6
第 1 章 商业智能化  / 8
谁是大数据用户？  / 9
公司是如何运用大数据的  / 11
别慌！  / 15
专心收获成果  / 16
第 2 章 S：制定智能战略  / 19
大数据世界，小就是美  / 22
SMART 战略板  / 25
梨树隐喻  / 27
实践中的 SMART 战略板  / 29
问对了问题是成功的一半  / 35
SMART 分析技术和谷歌  / 37
案例研究：Oxygen 计划  / 38
重点和行动纲领  / 43
第 3 章 M：度量指标和数据  / 44
数据类型  / 45
结构化数据  / 46
非结构化数据和半结构化数据  / 47
内部数据  / 48
外部数据  / 49
数据库：数据的新形式  / 50
活动数据  / 51
会话数据  / 54
照片和音频数据  / 55
传感器数据  / 58
物联网  / 61
大数据的分解  / 63
大数据反弹  / 64
如何测量和使用数据来获得战略性优势  / 67
确认你需要测量的数据  / 68
行动上的指标和数据  / 80
重点和行动纲领  / 82
第 4 章 A：运用数据分析技术  / 84
文本分析法  / 87
文本归类  / 88
文本收集  / 88
概念提取  / 89
情感分析  / 89
文件归纳  / 94
小结  / 94
言语分析法  / 96
小结  / 97
视频和图像分析技术  / 99
人脸识别  / 100
行为分析  / 102
态势感知  / 104
视频/图像分析技术已经被投入使用  / 104
负面效应  / 107
联合分析技术  / 108
联合分析技术的医疗应用  / 108
联合分析技术的其他应用  / 110
被点赞说明什么  / 112
透明度  / 115
不断创造附加值  / 119
预测 VS .隐私  / 120
做正确的事！  / 122
重点和行动纲领  / 123
第 5 章 R：展示数据分析结果  / 125
数据可视化  / 126
新式数据可视化  / 131
展示地图  / 131
展示文本  / 132
展示数据  / 134
展示行为和情绪  / 135
展示关联  / 136
无限可能  / 139
如何提升数据可视化水平  / 141
信息图表  / 143
注意自助式商业智能工具  / 148
成功的数据可视化和信息图的要素  / 152
管理仪表盘  / 154
终有一日壮志凌云  / 155
开发管理仪表盘  / 158
重点和行动纲领  / 161
第 6 章 T：改变商业模式  / 163
更好地理解并定位客户  / 164
改进优化业务流程  / 168
提高人们的健康和幸福水准  / 170
增强安全性，减少欺诈  / 175
鼓励提高企业和员工业绩  / 176
改善工作场所和其他基础设施的条件  / 180
新的商业机遇  / 181
智能化也将改变就业  / 187
重点和行动纲领  / 190
结论  / 192
关于作者  / 197
致谢  / 199
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能大数据SMART准则
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习
第1章　绪论   1
1.1  引言   1
1.2  人工智能的发展历程   2
1.3  机器学习及相关技术   4
1.3.1  学习形式分类   4
1.3.2  学习方法分类   5
1.3.3  机器学习的相关技术   7
1.4  国内外研究现状   8
1.4.1  国外研究现状   8
1.4.2  国内研究现状   9
第2章　深度学习   11
2.1  神经网络模型   11
2.1.1  人脑视觉机理   11
2.1.2  生物神经元   13
2.1.3  人工神经网络   15
2.2  BP神经网络   18
2.2.1  BP神经元   18
2.2.2  BP神经网络构成   19
2.2.3  正向传播   21
2.2.4  反向传播   21
2.3  卷积神经网络   24
2.3.1  卷积神经网络的历史   25
2.3.2  卷积神经网络的网络结构   26
2.3.3  局部感知   27
2.3.4  参数共享   28
2.3.5  多卷积核   28
2.3.6  池化（Pooling）   29
2.4  深度学习框架   30
2.4.1  Caffe   30
2.4.2  Torch   31
2.4.3  Keras   32
2.4.4  MXNet   32
2.4.5  TensorFlow   33
2.4.6  CNTK   33
2.4.7  Theano   34
第3章　Caffe简介及其安装配置   36
3.1  Caffe是什么   36
3.1.1  Caffe的特点   38
3.1.2  Caffe的架构   38
3.2  Caffe的安装环境   39
3.2.1  Caffe的硬件环境   39
3.2.2  Caffe的软件环境   43
3.2.3  Caffe的依赖库   44
3.2.4  Caffe开发环境的安装   46
3.3  Caffe接口   52
3.3.1  Caffe Python接口   52
3.3.2  Caffe MATLAB接口   55
3.3.3  Caffe命令行接口   56
第4章　Caffe网络定义   58
4.1  Caffe模型要素   58
4.1.1  网络模型   58
4.1.2  参数配置   62
4.2  Google Protobuf结构化数据   63
4.3  Caffe数据库   65
4.3.1  LevelDB   65
4.3.2  LMDB   66
4.3.3  HDF5   66
4.4  Caffe Net   66
4.5  Caffe Blob   68
4.6  Caffe Layer   70
4.6.1  Data Layers   71
4.6.2  Convolution Layers   75
4.6.3  Pooling Layers   76
4.6.4  InnerProduct Layers   77
4.6.5  ReLU Layers   78
4.6.6  Sigmoid Layers   79
4.6.7  LRN Layers   79
4.6.8  Dropout Layers   80
4.6.9  SoftmaxWithLoss Layers   80
4.6.10  Softmax Layers   81
4.6.11  Accuracy Layers   81
4.7  Caffe Solver   82
Solver方法   83
第5章　LeNet模型   88
5.1  LeNet模型简介   88
5.2  LeNet模型解读   89
5.3  Caffe环境LeNet模型   91
5.3.1  mnist实例详解   91
5.3.2  mnist手写测试   103
5.3.3  mnist样本字库的图片转换   106
第6章　AlexNet模型   107
6.1  AlexNet模型介绍   107
6.2  AlexNet模型解读   108
6.3  AlexNet模型特点   111
6.4  Caffe环境AlexNet模型训练   112
6.4.1  数据准备   112
6.4.2  其他支持文件   113
6.4.3  图片预处理   113
6.4.4  ImageNet数据集介绍   113
6.4.5  ImageNet图片介绍   115
6.4.6  ImageNet模型训练   115
6.4.7  Caffe的AlexNet模型与论文的不同   124
6.4.8  ImageNet模型测试   124
第7章　GoogLeNet模型   126
7.1  GoogLeNet模型简介   126
7.1.1  背景和动机   127
7.1.2  Inception结构   127
7.2  GoogLeNet模型解读   129
7.2.1  GoogLeNet模型结构   129
7.2.2  GoogLeNet模型特点   134
7.3  GoogLeNet模型的Caffe实现   135
第8章　VGGNet模型   146
8.1  VGGNet网络模型   146
8.1.1  VGGNet模型介绍   146
8.1.2  VGGNet模型特点   147
8.1.3  VGGNet模型解读   147
8.2  VGGNet网络训练   149
8.2.1  VGGNet训练参数设置   149
8.2.2  Multi-Scale训练   149
8.2.3  测试   150
8.2.4  部署   150
8.3  VGGNet模型分类实验   150
8.3.1  Single-scale对比   150
8.3.2  Multi-scale对比   151
8.3.3  模型融合   152
8.4  VGGNet网络结构   153
第9章　Siamese模型   158
9.1  Siamese网络模型   159
9.1.1  Siamese模型原理   159
9.1.2  Siamese模型实现   160
9.2  Siamese网络训练   165
9.2.1  数据准备   165
9.2.2  生成side   165
9.2.3  对比损失函数   166
9.2.4  定义solver   166
9.2.5  网络训练   166
第10章　SqueezeNet模型   168
10.1  SqueezeNet网络模型   168
10.1.1  SqueezeNet模型原理   168
10.1.2  Fire Module   169
10.1.3  SqueezeNet模型结构   170
10.1.4  SqueezeNet模型特点   171
10.2  SqueezeNet网络实现   172
第11章　FCN模型   177
11.1  FCN模型简介   177
11.2  FCN的特点和使用场景   178
11.3  Caffe FCN解读   179
11.3.1  FCN模型训练准备   180
11.3.1  FCN模型训练   183
第12章　R-CNN模型   196
12.1  R-CNN模型简介   196
12.2  R-CNN的特点和使用场景   197
12.3  Caffe R-CNN解读   198
12.3.1  R-CNN模型训练准备   198
12.3.2  R-CNN模型训练   201
第13章　Fast-RCNN模型   217
13.1  Fast-RCNN模型简介   217
13.2  Fast-RCNN的特点和使用场景   218
13.3  Caffe Fast-RCNN解读   220
13.3.1  Fast-RCNN模型训练准备   220
13.3.2  Fast-RCNN模型训练   222
第14章　Faster-RCNN模型   239
14.1  Faster-RCNN模型简介   239
14.2  Faster-RCNN的特点和使用场景   241
14.3  Caffe Faster-RCNN解读   242
14.3.1  Faster-RCNN模型训练准备   242
14.3.2  Faster-RCNN模型训练   244
第15章　SSD模型   264
15.1  SSD模型简介   264
15.2  SSD的特点和使用场景   266
15.3  Caffe SSD解读   267
15.3.1  SSD模型训练准备   267
15.3.2  SSD模型训练   268
第16章　Kaggle项目实践：人脸特征检测   290
16.1  项目简介   290
16.2  赛题和数据   291
16.3  Caffe训练和测试数据库   293
16.3.1  数据库生成   293
16.3.2  网络对比   295
16.3.3  网络一   296
16.3.4  网络二   300
16.3.5  Python人脸特征预测程序   306
第17章　Kaggle项目实践：猫狗分类检测   311
17.1  项目简介   311
17.2  赛题和数据   312
17.3  Caffe训练和测试数据库   312
17.3.1  数据库生成   312
17.3.2  Caffe实现   316
17.3.3  CatdogNet训练   328
17.3.4  CatdogNet模型验证   332
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据算法
序 1
前言 3
第1章二次排序：简介 19
二次排序问题解决方案 21
MapReduce/Hadoop的二次排序解决方案 25
Spark的二次排序解决方案 29
第2章二次排序：详细示例 42
二次排序技术 43
二次排序的完整示例 46
运行示例——老版本Hadoop API 50
运行示例——新版本Hadoop API 52
第3章 Top 10 列表 54
Top N 设计模式的形式化描述 55
MapReduce/Hadoop实现：唯一键 56
Spark实现：唯一键 62
Spark实现：非唯一键 73
使用takeOrdered()的Spark Top 10 解决方案 84
MapReduce/Hadoop Top 10 解决方案：非唯一键 91
第4章左外连接 96
左外连接示例 96
MapReduce左外连接实现 99
Spark左外连接实现 105
使用leftOuterJoin()的Spark实现 117
第5章反转排序 127
反转排序模式示例 128
反转排序模式的MapReduce/Hadoop实现 129
运行示例 134
第6章移动平均 137
示例1：时间序列数据（股票价格） 137
示例2：时间序列数据（URL访问数） 138
形式定义 139
POJO移动平均解决方案 140
MapReduce/Hadoop移动平均解决方案 143
第7章购物篮分析 155
MBA目标 155
MBA的应用领域 157
使用MapReduce的购物篮分析 157
Spark解决方案 166
运行Spark实现的YARN 脚本 179
第8章共同好友 182
输入 183
POJO共同好友解决方案 183
MapReduce算法 184
解决方案1: 使用文本的Hadoop实现 187
解决方案2: 使用ArrayListOfLongsWritable 的Hadoop实现 189
Spark解决方案 191
第9章使用MapReduce实现推荐引擎 201
购买过该商品的顾客还购买了哪些商品 202
经常一起购买的商品 206
推荐连接 210
第10章基于内容的电影推荐 225
输入 226
MapReduce阶段1 226
MapReduce阶段2和阶段3 227
Spark电影推荐实现 234
第11章使用马尔可夫模型的智能邮件营销 .253
马尔可夫链基本原理 254
使用MapReduce的马尔可夫模型 256
Spark解决方案 269
第12章 K-均值聚类 282
什么是K-均值聚类? 285
聚类的应用领域 285
K-均值聚类方法非形式化描述：分区方法 286
K-均值距离函数 286
K-均值聚类形式化描述 287
K-均值聚类的MapReduce解决方案 288
K-均值算法Spark实现 292
第13章 k-近邻 296
kNN分类 297
距离函数 297
kNN示例 298
kNN算法非形式化描述 299
kNN算法形式化描述 299
kNN的类Java非MapReduce 解决方案 299
Spark的kNN算法实现 301
第14章朴素贝叶斯 315
训练和学习示例 316
条件概率 319
深入分析朴素贝叶斯分类器 319
朴素贝叶斯分类器：符号数据的MapReduce解决方案 322
朴素贝叶斯分类器Spark实现 332
使用Spark和Mahout 347
第15章情感分析 349
情感示例 350
情感分数：正面或负面 350
一个简单的MapReduce情感分析示例 351
真实世界的情感分析 353
第16章查找、统计和列出大图中的所有三角形 354
基本的图概念 355
三角形计数的重要性 356
MapReduce/Hadoop解决方案 357
Spark解决方案 364
第17章 K-mer计数 375
K-mer计数的输入数据 376
K-mer计数应用 376
K-mer计数MapReduce/Hadoop解决方案 377
K-mer计数Spark解决方案 378
第18章 DNA测序 390
DNA测序的输入数据 392
输入数据验证 393
DNA序列比对 393
DNA测试的MapReduce算法 394
第19章 Cox回归 413
Cox模型剖析 414
使用R的Cox回归 415
Cox回归应用 416
Cox回归 POJO解决方案 417
MapReduce输入 418
使用MapReduce的Cox回归 419
第20章 Cochran-Armitage趋势检验 426
Cochran-Armitage算法 427
Cochran-Armitage应用 432
MapReduce解决方案 435
第21章等位基因频率 443
基本定义 444
形式化问题描述 448
等位基因频率分析的MapReduce解决方案 449
MapReduce解决方案, 阶段1 449
MapReduce解决方案，阶段2 459
MapReduce解决方案, 阶段3 463
染色体X 和Y的特殊处理 466
第22章 T检验 468
对bioset完成T检验 469
MapReduce问题描述 472
输入 472
期望输出 473
MapReduce解决方案 473
Spark实现 476
第23章皮尔逊相关系数 488
皮尔逊相关系数公式 489
皮尔逊相关系数示例 491
皮尔逊相关系数数据集 492
皮尔逊相关系数POJO 解决方案 492
皮尔逊相关系数MapReduce解决方案 493
皮尔逊相关系数的Spark 解决方案 496
运行Spark程序的YARN 脚本 516
使用Spark计算斯皮尔曼相关系数 517
第24章 DNA碱基计数 520
FASTA 格式 521
FASTQ 格式 522
MapReduce解决方案：FASTA 格式 522
运行示例 524
MapReduce解决方案: FASTQ 格式 528
Spark 解决方案: FASTA 格式 533
Spark解决方案: FASTQ 格式 537
第25章 RNA测序 543
数据大小和格式 543
MapReduce工作流 544
RNA测序分析概述 544
RNA测序MapReduce算法 548
第26章基因聚合 553
输入 554
输出 554
MapReduce解决方案（按单个值过滤和按平均值过滤） 555
基因聚合的Spark解决方案 567
Spark解决方案：按单个值过滤 567
Spark解决方案：按平均值过滤 576
第27章线性回归 586
基本定义 587
简单示例 587
问题描述 588
输入数据 589
期望输出 590
使用SimpleRegression的MapReduce解决方案 590
Hadoop实现类 593
使用R线性模型的MapReduce解决方案 593
第28章 MapReduce和幺半群 600
概述 600
幺半群的定义 602
幺半群和非幺半群示例 603
MapReduce示例：非幺半群 606
MapReduce示例：幺半群 608
使用幺半群的Spark示例 612
使用幺半群的结论 618
函子和幺半群 619
第29章小文件问题 622
解决方案1：在客户端合并小文件 623
解决方案2：用CombineFileInputFormat解决小文件问题 629
其他解决方案 634
第30章 MapReduce的大容量缓存 635
实现方案 636
缓存问题形式化描述 637
一个精巧、可伸缩的解决方案 637
实现LRUMap缓存 640
使用LRUMap的MapReduce解决方案 646
第31章 Bloom过滤器 651Bloom
过滤器性质 651
一个简单的Bloom过滤器示例 653
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>高级人工智能
前言
第1章 绪论
第2章 人工智能逻辑
第3章 约束推理
第4章 定性推理
第5章 基于案例的推理
第6章 贝叶斯网络
第7章 归纳学习
第8章 统计学习
第9章 解释学习
第10章 强化学习
第11章 元监督学习
第12章 关联规则
第13章 进化计算
第14章 知识发现
第15章 主体计算
第16章 互联网智能
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>高级人工智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Mahout实践指南（大数据技术丛书）
第1章　Mahout入门 / 1
秘笈1　安装Java和Hadoop / 1
秘笈2　设置Maven和NetBeans开发环境 / 6
秘笈3　编写一个基本的推荐系统 / 9
第2章　使用序列文件——什么时候和为什么 / 19
秘笈4　从命令行创建序列文件 / 20
秘笈5　编写代码创建序列文件 / 23
秘笈6　编码实现读取序列文件 / 28
第3章　将Mahout和外部资源整合 / 33
秘笈7　导入外部资源到HDFS / 34
秘笈8　将数据从HDFS导入到RDBMS / 43
秘笈9　创建一个Sqoop作业来处理RDBMS / 45
秘笈10　使用Sqoop API导入数据 / 47
第4章　实现朴素贝叶斯分类器 / 49
秘笈11　使用Mahout文本分类器演示基本的使用样例 / 50
秘笈12　编码实现朴素贝叶斯分类器 / 60
秘笈13　通过命令行使用互补朴素贝叶斯 / 64
秘笈14　编码使用互补朴素贝叶斯分类器 / 65
第5章　股市预测 / 67
秘笈15　为logistic回归准备数据 / 67
秘笈16　使用logistic预测GOOG股票动态 / 71
秘笈17　通过Java编码使用自适应的logistic回归 / 76
秘笈18　在大规模的数据集上使用logistic回归 / 79
秘笈19　使用随机森林预测市场动态 / 83
第6章　顶棚聚类 / 87
秘笈20　基于命令行的顶棚聚类 / 87
秘笈21　基于带参数命令行的顶棚聚类 / 91
秘笈22　通过Java代码使用顶棚聚类 / 95
秘笈23　编写你自己的距离估计 / 98
第7章　频谱聚类 / 101
秘笈24　通过命令行使用EigenCuts / 101
秘笈25　在Java代码中使用EigenCuts / 104
秘笈26　从原始数据创建相似度矩阵 / 108
秘笈27　使用频谱聚类进行图像分割 / 114
第8章　K-均值聚类 / 119
秘笈28　在Java代码中使用K-均值聚类 / 119
秘笈29　使用K-均值聚类对交通事故进行聚类 / 124
秘笈30　使用MapReduce进行K-均值聚类 / 128
秘笈31　命令行方式使用K-均值聚类 / 132
第9章　软计算 / 139
秘笈32　使用Mahout进行频繁模式挖掘 / 139
秘笈33　为频繁模式挖掘创建评价准则 / 142
秘笈34　在Java代码中使用频繁模式挖掘 / 147
秘笈35　使用LDA创建主题 / 153
第10章　实现遗传算法 / 159
秘笈36　设置Mahout以便使用遗传算法 / 159
秘笈37　在图上使用遗传算法 / 163
秘笈38　在Java代码中使用遗传算法 / 167
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Mahout实践指南（大数据技术丛书）
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Keras快速上手：基于Python的深度学习实战
1 准备深度学习的环境 1
1.1 硬件环境的搭建和配置选择  1
1.1.1 通用图形处理单元  3
1.1.2 你需要什么样的 GPU 加速卡  6
1.1.3 你的 GPU 需要多少内存  6
1.1.4 是否应该用多个 GPU  10
1.2 安装软件环境  12
1.2.1 所需软件列表  12
1.2.2 CUDA 的安装  13
1.2.3 Python 计算环境的安装  13
1.2.4 深度学习建模环境介绍  15
1.2.5 安装 CNTK 及对应的 Keras  17
1.2.6 安装 Theano 计算环境  23
1.2.7 安装 TensorFlow 计算环境  25
1.2.8 安装 cuDNN 和 CNMeM  27
2 数据收集与处理 28
2.1 网络爬虫  28
2.1.1 网络爬虫技术  29
2.1.2 构造自己的 Scrapy 爬虫  30
2.1.3 构造可接受参数的 Scrapy 爬虫  35
2.1.4 运行 Scrapy 爬虫  36
2.1.5 运行 Scrapy 爬虫的一些要点  38
2.2 大规模非结构化数据的存储和分析  40
2.2.1 ElasticSearch 介绍  42
2.2.2 ElasticSearch 应用实例  44
3 深度学习简介 57
3.1 概述  57
3.2 深度学习的统计学入门  58
3.3 一些基本概念的解释  61
3.3.1 深度学习中的函数类型  62
3.3.2 深度学习中的其他常见概念  65
3.4 梯度递减算法  67
3.5 后向传播算法  70
4 Keras 入门 72
4.1 Keras 简介  72
4.2 Keras 中的数据处理  73
4.2.1 文字预处理  74
4.2.2 序列数据预处理  82
4.2.3 图片数据输入  83
4.3 Keras 中的模型  83
4.4 Keras 中的重要对象  86
4.5 Keras 中的网络层构造  90
4.6 使用 Keras 进行奇异值矩阵分解  102
5 推荐系统 105
5.1 推荐系统简介  105
5.2 矩阵分解模型  108
5.3 深度神经网络模型  114
5.4 其他常用算法  117
5.5 评判模型指标  119
6 图像识别 121
6.1 图像识别入门  121
6.2 卷积神经网络的介绍  122
6.3 端到端的 MNIST 训练数字识别  127
6.4 利用 VGG16 网络进行字体识别  131
6.5 总结  135
7 自然语言情感分析 136
7.1 自然语言情感分析简介  136
7.2 文字情感分析建模  139
7.2.1 词嵌入技术  139
7.2.2 多层全连接神经网络训练情感分析  140
7.2.3 卷积神经网络训练情感分析  143
7.2.4 循环神经网络训练情感分析  144
7.3 总结  146
8 文字生成 147
8.1 文字生成和聊天机器人  147
8.2 基于检索的对话系统  148
8.3 基于深度学习的检索式对话系统  159
8.3.1 对话数据的构造  159
8.3.2 构造深度学习索引模型  162
8.4 基于文字生成的对话系统  166
8.5 总结  172
9 时间序列 173
9.1 时间序列简介  173
9.2 基本概念  174
9.3 时间序列模型预测准确度的衡量  178
9.4 时间序列数据示例  179
9.5 简要回顾 ARIMA 时间序列模型  181
9.6 循环神经网络与时间序列模型  186
9.7 应用案例  188
9.7.1 长江汉口月度流量时间序列模型  190
9.7.2 国际航空月度乘客数时间序列模型  203
9.8 总结  209
10 智能物联网 210
10.1 Azure 和 IoT  210
10.2 Azure IoT Hub 服务  213
10.3 使用 IoT Hub 管理设备概述  215
10.4 使用.NET 将模拟设备连接到 IoT 中心  218
10.5 机器学习应用实例  237
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Keras快速上手：基于Python的深度学习实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>爱犯错的智能体
目录
简单视觉错觉/1
1 视觉倒像 / 2
2 颠倒的视界 / 7
3 看不见的萨摩耶 / 13
4 看得见的斑点狗 18
5 火星人脸的阴影 / 23
6 外国的月亮比较圆 / 32
复杂视觉错觉/39
7 眼中的黎曼流形与距离错觉 / 40
8 由粗到细、大范围优先的视觉 / 53
9 抽象的颜色与高层认知 / 61
10 自举的视觉与智能 / 70
11 主观时间与运动错觉 79
听觉、体感和语言/89
12 听觉错觉与语音、歌唱的智能分析 / 90
13 视听错觉与无限音阶中的拓扑 / 101
14 我思故我在？ / 114
15 可塑与多义 / 122
梦、顿悟与情感/133
16 庄周梦蝶与梦境学习 / 134
17 灵光一闪与认知错觉 / 144
18 情感与回忆错觉 / 153
群体智能/161
19 群体的情感共鸣：AI 写歌，抓不住回忆 / 162
20 群体智能与错觉 / 169
总结/181
21 平衡：机器 vs 智能 / 182
附录/201
附录一：深度学习，你就是那位 116 岁的长寿老奶奶！/200
附录二：童话（同化）世界的人工智能/205
参考文献 / 209
图片来源 / 229
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>爱犯错的智能体
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘
第1章 数据挖掘的概念
第2章 数据准备
第3章 数据归约
第4章 从数据中学习
第5章 统计方法
第6章 聚类分析
第7章 决策树和决策规则
第8章 关联规则
第9章 人工神经网络
第10章 遗传算法
第11章 模糊集和模糊逻辑
第12章 可视化方法
第13章 参考书目
附录A 数据挖掘工具
附录B 数据挖掘应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据挖掘
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>情感分析：挖掘观点、情感和情绪
目　录
Sentiment Analysis：Mining Opinions，Sentiments，and Emotions
译者序
前言
致谢
第1章　引言1
1.1　情感分析应用3
1.2　情感分析研究6
1.2.1　针对不同文本颗粒度的情感分析研究7
1.2.2　情感词典及其问题8
1.2.3　辩论与评论分析9
1.2.4　意图挖掘9
1.2.5　垃圾观点检测与评论质量10
1.3　情感分析是个迷你自然语言处理任务11
1.4　本书撰写方式11
第2章　什么是情感分析13
2.1　观点定义14
2.1.1　观点的定义14
2.1.2　情感对象15
2.1.3　观点中的情感16
2.1.4　简化的观点定义17
2.1.5　观点的理由和限定条件19
2.1.6　情感分析的目标和任务20
2.2　观点摘要定义23
2.3　感情、情绪与心情24
2.3.1　心理学中的感情、情绪与心情25
2.3.2　情感分析中的感情、情绪与心情28
2.4　观点的不同类型30
2.4.1　常规型观点和比较型观点31
2.4.2　主观的和隐含在事实中的观点31
2.4.3　第一人称和非第一人称观点34
2.4.4　元观点35
2.5　作者和读者视角35
2.6　小结36
第3章　文档级情感分类37
3.1　基于监督的情感分类38
3.1.1　基于机器学习算法的情感分类38
3.1.2　使用自定义打分函数的情感分类44
3.2　基于无监督的情感分类45
3.2.1　使用句法模板和网页检索的情感分类45
3.2.2　使用情感词典的情感分类46
3.3　情感评分预测48
3.4　跨领域情感分类49
3.5　跨语言情感分类51
3.6　文档的情绪分类52
3.7　小结53
第4章　句子级主客观和情感分类54
4.1　主观性55
4.2　句子级主客观分类56
4.3　句子级情感分类59
4.3.1　句子级情感分类的前提假设59
4.3.2　分类方法60
4.4　处理条件句61
4.5　处理讽刺句62
4.6　跨语言主客观分类和情感分类64
4.7　在情感分类中使用语篇信息65
4.8　句子级情绪分类66
4.9　讨论67
第5章　属性级情感分类68
5.1　属性级情感分类方法69
5.1.1　基于监督学习的方法69
5.1.2　基于词典的方法70
5.1.3　两种方法的优缺点72
5.2　情感组合规则73
5.2.1　情感组合规则概述74
5.2.2　情感减弱和情感增强表达81
5.2.3　SMALL_OR_LESS和LARGE_OR_MORE表达83
5.2.4　情绪和情感强度86
5.2.5　情感词的含义86
5.2.6　其他方法概述88
5.3　否定和情感89
5.3.1　否定词89
5.3.2　never92
5.3.3　其他常用的情感转换词94
5.3.4　否定词移动现象94
5.3.5　否定范围95
5.4　情态和情感96
5.5　并列连词but100
5.6　非观点内容的情感词102
5.7　规则表示103
5.8　词义消歧和指代消解105
5.9　小结106
第6章　属性和实体抽取108
6.1　基于频率的属性抽取109
6.2　利用句法关系110
6.2.1　利用观点和观点评价对象间的评价关系111
6.2.2　利用部分整体和属性关系116
6.3　基于监督学习的属性抽取118
6.3.1　隐马尔可夫模型118
6.3.2　条件随机场119
6.4　隐含属性的映射121
6.4.1　基于语料库的方法121
6.4.2　基于词典的方法122
6.5　属性聚类124
6.6　基于主题模型的属性抽取126
6.6.1　隐狄利克雷分配127
6.6.2　基于无监督主题模型进行观点属性抽取129
6.6.3　在主题模型中加入领域先验知识133
6.6.4　基于终身学习的主题模型：像人类一样学习135
6.6.5　使用短语作为主题词138
6.7　实体抽取与消解141
6.7.1　实体抽取与消解的问题定义142
6.7.2　实体抽取144
6.7.3　实体链接145
6.7.4　实体搜索和链接147
6.8　观点持有者和观点时间抽取147
6.9　小结148
第7章　情感词典构建149
7.1　基于词典的方法149
7.2　基于语料库的方法152
7.2.1　从语料库中识别情感词152
7.2.2　处理上下文相关的情感词153
7.2.3　词典自适应155
7.2.4　其他相关工作156
7.3　隐含了情感信息（期望或者不期望）的事实型描述156
7.4　小结158
第8章　比较型观点分析159
8.1　问题定义159
8.2　比较句识别162
8.3　比较句中的优选实体集识别163
8.4　特殊类型的比较句164
8.4.1　非标准型比较164
8.4.2　交叉类型的比较166
8.4.3　单实体比较167
8.4.4　带有compare和comparison的句子168
8.5　实体与属性抽取169
8.6　小结170
第9章　观点摘要和检索172
9.1　基于属性的观点摘要172
9.2　基于属性的观点摘要进阶175
9.3　可对照的观点摘要176
9.4　传统摘要177
9.5　比较型观点摘要177
9.6　观点检索177
9.7　现有观点检索技术178
9.8　小结180
第10章　辩论与评论分析181
10.1　辩论中的立场识别181
10.2　对辩论、讨论进行建模184
10.2.1　JTE模型185
10.2.2　JTE-R模型：对回复关系进行建模188
10.2.3　JTE-P模型：考虑作者之间的交互关
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>情感分析：挖掘观点、情感和情绪
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习、优化与识别
第1章 深度学习基础 1
1.1 数学基础 2
1.1.1 矩阵论 2
1.1.2 概率论 3
1.1.3 优化分析 5
1.1.4 框架分析 6
1.2 稀疏表示 8
1.2.1 稀疏表示初步 8
1.2.2 稀疏模型 20
1.2.3 稀疏认知学习、计算与识别的范式 24
1.3 机器学习与神经网络 31
1.3.1 机器学习 31
1.3.2 神经网络 36
参考文献 38
第2章 深度前馈神经网络 41
2.1 神经元的生物机理 42
2.1.1 生物机理 42
2.1.2 单隐层前馈神经网络 43
2.2 多隐层前馈神经网络 45
2.3 反向传播算法 47
2.4 深度前馈神经网络的学习范式 48
参考文献 51
第3章 深度卷积神经网络 54
3.1 卷积神经网络的生物机理及数学刻画 55
3.1.1 生物机理 55
3.1.2 卷积流的数学刻画 56
3.2 深度卷积神经网络 61
3.2.1 典型网络模型与框架 61
3.2.2 学习算法及训练策略 69
3.2.3 模型的优缺点分析 71
3.3 深度反卷积神经网络 73
3.3.1 卷积稀疏编码 74
3.3.2 深度反卷积神经网络 75
3.3.3 网络模型的性能分析与应用举例 77
3.4 全卷积神经网络 77
3.4.1 网络模型的数学刻画 77
3.4.2 网络模型的性能分析及应用举例 79
参考文献 80
第4章 深度堆栈自编码网络 83
4.1 自编码网络 84
4.1.1 逐层学习策略 84
4.1.2 自编码网络 84
4.1.3 自编码网络的常见范式 87
4.2 深度堆栈网络 90
4.3 深度置信网络/深度玻尔兹曼机网络 93
4.3.1 玻尔兹曼机/受限玻尔兹曼机 93
4.3.2 深度玻尔兹曼机/深度置信网络 94
参考文献 96
第5章 稀疏深度神经网络 99
5.1 稀疏性的生物机理 100
5.1.1 生物视觉机理 100
5.1.2 稀疏性响应与数学物理描述 102
5.2 稀疏深度网络模型及基本性质 102
5.2.1 数据的稀疏性 103
5.2.2 稀疏正则 103
5.2.3 稀疏连接 104
5.2.4 稀疏分类器设计 106
5.2.5 深度学习中关于稀疏的技巧与策略 108
5.3 网络模型的性能分析 110
5.3.1 稀疏性对深度学习的影响 110
5.3.2 对比实验及结果分析 110
参考文献 111
第6章 深度融合网络 113
6.1 深度SVM网络 114
6.1.1 从神经网络到SVM 114
6.1.2 网络模型的结构 115
6.1.3 训练技巧 117
6.2 深度PCA网络 117
6.3 深度ADMM网络 119
6.4 深度极限学习机 121
6.4.1 极限学习机 121
6.4.2 深度极限学习机 123
6.5 深度多尺度几何网络 125
6.5.1 深度脊波网络 125
6.5.2 深度轮廓波网络 127
6.6 深度森林 130
6.6.1 多分辨特性融合 131
6.6.2 级联特征深度处理 131
参考文献 133
第7章 深度生成网络 136
7.1 生成式对抗网络的基本原理 137
7.1.1 网络模型的动机 137
7.1.2 网络模型的数学物理描述 139
7.2 深度卷积对抗生成网络 141
7.2.1 网络模型的基本结构 141
7.2.2 网络模型的性能分析 144
7.2.3 网络模型的典型应用 146
7.3 深度生成网络模型的新范式 151
7.3.1 生成式对抗网络的新范式 151
7.3.2 网络框架的性能分析与改进 154
7.4 应用驱动下的两种新生成式对抗网络 155
7.4.1 堆栈生成式对抗网络 155
7.4.2 对偶学习范式下的生成式对抗网络 158
7.5 变分自编码器 160
参考文献 162
第8章 深度复卷积神经网络与深度二值神经网络 167
8.1 深度复卷积神经网络 168
8.1.1 网络模型构造的动机 168
8.1.2 网络模型的数学物理描述 168
8.2 深度二值神经网络 172
8.2.1 网络基本结构 172
8.2.2 网络的数学物理描述 173
8.2.3 讨论 176
参考文献 177
第9章 深度循环和递归神经网络 180
9.1 深度循环神经网络 181
9.1.1 循环神经网络的生物机理 181
9.1.2 简单的循环神经网络 181
9.1.3 深度循环神经网络的数学物理描述 183
9.2 深度递归神经网络 188
9.2.1 简单的递归神经网络 188
9.2.2 深度递归神经网络的优势 189
9.3 长短时记忆神经网络 190
9.3.1 改进动机分析 190
9.3.2 长短时记忆神经网络的数学分析 191
9.4 典型应用 192
9.4.1 深度循环神经网络的应用举例 193
9.4.2 深度递归神经网络的应用举例 194
参考文献 194
第10章 深度强化学习 197
10.1 深度强化学习基础 198
10.1.1 深度强化学习的基本思路 198
10.1.2 发展历程 198
10.1.3 应用的新方向 200
10.2 深度Q网络 201
10.2.1 网络基本模型与框架 201
10.2.2 深度Q网络的数学分析 202
10.3 应用举例—AlphaGo 204
10.3.1 AlphaGo原理分析 205
10.3.2 深度强化学习性能分析 206
参考文献 207
第11章 深度学习软件仿真平台及开发环境 209
11.1 Caffe平台 210
11.1.1 Caffe平台开发环境 210
11.1.2 AlexNet神经网络学习 210
11.1.3 AlexNet神经网络应用于图像分类 212
11.2 TensorFlow平台 215
11.2.1 TensorFlow平台开发环境 215
11.2.2 深度卷积生成式对抗网DCGAN 216
11.2.3 DAN应用于样本扩充 217
11.3 MXNet平台 220
11.3.1 MXNet平台开发环境 220
11.3.2 VGG-NET深度神经网络学习 222
11.3.3 图像分类应用任务 225
11.4 Torch 7平台 226
11.4.1 Torch 7平台开发环境 226
11.4.2 二值神经网络 227
11.4.3 二值神经网络应用于图像分类 239
11.5 Theano平台 233
11.5.1 Theano平台开发环境 233
11.5.2 递归神经网络 234
11.5.3 LSTM应用于情感分类任务 237
参考文献 238
第12章 基于深度神经网络的SAR/PolSAR影像地物分类 240
12.1 数据集及研究目的 241
12.1.1 数据集特性分析 241
12.1.2 基本数据集 244
12.1.3 研究目的 247
12.2 基于深度神经网络的SAR影像地物分类 251
12.2.1 基于自适应自编码和超像素的SAR图像分类 251
12.2.2 基于卷积中层特征学习的SAR图像分类 257
12.3 基于第一代深度神经网络的PolSAR影像地物分类 263
12.3.1 基于稀疏极化DBN的极化SAR地物分类 263
12.3.2 基于深度PCA网络的极化SAR影像地物分类 267
12.4 基于第二代深度神经网络的PolSAR影像地物分类 271
12.4.1 基于深度复卷积网络的极化PolSAR影像地物分类 271
12.4.2基于生成式对抗网的极化PolSAR影像地物分类 274
12.4.3基于深度残差网络的极化PolSAR影像地物分类 278
参考文献 280
第13章 基于深度神经网络的SAR影像变化检测 284
13.1 数据集特点及研究目的 285
13.1.1 研究目的 285
13.1.2 数据基本特性 288
13.1.3 典型数据集 291
13.2 基于深度学习和SIFT特征的SAR图像变化检测 293
13.2.1 基本方法与实现策略 284
13.2.2 对比实验结果分析 295
13.3基于SAE的SAR图像变化检测 299
13.3.1 基本方法与实现策略 299
13.3.2 对比实验结果分析 303
13.4基于CNN的SAR图像变化检测 305
13.4.1基本方法与实现策略 305
13.4.2对比实验结果分析 307
参考文献 309
第14章 基于深度神经网络的高光谱图像分类与压缩 311
14.1 数据集及研究目的 312
14.1.1 高光谱遥感技术 312
14.1.2 高光谱遥感的研究目的 313
14.1.3 常用的高光谱数据集 314
14.2 基于深度神经网络的高光谱影像的分类 318
14.2.1 基于堆栈自编码的高光谱影像的分类 319
14.2.2 基于卷积神经网络的高光谱影像的分类 325
14.3基于深度神经网络的高光谱影像的压缩 333
14.3.1 基于深度自编码网络的高光谱图像压缩方法 334
14.3.2 实验设计及分类结果 336
参考文献 338
第15章 基于深度神经网络的目标检测与识别 340
15.1 数据特性及研究目的 341
15.1.1 研究目的 341
15.1.2 常用数据集 343
15.2 基于快速CNN的目标检测与识别 345
15.2.1 R-CNN 346
15.2.2 Fast R-CNN 348
15.2.3 Faster R-CNN 349
15.2.4 对比实验结果与分析 352
15.3 基于回归学习的目标检测与识别 353
15.3.1 YOLO 353
15.3.2 SSD 356
15.3.3 对比实验结果分析 359
15.4 基于学习搜索的目标检测与识别 360
15.4.1 基于深度学习的主动目标定位 360
15.4.2 AttentionNet 363
15.4.3 对比实验结果分析 365
参考文献 366
第16章 总结与展望 368
16.1 深度学习发展历史图 369
16.1.1 从机器学习、稀疏表示学习到深度学习 370
16.1.2 深度学习、计算与认知的范式演进 371
16.1.3 深度学习形成脉络 375
16.2 深度学习的典型应用 375
16.2.1 目标检测与识别 375
16.2.2 超分辨 376
16.2.3 自然语言处理 376
16.3 深度神经网络的可塑性 377
16.3.1 旋转不变性 377
16.3.2 平移不变性 378
16.3.3 多尺度、多分辨和多通路特性 378
16.3.4 稀疏性 379
16.4 基于脑启发式的深度学习前沿方向 380
16.4.1 生物神经领域关于认知、识别、注意等的最新研究进展 380
16.4.2 深度神经网络的进一步研究方向 382
16.4.3 深度学习的可拓展性 383
参考文献 383
附录A 基于深度学习的常见任务处理介绍 386
附录B 代码介绍 393
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习、优化与识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能Web算法
前言 .............. XV
致谢 ............. XIX
关于本书 ...... XXI
1 什么是智能Web......................................... 1
1.1 智能Web 应用实例 ............................................ 3
1.2 智能应用的基本要素 ......................................... 4
1.3 什么应用会受益于智能 ..................................... 5
1.3.1 社交网络 . 6
1.3.2 Mashup .... 7
1.3.3 门户网站 . 8
1.3.4 维基 ......... 9
1.3.5 文件分享网站 ......................................... 9
1.3.6 网络游戏 ............................................... 11
1.4 如何构建智能应用 ........................................... 11
1.4.1 检查功能和数据 ................................... 12
1.4.2 获取更多的数据 ................................... 12
1.5 机器学习、数据挖掘及其他 ........................... 16
1.6 智能应用中八个常见的误区 ........................... 17
1.6.1 误区1：数据是可靠的 ........................ 18
1.6.2 误区2：计算能马上完成 .................... 19
1.6.3 误区3：不用考虑数据规模 ................ 19
1.6.4 误区4：不考虑解决方案的可扩展性  19
1.6.5 误区5：随处使用同样的方法 ............ 19
1.6.6 误区6：总是能知道计算时间 ............ 20
1.6.7 误区7：复杂的模型更好 .................... 20
1.6.8 误区8：存在无偏见的模型 ................ 20
1.7 小结 ................... 20
1.8 参考资料 ........... 21
2 搜索.......... 22
2.1 用Lucene 实现搜索 ......................................... 23
2.1.1 理解Lucene 代码 ................................. 24
2.1.2 搜索的基本步骤 ................................... 31
2.2 为什么搜索不仅仅是索引 ............................... 33
2.3 用链接分析改进搜索结果 ............................... 35
2.3.1 PageRank 简介 ...................................... 35
2.3.2 计算PageRank 向量 ............................. 37
2.3.3 alpha：网页间跳转的影响 .................. 38
2.3.4 理解幂方法 ........................................... 40
2.3.5 结合索引分值和PageRank 分值 ......... 45
2.4 根据用户点击改进搜索结果 ........................... 47
2.4.1 用户点击初探 ....................................... 48
2.4.2 朴素贝叶斯分类器的使用 ................... 50
2.4.3 整合Lucene 索引、PageRank 和用户点击 ........................................ 54
2.5 Word、PDF 等无链接文档的排序 .................. 58
2.5.1 DocRank 算法简介 ............................... 58
2.5.2 DocRank 的原理 ................................... 60
2.6 大规模实现的有关问题 ................................... 65
2.7 用户得到了想要的结果吗？精确度和查全率 ............................................... 67
2.8 总结 ................... 69
2.9 To Do ................. 70
2.10 参考资料 ......... 72
3 推荐系统 .. 73
3.1 一个在线音乐商店：基本概念 ....................... 74
3.1.1 距离与相似度的概念 ........................... 75
3.1.2 走近相似度的计算 ............................... 80
3.1.3 什么才是最好的相似度计算公式 ....... 83
3.2 推荐引擎是怎么工作的 ................................... 84
3.2.1 基于相似用户的推荐 ........................... 85
3.2.2 基于相似条目的推荐 ........................... 94
3.2.3 基于内容的推荐 ................................... 98
3.3 推荐朋友、文章与新闻报道 ......................... 104
3.3.1 MyDiggSpace.com 简介 ..................... 105
3.3.2 发现朋友 ............................................. 106
3.3.3 DiggDelphi 的内部工作机制 ............. 108
3.4 像Netflix.com 那样推荐电影 ........................ 114
3.4.1 电影数据集的介绍及推荐器 ............. 114
3.4.2 数据标准化与相关系数 ..................... 117
3.5 大规模的实现与评估 ..................................... 123
3.6 总结 ................. 124
3.7 To Do ............... 125
3.8 参考资料 ......... 127
4 聚类：事物的分组 .................................. 128
4.1 聚类的需求 ..... 129
4.1.1 网站中的用户组：案例研究 ............. 129
4.1.2 用SQL order by 子句分组 ................. 131
4.1.3 用数组排序分组 ................................. 132
4.2 聚类算法概述 . 135
4.2.1 基于分组结构的聚类算法分类 ......... 136
4.2.2 基于数据类型和结构的聚类算法分类 ............................................. 137
4.2.3 根据数据规模的聚类算法分类 ......... 137
4.3 基于链接的算法 ............................................. 138
4.3.1 树状图：基本的聚类数据结构 ......... 139
4.3.2 基于链接的算法概况 ......................... 141
4.3.3 单链接算法 ......................................... 142
4.3.4 平均链接算法 ..................................... 144
4.3.5 最小生成树算法 ................................. 147
4.4 k-means 算法 .. 149
4.4.1 初识k-means 算法 ............................. 150
4.4.2 k-means 的内部原理 .......................... 151
4.5 鲁棒的链接型聚类（ROCK） ...................... 153
4.5.1 ROCK 简介 ......................................... 154
4.5.2 为什么ROCK 这么强大 .................... 154
4.6 DBSCAN......... 159
4.6.1 基于密度的算法简介 ......................... 159
4.6.2 DBSCAN 的原理 ................................ 162
4.7 超大规模数据聚类 ......................................... 165
4.7.1 计算复杂性 ......................................... 166
4.7.2 高维度 . 167
4.8 总结 ................. 168
4.9 To Do ............... 169
4.10 参考资料 ....... 171
5 分类：把事物放到它该在的地方 ............ 172
5.1 对分类的需求 . 173
5.2 分类器的概述 . 177
5.2.1 结构分类算法 ..................................... 178
5.2.2 统计分类算法 ..................................... 180
5.2.3 分类器的生命周期 ............................. 181
5.3 邮件的自动归类与垃圾邮件过滤 ................. 182
5.3.1 朴素贝叶斯分类 ................................. 184
5.3.2 基于规则的分类 ................................. 197
5.4 用神经网络做欺诈检测 ................................. 210
5.4.1 交易数据中关于欺诈检测的一个用例 ............................................. 210
5.4.2 神经网络概览 ..................................... 212
5.4.3 一个可用的神经网络欺诈检测器 ..... 214
5.4.4 神经网络欺诈检测器剖析 ................. 218
5.4.5 创建通用神经网络的基类 ................. 226
5.5 你的结果可信吗 ............................................. 232
5.6 大数据集的分类 ............................................. 235
5.7 总结 ................. 237
5.8 To Do ............... 239
5.9 参考资料 ......... 242
6 分类器组合 ............................................. 244
6.1 信贷价值：分类器组合案例研究 ................. 246
6.1.1 数据的简要说明 ................................. 247
6.1.2 为真实问题生成人工数据 ................. 250
6.2 用单分类器做信用评估 ................................. 255
6.2.1 朴素贝叶斯的基准线 ......................... 255
6.2.2 决策树基准线 ..................................... 258
6.2.3 神经网络的基准线 ............................. 260
6.3 在同一个数据集中比较多个分类器 ............. 263
6.3.1 McNemar 检验 .................................... 264
6.3.2 差额比例检验 ..................................... 266
6.3.3 Cochran Q 检验与F 检验 .................. 268
6.4 bagging: bootstrap 聚合（bootstrap aggregating） ....................................... 270
6.4.1 bagging 实例 ....................................... 272
6.4.2 bagging 分类器底层细节 ................... 274
6.4.3 分类器集成 ......................................... 276
6.5 boosting：一种迭代提高的方法 ................... 279
6.5.1 boosting 分类器实例 .......................... 280
6.5.2 boosting 分类器底层细节 .................. 282
6.6 总结 ................. 286
6.7 To Do ............... 288
6.8 参考资料 ......... 292
7 智能技术大汇集：一个智能新闻门户 ..... 293
7.1 功能概览 ......... 295
7.2 获取并清洗内容 ............................................. 296
7.2.1 各就各位——预备——开抓！ .......... 296
7.2.2 搜索预备知识回顾 ............................. 298
7.2.3 一个抓取并处理好的新闻数据集 ..... 299
7.3 搜索新闻 ......... 301
7.4 分配新闻类别 . 304
7.4.1 顺序问题 ............................................. 304
7.4.2 使用NewsProcessor 类进行分类 ...... 309
7.4.3 分类器 . 310
7.4.4 分类策略：超越底层的分类 ............. 313
7.5 用NewsProcessor 类创建新闻分组 .............. 316
7.5.1 聚类全部文章 ..................................... 317
7.5.2 在一个新闻类别中聚类文章 ............. 321
7.6 基于用户评分的动态内容展示 ..................... 325
7.7 总结 ................. 328
7.8 To Do ............... 329
7.9 参考资料 ......... 333
附录A BeanShell 简介 .............................. 334
A.1 什么是BeanShell .................................. 334
A.2 为什么使用BeanShell .......................... 335
A.3 运行BeanShell ...................................... 335
A.4 参考资料 ............................................... 336
附录B 网络采集 ........................................ 337
B.1 爬虫组件概况 ....................................... 337
B.1.1 采集的步骤 .............................. 338
B.1.2 我们的简单爬虫 ...................... 338
B.1.3 开源Web 爬虫 ......................... 339
B.2 参考资料 ............................................... 340
附录C 数学知识回顾 ................................. 341
C.1 向量和矩阵 ........................................... 341
C.2 距离的度量 ........................................... 342
C.3 高级矩阵方法 ....................................... 344
C.4 参考资料 ............................................... 344
附录D 自然语言处理 ................................. 345
D.1 参考资料 ............................................... 347
附录E 神经网络 ........................................ 348
E.1 参考资料 ............................................... 349
索引 ............. 350
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>智能Web算法
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据策略：如何成功使用大数据与10个行业案例分享
目    录
第1章  何为真正的大数据	1
1.1  技术层面的定义	1
1.2  为什么数据规模无关紧要	4
1.3  大数据对管理层意味着什么	4
1.3.1  “大数据是万能的”	4
1.3.2  “数据只是另一种电子表格”	5
1.4  大数据的执行方式	5
1.5  小结	10
第2章  如何制定成功的大数据策略	11
2.1  转不出的死命循环	11
2.2  如何解开“谁是第一次”这个难题	13
2.2.1  改变大数据视角	13
2.2.2  用户认知与数据采集	13
2.2.3  Facebook预测性分析的现实	14
2.2.4  Facebook数据收集走得更远	15
2.2.5  使用Facebook坦诚认知大数据发展潜力	16
2.2.6  专业认知与大数据现实	16
2.2.7  从感知到认知偏差	17
2.2.8  寻找大数据占卜师	17
2.3  下一步：拥抱无知	19
2.4  始于何处	19
2.4.1  在结束时开始	20
2.4.2  当行动变为无为时	21
2.5  确认目标，瞄准目标	22
2.6  如何获得最佳实践方法，让落后观念远离前进的道路	24
2.6.1  解决人们对大数据的恐慌	24
2.6.2  终结未知的恐惧	24
2.6.3  接受改变，融入改变	25
2.6.4  机器统治并不确定，人类仍然起作用	26
2.6.5  接触少数固执的人	26
2.7  回答没人提出的问题	26
2.7.1  持续询问可能性	27
2.7.2  寻找最终目标	27
2.8  与解说团队交叉合作	28
2.8.1  为团队增加业务分析师和关键终端用户	28
2.8.2  为收集和管理数据增加首席数据官	29
2.9  小处着手、逐步发展并扩张	30
2.10  原型和迭代策略	31
2.11  谈谈向数据策略中添加预测分析	31
2.12  民主化数据，但预计几乎无人使用(目前)	31
2.13  策略就是一个活的文档；充实它、滋养它	32
2.14  小结	32
第3章  提出“正确”的问题	33
3.1  协作努力，提出问题	34
3.2  魔法8号球效应	35
3.3  用数学软件来分析现实问题	36
3.4  “正确”问题的清单	36
3.5  小结	36
第4章  选择“正确”数据源的方法	37
4.1  需要更多的数据源(数据类型)而非数据本身(数据容量)	37
4.2  为什么无论数据规模多大，生成的数据量都会不足且永远不足	38
4.3  数据囤积与先捉再放	38
4.4  不可思议的大数据案例：购买尿布的狗主人	39
4.5  升级事务性数据的价值	39
4.6  社交媒体数据分析的局限性	40
4.7  大数据买卖的货币价值	40
4.8  利用黑客技术赚钱碰到麻烦	41
4.9  评估数据源	42
4.10  过时的模型招致竞争对手	42
4.11  购买数据时的考量	43
4.12  确定所需的外围数据	43
4.13  谈谈结构化与非结构化数据	44
4.14  防止人为偏见对数据选择的影响	46
4.15  数据孤岛的危险	46
4.16  使用所需数据源的必要步骤	47
4.17  小结	48
第5章  解答大数据问题如同玩魔方	49
5.1  可行性数据的概念	49
5.2  描述性、预测性和规范性数据分析类型的差异	51
5.2.1  描述性数据分析	52
5.2.2  预测性数据分析	53
5.2.3  规范性数据分析	53
5.3  已有明确答案的问题	54
5.4  解释会导致更多的问题	55
5.5  需要解读的问题——魔方	55
5.6  小结	57
第6章  实时分析在动态化策略中的作用	59
6.1  检查实时错觉和时间胶囊	60
6.2  静态策略与动态策略	61
6.3  谈谈转向动态策略的变革管理	62
6.4  选择分析方式	62
6.5  利用专家经验，加速数据分析	65
6.6  实时分析来得太迟时该怎么办	66
6.7  小结	66
第7章  大数据的价值主张和货币化	67
7.1  确定未知领域的投资回报率(ROI)	67
7.2  滥发的货币和模糊的投资回报率	69
7.3  成本核算的困惑	70
7.4  成本不是问题	71
7.5  先考虑大数据项目再谈商业案例	71
7.6  计算实际成本	72
7.7  价值所在	73
7.7.1  从技术角度看待商业案例	73
7.7.2  从非技术角度看待商业案例	74
7.8  项目回报率的计算公式	74
7.9  重要问题：是否应该出售数据	76
7.9.1  销售数据解析	77
7.9.2  物以稀为贵	77
7.10  小结	78
第8章  协同经济的兴起和盈利方式	79
8.1  数据等于知识和财富	79
8.2  大数据带来的最大冲击：颠覆原有模式	80
8.2.1  分享经济	82
8.2.2  创客运动	83
8.2.3  合作创新	84
8.3  新模式在新协同经济中兴起	85
8.4  强调流畅性，摒弃灵活度	87
8.5  应用大数据制定战略新模式	89
8.6  小结	90
第9章  隐私难题	91
9.1  真相揭开的那天预示着个人隐私神话的失败	92
9.1.1  危险汇总	94
9.1.2  可在世界各地接听的手机通话	94
9.1.3  公民和退伍军人的数据如何帮助其他国家策划袭击	96
9.1.4  数据扩散逐步升级	97
9.1.5  为个人隐私画一条底线	98
9.1.6  企业的隐私难题	101
9.2  数据收集中的4大转变	102
9.2.1  数据入侵性改变	103
9.2.2  数据多样性的改变	104
9.2.3  数据整合性的改变	105
9.2.4  数据作用范围的改变	105
9.3  必须质疑的商业问题	110
9.4  谁是真正的数据拥有者	110
9.5  当前法律和措施在设定先例中的作用	111
9.6  授权允许的误区	113
9.7  个人价值与混合数据	113
9.8  匿名数据的误区	114
9.9  个人隐私与个人利益之间的平衡	115
9.10  数据收集何时会使你或你的公司承担责任	115
9.11  商业价值的透明度	117
9.12  数据从业人员必须铭记的事实	118
9.13  小结	118
第10章  国防情报部门中的用例	119
10.1  态势感知和可视化	120
10.2  信息相关性问题处理(“了解情况”问题)	121
10.3  海量数据中信息搜索和发现(“海底捞针”问题)	124
10.4  企业网络安全数据管理	127
10.5  后勤信息(包括粗放型/动态性企业资产目录)	127
10.6  加强卫生保健	127
10.7  开源信息	129
10.8  内存数据的现代化	130
10.9  企业数据中心	130
10.10  武器装备与战争中的大数据用例	130
10.11  小结	131
第11章  政府大数据管理用例	133
11.1  大数据趋势对政府数据的影响	134
11.2  联合国“全球脉动”计划用例	135
11.3  联邦政府(非国防部或情报界)用例	137
11.4  州政府用例	139
11.5  当地政府用例	142
11.6  法律实施用例	144
11.7  小结	145
第12章  安全行业用例	147
12.1  一切都在互联网上	147
12.2  亦敌亦友的数据	148
12.3  防病毒/反恶意软件用例	149
12.4  目标如何击中要害	151
12.5  虚拟和现实世界的碰撞	156
12.6  纷乱的机器数据	157
12.6.1  农民面临的信息安全困境	157
12.6.2  物联网中农民面临的安全困境周而复始	158
12.7  当前和未来信息安全分析法	159
12.8  小结	162
第13章  医疗保健领域用例	163
13.1  解决抗生素危机	163
13.2  使用大数据治病	165
13.3  从谷歌到疾病预防控制中心	165
13.3.1  美国疾病预防控制中心(CDC)的糖尿病交互图谱	168
13.3.2  项目数据领域	171
13.3.3  赛智生物网络	172
13.4  另一方：生物黑客	173
13.5  电子健康记录(EHR)、电子病历(EMR)和大数据	175
13.6  公布医疗保健数据	176
13.7  小结	179
第14章  小企业和农场用例	181
14.1  大数据适用于小企业	181
14.2  炒作和真实世界局限性之间的界限	182
14.3  为工作选择合适的工具	182
14.4  可能会使用的外部数据源示例	187
14.5  给使用共用或共享数据农民的一句忠告	192
14.5.1  说法一：数据属于农民	193
14.5.2  说法二：数据只用于“帮助”农民从农场中更加受益	194
14.5.3  说法三：农民的数据将会保密	194
14.6  钱、钱、钱：大数据扩大借贷能力的方式	195
14.6.1  PayPal信贷	196
14.6.2  亚马逊资本服务	196
14.6.3  数据驱动型贷款公司Kabbage	197
14.7  小结	197
第15章  交通运输中的用例	199
15.1  加速发展大数据赚取利润	199
15.1.1  美中不足的事	200
15.1.2  依靠数据获胜不会长久	201
15.1.3  火车、飞机和船舶中的数据使用	201
15.2  车联网：很可能不是你以为的那样	203
15.2.1  数据引导创新和自动化	206
15.2.2  智能城市的崛起	206
15.2.3  正在发生的交通创新实例	207
15.3  数据和无人驾驶汽车	208
15.4  互联的基础设施	210
15.5  汽车保险品牌数据收集设备	212
15.6  交通领域无法预料的数据可靠性	214
15.7  小结	215
第16章  能源领域中的用例	217
16.1  关于能源神话和假设的大数据	217
16.2  美国能源信息署(EIA)能源数据存储库	219
16.3  EIA能源数据表格浏览器	220
16.4  失踪的智能电表数据	222
16.5  EIA的API和数据集	222
16.6  国际意义与合作	223
16.7  公私合作下的能源数据变革	224
16.8  公用事业用例	225
16.9  小结	227
第17章  零售业大数据用例	229
17.1  在大数据中重新运用老战术	229
17.1.1  零售业没搞砸，对象客户发生了变化	231
17.1.2  品牌叛变和恶魔客户	231
17.1.3  客户体验又成为一个问题	232
17.1.4  大数据与恶魔客户复兴	232
17.2  零售业与大数据博弈的原因	234
17.3  大数据帮助零售业的方式	234
17.3.1  产品选择和定价	235
17.3.2  当前市场分析	236
17.3.3  利用大数据开发新的定价模式	236
17.3.4  寻找更好的方法获取更多、更好和更清洁的客户数据	237
17.3.5  研究和预测客户接受度和反应	237
17.3.6  预测并规划应对更广泛的市场发展趋势	241
17.4  预测零售业未来	243
17.5  小结	244
第18章  银行和金融服务业用例	245
18.1  定义问题	245
18.2  银行和贷款机构的用例	246
18.3  大数据如何在借贷领域点燃新竞争	248
18.4  新型可选择贷款方式	248
18.4.1  贝宝(PayPal)贷款项目	248
18.4.2  人人贷和贷款俱乐部	249
18.5  零售商与银行的较量；信用卡品牌规避银行	250
18.6  征信局所面临的大数据问题	250
18.7  谈谈保险公司	252
18.8  小结	254
第19章  制造业用例	255
19.1  经济形式与机会展望	256
19.2  制造业的十字路口	258
19.3  3D打印与大数据的相交点	260
19.4  3D打印是如何影响制造业并扰乱客户的	261
19.4.1  盈创公司一天打印10所住宅	261
19.4.2  3D打印的景观别墅	262
19.4.3  3D打印的傍水小宅	263
19.4.4  3D家庭打印对制造业的影响	263
19.5  增材制造的转变将是巨大的，并会波及所有部门	263
19.6  个性化制造将如何改变一切，甚至创造更多的大数据	265
19.7  制造业内部新数据源涌出	266
19.8  此行业的用例	267
19.9  小结	267
第20章  下放权力	269
20.1  数据民主化	269
20.2  4步措施	270
20.3  其他4步	272
20.4  小结	273
第21章  摘要	275
21.1  何为真正的大数据	275
21.2  如何制定成功的大数据策略	276
21.3  提出“正确”的问题	276
21.4  选择“正确”数据源的方法	277
21.5  解答大数据问题如同玩魔方	277
21.6  实时分析在动态化策略中的作用	278
21.7  大数据的价值主张和货币化	279
21.8  协同经济的兴起和盈利方式	279
21.9  隐私难题	280
21.10  政府大数据管理用例	280
21.11  国防情报部门中的用例	281
21.12  安全行业用例	282
21.13  医疗保健领域用例	282
21.14  小企业和农场用例	283
21.15  能源领域中的用例	284
21.16  交通运输中的用例	285
21.17  零售业大数据用例	286
21.18  银行和金融服务业用例	287
21.19  制造业用例	288
21.20  下放权力	289
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据策略：如何成功使用大数据与10个行业案例分享
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Mahout算法解析与案例实战
第一部分　基础篇
第1章　Mahout简介   2
1.1　Mahout应用背景   2
1.2　Mahout算法库   3
1.2.1　聚类算法   4
1.2.2　分类算法   5
1.2.3　协同过滤算法   6
1.2.4　频繁项集挖掘算法   7
1.3　Mahout应用   7
1.4　本章小结   8
第2章　Mahout安装配置   9
2.1　Mahout安装前的准备   9
2.1.1　安装JDK   10
2.1.2　安装Hadoop   12
2.2　两种安装方式   20
2.2.1　使用Maven安装   20
2.2.2　下载发布版安装   22
2.3　测试安装   22
2.4　本章小结   24
第二部分　算法篇
第3章　聚类算法   26
3.1　Canopy算法   26
3.1.1　Canopy算法简介   26
3.1.2　Mahout中Canopy算法实现原理   28
3.1.3　Mahout的Canopy算法实战   29
3.1.4　Canopy算法小结   37
3.2　K-Means算法   37
3.2.1　K-Means算法简介   37
3.2.2　Mahout中K-Means算法实现原理   38
3.2.3　Mahout的K-Means算法实战   39
3.2.4　K-Means算法小结   46
3.3　Mean Shift算法   46
3.3.1　Mean Shift算法简介   46
3.3.2　Mahout中Mean Shift算法实现原理   46
3.3.3　Mahout的Mean Shift算法实战   48
3.3.4　Mean Shift算法小结   51
3.4　本章小结   51
第4章　分类算法   52
4.1　 Bayesian算法   53
4.1.1　Bayesian算法简介   53
4.1.2　Mahout 中Bayesian算法实现原理   55
4.1.3　Mahout的Bayesian算法实战   59
4.1.4　拓展   70
4.1.5　Bayesian算法小结   70
4.2　Random Forests算法   70
4.2.1　Random Forests算法简介   70
4.2.2　Mahout中Random Forests算法实现原理   72
4.2.3　Mahout的Random Forests算法实战   77
4.2.4　拓展   81
4.2.5　Random Forests算法小结   82
4.3　本章小结   83
第5章　协同过滤算法   84
5.1　Distributed Item-Based Collaborative Filtering算法   85
5.1.1　Distributed Item-Based Collaborative Filtering算法简介   85
5.1.2　Mahout中Distributed ItemBased Collaborative Filtering算法实现原理   86
5.1.3　Mahout的Distributed Item Based Collaborative Filtering算法实战   90
5.1.4　拓展   93
5.1.5　Distributed ItemBased Collabo-rative Filtering算法小结   94
5.2　Collaborative Filtering with ALSWR算法   94
5.2.1　Collaborative Filtering with ALSWR算法简介   94
5.2.2　Mahout中Collaborative Filtering with ALS-WR算法实现原理   98
5.2.3　Mahout的Collaborative Filtering with ALS-WR算法实战   99
5.2.4　拓展   107
5.2.5　Collaborative Filtering with ALSWR算法小结   107
5.3　本章小结   107
第6章　模式挖掘算法   108
6.1　FP树关联规则算法   109
6.1.1　FP树关联规则算法简介   109
6.1.2　Mahout中Parallel Frequent Pattern Mining算法实现原理   113
6.1.3　Mahout的Parallel Frequent Pattern Mining算法实战   120
6.1.4　拓展   125
6.2　本章小结   126
第7章　Mahout中的其他算法   127
7.1　Dimension Reduction算法   128
7.1.1　Dimension Reduction算法简介   128
7.1.2　Mahout中Dimension Reduction算法实现原理   129
7.1.3　Mahout的Dimension Reduction算法实战   133
7.1.4　拓展   139
7.2　本章小结   142
第三部分　实战篇
第8章　Friend Find系统   144
8.1　系统功能   145
8.1.1　系统管理员   145
8.1.2　普通用户   146
8.1.3　总体功能   146
8.2　数据库设计   147
8.2.1　原始用户数据表   148
8.2.2　注册用户数据表   149
8.2.3　系统管理员表   149
8.2.4　聚类中心表   149
8.3　系统技术框架   150
8.4　系统流程   152
8.4.1　登录   152
8.4.2　注册   153
8.4.3　上传数据   154
8.4.4　调用K-Means算法   155
8.4.5　查看用户分组   157
8.4.6　查看分组情况   158
8.4.7　查看分组成员   159
8.5　系统实现   159
8.5.1　登录   159
8.5.2　注册   161
8.5.3　上传数据   162
8.5.4　调用K-Means算法   163
8.5.5　查看用户分组   167
8.5.6　查看分组情况   167
8.5.7　查看分组成员   168
8.6　本章小结   170
第9章　Wine Identification系统   171
9.1　系统功能   172
9.1.1　用户管理模块   173
9.1.2　随机森林模型建立模块   173
9.1.3　随机森林模型预测模块   173
9.2　系统框架   173
9.3　数据库设计   180
9.3.1　用户表   180
9.3.2　系统常量表   181
9.4　系统流程   181
9.4.1　登录   182
9.4.2　注销   182
9.4.3　权限修改   182
9.4.4　密码修改   183
9.4.5　用户列表   183
9.4.6　数据上传   184
9.4.7　随机森林模型建立   185
9.4.8　随机森林模型评估   186
9.4.9　随机森林模型预测   187
9.5　系统实现   188
9.5.1　登录   188
9.5.2　注销   188
9.5.3　权限修改   189
9.5.4　密码修改   190
9.5.5　用户列表   191
9.5.6　数据上传   193
9.5.7　随机森林模型建立   194
9.5.8　随机森林模型评估   194
9.5.9　随机森林模型预测   195
9.6　本章小结   196
第10章　Dating Recommender系统   197
10.1　系统功能   198
10.1.1　系统管理员功能   198
10.1.2　普通用户功能   199
10.1.3　功能总述   199
10.2　系统框架   200
10.3　数据库设计   203
10.3.1　系统管理员表   203
10.3.2　原始用户推荐信息表   204
10.3.3　基础数据top10表   204
10.4　系统流程   204
10.4.1　登录   205
10.4.2　上传数据   205
10.4.3　推荐分析   206
10.4.4　单用户推荐   210
10.4.5　新用户推荐   211
10.5　算法设计   214
10.5.1　协同过滤算法接口设计   214
10.5.2　top10算法设计   215
10.5.3　新用户推荐算法设计   221
10.6　系统实现   228
10.6.1　登录   228
10.6.2　上传数据   229
10.6.3　推荐分析   230
10.6.4　单用户推荐   232
10.6.5　新用户推荐   234
10.7　本章小结   235
第11章　博客推荐系统   237
11.1　系统功能   238
11.1.1　用户管理   238
11.1.2　建立知识库   239
11.1.3　博客管理   239
11.2　系统框架   240
11.3　数据库设计   246
11.3.1　用户信息表   246
11.3.2　知识库信息表   247
11.3.3　系统常量表   248
11.4　系统流程   248
11.4.1　登录   248
11.4.2　注册   248
11.4.3　密码修改   249
11.4.4　订阅博客查看   249
11.4.5　博客订阅与退订   249
11.4.6　博客推荐   250
11.4.7　上传数据   252
11.4.8　调用FP树关联规则算法   253
11.5　算法设计   260
11.6　系统实现   262
11.6.1　登录   262
11.6.2　注册   263
11.6.3　密码修改   264
11.6.4　订阅博客查看   265
11.6.5　运行FP云算法   266
11.6.6　博客订阅与退订   267
11.6.7　博客推荐   268
11.7　本章小结   270
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Mahout算法解析与案例实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>南京大学人工智能本科专业教育培养体系
前 言
第 1 章 创办一流大学人工智能教育的思考
第 2 章 南京大学人工智能学院本科培养方案
2.1 专业方向简介
2.2 培养目标和专业特色
2.3 培养毕业要求
2.4 培养规格路径
2.5 课程体系设置
第 3 章 数学基础课程教学大纲
3.1 “数学分析（一）”教学大纲
3.2 “数学分析（二）”教学大纲
3.3 “高等代数（一）”教学大纲
3.4 “高等代数（二）”教学大纲
3.5 “离散数学”教学大纲
3.6 “概率论与数理统计”教学大纲
3.7 “优化方法”教学大纲
3.8 “数理逻辑”教学大纲
第 4 章 学科基础课程教学大纲
4.1 “人工智能导引”教学大纲
4.2 “人工智能导论”教学大纲
4.3 “数据结构与算法分析”教学大纲
4.4 “程序设计基础”教学大纲
4.5 “人工智能程序设计”教学大纲
4.6 “机器学习导论”教学大纲
4.7 “知识表示与处理”教学大纲
4.8 “模式识别与计算机视觉”教学大纲
4.9 “自然语言处理”教学大纲
4.10 “数字系统设计基础”教学大纲
4.11 “计算机系统基础”教学大纲
4.12 “操作系统”教学大纲
第 5 章 专业方向课程教学大纲
5.1 “泛函分析”教学大纲
5.2 “数字信号处理”教学大纲
5.3 “高级机器学习”教学大纲
5.4 “计算方法”教学大纲
5.5 “控制理论与方法”教学大纲
5.6 “机器人学导论”教学大纲
5.7 “多智能体系统”教学大纲
5.8 “分布式与并行计算”教学大纲 / 75
第 6 章 专业选修课程教学大纲
6.1 数学拓展类课程教学大纲
6.1.1 “数学建模”教学大纲
6.1.2 “矩阵计算”教学大纲
6.1.3 “随机过程”教学大纲
6.1.4 “组合数学”教学大纲
6.1.5 “博弈论及其应用”教学大纲
6.1.6 “时间序列分析”教学大纲
6.2 学科拓展类课程教学大纲
6.2.1 “编译原理”教学大纲
6.2.2 “随机算法”教学大纲
6.2.3 “数据库概论”教学大纲
6.2.4 “形式语言与自动机”教学大纲
6.2.5 “计算机体系结构”教学大纲
6.2.6 “软件体系结构”教学大纲
6.3 专业拓展类课程教学大纲
6.3.1 “自动规划”教学大纲
6.3.2 “归纳逻辑程序设计”教学大纲
6.3.3 “学习理论导论”教学大纲
6.3.4 “概率图模型”教学大纲
6.3.5 “强化学习”教学大纲
6.3.6 “神经网络”教学大纲
6.3.7 “启发式搜索与演化算法”教学大纲
6.3.8 “信息检索”教学大纲
6.3.9 “语音信号处理”教学大纲
6.3.10 “深度学习与应用”教学大纲
6.3.11 “复杂结构数据挖掘”教学大纲
6.4 交叉复合类课程教学大纲
6.4.1 “认知科学导论”教学大纲
6.4.2 “神经科学导论”教学大纲
6.4.3 “计算语言学”教学大纲
6.4.4 “计算金融”教学大纲
6.4.5 “计算生物学导论”教学大纲
6.4.6 “传感器设计与应用”教学大纲
6.4.7 “智能硬件与新器件”教学大纲
6.4.8 “人工智能伦理”教学大纲
6.5 应用实践类课程教学大纲
6.5.1 “智能系统设计与应用”教学大纲
6.5.2 “智能应用建模”教学大纲
6.5.3 “机器学习系统与平台”教学大纲
6.5.4 “机器人系统开发”教学大纲
6.5.5 “人工智能企业实训”教学大纲
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>南京大学人工智能本科专业教育培养体系
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习轻松学
1 机器学习与深度学习的概念1
1.1 什么是机器学习 1
1.1.1 机器学习的形式. 2
1.1.2 机器学习的几个组成部分. 8
1.2 深度学习的逆袭 9
1.3 深层模型在视觉领域的应用. 13
1.4 本书的主要内容 15
1.5 总结. 17
2 数学与机器学习基础18
2.1 线性代数基础. 18
2.2 对称矩阵的性质 22
2.2.1 特征值与特征向量 22
2.2.2 对称矩阵的特征值和特征向量 23
2.2.3 对称矩阵的对角化 24
2.3 概率论. 25
2.3.1 概率与分布. 25
2.3.2 最大似然估计 28
2.4 信息论基础 31
2.5 KL 散度. 33
2.6 凸函数及其性质 37
2.7 机器学习基本概念. 39
2.8 机器学习的目标函数 42
2.9 总结. 44
3 CNN 的基石：全连接层45
3.1 线性部分. 45
3.2 非线性部分 48
3.3 神经网络的模样 50
3.4 反向传播法 55
3.4.1 反向传播法的计算方法. 55
3.4.2 反向传播法在计算上的抽象. 58
3.4.3 反向传播法在批量数据上的推广. 59
3.4.4 具体的例子. 63
3.5 参数初始化 65
3.6 总结. 68
4 CNN 的基石：卷积层69
4.1 卷积操作. 69
4.1.1 卷积是什么. 69
4.1.2 卷积层效果展示. 73
4.1.3 卷积层汇总了什么 76
4.1.4 卷积的另一种解释 77
4.2 卷积层的反向传播. 79
4.2.1 实力派解法. 80
4.2.2 “偶像派”解法. 84
4.3 ReLU 88
4.3.1 梯度消失问题 89
4.3.2 ReLU 的理论支撑. 92
4.3.3 ReLU 的线性性质. 93
4.3.4 ReLU 的不足. 93
4.4 总结. 94
4.5 参考文献. 94
5 Caffe 入门95
5.1 使用Caffe 进行深度学习训练. 96
5.1.1 数据预处理. 96
5.1.2 网络结构与模型训练的配置. 100
5.1.3 训练与再训练 108
5.1.4 训练日志分析 110
5.1.5 预测检验与分析. 112
5.1.6 性能测试 115
5.2 模型配置文件介绍. 117
5.3 Caffe 的整体结构. 122
5.3.1 SyncedMemory 124
5.3.2 Blob 125
5.3.3 Layer 125
5.3.4 Net 126
5.3.5 Solver 126
5.3.6 多GPU 训练. 127
5.3.7 IO 127
5.4 Caffe 的Layer 128
5.4.1 Layer 的创建——LayerRegistry 128
5.4.2 Layer 的初始化. 130
5.4.3 Layer 的前向计算. 132
5.5 Caffe 的Net 组装流程 133
5.6 Caffe 的Solver 计算流程. 139
5.6.1 优化流程 140
5.6.2 多卡优化算法 142
5.7 Caffe 的Data Layer 145
5.7.1 Datum 结构. 145
5.7.2 DataReader Thread 147
5.7.3 BasePrefetchingDataLayer Thread 148
5.7.4 Data Layer 149
5.8 Caffe 的Data Transformer 150
5.8.1 C++ 中的Data Transformer 150
5.8.2 Python 中的Data Transformer 153
5.9 模型层扩展实践——Center Loss Layer 156
5.9.1 Center Loss 的原理 156
5.9.2 Center Loss 实现. 160
5.9.3 实验分析与总结. 164
5.10 总结. 165
5.11 参考文献. 165
6 深层网络的数值问题166
6.1 ReLU 和参数初始化. 166
6.1.1 第一个ReLU 数值实验. 167
6.1.2 第二个ReLU 数值实验. 169
6.1.3 第三个实验——Sigmoid 171
6.2 Xavier 初始化. 172
6.3 MSRA 初始化. 178
6.3.1 前向推导 178
6.3.2 后向推导 181
6.4 ZCA 182
6.5 与数值溢出的战斗. 186
6.5.1 Softmax Layer 186
6.5.2 Sigmoid Cross Entropy Loss 189
6.6 总结. 192
6.7 参考文献. 192
7 网络结构193
7.1 关于网络结构，我们更关心什么 193
7.2 网络结构的演化 195
7.2.1 VGG：模型哲学. 195
7.2.2 GoogLeNet：丰富模型层的内部结构. 196
7.2.3 ResNet：从乘法模型到加法模型. 197
7.2.4 全连接层的没落. 198
7.3 Batch Normalization 199
7.3.1 Normalization 199
7.3.2 使用BN 层的实验. 200
7.3.3 BN 的实现. 201
7.4 对Dropout 的思考. 204
7.5 从迁移学习的角度观察网络功能 206
7.6 ResNet 的深入分析. 210
7.6.1 DSN 解决梯度消失问题 211
7.6.2 ResNet 网络的展开结构. 212
7.6.3 FractalNet 214
7.6.4 DenseNet 215
7.7 总结. 217
7.8 参考文献. 217
8 优化与训练219
8.1 梯度下降是一门手艺活儿. 219
8.1.1 什么是梯度下降法 219
8.1.2 优雅的步长. 220
8.2 路遥知马力：动量. 225
8.3 SGD 的变种算法 232
8.3.1 非凸函数 232
8.3.2 经典算法的弯道表现. 233
8.3.3 Adagrad 234
8.3.4 Rmsprop 235
8.3.5 AdaDelta 236
8.3.6 Adam 237
8.3.7 爬坡赛. 240
8.3.8 总结. 242
8.4 L1 正则的效果. 243
8.4.1 MNIST 的L1 正则实验. 244
8.4.2 次梯度下降法 246
8.5 寻找模型的弱点 251
8.5.1 泛化性实验. 252
8.5.2 精确性实验. 255
8.6 模型优化路径的可视化. 255
8.7 模型的过拟合. 260
8.7.1 过拟合方案. 261
8.7.2 SGD 与过拟合 263
8.7.3 对于深层模型泛化的猜想. 264
8.8 总结. 265
8.9 参考文献. 265
9 应用：图像的语意分割267
9.1 FCN 268
9.2 CRF 通俗非严谨的入门. 272
9.2.1 有向图与无向图模型. 272
9.2.2 Log-Linear Model 278
9.2.3 条件随机场. 280
9.3 Dense CRF 281
9.3.1 Dense CRF 是如何被演化出来的. 281
9.3.2 Dense CRF 的公式形式. 284
9.4 Mean Field 对Dense CRF 模型的化简 285
9.5 Dense CRF 的推断计算公式 288
9.5.1 Variational Inference 推导 289
9.5.2 进一步化简. 291
9.6 完整的模型：CRF as RNN 292
9.7 总结. 294
9.8 参考文献. 294
10 应用：图像生成295
10.1 VAE 295
10.1.1 生成式模型. 295
10.1.2 Variational Lower bound 296
10.1.3 Reparameterization Trick 298
10.1.4 Encoder 和Decoder 的计算公式. 299
10.1.5 实现. 300
10.1.6 MNIST 生成模型可视化 301
10.2 GAN 303
10.2.1 GAN 的概念. 303
10.2.2 GAN 的训练分析. 305
10.2.3 GAN 实战. 309
10.3 Info-GAN 314
10.3.1 互信息. 315
10.3.2 InfoGAN 模型 317
10.4 Wasserstein GAN 320
10.4.1 分布的重叠度 321
10.4.2 两种目标函数存在的问题. 323
10.4.3 Wasserstein 距离. 325
10.4.4 Wasserstein 距离的优势. 329
10.4.5 Wasserstein GAN 的实现 331
10.5 总结. 333
10.6 参考文献. 334
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习轻松学
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计模式识别
第1章 统计模式识别绪论
1.1 统计模式识别
1.1.1 引言
1.1.2 基本模型
1.2 解决模式识别问题的步骤
1.3 问题讨论
1.4 统计模式识别的方法
1.5 基本决策理论
1.5.1 最小错误贝叶斯决策规则
1.5.2 最小错误贝叶斯决策规则——拒绝分类
1.5.3 最小风险贝叶斯决策规则
1.5.4 最小风险贝叶斯决策规则——拒绝分类
1.5.5 NeymanPearson决策规则
1.5.6 最小最大决策
1.5.7 讨论
1.6 判别函数
1.6.1 引言
1.6.2 线性判别函数
1.6.3 分段线性判别函数
1.6.4 广义线性判别函数
1.6.5 小结
1.7 多重回归
1.8 本书梗概
1.9 提示及参考文献
习题
第2章 密度估计的参数法
2.1 引言
2.2 分布参数估计
2.2.1 估计法
2.2.2 预测法
2.3 高斯分类器
2.3.1 详述
2.3.2 高斯分类器插入估计的推导
2.3.3 应用研究举例
2.4 处理高斯分类器的奇异问题
2.4.1 引言
2.4.2 朴素贝叶斯
2.4.3 投影到子空间
2.4.4 线性判别函数
2.4.5 正则化判别分析
2.4.6 应用研究举例
2.4.7 拓展研究
2.4.8 小结
2.5 有限混合模型
2.5.1 引言
2.5.2 混合判别模型
2.5.3 正态混合模型的参数估计
2.5.4 正态混合模型协方差矩阵约束
2.5.5 混合模型分量的数量
2.5.6 期望最大化算法下的极大似然估计
2.5.7 应用研究举例
2.5.8 拓展研究
2.5.9 小结
2.6 应用研究
2.7 总结和讨论
2.8 建议
2.9 提示及参考文献
习题
第3章 密度估计的贝叶斯法
3.1 引言
3.1.1 基本原理
3.1.2 递归计算
3.1.3 比例性
3.2 解析解
3.2.1 共轭先验概率
3.2.2 方差已知的正态分布的均值估计
3.2.3 多元正态分布的均值及协方差矩阵估计
3.2.4 未知类先验概率的情形
3.2.5 小结
3.3 贝叶斯采样方案
3.3.1 引言
3.3.2 梗概
3.3.3 贝叶斯分类器的采样类型
3.3.4 拒绝采样
3.3.5 均匀比
3.3.6 重要性采样
3.4 马尔可夫链蒙特卡罗方法
3.4.1 引言
3.4.2 吉布斯(Gibbs)采样器
3.4.3 MetropolisHastings算法
3.4.4 数据扩充
3.4.5 可逆跳跃马尔可夫链蒙特卡罗方法
3.4.6 切片采样
3.4.7 MCMC举例——正弦噪声估计
3.4.8 小结
3.4.9 提示及参考文献
3.5 贝叶斯判别方法
3.5.1 标记训练数据
3.5.2 无类别标签的训练数据
3.6 连续蒙特卡罗采样
3.6.1 引言
3.6.2 基本方法
3.6.3 小结
3.7 变分贝叶斯方法
3.7.1 引言
3.7.2 描述
3.7.3 分解为因子的变分近似
3.7.4 简单的例子
3.7.5 模型选择中的运用
3.7.6 拓展研究与应用
3.7.7 小结
3.8 近似贝叶斯计算
3.8.1 引言
3.8.2 ABC拒绝采样
3.8.3 ABC MCMC采样
3.8.4 ABC总体蒙特卡罗采样
3.8.5 模型选择
3.8.6 小结
3.9 应用研究举例
3.10应用研究
3.11总结和讨论
3.12建议
3.13提示及参考文献
习题
第4章 密度估计的非参数法
4.1 引言
4.1.1 密度估计的基本性质
4.2 k近邻法
4.2.1 k近邻分类器
4.2.2 推导
4.2.3 距离度量的选择
4.2.4 最近邻法决策规则的性质
4.2.5 线性逼近排除搜索算法
4.2.6 分支定界搜索算法： kd树
4.2.7 分支定界搜索算法： ball树
4.2.8 剪辑方法
4.2.9 应用研究举例
4.2.10拓展研究
4.2.11小结
4.3 直方图法
4.3.1 直方图自适应数据
4.3.2 独立性假设（朴素贝叶斯）
4.3.3 Lancaster模型
4.3.4 最大权值相关树
4.3.5 贝叶斯网络
4.3.6 应用研究举例： 朴素贝叶斯文本分类
4.3.7 小结
4.4 核函数方法
4.4.1 有偏估计
4.4.2 延伸到多元
4.4.3 平滑参数的选择
4.4.4 核函数的选择
4.4.5 应用研究举例
4.4.6 拓展研究
4.4.7 小结
4.5 用基函数展开
4.6 copula方法
4.6.1 引言
4.6.2 数学基础
4.6.3 copula函数
4.6.4 copula概率密度函数的估计
4.6.5 简单举例
4.6.6 小结
4.7 应用研究
4.7.1 比较研究
4.8 总结和讨论
4.9 建议
4.10提示及参考文献
习题
第5章 线性判别分析
5.1 引言
5.2 两类问题算法
5.2.1 总体思路
5.2.2 感知准则
5.2.3 Fisher准则
5.2.4 最小均方误差法
5.2.5 拓展研究
5.2.6 小结
5.3 多类算法
5.3.1 总体思路
5.3.2 错误修正法
5.3.3 Fisher准则：线性判别分析
5.3.4 最小均方误差法
5.3.5 正则化
5.3.6 应用研究实例
5.3.7 拓展研究
5.3.8 小结
5.4 支持向量机
5.4.1 引言
5.4.2 两类线性可分数据问题
5.4.3 两类线性不可分数据问题
5.4.4 多类支持向量机
5.4.5 支持向量机回归
5.4.6 具体实施
5.4.7 应用研究举例
5.4.8 小结
5.5 logistic判别
5.5.1 两类问题
5.5.2 极大似然估计
5.5.3 多类logistic判别
5.5.4 应用研究举例
5.5.5 拓展研究
5.5.6 小结
5.6 应用研究
5.7 总结和讨论
5.8 建议
5.9 提示及参考文献
习题
第6章 非线性判别分析——核与投影法
6.1 引言
6.2 径向基函数
6.2.1 引言
6.2.2 模型的确定
6.2.3 指定函数的形式
6.2.4 中心位置
6.2.5 平滑参数
6.2.6 权值的计算
6.2.7 模型阶次的选择
6.2.8 简单径向基函数
6.2.9 一些调整
6.2.10径向基函数的性质
6.2.11应用研究举例
6.2.12拓展研究
6.2.13小结
6.3 非线性支持向量机
6.3.1 引言
6.3.2 二分类
6.3.3 核函数的类型
6.3.4 模型选择
6.3.5 多类支持向量机
6.3.6 概率估计
6.3.7 非线性回归
6.3.8 应用研究举例
6.3.9 拓展研究
6.3.10小结
6.4 多层感知器
6.4.1 引言
6.4.2 多层感知器结构的确定
6.4.3 多层感知器权值的确定
6.4.4 多层感知器的建模能力
6.4.5 logistic分类
6.4.6 应用研究举例
6.4.7 贝叶斯多层感知器网络
6.4.8 投影寻踪
6.4.9 小结
6.5 应用研究
6.6 总结和讨论
6.7 建议
6.8 提示及参考文献
习题
第7章 规则和决策树归纳法
7.1 引言
7.2 决策树
7.2.1 引言
7.2.2 决策树的构造
7.2.3 拆分规则的选择
7.2.4 终止拆分过程
7.2.5 为终端节点分配类标签
7.2.6 决策树剪枝（含实施示例）
7.2.7 决策树构造方法
7.2.8 其他问题
7.2.9 应用研究举例
7.2.10拓展研究
7.2.11小结
7.3 规则归纳
7.3.1 引言
7.3.2 从决策树生成规则
7.3.3 用连续覆盖算法进行规则归纳
7.3.4 应用研究举例
7.3.5 拓展研究
7.3.6 小结
7.4 多元自适应回归样条
7.4.1 引言
7.4.2 递归分割模型
7.4.3 应用研究举例
7.4.4 拓展研究
7.4.5 小结
7.5 应用研究
7.6 总结和讨论
7.7 建议
7.8 提示及参考文献
习题
第8章 组合方法
8.1 引言
8.2 分类器组合方案特性
8.2.1 特征空间
8.2.2 层次
8.2.3 训练程度
8.2.4 成员分类器的形式
8.2.5 结构
8.2.6 优化
8.3 数据融合
8.3.1 体系结构
8.3.2 贝叶斯方法
8.3.3 奈曼皮尔逊(NeymanPearson)公式
8.3.4 可训练规则
8.3.5 固定规则
8.4 分类器组合方法
8.4.1 乘积规则
8.4.2 和式规则
8.4.3 最小、最大及中值组合分类器
8.4.4 多数表决
8.4.5 Borda数
8.4.6 在类别预测上训练组合分类器
8.4.7 叠加归纳
8.4.8 专家混合器
8.4.9 bagging
8.4.10boosting
8.4.11随机森林
8.4.12模型平均
8.4.13方法小结
8.4.14应用研究举例
8.4.15拓展研究
8.5 应用研究
8.6 总结和讨论
8.7 建议
8.8 提示及参考文献
习题
第9章 性能评价
9.1 引言
9.2 性能评价
9.2.1 性能测度
9.2.2 判别力
9.2.3 可靠性
9.2.4 用于性能评价的ROC曲线
9.2.5 总体漂移和传感漂移
9.2.6 应用研究举例
9.2.7 拓展研究
9.2.8 小结
9.3 分类器性能的比较
9.3.1 哪种方法最好
9.3.2 统计检验
9.3.3 错分代价不定情况下的比较规则
9.3.4 应用研究举例
9.3.5 拓展研究
9.3.6 小结
9.4 应用研究
9.5 总结和讨论
9.6 建议
9.7 提示及参考文献
习题
第10章 特征选择与特征提取
10.1 引言
10.2 特征选择
10.2.1 引言
10.2.2 对特征选择方法的表述
10.2.3 评估方法
10.2.4 选择特征子集的搜索算法
10.2.5 全搜索： 分支定界法
10.2.6 顺序搜索
10.2.7 随机搜索
10.2.8 马尔可夫覆盖
10.2.9 特征选择的稳定性
10.2.10应用研究举例
10.2.11拓展研究
10.2.12小结
10.3 线性特征提取
10.3.1 主成分分析
10.3.2 KarhunenLoève变换
10.3.3 应用研究举例
10.3.4 拓展研究
10.3.5 小结
10.4 多维尺度分析
10.4.1 经典尺度分析
10.4.2 计量多维尺度
10.4.3 次序尺度分析
10.4.4 算法
10.4.5 用于特征提取的多维尺度分析
10.4.6 应用研究举例
10.4.7 拓展研究
10.4.8 小结
10.5 应用研究
10.6 总结和讨论
10.7 建议
10.8 提示及参考文献
习题
第11章 聚类
11.1 引言
11.2 分层聚类法
11.2.1 单链接方法
11.2.2 完全链接方法
11.2.3 平方和方法
11.2.4 通用合并算法
11.2.5 分层聚类法的性质
11.2.6 应用研究举例
11.2.7 小结
11.3 快速分类
11.4 混合模型
11.4.1 模型描述
11.4.2 应用研究举例
11.5 平方和方法
11.5.1 聚类准则
11.5.2 聚类算法
11.5.3 矢量量化
11.5.4 应用研究举例
11.5.5 拓展研究
11.5.6 小结
11.6 谱聚类
11.6.1 图论初步
11.6.2 相似矩阵
11.6.3 聚类应用
11.6.4 谱聚类算法
11.6.5 拉普拉斯矩阵的形式
11.6.6 应用研究举例
11.6.7 拓展研究
11.6.8 小结
11.7 聚类有效性
11.7.1 引言
11.7.2 统计检验
11.7.3 缺失类结构
11.7.4 各聚类的有效性
11.7.5 分级聚类
11.7.6 各单聚类的有效性
11.7.7 划分
11.7.8 相关准则
11.7.9 选择聚类个数
11.8 应用研究
11.9 总结和讨论
11.10建议
11.11提示及参考文献
习题
第12章 复杂网络
12.1 引言
12.1.1 特征
12.1.2 属性
12.1.3 问题阐述
12.1.4 描述性特征
12.1.5 概要
12.2 网络的数学描述
12.2.1 图矩阵
12.2.2 连通性
12.2.3 距离测度
12.2.4 加权网络
12.2.5 中心测度
12.2.6 随机图
12.3 社区发现
12.3.1 聚类方法
12.3.2 GirvanNewman算法
12.3.3 模块化方法
12.3.4 局部模块化
12.3.5 小集团过滤
12.3.6 应用研究举例
12.3.7 拓展研究
12.3.8 小结
12.4 链路预测
12.4.1 链路预测方法
12.4.2 应用研究举例
12.4.3 拓展研究
12.5 应用研究
12.6 总结和讨论
12.7 建议
12.8 提示及参考文献
习题
第13章 其他论题
13.1 模型选择
13.1.1 相互独立的训练集与测试集
13.1.2 交叉验证
13.1.3 贝叶斯观点
13.1.4 Akaike信息准则
13.1.5 最短描述长度
13.2 缺值数据
13.3 离群值检测和鲁棒方法
13.4 连续变量与离散变量的混合
13.5 结构风险最小化和VapnikChervonenkis维数
13.5.1 期望风险边界
13.5.2 VapnikChervonenkis维数
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>统计模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学
译者序
序言
前言
第一部分数据科学引论
第1章数据科学处理过程2
1.1数据科学项目中的角色2
1.2数据科学项目的阶段4
1.2.1制定目标5
1.2.2收集和管理数据5
1.2.3建立模型7
1.2.4模型评价和批判8
1.2.5展现和编制文档9
1.2.6模型部署和维护10
1.3设定预期11
1.4小结12
第2章向R加载数据14
2.1运用文件中的数据14
2.1.1在源自文件或URL的良结构数据上使用R15
2.1.2在欠结构数据上使用R17
2.2在关系数据库上使用R19
2.2.1一个生产规模的示例20
2.2.2从数据库向R系统加载数据23
2.2.3处理PUMS数据25
2.3小结28
第3章探索数据29
3.1使用概要统计方法发现问题30
3.2用图形和可视化方法发现问题34
3.2.1可视化检测单变量的分布35
3.2.2可视化检测两个变量间的关系42
3.3小结51
第4章管理数据52
4.1清洗数据52
4.1.1处理缺失值52
4.1.2数据转换56
4.2为建模和验证采样61
4.2.1测试集和训练集的划分61
4.2.2创建一个样本组列62
4.2.3记录分组63
4.2.4数据溯源63
4.3小结63
第二部分建模方法
第5章选择和评价模型66
5.1将业务问题映射到机器学习任务67
5.1.1解决分类问题67
5.1.2解决打分问题68
5.1.3目标未知情况下的处理69
5.1.4问题到方法的映射71
5.2模型评价71
5.2.1分类模型的评价72
5.2.2打分模型的评价76
5.2.3概率模型的评价78
5.2.4排名模型的评价82
5.2.5聚类模型的评价82
5.3模型验证84
5.3.1常见的模型问题的识别84
5.3.2模型可靠性的量化85
5.3.3模型质量的保证86
5.4小结88
第6章记忆化方法89
6.1KDD和KDD Cup 200989
6.2构建单变量模型91
6.2.1使用类别型特征92
6.2.2使用数值型特征94
6.2.3使用交叉验证估计过拟合的影响96
6.3构建多变量模型97
6.3.1变量选择97
6.3.2使用决策树99
6.3.3使用最近邻方法102
6.3.4使用朴素贝叶斯105
6.4小结108
第7章线性回归与逻辑斯谛回归110
7.1使用线性回归110
7.1.1理解线性回归110
7.1.2构建线性回归模型113
7.1.3预测114
7.1.4发现关系并抽取建议117
7.1.5解读模型概要并刻画系数质量118
7.1.6线性回归要点122
7.2使用逻辑斯谛回归123
7.2.1理解逻辑斯谛回归123
7.2.2构建逻辑斯谛回归模型124
7.2.3预测125
7.2.4从逻辑斯谛回归模型中发现关系并抽取建议129
7.2.5解读模型概要并刻画系数130
7.2.6逻辑斯谛回归要点136
7.3小结137
第8章无监督方法138
8.1聚类分析138
8.1.1距离139
8.1.2准备数据140
8.1.3使用hclust（）进行层次聚类142
8.1.4k—均值算法150
8.1.5分派新的点到簇154
8.1.6聚类要点156
8.2关联规则156
8.2.1关联规则概述156
8.2.2问题举例157
8.2.3使用arules程序包挖掘关联规则158
8.2.4关联规则要点165
8.3小结165
第9章高级方法探索166
9.1使用bagging和随机森林方法减少训练方差167
9.1.1使用bagging方法改进预测167
9.1.2使用随机森林方法进一步改进预测170
9.1.3bagging和随机森林方法要点173
9.2使用广义加性模型学习非单调关系173
9.2.1理解GAM174
9.2.2一维回归示例174
9.2.3提取非线性关系178
9.2.4在真实数据上使用GAM179
9.2.5使用GAM实现逻辑斯谛回归182
9.2.6GAM要点183
9.3使用核方法提高数据可分性183
9.3.1理解核函数184
9.3.2在问题中使用显式核函数187
9.3.3核方法要点190
9.4使用SVM对复杂的决策边界建模190
9.4.1理解支持向量机190
9.4.2在人工示例数据中使用SVM192
9.4.3在真实数据中使用SVM195
9.4.4支持向量机要点197
9.5小结197
第三部分结果交付
第10章文档编制和部署200
10.1buzz数据集200
10.2使用knitr产生里程碑文档202
10.2.1knitr是什么202
10.2.2knitr技术详解204
10.2.3使用knitr编写buzz数据文档205
10.3在运行时文档编制中使用注释和版本控制208
10.3.1编写有效注释208
10.3.2使用版本控制记录历史209
10.3.3使用版本控制探索项目213
10.3.4使用版本控制分享工作217
10.4模型部署220
10.4.1将模型部署为RHTTP服务220
10.4.2按照输出部署模型222
10.4.3要点223
10.5小结224
第11章有效的结果展现226
11.1将结果展现给项目出资方227
11.1.1概述项目目标228
11.1.2陈述项目结果229
11.1.3补充细节230
11.1.4提出建议并讨论未来工作231
11.1.5向项目出资方展现的要点232
11.2向最终用户展现模型232
11.2.1概述项目目标232
11.2.2展现模型如何融入用户的工作流程233
11.2.3展现如何使用模型235
11.2.4向最终用户展现的要点236
11.3向其他数据科学家展现你的工作236
11.3.1介绍问题236
11.3.2讨论相关工作237
11.3.3讨论你的方法238
11.3.4讨论结果和未来工作239
11.3.5向其他数据科学家展现的要点240
11.4小结240
附录A使用R和其他工具241
附录B重要的统计学概念263
附录C更多的工具和值得探索的思路292
参考文献297
索引299
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数据科学
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别与智能计算的MATLAB实现
第1章 绪论
1.1 模式识别的基本概念
1.1.1 模式与模式识别的概念
1.1.2 模式的特征
1.1.3 模式识别系统
1.2 模式识别的主要方法
1.3 模式识别的主要研究内容
1.4 模式识别在科学研究中的应用
1.4.1 化合物的构效分析
1.4.2 谱图解析
1.4.3 材料研究
1.4.4 催化剂研究
1.4.5 机械故障诊断与监测
1.4.6 化学物质源产地判断
1.4.7 疾病的诊断与预测
1.4.8 矿藏勘探
1.4.9 考古及食品工业中的应用
第2章 统计模式识别技术
2.1 基于概率统计的贝叶斯分类方法
2.1.1 最小错误率贝叶斯分类
2.1.2 最小风险率贝叶斯分类
2.2 线性分类器
2.2.1 线性判别函数
2.2.2 Fisher线性判别函数
2.2.3 感知器算法
2.3 非线性分类器
2.3.1 分段线性判别函数
2.3.2 近邻法
2.3.3 势函数法
2.3.4 SIMCA方法
2.4 聚类分析
2.4.1 模式相似度
2.4.2 聚类准则
2.4.3 层次聚类法
2.4.4 动态聚类法
2.4.5 决策树分类器
2.5 统计模式识别在科学研究中的应用
第3章 人工神经网络及模式识别
3.1 人工神经网络的基本概念
3.1.1 人工神经元
3.1.2 传递函数
3.1.3 人工神经网络分类和特点
3.2 BP人工神经网络
3.2.1 BP人工神经网络学习算法
3.2.2 BP人工神经网络MATLAB实现
3.3 径向基函数神经网络RBF
3.3.1 RBF的结构与学习算法
3.3.2 RBF的MATLAB实现
3.4 自组织竞争人工神经网络
3.4.1 自组织竞争人工神经网络的基本概念
3.4.2 自组织竞争神经网络的学习算法
3.4.3 自组织竞争网络的MATLAB实现
3.5 对向传播神经网络CPN
3.5.1 CPN的基本概念
3.5.2 CPN网络的学习算法
3.6 反馈型神经网络Hopfield
3.6.1 Hopfield网络的基本概念
3.6.2 Hopfield网络的学习算法
3.6.3 Hopfield网络的MATLAB实现
3.7 人工神经网络技术在科学研究中的应用
第4章 模糊系统理论及模式识别
4.1 模糊系统理论基础
4.1.1 模糊集合
4.1.2 模糊关系
4.1.3 模糊变换与模糊综合评判
4.1.4 Ifthen规则
4.1.5 模糊推理
4.2 模糊模式识别的基本方法
4.2.1 最大隶属度原则
4.2.2 择近原则
4.2.3 模糊聚类分析
……
第5章 核函数方法及应用
第6章 支持向量机及其模式识别
第7章 可拓学及其模式识别
第8章 粗糙集理论及其模式识别
第9章 遗传算法及模式识别
第10章 蚁群算法及其模式识别
第11章 粒子群算法及其模式识别
第12章 可视化模式识别技术
第13章 灰色系统方法及应用
第14章 模式识别的特征及确定
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别与智能计算的MATLAB实现
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数值最优化算法与理论
第1章 引言
1.1 最优化问题概述
1.2 凸集和凸函数
习题1
第2章 无约束问题的下降算法与线性搜索
2.1 无约束问题解的最优性条件
2.2 下降算法的一般步骤
2.3 线性搜索
2.4 下降算法的全局收敛性
2.5 下降算法的收敛速度
习题2
第3章 无约束问题算法（I）
3.1 最速下降法
3.2 Newton法及其修正形式
3.3 正则化Newton法
习题3
第4章 无约束问题算法（II）
4.1 拟Newton法及其性质
4.2 拟Newton法的收敛性理论
4.3 拟Newton法的修正形式
习题4
第5章 无约束问题算法（III）
5.1 二次函数极小化问题的共轭方向法
5.2 非线性共轭梯度法
5.3 下降共轭梯度法
5.4 共轭梯度法的收敛速度
习题5
第6章 无约束问题算法（Iv）
6.1 信赖域算法的基本结构
6.2 信赖域算法的收敛性
6.3 信赖域一线性搜索型算法
6.4 信赖域子问题的求解
习题6
第7章 无约束问题算法（V）
7.1 坐标轮换法及其改进
7.2 Powell直接法
7.3 轴向搜索法
习题7
第8章 非线性方程组与最小二乘问题
8.1 非线性方程组的局部算法
8.2 非线性方程组的全局化算法
8.3 最小二乘问题
习题8
第9章 约束问题解的最优性条件
9.1 可行方向
9.2 约束问题的最优性条件
习题9
第10章 线性规划
10.1 线性规划问题的标准型
10.2 线性规划问题的基本概念和基本理论
10.3 单纯形法
10.4 初始基础可行解的确定
10.5 线性规划问题的对偶理论
习题10
第11章 二次规划
11.1 等式约束二次规划
11.2 解二次规划的有效集法
习题11
第12章 约束问题算法（I）
12.1 罚函数法
12.2 乘子法
习题12
第13章 约束问题算法（II）
13.1 线性约束问题的可行方向法
13.2 投影梯度法
13.3 既约梯度法
13.4 广义既约梯度法
习题13
第14章 约束问题算法（III）
14.1 局部序列二次规划算法
14.2 全局SQP算法
14.3 信赖域SQP算法
14.4 Maratos效应及改进策略
习题14
第15章 全局最优化方法简介
15.1 基本概念
15.2 覆盖法
15.3 外逼近法
15.4 分枝定界法
15.5 应用分枝定界法的几个问题
15.6 遗传算法
习题15
参考文献
附录A 解线性方程组的常用算法
A1 Gauss消元法
A2 LU分解
A3 迭代法
附录B MATLAB入门
B1 基本运算
B2 基本绘图
B3 逻辑控制
B4M文件
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>数值最优化算法与理论
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>医疗革命
第1 章 数据分析与数据挖掘的力量  1
1.1 葡萄牙医生解决世界新生儿出生缺陷的故事  2
1.2 医学数据挖掘的主要定义  5
1.2.1 数据挖掘的定义  5
1.2.2 医学数据挖掘的故事  5
1.3 医学数据模式识别的七大原理与案例讲解  6
1.3.1 什么是模式识别  6
1.3.2 7 个小故事  7
1.4 临床医学领域的机器学习与人工智能  12
1.5 神经元网络的基本原理  13
第2 章 临床医学的数据挖掘  20
2.1 房颤与肾功能关联现象的故事  21
2.2 支持向量机的算法原理与应用  30
2.2.1 一个故事的开场白  30
2.2.2 支持向量机的主要特点  31
2.2.3 支持向量机的应用案例  39
2.3 疾病规律与统计学革命  43
2.3.1 肝胆外科的统计学故事  43
2.3.2 双盲实验的诞生  44
2.3.3 几则很有趣的医学统计学故事  47
2.4 老年肺癌研究  50
2.4.1 数据的抓取与来源  50
2.4.2 癌症与老龄化的相关性分析  51
2.4.3 老年人肺癌手术适用性评估关键词频率  53
2.4.4 老年肺肿瘤的数据分析  54
2.4.5 英国肺癌患者38 年来死亡率研究  59
2.4.6 老龄肺癌死亡率数据的三维分析  59
2.5 临床医学与数据挖掘的边缘学科  62
2.5.1 几个实例  62
2.5.2 医学统计学与医学数据挖掘的区别  69
2.5.3 有关数据挖掘是边缘学科的几个实例  72
2.5.4 一个医学数据挖掘的案例  74
第3 章 临床医学与数据技术的深度融合  90
3.1 二型糖尿病与胰腺癌的故事  91
3.2 Cox 回归的基本原理与应用  94
3.2.1 Cox 回归的基本原理  94
3.2.2 晚期肺癌伴脑转移患者的预后多因素Cox 回归  95
3.2.3 本案例的几点启示  100
3.3 医学数据分析中的故事  101
3.4 聚类的临床医学意义  103
3.4.1 聚类算法的基本定义  103
3.4.2 临床医学数据挖掘中聚类的意义  104
3.4.3 案例  112
3.5 贝叶斯算法的应用案例  113
3.5.1 一个流传甚广的故事  113
3.5.2 一个贝叶斯算法的医学案例  114
第4 章 临床医学的模式识别  126
4.1 模式识别是什么  127
4.1.1 定义  127
4.1.2 临床医学模式识别的故事  127
4.2 基线静息心率的故事  130
4.3 决策树算法  132
4.4 最大期望（EM）算法  135
4.5 算法的规律与临床医学的本质  140
4.5.1 算法的本质是什么  140
4.5.2 数据挖掘中医学的本质  141
第5 章 医学数据挖掘的常用工具  146
5.1 SAS 挖掘软件运用案例  147
5.2 Weka 软件介绍  150
5.3 Matlab 案例  152
5.4 R 语言案例  162
5.5 临床医生如何用好挖掘工具  164
第6 章 专业级医学SCI 论文中的统计工具  169
6.1 医学数据中的T 值与P 值故事  170
6.2 K 线图的故事  172
6.3 国际顶级期刊上的数据技术  174
6.4 SCI 荟萃分析中的统计学工具  180
6.4.1 研究对象及入选标准  181
6.4.2 统计学处理  181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>医疗革命
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习
1 深度学习简介1
1.1 人工智能、机器学习和深度学习  1
1.1.1 引言  1
1.1.2 人工智能、机器学习和深度学习三者的关系  2
1.2 神经网络  3
1.2.1 感知器  3
1.2.2 激活函数  5
1.2.3 损失函数  8
1.2.4 梯度下降和随机梯度下降  8
1.2.5 反向传播算法简述  11
1.2.6 其他神经网络  12
1.3 学习方法建议  13
1.3.1 网络资源  13
1.3.2 TensorFlow 官方深度学习教程  14
1.3.3 开源社区  15
1.4 TensorLayer  15
1.4.1 深度学习框架概况  15
1.4.2 TensorLayer 概括  16
1.4.3 实验环境配置  17
2 多层感知器19
2.1 McCulloch-Pitts 神经元模型  19
2.1.1 人工神经网络到底能干什么？到底在干什么  21
2.1.2 什么是激活函数？什么是偏值  22
2.2 感知器  23
2.2.1 什么是线性分类器  24
2.2.2 线性分类器有什么优缺点  26
2.2.3 感知器实例和异或问题（XOR 问题）  26
2.3 多层感知器  30
2.4 实现手写数字分类  32
2.5 过拟合  40
2.5.1 什么是过拟合  40
2.5.2 Dropout  41
2.5.3 批规范化  42
2.5.4 L1、L2 和其他正则化方法  42
2.5.5 Lp 正则化的图形化解释  44
2.6 再实现手写数字分类  46
2.6.1 数据迭代器  46
2.6.2 通过all_drop 启动与关闭Dropout  47
2.6.3 通过参数共享实现训练测试切换  50
3 自编码器54
3.1 稀疏性  54
3.2 稀疏自编码器  56
3.3 实现手写数字特征提取  59
3.4 降噪自编码器  65
3.5 再实现手写数字特征提取  68
3.6 堆栈式自编码器及其实现  72
4 卷积神经网络80
4.1 卷积原理  80
4.1.1 卷积操作  81
4.1.2 张量  84
4.1.3 卷积层  85
4.1.4 池化层  87
4.1.5 全连接层  89
4.2 经典任务  90
4.2.1 图像分类  90
4.2.2 目标检测  91
4.2.3 语义分割  94
4.2.4 实例分割  94
4.3 经典卷积网络  95
4.3.1 LeNet  95
4.3.2 AlexNet  96
4.3.3 VGGNet  96
4.3.4 GoogLeNet  98
4.3.5 ResNet  99
4.4 实现手写数字分类  100
4.5 数据增强与规范化  104
4.5.1 数据增强  104
4.5.2 批规范化  106
4.5.3 局部响应归一化  107
4.6 实现CIFAR10 分类  108
4.6.1 方法1：tl.prepro 做数据增强  108
4.6.2 方法2：TFRecord 做数据增强  114
4.7 反卷积神经网络  120
5 词的向量表达121
5.1 目的与原理  121
5.2 Word2Vec  124
5.2.1 简介  124
5.2.2 Continuous Bag-Of-Words（CBOW）模型  124
5.2.3 Skip Gram（SG）模型  129
5.2.4 Hierarchical Softmax  132
5.2.5 Negative Sampling  135
5.3 实现Word2Vec  136
5.3.1 简介  136
5.3.2 实现  136
5.4 重载预训练矩阵  144
6 递归神经网络148
6.1 为什么需要它  148
6.2 不同的RNNs  151
6.2.1 简单递归网络  151
6.2.2 回音网络  152
6.3 长短期记忆  153
6.3.1 LSTM 概括  153
6.3.2 LSTM 详解  157
6.3.3 LSTM 变种  159
6.4 实现生成句子  160
6.4.1 模型简介  160
6.4.2 数据迭代  163
6.4.3 损失函数和更新公式  164
6.4.4 生成句子及Top K 采样  167
6.4.5 接下来还可以做什么  169
7 深度增强学习171
7.1 增强学习  172
7.1.1 概述  172
7.1.2 基于价值的增强学习  173
7.1.3 基于策略的增强学习  176
7.1.4 基于模型的增强学习  177
7.2 深度增强学习  179
7.2.1 深度Q 学习  179
7.2.2 深度策略网络  181
7.3 更多参考资料  187
7.3.1 书籍  187
7.3.2 在线课程  187
8 生成对抗网络188
8.1 何为生成对抗网络  189
8.2 深度卷积对抗生成网络  190
8.3 实现人脸生成  191
8.4 还能做什么  198
9 高级实现技巧202
9.1 与其他框架对接  202
9.1.1 无参数层  203
9.1.2 有参数层  203
9.2 自定义层  204
9.2.1 无参数层  204
9.2.2 有参数层  205
9.3 建立词汇表  207
9.4 补零与序列长度  209
9.5 动态递归神经网络  210
9.6 实用小技巧  211
9.6.1 屏蔽显示  211
9.6.2 参数名字前缀  212
9.6.3 获取特定参数  213
9.6.4 获取特定层输出  213
10 实例一：使用预训练卷积网络214
10.1 高维特征表达  214
10.2 VGG 网络  215
10.3 连接TF-Slim  221
11 实例二：图像语义分割及其医学图像应用225
11.1 图像语义分割概述  225
11.1.1 传统图像分割算法简介  227
11.1.2 损失函数与评估指标  229
11.2 医学图像分割概述  230
11.3 全卷积神经网络和U-Net 网络结构  232
11.4 医学图像应用：实现脑部肿瘤分割  234
11.4.1 数据与数据增强  235
11.4.2 U-Net 网络  238
11.4.3 损失函数  239
11.4.4 开始训练  241
12 实例三：由文本生成图像244
12.1 条件生成对抗网络之GAN-CLS  245
12.2 实现句子生成花朵图片  246
13 实例四：超高分辨率复原260
13.1 什么是超高分辨率复原  260
13.2 网络结构  261
13.3 联合损失函数  264
13.4 训练网络  269
13.5 使用测试  277
14 实例五：文本反垃圾280
14.1 任务场景  280
14.2 网络结构  281
14.3 词的向量表示  282
14.4 Dynamic RNN 分类器  283
14.5 训练网络  284
14.5.1 训练词向量  284
14.5.2 文本的表示  290
14.5.3 训练分类器  291
14.5.4 模型导出  296
14.6 TensorFlow Serving 部署  299
14.7 客户端调用  301
14.8 其他常用方法  306
中英对照表及其缩写309
参考文献316
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>面向MATLAB工具箱的神经网络理论与应用
第3版前言第2版前言前言第1章  概述  1.1  人工神经网络概念的提出  1.2  神经细胞以及人工神经元的组成  1.3  人工神经网络应用领域  1.4  人工神经网络发展的回顾  1.5  人工神经网络的基本结构与模型    1.5.1  人工神经元的模型    1.5.2  激活转移函数    1.5.3  单层神经元网络模型结构    1.5.4  多层神经网络    1.5.5  递归神经网络  1.6  用MATLAB计算人工神经网络输出  1.7  本章小结  习题第2章  前向神经网络  2.1  感知器    2.1.1  感知器的网络结构    2.1.2  感知器的图形解释    2.1.3  感知器的学习规则    2.1.4  网络的训练    2.1.5  感知器的局限性    2.1.6  “异或”问题    2.1.7  解决线性可分性限制的办法    2.1.8  本节小结  2.2  自适应线性元件    2.2.1  自适应线性神经元模型和结构    2.2.2  W-H学习规则    2.2.3  网络训练    2.2.4  例题与分析    2.2.5  对比与分析    2.2.6  单步延时线及其自适应滤波器的实现    2.2.7  自适应线性网络的应用    2.2.8  本节小结  2.3  反向传播网络    2.3.1  BP网络模型与结构    2.3.2  BP学习规则    2.3.3  BP网络的训练及其设计过程    2.3.4  BP网络的设计    2.3.5  限制与不足    2.3.6  反向传播法的改进方法    2.3.7  基于数值优化方法的网络训练算法    2.3.8  数值实例对比    2.3.9  本节小结  习题第3章  递归神经网络  3.1  各种递归神经网络    3.1.1  全局反馈型递归神经网络    3.1.2  前向递归神经网络    3.1.3  混合型网络    3.1.4  本节小结  3.2  全局反馈递归网络    3.2.1  霍普菲尔德网络模型    3.2.2  状态轨迹    3.2.3  离散型霍普菲尔德网络    3.2.4  连续型霍普菲尔德网络    3.2.5  本节小结  3.3  Elman网络    3.3.1  网络结构及其输入输出关系式    3.3.2  修正网络权值的学习算法    3.3.3  稳定性推导    3.3.4  对稳定性结论的分析    3.3.5  对角递归网络稳定时学习速率的确定    3.3.6  本节小结  3.4  对角递归神经网络    3.4.1  网络结构及其输入输出关系式    3.4.2  网络的稳定性分析    3.4.3  进一步的讨论    3.4.4  数值实例    3.4.5  本节小结  3.5  局部递归神经网络    3.5.1  PIDNNC的设计    3.5.2  闭环控制系统稳定性分析    3.5.3  实时在线控制策略的设计步骤    3.5.4  数值应用    3.5.5  本节小结  习题第4章  局部连接神经网络  4.1  径向基函数网络    4.1.1  径向基函数及其网络分析    4.1.2  网络的训练与设计    4.1.3  广义径向基函数网络    4.1.4  数字应用对比及性能分析    4.1.5  本节小结  4.2  B样条基函数及其网络  4.3  CMAC神经网络    4.3.1  CMAC网络基本结构    4.3.2  CMAC的学习算法  4.4局  部神经网络的性能对比分析    4.4.1  CMAC、B样条和RBF共有的结构特点    4.4.2  CMAC、B样条和RBF的不同之处  4.5  K型局部连接神经网络    4.5.1  网络结构与权值修正法    4.5.2  网络特性分析    4.5.3  数字应用对比及性能分析    4.5.4  本节小结  习题第5章  自组织竞争神经网络  5.1  几种联想学习规则    5.1.1  内星学习规则    5.1.2  外星学习规则    5.1.3  科荷伦学习规则  5.2  自组织竞争网络    5.2.1  网络结构    5.2.2  竞争学习规则    5.2.3  竞争网络的训练过程  5.3  科荷伦自组织映射网络    5.3.1  科荷伦网络拓扑结构    5.3.2  网络的训练过程  5.4  自适应共振理论    5.4.1  ART-1网络结构    5.4.2  ART-1的运行过程    5.4.3  ART-2神经网络  5.5  本章小结  习题第6章  随机神经网络  6.1  概述    6.1.1  随机神经网络的发展    6.1.2  GNN模型描述    6.1.3  RNN的学习算法    6.1.4  RNN的应用    6.1.5  其他随机网络    6.1.6  研究前景  6.2  用Boltzmann机求解典型NP优化问题TSP    6.2.1  Boltzmann机网络模型及其权值修正规则    6.2.2  用Boltzmann机网络解TSP    6.2.3  Boltzmann机与Hopfield网络解TSP的对比    6.2.4  本节小结  6.3  随机神经网络算法改进及其应用    6.3.1  DRNN解TSP的参数推导和改进方法    6.3.2  DRNN网络解TSP改进方法的实验对比    6.3.3  本节小结  6.4  采用DRNN网络优化求解的对比研究    6.4.1  DRNN与Hopfield网络求解TSP的理论分析    6.4.2  DRNN与Hopfield网络解TSP的实验对比    6.4.3  本节小结  习题第7章  面向工具箱的神经网络实际应用  7.1  综述    7.1.1  神经网络技术的选用    7.1.2  神经网络各种模型的应用范围    7.1.3  网络设计的基本原则  7.2  神经网络在控制系统中的应用    7.2.1  反馈线性化    7.2.2  问题的提出    7.2.3  神经网络设计  7.3  利用神经网络进行字母的模式识别    7.3.1  问题的阐述    7.3.2神经网络的设计  7.4  用于字符识别的三种人工神经网络的性能对比    7.4.1  用于字母识别的感知器网络    7.4.2  用于字母识别的霍普菲尔德网络    7.4.3  字母识别实验及其结果分析附录A  MATLAB 7.1神经网络工具箱4.0.6函数一览表附录B  程序目录参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>面向MATLAB工具箱的神经网络理论与应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统(原理与实践)/计算机科学丛书
出版者的话
译者序
前言
致谢
作者简介
第1章推荐系统概述
1.1引言
1.2推荐系统的目标
1.2.1推荐系统应用范围
1.3推荐系统的基本模型
1.3.1协同过滤模型
1.3.2基于内容的推荐系统
1.3.3基于知识的推荐系统
1.3.4人口统计推荐系统
1.3.5混合集成的推荐系统
1.3.6对推荐系统的评价
1.4推荐系统领域特有的挑战
1.4.1基于上下文的推荐系统
1.4.2时间敏感的推荐系统
1.4.3基于位置的推荐系统
1.4.4社交信息系统
1.5高级论题和应用
1.5.1推荐系统中的冷启动问题
1.5.2抗攻击推荐系统
1.5.3组推荐系统
1.5.4多标准推荐系统
1.5.5推荐系统中的主动学习
1.5.6推荐系统中的隐私问题
1.5.7应用领域
1.6小结
1.7相关工作
1.8习题
第2章基于近邻的协同过滤
2.1引言
2.2评分矩阵的关键性质
2.3通过基于近邻的方法预测评分
2.3.1基于用户的近邻模型
2.3.2基于物品的近邻模型
2.3.3高效的实现和计算复杂度
2.3.4基于用户的方法和基于物品的方法的比较
2.3.5基于近邻方法的优劣势
2.3.6基于用户的方法和基于物品的方法的联合
2.4聚类和基于近邻的方法
2.5降维与近邻方法
2.5.1处理偏差
2.6近邻方法的回归模型视角
2.6.1基于用户的最近邻回归
2.6.2基于物品的最近邻回归
2.6.3基于用户的方法和基于物品的方法的结合
2.6.4具有相似度权重的联合插值
2.6.5稀疏线性模型
2.7基于近邻方法的图模型
2.7.1用户物品图
2.7.2用户用户图
2.7.3物品物品图
2.8小结
2.9相关工作
2.10习题
第3章基于模型的协同过滤
3.1引言
3.2决策和回归树
3.2.1将决策树扩展到协同过滤
3.3基于规则的协同过滤
3.3.1将关联规则用于协同过滤
3.3.2面向物品的模型与面向用户的模型
3.4朴素贝叶斯协同过滤
3.4.1处理过拟合
3.4.2示例：使用贝叶斯方法处理二元评分
3.5将任意分类模型当作黑盒来处理
3.5.1示例：使用神经网络作为黑盒分类器
3.6潜在因子模型
3.6.1潜在因子模型的几何解释
3.6.2潜在因子模型的低秩解释
3.6.3基本矩阵分解原理
3.6.4无约束矩阵分解
3.6.5奇异值分解
3.6.6非负矩阵分解
3.6.7理解矩阵因子分解方法族
3.7集成因子分解和近邻模型
3.7.1基准估计：非个性化偏倚中心模型
3.7.2模型的近邻部分
3.7.3模型的潜在因子部分
3.7.4集成近邻和潜在因子部分
3.7.5求解优化模型
3.7.6关于精度的一些观察
3.7.7将潜在因子模型集成到任意模型
3.8小结
3.9相关工作
3.10习题
第4章基于内容的推荐系统
4.1引言
4.2基于内容的系统的基本组件
4.3预处理和特征提取
4.3.1特征提取
4.3.2特征表示和清洗
4.3.3收集用户的偏好
4.3.4监督特征选择和加权
4.4学习用户画像和过滤
4.4.1最近邻分类
4.4.2与基于案例的推荐系统的关联性
4.4.3贝叶斯分类器
4.4.4基于规则的分类器
4.4.5基于回归的模型
4.4.6其他学习模型和比较概述
4.4.7基于内容的系统的解释
4.5基于内容的推荐与协同推荐
4.6将基于内容的模型用于协同过滤
4.6.1利用用户画像
4.7小结
4.8相关工作
4.9习题
第5章基于知识的推荐系统
5.1引言
5.2基于约束的推荐系统
5.2.1返回相关结果
5.2.2交互方法
5.2.3排序匹配的物品
5.2.4处理不可接受的结果或空集
5.2.5添加约束
5.3基于案例的推荐系统
5.3.1相似性度量
5.3.2批评方法
5.3.3批评的解释
5.4基于知识的系统的持久个性化
5.5小结
5.6相关工作
5.7习题
第6章基于集成的混合推荐系统
6.1引言
6.2从分类角度看集成方法
6.3加权型混合系统
6.3.1几种模型组合的方法
6.3.2对分类中的bagging算法的调整
6.3.3随机性注入算法
6.4切换型混合系统
6.4.1为解决冷启动问题的切换机制
6.4.2桶模型
6.5级联型混合系统
6.5.1推荐结果的逐步优化
6.5.2boosting算法
6.6特征放大型混合系统
6.7元级型混合系统
6.8特征组合型混合系统
6.8.1回归分析和矩阵分解
6.8.2元级特征
6.9交叉型混合系统
6.10小结
6.11相关工作
6.12习题
第7章推荐系统评估
7.1引言
7.2评估范例
7.2.1用户调查
7.2.2在线评估
7.2.3使用历史数据集进行离线评估
7.3评估设计的总体目标
7.3.1精确性
7.3.2覆盖率
7.3.3置信度和信任度
7.3.4新颖度
7.3.5惊喜度
7.3.6多样性
7.3.7健壮性和稳定性
7.3.8可扩展性
7.4离线推荐评估的设计要点
7.4.1Netflix Prize数据集的案例研究
7.4.2为训练和测试分解评分
7.4.3与分类设计的比较
7.5离线评估的精确性指标
7.5.1度量预测评分的精确性
7.5.2通过相关性评估排名
7.5.3通过效用评估排名
7.5.4通过ROC曲线评估排名
7.5.5哪种排名方式最好
7.6评估指标的局限性
7.6.1避免评估游戏
7.7小结
7.8相关工作
7.9习题
第8章上下文敏感的推荐系统
8.1引言
8.2多维方法
8.2.1层级的重要性
8.3上下文预过滤：一种基于降维的方法
8.3.1基于集成的改进
8.3.2多级别的估计
8.4后过滤方法
8.5上下文建模
8.5.1基于近邻的方法
8.5.2潜在因子模型
8.5.3基于内容的模型
8.6小结
8.7相关工作
8.8习题
第9章时间与位
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>推荐系统(原理与实践)/计算机科学丛书
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
总序前言第1章  绪论  1.1  模式和模式识别  1.2  模式的分类  1.3  模式识别系统的基本构成  1.4  模式识别方法及其分类  1.5  模式识别举例  1.6  本书内容安排第2章  统计模式识别中的几何方法  2.1  统计分类的基本思想    2.1.1  特征空间和分类器设计    2.1.2  两个例子  2.2  模式的相似性度量和最小距离分类器    2.2.1  相似性度量和距离函数    2.2.2  最小距离分类器  2.3  线性可分情况下的几何分类法    2.3.1  线性判别函数和线性分类器    2.3.2  线性判别函数的参数确定    2.3.3  感知器算法    2.3.4  收敛性定理    2.3.5  梯度下降法    2.3.6  最小平方误差法  2.4  非线性可分情况下的几何分类法    2.4.1  广义线性判别函数法    2.4.2  分段线性判别函数法    2.4.3  非线性判别函数法：位势函数法  2.5  线性可分问题的非迭代解法  2.6  最优分类超平面  本章小结第3章  统计模式识别中的概率方法  3.1  用概率方法描述分类问题  3.2  几个相关的概念  3.3  最小错误概率判决准则  3.4  最小风险判决规则  3.5  贝叶斯统计判决规则的似然比表现形式    3.5.1  最小错误概率判决规则的似然比表现形式    3.5.2  最小风险判决规则的似然比表现形式  3.6  拒绝判决  3.7  贝叶斯分类器的一般结构  3.8  Neyman-Pearson判决规则  3.9  最小最大判决规则  3.10  基于分段线性化的分类器设计  3.11  正态分布下的分类器设计    3.11.1  正态分布的定义和若干性质    3.11.2  正态分布下的分类器设计  3.12  有监督情况下类条件概率密度的参数估计    3.12.1  最大似然估计    3.12.2  贝叶斯估计和贝叶斯学习  3.13  非监督情况下类条件概率密度的参数估计  3.14  类条件概率密度的非参数估计    3.14.1  非参数估计的基本概念和方法    3.14.2  Parzen窗估计法    3.14.3  kn-近邻估计法    3.14.4  正交级数副近法  本章小结第4章  分类器的错误率  4.1  正态分布下的错误率  4.2  样本各维之间统计独立情况下的错误率  4.3  错误率界限的理论估计    4.3.1  Chernoff界限    4.3.2  Bhattacharyya界限  4.4  近邻分类法的错误率  4.5  分类器错误率的实验估计    4.5.1  已训练分类器错误率的实验估计    4.5.2  有限样本情况下分类器错误率的实验估计  本章小结第5章  统计模式识别中的聚类方法  5.1  聚类分析  5.2  聚类准则    5.2.1  误差平方和准则函数    5.2.2  权平均平方距离和准则函数    5.2.3  类间距离和准则函数    5.2.4  离散度准则函数  5.3  基于分裂的聚类算法    5.3.1  简单增类聚类算法    5.3.2  改进的增类聚类算法  5.4  基于合并的聚类算法  5.5  动态聚类算法    5.5.1  C-均值动态聚类算法(Ⅰ)    5.5.2  C-均值动态聚类算法(Ⅱ)    5.5.3  ISODATA算法    5.5.4  基于样本和核的相似性度量的动态聚类算法  5.6  基于近邻函数值准则的聚类算法  5.7  最小张树聚类算法  本章小结第6章  结构模式识别中的句法方法  6.1  模式基元和模式结构的表达  6.2  形式语言基础    6.2.1  集合、集合间的关系和集合运算    6.2.2  符号串和语言    6.2.3  文法    6.2.4  文法的分类  6.3  有限状态自动机    6.3.1  确定的有限状态自动机    6.3.2  非确定的有限状态自动机    6.3.3  有限状态自动机之间的等价    6.3.4  有限状态文法和有限状态自动机  6.4  下推自动机    6.4.1  下推自动机的即时描述    6.4.2  上下文无关文法和下推自动机  6.5  图灵机  6.6  关于语言、文法和自动机的再讨论    6.6.1  语言的命名    6.6.2  从语言构建自动机    6.6.3  语言类型的确定  6.7  句法分析    6.7.1  正向剖析过程的树表示    6.7.2  先验规则引导的树正向剖析算法    6.7.3  基于三角表格的反向剖析算法  6.8  文法推断    6.8.1  正则文法的推断    6.8.2  非正则文法的推断  本章小结第7章  总结附录参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器翻译
第一章 绪论
1.1 机器翻译概述
1.1.1 机器翻译定义
1.1.2 机器翻译简史
1.1.3 机器翻译方法
1.1.4 机器翻译分析及展望
1.2 机器翻译的应用
1.2.1 文本翻译
1.2.2 语音翻译
1.2.3 应用扩展
1.3 本书章节总览
参考文献
第二章 机器翻译语料和评测
2.1 机器翻译语料
2.1.1 单语语料
2.1.2 双语语料
2.1.3 语料获取
2.1.4 语料处理
2.2 机器翻译评测
2.2.1 人工评测
2.2.2 自动评测
2.2.3 评测活动
参考文献
第三章 统计机器翻译基础
3.1 统计机器翻译简介
3.1.1 统计机器翻译系统框架
3.1.2 统计机器翻译基本流程
3.2 统计机器翻译建模
3.2.1 噪声-信道模型
3.2.2 对数-线性模型
3.2.3 模型训练方法
3.3 语言模型
3.3.1 n元文法语言模型定义
3.3.2 语言模型的平滑
3.3.3 语言模型的评价指标
3.4 翻译模型
3.4.1 词汇翻译模型
3.4.2 短语翻译模型
3.5 调序模型
3.5.1 基于跳转距离的调序模型
3.5.2 词汇化调序模型
3.5.3 基于句法的调序模型
3.6 扩展阅读
参考文献
第四章 统计机器翻译系统模型
4.1 基于短语的统计机器翻译模型
4.1.1 噪声-信道模型短语翻译模型
4.1.2 对数-线性模型短语翻译模型
4.1.3 解码
4.2 基于形式文法的统计机器翻译模型
4.2.1 基于反向转录文法的统计机器翻译模型
4.2.2 基于层次化短语的统计机器翻译模型
4.3 基于句法的统计机器翻译系统模型
4.3.1 树到串的翻译模型
4.3.2 串到树的翻译模型
4.4 多系统融合
4.4.1 句子级系统融合
4.4.2 短语级系统融合
4.4.3 词级系统融合
4.5 领域自适应
4.5.1 基于数据选择的领域自适应
4.5.2 基于自学习的领域自适应
4.5.3 基于上下文信息的领域自适应
4.6 统计机器翻译开源工具
4.7 扩展阅读
参考文献
第五章 自然语言处理中的深度学习基础
5.1 深度学习基础
5.1.1 简介
5.1.2 感知机
5.1.3 多层感知机
5.1.4 激活函数
5.1.5 反向传播算法
5.2 神经网络学习算法
5.2.1 随机梯度下降算法
5.2.2 基于动量的随机梯度下降算法
5.2.3 AdaGrad算法
5.2.4 RMSProp算法
5.2.5 AdaDelta算法
5.2.6 Adam算法
5.2.7 不同参数更新方法的比较
5.3 自然语言处理中常用的神经网络模型
5.3.1 前馈神经网络
5.3.2 循环神经网络
5.3.3 长短时记忆网络
5.3.4 深层循环神经网络
5.3.5 卷积神经网络
5.3.6 通用词嵌入
5.4 扩展阅读
5.5 词汇缩写详解
参考文献
第六章 神经机器翻译
6.1 简单的神经网络机器翻译模型
6.2 神经联合模型
6.2.1 从语言模型到联合模型
6.2.2 基于神经网络的联合模型
6.2.3 基于神经网络的联合模型的训练
6.2.4 联合模型解码速度的优化
6.3 基于序列转换的神经机器翻译
6.3.1 编码器-解码器框架
6.3.2 编码器及其构造
6.3.3 其他方式的编码器
6.3.4 解码器及其构造
6.4 注意力模型
6.4.1 基本序列转换模型的困难
6.4.2 注意力网络
6.4.3 匹配函数
6.4.4 局部匹配与全局匹配
6.5 卷积串到串模型
6.5.1 卷积编码器和解码器
6.5.2 多步注意力机制
6.6 完全基于注意力网络的神经翻译模型
6.6.1 基于注意力网络的编码器和解码器
6.6.2 分组（multi-head）注意力网络
6.6.3 位置编码（positional encoding）
6.6.4 自注意力网络性能分析
6.7 参数正则化
6.7.1 L1／L2正则化
6.7.2 maxout和dropout正则化
6.8 神经机器翻译解码
6.8.1 贪心搜索（greedy search）
6.8.2 束搜索（beam search）
6.8.3 集合解码（ensemble decoding）
6.9 神经机器翻译模型的训练
6.10 扩展阅读
6.11 本章小结
参考文献
第七章 前沿课题
7.1 基于句法的神经机器翻译
7.2 并行化训练
7.2.1 数据并行化
7.2.2 模型并行化
7.3 神经机器翻译的快速解码技术
7.3.1 网络预计算
7.3.2 参数的量化
7.3.3 受限词表优化
7.4 注意力模型的改进
7.4.1 覆盖度和能产度
7.4.2 循环注意力网络
7.5 神经机器翻译的可伸缩性
7.5.1 近似softmax函数
7.5.2 未登录词处理
7.5.3 基于词根分解的开放词汇表
7.6 单语数据在神经机器翻译中的应用
7.6.1 独立的神经语言模型
7.6.2 往返翻译（back translatinn）
7.6.3 联合训练（joint training）
7.6.4 强化学习在神经机器翻译中的应用
7.6.5 生成对抗网络
7.7 扩展阅读
7.8 本章小结
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>机器翻译
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark大数据分析实战
前 言
第1章 Spark简介 1
1.1 初识Spark 1
1.2 Spark生态系统BDAS 3
1.3 Spark架构与运行逻辑 4
1.4 弹性分布式数据集 6
1.4.1 RDD简介 6
1.4.2 RDD算子分类 8
1.5 本章小结 17
第2章 Spark开发与环境配置 18
2.1 Spark应用开发环境配置 18
2.1.1 使用Intellij开发Spark程序 18
2.1.2 使用SparkShell进行交互式数据分析 23
2.2 远程调试Spark程序 24
2.3 Spark编译 26
2.4 配置Spark源码阅读环境 29
2.5 本章小结 29
第3章 BDAS简介 30
3.1 SQL on Spark 30
3.1.1 为什么使用Spark SQL 31
3.1.2 Spark SQL架构分析 32
3.2 Spark Streaming 35
3.2.1 Spark Streaming简介 35
3.2.2 Spark Streaming架构 38
3.2.3 Spark Streaming原理剖析 38
3.3 GraphX 45
3.3.1 GraphX简介 45
3.3.2 GraphX的使用简介 45
3.3.3 GraphX体系结构 48
3.4 MLlib 50
3.4.1 MLlib简介 50
3.4.2 MLlib中的聚类和分类 52
3.5 本章小结 57
第4章 Lamda架构日志分析流水线 58
4.1 日志分析概述 58
4.2 日志分析指标 61
4.3 Lamda架构 62
4.4 构建日志分析数据流水线 64
4.4.1 用Flume进行日志采集 64
4.4.2 用Kafka将日志汇总 68
4.4.3 用Spark Streaming进行实时日志分析 70
4.4.4 Spark SQL离线日志分析 75
4.4.5 用Flask将日志KPI可视化 78
4.5 本章小结 81
第5章 基于云平台和用户日志的推荐系统 82
5.1 Azure云平台简介 82
5.1.1 Azure网站模型 83
5.1.2 Azure数据存储 84
5.1.3 Azure Queue消息传递 84
5.2 系统架构 85
5.3 构建Node.js应用 86
5.3.1 创建Azure Web应用 87
5.3.2 构建本地Node.js网站 90
5.3.3 发布应用到云平台 90
5.4 数据收集与预处理 91
5.4.1 通过JS收集用户行为日志 92
5.4.2 用户实时行为回传到Azure Queue 94
5.5 Spark Streaming实时分析用户日志 96
5.5.1 构建Azure Queue的Spark Streaming Receiver 96
5.5.2 Spark Streaming实时处理Azure Queue日志 97
5.5.3 Spark Streaming数据存储于Azure Table 98
5.6 MLlib离线训练模型 99
5.6.1 加载训练数据 99
5.6.2 使用rating RDD训练ALS模型 100
5.6.3 使用ALS模型进行电影推荐 101
5.6.4 评估模型的均方差 101
5.7 本章小结 102
第6章 Twitter情感分析 103
6.1 系统架构 103
6.2 Twitter数据收集 104
6.2.1 设置 104
6.2.2 Spark Streaming接收并输出Tweet 109
6.3 数据预处理与Cassandra存储 111
6.3.1 添加SBT依赖 111
6.3.2 创建Cassandra Schema 112
6.3.3 数据存储于Cassandra 112
6.4 Spark Streaming热点Twitter分析 113
6.5 Spark Streaming在线情感分析 115
6.6 Spark SQL进行Twitter分析 118
6.6.1 读取Cassandra数据 118
6.6.2 查看JSON数据模式 118
6.6.3 Spark SQL分析Twitter 119
6.7 Twitter可视化 123
6.8 本章小结 125
第7章 热点新闻分析系统 126
7.1 新闻数据分析 126
7.2 系统架构 126
7.3 爬虫抓取网络信息 127
7.3.1 Scrapy简介 127
7.3.2 创建基于Scrapy的新闻爬虫 128
7.3.3 爬虫分布式化 133
7.4 新闻文本数据预处理 134
7.5 新闻聚类 135
7.5.1 数据转换为向量（向量空间模型VSM） 135
7.5.2 新闻聚类 136
7.5.3 词向量同义词查询 138
7.5.4 实时热点新闻分析 138
7.6 Spark Elastic Search构建全文检索引擎 139
7.6.1 部署Elastic Search 139
7.6.2 用Elastic Search索引MongoDB数据 141
7.6.3 通过Elastic Search检索数据 143
7.7 本章小结 145
第8章 构建分布式的协同过滤推荐系统 146
8.1 推荐系统简介 146
8.2 协同过滤介绍 147
8.2.1 基于用户的协同过滤算法User-based CF 148
8.2.2 基于项目的协同过滤算法Item-based CF 149
8.2.3 基于模型的协同过滤推荐Model-based CF 150
8.3 基于Spark的矩阵运算实现协同过滤算法 152
8.3.1 Spark中的矩阵类型 152
8.3.2 Spark中的矩阵运算 153
8.3.3 实现User-based协同过滤的示例 153
8.3.4 实现Item-based协同过滤的示例 154
8.3.5 基于奇异值分解实现Model-based协同过滤的示例 155
8.4 基于Spark的MLlib实现协同过滤算法 155
8.4.1 MLlib的推荐算法工具 155
8.4.2 MLlib协同过滤推荐示例 156
8.5 案例：使用MLlib协同过滤实现电影推荐 157
8.5.1 MovieLens数据集 157
8.5.2 确定ZUI佳的协同过滤模型参数 158
8.5.3 利用ZUI佳模型进行电影推荐 160
8.6 本章小结 161
第9章 基于Spark的社交网络分析 162
9.1 社交网络介绍 162
9.1.1 社交网络的类型 162
9.1.2 社交网络的相关概念 163
9.2 社交网络中社团挖掘算法 164
9.2.1 聚类分析和K均值算法简介 165
9.2.2 社团挖掘的衡量指标 165
9.2.3 基于谱聚类的社团挖掘算法 166
9.3 Spark中的K均值算法 168
9.3.1 Spark中与K均值有关的对象和方法 168
9.3.2 Spark下K均值算法示例 168
9.4 案例：基于Spark的Facebook社团挖掘 169
9.4.1 SNAP社交网络数据集介绍 169
9.4.2 基于Spark的社团挖掘实现 170
9.5 社交网络中的链路预测算法 172
9.5.1 分类学习简介 172
9.5.2 分类器的评价指标 173
9.5.3 基于Logistic回归的链路预测算法 174
9.6 Spark MLlib中的Logistic回归 174
9.6.1 分类器相关对象 174
9.6.2 模型验证对象 175
9.6.3 基于Spark的Logistic回归示例 175
9.7 案例：基于Spark的链路预测算法 177
9.7.1 SNAP符号社交网络Epinions数据集 177
9.7.2 基于Spark的链路预测算法 177
9.8 本章小结 179
第10章 基于Spark的大规模新闻主题分析 180
10.1 主题模型简介 180
10.2 主题模型LDA 181
10.2.1 LDA模型介绍 181
10.2.2 LDA的训练算法 183
10.3 Spark中的LDA模型 185
10.3.1 MLlib对LDA的支持 185
10.3.2 Spark中LDA模型训练示例 186
10.4 案例：Newsgroups新闻的主题分析 189
10.4.1 Newsgroups数据集介绍 190
10.4.2 交叉验证估计新闻的主题个数 190
10.4.3 基于主题模型的文本聚类算法 193
10.4.4 基于主题模型的文本分类算法 195
10.5 本章小结 196
第11章 构建分布式的搜索引擎 197
11.1 搜索引擎简介 197
11.2 搜索排序概述 198
11.3 查询无关模型PageRank 199
11.4 基于Spark的分布式PageRank实现 200
11.4.1 PageRank的MapReduce实现 200
11.4.2 Spark的分布式图模型GraphX 203
11.4.3 基于GraphX的PageRank实现 203
11.5 案例：GoogleWeb Graph的PageRank计算 204
11.6 查询相关模型Ranking SVM 206
11.7 Spark中支持向量机的实现 208
11.7.1 Spark中的支持向量机模型 208
11.7.2 使用Spark测试数据演示支持向量机的训练 209
11.8 案例：基于MSLR数据集的查询排序 211
11.8.1 Microsoft Learning to Rank数据集介绍 211
11.8.2 基于Spark的Ranking SVM实现 212
11.9 本章小结 213
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Spark大数据分析实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Logistic回归入门
序
前言
第1章 Logistic回归的逻辑
第1节 对虚拟因变量进行回归
第2节 把概率转换成Logistic
第3节 非线性的线性化
第4节 小结
第2章 解释Logistic回归系数
第1节 比数的对数
第2节 比数
第3节 概率
第4节 显著性检验
第5节 标准化的系数
第6节 一个实例
第7节 小结
第3章 估计和模型匹配
第1节 最大似然估计
第2节 对数似然函数
第3节 估计
第4节 用对数似然值来检测显著性
第5节 模型评估
第6节 一个实例
第7节 小结
第4章 Probit分析
第1节 另一种将非线性线性化的方式
第2节 Probit分析
第3节 对系数的解释
第4节 最大似然估计
第5节 一个实例
第6节 小结
第5章 总结
附录
注释
参考文献
译名对照表
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Logistic回归入门
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>造物的困惑
第1章 万物之灵
第2章 人工智能
第3章 机器与人的竞赛
第4章 更小更快的计算机
第5章 基因芯片
第6章 人体的修补
第7章 干细胞
第8章 转基因
第9章 克隆的震撼
第10章 人造生命
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>造物的困惑
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>高等人工智能原理
前言
第一篇总论：高等人工智能研究的科学观与方法论
第1章自然智能理论研究的启迪
1.1脑神经科学研究简介
1.1.1人类大脑与智能系统
1.1.2脑的组织学
1.1.3脑组织的细胞学
1.2认知科学研究简介
1.2.1感知
1.2.2注意
1.2.3记忆
1.2.4思维
1.2.5语言
1.2.6情绪
1.3脑科学与认知科学的融通：“全信息”科学观
1.3.1脑神经科学与认知科学：存在“理论的断裂”
1.3.2认知科学研究：需要“全信息”，也能生成”全信息”
1.4小结与评注
参考文献
第2章人工智能研究方法的变革
2.1人工智能研究鸟瞰
2.1.1人工智能的基本概念
2.1.2“人工智能”含义的辨析
2.1.3人工智能研究的历史与现状
2.2科学研究方法的进化
2.2.1科学方法论的进化
2.2.2科学方法论演进概要
2.3概念与方法的重审：开放复杂信息系统的科学方法论
2.3.1人工智能研究遭遇的科学方法论问题
2.3.2人工智能研究的新型科学方法论
2.3.3《高等人工智能原理》一书的知识结构
2.4小结与评注
参考文献
第二篇高等人工智能的基础理论
第3章全信息理论
3.1基本概念
3.1.1现有信息概念简评
3.1.2信息定义谱系：本体论信息与认识论信息
3.1.3Shannon信息：统计型语法信息
3.2全信息的分类与描述
3.2.1信息的分类
3.2.2信息的描述
3.3信息的度量
3.3.1概率语法信息的测度：Shannon概率熵
3.3.2模糊语法信息的测度：DeLuca—Termin模糊熵
3.3.3语法信息的统一测度：一般信息函数
3.3.4全信息的测度
3.4小结与评注
参考文献
第4章知识理论
4.1知识的概念、分类与表示
4.1.1知识及其相关的基本概念
4.1.2知识的分类与表示
4.2知识的度量
4.2.1针对“知识生成”的知识测度
4.2.2针对“知识激活”的知识度量
4.3知识的生态学
4.3.1知识的内生态系统
4.3.2知识的外生态系统
4.4小结与评注
参考文献
第三篇高等人工智能的主体理论
第5章感知、注意与记忆：第一类信息转换原理
5.1高等人工智能的系统模型与机制主义方法
5.1.1高等人工智能的系统模型
5.1.2信息转换：高等人工智能系统的机制主义方法
5.2第一类信息转换原理及感知与注意的生成机制
5.2.1第一类信息转换原理：全信息的生成机理
5.2.2重要的副产品：脑科学与认知科学的“搭界”
5.2.3第一类信息转换原理的应用：感知注意的生成机理
5.3记忆系统的全信息机制
5.3.1记忆系统的全信息存储
5.3.2长期记忆系统的信息存储结构与提取方式
5.4小结与评注
参考文献
第6章意识、情感、理智与行为：第二类信息转换原理
6.1基础意识的生成机制：第二类A型信息转换原理
6.1.1意识的含义
6.1.2基础意识的生成机制
6.2情感的生成机制：第二类B型信息转换原理
6.2.1基本概念
6.2.2情感的分类
6.2.3情感生成的机制
6.3理智的生成机制：第二类C型信息转换原理
6.3.1理智的基本概念
6.3.2理智生成的机制
6.3.3综合决策
6.4策略执行的机制：第二类D型信息转换原理
6.4.1策略表示
6.4.2策略执行：从策略信息到策略行为的转换
6.5小结与评注
参考文献
第四篇高等人工智能与现行人工智能的关系
第7章物理符号系统：规范知识支持的机制主义方法
7.1形态性知识支持的智能生成方法
7.1.1一般模型
7.1.2控制策略
7.2内容性知识支持的机制主义方法
7.2.1谓词逻辑
7.2.2归谬推理
7.3价值性知识支持的机制主义方法
7.3.1启发式搜索
7.3.2博弈树搜索
7.3.3智能搜索与智能检索方法
7.4小结与评注
参考文献
第8章人工神经网络：经验知识支持的机制主义方法
8.1生物神经网络与人T神经网络
8.1.1人类智能与生物神经网络
8.1.2人工神经网络基础
8.2前向神经网络及其应用
8.2.1单层感知器
8.2.2多层感知器
8.3反馈神经网络
8.3.1Hopfield模型
8.3.2联想存储器：反馈型神经网络设计举例
8.4白组织神经网络
8.5小结与评注
参考文献
第9章感知一动作系统：常识知识支持的机制主义方法
9.1传感
9.2模式分类
9.2.1统计识别方法
9.2.2语言学方法
9.2.3神经网络方法
9.2.4关于“模式理解”的提要
9.3感知—动作系统
9.3.1感知—动作系统的总体原则
9.3.2几个典型的感知动作系统
9.3.3智能体：感知—动作系统的变种
9.4小结与评注
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>高等人工智能原理
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>不确定性推理原理
目录
前言
绪论
0－1 人工智能及其推理特征
0－2 常识推理的基本内容
0－3 不确定性推理原理与方法
0－4 本书的结构
第1章 测度与信息
1－1 经典集合与模糊集合
1－2 模糊测度及其性质
1－3 概率测度与贝叶斯公式
1－4 信任测度与似然测度
1－5 可能性测度与必然性测度
1－6 模糊测度各类之间的关系
1－7 不确定性度量与信息
第2章 包含度理论
2－1 包含度的定义及其性质
2－2 包含度的生成方法
2－3 相似度及其在专家系统检索中的应用
2－4 关系数据库系统及其性质
2－5 关系数据库上的知识获取
2－6 蕴含度及其在不确定性推理中的应用
2－7 专家系统中证据的合成、传播与修正
2－8 关系数据库的随机集表示
第3章 概率推理
3－1 概率推理原理
3－2 贝叶斯网络概率推理
3－3 主观贝叶斯概率推理
3－4 主观贝叶斯概率推理的讨论
3－5 主观概率推理的包含度方法
3－6 MYCIN确定因子概率推理方法
3－7 MYCIN确定因子的模糊扩张
3－8 概率推理的区间估计
第4章 证据推理
4－1 证据推理原理
4－2 关于证据推理的进一步讨论
4－3 证据推理模式
4－4 关系数据库上的证据推理
4－5 模糊关系数据库上的证据推理
4－6 随机关系数据库上的证据推理
4－7 基于随机集的证据推理
第5章 模糊推理
5－1 模糊推理原理
5－2 宏观模糊推理
5－3 微观模糊推理
5－4 Mamdani模糊推理
5－5 Lukasiewicz多值逻辑的模糊化
5－6 模糊真值推理
5－7 模糊推理的神经网络算法
5－8 模糊规则的谐调性与矛盾规则的排除
第6章 信息推理
6－1 信息推理原理
6－2 合情推理信息模型
6－3 概率命题的合情推理
6－4 关系数据库上的合情推理
6－5 假设生成与创新思维
6－6 默认推理的包含度解释
6－7 知识库的维护与修正
参考文献

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>不确定性推理原理
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据掘金
第1章 分析学入门
分析学与分析有区别吗
数据挖掘该归何处
分析学何以突然受到追捧
分析学的应用领域
分析学面临的主要挑战
分析学的发展历史
分析学的简单分类
分析学的前沿技术——以IBM Watson 为例
第2章 数据挖掘入门
数据挖掘是什么
哪些不属于数据挖掘
数据挖掘最常见的应用
数据挖掘能够发现怎样的规律
常用的数据挖掘工具
数据挖掘的负面影响：隐私问题
第3章 数据挖掘过程
数据库知识获取过程
跨行业标准化数据挖掘流程
SEMMA
数据挖掘六西格玛方法
哪种方法最好
第4章 数据与数据挖掘的方法
数据挖掘中的数据属性
数据挖掘中的数据预处理
数据挖掘方法
预测法
分类法
决策树
数据挖掘中的聚类分析
K 均值聚类算法
关联法
Apriori 算法
对数据挖掘的误解与事实
第5章 数据挖掘算法
近邻算法
评估相似性：距离度量
人工神经网络
支持向量机
线性回归
逻辑回归
时间序列预测
第6章 文本分析和情感分析
自然语言处理
文本挖掘应用
文本挖掘的流程
文本挖掘工具
情感分析
第7章 大数据分析学
大数据从何而来
定义“大数据”的V 们
大数据的关键概念
大数据分析处理的商业问题
大数据科技
数据科学家
大数据和流分析法
数据流挖掘
译者后记
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据掘金
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>生物信息学
1生物信息学：基因组到药物的桥梁3
11疾病的分子基础3
12疾病治疗的分子途径7
13寻找蛋白质靶点8
131基因组学与蛋白质组学10
132基因/蛋白质所能提供的信息10
14药物开发11
15生物信息学的概貌12
151生物信息学的内在属性14
16生物信息学的扩展属性16
161基本贡献：分子生物学数据库和基因组比较16
162应用之一：基因和蛋白质表达数据17
163应用之二：药物筛选18
164应用之三：遗传变异18
参考文献19
2序列分析20
21引言20
22序列分析21
221二级结构预测22
23双重序列比对24
231点阵作图法24
232序列比对25
24数据库检索 Ⅰ：单一序列的启发式算法28
25比对与相似性搜索的统计31
26多重序列比对33
27多重比对和数据库搜索35
28蛋白质家族和蛋白质结构域36
29结论37
参考文献37
3真核基因的结构、性质以及计算识别42
31真核基因的结构特点42
32哺乳类动物基因组中拼接位点的分类44
33识别功能信号的方法47
331搜寻保守序列的非随机的相似性47
332位点特异性识别器49
333内容特异性测定方法51
334基于框架特异性的蛋白编码区识别方法51
335精确性量度52
336线性辨识分析的应用52
337供体受体拼接位点的预测53
338人类DNA中启动子序列的识别56
339poly(A)位点的预测58
34基因识别方法61
35用于多基因预测的差异分析概率法61
351使用HMM的多基因预测方法62
352基于模式的多基因预测方法64
353基因识别程序的准确性67
354利用蛋白质或EST相似性信息来改进基因预测69
36基因组测序计划所产生序列的注释70
37InfoGene：已知基因和预测基因的数据库72
38预测的基因功能分析和确证74
39基因发现与功能位点预测的常用网址76
致谢76
参考文献77
4分析基因组中的调控区域82
41真核基因组中调控区域的主要特征82
42调控区域的主要功能82
421转录因子结合位点(TF位点)83
422序列特征83
423结构元件83
424调控区域的组织原则83
425用于分析和检查调控区域的生物信息学模型87
43元件检测的方法88
431转录因子结合位点的检测88
432结构元件的检测89
433其他元件的检测89
44调控区域的分析90
441训练集的选择90
442统计学和生物学显著性90
443上下文依赖性91
45调控区域的检测方法91
451调控区域的类型92
452调控序列的识别方法93
46大的基因组序列分析97
461灵敏度与特异性的平衡98
462长的上下文序列98
463比较基因组学的特征99
464基于高通量方法的数据集分析99
47结论99
参考文献100
5生物学和医学中的同源模建103
51引言103
511同源模建的概念103
512同源蛋白是如何产生的？104
513同源模建的目的105
514基因组计划的影响106
52数据输入107
53方法109
531在不同层次的复杂性上模建109
532环模建110
533侧链模建119
534完整模建的方法127
54结果129
541靶蛋白的范围129
542举例：淀粉状前体蛋白β分泌酶130
55优势和局限性134
56检验135
561侧链预测的精度135
562CASP会议136
563蛋白质健康度137
57可获得性139
58附录139
581骨架构象139
582侧链构象分析145
致谢149
参考文献149
6蛋白质结构预测163
61概述164
611术语的定义166
612本章所涉及的内容167
62数据169
621输入数据169
622输出数据169
623其他输入数据169
624结构比较和分类170
625评分函数和（经验）能量势172
63方法175
631二级结构预测175
632基于知识的三维结构预测177
64结果189
641远缘同源检测189
642结构基因组学189
643为结构基因组学选择靶标194
644基因组注释196
645序列到结构到功能的范式（Paradigm）196
65预测的验证197
651基准集（Benchmark set）测试197
652盲法预测实验（CASP）199
66结论：优势和局限性201
661线串法201
662优势202
663局限性202
67获取方式203
致谢203
参考文献204
7药物设计中的蛋白质配体对接216
71引言216
711对接的分类217
712基于结构的药物设计的应用218
72蛋白质配体对接的方法219
721刚性结构对接219
722柔性配体对接算法223
723模拟对接228
724组合库的对接231
725蛋白质配体复合物计分232
73验证与应用234
731X射线结构的再造234
732盲法预测验证235
733筛选小分子数据库235
734组合库的对接237
74实际中的分子对接237
741输入数据的准备237
742分析对接结果238
743选择正确的对接工具238
75总结239
76可获取的软件240
致谢240
参考文献240
8蛋白质蛋白质和蛋白质DNA对接的模建248
81引言248
811蛋白质蛋白质和蛋白质DNA对接的必要性248
812计算方法概述248
813本章的范围250
82蛋白复合物的结构研究250
83蛋白质蛋白质对接的方法251
831用傅里叶相关理论来进行刚性结构对接251
832用残基对势为对接复合物再排序256
833距离限制的使用258
834复合物的精细化和附加筛选258
835对接的实现260
84蛋白质蛋白质对接的结果261
85蛋白质DNA复合物的模建264
851方法264
852结果265
86蛋白质蛋白质对接方案267
861对接模拟结果的评估267
862傅里叶关联法268
863其他刚性对接方法268
864柔性蛋白质蛋白质对接270
865用刚性处理法对假定的对接复合物重排名270
866在假定的对接复合物重排名过程中引入柔性271
87蛋白质蛋白质对接的盲法实验271
88蛋白质对接的能量方面273
89结论274
致谢275
参考文献275
第2篇应用
9分子生物学资源的集成与获取281
91引言281
92分子生物学资源282
921数据库282
922应用程序286
923全球范围的数据库与应用程序286
93SRS概述287
931元定义层288
932SRS核心288
933包封程序288
934客户端程序288
94集成分子生物学资源289
941SRS标记服务器289
942分子生物学资源的元定义290
943索引数据库291
944查询与链接数据库291
945浏览器和对象加载器291
946应用程序——分析数据292
95SRS数据仓库292
96访问集成数据293
961网页界面293
962应用程序的界面（API）295
963其他界面296
97其他方法296
98总结297
参考文献297
10基因组测序计划的生物信息学支持298
101引言298
102方法302
1021相似读序对的快速鉴定303
1022低质末端区的去除305
1023重叠区的计算和评估306
1024叠连群的构建306
1025一致序列的构建308
103示例308
104其他拼装程序313
105结论315
致谢315
参考文献315
11序列差异性分析317
111引言317
112序列差异性317
113连锁分析318
114关联分析320
115为什么由遗传分析转移到单核苷酸多态性？321
116SNP的发现321
117基因型定型技术323
118在人类基因组中SNP是频繁出现的并且其组织结构很复杂325
119混合池策略（Pooling Strategies）327
1110结论327
参考文献328
12蛋白质组分析332
121引言和原理332
122蛋白质分离336
1221实验方面：一种实验操作技术——二维电泳技术的介绍336
1222应用二维电泳技术作为诊断学和疾病描述的工具337
123二维电泳图谱的计算机分析339
1231二维电泳分析软件341
124分离后蛋白质的验证和性质测定347
1241引言347
1242工具349
125蛋白质组数据库352
1251引言352
1252蛋白质序列数据库352
1253核酸序列数据库356
1254蛋白质家族、结构域及功能位点的数据库：InterPro357
1255二维电泳数据库357
1256翻译后修饰数据库358
1257结论359
126蛋白质组分析中的自动化359
1261引言359
1262应用肽质量指纹技术的机器化蛋白质鉴定360
1263分子扫描362
1264其他技术364
127结论365
参考文献366
13基因组和蛋白质组中靶标的搜寻369
131引言369
132大规模基因表达研究和药物靶点鉴定的实验设计369
133药物靶点发现中的计算分析372
1331Shannon 熵372
1332聚类374
1333分析方法联合应用于实验药物的开发377
1334如何选择这些方法378
1335未来展望：遗传网络的逆向工程378
1336基因组和蛋白质组380
134结论380
参考文献380
14数据库的筛选382
141引言382
142计算机虚拟筛选的方法384
1421基于配体相似性的虚拟筛选384
1422基于结构的虚拟筛选387
143虚拟筛选应用389
144第一个测试方案：快速相似性筛选算法的应用389
1441库生成389
1442计算细节391
1443筛选结果的讨论391
145第二个测试方案：对接作为一种虚拟筛选工具397
1451库生成398
1452对接程序398
1453对接结果讨论398
146总结和展望402
致谢403
参考文献403
15未来方向407
151基因组学和生物信息学的进展将如何改变我们对生物学
和医学的观点？407
152生物信息学将面临的主要挑战是什么？409
1521新的实验数据409
1522新的分析方法411
1523生物学上的整合观点413
153生物信息学的展望和内在局限性416
参考文献417
附录生物信息学中算法术语词表419
第2篇应用
第9章1
第2章药物开发过程27
本书适用于药物研究与开发领域，生物学、生物化学专业的研究人员，同时可供药学专业的高年级本科生和研究生参考。



>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>生物信息学
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言与数据挖掘
版权信息
前言
第一部分　基础篇
第1章　R语言的安装与使用
1.1　R安装与升级
1.2　R使用入门
1.3　R数据分析包
1.4　配套资源使用说明
1.5　小结
1.6　上机实验
第2章　数据对象与数据读写
2.1　数据类型
2.2　数据结构
2.3　数据文件的读写
2.4　小结
2.5　上机实验
第3章　R语言常用数据管理
3.1　变量的重命名
3.2　缺失值分析
3.3　数据排序
3.4　随机抽样
3.5　数值运算函数
3.6　字符串处理
3.7　文本分词
3.8　apply函数族
3.9　数据整合
3.10　控制流
3.11　函数的编写
3.12　小结
3.13　上机实验
第4章　图形探索
4.1　图形元素
4.2　图形组合
4.3　图形保存
4.4　图形函数
4.5　小结
4.6　上机实验
第5章　高级绘图工具
5.1　lattice包绘图工具
5.2　ggplot2包绘图工具
5.3　交互式绘图工具简介
5.4　小结
5.5　上机实验
第二部分　建模应用篇
第6章　分类与预测
6.1　回归分析
6.2　决策树
6.3　人工神经网络
6.4　KNN算法
6.5　朴素贝叶斯分类
6.6　其他分类与预测算法函数
6.7　分类与预测算法评价
6.8　小结
6.9　上机实验
第7章　聚类分析
7.1　K-Means聚类分析函数
7.2　层次聚类算法
7.3　其他聚类分析函数
7.4　小结
7.5　上机实验
第8章　关联规则
8.1　Apriori关联规则
8.2　小结
8.3　上机实验
第9章　智能推荐
9.1　智能推荐模型构建
9.2　智能推荐模型评价
9.3　小结
9.4　上机实验
第10章　时间序列
10.1　ARIMA模型
10.2　其他时间序列模型
10.3　小结
10.4　上机实验
第三部分　Rattle篇
第11章　可视化数据挖掘工具Rattle
11.1　Rattle简介及其安装
11.2　功能预览
11.3　数据导入
11.4　数据探索
11.5　数据建模
11.6　模型评估
11.7　小结
11.8　上机实验
参考资料
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>R语言与数据挖掘
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python自然语言处理
译者序
推荐序
作者介绍
关于审校人员
前言
第1章 引言 1
1.1 自然语言处理 1
1.2 基础应用 5
1.3 高级应用 6
1.4 NLP和Python相结合的优势 7
1.5 nltk环境搭建 7
1.6 读者提示 8
1.7 总结 9
第2章 实践理解语料库和数据集 10
2.1 语料库 10
2.2 语料库的作用 11
2.3 语料分析 13
2.4 数据属性的类型 16
2.4.1 分类或定性数据属性 16
2.4.2 数值或定量数据属性 17
2.5 不同文件格式的语料 18
2.6 免费语料库资源 19
2.7 为NLP应用准备数据集 20
2.7.1 挑选数据 20
2.7.2 预处理数据集 20
2.8 网页爬取 21
2.9 总结 23
第3章 理解句子的结构 24
3.1 理解NLP的组成 24
3.1.1 自然语言理解 24
3.1.2 自然语言生成 25
3.1.3 NLU和NLG的区别 25
3.1.4 NLP的分支 26
3.2 上下文无关文法 26
3.3 形态分析 28
3.3.1 形态学 28
3.3.2 词素 28
3.3.3 词干 28
3.3.4 形态分析 28
3.3.5 词 29
3.3.6 词素的分类 29
3.3.7 词干和词根的区别 32
3.4 词法分析 32
3.4.1 词条 33
3.4.2 词性标注 33
3.4.3 导出词条的过程 33
3.4.4 词干提取和词形还原的区别 34
3.4.5 应用 34
3.5 句法分析 34
3.6 语义分析 36
3.6.1 语义分析概念 36
3.6.2 词级别的语义 37
3.6.3 上下位关系和多义词 37
3.6.4 语义分析的应用 38
3.7 消歧 38
3.7.1 词法歧义 38
3.7.2 句法歧义 39
3.7.3 语义歧义 39
3.7.4 语用歧义 39
3.8 篇章整合 40
3.9 语用分析 40
3.10 总结 40
第4章 预处理 42
4.1 处理原始语料库文本 42
4.1.1 获取原始文本 42
4.1.2 小写化转换 44
4.1.3 分句 44
4.1.4 原始文本词干提取 46
4.1.5 原始文本词形还原 46
4.1.6 停用词去除 48
4.2 处理原始语料库句子 50
4.2.1 词条化 50
4.2.2 单词词形还原 51
4.3 基础预处理 52
4.4 实践和个性化预处理 57
4.4.1 由你自己决定 57
4.4.2 预处理流程 57
4.4.3 预处理的类型 57
4.4.4 理解预处理的案例 57
4.5 总结 62
第5章 特征工程和NLP算法 63
5.1 理解特征工程 64
5.1.1 特征工程的定义 64
5.1.2 特征工程的目的 64
5.1.3 一些挑战 65
5.2 NLP中的基础特征 65
5.2.1 句法分析和句法分析器 65
5.2.2 词性标注和词性标注器 81
5.2.3 命名实体识别 85
5.2.4 n元语法 88
5.2.5 词袋 89
5.2.6 语义工具及资源 91
5.3 NLP中的基础统计特征 91
5.3.1 数学基础 92
5.3.2 TF-IDF 96
5.3.3 向量化 99
5.3.4 规范化 100
5.3.5 概率模型 101
5.3.6 索引 103
5.3.7 排序 103
5.4 特征工程的优点 104
5.5 特征工程面临的挑战 104
5.6 总结 104
第6章 高级特征工程和NLP算法 106
6.1 词嵌入 106
6.2 word2vec基础 106
6.2.1 分布语义 107
6.2.2 定义word2vec 108
6.2.3 无监督分布语义模型中的必需品 108
6.3 word2vec模型从黑盒到白盒 109
6.4 基于表示的分布相似度 110
6.5 word2vec模型的组成部分 111
6.5.1 word2vec的输入 111
6.5.2 word2vec的输出 111
6.5.3 word2vec模型的构建模块 111
6.6 word2vec模型的逻辑 113
6.6.1 词汇表构建器 114
6.6.2 上下文环境构建器 114
6.6.3 两层的神经网络 116
6.6.4 算法的主要流程 119
6.7 word2vec模型背后的算法和数学理论 120
6.7.1 word2vec算法中的基本数学理论 120
6.7.2 词汇表构建阶段用到的技术 121
6.7.3 上下文环境构建过程中使用的技术 122
6.8 神经网络算法 123
6.8.1 基本神经元结构 123
6.8.2 训练一个简单的神经元 124
6.8.3 单个神经元的应用 126
6.8.4 多层神经网络 127
6.8.5 反向传播算法 127
6.8.6 word2vec背后的数学理论 128
6.9 生成最终词向量和概率预测结果的技术 130
6.10 word2vec相关的一些事情 131
6.11 word2vec的应用 131
6.11.1 实现一些简单例子 132
6.11.2 word2vec的优势 133
6.11.3 word2vec的挑战 133
6.11.4 在实际应用中使用word2vec 134
6.11.5 何时使用word2vec 135
6.11.6 开发一些有意思的东西 135
6.11.7 练习 138
6.12 word2vec概念的扩展 138
6.12.1 para2vec 139
6.12.2 doc2vec 139
6.12.3 doc2vec的应用 140
6.12.4 GloVe 140
6.12.5 练习 141
6.13 深度学习中向量化的重要性 141
6.14 总结 142
第7章 规则式自然语言处理系统 143
7.1 规则式系统 144
7.2 规则式系统的目的 146
7.2.1 为何需要规则式系统 146
7.2.2 使用规则式系统的应用 147
7.2.3 练习 147
7.2.4 开发规则式系统需要的资源 147
7.3 规则式系统的架构 148
7.3.1 从专家系统的角度来看规则式系统的通用架构 149
7.3.2 NLP应用中的规则式系统的实用架构 150
7.3.3 NLP应用中的规则式系统的定制架构 152
7.3.4 练习 155
7.3.5 Apache UIMA架构 155
7.4 规则式系统的开发周期 156
7.5 规则式系统的应用 156
7.5.1 使用规则式系统的NLP应用 156
7.5.2 使用规则式系统的通用AI应用 157
7.6 使用规则式系统来开发NLP应用 157
7.6.1 编写规则的思维过程 158
7.6.2 基于模板的聊天机器人应用 165
7.7 规则式系统与其他方法的对比 168
7.8 规则式系统的优点 169
7.9 规则式系统的缺点 169
7.10 规则式系统面临的挑战 170
7.11 词义消歧的基础 170
7.12 规则式系统近期发展的趋势 171
7.13 总结 171
第8章 自然语言处理中的机器学习方法 172
8.1 机器学习的基本概念 172
8.2 自然语言处理应用的开发步骤 176
8.2.1 第一次迭代时的开发步骤 177
8.2.2 从第二次到第N次迭代的开发步骤 177
8.3 机器学习算法和其他概念 179
8.3.1 有监督机器学习方法 179
8.3.2 无监督机器学习方法 206
8.3.3 半监督机器学习算法 210
8.3.4 一些重要概念 211
8.3.5 特征选择 215
8.3.6 维度约减 219
8.4 自然语言处理中的混合方法 221
8.5 总结 221
第9章 NLU和NLG问题中的深度学习 223
9.1 人工智能概览 223
9.1.1 人工智能的基础 223
9.1.2 人工智能的阶段 225
9.1.3 人工智能的种类 227
9.1.4 人工智能的目标和应用 227
9.2 NLU和NLG之间的区别 232
9.2.1 自然语言理解 232
9.2.2 自然语言生成 232
9.3 深度学习概览 233
9.4 神经网络基础 234
9.4.1 神经元的第一个计算模型 235
9.4.2 感知机 236
9.4.3 理解人工神经网络中的数学概念 236
9.5 实现神经网络 249
9.5.1 单层反向传播神经网络 249
9.5.2 练习 251
9.6 深度学习和深度神经网络 251
9.6.1 回顾深度学习 251
9.6.2 深度神经网络的基本架构 251
9.6.3 NLP中的深度学习 252
9.6.4 传统NLP和深度学习NLP技术的区别 253
9.7 深度学习技术和NLU 255
9.8 深度学习技术和NLG 262
9.8.1 练习 262
9.8.2 菜谱摘要和标题生成 262
9.9 基于梯度下降的优化 265
9.10 人工智能与人类智能 269
9.11 总结 269
第10章 高级工具 270
10.1 使用Apache Hadoop作为存储框架 270
10.2 使用Apache Spark作为数据处理框架 272
10.3 使用Apache Flink作为数据实时处理框架 274
10.4 Python中的可视化类库 274
10.5 总结 275
第11章 如何提高你的NLP技能 276
11.1 开始新的NLP职业生涯 276
11.2 备忘列表 277
11.3 确定你的领域 277
11.4 通过敏捷的工作来实现成功 278
11.5 NLP和数据科学方面一些有用的博客 278
11.6 使用公开的数据集 278
11.7 数据科学领域需要的数学知识 278
11.8 总结 279
第12章 安装指导 280
12.1 安装Python、pip和NLTK 280
12.2 安装PyCharm开发环境 280
12.3 安装依赖库 280
12.4 框架安装指导 281
12.5 解决你的疑问 281
12.6 总结 281
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python自然语言处理
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>不确定性人工智能
第1章面向不确定性的人工智能
1.1人类智能的不确定性
1.1.1不确定性的魅力
1.1.2熵的世界
1.2人工智能50年
1.2.1从著名的达特茅斯会议谈起
1.2.2与时俱进的研究目标
1.2.3人工智能50年主要成就
1.3人工智能研究的主要方法
1.3.1符号主义方法
1.3.2联结主义方法
1.3.3行为主义方法
1.4人工智能的学科大交叉趋势
1.4.1脑科学与人工智能
1.4.2认知科学与人工智能
1.4.3网络科学与人工智能
1.4.4学科交叉孕育人工智能大突破
第2章定性定量转换的认知模型——云模型
2.1不确定性人工智能研究的切入点
2.1.1人类智能研究的多个切入点
2.1.2抓住自然语言中的概念不放
2.1.3概念中的随机性和模糊性
2.2用云模型表示概念的不确定性
2.2.1云和云滴
2.2.2云的数字特征
2.2.3云模型的种类
2.3正向高斯云算法
2.3.1算法描述
2.3.2云滴对概念的贡献
2.3.3用高斯云理解农历节气
2.4高斯云的数学性质
2.4.1云滴分布的统计分析
2.4.2云滴确定度分布的统计分析
2.4.3高斯云的期望曲线
2.4.4从云到雾
2.5逆向高斯云算法
2.5.1算法描述
2.5.2逆向高斯云的参数估计与误差分析
2.6进一步理解云模型
2.6.1射击评判
2.6.2带有不确定性的分形
2.7高斯云的普适性
2.7.1高斯分布的普适性
2.7.2钟形隶属函数的普遍性
2.7.3高斯云的普遍意义
第3章云变换
3.1粒计算中的基本术语
3.1.1尺度、层次和粒度
3.1.2概念树和泛概念树
3.2高斯变换
3.2.1高斯变换参数估计
3.2.2高斯变换算法
3.3高斯云变换
3.3.1从高斯变换到高斯云变换
3.3.2启发式高斯云变换
3.3.3自适应高斯云变换
3.3.4多维高斯云变换
3.4高斯云变换用于图像分割
3.4.1图像中的过渡区发现
3.4.2图像中差异性目标提取
第4章数据场与拓扑势
4.1数据场
4.1.1用场描述数据对象间的相互作用
4.1.2从物理场到数据场
4.1.3数据的势场和力场
4.1.4场函数中影响因子的选取
4.2基于数据场的聚类
4.2.1分类与聚类中的不确定性
4.2.2用数据场实现动态聚类
4.2.3用数据场实现人脸图像的表情聚类
4.3基于拓扑势的复杂网络研究
4.3.1从数据场到拓扑势
4.3.2用拓扑势发现网络中重要节点
4.3.3用拓扑势发现网络社区
4.3.4用拓扑势发现维基百科中的热词条
第5章云推理与云控制
5.1云推理
5.1.1云模型构造定性规则
5.1.2规则集生成
5.2云控制
5.2.1云控制的机理
5.2.2云控制对模糊控制的理论解释
5.3倒立摆中的不确定性控制
5.3.1倒立摆及其控制
5.3.2一级、二级倒立摆的定性控制机理
5.3.3三级倒立摆的云控制策略
5.3.4倒立摆的动平衡模式
5.4智能驾驶中的不确定性控制
5.4.1汽车的智能驾驶
5.4.2基于智能车辆的驾驶行为模拟
第6章用认知物理学方法研究群体智能
6.1相互作用是群体智能的重要成因
6.1.1群体智能
6.1.2涌现是群体行为的一种表现形态
6.2云模型和数据场在群体智能研究中的应用
6.2.1用云模型表示个体行为的离散性
6.2.2用数据场描述个体间的相互作用
6.3典型案例：“掌声响起来”
6.3.1用云模型表示人的鼓掌行为
6.3.2用数据场反映掌声的相互传播
6.3.3“掌声响起来”的计算模型
6.3.4实验平台
6.3.5涌现的多样性分析
6.3.6带引导的掌声同步
第7章云计算推动不确定性人工智能大发展
7.1从云模型看模糊集合的贡献与局限
7.1.1模糊逻辑似是而非的争论
7.1.2模糊性对随机性的依赖性
7.1.3从模糊推理到不确定性推理
7.2从图灵计算到云计算
7.2.1超出图灵机的云计算
7.2.2云计算与云模型
7.2.3游走在高斯和幂律分布之间的云模型
7.3大数据呼唤不确定性人工智能
7.3.1从数据库到大数据
7.3.2网络交互和群体智能
7.4不确定性人工智能展望
参考文献
基金资助目录
相关专利
索引
再版后记
附录不确定性人工智能理论与应用学术沙龙——对话实录
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>不确定性人工智能
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow学习指南
前言1
第1章 引言5
1.1 走入深度学习5
1.2 TensorFlow：名字中的含义8
1.3 高层次概览9
1.4 本章总结11
第2章 随之“流”动：启动与运行TensorFlow12
2.1 安装TensorFlow12
2.2 Hello World14
2.3 MNIST16
2.4 softmax回归17
2.5 本章总结24
第3章 理解TensorFlow基础知识25
3.1 计算图25
3.2 图、会话和提取数据26
3.3 流动的张量32
3.4 变量、占位符和简单的优化41
3.5 本章总结52
第4章 卷积神经网络53
4.1 卷积神经网络简介53
4.2 MNIST：第二轮55
4.3 CIFAR1063
4.4 本章总结71
第5章 文本I：文本及序列的处理，以及TensorBoard可视化72
5.1 序列数据的重要性72
5.2 循环神经网络简介73
5.3 处理RNN的文本序列87
5.4 本章总结97
第6章 文本II：词向量、高级RNN和词嵌入可视化99
6.1 词嵌入介绍99
6.2 word2vec101
6.3 预训练词嵌入，高级RNN110
6.4 本章总结116
第7章 TensorFlow抽象与简化117
7.1 本章概述117
7.2 contrib.learn121
7.3 TFLearn136
7.4 本章总结156
第8章 队列、线程和数据读取158
8.1 输入管道158
8.2 TFRecord159
8.3 队列162
8.4 完全多线程的输入管道168
8.5 本章总结172
第9章 分布式 TensorFlow173
9.1 分布式计算173
9.2 TensorFlow 元素175
9.3 分布式示例180
9.4 本章总结187
第10章 用TensorFlow导出和提供服务模型188
10.1 保存和导出模型188
10.2 TensorFlow Serving简介199
10.3 本章总结209
附录A 模型构建和使用TensorFlow Serving的建议210
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow学习指南
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>非参数支持向量回归和分类理论及其在金融市场预测中的应用
第一章　预测概述
第一节　预测的重要性
第二节　什么是预测?
第三节　预测方法的发展
第四节　预测与决策
第二章　支持向量回归和分粪理论
第一节　支持向量算法
第二节　支持向量回归
第三节　支持向量分类
第四节　蒙特卡罗仿真
附录
第三章　汇率预测：基于前馈SVR的非线性ARl模型
第一节　介绍
第二节　数据收集和处理
第三节　实证模型设定
第四节　预测方案和评估标准
第五节　预测结果比较分析
第六节　人民币汇率预测
第七节　结论
第四章　金融收益率水平预测：基于反馈SVR的非线性ARIMA模型
第一节　介绍
第二节　反馈SVR机制设计
第三节　金融收益率定义
第四节　固定预铡评估
第五节　递归预测评估
第六节 中国证券指数和汇率收益率水平预测
第七节　结论
第五章　金融收益率波动性预测：基于反馈SVR的非线性GARCH模型
第一节　介绍
第二节　实证模型和预测方案
第三节　蒙特卡罗仿真
第四节　真实数据检验
第五节 中国金融波动性预测案例
第六节　结论
第六章　公司信用风险预测：基于SVC的非线性概率模型
第一节　介绍
第二节　数据描述和处理
第三节　预测分析框架
第四节　实证分析
第五节　CAPM检验案例
第六节　结论
第七章　结束语
词汇表
后记
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>非参数支持向量回归和分类理论及其在金融市场预测中的应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>随机过程
第三版说明
第二版说明
第一版前言
第1章 引论
1.1引言
1.1.1基本概念和例子
1.1.2有限维分布和数字特征
1.1.3平稳过程和独立增量过程
1.2条件期望和矩母函数
1.2.1条件期望
1.2.2矩母函数及生成函数
1.3收敛性
习题1
第2章Poisson过程
2.1 Poisson过程
2.2与Poisson过程相联系的若干分布
2.3 Poisson过程的推广
2.3.1非齐次Poisson过程
2.3.2复合Poisson过程
2.3.3标值（Marked）Poisson过程
2.3.4空间Poisson过程
2.3.5更新过程
习题2
第3章Markov过程
3.1 Markov链的定义和例子
3.2 Markov链的状态分类
3.2.1互达性和周期性
3.2.2常返（recurrent）与瞬过（transient）
3.3 Markov链的极限定理与平稳分布
3.4分支过程
3.5连续时间Markov链
3.5.1连续时间Markov链
3.5.2纯生过程
3.6生灭过程
3.6.1生灭过程（birth and death process）
3.6.2 Kolmogorov向后向前微分方程
习题3
第4章平稳过程
4.1定义和例子
4.2遍历性定理
4.3平稳过程的协方差函数和功率谱密度
4.3.1协方差函数
4.3.2几个常见随机信号的协方差函数
4.3.3功率谱密度
4.4平稳序列的预报
4.4.1一般预报理论
4.4.2平稳序列的预报
习题4
第5章Brown运动
5.1定义
5.2 Brown运动的性质
5.3随机积分和随机微分方程
5.3.1积分
5.3.2微分
5.3.3关于Brown运动的积分
5.3.4常系数线性随机微分方程
5.3.5 n阶常系数线性随机微分方程
5.4 It6微分公式和～般随机微分方程
5.4.1 It6微分公式
5.4.2一般随机微分方程简介
5.5 Brown运动的其他一些应用
习题5
第6章鞅过程及其性质
6.1条件期望及其性质
6.2鞅和鞅差过程的定义和例子
6.3鞅和鞅差的性质
6.3.1鞅的性质
6.3.2鞅差的性质
6.4下（上）鞅及其初等性质
6.5连续时间下的鞅过程和下鞅过程
6.6停时
习题6
参考文献
附录A
附录B
附表
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>随机过程
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>半监督学习
目录
第1章绪论
1.1研究背景和意义
1.2国内外研究现状
1.3研究内容和方法
参考文献
第2章生成模型
2.1贝叶斯决策理论
2.2密度函数参数估计
2.3半监督混合模型
2.4半监督混合模型的应用和优缺点分析
参考文献
第3章协同训练算法
3.1视图
3.2协同训练
3.3协同训练相关理论
3.4多视协同训练方法
3.5协同训练方法的应用和优缺点分析
参考文献
第4章基于图的半监督学习方法
4.1图
4.2标记传递算法
4.3最小切
4.4调和函数
4.5流形正则化框架
4.6基于图的半监督学习方法的应用以及优缺点分析
参考文献
第5章半监督支持向量机
5.1支持向量机简介
5.2半监督支持向量机简介
5.3半监督支持向量机的求解
5.4半监督支持向量机的应用以及优缺点分析
参考文献
第6章哈希图半监督学习方法及其在图像分割中的应用
6.1基于图的半监督学习方法在图像分割中的应用
6.2哈希图半监督学习方法及其在图像分割中的应用
6.3本章小结
参考文献
第7章归一化图半监督学习方法及其在个人信用评估中的应用
7.1不均衡问题对图半监督学习方法的影响
7.2归一化图半监督学习方法
7.3基于归一化图半监督学习的个人信用评估方法
7.4本章小结
参考文献
第8章多标记半监督学习方法
8.1多标记半监督学习方法提出背景
8.2希尔伯特一施密特独立性度量
8.3最大化依赖性多标记半监督学习方法
8.4正则依赖性多标记半监督学习方法
8.5实验
8.6本章小结
参考文献
第9章正例半监督学习方法及其在图像分割中的应用
9.1正例半监督学习的定义
9.2正例半监督学习的应用
9.3正例半监督学习的相关理论基础
9.4朴素贝叶斯一期望最大化正例半监督学习方法
9.5正例图半监督学习图像分割方法
参考文献
第10章总结与展望
10.1工作总结
10.2展望
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>半监督学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据搜索与挖掘
《信息科学技术学术著作丛书》序
序
前言
第1章绪论
1.1大数据
1.2云计算及Hadoop简介
1.3Web搜索、全文索引与Lucene简介
1.3.1Web搜索
1.3.2全文索引
1.3.3Lucene简介
1.4大数据挖掘
1.5本书主要内容及其知识点
1.6本章小结
参考文献
第2章大数据搜索挖掘综述
2.1常用的信息检索模型
2.1.1传统布尔检索与扩展布尔检索模型
2.1.2向量空间模型
2.1.3概率检索模型
2.1.4语言模型
2.2自然语言理解与处理概述
2.3中文词法分析中的分词处理
2.3.1基于词典和规则的汉字分词
2.3.2基于大规模语料库的统计学习的分词方法
2.3.3规则和统计方法相结合的汉字分词方法
2.4未登录词及其识别
2.4.1命名实体及其识别
2.4.2未登录词与新词识别
2.5有意义串及其识别
2.6词典组织与管理
2.6.1基于Trie索引树的词典管理
2.6.2基于哈希表的词典管理
2.7文本分类
2.8文本聚类
2.8.1文本表示
2.8.2相似度度量
2.8.3聚类算法体系
2.9话题识别与跟踪
2.10句子及其检索
2.10.1传统的文档检索方法
2.10.2信息过滤方法
2.10.3分类方法
2.10.4语义比较方法
2.10.5隐马尔可夫模型方法
2.10.6自动文摘方法
2.11句子级新信息检测
2.11.1词重叠度
2.11.2最大区间相关度
2.11.3余弦冗余度
2.11.4命名实体触发方法
2.11.5统计机器翻译模型
2.11.6LexRank方法
2.12本章小结
参考文献
第3章大数据检索与分词
3.1概述
3.2分词对中文信息检索的影响
3.3分词精度与检索性能的关系
3.4大数据应用环境下中文信息检索的分词算法及其特点
3.4.1分词算法的时间性能要求高
3.4.2分词正确率的提高并不一定带来检索性能的提高
3.4.3分词切分粒度需在查询扩展层面进行相关处理
3.4.4未登录词识别的准确率要比召回率更重要
3.5基于双数组Trie树优化算法的词典
3.5.1双数组Trie树算法介绍及其优化
3.5.2利用优化的双数组Trie树算法组织词典
3.5.3实验结果与分析
3.6本章小结
参考文献
第4章基于层次隐马尔可夫模型的浅层词法分析
4.1概述
4.2英文浅层分析的实现
4.2.1英文断句与词汇切分
4.2.2词性标注
4.2.3词干抽取与词形还原。
4.3停用词处理与特征词选择
4.3.1停用词处理
4.3.2特征词选择
4.4基于层次隐马尔可夫模型的汉语浅层分析及其应用
4.4.1层次隐马尔可夫模型
4.4.2基于类的隐马尔可夫分词算法
4.4.3N最短路径的切分排歧策略
4.4.4未登录词的隐马尔可夫识别方法
4.5汉语词法分析系统ICTCLAS性能实验与分析
4.5.1词法分析与层次隐马尔可夫模型
4.5.2ICTCLAS在973评测中的测试结果
4.5.3第一届国际分词大赛的评测结果
4.6基于单字位置成词概率识别未登录词的算法
4.6.1字的位置成词概率
4.6.2局部二元串频统计
4.6.3有关未登录词识别的实验结果
4.7本章小结
参考文献
第5章大数据语言新特征发现
5.1概述
5.2基于上下文邻接分析和语言模型的有意义串提取
5.2.1上下文邻接分析
5.2.2语言模型分析
5.2.3重复串发现及处理流程
5.2.4实验设计及结果分析
5.3基于局部性原理的低频有意义串提取
5.3.1有意义串的局部性
5.3.2局部性度量
5.3.3算法流程
5.3.4实验结果与分析
5.4基于伪相关反馈模型的有意义串提取
5.4.1算法的基本思想
5.4.2相关度的定义
5.4.3位置成词概率PWP的更新
5.4.4算法流程
5.4.5实验结果及分析
5.5本章小结
参考文献
第6章大数据聚类与分类
6.1概述
6.2基于关键词提取的搜索结果聚类
6.2.1相关术语简介
6.2.2关键词提取
6.2.3基于关键词的检索结果聚类方法
6.2.4实验结果及分析
6.3基于K—means算法的有意义串主题聚类算法
6.4基于邻接串种类的有意义串语境聚类
6.5有意义串对分类的改进
6.6本章小结
参考文献
……
第7章大数据文本自动摘要
第8章JZSearch大数据精准搜索引擎
第9章面向大数据的句子检索与新颖性监测
第10章人物追踪中的数据预处理与属性抽取
第11章人物模型组织与基于事件的信息处理
附录AICTCLAS/NLPIR2014汉语分词系统介绍
附录BNLPIR大数据搜索与挖掘共享开发平台
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>大数据搜索与挖掘
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>舆情信息分析与处理技术
前言
第1章  绪论
1.1  概述
1.1.1  网络舆情的概念
1.1.2  网络舆情的特点
1.1.3  微博舆情的特点
1.1.4  网络舆情的发展阶段
1.1.5  网络舆情的传播规律
1.2  国内外研究现状
1.2.1  舆情传播网络结构和模型研究
1.2.2  舆情传播的理论模型和一般规律
1.2.3  网络舆情监测的相关关键技术
1.3  舆情信息分析系统
1.3.1  系统背景
1.3.2  系统概述
1.3.3  系统架构
1.3.4  功能描述
1.4  内容和章节安排
参考文献
第2章  舆情信息的收集
2.1  概述
2.2  网页的结构
2.2.1  HTML中的标记符
2.2.2  DOM树
2.3  网页的爬取
2.3.1  爬虫的基本原理
2.3.2  链接URL的选择
2.3.3  爬虫遵循的规则
2.3.4  网页更新
2.3.5  多线程爬取
2.3.6  分布式策略
2.3.7  动态网页的爬取
2.4  网页信息的提取
2.4.1  信息提取与信息检索的区别
2.4.2  信息提取方法
2.4.3  信息提取的评价标准
2.5  基于模板的舆情信息提取系统
2.5.1  主要信息源
2.5.2  网页爬虫模块
2.5.3  网页信息提取模块
2.5.4  网页信息自动提取方案
2.6  系统设计
2.7  本章小结
参考文献
第3章  舆情信息的内容分析
3.1  概述
3.2  信息预处理
3.2.1  分词处理
3.2.2  向量空间模型
3.2.3  特征降维
3.3  舆情信息内容识别
3.3.1  舆情内容特征库构建
3.3.2  舆情文本分类
3.3.3  舆情文本聚类
3.3.4  舆情内容识别评测
3.4  舆情话题发现
3.4.1  热点分析
3.4.2  话题发现
3.4.3  话题跟踪
3.5  舆情情感分析
3.5.1  情感建模
3.5.2  情感词库的建立
3.5.3  情感分析方法
3.6  舆情观点挖掘
3.6.1  观点规则库构建
3.6.2  观点分类和聚类
3.6.3  观点倾向性分析
3.7  系统设计
3.8  本章小结
参考文献
第4章  舆情信息结构分析
4.1  舆情网络的构建
4.2  舆情网络分析基础
4.2.1  节点扩散能力
4.2.2  整体扩散能力
4.2.3  聚集性
4.2.4  关键节点
4.3  舆情网络的社区结构分析
4.3.1  社区发现与话题识别
4.3.2  常见的社区发现方法
4.3.3  基于节点扩展的社区发现
4.3.4  基于节点合并的社区发现
4.4  舆情网络的演化
4.4.1  网络扩散能力演化
4.4.2  网络社区结构演化
4.5  舆情网络的行为分析
4.5.1  舆情的定义与分级
4.5.2  行为分析
4.5.3  网络行为分析的具体步骤
4.5.4  舆情网络行为分析实例
4.6  本章小结
参考文献
第5章  舆情的传播与控制
5.1  舆情传播模型
5.1.1  三种基本的传播模型
5.1.2  考虑人类活动时间特性的传播模型
5.1.3  考虑人类活动空间模式的传播模型
5.2  舆情传播的影响因素
5.2.1  初始信息源的影响
5.2.2  混合中心性指标下初始节点对传播的影响
5.2.3  网络结构的影响
5.3  舆情趋势预测
5.3.1  预测模型
5.3.2  模型库建立与预测
5.3.3  实验结果及分析
5.4  舆情控制策略
5.4.1  概述
5.4.2  随机免疫
5.4.3  关键节点免疫策略
5.4.4  关键链路免疫策略
5.4.5  其他免疫策略
5.4.6  舆情控制实例
5.5  本章小结
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>舆情信息分析与处理技术
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>ゼロから作るDeep Learning
目次
まえがき
1章　Python入門
1.1　Pythonとは
1.2　Pythonのインストール
1.2.1　Pythonのバージョン
1.2.2　使用する外部ライブラリ
1.2.3　Anacondaディストリビューション
1.3　Pythonインタプリタ
1.3.1　算術計算
1.3.2　データ型
1.3.3　変数
1.3.4　リスト
1.3.5　ディクショナリ
1.3.6　ブーリアン
1.3.7　if文
1.3.8　for文
1.3.9　関数
1.4　Pythonスクリプトファイル
1.4.1　ファイルに保存
1.4.2　クラス
1.5　NumPy
1.5.1　NumPyのインポート
1.5.2　NumPy配列の生成
1.5.3　NumPyの算術計算
1.5.4　NumPyのN次元配列
1.5.5　ブロードキャスト
1.5.6　要素へのアクセス
1.6　Matplotlib
1.6.1　単純なグラフの描画
1.6.2　pyplotの機能
1.6.3　画像の表示
1.7　まとめ
2章　パーセプトロン
2.1　パーセプトロンとは
2.2　単純な論理回路
2.2.1　ANDゲート
2.2.2　NANDゲートとORゲート
2.3　パーセプトロンの実装
2.3.1　簡単な実装
2.3.2　重みとバイアスの導入
2.3.3　重みとバイアスによる実装
2.4　パーセプトロンの限界
2.4.1　XORゲート
2.4.2　線形と非線形
2.5　多層パーセプトロン
2.5.1　既存ゲートの組み合わせ
2.5.2　XORゲートの実装
2.6　NANDからコンピュータへ
2.7　まとめ
3章　ニューラルネットワーク
3.1　パーセプトロンからニューラルネットワークへ
3.1.1　ニューラルネットワークの例
3.1.2　パーセプトロンの復習
3.1.3　活性化関数の登場
3.2　活性化関数
3.2.1　シグモイド関数
3.2.2　ステップ関数の実装
3.2.3　ステップ関数のグラフ
3.2.4　シグモイド関数の実装
3.2.5　シグモイド関数とステップ関数の比較
3.2.6　非線形関数
3.2.7　ReLU関数
3.3　多次元配列の計算
3.3.1　多次元配列
3.3.2　行列の内積
3.3.3　ニューラルネットワークの内積
3.4　3層ニューラルネットワークの実装
3.4.1　記号の確認
3.4.2　各層における信号伝達の実装
3.4.3　実装のまとめ
3.5　出力層の設計
3.5.1　恒等関数とソフトマックス関数
3.5.2　ソフトマックス関数の実装上の注意
3.5.3　ソフトマックス関数の特徴
3.5.4　出力層のニューロンの数
3.6　手書き数字認識
3.6.1　MNISTデータセット
3.6.2　ニューラルネットワークの推論処理
3.6.3　バッチ処理
3.7　まとめ
4章　ニューラルネットワークの学習
4.1　データから学習する
4.1.1　データ駆動
4.1.2　訓練データとテストデータ
4.2　損失関数
4.2.1　2乗和誤差
4.2.2　交差エントロピー誤差
4.2.3　ミニバッチ学習
4.2.4　［バッチ対応版］交差エントロピー誤差の実装
4.2.5　なぜ損失関数を設定するのか？
4.3　数値微分
4.3.1　微分
4.3.2　数値微分の例
4.3.3　偏微分
4.4　勾配
4.4.1　勾配法
4.4.2　ニューラルネットワークに対する勾配
4.5　学習アルゴリズムの実装
4.5.1　2層ニューラルネットワークのクラス
4.5.2　ミニバッチ学習の実装
4.5.3　テストデータで評価
4.6　まとめ
5章　誤差逆伝播法
5.1　計算グラフ
5.1.1　計算グラフで解く
5.1.2　局所的な計算
5.1.3　なぜ計算グラフで解くのか？
5.2　連鎖率
5.2.1　計算グラフの逆伝播
5.2.2　連鎖率とは
5.2.3　連鎖率と計算グラフ
5.3　逆伝播
5.3.1　加算ノードの逆伝播
5.3.2　乗算ノードの逆伝播
5.3.3　リンゴの例
5.4　単純なレイヤの実装
5.4.1　乗算レイヤの実装
5.4.2　加算レイヤの実装
5.5　活性化関数レイヤの実装
5.5.1　ReLUレイヤ
5.5.2　Sigmoidレイヤ
5.6　A.ne／Softmaxレイヤの実装
5.6.1　A.neレイヤ
5.6.2　バッチ版A.neレイヤ
5.6.3　Softmax-with-Lossレイヤ
5.7　誤差逆伝播法の実装
5.7.1　ニューラルネットワークの学習の全体図
5.7.2　誤差逆伝播法に対応したニューラルネットワークの実装
5.7.3　誤差逆伝播法の勾配確認
5.7.4　誤差逆伝播法を使った学習
5.8　まとめ
6章　学習に関するテクニック
6.1　パラメータの更新
6.1.1　冒険家の話
6.1.2　SGD
6.1.3　SGDの欠点
6.1.4　Momentum
6.1.5　AdaGrad
6.1.6　Adam
6.1.7　どの更新手法を用いるか？
6.1.8　MNISTデータセットによる更新手法の比較
6.2　重みの初期値
6.2.1　重みの初期値を0にする？
6.2.2　隠れ層のアクティベーション分布
6.2.3　ReLUの場合の重みの初期値
6.2.4　MNISTデータセットによる重み初期値の比較
6.3　Batch Normalization
6.3.1　Batch Normalizationのアルゴリズム
6.3.2　Batch Normalizationの評価
6.4　正則化
6.4.1　過学習
6.4.2　Weight decay
6.4.3　Dropout
6.5　ハイパーパラメータの検証
6.5.1　検証データ
6.5.2　ハイパーパラメータの最適化
6.5.3　ハイパーパラメータ最適化の実装
6.6　まとめ
7章　畳み込みニューラルネットワーク
7.1　全体の構造
7.2　畳み込み層
7.2.1　全結合層の問題点
7.2.2　畳み込み演算
7.2.3　パディング
7.2.4　ストライド
7.2.5　3次元データの畳み込み演算
7.2.6　ブロックで考える
7.2.7　バッチ処理
7.3　プーリング層
7.3.1　プーリング層の特徴
7.4　Convolution／Poolingレイヤの実装
7.4.1　4次元配列
7.4.2　im2colによる展開
7.4.3　Convolutionレイヤの実装
7.4.4　Poolingレイヤの実装
7.5　CNNの実装
7.6　CNNの可視化
7.6.1　1層目の重みの可視化
7.6.2　階層構造による情報抽出
7.7　代表的なCNN
7.7.1　LeNet
7.7.2　AlexNet
7.8　まとめ
8章　ディープラーニング
8.1　ネットワークをより深く
8.1.1　よりディープなネットワークへ
8.1.2　さらに認識精度を高めるには
8.1.3　層を深くすることのモチベーション
8.2　ディープラーニングの小歴史
8.2.1　ImageNet
8.2.2　VGG
8.2.3　GoogLeNet
8.2.4　ResNet
8.3　ディープラーニングの高速化
8.3.1　取り組むべき問題
8.3.2　GPUによる高速化
8.3.3　分散学習
8.3.4　演算精度のビット削減
8.4　ディープラーニングの実用例
8.4.1　物体検出
8.4.2　セグメンテーション
8.4.3　画像キャプション生成
8.5　ディープラーニングの未来
8.5.1　画像スタイル変換
8.5.2　画像生成
8.5.3　自動運転
8.5.4　Deep Q-Network（強化学習）
8.6　まとめ
付録A　Softmax-with-Lossレイヤの計算グラフ
A.1　順伝播
A.2　逆伝播
A.3　まとめ
参考文献
Python / NumPy
計算グラフ（誤差逆伝播法）
Deep Learningのオンライン授業（資料）
パラメータの更新方法
重みパラメータの初期値
Batch Normalization / Dropout
ハイパーパラメータの最適化
CNNの可視化
代表的なネットワーク
データセット
計算の高速化
MNISTデータセットの精度ランキングおよび最高精度の手法
ディープラーニングのアプリケーション
索引
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>ゼロから作るDeep Learning
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
第1章 引论　1.1 概述　　1.1.1 模式识别的概念　　1.1.2 模式识别系统　　1.1.3 模式识别的基本方法　1.2 特征矢量和特征空间　1.3 随机矢量的描述　1.4 正态分布　　1.4.1 正态分布的定义　　1.4.2 多元正态分布的性质第2章 聚类分析及最近邻方法　2.1 聚类分析的概念　　2.1.1 聚类分析的基本思想　　2.1.2 特征量　　2.1.3 方法的有效性　2.2 模式相似性测度　　2.2.1 距离测度(差值测度)　　2.2.2 相似测度　　2.2.3 匹配测度　2.3 类间距离　　2.3.1 类间距离测度方法　2.4 准则函数　　2.4.1 点与集合间的距离　　2.4.2 聚类的准则函数　2.5 聚类的算法　　2.5.1 聚类的技术方案　　2.5.2 基于相似性阈值的简单聚类方法　　2.5.3 谱系聚类法　　2.5.4 动态聚类法(Dynamic clustering algorithm)　　2.5.5 近邻函数法　2.6 最近邻方法　　2.6.1 最近邻法　　2.6.2 剪辑最近邻法　　2.6.3 引入拒绝类别决策的最近邻法　习题　算法编程第3章 判别域代数界面方程法　3.1 判别域界面方程分类的概念　3.2 线性判别函数　　3.2.1 两类问题　　3.2.2 多类问题　3.3 判别函数值的鉴别意义、权空间及解空间　　3.3.1 判别函数值的大小、正负的数学意义　　3.3.2 权空间、解矢量与解空间　3.4 Fisher线性判别　3.5 线性可分条件下判别函数权矢量算法　　3.5.1 感知器算法　　3.5.2 一次准则函数及梯度下降法　　3.5.3 感知器训练算法在多类问题中的应用  3.6 一般情况下的判别函数权矢量算法    3.6.1 分段二次准则函数及共轭梯度法    3.6.2 最小平方误差准则及W－H算法    3.6.3 H－K(Ho－Kashyap)算法  3.7 广义线性判别函数  3.8 二次判别函数  3.9 位势函数分类法    3.9.1 位势函数的概念    3.9.2 由位势函数产生判别函数的训练算法及分类规则  3.10 支持矢量机简介  习题  算法编程第4章 统计判决  4.1 最小误判概率准则判决    4.1.1 最小误判概率准则判决的一般形式    4.1.2 正态模式最小误判概率判决规则的具体形式    4.1.3 正态模式分类的误判概率  4.2 最小损失准则判决    4.2.1 损失概念、损失函数与平均损失    4.2.2 最小损失准则判决  4.3 最小最大损失准则  4.4 N－P(Neyman－Pearson)判决  4.5 序贯判决(SPRD)    4.5.1 控制误判概率的序贯判决    4.5.2 计人提取特征代价的最小损失准则下的序贯  判决  习题  算法编程第5章 统计决策中的经典学习方法  5.1 统计推断概述  5.2 参数估计    5.2.1 均值矢量和协方差阵的矩法估计    5.2.2 最大似然估计(MLE)    5.2.3 贝叶斯估计(BE)    5.2.4 最大似然估计和贝叶斯估计的性能比较  5.3 贝叶斯学习  5.4 概密的窗函数估计法    5.4.1 概密的基本估计式    5.4.2 Parzen窗法    5.4.3 KN－近邻估计法    5.4.4 后验概率的估计  5.5 有限项正交函数级数逼近法    5.5.1 最小积分平方差逼近方法    5.5.2 最小均方差逼近方法  5.6 用位势函数法逼近贝叶斯判决函数  5.7 错误率估计    5.7.1 分类器错误率的实验估算基本原理    5.7.2 样本抽取方式对误判概率估计的影响    5.7.3 训练与测试样本集的大小对错误率的影响    5.7.4 训练样本使用技术及错误率的测试方法  习题  算法编程第6章 特征提取与选择  6.1 概述  6.2 类别可分性判据    6.2.1 基于几何距离的可分性判据    6.2.2 基于类的概率密度函数的可分性判据    6.2.3 基于后验概率的可分性判据  6.3 基于可分性判据进行变换的特征提取    6.3.1 基于离差阵的特征提取    6.3.2 多类情况    6.3.3 基于熵概念的某些特征提取与选择方法  6.4 最佳鉴别矢量的提取    6.4.1 Fisher鉴别矢量及鉴别平面    6.4.2 最佳鉴别矢量集  6.5 离散K－L变换及其在特征提取与选择中的应用    6.5.1 离散K－L变换(DKLT)    6.5.2 离散K－L变换在特征提取与选择中的应用  6.6 特征选择中的直接挑选法    6.6.1 次优搜索法    6.6.2 最优搜索法  习题第7章 其他模式识别方法  7.1 模糊模式识别      7.1.1 模糊数学基础知识    7.1.2 模糊模式识别的基本方法  7.2 神经网络在模式识别中的应用    7.2.1 人工神经网络的基本知识    7.2.2 常见的神经网络模型  7.3 句法模式识别      7.3.1 句法模式识别概述    7.3.2 形式语言介绍    7.3.3 句法模式识别的基本内容  7.4 信息融合    7.4.1 信息融合概述    7.4.2 融合技术层次性及融合系统功能模块和结构  7.5 树分类器    7.5.1 树分类器原理及设计原则    7.5.2 树分类器关键技术    7.5.3 决策树生成算法  习题参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>模式识别
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Activity Learning-从传感器数据中发现.识别和预测人的行为
目录
第1章 引言 1
第2章 活动 7
2.1活动的定义 7
2.2活动的分类 10
2.3补充阅读 10
第3章 传感技术 15
3.1用于活动学习的传感器 16
3.1.1环境传感器 16
3.1.2可随身佩戴的传感器 21
3.2传感器数据集样本 22
3.3特征量 26
3.3.1序列特征量 28
3.3.2离散事件特征量 30
3.3.3统计特征量 34
3.3.4谱特征量 43
3.3.5活动背景的特征量 45
3.4多传感器融合 46
3.5补充阅读 51
第4章 机器学习 55
4.1监督学习 55
4.2朴素贝叶斯分类器 60
4.3高斯混合模型 65
4.4隐马尔可夫模型 68
4.5决策树 73
4.6支持向量机 76
4.7条件随机场 84
4.8分类器的组合模型 86
4.8.1提升 86
4.8.2袋化 88
4.9降维技术 89
4.10补充阅读 98
第5章 活动识别 101
5.1活动分割 103
5.2滑动窗口 109
5.2.1时基窗口分割 110
5.2.2基于大小的窗口分割 111
5.2.3给窗口内的事件分配权值 113
5.2.4动态窗口大小 119
5.3无监督分割 121
5.4性能测量 126
5.4.1基于分类器的活动识别性能指标 129
5.4.2基于事件的活动识别性能指标 135
5.4.3评估活动识别的实验框架 139
5.5补充阅读 141
第6章 活动发现 145
6.1零样本学习 147
6.2序列挖掘 149
6.2.1基于频率的序列挖掘 151
6.2.2基于压缩比的序列挖掘 153
6.3聚类 159
6.4主题模型 162
6.5性能测量指标 165
6.6补充阅读 169
第7章 活动预测 171
7.1活动序列预测 172
7.2活动预报 180
7.3基于概率图的活动预测 186
7.4基于规则的活动时序预测 189
7.5性能测量 193
7.6补充阅读 200
第8章 活动学习存在的实际问题 203
8.1收集带标签的传感器数据 203
8.2迁移学习 217
8.2.1实例迁移和标签迁移 222
8.2.2无共生数据的特征迁移 226
8.2.3有共生数据的知情特征迁移 228
8.2.4用教师-学生模型实现共生数据的不知情特征迁移 230
8.2.5用特征空间对齐方法实现共生数据的不知情特征迁移 232
8.3多标签学习 233
8.3.1问题变换 236
8.3.2标签相关性利用 238
8.3.3多标签学习算法的性能评估 244
8.4多个体的活动学习 246
8.4.1学习群体活动 246
8.4.2训练一个测试多个 251
8.4.3分离事件流 254
8.4.4跟踪多用户 258
8.5补充阅读 261
第9章 活动学习的实际应用 267
9.1健康 267
9.2活动感知服务 271
9.3安全与应急处理 274
9.4活动重构、表示和可视化 275
9.5分析人类的动态行为 282
9.6补充阅读 287
第10章 活动学习的未来 291
附录A 活动样本数据 297
附录B 参考文献 323
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Activity Learning-从传感器数据中发现.识别和预测人的行为
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>稀疏建模理论、算法及其应用
第1章 导论
1.1 引导性示例
1.1.1 计算机网络诊断
1.1.2 神经影像分析
1.1.3 压缩感知
1.2 稀疏复原简介
1.3 统计学习与压缩感知
1.4 总结与参考书目 [1]
第2章 稀疏复原：问题描述
2.1 不含噪稀疏复原
2.2 近似
2.3 凸性： 简要回顾
2.4 问题（P0）的松弛
2.5 lq-正则函数对解的稀疏性的影响
2.6 l1范数最小化与线性规划的等价性
2.7 含噪稀疏复原
2.8 稀疏复原问题的统计学视角
2.9 扩展LASSO：其他损失函数与正则函数
2.10 总结与参考书目
第3章 理论结果（确定性部分）
3.1 采样定理
3.2 令人惊讶的实验结果
3.3 从不完全频率信息中进行信号复原
3.4 互相关 [1]
3.5 Spark与问题（P0）解的唯一性
3.6 零空间性质与问题（P1）解的唯一性
3.7 有限等距性质
3.8 最坏情况下精确复原问题的平方根瓶颈
3.9 基于RIP的精确重构
3.10 总结与参考书目第4章理论结果（概率部分）
4.1 RIP何时成立？
4.2 Johnson-Lindenstrauss引理与亚高斯随机矩阵的RIP
4.2.1 Johnson-Lindenstrauss集中不等式的证明
4.2.2 具有亚高斯随机元素的矩阵的RIP
4.3 满足RIP的随机矩阵
4.3.1 特征值与RIP
4.3.2 随机向量，等距随机向量
4.4 具有独立有界行的矩阵与具有傅里叶变换随机行的矩阵的RIP
4.4.1 URI的证明
4.4.2 一致大数定律的尾界
4.5 总结与参考书目
第5章 稀疏复原问题的算法
5.1 一元阈值是正交设计的最优方法
5.1.1 l0范数最小化
5.1.2 l1范数最小化 [1]
5.2 求解l0范数最小化的算法
5.2.1 贪婪方法综述
5.3 用于l1范数最小化的算法
5.3.1 用于求解LASSO的最小角回归方法
5.3.2 坐标下降法
5.3.3 近端方法
5.4 总结与参考书目
第6章 扩展LASSO：结构稀疏性
6.1 弹性网
6.1.1 实际中的弹性网：神经成像应用
6.2 融合LASSO
6.3 分组LASSO：l1/l2罚函数
6.4 同步LASSO：l1/l∞罚函数
6.5 一般化
6.5.1 块l1/lq范数及其扩展
6.5.2 重叠分组
6.6 应用
6.6.1 时间因果关系建模
6.6.2 广义加性模型
6.6.3 多核学习
6.6.4 多任务学习
6.7 总结与参考书目
第7章 扩展LASSO：其他损失函数
7.1 含噪观测情况下的稀疏复原
7.2 指数族、 GLM与Bregman散度 [1]
7.2.1 指数族
7.2.2 广义线性模型
7.2.3 Bregman散度
7.3 具有GLM回归的稀疏复原
7.4 总结与参考书目
第8章 稀疏图模型
8.1 背景
8.2 马尔可夫网络
8.2.1 马尔可夫性质：更为仔细的观察
8.2.2 高斯MRF
8.3 马尔可夫网络中的学习与推断
8.3.1 学习
8.3.2 推断
8.3.3 例子：神经影像应用
8.4 学习稀疏高斯MRF
8.4.1 稀疏逆协方差选择问题 [1]
8.4.2 优化方法
8.4.3 选择正则化参数
8.5 总结与参考书目
第9章 稀疏矩阵分解：字典学习与扩展
9.1 字典学习
9.1.1 问题描述
9.1.2 字典学习算法
9.2 稀疏PCA
9.2.1 背景
9.2.2 稀疏PCA：合成视角
9.2.3 稀疏PCA：分析视角
9.3 用于盲源分离的稀疏NMF
9.4 总结与参考书目
后记
附录A 数学背景
参考文献 [1]
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>稀疏建模理论、算法及其应用
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>機械学習のための確率と統計
第1章 確率変数と確率分布
第2章 離散型確率分布の例
第3章 連続型確率分布の例
第4章 多次元確率分布の性質
第5章 多次元確率分布の例
第6章 任意の確率分布に従う標本の生成
第7章 独立な確率変数の和の確率分布
第8章 確率不等式
第9章 統計的推定
第10章 仮説検定
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>機械学習のための確率と統計
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow深度学习
第一部分探索深度学习之方式的开始
第1章开篇
1.1人工智能的发展
1.1.1萌芽
1.1.2复苏
1.1.3现代实践：大数据+深度神经网络模型
1.2大数据
1.3机器学习与深度学习
1.3.1机器学习
1.3.2深度学习
1.3.3同人工智能的关系
1.4人工神经网络与TensorFlow
1.4.1人工神经网络
1.4.2TensorFlow
1.5其他主流深度学习框架介绍
1.5.1Caffe
1.5.2Torch
1.5.3Theano
1.5.4MXNet
1.5.5Keras
1.6机器学习的常见任务
1.6.1分类
1.6.2回归
1.6.3去噪
1.6.4转录
1.6.5机器翻译
1.6.6异常检测
1.6.7结构化输出
1.7深度学习的现代应用
1.7.1计算机视觉
1.7.2自然语言处理
1.7.3语音识别
第2章安装TensorFlow
2.1安装前的须知
2.1.1检查硬件是否达标
2.1.2推荐选用GPU进行训练
2.1.3为什么选择Linux系统
2.1.4为什么选择Python语言
2.2安装Anaconda
2.3TensorFlow的两个主要依赖包
2.3.1Protocol Buffer
2.3.2Bazel
2.4安装CUDA和cuDNN
2.4.1CUDA
2.4.2cuDNN
2.5正式安装TensorFlow
2.5.1使用pip安装
2.5.2从源代码编译并安装
2.6测试你的TensorFlow
2.6.1运行向量相加的例子
2.6.2加载过程存在的一些问题
2.7推荐使用IDE
第3章TensorFlow编程策略
3.1初识计算图与张量
3.2计算图——TensorFlow的计算模型
3.3张量——TensorFlow的数据模型
3.3.1概念
3.3.2使用张量
3.4会话——TensorFlow的运行模型
3.4.1TensorFlow系统结构概述
3.4.2简单使用会话
3.4.3使用with/as环境上下文管理器
3.4.4Session的参数配置
3.4.5placeholder机制
3.5TensorFlow变量
3.5.1创建变量
3.5.2变量与张量
3.6管理变量的变量空间
3.6.1get_variable()函数
3.6.2variable_scope()与name_scope()
第二部分TensorFlow实现深度网络
第4章深度前馈神经网络
4.1网络的前馈方式
4.2全连接
4.2.1神经元与全连接结构
4.2.2前向传播算法
4.3线性模型的局限性
4.4激活函数
4.4.1常用激活函数
4.4.2激活函数实现去线性化
4.5多层网络解决异或运算
4.6损失函数
4.6.1经典损失函数
4.6.2自定义损失函数
第5章优化网络的方法
5.1基于梯度的优化
5.1.1梯度下降算法
5.1.2随机梯度下降
5.2反向传播
5.2.1简要解释反向传播算法
5.2.2自适应学习率算法
5.2.3TensorFlow提供的优化器
5.3学习率的独立设置
5.3.1指数衰减的学习率
5.3.2其他优化学习率的方法
5.4拟合
5.4.1过拟合和欠拟合
5.4.2正则化的方法
5.4.3Bagging方法
5.4.4Dropout方法
第6章全连神经网络的经典实践
6.1MNIST数据集
6.2网络的设计
6.3超参数和验证集
6.4与简单模型的对比
第7章卷积神经网络
7.1准备性的认识
7.1.1图像识别与经典数据集
7.1.2卷积网络的神经科学基础
7.1.3卷积神经网络的历史
7.2卷积
7.2.1卷积运算
7.2.2卷积运算的稀疏连接
7.2.3卷积运算的参数共享
7.2.4卷积运算的平移等变
7.2.5多卷积核
7.2.6卷积层的代码实现
7.3池化
7.3.1池化过程
7.3.2常用池化函数
7.3.3池化层的代码实现
7.4实现卷积神经网络的简例
7.4.1卷积神经网络的一般框架
7.4.2用简单卷积神经网络实现Cifar-10数据集分类
7.5图像数据处理
7.5.1图像编解码处理
7.5.2翻转图像
7.5.3图像色彩调整
7.5.4图像标准化处理
7.5.5调整图像大小
7.5.6图像的标注框
第8章经典卷积神经网络
8.1LeNet-5卷积网络模型
8.1.1模型结构
8.1.2TensorFlow实现
8.2AlexNet卷积网络模型
8.2.1模型结构
8.2.2TensorFlow实现
8.3VGGNet卷积网络模型
8.3.1模型结构
8.3.2TensorFlow实现
8.4InceptionNet-V3卷积网络模型
8.4.1模型结构
8.4.2Inception V3 Module的实现
8.4.3使用Inception V3完成模型迁移
8.5ResNet卷积网络模型
8.5.1模型结构
8.5.2TensorFlow实现
第9章循环神经网络
9.1循环神经网络简介
9.1.1循环神经网络的前向传播程序设计
9.1.2计算循环神经网络的梯度
9.1.3循环神经网络的不同设计模式
9.2自然语言建模与词向量
9.2.1统计学语言模型
9.2.2Word2Vec
9.2.3用TensorFlow实现Word2Vec
9.3LSTM实现自然语言建模
9.3.1长短时记忆网络（LSTM）
9.3.2LSTM在自然语言建模中的应用
9.3.3循环神经网络的Dropout
9.4循环神经网络的变种
9.4.1双向循环神经网络
9.4.2深层循环神经网络
第10章深度强化学习
10.1理解基本概念
10.2深度强化学习的思路
10.3典型应用场景举例
10.3.1场景1：机械臂自控
10.3.2场景2：自动游戏系统
10.3.3场景3：自动驾驶
10.3.4场景4：智能围棋系统
10.4Q学习与深度Q网络
10.4.1Q学习与深度Q学习
10.4.2深度Q网络
第三部分TensorFlow的使用进阶
第11章数据读取
11.1文件格式
11.1.1TFRecord格式
11.1.2CSV格式
11.2队列
11.2.1数据队列
11.2.2文件队列
11.3使用多线程处理输入的数据
11.3.1使用Coordinator类管理线程
11.3.2使用QueueRunner创建线程
11.4组织数据batch
第12章模型持久化
12.1通过代码实现
12.2模型持久化的原理
12.2.1model.ckpt.mate文件
12.2.2从.index与.data文件读取变量的值
12.3持久化的MNIST手写字识别
12.4PB文件
第13章TensorBoard可视化
13.1TensorBoard简要介绍
13.2MNIST手写字识别的可视化
13.2.1实现的过程
13.2.2标量数据可视化结果
13.2.3图像数据可视化结果
13.2.4计算图可视化结果
13.3其他监控指标可视化
第14章加速计算
14.1TensorFlow支持的设备
14.2TensorFlow单机实现
14.2.1查看执行运算的设备
14.2.2device()函数的使用
14.3并行训练的原理
14.3.1数据并行
14.3.2模型并行
14.4单机多GPU加速TensorFlow程序
14.4.1实现的过程
14.4.2多GPU并行的可视化
14.5分布式TensorFlow概述
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>TensorFlow深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
●前言
●章 绪论
● 1.1 预测和推荐问题描述
● 1.2 研究意义
● 1.3 国内外研究现状及发展动态
● 1.3.1 数据稀疏性和冷启动问题
● 1.3.2 用户偏好和物品流行度动态建模
● 1.3.3 大数据处理和模型的扩展性
● 1.3.4 多样性和准确性平衡问题
● 1.4 本书组织结构
●第2章 FM模型及其扩展
● 2.1 逻辑回归模型
● 2.2 基于因子分解的多项式回归模型
● 2.3 FM模型
● 2.4 FM模型与矩阵分解模型的转化
● 2.4.1 矩阵分解模型
● 2.4.2 FM模型转化为矩阵分解模型
● 2.5 FM模型的高阶扩展
● 2.6 FM模型的场交互扩展
● 2.7 FM模型的层次交互扩展
●部分目录
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>
