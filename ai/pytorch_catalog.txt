>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习框架PyTorch：入门与实践
1  PyTorch简介
1.1 PyTorch的诞生
1.2 常见的深度学习框架简介
1.2.1 Theano
1.2.2 TensorFlow
1.2.3 Keras
1.2.4 Caffe/Caffe2
1.2.5 MXNet
1.2.6 CNTK
1.2.7 其他框架
1.3 属于动态图的未来
1.4 为什么选择PyTorch
1.5 星火燎原
1.6 fast.ai 放弃Keras+TensorFlow选择PyTorch
2  快速入门
2.1 安装与配置
2.1.1 安装PyTorch
2.1.2 学习环境配置
2.2 PyTorch入门第一步
2.2.1 Tensor
2.2.2 Autograd：自动微分
2.2.3 神经网络
2.2.4 小试牛刀：CIFAR-10分类
3  Tensor和autograd
3.1 Tensor
3.1.1 基础操作
3.1.2 Tensor和Numpy
3.1.3 内部结构
3.1.4 其他有关Tensor的话题
3.1.5 小试牛刀：线性回归
3.2 autograd
3.2.1 Variable
3.2.2 计算图
3.2.3 扩展autograd
3.2.4 小试牛刀：用Variable实现线性回归
4  神经网络工具箱nn
4.1 nn.Module
4.2 常用的神经网络层
4.2.1 图像相关层
4.2.2 激活函数
4.2.3 循环神经网络层
4.2.4 损失函数
4.3 优化器
4.4 nn.functional
4.5 初始化策略
4.6 nn.Module深入分析
4.7 nn和autograd的关系
4.8 小试牛刀：用50行代码搭建ResNet
5  PyTorch中常用的工具
5.1 数据处理
5.2 计算机视觉工具包：torchvision
5.3 可视化工具
5.3.1 Tensorboard
5.3.2 visdom
5.4 使用GPU加速：cuda
5.5 持久化
6  PyTorch实战指南
6.1 编程实战：猫和狗二分类
6.1.1 比赛介绍
6.1.2 文件组织架构
6.1.3 关于__init__.py
6.1.4 数据加载
6.1.5 模型定义
6.1.6 工具函数
6.1.7 配置文件
6.1.8 main.py
6.1.9 使用
6.1.10 争议
6.2 PyTorch Debug 指南
6.2.1 ipdb 介绍
6.2.2 在PyTorch中Debug
7  AI插画师：生成对抗网络
7.1 GAN的原理简介
7.2 用GAN生成动漫头像
7.3 实验结果分析
8  AI艺术家：神经网络风格迁移
8.1 风格迁移原理介绍
8.2 用PyTorch实现风格迁移
8.3 实验结果分析
9  AI诗人：用RNN写诗
9.1 自然语言处理的基础知识
9.1.1 词向量
9.1.2 RNN
9.2 CharRNN
9.3 用PyTorch实现CharRNN
9.4 实验结果分析
10  Image Caption：让神经网络看图讲故事
10.1 图像描述介绍
10.2 数据
10.2.1 数据介绍
10.2.2 图像数据处理
10.2.3 数据加载
10.3 模型与训练
10.4 实验结果分析
11  展望与未来
11.1 PyTorch的局限与发展
11.2 使用建议
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习框架PyTorch：入门与实践
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch深度学习
第 1章　PyTorch与深度学习 1
1．1　人工智能　1
1．2　机器学习　3
1．3　深度学习　4
1．3．1　深度学习的应用　4
1．3．2　深度学习的浮夸宣传　6
1．3．3　深度学习发展史　6
1．3．4　为何是现在　7
1．3．5　硬件可用性　7
1．3．6　数据和算法　8
1．3．7　深度学习框架　9
1．4　小结　10
第　2章 神经网络的构成　11
2．1　安装PyTorch　11
2．2　实现第 一个神经网络　12
2．2．1　准备数据　13
2．2．2　为神经网络创建数据　20
2．2．3　加载数据　24
2．3　小结　25
第3章　深入了解神经网络　26
3．1　详解神经网络的组成部分　26
3．1．1　层—神经网络的基本组成　27
3．1．2　非线性激活函数　29
3．1．3　PyTorch中的非线性激活函数　32
3．1．4　使用深度学习进行图像分类　36
3．2　小结　46
第4章　机器学习基础　47
4．1　三类机器学习问题　47
4．1．1　有监督学习　48
4．1．2　无监督学习　48
4．1．3　强化学习　48
4．2　机器学习术语　49
4．3　评估机器学习模型　50
4．4　数据预处理与特征工程　54
4．4．1　向量化　54
4．4．2　值归一化　54
4．4．3　处理缺失值　55
4．4．4　特征工程　55
4．5　过拟合与欠拟合　56
4．5．1　获取更多数据　56
4．5．2　缩小网络规模　57
4．5．3　应用权重正则化　58
4．5．4　应用dropout　58
4．5．5　欠拟合　60
4．6　机器学习项目的工作流　60
4．6．1　问题定义与数据集创建　60
4．6．2　成功的衡量标准　61
4．6．3　评估协议　61
4．6．4　准备数据　62
4．6．5　模型基线　62
4．6．6　大到过拟合的模型　63
4．6．7　应用正则化　63
4．6．8　学习率选择策略　64
4．7　小结　65
第5章　深度学习之计算机视觉　66
5．1　神经网络简介　66
5．2　从零开始构建CNN模型　69
5．2．1　Conv2d　71
5．2．2　池化　74
5．2．3　非线性激活—ReLU　75
5．2．4　视图　76
5．2．5　训练模型　77
5．2．6　狗猫分类问题—从零开始构建CNN　80
5．2．7　利用迁移学习对狗猫分类　82
5．3　创建和探索VGG16模型　84
5．3．1　冻结层　85
5．3．2　微调VGG16模型　85
5．3．3　训练VGG16模型　86
5．4　计算预卷积特征　88
5．5　理解CNN模型如何学习　91
5．6　CNN层的可视化权重　94
5．7　小结　95
第6章　序列数据和文本的深度学习　96
6．1　使用文本数据　96
6．1．1　分词　98
6．1．2　向量化　100
6．2　通过构建情感分类器训练词向量　104
6．2．1　下载IMDB数据并对文本分词　104
6．2．2　构建词表　106
6．2．3　生成向量的批数据　107
6．2．4　使用词向量创建网络模型　108
6．2．5　训练模型　109
6．3　使用预训练的词向量　110
6．3．1　下载词向量　111
6．3．2　在模型中加载词向量　112
6．3．3　冻结embedding层权重　113
6．4　递归神经网络（RNN）　113
6．5　LSTM　117
6．5．1　长期依赖　117
6．5．2　LSTM网络　117
6．6　基于序列数据的卷积网络　123
6．7　小结　125
第7章　生成网络　126
7．1　神经风格迁移　126
7．1．1　加载数据　129
7．1．2　创建VGG模型　130
7．1．3　内容损失　131
7．1．4　风格损失　131
7．1．5　提取损失　133
7．1．6　为网络层创建损失函数　136
7．1．7　创建优化器　136
7．1．8　训练　137
7．2　生成对抗网络（GAN）　138
7．3　深度卷机生成对抗网络　139
7．3．1　定义生成网络　140
7．3．2　定义判别网络　144
7．3．3　定义损失函数和优化器　145
7．3．4　训练判别网络　145
7．3．5　训练生成网络　146
7．3．6　训练整个网络　147
7．3．7　检验生成的图片　148
7．4　语言建模　150
7．4．1　准备数据　151
7．4．2　生成批数据　152
7．4．3　定义基于LSTM的模型　153
7．4．4　定义训练和评估函数　155
7．4．5　训练模型　157
7．5　小结　159
第8章　现代网络架构　160
8．1　现代网络架构　160
8．1．1　ResNet　160
8．1．2　Inception　168
8．2　稠密连接卷积网络（DenseNet）　175
8．2．1　DenseBlock　175
8．2．2　DenseLayer　176
8．3　模型集成　180
8．3．1　创建模型　181
8．3．2　提取图片特征　182
8．3．3　创建自定义数据集和数据加载器　183
8．3．4　创建集成模型　184
8．3．5　训练和验证模型　185
8．4　encoder-decoder架构　186
8．4．1　编码器　188
8．4．2　解码器　188
8．5　小结　188
第9章　未来走向　189
9．1　未来走向　189
9．2　回顾　189
9．3　有趣的创意应用　190
9．3．1　对象检测　190
9．3．2　图像分割　191
9．3．3　PyTorch中的OpenNMT　192
9．3．4　Allen NLP　192
9．3．5　fast．ai—神经网络不再神秘　192
9．3．6　Open Neural Network Exchange　192
9．4　如何跟上前沿　193
9．5　小结　193
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch深度学习
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch 机器学习从入门到实战
前言
第 1 章 深度学习介绍......................................................................................... 1
1.1 人工智能、机器学习与深度学习 .................................................................. 2
1.2 深度学习工具介绍 .......................................................................................... 5
1.3 PyTorch 介绍.................................................................................................... 7
1.4 你能从本书中学到什么 .................................................................................. 9
第 2 章 PyTorch 安装和快速上手 ...................................................................... 11
2.1 PyTorch 安装.................................................................................................. 12
2.1.1 Anaconda 安装.................................................................................... 12
2.1.2 PyTorch 安装....................................................................................... 19
2.2 Jupyter Notebook 使用................................................................................... 19
2.3 NumPy 基础知识........................................................................................... 22
2.3.1 基本概念 ............................................................................................. 23
2.3.2 创建数组 ............................................................................................. 24
2.3.3 基本运算 ............................................................................................. 26
2.3.4 索引、切片和迭代 ............................................................................. 27
2.3.5 数组赋值 ............................................................................................. 32
2.3.6 更改数组的形状 ................................................................................. 33
2.3.7 组合、拆分数组 ................................................................................. 34
2.3.8 广播 ..................................................................................................... 35
2.4 PyTorch 基础知识.......................................................................................... 37
2.4.1 Tensor 简介 ......................................................................................... 37
2.4.2 Variable 简介....................................................................................... 37VIII
PyTorch 机器学习从入门到实战
2.4.3 CUDA 简介......................................................................................... 38
2.4.4 模型的保存与加载 ............................................................................. 39
2.4.5 第一个 PyTorch 程序.......................................................................... 39
第 3 章 神经网络 .............................................................................................. 42
3.1 神经元与神经网络 ........................................................................................ 43
3.2 激活函数 ........................................................................................................ 45
3.2.1 Sigmoid ................................................................................................ 46
3.2.2 Tanh ..................................................................................................... 47
3.2.3 Hard Tanh ............................................................................................ 48
3.2.4 ReLU ................................................................................................... 49
3.2.5 ReLU 的扩展 ...................................................................................... 50
3.2.6 Softmax ................................................................................................ 53
3.2.7 LogSoftmax ......................................................................................... 54
3.3 前向算法 ........................................................................................................ 54
3.4 损失函数 ........................................................................................................ 56
3.4.1 损失函数的概念 ................................................................................. 56
3.4.2 回归问题 ............................................................................................. 56
3.4.3 分类问题 ............................................................................................. 57
3.4.4 PyTorch 中常用的损失函数............................................................... 58
3.5 后向算法 ........................................................................................................ 61
3.6 数据的准备 .................................................................................................... 64
3.7 实例：单层神经网络 .................................................................................... 65
第 4 章 深层神经网络及训练............................................................................ 69
4.1 深层神经网络 ................................................................................................ 71
4.1.1 神经网络为何难以训练 ..................................................................... 71
4.1.2 改进策略 ............................................................................................. 73
4.2 梯度下降 ........................................................................................................ 73
4.2.1 随机梯度下降 ..................................................................................... 73
4.2.2 Mini-Batch 梯度下降.......................................................................... 74
4.3 优化器 ............................................................................................................ 75
4.3.1 SGD ..................................................................................................... 76
4.3.2 Momentum .......................................................................................... 76
4.3.3 AdaGrad .............................................................................................. 77
4.3.4 RMSProp ............................................................................................. 78IX
目 录
4.3.5 Adam ................................................................................................... 79
4.3.6 选择正确的优化算法 ......................................................................... 79
4.3.7 优化器的使用实例 ............................................................................. 80
4.4 正则化 ............................................................................................................ 83
4.4.1 参数规范惩罚 ..................................................................................... 84
4.4.2 Batch Normalization ............................................................................ 84
4.4.3 Dropout ................................................................................................ 85
4.5 实例：MNIST 深层神经网络....................................................................... 87
第 5 章 卷积神经网络....................................................................................... 91
5.1 计算机视觉 .................................................................................................... 93
5.1.1 人类视觉和计算机视觉 ..................................................................... 93
5.1.2 特征提取 ............................................................................................. 93
5.1.3 数据集 ................................................................................................. 95
5.2 卷积神经网络 ................................................................................................ 98
5.2.1 卷积层 ............................................................................................... 100
5.2.2 池化层 ............................................................................................... 102
5.2.3 经典卷积神经网络 ........................................................................... 103
5.3 MNIST 数据集上卷积神经网络的实现..................................................... 108
第 6 章 嵌入与表征学习 .................................................................................. 112
6.1 PCA .............................................................................................................. 113
6.1.1 PCA 原理 .......................................................................................... 113
6.1.2 PCA 的 PyTorch 实现....................................................................... 114
6.2 自动编码器 .................................................................................................. 115
6.2.1 自动编码器原理 ............................................................................... 116
6.2.2 自动解码器的 PyTorch 实现............................................................ 116
6.2.3 实例：图像去噪 ............................................................................... 120
6.3 词嵌入 .......................................................................................................... 123
6.3.1 词嵌入原理 ....................................................................................... 123
6.3.2 实例：基于词向量的语言模型实现 ............................................... 126
第 7 章 序列预测模型..................................................................................... 130
7.1 序列数据处理 .............................................................................................. 131
7.2 循环神经网络 .............................................................................................. 132
7.3 LSTM 和 GRU ............................................................................................. 136X
PyTorch 机器学习从入门到实战
7.4 LSTM 在自然语言处理中的应用............................................................... 140
7.4.1 词性标注 ........................................................................................... 140
7.4.2 情感分析 ........................................................................................... 142
7.5 串到串网络 .................................................................................................. 143
7.5.1 串到串网络原理 ............................................................................... 143
7.5.2 注意力机制 ....................................................................................... 144
7.6 实例：基于 GRU 和 Attention 的机器翻译............................................... 145
7.6.1 公共模块 ........................................................................................... 145
7.6.2 数据处理 ........................................................................................... 145
7.6.3 模型定义 ........................................................................................... 149
7.6.4 训练模块定义 ................................................................................... 153
7.6.5 训练和模型保存 ............................................................................... 159
7.6.6 评估过程 ........................................................................................... 161
第 8 章 PyTorch 项目实战 .............................................................................. 163
8.1 图像识别和迁移学习——猫狗大战 .......................................................... 164
8.1.1 迁移学习介绍 ................................................................................... 164
8.1.2 计算机视觉工具包 ........................................................................... 164
8.1.3 猫狗大战的 PyTorch 实现................................................................ 165
8.2 文本分类 ...................................................................................................... 170
8.2.1 文本分类的介绍 ............................................................................... 171
8.2.2 计算机文本工具包 ........................................................................... 172
8.2.3 基于 CNN 的文本分类的 PyTorch 实现 ......................................... 172
8.3 语音识别系统介绍 ...................................................................................... 180
8.3.1 语音识别介绍 ................................................................................... 181
8.3.2 命令词识别的 PyTorch 实现............................................................ 181
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch 机器学习从入门到实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习入门之PyTorch
第 1 章 深度学习介绍 1
1.1 人工智能 1
1.2 数据挖掘、机器学习与深度学习2
1.2.1 数据挖掘 3
1.2.2 机器学习 3
1.2.3 深度学习 4
1.3 学习资源与建议 8
第 2 章 深度学习框架 11
2.1 深度学习框架介绍 . 11
2.2 PyTorch 介绍. 13
2.2.1 什么是 PyTorch. 13
2.2.2 为何要使用 PyTorch 14
2.3 配置 PyTorch 深度学习环境 15
2.3.1 操作系统的选择. 15
2.3.2 Python 开发环境的安装 16
2.3.3 PyTorch 的安装. 18
第 3 章 多层全连接神经网络 24
3.1 热身：PyTorch 基础 24
3.1.1 Tensor（张量）. 24
3.1.2 Variable（变量）26
3.1.3 Dataset（数据集）28
3.1.4 nn.Module（模组） 29
3.1.5 torch.optim（优化） 30
3.1.6 模型的保存和加载 31
3.2 线性模型 32
3.2.1 问题介绍 32
3.2.2 一维线性回归33
3.2.3 多维线性回归34
3.2.4 一维线性回归的代码实现. 35
3.2.5 多项式回归 38
3.3 分类问题 42
3.3.1 问题介绍 42
3.3.2 Logistic 起源 42
3.3.3 Logistic 分布 42
3.3.4 二分类的 Logistic 回归 43
3.3.5 模型的参数估计. 44
3.3.6 Logistic 回归的代码实现45
3.4 简单的多层全连接前向网络 . 49
3.4.1 模拟神经元 49
3.4.2 单层神经网络的分类器 50
3.4.3 激活函数 51
3.4.4 神经网络的结构. 54
3.4.5 模型的表示能力与容量 55
3.5 深度学习的基石：反向传播算法57
3.5.1 链式法则 57
3.5.2 反向传播算法58
3.5.3 Sigmoid 函数举例58
3.6 各种优化算法的变式59
3.6.1 梯度下降法 59
3.6.2 梯度下降法的变式 62
3.7 处理数据和训练模型的技巧 . 64
3.7.1 数据预处理 64
3.7.2 权重初始化 66
3.7.3 防止过拟合 67
3.8 多层全连接神经网络实现 MNIST 手写数字分类 69
3.8.1 简单的三层全连接神经网络70
3.8.2 添加激活函数70
3.8.3 添加批标准化71
3.8.4 训练网络 71
第 4 章 卷积神经网络 76
4.1 主要任务及起源 76
4.2 卷积神经网络的原理和结构 . 77
4.2.1 卷积层80
4.2.2 池化层84
4.2.3 全连接层 85
4.2.4 卷积神经网络的基本形式. 85
4.3 PyTorch 卷积模块 . 87
4.3.1 卷积层87
4.3.2 池化层88
4.3.3 提取层结构 90
4.3.4 如何提取参数及自定义初始化 91
4.4 卷积神经网络案例分析. 92
4.4.1 LeNet. 93
4.4.2 AlexNet94
4.4.3 VGGNet 95
4.4.4 GoogLeNet . 98
4.4.5 ResNet100
4.5 再实现 MNIST 手写数字分类 . 103
4.6 图像增强的方法 105
4.7 实现 cifar10 分类 107
第 5 章 循环神经网络 111
5.1 循环神经网络111
5.1.1 问题介绍 112
5.1.2 循环神经网络的基本结构. 112
5.1.3 存在的问题 115
5.2 循环神经网络的变式：LSTM 与 GRU 116
5.2.1 LSTM. 116
5.2.2 GRU. 119
5.2.3 收敛性问题 120
5.3 循环神经网络的 PyTorch 实现 122
5.3.1 PyTorch 的循环网络模块122
5.3.2 实例介绍 127
5.4 自然语言处理的应用131
5.4.1 词嵌入131
5.4.2 词嵌入的 PyTorch 实现 133
5.4.3 N Gram 模型 133
5.4.4 单词预测的 PyTorch 实现134
5.4.5 词性判断 136
5.4.6 词性判断的 PyTorch 实现137
5.5 循环神经网络的更多应用140
5.5.1 Many to one 140
5.5.2 Many to Many（shorter）141
5.5.3 Seq2seq141
5.5.4 CNN+RNN . 142
第 6 章 生成对抗网络 144
6.1 生成模型 144
6.1.1 自动编码器 145
6.1.2 变分自动编码器. 150
6.2 生成对抗网络153
6.2.1 何为生成对抗网络 153
6.2.2 生成对抗网络的数学原理. 160
6.3 Improving GAN164
6.3.1 Wasserstein GAN. 164
6.3.2 Improving WGAN167
6.4 应用介绍 168
6.4.1 Conditional GAN. 168
6.4.2 Cycle GAN . 170
第 7 章 深度学习实战 173
7.1 实例一——猫狗大战：运用预训练卷积神经网络进行特征提取与预测 . 173
7.1.1 背景介绍 174
7.1.2 原理分析 174
7.1.3 代码实现 177
7.1.4 总结. 183
7.2 实例二——Deep Dream：探索卷积神经网络眼中的世界183
7.2.1 原理介绍 184
7.2.2 预备知识：backward . 185
7.2.3 代码实现 190
7.2.4 总结. 195
7.3 实例三——Neural-Style：使用 PyTorch 进行风格迁移196
7.3.1 背景介绍 196
7.3.2 原理分析 197
7.3.3 代码实现 199
7.3.4 总结. 205
7.4 实例四——Seq2seq：通过 RNN 实现简单的 Neural Machine Translation . 205
7.4.1 背景介绍 206
7.4.2 原理分析 206
7.4.3 代码实现 209
7.4.4 总结. 221
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习入门之PyTorch
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习原理与PyTorch实战
目　　录
第　1章 深度学习简介　1
1．1　深度学习与人工智能　1
1．2　深度学习的历史渊源　2
1．2．1　从感知机到人工神经网络　3
1．2．2　深度学习时代　4
1．2．3　巨头之间的角逐　5
1．3　深度学习的影响因素　6
1．3．1　大数据　6
1．3．2　深度网络架构　7
1．3．3　GPU　11
1．4　深度学习为什么如此成功　11
1．4．1　特征学习（representation learning）　11
1．4．2　迁移学习（transfer learning）　12
1．5　小结　13
参考文献　14
第　2章 PyTorch简介　15
2．1　PyTorch安装　15
2．2　初识PyTorch　15
2．2．1　与Python的完美融合　16
2．2．2　张量计算　16
2．2．3　动态计算图　20
2．3　PyTorch实例：预测房价　27
2．3．1　准备数据　27
2．3．2　模型设计　28
2．3．3　训练　29
2．3．4　预测　31
2．3．5　术语汇总　32
2．4　小结　33
第3章　单车预测器：你的第 一个
神经网络　35
3．1　共享单车的烦恼　35
3．2　单车预测器1．0　37
3．2．1　神经网络简介　37
3．2．2　人工神经元　38
3．2．3　两个隐含层神经元　40
3．2．4　训练与运行　42
3．2．5　失败的神经预测器　43
3．2．6　过拟合　48
3．3　单车预测器2．0　49
3．3．1　数据的预处理过程　49
3．3．2　构建神经网络　52
3．3．3　测试神经网络　55
3．4　剖析神经网络Neu　57
3．5　小结　61
3．6　Q&A　61
第4章　机器也懂感情——中文情绪
分类器　63
4．1　神经网络分类器　64
4．1．1　如何用神经网络做分类　64
4．1．2　分类问题的损失函数　66
4．2　词袋模型分类器　67
4．2．1　词袋模型简介　68
4．2．2　搭建简单文本分类器　69
4．3　程序实现　70
4．3．1　数据获取　70
4．3．2　数据处理　74
4．3．3　文本数据向量化　75
4．3．4　划分数据集　76
4．3．5　建立神经网络　78
4．4　运行结果　80
4．5　剖析神经网络　81
4．6　小结　85
4．7　Q&A　85
第5章　手写数字识别器——认识卷积
神经网络　87
5．1　什么是卷积神经网络　88
5．1．1　手写数字识别任务的CNN
网络及运算过程　88
5．1．2　卷积运算操作　90
5．1．3　池化操作　96
5．1．4　立体卷积核　97
5．1．5　超参数与参数　98
5．1．6　其他说明　99
5．2　手写数字识别器　100
5．2．1　数据准备　100
5．2．2　构建网络　103
5．2．3　运行模型　105
5．2．4　测试模型　106
5．3　剖析卷积神经网络　107
5．3．1　第 一层卷积核与特征图　107
5．3．2　第二层卷积核与特征图　109
5．3．3　卷积神经网络的健壮性试验　110
5．4　小结　112
5．5　Q&A　112
5．6　扩展阅读　112
第6章　手写数字加法机——迁移学习　113
6．1　什么是迁移学习　114
6．1．1　迁移学习的由来　114
6．1．2　迁移学习的分类　115
6．1．3　迁移学习的意义　115
6．1．4　如何用神经网络实现迁移
学习　116
6．2　应用案例：迁移学习如何抗击贫困　118
6．2．1　背景介绍　118
6．2．2　方法探寻　119
6．2．3　迁移学习方法　120
6．3　蚂蚁还是蜜蜂：迁移大型卷积神经
网络　121
6．3．1　任务描述与初步尝试　121
6．3．2　ResNet与模型迁移　122
6．3．3　代码实现　123
6．3．4　结果分析　127
6．3．5　更多的模型与数据　128
6．4　手写数字加法机　128
6．4．1　网络架构　128
6．4．2　代码实现　129
6．4．3　训练与测试　136
6．4．4　结果　138
6．4．5　大规模实验　138
6．5　小结　143
6．6　实践项目：迁移与效率　143
第7章　你自己的Prisma——图像
风格迁移　145
7．1　什么是风格迁移　145
7．1．1　什么是风格　145
7．1．2　风格迁移的涵义　146
7．2　风格迁移技术发展简史　147
7．2．1　神经网络之前的风格迁移　147
7．2．2　特定风格的实现　148
7．3　神经网络风格迁移　149
7．3．1　神经网络风格迁移的优势　150
7．3．2　神经网络风格迁移的基本
思想　150
7．3．3　卷积神经网络的选取　151
7．3．4　内容损失　152
7．3．5　风格损失　152
7．3．6　风格损失原理分析　153
7．3．7　损失函数与优化　156
7．4　神经网络风格迁移实战　157
7．4．1　准备工作　157
7．4．2　建立风格迁移网络　159
7．4．3　风格迁移训练　162
7．5　小结　165
7．6　扩展阅读　165
第8章　人工智能造假术——图像生成
与对抗学习　166
8．1　反卷积与图像生成　169
8．1．1　CNN回顾　169
8．1．2　反卷积操作　171
8．1．3　反池化过程　173
8．1．4　反卷积与分数步伐　174
8．1．5　输出图像尺寸公式　175
8．1．6　批正则化技术　176
8．2　图像生成实验1——最小均方误差
模型　177
8．2．1　模型思路　177
8．2．2　代码实现　178
8．2．3　运行结果　182
8．3　图像生成实验2——生成器-识别器
模型　184
8．3．1　生成器-识别器模型的实现　184
8．3．2　对抗样本　187
8．4　图像生成实验3——生成对抗网络
GAN　190
8．4．1　GAN的总体架构　191
8．4．2　程序实现　192
8．4．3　结果展示　195
8．5　小结　197
8．6　Q&A　197
8．7　扩展阅读　198
第9章　词汇的星空——神经语言模型
与Word2Vec　199
9．1　词向量技术介绍　199
9．1．1　初识词向量　199
9．1．2　传统编码方式　200
9．2　NPLM：神经概率语言模型　201
9．2．1　NPLM的基本思想　202
9．2．2　NPLM的运作过程详解　202
9．2．3　读取NPLM中的词向量　205
9．2．4　NPLM的编码实现　206
9．2．5　运行结果　209
9．2．6　NPLM的总结与局限　211
9．3　Word2Vec　211
9．3．1　CBOW模型和Skip-gram模型的结构　211
9．3．2　层级软最大　213
9．3．3　负采样　213
9．3．4　总结及分析　214
9．4　Word2Vec的应用　214
9．4．1　在自己的语料库上训练Word2Vec词向量　214
9．4．2　调用现成的词向量　216
9．4．3　女人-男人＝皇后-国王　218
9．4．4　使用向量的空间位置进行词对词翻译　220
9．4．5　Word2Vec小结　221
9．5　小结　221
9．5　Q&A　222
第　10章 LSTM作曲机——序列生成
模型　224
10．1　序列生成问题　224
10．2　RNN与LSTM　225
10．2．1　RNN　226
10．2．2　LSTM　231
10．3　简单01序列的学习问题　235
10．3．1　RNN的序列学习　236
10．3．2　LSTM的序列学习　245
10．4　LSTM作曲机　248
10．4．1　MIDI文件　248
10．4．2　数据准备　249
10．4．3　模型结构　249
10．4．4　代码实现　250
10．5　小结　259
10．6　Q&A　259
10．7　扩展阅读　259
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习原理与PyTorch实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习之PyTorch实战计算机视觉
第1章  浅谈人工智能、神经网络和计算机视觉  1
1.1  人工还是智能  1
1.2  人工智能的三起两落  2
1.2.1  两起两落  2
1.2.2  卷土重来  3
1.3  神经网络简史  5
1.3.1  生物神经网络和人工神经网络  5
1.3.2  M-P模型  6
1.3.3  感知机的诞生  9
1.3.4  你好，深度学习  10
1.4  计算机视觉  11
1.5  深度学习+  12
1.5.1  图片分类  12
1.5.2  图像的目标识别和语义分割  13
1.5.3  自动驾驶  13
1.5.4  图像风格迁移  14
第2章  相关的数学知识  15
2.1  矩阵运算入门  15
2.1.1  标量、向量、矩阵和张量  15
2.1.2  矩阵的转置  17
2.1.3  矩阵的基本运算  18
2.2  导数求解  22
2.2.1  一阶导数的几何意义  23
2.2.2  初等函数的求导公式  24
2.2.3  初等函数的和、差、积、商求导  26
2.2.4  复合函数的链式法则  27
第3章  深度神经网络基础  29
3.1  监督学习和无监督学习  29
3.1.1  监督学习  30
3.1.2  无监督学习  32
3.1.3  小结  33
3.2  欠拟合和过拟合  34
3.2.1  欠拟合  34
3.2.2  过拟合  35
3.3  后向传播  36
3.4  损失和优化  38
3.4.1  损失函数  38
3.4.2  优化函数  39
3.5  激活函数  42
3.5.1  Sigmoid  44
3.5.2  tanh  45
3.5.3  ReLU  46
3.6  本地深度学习工作站  47
3.6.1  GPU和CPU  47
3.6.2  配置建议  49
第4章  卷积神经网络  51
4.1  卷积神经网络基础  51
4.1.1  卷积层  51
4.1.2  池化层  54
4.1.3  全连接层  56
4.2  LeNet模型  57
4.3  AlexNet模型  59
4.4  VGGNet模型  61
4.5  GoogleNet  65
4.6  ResNet  69
第5章  Python基础  72
5.1  Python简介  72
5.2  Jupyter Notebook  73
5.2.1  Anaconda的安装与使用  73
5.2.2  环境管理  76
5.2.3  环境包管理  77
5.2.4  Jupyter Notebook的安装  79
5.2.5  Jupyter Notebook的使用  80
5.2.6  Jupyter Notebook常用的快捷键  86
5.3  Python入门  88
5.3.1  Python的基本语法  88
5.3.2  Python变量  92
5.3.3  常用的数据类型  94
5.3.4  Python运算  99
5.3.5  Python条件判断语句  107
5.3.6  Python循环语句  109
5.3.7  Python中的函数  113
5.3.8  Python中的类  116
5.4  Python中的NumPy  119
5.4.1  NumPy的安装  119
5.4.2  多维数组  119
5.4.3  多维数组的基本操作  125
5.5  Python中的Matplotlib  133
5.5.1  Matplotlib的安装  133
5.5.2  创建图  133
第6章  PyTorch基础  142
6.1  PyTorch中的Tensor  142
6.1.1  Tensor的数据类型  143
6.1.2  Tensor的运算  146
6.1.3  搭建一个简易神经网络  153
6.2  自动梯度  156
6.2.1  torch.autograd和Variable  156
6.2.2  自定义传播函数  159
6.3  模型搭建和参数优化  162
6.3.1  PyTorch之torch.nn  162
6.3.2  PyTorch之torch.optim  167
6.4  实战手写数字识别  169
6.4.1  torch和torchvision  170
6.4.2  PyTorch之torch.transforms  171
6.4.3  数据预览和数据装载  173
6.4.4  模型搭建和参数优化  174
第7章  迁移学习  180
7.1  迁移学习入门  180
7.2  数据集处理  181
7.2.1  验证数据集和测试数据集  182
7.2.2  数据预览  182
7.3  模型搭建和参数优化  185
7.3.1  自定义VGGNet  185
7.3.2  迁移VGG16  196
7.3.3  迁移ResNet50  203
7.4  小结  219
第8章  图像风格迁移实战  220
8.1  风格迁移入门  220
8.2  PyTorch图像风格迁移实战  222
8.2.1  图像的内容损失  222
8.2.2  图像的风格损失  223
8.2.3  模型搭建和参数优化  224
8.2.4  训练新定义的卷积神经网络  226
8.3  小结  232
第9章  多模型融合  233
9.1  多模型融合入门  233
9.1.1  结果多数表决  234
9.1.2  结果直接平均  236
9.1.3  结果加权平均  237
9.2  PyTorch之多模型融合实战  239
9.3  小结  246
第10章  循环神经网络  247
10.1  循环神经网络入门  247
10.2  PyTorch之循环神经网络实战  249
10.3  小结  257
第11章  自动编码器  258
11.1  自动编码器入门  258
11.2  PyTorch之自动编码实战  259
11.2.1  通过线性变换实现自动编码器模型  260
11.2.2  通过卷积变换实现自动编码器模型  267
11.3  小结  273
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习之PyTorch实战计算机视觉
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习框架PyTorch快速开发与实战
第一部分  理论部分
第1章  深度学习简介  2
1.1  深度学习  2
1.2  神经网络的发展  6
1.3  深度学习的应用  7
1.4  常用的数学知识和机器学习算法  8
1.5  PyTorch简介  11
1.5.1  PyTorch介绍  11
1.5.2  使用PyTorch的公司  15
1.5.3  PyTorch API  16
1.5.4  为什么选择Python语言  16
1.5.5  Python语言的特点  16
1.6  常用的机器学习、深度学习开源框架  17
1.7  其他常用的模块库  19
1.8  深度学习常用名词  20
第2章  PyTorch环境安装  33
2.1  基于Ubuntu环境的安装  33
2.1.1  安装Anaconda  35
2.1.2  设置国内镜像  36
2.2  Conda命令安装PyTorch  37
2.3  pip命令安装PyTorch  37
2.4  配置CUDA  38
第3章  PyTorch基础知识  40
3.1  张量  40
3.2  数学操作  43
3.3  数理统计  44
3.4  比较操作  45
第4章  简单案例入门  47
4.1  线性回归  47
4.2  逻辑回归  52
第5章  前馈神经网络  59
5.1  实现前馈神经网络  61
5.2  数据集  68
5.3  卷积层  72
5.4  Functional函数  75
5.5  优化算法  82
5.6  自动求导机制  85
5.7  保存和加载模型  87
5.8  GPU加速运算  87
第6章  PyTorch可视化工具  89
6.1  Visdom介绍  89
6.2  Visdom基本概念  90
6.2.1  Panes（窗格）  90
6.2.2  Environments（环境）  90
6.2.3  State（状态）  91
6.3  安装Visdom  91
6.4  可视化接口  91
6.4.1  Python函数属性提取技巧  92
6.4.2  vis.text  93
6.4.3  vis.image  93
6.4.4  vis.scatter  94
6.4.5  vis.line  95
6.4.6  vis.stem  97
6.4.7  vis.heatmap  97
6.4.8  vis.bar  99
6.4.9  vis.histogram  101
6.4.10  vis.boxplot  102
6.4.11  vis.surf  103
6.4.12  vis.contour  104
6.4.13  vis.mesh  106
6.4.14  vis.svg  107
第二部分  实战部分
第7章  卷积神经网络  110
7.1  卷积层  112
7.2  池化层  114
7.3  经典的卷积神经网络  115
7.3.1  LeNet-5神经网络结构  115
7.3.2  ImageNet-2010网络结构  117
7.3.3  VGGNet网络结构  122
7.3.4  GoodLeNet网络结构  124
7.3.5  ResNet网络结构  126
7.4  卷积神经网络案例  129
7.5  深度残差模型案例  138
第8章  循环神经网络简介  145
8.1  循环神经网络模型结构  146
8.2  不同类型的RNN  147
8.3  LSTM结构具体解析  151
8.4  LSTM的变体  153
8.5  循环神经网络实现  156
8.5.1  循环神经网络案例  156
8.5.2  双向RNN案例  160
第9章  自编码模型  164
第10章  对抗生成网络  172
10.1  DCGAN原理  175
10.2  GAN对抗生成网络实例  180
第11章  Seq2seq自然语言处理  186
11.1  Seq2seq自然语言处理简介  186
11.2  Seq2seq自然语言处理案例  188
第12章  利用PyTorch实现量化交易  204
12.1  线性回归预测股价  205
12.2  前馈神经网络预测股价  209
12.3  递归神经网络预测股价  214
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>深度学习框架PyTorch快速开发与实战
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>白话强化学习与PyTorch
第1章  强化学习是什么
1.1 题设
1.1.1 多智能才叫智能
1.1.2 人工智能的定义
1.2 强化学习的研究对象
1.2.1 什么场合需要强化学习
1.2.2 强化学习的建模
1.3 本章小结
第2章  强化学习的脉络
2.1 什么是策略
2.2 什么是好的策略
2.3 什么是模型
2.4 如何得到一个好的策略
2.4.1 直接法
2.4.2 间接法
2.5 马尔可夫决策过程
2.5.1 状态转移
2.5.2 策略与评价
2.5.3 策略优化
2.6 MODEL-BASED和MODEL-FREE
2.6.1 Model-Based
2.6.2 规划问题
2.6.3 Model-Free
2.7 本章小结
第3章  动态规划
3.1 状态估值
3.2 策略优化
3.3 本章小结
第4章  蒙特卡罗法
4.1 状态估值
4.2 两种估值方法
4.2.1 首次访问策略估值
4.2.2 每次访问策略估值
4.3 策略优化
4.4 本章小结
第5章  时间差分
5.1 SARSA算法
5.1.1 伪代码
5.1.2 SARSA的优缺点
5.2 Q-LEARNING
5.2.1 伪代码
5.2.2 Q-Learning的优缺点
5.3 ON-POLICY和OFF-POLICY
5.4 ON-LINE学习和OFF-LINE学习
5.5 比较与讨论
5.6 本章小结
第6章  深度学习
6.1 PyTorch简介
6.1.1 历史渊源
6.1.2 支持
6.2 神经元
6.3 线性回归
6.4 激励函数
6.4.1 Sigmoid函数
6.4.2 Tanh函数
6.4.3 ReLU函数
6.4.4 Linear函数
6.5 神经网络
6.6 网络训练
6.6.1 输入
6.6.2 输出
6.6.3 网络结构
6.6.4 损失函数
6.6.5 求解极小值
6.6.6 线性回归
6.6.7 凸函数
6.6.8 二元（多元）凸函数
6.6.9 导数补充
6.6.10 导数怎么求
6.6.11 “串联式”神经元
6.6.12 模型的工作
6.6.13 损失函数的理解
6.7 深度学习的优势
6.7.1 线性和非线性的叠加
6.7.2 不用再提取特征
6.7.3 处理线性不可分
6.8 手写数字识别公开数据集
6.9 全连接网络
6.9.1 输入输出
6.9.2 代码解读
6.9.2.1 网络结构
6.9.2.2 交叉熵损失函数
6.9.3 运行结果
6.10 卷积网络
6.10.1 代码解读
6.10.2 理解卷积网络结构
6.10.3 卷积核结构
6.11 循环神经网络
6.11.1 网络结构
6.11.2 RNN应用案例
6.11.3 代码解读
6.12 其它注意事项
6.12.1 并行计算
6.12.2 梯度消失与梯度爆炸
6.12.3 归一化
6.12.4 超参数设置
6.12.5 正则化
6.12.6 不唯一的模型
6.13 深度神经网络的发展趋势
6.14 本章小结
第7章  GYM——不要钱的试验场
7.1 简介
7.2 安装
7.3 类别介绍
7.4 接口
7.5 本章小结
第8章  DQN算法族
8.1 DQN 2013
8.1.1 模型结构
8.1.2 训练过程
8.1.3 Replay Memory
8.1.4 小结
8.2 DQN 2015
8.2.1 模型结构
8.2.2 训练过程
8.2.3 Target网络
8.2.4 小结
8.3 DOUBLE DQN
8.3.1 模型结构
8.3.2 训练过程
8.3.3 效果
8.3.4 小结
8.4 DUELING DQN
8.4.1 模型结构
8.4.2 效果
8.4.3 小结
8.5 优先回放DQN
8.6 GORILA DQN
8.7 本章小结
第9章  PG算法族
9.1 策略梯度
9.2 ACTOR-CRITIC
9.3 DPG
9.4 DDPG
9.5 本章小结
第10章  A3C
10.1 模型结构
10.1.1 A3C DQN
10.1.2 A3C DDPG
10.2 本章小结
第11章、UNREAL
11.1 主任务
11.2 像素控制任务
11.3 奖励值预测
11.4 值函数回放
11.5 损失函数
11.6 本章小结
第12章  NEAT
12.1 遗传算法
12.1.1 进化过程
12.1.2 算法流程
12.1.3 背包问题
12.1.4 极大（小）值问题
12.2 NEAT原理
12.2.1 基因组
12.2.2 变异和遗传
12.3 NEAT示例
12.3.1 Cartpole
12.3.2 Lunar Lander
12.4 本章小结
第13章  SERPENTAI
13.1 简介
13.2 安装配置
13.3 示例
13.3.1 创建Game Plugin
13.3.2 创建Game Agent
13.3.3 训练Context Classifier
13.3.4 模型设计
13.3.5 训练Agent
13.4 本章小结
第14章  案例详解
14.1 ALPHAGO
14.1.1 AlphaGO的前世今生
14.1.2 深蓝是谁
14.1.3 围棋到底有多复杂
14.1.4 论文要义
14.1.5 成绩
14.1.6 开源项目
14.2 ALPHAGO ZERO
14.2.1 改进之处
14.2.2 成绩
14.2.3 开源项目
14.3 试验场大观
14.3.1 《星际争霸2》
14.3.2 VizDoom
14.3.3 Universe
14.3.4 DOTA2
14.4 本章小结
第15章  扩展讨论
15.1 TRPO
15.2 反向强化学习
15.3 模型压缩
15.3.1 剪枝
15.3.2 量化
15.3.3 结构压缩
15.3.4 矩阵分解
15.4 本章小结
后记
附录
参考文献
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>白话强化学习与PyTorch
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python深度学习：基于PyTorch
Contents  目　　录
前言
第一部分　PyTorch基础
第1章　Numpy基础2
1.1　生成Numpy数组3
1.1.1　从已有数据中创建数组3
1.1.2　利用random模块生成数组4
1.1.3　创建特定形状的多维数组5
1.1.4　利用arange、linspace函数生成数组6
1.2　获取元素7
1.3　Numpy的算术运算9
1.3.1　对应元素相乘9
1.3.2　点积运算10
1.4　数组变形11
1.4.1　更改数组的形状11
1.4.2　合并数组14
1.5　批量处理16
1.6　通用函数17
1.7　广播机制19
1.8　小结20
第2章　PyTorch基础21
2.1　为何选择PyTorch？21
2.2　安装配置22
2.2.1　安装CPU版PyTorch22
2.2.2　安装GPU版PyTorch24
2.3　Jupyter Notebook环境配置26
2.4　Numpy与Tensor28
2.4.1　Tensor概述28
2.4.2　创建Tensor28
2.4.3　修改Tensor形状30
2.4.4　索引操作31
2.4.5　广播机制32
2.4.6　逐元素操作32
2.4.7　归并操作33
2.4.8　比较操作34
2.4.9　矩阵操作35
2.4.10　PyTorch与Numpy比较35
2.5　Tensor与Autograd36
2.5.1　自动求导要点36
2.5.2　计算图37
2.5.3　标量反向传播38
2.5.4　非标量反向传播39
2.6　使用Numpy实现机器学习41
2.7　使用Tensor及Antograd实现机器学习44
2.8　使用TensorFlow架构46
2.9　小结48
第3章　PyTorch神经网络工具箱49
3.1　神经网络核心组件49
3.2　实现神经网络实例50
3.2.1　背景说明51
3.2.2　准备数据52
3.2.3　可视化源数据53
3.2.4　构建模型53
3.2.5　训练模型54
3.3　如何构建神经网络？56
3.3.1　构建网络层56
3.3.2　前向传播57
3.3.3　反向传播57
3.3.4　训练模型58
3.4　神经网络工具箱nn58
3.4.1　nn.Module58
3.4.2　nn.functional58
3.5　优化器59
3.6　动态修改学习率参数60
3.7　优化器比较60
3.8　小结62
第4章　PyTorch数据处理工具箱63
4.1　数据处理工具箱概述63
4.2　utils.data简介64
4.3　torchvision简介66
4.3.1　transforms67
4.3.2　ImageFolder67
4.4　可视化工具69
4.4.1　tensorboardX简介69
4.4.2　用tensorboardX可视化神经网络71
4.4.3　用tensorboardX可视化损失值72
4.4.4　用tensorboardX可视化特征图73
4.5　本章小结74
第二部分　深度学习基础
第5章　机器学习基础76
5.1　机器学习的基本任务76
5.1.1　监督学习77
5.1.2　无监督学习77
5.1.3　半监督学习78
5.1.4　强化学习78
5.2　机器学习一般流程78
5.2.1　明确目标79
5.2.2　收集数据79
5.2.3　数据探索与预处理79
5.2.4　选择模型及损失函数80
5.2.5　评估及优化模型81
5.3　过拟合与欠拟合81
5.3.1　权重正则化82
5.3.2　Dropout正则化83
5.3.3　批量正则化86
5.3.4　权重初始化88
5.4　选择合适激活函数89
5.5　选择合适的损失函数90
5.6　选择合适优化器92
5.6.1　传统梯度优化的不足93
5.6.2　动量算法94
5.6.3　AdaGrad算法96
5.6.4　RMSProp算法97
5.6.5　Adam算法98
5.7　GPU加速99
5.7.1　单GPU加速100
5.7.2　多GPU加速101
5.7.3　使用GPU注意事项104
5.8　本章小结104
第6章　视觉处理基础105
6.1　卷积神经网络简介105
6.2　卷积层107
6.2.1　卷积核108
6.2.2　步幅109
6.2.3　填充111
6.2.4　多通道上的卷积111
6.2.5　激活函数113
6.2.6　卷积函数113
6.2.7　转置卷积114
6.3　池化层115
6.3.1　局部池化116
6.3.2　全局池化117
6.4　现代经典网络119
6.4.1　LeNet-5模型119
6.4.2　AlexNet模型120
6.4.3　VGG模型121
6.4.4　GoogleNet模型122
6.4.5　ResNet模型123
6.4.6　胶囊网络简介124
6.5　PyTorch实现CIFAR-10多分类125
6.5.1　数据集说明125
6.5.2　加载数据125
6.5.3　构建网络127
6.5.4　训练模型128
6.5.5　测试模型129
6.5.6　采用全局平均池化130
6.5.7　像Keras一样显示各层参数131
6.6　模型集成提升性能133
6.6.1　使用模型134
6.6.2　集成方法134
6.6.3　集成效果135
6.7　使用现代经典模型提升性能136
6.8　本章小结137
第7章　自然语言处理基础138
7.1　循环神经网络基本结构138
7.2　前向传播与随时间反向传播140
7.3　循环神经网络变种143
7.3.1　LSTM144
7.3.2　GRU145
7.3.3　Bi-RNN146
7.4　循环神经网络的PyTorch实现146
7.4.1　RNN实现147
7.4.2　LSTM实现149
7.4.3　GRU实现151
7.5　文本数据处理152
7.6　词嵌入153
7.6.1　Word2Vec原理154
7.6.2　CBOW模型155
7.6.3　Skip-Gram模型155
7.7　PyTorch实现词性判别156
7.7.1　词性判别主要步骤156
7.7.2　数据预处理157
7.7.3　构建网络157
7.7.4　训练网络158
7.7.5　测试模型160
7.8　用LSTM预测股票行情160
7.8.1　 导入数据160
7.8.2　数据概览161
7.8.3　预处理数据162
7.8.4　定义模型163
7.8.5　训练模型163
7.8.6　测试模型164
7.9　循环神经网络应用场景165
7.10　小结166
第8章　生成式深度学习167
8.1　用变分自编码器生成图像167
8.1.1　自编码器168
8.1.2　变分自编码器168
8.1.3　用变分自编码器生成图像169
8.2　GAN简介173
8.2.1　GAN架构173
8.2.2　GAN的损失函数174
8.3　用GAN生成图像175
8.3.1　判别器175
8.3.2　生成器175
8.3.3　训练模型175
8.3.4　可视化结果177
8.4　VAE与GAN的优缺点178
8.5　ConditionGAN179
8.5.1　CGAN的架构179
8.5.2　CGAN生成器180
8.5.3　CGAN判别器180
8.5.4　CGAN损失函数181
8.5.5　CGAN可视化181
8.5.6　查看指定标签的数据182
8.5.7　可视化损失值182
8.6　DCGAN183
8.7　提升GAN训练效果的一些技巧184
8.8　小结185
第三部分　深度学习实践
第9章　人脸检测与识别188
9.1　人脸识别一般流程188
9.2　人脸检测189
9.2.1　目标检测189
9.2.2　人脸定位191
9.2.3　人脸对齐191
9.2.4　MTCNN算法192
9.3　特征提取193
9.4　人脸识别198
9.4.1　人脸识别主要原理198
9.4.2　人脸识别发展198
9.5　PyTorch实现人脸检测与识别199
9.5.1　验证检测代码199
9.5.2　检测图像200
9.5.3　检测后进行预处理200
9.5.4　查看经检测后的图像201
9.5.5　人脸识别202
9.6　小结202
第10章　迁移学习实例203
10.1　迁移学习简介203
10.2　特征提取204
10.2.1　PyTorch提供的预处理模块205
10.2.2　特征提取实例206
10.3　数据增强209
10.3.1　按比例缩放209
10.3.2　裁剪210
10.3.3　翻转210
10.3.4　改变颜色211
10.3.5　组合多种增强方法211
10.4　微调实例212
10.4.1　数据预处理212
10.4.2　加载预训练模型213
10.4.3　修改分类器213
10.4.4　选择损失函数及优化器213
10.4.5　训练及验证模型214
10.5　清除图像中的雾霾214
10.6　小结217
第11章　神经网络机器翻译实例218
11.1　Encoder-Decoder模型原理218
11.2　注意力框架220
11.3　PyTorch实现注意力Decoder224
11.3.1　构建Encoder224
11.3.2　构建简单Decoder225
11.3.3　构建注意力Decoder226
11.4　用注意力机制实现中英文互译227
11.4.1　导入需要的模块228
11.4.2　数据预处理228
11.4.3　构建模型231
11.4.4　训练模型234
11.4.5　随机采样，对模型进行测试235
11.4.6　可视化注意力236
11.5　小结237
第12章　实战生成式模型238
12.1　DeepDream模型238
12.1.1　Deep Dream原理238
12.1.2　DeepDream算法流程239
12.1.3　用PyTorch实现Deep Dream240
12.2　风格迁移243
12.2.1　内容损失244
12.2.2　风格损失245
12.2.3　用PyTorch实现神经网络风格迁移247
12.3　PyTorch实现图像修复252
12.3.1　网络结构252
12.3.2　损失函数252
12.3.3　图像修复实例253
12.4　PyTorch实现DiscoGAN255
12.4.1　DiscoGAN架构256
12.4.2　损失函数258
12.4.3　DiscoGAN实现258
12.4.4　用PyTorch实现从边框生成鞋子260
12.5　小结262
第13章　Caffe2模型迁移实例263
13.1　Caffe2简介263
13.2　Caffe如何升级到Caffe2264
13.3　PyTorch如何迁移到Caffe2265
13.4　小结268
第14章　AI新方向：对抗攻击269
14.1　对抗攻击简介269
14.1.1　白盒攻击与黑盒攻击270
14.1.2　无目标攻击与有目标攻击270
14.2　常见对抗样本生成方式271
14.2.1　快速梯度符号法271
14.2.2　快速梯度算法271
14.3　PyTorch实现对抗攻击272
14.3.1　实现无目标攻击272
14.3.2　实现有目标攻击274
14.4　对抗攻击和防御措施276
14.4.1　对抗攻击276
14.4.2　常见防御方法分类276
14.5　总结277
第15章　强化学习278
15.1　强化学习简介278
15.2　Q-Learning原理281
15.2.1　Q-Learning主要流程281
15.2.2　Q函数282
15.2.3　贪婪策略283
15.3　用PyTorch实现Q-Learning283
15.3.1　定义Q-Learing主函数283
15.3.2　执行Q-Learing284
15.4　SARSA算法285
15.4.1　SARSA算法主要步骤285
15.4.2　用PyTorch实现SARSA算法286
15.5　小结287
第16章　深度强化学习288
16.1　DQN算法原理288
16.1.1　Q-Learning方法的局限性289
16.1.2　用DL处理RL需要解决的问题289
16.1.3　用DQN解决方法289
16.1.4　定义损失函数290
16.1.5　DQN的经验回放机制290
16.1.6　目标网络290
16.1.7　网络模型291
16.1.8　DQN算法291
16.2　用PyTorch实现DQN算法292
16.3　小结295
附录A　PyTorch0.4版本变更296
附录B　AI在各行业的最新应用301
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Python深度学习：基于PyTorch
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch深度学习入门
前言	阅读
第一部分　基础篇
第1章　准备工作
第2章　Tensor基础
第3章　深度学习基础	阅读
第二部分　实战篇
第4章　迁移学习
第5章　序列转序列模型
第6章　生成对抗网络
第7章　深度强化学习
第8章　风格迁移
第三部分　高级篇
第9章　PyTorch扩展
第10章　PyTorch模型迁移
第11章　PyTorch可视化
第12章　PyTorch的并行计算
>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>PyTorch深度学习入门
